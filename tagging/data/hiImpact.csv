year,title,abstract,full_text
2002,Networks on Chips - A New SoC Paradigm.,"On-chip micronetworks, designed with a layered methodology, will meet the distinctive challenges of providing functionally correct, reliable operation of interacting system-on-chip components. A system on chip (SoC) can provide an integrated solution to challenging design problems in the telecommunications, multimedia, and consumer electronics domains. Much of the progress in these fields hinges on the designers' ability to conceive complex electronic engines under strong time-to-market pressure. Success will require using appropriate design and process technologies, as well as interconnecting existing components reliably in a plug-and-play fashion. Focusing on using probabilistic metrics such as average values or variance to quantify design objectives such as performance and power will lead to a major change in SoC design methodologies. Overall, these designs will be based on both deterministic and stochastic models. Creating complex SoCs requires a modular, component-based approach to both hardware and software design. Despite numerous challenges, the authors believe that developers will solve the problems of designing SoC networks. At the same time, they believe that a layered micronetwork design methodology will likely be the only path to mastering the complexity of future SoC designs.",
2006,A survey of research and practices of Network-on-chip.,"The scaling of microchip technologies has enabled large scale systems-on-chip (SoC). Network-on-chip (NoC) research addresses global communication in SoC, involving (i) a move from computation-centric to communication-centric design and (ii) the implementation of scalable communication structures. This survey presents a perspective on existing NoC research. We define the following abstractions: system, network adapter, network, and link to explain and structure the fundamental concepts. First, research relating to the actual network design is reviewed. Then system level design and modeling are discussed. We also evaluate performance analysis techniques. The research shows that NoC constitutes a unification of current trends of intrachip communication rather than an explicit new alternative.",
2002,A Network on Chip Architecture and Design Methodology.,"We propose a packet switched platform for single chip systems which scales well to an arbitrary number of processor like resources. The platform, which we call Network-on-Chip (NOC), includes both the architecture and the design methodology. The NOC architecture is a m/spl times/n mesh of switches and resources are placed on the slots formed by the switches. We assume a direct layout of the 2-D mesh of switches and resources providing physical- and architectural-level design integration. Each switch is connected to one resource and four neighboring switches, and each resource is connected to one switch. A resource can be a processor core, memory, an FPGA, a custom hardware block or any other intellectual property (IP) block, which fits into the available slot and complies with the interface of the NOC. The NOC architecture essentially is the onchip communication infrastructure comprising the physical layer, the data link layer and the network layer of the OSI protocol stack. We define the concept of a region, which occupies an area of any number of resources and switches. This concept allows the NOC to accommodate large resources such as large memory banks, FPGA areas, or special purpose computation resources such as high performance multi-processors. The NOC design methodology consists of two phases. In the first phase a concrete architecture is derived from the general NOC template. The concrete architecture defines the number of switches and shape of the network, the kind and shape of regions and the number and kind of resources. The second phase maps the application onto the concrete architecture to form a concrete product.",
2007,On-Chip Interconnection Architecture of the Tile Processor.,"IMesh, the tile processor architecture's on-chip interconnection network, connects the multicore processor's tiles with five 2D mesh networks, each specialized for a different use. taking advantage of the five networks, the C-based ILIB interconnection library efficiently maps program communication across the on-chip interconnect. the tile processor's first implementation, the tile64, contains 64 cores and can execute 192 billion 32-bit operations per second at 1 Ghz.",
2005,Performance Evaluation and Design Trade-Offs for Network-on-Chip Interconnect Architectures.,"Multiprocessor system-on-chip (MP-SoC) platforms are emerging as an important trend for SoC design. Power and wire design constraints are forcing the adoption of new design methodologies for system-on-chip (SoC), namely, those that incorporate modularity and explicit parallelism. To enable these MP-SoC platforms, researchers have recently pursued scaleable communication-centric interconnect fabrics, such as networks-on-chip (NoC), which possess many features that are particularly attractive for these. These communication-centric interconnect fabrics are characterized by different trade-offs with regard to latency, throughput, energy dissipation, and silicon area requirements. In this paper, we develop a consistent and meaningful evaluation methodology to compare the performance and characteristics of a variety of NoC architectures. We also explore design trade-offs that characterize the NoC approach and obtain comparative results for a number of common NoC topologies. To the best of our knowledge, this is the first effort in characterizing different NoC architectures with respect to their performance and design trade-offs. To further illustrate our evaluation methodology, we map a typical multiprocessing platform to different NoC interconnect architectures and show how the system performance is affected by these design trade-offs.","IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 1025 Performance Evaluation and Design Trade-Offs for Network-on-Chip Interconnect Architectures Partha Prat im Pande, Student Member, IEEE, Cr ist ian Grecu, Michae l Jones, Andre´ Ivanov, Sen ior Member, IEEE, and Resve Sa leh, Sen ior Member, IEEE Abstract—Multiprocessor system-on-chip (MP-SoC) platforms are emerging as an important trend for SoC design. Power and wire design constraints are forcing the adoption of new design methodologies for system-on-chip (SoC), namely, those that incorporate modularity and explicit parallelism. To enable these MP-SoC platforms, researchers have recently pursued scaleable communicationcentric interconnect fabrics, such as networks-on-chip (NoC), which possess many features that are particularly attractive for these. These communication-centric interconnect fabrics are characterized by different trade-offs with regard to latency, throughput, energy dissipation, and silicon area requirements. In this paper, we develop a consistent and meaningful evaluation methodology to compare the performance and characteristics of a variety of NoC architectures. We also explore design trade-offs that characterize the NoC approach and obtain comparative results for a number of common NoC topologies. To the best of our knowledge, this is the first effort in characterizing different NoC architectures with respect to their performance and design trade-offs. To further illustrate our evaluation methodology, we map a typical multiprocessing platform to different NoC interconnect architectures and show how the system performance is affected by these design trade-offs. Index Terms—Network-on-chip, MP-SoC, infrastructure IP, interconnect architecture, system-on-chip. æ 1 INTRODUCTION AND MOTIVATION SOC design methodologies will undergo revolutionary changes in the years to come. According to recent publications [1], [2], [3], the emergence of SoC platforms consisting of a large set of embedded processors is imminent. A key component of these multiprocessor SoC (MP-SoC) platforms [2] is the interconnect topology. Such SoCs imply the seamless integration of numerous IPs performing different functions and operating at different clock frequencies. The integration of several components into a single system gives rise to new challenges. It is critical that infrastructure IP (I2P) [4] be developed for a systematic integration of numerous functional IP blocks to enable the widespread use of the SoC design methodology. One of the major problems associated with future SOC designs arises from nonscalable global wire delays. Global wires carry signals across a chip, but these wires typically do not scale in length with technology scaling [5]. Though gate delays scale down with technology, global wire delays typically increase exponentially or, at best, linearly by inserting repeaters. Even after repeater insertion [5], the delay may exceed the limit of one clock cycle (often, multiple clock cycles). In ultra-deep submicron processes, 80 percent or more of the delay of critical paths will be due to interconnects [6], [7]. In fact, many large designs today use FIFO (first-in, first-out) buffers to synchronously propagate data over large distances to overcome this . The authors are with the SOC Research Lab, Department of Electrical and Computer Engineering, University of British Columbia, 2356 Main Mall, Vancouver, BC, V6T 1Z4 Canada. E-mail: {parthap, grecuc, michaelj, ivanov, res}@ece.ubc.ca. Manuscript received 28 May 2004; revised 21 Nov. 2004; accepted 8 Mar. 2004; published online 15 June 2005. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TC-0183-0504. problem. This solution is ad hoc in nature. According to ITRS (2003 update) [8], “Global synchronization becomes prohibitively costly due to process variability and power dissipation, and cross-chip signaling can no longer be achieved in a single clock cycle.” Thus, system design must incorporate networking and distributed computation paradigms with communication structures designed first and then functional blocks integrated into the communication backbone. The most frequently used on-chip interconnect architecture is the shared medium arbitrated bus, where all communication devices share the same transmission medium. The advantages of the shared-bus architecture are simple topology, low area cost, and extensibility. However, for a relatively long bus line, the intrinsic parasitic resistance and capacitance can be quite high. Moreover, every additional IP block connected to the bus adds to this parasitic capacitance, in turn causing increased propagation delay. As the bus length increases and/or the number of IP blocks increases, the associated delay in bit transfer over the bus may grow to become arbitrarily large and will eventually exceed the targeted clock period. This thus limits, in practice, the number of IP blocks that can be connected to a bus and thereby limits the system scalability [9]. One solution for such cases is to split the bus into multiple segments and introduce a hierarchical architecture [10], however, this is ad hoc in nature and has the inherent limitations of the bus-based systems. For SoCs consisting of tens or hundreds of IP blocks, bus-based interconnect architectures will lead to serious bottleneck problems as all attached devices must share the bandwidth of the bus [9]. To overcome the above-mentioned problems, several research groups, including our group, have advocated the use of a communication-centric approach to integrate IPs in complex SoCs. This new model allows the decoupling of the processing elements (i.e., the IPs) from the communication fabric (i.e., the network). The need for global synchronization 0018-9340/05/$20.00 ß 2005 IEEE Published by the IEEE Computer Society 1026 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 1. NoC architectures. (a) SPIN, (b) CLICH EE, (c) Torus, (d) Folded torus, (e) Octagon, (f) BFT. can thereby disappear. This new approach employs explicit parallelism, exhibits modularity to minimize the use of global wires, and utilizes locality for power minimization [3]. In a network-centric approach, the communication between IPs can take place in the form of packets. We suggest that a network-on-chip (NoC) resemble the interconnect architecture of high-performance parallel computing systems. The common characteristic of these kinds of architectures is that the functional IP blocks communicate with each other with the help of intelligent switches. As such, the switches can be considered as infrastructure IPs (I2Ps) [3] providing a robust data transfer medium for the functional IP modules. A number of different interconnect architectures for MPSoC platforms have been proposed. Their origins can be traced back to the field of parallel computing. However, a different set of constraints exists when adapting these architectures to the SoC design paradigm. High throughput and low latency are the desirable characteristics of a multiprocessing system. Instead of aiming strictly for speed, designers increasingly need to consider energy consumption constraints [3], especially in the SoC domain. None of the existing works on NoCs has compared the proposed interconnect architectures relative to throughput, latency, and energy. The main focus of this paper is the detailed comparative evaluation of a set of recently proposed NoC architectures with realistic traffic models. Our work furthers the body of knowledge associated with the design and analysis of such complex architectures and our analysis allows us to identify useful design trade-offs that are critical for the optimal development of integrated network-based designs. 2 RELATED WORK Current SoC designs predominantly use shared-medium bus-based functional interconnects to integrate IP blocks. There are mainly three types of commercial bus-based SoC interconnect specifications: ARM AMBA [11] bus, Wishbone [12], and IBM CoreConnect [13]. In [10], bus splitting has been proposed as an efficient solution for energy savings. A few on-chip micronetwork proposals for SoC integration can be found in the literature. Sonic’s Silicon Backplane [14] is one example. In this architecture, IP blocks are connected to the communication fabric through specialized interfaces called agents. Each core communicates with an agent using the Open Core Protocol (OCP) [15]. Agents communicate with each other using time division-multiple access (TDMA) bus access schemes. These agents effectively decouple the IP cores from the communication network. MIPS Technologies has introduced an on-chip switch integrating IP blocks in an SoC [16]. The switch, called SoC-it, is intended to provide a high-performance link between a MIPS processor and multiple third-party IP cores. It is a central switch connecting different peripherals, but only in a point-to-point mode. None of these involves any specific interconnect architecture. Hence, we omit treating this approach any further in the remainder of this paper. In the following, we briefly describe the different NoC architectures proposed recently. For the purpose of illustration, the functional IP blocks are denoted by white squares, while the infrastructure IPs (switches) are denoted by dark squares. Guerrier and Greiner [17] have proposed a generic interconnect template called SPIN (Scalable, Programmable, Integrated Network) for on-chip packet switched interconnections, where a fat-tree architecture is used to interconnect IP blocks. In this fat tree, every node has four children and the parent is replicated four times at any level of the tree. Fig. 1a shows the basic SPIN architecture with N ¼ 16 nodes, representing the number of functional IP blocks in the system. The size of the network grows as ðN logN Þ=8. The functional IP blocks reside at the leaves and the switches reside at the vertices. In this architecture, the number of switches converges to S ¼ 3N 4 , where N is the system size in terms of number of functional IPs. PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1027 Kumar et al. [18] have proposed a mesh-based interconnect architecture called CLICH EE (Chip-Level Integration of Communicating Heterogeneous Elements). This architecture consists of an m  n mesh of switches interconnecting computational resources (IPs) placed along with the switches, as shown in Fig. 1b in the particular case of 16 functional IP blocks. Every switch, except those at the edges, is connected to four neighboring switches and one IP block. In this case, the number of switches is equal to the number of IPs. The IPs and the switches are connected through communication channels. A channel consists of two unidirectional links between two switches or between a switch and a resource. Dally and Towles [19] have proposed a 2D torus as an NoC architecture, shown in Fig. 1c. The Torus architecture is basically the same as a regular mesh [22]; the only difference is that the switches at the edges are connected to the switches at the opposite edge through wrap-around channels. Every switch has five ports, one connected to the local resource and the others connected to the closest S ¼ N . The long end-around connections can yield exneighboring switches. Again, the number of switches is cessive delays. However, this can be avoided by folding the torus, as shown in Fig. 1d [28]. This renders to a more suitable VLSI implementation and, consequently, in our further comparative analysis, we consider the Folded Torus of Fig. 1d. Karim et al. [20] have proposed the OCTAGON MP-SoC architecture. Fig. 1e shows a basic octagon unit consisting of eight nodes and 12 bidirectional links. Each node is associated with a processing element and a switch. Communication between any pair of nodes takes at most two hops within the basic octagonal unit. For a system consisting of more than eight nodes, the octagon is extended to multidimensional space. The scaling strategy is as follows: Each octagon node is indexed by the 2-tuple ði; jÞ, i; j 2 ½0; 7. For each i ¼ I , I 2 ½0; 7, an octagon is constructed using nodes fðI ; jÞ; j 2 ½0; 7g, which results in eight individual octagon structures. These octagons are then connected by linking the corresponding i nodes according to the octagon configuration. Each node ðI ; J Þ belongs to two octagons: one consisting of nodes fðI ; jÞj 2 ½0; 7g and the other consisting of nodes fði; J Þi 2 ½0; 7g. Of course, this type of interconnection mechanism may significantly increase the wiring complexity. We proposed an interconnect template following a Butterfly Fat-Tree (BFT) [21] architecture, as shown in Fig. 1f. In our network, the IPs are placed at the leaves and to label each node, ðl; pÞ, where l denotes a node’s level and switches placed at the vertices. A pair of coordinates is used p denotes its position within that level. In general, at the lowest level, there are N functional IPs with addresses ranging from 0 to ðN   1Þ. The pair ð0; N Þ denotes the locations of IPs at that lowest level. Each switch, denoted by S ðl; pÞ, has four child ports and two parent ports. The IPs are connected to N =4 switches at the first level. In the jth level of the tree, there are N =2jþ1 switches. The number of switches in the butterfly fat tree architecture converges to a constant independent of the number of levels. If we consider a 4-ary tree, as shown in Fig. 1f, with four down links corresponding to child ports and two up links corresponding to parent ports, then the total number of switches in level j ¼ 1 is N =4. At each subsequent level, the number of required switches reduces by a factor of 2. In this way, the total number of switches approaches S ¼ N 2 , as N grows arbitrarily large [21]. 3 SWITCHING METHODOLOGIES Switching techniques determine when and how internal switches connect their inputs to outputs and the time at which message components may be transferred along these paths. For uniformity, we apply the same approach for all NoC architectures. There are different types of switching techniques, namely, Circuit Switching, Packet Switching, and Wormhole Switching [22]. In circuit switching, a physical path from source to destination is reserved prior to the transmission of the data . The path is held until all the data has been transmitted. The advantage of this approach is that the network bandwidth is reserved for the entire duration of the data. However, valuable resources are also tied up for the duration of the transmitted data and the set up of an end-to-end path causes unnecessary delays. In packet switching, data is divided into fixed-length blocks called packets and, instead of establishing a path before sending any data, whenever the source has a packet to be sent, it transmits the data. The need for storing entire packets in a switch in case of conventional packet switching makes the buffer requirement high in these cases. In an SoC environment, the requirement is that switches should not consume a large fraction of silicon area compared to the IP blocks. In wormhole switching, the packets are divided into fixed length flow control units (flits) and the input and output buffers are expected to store only a few flits. As a result, the buffer space requirement in the switches can be small compared to that generally required for packet switching. Thus, using a wormhole switching technique, the switches will be small and compact. The first flit, i.e., header flit, of a packet contains routing information. Header flit decoding enables the switches to establish the path and subsequent flits simply follow this path in a pipelined fashion. As a result, each incoming data flit of a message packet is simply forwarded along the same output channel as the preceding data flit and no packet reordering is required at destinations. If a certain flit faces a busy channel, subsequent flits also have to wait at their current locations. One drawback of this simple wormhole switching method is that the transmission of distinct messages cannot be interleaved or multiplexed over a physical channel. Messages must cross the channel in their entirety before the channel can be used by another message. This will decrease channel utilization if a flit from a given packet is blocked in a buffer. By introducing virtual channels [22] in the input and output ports, we can increase channel utility considerably. If a flit belonging to a particular packet is blocked in one of the virtual channels, then flits of alternate packets can use the other virtual channel buffers and, ultimately, the physical channel. The canonical architecture of a switch having virtual channels is shown in Fig. 2. 4 PERFORMANCE METRICS To compare and contrast different NoC architectures, a standard set of performance metrics can be used [22], [27]. For example, it is desirable that an MP-SoC interconnect 1028 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 2. Virtual-channel switch. architecture exhibits high throughput, low latency, energy efficiency, and low area overhead. In today’s power constrained environments, it is increasingly critical to be able to identify the most energy efficient architectures and to be able to quantify the energy-performance trade-offs [3]. Generally, the additional area overhead due to the infrastructure IPs should be reasonably small. We now describe these metrics in more detail. 4.1 Message Throughput Typically, the performance of a digital communication network is characterized by its bandwidth in bits/sec. However, we are more concerned here with the rate that message traffic can be sent across the network and, so, throughput is a more appropriate metric. Throughput can be defined in a variety of different ways depending on the specifics of the implementation. For message passing systems, we can define message throughput, T P , as follows: T P ¼ ðT otal messages completedÞ  ðM essage lengthÞ ðN umber of IP blocksÞ  ðT otal timeÞ ; ð1Þ where Total messages completed refers to the number of whole messages that successfully arrive at their destination IPs, Message length is measured in flits, Number of IP blocks is the number of functional IP blocks involved in the communication, and Total time is the time (in clock cycles) that elapses between the occurrence of the first message generation and the last message reception. Thus, message throughput is measured as the fraction of the maximum overall throughput of T P ¼ 1 corresponds to all end nodes load that the network is capable of physically handling. An receiving one flit every cycle. Accordingly, throughput is measured in flits/cycle/IP. Throughput signifies the maximum value of the accepted traffic and it is related to the peak data rate sustainable by the system. 4.2 Transport Latency Transport latency is defined as the time (in clock cycles) that elapses from between the occurrence of a message header injection into the network at the source node and the occurrence of a tail flit reception at the destination node [21]. We refer to this simply as latency in the remainder of this paper. In order to reach the destination node from some starting source node, flits must travel through a path consisting of a set of switches and interconnect, called stages. Depending on the source/destination pair and the routing algorithm, each message may have a different latency. There is also some overhead in the source and destination that also contributes to the overall latency. Therefore, for a given message i, the latency Li is: Li ¼ sender overhead þ transport latency þ receiver overhead: We use the average latency as a performance metric in our evaluation methodology. Let P be the total number of messages reaching their destination IPs and let Li be the latency of each message i, where i ranges from 1 to P . The average latency, Lavg , is then calculated according to the following: P Lavg ¼ P l Li P : ð2Þ 4.3 Energy When flits travel on the interconnection network, both the interswitch wires and the logic gates in the switches toggle and this will result in energy dissipation. Here, we are concerned with the dynamic energy dissipation caused by the communication process in the network. The flits from the source nodes need to traverse multiple hops consisting of switches and wires to reach destinations. Consequently, we determine the energy dissipated by the flits in each interconnect and switch hop. The energy per flit per hop is given by Ehop ¼ Eswitch þ Einterconnect ; ð3Þ where Eswitch and Einterconnect depend on the total capacitances and signal activity of the switch and each section of interconnect wire, respectively. They are determined as follows: Eswitch ¼ switchCswitchV 2 ; ð4Þ Einterconnect ¼ interconnectCinterconnectV 2 : switch ; interconnect and Cswitch ; Cinterconnect are the s ignal ð5Þ activities and the total capacitances of the switches and wire segments, respectively. The energy dissipated in transporting a packet consisting of n flits over h hops can be calculated as Epacket ¼ n X h Ehop;j : j¼1 ð6Þ Let P be the total number of packets transported, and let Epacket be the energy dissipated by the ith packet, where i ranges from 1 to P . The average energy per packet, E packet , is then calculated according to the following equation: P  P  P E packet ¼ P i¼1 Epacketi P ¼ P i¼1 ni hi j¼1 Ehop;j P : ð7Þ The parameters switch and interconnect are those that capture the fact that the signal activities in the switches and the interconnect segments will be data-dependent, e.g., there may be long sequences of 1s or 0s that will not cause any transitions. Any of the different low-power coding techniques [29] aimed at minimizing the number of transitions can be applied to any of the topologies described here. For the sake of simplicity and without loss of generality, we do not consider any specialized coding techniques in our analysis. 4.4 Area Requirements To evaluate the feasibility of these interconnect schemes, we consider their respective silicon area requirements. As the switches form an integral part of the active components, the PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1029 infrastructure, it is important to determine the amount of relative silicon area they consume. The switches have two main components: the storage buffer and logic to implement routing and flow control. The storage buffers are the FIFOs at the inputs and outputs of the switch. Another source of silicon area overhead arises from the interswitch wires, which, depending on their lengths, may have to be buffered through repeater insertion to keep the interswitch delay within one clock cycle [9]. Consequently, this additional buffer area should also be taken into account. Another important factor that needs to be considered when analyzing the area overhead is the wiring layout. One of the main advantages of the NoC design methodology is the division of long global wires into smaller segments, characterized by propagation times that are compatible with the clock cycle budget [30]. All the NoC architectures considered here achieve this as a result of their inherent interconnect structure. But, the segmented wire lengths will vary from one topology to another. Consequently, for each architecture, the layout of interswitch wire segments presents different degrees of complexity. Architectures that possess longer interswitch wires will generally create more routing challenges, compared to those possessing only shorter wire segments. Long wires can block wiring channels, forcing the use of additional metal layers and causing other wires to become longer. The determination of the distribution of interswitch wire lengths can give a firstorder indication of the overall wiring complexity. 4.5 Evaluation Methodology In order to carry out a consistent comparison, we developed a simulator employing flit-level event-driven wormhole routing to study the characteristics of the communicationcentric parameters of the interconnect infrastructures. In our experiments, the traffic injected by the functional IP blocks followed Poisson [31] and self-similar distributions [31]. In the past, a Poisson distributed injection rate was frequently used when characterizing performance of multiprocessor platforms [32]. However, the self-similar distribution was found to be a better match to real-world SoC scenarios [33]. Each simulation was initially run for 1,000 cycles to allow transient effects to stabilize and, subsequently, it was executed for 20,000 cycles. Using a flit counter at the destinations, we obtain the throughput as the number of flits reaching each destination per unit time. To calculate average latency and energy, we associate an ordered pair, ðLswitch ; Eswitch Þ, with each switch and an ordered pair, ðLinterconnect ; Einterconnect Þ, with each interconnect segment, where Lswitch ; Linterconnect and Eswitch ; Einterconnect denote the delays and energy dissipated in the switch and interconnect, respectively. The average latency and energy dissipation are calculated according to (2) and (7). To estimate the silicon area consumed by the switches, we developed their VHDL models and synthesized them using a fully static, standard cell-based approach for a 0.13 m CMOS technology library. Starting from this initial estimation, by using an ITRS (International Technology Roadmap for Semiconductors) suggested scaling factor of 0.7, we can project the area overhead in future technology nodes. 5 INFRASTRUCTURE IP DESIGN CONSIDERATIONS One common characteristic of the communication-centric architectures described in this paper is that the functional IP blocks communicate with each other with the help of intelligent switches. The switches provide a robust data transport medium for the functional IP modules. To ensure the consistency of the comparisons we later make in this paper, we assume that similar types of switching and routing circuits are used in all cases. These designs are now described in more detail. 5.1 Switch Architecture The different components of the switch port are shown in Fig. 3. It mainly consists of input/output FIFO buffers, input/output arbiters, one-of-four MUX and DEMUX units, and a routing block. In order to have a considerably high throughput, we use a virtual channel switch, where each port of the switch has multiple parallel buffers [22]. Each physical input port has more than one virtual channel, uniquely identified by its virtual channel identifier (VCID). Flits may simultaneously arrive at more than one virtual channel. As a result, an arbitration mechanism is necessary to allow only one virtual channel to access a single physical port. Let there be m virtual channels corresponding to each input port; we need an m : 1 arbiter at the input. Similarly, flits from more than one input port may simultaneously try to access a particular output port. If k is the number of ports in a switch, then we need a ðk   1Þ : 1 arbiter at each output port. The routing logic block determines the output port to be taken by an incoming flit. The operation of the switch consists of one or more processes, depending on the nature of the flit. In the case of a header flit, the processing sequence is: 1) input arbitration, 2) routing, and 3) output arbitration. In the case of body flits, switch traversal replaces the routing process since the routing decision based on the header information is maintained for the subsequent body flits. The basic functionality of the input/output arbitration blocks does not vary from one architecture to another. The design of the routing hardware depends on the specific topology and routing algorithm adopted. In order to make the routing logic simple, fast, and compact, we follow different forms of deterministic routing [22]. In our routing schemes, we use distributed source routing, i.e., the source node determines only its neighboring nodes that are involved in message delivery. For the tree-based architectures (SPIN and BFT), the routing algorithm applied is the least common ancestor (LCA) and, for CLICH EE and Folded Torus, we apply the e-Cube (dimensional) routing [21]. In the case of Octagon, we adopt the hierarchical address-based routing as proposed in [19]. The corresponding routing blocks have been implemented for all the above-mentioned cases. The arbiter circuit essentially consists of a priority matrix, which stores the priorities [23] of the requesters, and grant generation circuits used to grant resources to requesters. The matrix arbiter stores priorities between n requesters in a binary n-by-n matrix. Each matrix element ½i; j records the binary priority between each pair of inputs. For example, suppose requester i has a higher priority than requester j, then the matrix element ½i; j will be set to 1, while the corresponding matrix element ½j; i will be 0. A requester will be granted the resource if no other higher priority requester is bidding for the same resource. Once a 1030 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 3. Block diagram of a switch port. Fig. 4. (a) Block diagram of an arbiter; (b) one element of the priority matrix. requester succeeds in being granted a resource, its priority is updated and set to be the lowest among all requesters. A block diagram of the arbiter and one element of the priority matrix circuit is shown in Fig. 4. The FIFO buffers are also critical components of the switch. Their operating speed should be high enough not to become a bottleneck in a high-speed network. More specifically, the switches at level one need to be interfaced with the SoC’s constituent IP blocks. Hence, the switches should be able to receive and transmit data at the rated speed of the corresponding IPs. Furthermore, the FIFOs should be able to operate with different read and write clocks as the SoC’s constituents IPs are expected to generally operate at different frequencies. Instead of using separate counters to implement read and write pointers, two tokens are circulated among the FIFO cells to implement read and write operations [24]. A FIFO cell can be read from or written into only if it holds the corresponding token. After a token is used in a given cell, it is subsequently passed on to the adjacent cell. 5.2 Virtual Channel Allocation The virtual channel allocation determines which output virtual channel is taken by a message at each of the intermediate switch nodes. Each switch input port has a separate queue buffer corresponding to the virtual channels. When a flit first arrives at an input port, its type is decoded. If it is a header flit, then, according to its VCID field, it is stored in the corresponding virtual channel buffer. The routing logic determines the output port to be taken by this flit and assigns the incoming flit to an available output virtual channel. The VCID of the flit is modified accordingly. When the subsequent body flits arrive, they are queued into the buffer of the input virtual channel and subsequently inherit the particular output virtual channel reserved by the header. Instead of reserving output ports for the entire duration of a packet, the switch allocates output ports on a flit-by-flit basis. 5.3 Network Interfacing The success of the NoC design paradigm relies greatly on the standardization of the interfaces between IP cores and the interconnection fabric. The Open Core Protocol (OCP) [15] is an interface standard receiving wide industrial and academic acceptance. Using a standard interface should not impact the methodologies for IP core development. In fact, IP cores wrapped with a standard interface like the OCP interface will exhibit a higher reusability and greatly simplify the task of system integration. The network interface will have two functions: 1. injecting/absorbing the flits leaving/arriving at the functional IP blocks; 2. packe t iz ing/depacke t iz ing the s igna ls com ing from/reaching to OCP compatible cores in form of messages/flits. As shown in Fig. 5, for a core having both master and slave interfaces, the OCP compliant signals coming out of the Fig. 5. Interfacing of IP cores with the network fabric. PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1031 TABLE 1 Simulation Parameters 1 The average message latency decreases when buffer size increases [22]. According to [22], the effect of buffer size on performance is small. Consequently, to avoid excessive silicon area consumption in our switch design, here we considered the buffer depths to be equal to two flits. 2 The bridge nodes connecting two adjacent OCTAGONS have six ports. functional IP blocks are packetized by a second interface, which sits between the OCP instances and the communication fabric. 6 EXPERIMENTAL RESULTS AND ANALYSIS We applied our evaluation methodology to all the proposed NoC architectures described earlier in this paper. The wormhole routing simulator was used to compare and contrast the NoC topologies in terms of throughput and latency. In this simulator, the user may choose between uniform and localized traffic patterns for the packets. There are options of using both Poisson and self-similar message injection distributions. Self-similar traffic has been observed in the bursty traffic between on-chip modules in typical MPEG-2 video applications [33] and networking applications [32]. It has been shown that modeling of self-similar traffic can be obtained by aggregating a large number of ON-OFF message sources [32]. The length of time each message spends in either the ON or the OFF state should be selected according to a distribution which exhibits long-range dependence. The Pareto distribution (ðFðxÞ ¼ 1   x  , with 1 <  < 2) has been found to fit well to this kind of traffic. A packet train remains in the ON state for tON ¼ ð1   rÞ  1 ON and in the OFF state for tOF F ¼ ð1   rÞ  1 OF F , where r is a random number uniformly distributed between 0 and 1, ON ¼ 1:9, and OF F ¼ 1:25 [31]. The destination IP selection depends on the traffic pattern adopted. The simulator is capable of handling variable message length. Message lengths may vary depending on the application. On the other hand, message length and buffer depth are strongly correlated. In an SoC environment, buffer depth is of extreme importance as it adds to the silicon area overhead due to the switches. In addition, switch parameters can also be specified. These include input/output port buffer depths (in flits), number of ports, and the number of virtual channels per switch port. Messages arriving at destinations are immediately consumed at the rate of one flit per time step, i.e., no blocking is encountered at the destinations. All resource contention is handled without bias in the sense that granting of resources to packets is done on a first come, first-serve basis. The energy dissipation of NoC fabrics arise from two different sources: 1) the switch blocks, which include the buffers, and 2) interswitch wire segments. To study the energy efficiency of the interconnect architectures, we determine the energy dissipated in each switch, Eswitch , by running Synopsys Prime Power on the gate-level netlist of the switch blocks, including the FIFO buffers. Our energy estimation methodology involved feeding a large set of data patterns to the switch blocks. Through functional simulation using Synopsys Prime Power, the average values for the activity factors were determined. The experimental data set included long sequences of 1s and 0s to account for the possible cases where low transition activity data were to be transported. To determine interconnect energy, Einterconnect , Fig. 6. Variation of throughput under spatially uniform traffic distribution. Fig. 7. Variation of latency with virtual channels. 1032 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 8. Variation of accepted traffic with injection load. (a) Poisson. (b) Self-similar. Fig. 9. Variation of throughput under localized traffic (number of vc = 4). (a) Poisson. (b) Self-similar. Fig. 10. Latency variation with injection load for spatially uniform traffic distribution. (a) Poisson. (b) Self-similar. the capacitance of each interconnect stage, Cinterconnect , is Cinterconnect ¼ Cwire  waþ1;a þ n  m  ðCG þ CJ Þ; ð8Þ calculated taking into account the specific layout of each where Cwire is the wire capacitance per unit length and waþ1;a topology. Cinterconnect can be estimated according to the is the wire length between two consecutive switches; CG and following expression: CJ are the gate and junction capacitance of a minimum size PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1033 Fig. 11. Top: Latency variation with injection load (localization factor = 0.3). (a) Poisson. (b) Self-similar. Middle: Latency variation with injection load (localization factor = 0.5). (c) Poisson. (d) Self-similar. Bottom: Latency variation with injection load (localization factor = 0.8). (e) Poisson. (f) Self-similar. inverter, respectively, n denotes the number of inverters adjacent wires switch in the opposite direction of the signal (when buffer insertion is needed) in a particular interswitch wire segment, and m is their corresponding size with respect line simultaneously [6]. In all the subsequent experiments, we consider each to a minimum size inverter. While calculating Cwire , we have considered the worst-case switching scenario, where the two system to be consisting of 256 functional IP blocks, i.e., N ¼ 256. Table 1 summarizes the simulation parameters. 1034 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 6.1 Throughput and Latency We now compare the throughput and latency characteristics of the various NoC architectures. The throughput of the communication infrastructure generally depends on the traffic pattern. Fig. 6 shows the variation of throughput with the number of virtual channels for all the topologies, determined through simulation using (1). Measuring throughput under uniform spatial distribution assumptions is an accepted metric [22] for evaluating parallel systems. Throughput is the maximum traffic accepted by the network and it relates to the peak data rate sustainable by the system. The accepted traffic depends on the rate at which the functional IP blocks are injecting data into the network. Ideally, accepted traffic should increase linearly with this injection load. However, due to the limitation of routing resources (switches and interconnect wires), accepted traffic will saturate at a certain value of the injection load. Similarly to the throughput, the unit of measure for injection load is also flits/cycle/IP. For both Poisson and self-similar injection rates, the variation of throughput with virtual channels has similar characteristics. From Fig. 6, when the number of virtual channels is increased beyond four, there is a trend toward throughput saturation. However, each additional virtual channel implies an increased silicon area. Fig. 7 shows the variation of latency with the number of virtual channels. The average message latency depends on the number of virtual channels and injection load. In this case, the average latency generally increases with the number of virtual channels. To keep the latency low while simultaneously maintaining a considerable throughput, the number of virtual channels is constrained to four in the design of the switches. Consequently, a system with four virtual channels strikes an appropriate balance between high throughput, low latency, and conservation of silicon area. This result is consistent with previous research on the optimal number of virtual channels [36] and, in part, validates the modeling and simulation approach used to generate the results in this paper. The plots in Fig. 6 also indicate that, under the uniform traffic assumption, BFT, CLICH EE, and Folded Torus provide a lower throughput than do SPIN and Octagon. This happens due to the fact that SPIN and Octagon have more links between a source and a destination pair than do the others. The role of injection load on the accepted traffic was also studied and shown in Fig. 8. We observe that the accepted traffic increases linearly with the injection load up to the throughput saturation point. Fig. 8b shows that self-similar traffic saturates the networks at slightly lower average data rates. While these results are as one would expect, the assumption of spatial uniformity of traffic is not very realistic in an SoC environment since different functions will be mapped to different parts of the SoC and they will exhibit highly localized patterns. Hence, we studied the effect of traffic localization on throughput for both types of injection processes and considered the illustrative case of spatial localization where local messages travel from a source to the set of the nearest destinations. In the case of BFT and SPIN, localized traffic is constrained within a cluster consisting of a single subtree, while, in the case of CLICH EE and Folded Torus, it is constrained within the four destinations placed at the shortest Manhattan distance [14]. Fig. 12. Average energy dissipation per packet. In the case of Octagon, the local traffic is the traffic constrained within the basic group of eight IP blocks. We define the localization factor as the ratio of local traffic to total traffic. For example, if the localization factor is 0.3, then 30 percent of the traffic generated by an IP occurs within its cluster, while the rest of the traffic is randomly distributed in the remainder of the entire SoC. F ig . 9 shows the effect o f traffic local ization on throughput for all the topologies. We assumed that the number of virtual channels (vc) is four, based on the previously described experiments. Localization of traffic does not have much impact on SPIN and Octagon, but it enhances the throughput of BFT, CLICH EE, and Folded Torus considerably. Though SPIN and Octagon have very high throughput for the uniformly distributed traffic, they lack the ability to exploit the traffic localization inherent in SoC architectures. In Fig. 10, we show the variation of latency with injection load in the case of both Poisson and self-similar distributions for uniform traffic. The injection load directly affects the average message latency. As the injection load approaches the accepted traffic (throughput) limit, there will be more message contention and latency will increase. At the limit, latency increases exponentially when the injection load reaches the saturation point. Consequently, the desirable point of operation for the system should be well below network saturation. The self-similar traffic distribution yields higher average message latency, principally due to its bursty nature. We considered the effect of traffic localization on the latency. Variation of latency with localization factors of 0.3, 0.5, and 0.8 is shown in Fig. 11a, Fig. 11b, Fig. 11c, Fig. 11d, Fig. 11e and Fig. 11f. One important effect of localization on the latency characteristic is that it allows a higher injection load. Consequently, more traffic can be processed without the network being saturated. Eventually, this will enhance the overall datarate of the system. It is seen from Fig. 11 that, similar to the case of throughput characteristics, traffic localization does not have significant impact on the latency variations for SPIN and Octagon. 6.2 Energy Dissipation While evaluating the feasibility of an interconnect infrastructure, its energy dissipation profile must be considered as it can be a significant portion of the overall SoC energy budget. The metric for comparing the NoC architecture PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1035 Fig. 13. Energy dissipation profile for uniform traffic. (a) Poisson. (b) Self-similar. with respect to the energy dissipation is the average dynamic energy dissipated when a packet moves between a pair of source and destination IP blocks. This average energy dissipation, in turn, depends on the number of virtual channels and injection load. Fig. 12 shows the variation of average energy dissipation per packet as a function of the number of virtual channels (the same for both Poisson and self-similar traffic) assuming the networks to be operated at the peak sustainable data rate. We can observe that the energy dissipation increases linearly with the number of virtual channels for all the architectures. Consequently, a system with four virtual channels per physical link will give reasonably low energy dissipation without compromising throughput. The effect of injection load on the energy dissipation for a uniform traffic distribution for both Poisson and self-similar injection process is shown in Fig. 13. Similar to the nature of accepted traffic variations, the energy dissipation profiles show a saturating characteristic occurring when the injection load reaches the throughput limit. Beyond saturation, no additional messages can be injected successfully into the system and, consequently, no additional energy is dissipated. We also consider the effect of traffic localization on the energy dissipation profile for all the NoC architectures. Fig. 14a, Fig. 14b, Fig. 14c, Fig. 14d, Fig. 14e, and Fig. 14f show the energy dissipation profile for localization factors of 0.3, 0.5, and 0.8, respectively. The benefits of traffic localization are evident from these figures: Increasing the amount of traffic localization causes more messages to be injected without increasing the average energy dissipation. This happens due to the fact that, on the average, messages will traverse fewer stages in the case of a greater amount of localization. Consequently, the functional mapping should be performed so as to exploit the advantages of spatial locality, i.e., the blocks that communicate more frequently should be placed close to each other. This will reduce the use of long global paths and the energy dissipation. From Figs. 13 and 14, we can infer that the architectures with a higher degree of connectivity like SPIN and Octagon have greater average energy dissipation at saturation than the others, though they provide higher throughput and lower latency on the average. 6.3 Area Overhead In the NoC design paradigm, the silicon area overhead arises due to the presence of the switches, the interswitch repeaters, and the interfaces between the functional IP blocks and the network. Regardless of the specific topology used by the interconnect infrastructure, each functional IP blocks needs to have the OCP-IP interface. Consequently, in our analysis, we consider the whole interfacing circuitry a part of the functional IP blocks. From our detailed circuit level design and synthesis, we deduce that, within a switch, the buffer area significantly dominates the logic [25]. The buffer area, in turn, largely depends on the number of virtual channels and the flit length. In a networked SoC, IPs can be divided into two groups, functional and infrastructure IPs (switches). Hence, the distribution of functional IPs and I2Ps depends on their respective sizes and interconnect topology. Letting AF I P denote the area of the functional IP blocks and AI 2 P denote the area of the switches, then Areachip ¼ N1  AF IP þ N2  AI 2 P ; where N1 and N2 are the number of functional and area of the SoC under consideration. For a BFT, N1 ¼ 2N2 , infrastructure IPs, respectively, and Areachip is the total for SPIN architecture, N1 ¼ 4 3 N2 , and, for all the others, N1 ¼ N2 . These numbers help to determine the distribution of functional and infrastructure IP blocks in an SoC. Through RTL level design and synthesis, we found that the switches consist of approximately 30K gates,3 while the OCP-IP interface accounted for around 1,400 gates. Using (9) and the constraints on N1 and N2 , we can determine the distribution of functional and infrastructure IP blocks in all the topologies. We consider the case where functional IP blocks are constrained to be of the order of 100K gates, as suggested in [6]. Table 2 shows the maximum number of 100K blocks that can be integrated within an SoC in different technology nodes [9]. The distribution of functional and infrastructure IP blocks is indicated in Table 3. Under these assumptions, we determined the silicon area consumed by the switch blocks for all the architectures. ð9Þ 3. Here, we consider a 2-input NAND structure as a reference gate. 1036 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 14. Top: Energy dissipation profile for localized traffic (localization factor = 0.3). (a) Poisson. (b) Self-similar. Middle: Energy dissipation profile for localized traffic (localization factor =0 .5). (c) Poisson. (d) Self-similar. Bottom: Energy dissipation profile for localized traffic (localization factor = 0.8). (a) Poisson. (b) Self-similar. TABLE 2 Maximum Number of 100K IP Blocks in Different Technology Nodes The other factors contributing to the area overhead are the interswitch repeaters. The wire length between switches in the BFT and SPIN architectures depends on the levels of the switches. Consequently, to keep the interswitch wire delay within one clock cycle, some of them need to be buffered [8] . In CLICH EE and Folded Torus, all the interswitch wires are of equal length and their delay is always within one clock cycle [8]. Therefore, no repeater insertion is required. In Octagon, the interswitch wires connecting functional IP blocks in disjoint octagon units [19] need to be buffered. PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1037 TABLE 3 Distribution of Functional and Infrastructure IP Blocks The silicon area overhead in different technology nodes can be estimated for all the interconnect architectures as the sum of the area due to the switches (AreaI 2 P ) and repeaters (Arearepeaters ): Areaoverhead ¼ AreaI 2 P þ Arearepeaters : ð10Þ Fig. 15 reports the silicon area overhead for all the platforms under consideration across different technology nodes, assuming a die size of 20mm  20mm and that each functional IP block consists of 100K equivalent 2-input NAND gates. From Fig. 15, we see that both SPIN and Octagon have a considerably higher silicon area overhead. This happens due to the fact that both these architectures provide a higher degree of connectivity. The percentage of silicon area overhead for different platforms increases slightly with technology scaling. However, the relative area overhead between any two platforms remains almost unchanged. 6.4 Wiring Complexity The complexity of the wire area estimation problem involves determination of the longest wire segments that may arise in each architecture and their distribution. The long wire segments block wiring channels and force other wires to become longer. From our experience, there will be additional area consumed by the wires than what is predicted by the first order analysis. Assuming this kind of overhead, our aim is to estimate the distribution of wire lengths in all the interconnect architectures under consideration. In an NoC environment, the interswitch wire segments are the longest on-chip wires except for clock, power, and ground wires [34]. Due to the structured nature Fig. 15. Area overhead. of NoC-based interconnects, the interswitch wire lengths can be determined a priori. The wire lengths between switches in the BFT and the SPIN architectures depend on the levels of the switches. On the other hand, the number of switch levels can be expressed as a function of system size (N) as levels ¼ log4 N for both, where N is the number of functional IP blocks in an SoC. The interswitch wire length is given by the following expression [21]: ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ p Area 2levels a ; waþ1;a ¼ ð11Þ where waþ1;a is the length of the wire spanning the distance between level a and level a þ 1 switches, where a can take integer values between 0 and ðlevels   1Þ. For CLICH EE and Folded Torus, all wire segments are of the same length, respectively; the interswitch wire lengths of the CLICH EE architecture can be determined from the following expression: ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ pﬃﬃﬃﬃﬃ Area p   1 N w ¼ ; ð12Þ while, for the Folded Torus, all the interswitch wire lengths are double those for CLICH EE [28]. Considering a die size of 20mm  20mm and a system size of 256 IP blocks, we determined the number of interswitch links and their lengths for all the NoC architectures under consideration. We calculated the interswitch wire lengths in the cases of CLICH EE, Folded Torus, BFT, and SPIN using (11) and (12) and Figs. 1 and 16. For Octagon, we determined the interswitch wire lengths following the low wiring complexity scaling strategy shown in [20]. As shown in Fig. 16, in each basic octagon unit, we can differentiate three types of links: long links (connecting blocks 0-4 and 7-3), medium length links (connecting blocks 0-7, 3-4, 1-5, and 2-6), and short links (connecting blocks 0-1, 1-2, 2-3, 4-5, 5-6, and 6-7). These link lengths can be determined by assuming the 256 IP blocks divided into 32 basic octagons, with four placed horizontally and eight placed vertically. Fig. 17 shows the distribution of interswitch wire lengths for all of the NoC architectures. From this figure, we can qualitatively infer that SPIN will have the highest degree of wiring complexity, while CLICH EE and Folded Torus will have the lowest complexity. Consequently, for the SPIN topology, the layout of interswitch wire segments will have the greatest impact on area overhead. CLICH EE and Folded Torus are the simplest ones from a layout perspective, while BFT and Octagon stand between these two groups. 1038 IEEE TRANSACTIONS ON COMPUTERS, VOL. 54, NO. 8, AUGUST 2005 Fig. 16. Simplified layout examples of SPIN, OCTAGON, and BFT. 7 CASE STUDY To illustrate how system designers can use the analytical and experimental procedures outlined in this paper to estimate the performance of an SoC application, we simulated a multiprocessor SoC, a network processing platform, mapped to different NoC communication fabrics we described in earlier sections. Among all the architectures under consideration, Octagon and SPIN have the higher throughput, but their energy dissipation is much greater than that of the others. In addition, the silicon area overhead due to the infrastructure IP blocks is also higher. Taking these facts into account, we considered the architectures with a lower energy dissipation profile, i.e., BFT, CLICH EE, and Folded Torus, for further evaluation. For illustrative purposes, we mapped the network processing platform onto these three interconnect architectures. The functional block diagram of the network processor is shown in Fig. 18, based on a commercial design [26]. All the functional blocks are divided into five clusters. Initially, we assumed the traffic to be uniformly distributed among these five clusters. The micro-engines (MEs) in clusters 2 and 3 are the programmable engines specialized for network processing. MEs do the main data plane [26] processing for each packet and communicate in a pipelined fashion within each ME cluster. Consequently, the traffic will be highly localized within these two clusters (clusters 2 and 3). As discussed earlier, we assumed localization factors of 0.3, 0.5, and 0.8 for the traffic within these two clusters, while the rest of the traffic is assumed to be uniformly random. We also assumed a self-similar injection process. Under the stated traffic distributions, we simulated the performance of the network processor SoC shown in Fig. 18. From the throughput characteristics, we can project the aggregate bandwidth [35] sustainable by the SoC platform by using the following expression: Aggregate Bandwidth ¼ ðN umber of IP blocksÞ  ðF lit lengthÞ  ðAccepted traff icÞ  ðclock rateÞ: Table 4 shows the projected bandwidth, assuming a clock rate of 500 MHz (typical for an SoC implemented in a 130 nm process) and 16-bit flit length, average message latency, and average energy dissipation. As expected and discussed in Section 6.1, throughput increases significantly with traffic localization, which in turn gives rise to higher aggregate bandwidth. The value of average latency is measured at an injection load below saturation. The effect of traffic localization on average latency is that it allows a higher injection load without saturating the network. The message latency, at a lower injection load (below saturation), remains largely unaffected by traffic localization. While measuring the average energy dissipation, to have a consistent comparison, we kept the system throughput at the same level for all the architectures, while varying the amount of localized traffic. When the factor of localization is varied from 0.3 to 0.8, the bit energy savings relative to the uniformly distributed traffic scenario vary from 20 percent to 50 percent. As shown in this case study, it is possible to project the achievable performance of a typical multicore SoC implemented using the NoC design paradigm. Fig. 17. Interswitch wire length distribution. Fig. 18. Functional block diagram of a typical network processor. PANDE ET AL.: PERFORMANCE EVALUATION AND DESIGN TRADE-OFFS FOR NETWORK-ON-CHIP INTERCONNECT ARCHITECTURES 1039 TABLE 4 Projected Performance of a Network Processor SoC Platform in NoC Design Paradigm 8 CONCLUSIONS Networks-on-chip (NoC) are emerging as a viable interconnect architecture for multiprocessor SoC platforms. In this new paradigm, infrastructure IPs are used to establish the on-chip communication medium. NoC-based architectures are characterized by various trade-offs with regard to functional, structural, and performance specifications. Here, we carried out detailed comparisons and contrasted different NoC architectures in terms of throughput, latency, energy dissipation, and silicon area overhead. We illustrated that some architectures can sustain very high data rates at the expense of high-energy dissipation and considerable silicon area overhead, while others can provide a lower data rate and lower energy dissipation levels. Our principal contribution lies in the establishment and illustration of a consistent comparison and evaluation methodology based on a set of readily quantifiable parameters for NoCs. Our methodology sets an important basis for the optimal evaluation and selection of interconnect infrastructures for large and complex SoCs. Though the parameters considered in our benchmarking are considered by experts in the field to be among the most critical, they do not constitute a unique set nor are they exhaustive. Different applications or circumstances may require this set to be altered or augmented, e.g., by including parameters such as testability, dependability, and reliability. However, they are an important set to characterize the emerging NoC architectures. ACKNOWLEDGMENTS The authors thank Micronet, PMC-Sierra, Gennum, and NSERC for their financial support and the CMC for providing access to CAD tools. The authors also thank Pierre Paulin of ST Microelectronics and Allan Nakamoto of PMC Sierra for their feedback. In addition, they wish to thank the expert reviewers for their extremely valuable comments, which helped them enhance the quality of their work. "
2008,Photonic Networks-on-Chip for Future Generations of Chip Multiprocessors.,"The design and performance of next-generation chip multiprocessors (CMPs) will be bound by the limited amount of power that can be dissipated on a single die. We present photonic networks-on-chip (NoC) as a solution to reduce the impact of intra-chip and off-chip communication on the overall power budget. A photonic interconnection network can deliver higher bandwidth and lower latencies with significantly lower power dissipation. We explain why on-chip photonic communication has recently become a feasible opportunity and explore the challenges that need to be addressed to realize its implementation. We introduce a novel hybrid micro-architecture for NoCs combining a broadband photonic circuit-switched network with an electronic overlay packet-switched control network. We address the critical design issues including: topology, routing algorithms, deadlock avoidance, and path-setup/tear-down procedures. We present experimental results obtained with POINTS, an event-driven simulator specifically developed to analyze the proposed idea, as well as a comparative power analysis of a photonic versus an electronic NoC. Overall, these results confirm the unique benefits for future generations of CMPs that can be achieved by bringing optics into the chip in the form of photonic NoCs.","1246 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Photonic Networks-on-Chip for Future Generations of Chip Multiprocessors Assaf Shacham, Member, IEEE, Keren Bergman, Sen ior Member, IEEE, and Luca P. Car loni, Member, IEEE Abstract—The design and performance of next-generation chip multiprocessors (CMPs) will be bound by the limited amount of power that can be dissipated on a single die. We present photonic networks-on-chip (NoC) as a solution to reduce the impact of intrachip and off-chip communication on the overall power budget. The low loss properties of optical waveguides, combined with bit-rate transparency, allow for a photonic interconnection network that can deliver considerably higher bandwidth and lower latencies with significantly lower power dissipation than an interconnection network based only on electronic signaling. We explain why on-chip photonic communication has recently become a feasible opportunity and explore the challenges that need to be addressed to realize its implementation. We introduce a novel hybrid microarchitecture for NoCs that combines a broadband photonic circuit-switched network with an electronic overlay packet-switched control network. This design leverages the strength of each technology and represents a flexible solution for the different types of messages that are exchanged on the chip; large messages are communicated more efficiently through the photonic network, while short messages are delivered electronically with minimal power consumption. We address the critical design issues including topology, routing algorithms, deadlock avoidance, and path-setup/teardown procedures. We present experimental results obtained with POINTS, an event-driven simulator specifically developed to analyze the proposed design idea, as well as a comparative power analysis of a photonic versus an electronic NoC. Overall, these results confirm the unique benefits for future generations of CMPs that can be achieved by bringing optics into the chip in the form of photonic NoCs. Index Terms—On-chip communication, chip multiprocessors, photonics, emerging technologies. Ç 1 INTRODUCTION IN the continual drive toward improved microprocessor performance, power efficiency has emerged as a prime design consideration. In fact, the limitations on power dissipation imposed by packaging constraints have become so paramount that performance metrics are now typically measured per unit power [1]. At the chip scale, the trend toward multicore architectures and chip multiprocessors (CMPs) for driving performance-per-watt by increasing the number of parallel computational cores is dominating new commercial releases [2], [3], [4], [5], [6]. With the future path clearly toward further multiplication of the on-chip processing cores, CMPs have begun to essentially resemble highly parallel computing systems integrated on a single chip. In this context, the role of the interconnect and associated global communication infrastructure is becoming central to the chip performance. As with highly parallel systems, performance is increasingly tied to how efficiently information is exchanged and how well the growing . A. Shacham is with Aprius Inc., 440 N. Wolfe Rd., Sunnyvale, CA 94085. E-mail: assaf@ee.columbia.edu. . K. Bergman is with the Department of Electrical Engineering, Columbia University, 500 W. 120th St., 1300 Mudd, New York, NY 10027. E-mail: bergman@ee.columbia.edu. . L.P. Carloni is with the Department of Computer Science, Columbia University, 466 Computer Science Building, 1214 Amsterdam Avenue, Mail Code: 0401, New York, NY 10027-7003. E-mail: luca@cs.columbia.edu. Manuscript received 5 July 2007; revised 3 Mar. 2008; accepted 13 Mar. 2008; published online 28 Apr. 2008. Recommended for acceptance by R. Marculescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TCSI-2007-07-0305. Digital Object Identifier no. 10.1109/TC.2008.78. number of computational resources are utilized. Thus, global on-chip communications will play a central role in the overall performance of future CMPs. The realization of a scalable on-chip communication infrastructure faces critical challenges in meeting the large bandwidth capacities and stringent latency requirements demanded by CMPs in a power-efficient fashion [7], [8]. Recent research on packet-switched networks-on-chip (NoC) [9], [10], [11], [12] has shown that carefully engineered shared links can provide enough bandwidth to replace many traditional bus-based communication media and point-topoint links. However, NoCs do not directly address the power dissipation challenge. With vastly increasing on-chip and off-chip communication bandwidths, the interconnect power consumption is widely seen as an acutely growing problem. It is unclear how electronic NoCs will continue to satisfy future bandwidths and latency requirements within the CMP power budget [13]. The insertion of photonics in the on-chip global interconnect structures for CMP can potentially leverage the unique advantages of optical communication and capitalize on the capacity, transparency, and fundamentally low energy consumption that have made photonics ubiquitous in long-haul transmission systems. The construction of photonic NoC could deliver performance-per-watt scaling that is simply not possible to reach with all-electronic interconnects. The photonics opportunity is made possible now by recent advances in nanoscale silicon photonics and considerably improved photonic integration with commercial CMOS chip manufacturing [14]. Unlike prior generations of photonic technologies, the remarkable capabilities of nanoscale silicon photonics offer the possibility of 0018-9340/08/$25.00 ß 2008 IEEE Published by the IEEE Computer Society SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1247 creating highly integrated photonic platforms for generating and receiving optical signals with fundamentally superior power efficiencies. These tremendous gains in power efficiencies for optical modulators and receivers are driven by the nanoscale device footprints and corresponding capacitances, as well as by the tight proximity of electronic drivers enabled by the monolithic CMOS platform integration [15], [16], [17], [18], [19]. Photonic elements have recently become available as library cells in standard CMOS processes. For the first time, we can practically consider basing the communication infrastructure of a CMP on a photonic interconnection network. In particular, photonic NoCs can deliver a dramatic reduction in power expended on intrachip global communications while satisfying the high bandwidths requirements of CMPs. Photonic NoCs change the rules of power scaling: As a result of low loss optical waveguides, once a photonic path is established, the data is transmitted end-toend without the need for repeating, regenerating, or buffering. In electronic NoCs, on the other hand, a message is buffered, regenerated, and then transmitted on the interrouter links multiple times en route to its destination. Furthermore, the switching and regenerating elements in CMOS consume dynamic power that grows with the data rate. The power consumption of optical switching elements, conversely, is independent of the bit rate, so, once generated, high-bandwidth messages do not consume additional dynamic power when routed.1 In this paper, we present photonic NoC as a solution for high-performance CMP design which leverages the remarkable progress in silicon photonics to offer a major reduction in the power dissipated on intrachip communications. The intrachip photonic infrastructure also offers seamless offchip communications. Specifically, we propose a hybrid NoC microarchitecture that combines a photonic circuit-switched network with an electronic packet-switched network. We envision that, in the span of three or four CMOS process generations, a similar photonic NoC will be implemented as an additional layer of optical and optoelectronic devices grown on top of the silicon die and the metal layers comprising the CMP and possibly with multiple memory planes in between. This will likely be realized using 3D Integration (3DI) based on through-silicon via technology [20] in order to separately optimize logic, memory, and Si photonics planes. Further, current trends in multicore architectures suggest that CMPs will soon host a few dozen complex cores, each containing multiple logic blocks including one or more processing units, a local memory, a direct memory access (DMA) memory controller, and a network interface. In our vision, the photonic NoC will be the global communication medium connecting these cores among themselves and with off-chip memories and devices. 1.1 Paper Organization and Contribution Early versions of the work presented here were reported in previous conference publications [21], [22], [23]. In this paper, we collect the main results presented in these papers and further extend the work with an improved power 1. While this is true for the photonic network, the power consumption of other network components (e.g., E/O and O/E conversion) does scale with the bit rate, but it is still significantly lower than that of an electronic NoC. A power analysis follows in Section 6. dissipation estimation model and new performance simulation results. This paper is organized as follows: Section 2 briefly reviews prior work done by researchers on the integration of optical communication elements in electronic integrated circuits and, specifically, in microprocessors. In Section 3, we give an overview of the hybrid microarchitecture, we explain the rationale behind its choice and we describe the most important photonic components that characterize it. In Section 4, we discuss in detail the critical design issues for the photonic NoC including: technology building blocks, network topology, routing algorithms, deadlock avoidance, and path-setup/ teardown procedures. We developed POINTS, an event-driven network traffic simulator, to quantitatively evaluate critical design aspects such as deadlock avoidance/recovery, optimal message size, path multiplicity (PM), and alternative flow control mechanisms. In Section 5, we report a series of simulationbased experimental results that broadly confirm the potential performance leap offered by the integration of a photonic NoC in future high-performance CMPs. In Section 6, we present a comparative power analysis of a photonic NoC versus an electronic NoC that is designed to provide the same bandwidth to the same number of cores. The compelling conclusion of the study is that the power expended on intrachip communications can be reduced by nearly two orders of magnitude when high-bandwidth communications is required among a large number of cores. Last, we comment on future research avenues. 2 RELATED WORK Optical communication is widely accepted as an interconnection medium for long and medium-reach distances, typically above 10 m [24]. A large body of research work exists on the design, fabrication, and performance analysis of optical interconnects for short-reach applications such as chip-to-chip interconnection. Studies about intrachip applications for optical interconnects are not as widely available because copper interconnects, until recently, have performed sufficiently well in addressing intrachip communication needs within power constraints. Collet et al. [25] have studied the relative performance of optical and electrical on-chip interconnects for CMOS processes between 0.7 and 0.05 m. They have concluded that the penetration of on-chip optical interconnects can be envisioned in lengths larger than 1,000 times the wavelength (e.g., 45 m in a 45 nm process) where they can have lower power and latency than electronic interconnects. The work assumes the lasers are integrated into the silicon die and are directly modulated, thus consuming the bulk of the power of the optical system. A multicore processor architecture where remote memory accesses are implemented as transactions on a global on-chip optical bus is suggested by Kirman et al. [26]. The work shows a latency reduction as high as 50 percent for some applications and a power reduction of about 30 percent over a baseline electrical bus. Because this design is based on bus topology, it suffers from obvious scalability limits. The simulated design connects 64 processing cores organized in 1248 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 four supernodes. It is expected that bus contention will limit performance when a larger number of nodes are connected in the bus. Additionally, optical buses are limited in the number of terminals due to the finite launching power and coupling losses incurred by each terminal. An optical NoC based on a wavelength-routed crossbar is presented by Brie´ re et al. [27]. The crossbar, comprised of passive resonator devices and routing between an inputoutput pair, is achieved by selecting the appropriate wavelength. This approach, however, requires either widely tunable laser sources or large arrays of fixed-wavelength sources with fast wavelength-selection switches. The performance of such a system will strongly depend on the ability to select a wavelength quickly and accurately and its scalability will be limited by the number of fixed sources (or the tuning range, if tunable lasers are used). Intel’s Technology and Manufacturing Group performed a study evaluating the benefits of optical intrachip interconnects [28]. Their conclusion is that, while optical clock distribution networks are not especially attractive, wavelength division multiplexing (WDM) does offer interesting advantages for intrachip optical interconnects over copper in deep-submicron processes. Our work builds on these projects and suggests a system where optical interconnects are used for intercore communication, thus replacing the global interconnects which are generally long and stretch across the chip. The penetration length is reduced by using on-chip modulators and simple off-chip constant-wave laser sources [14]. The off-chip lasers are cooled separately, thus dramatically reducing the chip’s power and heat density. The topology used is of a distributed network, which is scalable to a large number of terminals. Current silicon technology is leveraged to design a system which both consumes low power and is feasible for fabrication in today’s or near-term silicon-photonic technology. 3 HYBRID NOC MICROARCHITECTURE The photonic NoC microarchitecture employs a hybrid design synergistically combining an optical circuitswitched network for bulk message transmission and an electronic packet-switched network for distributed control and short message exchange. Hence, the term hybrid has a twofold meaning: It denotes both the concept of combining a circuit-switched network and a packet-switched network as well as the idea of combining electronic and photonic technologies. While photonic technology offers unique advantages in terms of energy and bandwidth, two necessary functions for packet switching, namely, buffering and header processing, are very difficult to implement with optical devices. On the other hand, electronic NoCs do have many advantages in flexibility and abundant functionality, but tend to consume high power, which scales up with the transmitted bandwidth [29]. The hybrid approach that we propose deals with this problem by employing two layers: 1. A photonic interconnection network, comprised of silicon broadband photonic switches interconnected by waveguides, is used to transmit large messages. 2. An electronic control network, topologically identical to the photonic network, is “folded” within the photonic network to control its operations and execute the exchange of short messages. Every photonic message transmitted is preceded by an electronic control packet (a path-setup packet) which is routed in the electronic network, acquiring and setting up a photonic path for the message. Buffering of messages is not currently feasible in the photonic network as there are no photonic equivalents for storage elements (e.g., flip-flops, registers, RAM). Hence, buffering, if necessary, only takes place for the electronic packets during the path-setup phase. The photonic messages are transmitted without buffering once the path has been acquired. This approach can be seen as optical circuit switching: The established paths are, in essence, optical circuits (or transparent lightpaths) between processing cores, thus enabling low-power, lowlatency, high-bandwidth communications. The main advantage of using photonic paths relies on a property of the photonic medium, known as bit-rate transparency [24]: Unlike routers based on CMOS technology that must switch with every bit of the transmitted data, leading to a dynamic power dissipation that scales with the bit rate [29], photonic switches switch on and off once per message and their energy dissipation does not depend on the bit rate. This property facilitates the transmission of very high-bandwidth messages while avoiding the power cost that is typically associated with them in traditional electronic networks. Another attractive feature of optical communications results from the low loss in optical waveguides: At the chip scale, the power dissipated on a photonic link is completely independent of the transmission distance. Energy dissipation remains essentially the same whether a message travels between two cores that are 2 mm or 2 cm apart or between two chips that are tens of centimeters apart—low loss off-chip interconnects enable the seamless scaling of the optical communication infrastructure to multichip systems. 3.1 Exploiting Photonics in NoC Design The proposed NoC is comprised of broadband 2  2 photonic switching elements (PSEs) interconnected by optical waveguides. The PSEs can switch wavelength parallel messages (i.e., each message is simultaneously encoded on several wavelengths) as a single unit, with a subnanosecond switching time. The switches are arranged as a 2D matrix and organized in groups of four. Each group is controlled by an electronic circuit termed electronic router (ER) to construct a 4  4 switch. This structure lends itself conveniently to the construction of planar 2D topologies such as a mesh or a torus. A detailed explanation on the design of the PSEs and the 4  4 switches is given in Section 4. Two-dimensional topologies are the most suitable for the construction of the proposed hybrid microarchitecture. The same reasons that made them popular in electronic NoCs, namely, their appropriateness for handling a large variety of workloads and their good layout compatibility with a tiled CMP chip [10], still apply in the photonic case. Further, largeradix switches are very difficult to construct using PSEs, so SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1249 these costs. An example of such an opportunity is an optical clock distribution network which can provide a highquality low-power clock to the entire chip, simplifying the clock recovery in the gateways. Since electronic signals are fundamentally limited in their bandwidth to a few gigahertz, larger data capacity is typically obtained by increasing the number of parallel wires. The optical equivalent of this wire parallelism can be provided by a large number of simultaneously modulated wavelengths using WDM [34] at the network interfaces. The translating device, which can be implemented using microring resonator modulators, converts directly between space-parallel electronics and wavelength-parallel photonics in a manner that conserves chip space as the translator scales to very large data capacities [35], [36]. The energy dissipated in these large parallel structures is not small, but it is still smaller then the energy consumed by the wide buses and buffers currently used in NoCs. The network gateway interface and corresponding E/O and O/E conversions occur once per core in the proposed system, compared to multiple ports at each router in electronic equivalent NoCs. A study of the power dissipated by the proposed hybrid NoC and a comparison with an allelectronic NoC architecture is given in Section 6. 3.2 Life of a Message in the Photonic NoC To illustrate the operation of the proposed NoC, we describe the typical chain of events in the transmission of a message between two ports placed on different cores in the CMP, for example, a write operation that takes place from a processing unit in a core to a memory that is located in another core. As soon as the write address is known, possibly even before the contents of the message are ready, a path-setup packet is sent on the electronic control network. The packet includes destination address information and, perhaps, additional control information such as priority or flow ID. The control packet is routed in the electronic network, reserving the photonic switches along the path for the photonic message which will follow it. At every router in the path, a next-hop decision is made according to the routing algorithm used in the network. When the path-setup packet reaches the destination port, the photonic path is reserved and is ready to route the message. Since the photonic path is completely bidirectional, a short light pulse can then be transmitted onto the waveguide in the opposite direction (from the destination to the source), signaling to the source that the path is open. This technique is similar to the one described in detail by Shacham and Bergman in [37]. When the optical pulse is rece ived at the message source , the opt ical l ink is established. The photonic message transmission then begins and the message follows the path from switch to switch until it reaches its destination. After the message transmission is completed, a pathteardown packet is sent to free the path resources for usage by other messages. Once the photonic message has been received and checked for errors, a small acknowledgment packet may be sent on the electronic control network to support guaranteed-delivery protocols. In the case where a path-setup packet is dropped in the router due to congestion, a path-blocked packet is transmitted Fig. 1. Building blocks examples. (a) A silicon nanophotonic wavelengthinsensitive switch [19]. (b) An ultracompact 10 Gbps silicon modulator [16]. (c) CMOS-compatible waveguides and holographic fiber-coupling lens for off-chip access [14]. the low-radix switches, the building blocks of mesh/torus networks, are a better fit. A key advantage of photonic implementations of meshes and tori is related to the nature of the guided waves. When two waveguides intersect at a right angle, as they do many times in mesh and torus networks, the waves continue propagating in their original direction and the crosstalk is negligible. This property enables the construction of the photonic NoC in a single layer, above the metal stack, thus reducing the fabrication complexity, the chip dimensions, and the total cost. Torus networks offer a lower network diameter compared to meshes, at the expense of having longer links [30]. Hence, they are a better choice for photonic NoCs since the transmission power on photonic links is independent of the length, unlike in copper lines. Topology can also be employed to address issues caused by the lack of buffering in photonics. Since the PSEs have small area and power consumption, many of them can be used to provision the network with additional paths on which circuits can be created, thus reducing the contention manifested as pathsetup latency. Electronic/Optical and Optical/Electronic (E/O and O/ E) conversions are necessary for the exchange of photonic messages on the NoC. Each core in the CMP, therefore, includes a network gateway serving as a photonic network interface. Small footprint microring-resonator-based silicon optical modulators with data rates up to 12.5 Gbps [31] as well as 10 Gbps Mach-Zehnder silicon modulators [14] , [16] and SiGe photodetectors [32] have been reported and have recently become commercially available [14] for photonic chip-to-chip interconnect systems (see Fig. 1). The laser sources, as in many off-chip optical communication systems [14], can be located off chip and coupled into the chip using optical fibers or, alternatively, can be bonded to the silicon die, constructing hybridevanescent laser sources [33]. The network gateways also include some circuitry for clock synchronization and recovery and serialization/ deserialization. When traditional approaches are used, this circuitry can be expensive both in terms of power and of latency. New technological opportunities enabled by the integration of photonics onto the silicon die may reduce 1250 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 2. PSE: (a) OFF state: A passive waveguide crossover. (b) ON state: Light is coupled into rings and forced to turn. Fig. 3. A 4  4 switch. Four PSE controlled by an electronic router (ER). by the dropping router to the source, backtracking the path traveled by the path-setup packet. The path-blocked packet releases the reserved switches and notifies the core attempting transmission that its request was not served. The source may then attempt transmission again and take advantage of PM in the network. 4 NETWORK DESIGN The design of the photonic NoC requires an approach fundamentally different, in many aspects, from electronic NoCs. In this section, we describe in detail the proposed implementation, including the network’s electronic and photonic building blocks, topology, routing algorithms, and flow control. 4.1 Building Blocks The main building block of the photonic NoC is a broadband PSE, based on a microring-resonator structure. A similar device, although optically pumped, was recently reported in [19]. The switch is, in essence, a waveguide intersection, positioned between two ring-shaped waveguide structures ( i .e . , microring resonators) . The rings have a certain resonance frequency, derived from material and structural properties. The PSE can be in one of two possible states: . OFF state: The resonant frequency of the rings is different from the wavelength (or wavelengths) on which the optical data stream is modulated. Hence, the light passes through the waveguide intersection uninterrupted, as if it is a passive waveguide crossover (Fig. 2a). . ON state: The switch is turned on by the injection of electrical current into p-n contacts surrounding the rings; the resonance of the rings shifts so that the light, now on resonance, is coupled into the rings, making a right angle turn, thus causing a switching action (Fig. 2b). Photonic switching elements and modulators based on these effects have been realized in silicon and a switching time of 30 ps has been experimentally demonstrated [31]. Their merit lies mainly in their extremely small footprint, with ring diameters of approximately 12 m, and their low power consumption of less than 0.5 mW of DC power when ON and approximately 1 pJ for modulating narrowband single-wavelength signals. For switching multiwavelength broadband signals, the ring resonators are designed as comb-pass filters with somewhat larger footprints, consuming 10 mW when ON [15], [18]. When the switches are OFF, they act as passive devices consuming nearly no power. Ring-resonator-based switches exhibit good crosstalk properties (> 20 dB), and a low insertion loss, approximately 1.5 dB [38]. Recent results reported in [19] (see Fig. 1a) demonstrate an optically pumped PSE with a measured insertion loss of 2.5 dB in the pass-band, capable of simultaneously switching nine 40 Gbps wavelengths. The switch is compact ð40  12mÞ and has a switching time < 2 ns. It is reasonable to assume that the loss figures can be improved with advances in fabrication techniques and that electrically pumped devices, necessary to enable fabrication and electronic control will be developed. The PSEs are interconnected by silicon waveguides, carrying the photonic signals, and are organized in groups termed an ER, forms a 4  4 switch (Fig. 3). The 4  4 switches of four. Each quadruplet, controlled by an electronic circuit are therefore interconnected by the inter-PSE waveguides and by the metal lines connecting the ERs. Control packets (e.g., path-setup) are received in the ER, processed, and sent to their next hop, while the PSEs are switched ON and OFF accordingly. Once a packet completes its journey through a sequence of ERs, a chain of PSEs is ready to route the optical message. Owing to the small footprint of the PSEs and the packets, the 4  4 switch can have a very small area. Based on simplicity of the ER, which only processes small control the size of the microring resonator devices [19], [31] and the minimal logic required to implement the ER, this area is estimated to be about 70  70m. A keen observer will notice that the 4  4 switch in Fig. 3 is blocking. For example, a message routed from South to East will block message requests from West to South and from East to North. In general, every message that makes a wide turn (i.e., a turn involving three PSEs) may block two other message requests that attempt to make wide turns. Messages that make narrow turns (e.g., South to West) and messages that are routed straight through do not block other messages and cannot be blocked. To limit the blocking problem, U-turns within the switches are forbidden. The blocking relationships between messages are summarized in Table 1. It is an important requirement for an atomic switch to have a nonblocking property in an interconnection network. Nonblocking switches offer improved performance and simplify network management and routing. However, constructing a nonblocking 4  4 switch with the given photonic building blocks requires an exceedingly complex structure. This has a negative impact on the area and, more importantly, the optical signal integrity, as each PSE hop introduces additional loss and crosstalk. The design choice is, therefore, to use the blocking switch because of SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1251 TABLE 1 Intermessage Blocking Relations in the 4  4 Photonic Switch its compactness and to bear its blocking properties in mind when designing the network topology and routing algorithm. It is worth mentioning that different PSE-grouping schemes can be used where the directions of the waveguides are flipped, causing the blocking properties to slightly change. One possible scheme is to group the PSEs as a mirror image of the current grouping scheme, where the directions of all waveguides are flipped. The analysis of this case is identical to the original grouping scheme. In yet another scheme, the direction of only one pair of waveguides is flipped (either the vertical or the horizontal). In this case, each turning message may block one other message. A related constraint resulting from the switch structure concerns the local injection/ejection port. Typically, 2D mesh/torus NoCs use 5  5 switches, where one port is dedicated for local injection and ejection of packets. A 5  5 switch is very simple to implement as an electronic transistor-based crossbar, but it is quite difficult to build using 2  2 PSEs. The injection and ejection of packets is therefore done through one of the four existing ports, blocking it for through traffic. This design decision constrains the topology, as described in Section 4.2. 4.2 Topology The topology of choice in our design reflects the characteristics of the entire system—a CMP, where a number of homogeneous processing cores are integrated as tiles on a single die. The communication requirements of a CMP are best served by a 2D regular topology such as a mesh or a torus [39]. These topologies well match the planar, regular layout of the CMP and the application-based nature of the traffic—any program running on the CMP may generate a different traffic pattern [30]. As explained above, a regular 2D topology requires 5  5 switches which are overly complex to implement using photonic technology. We therefore use a folded-torus topology as a base and augment it with access points for the gateways. Fig. 4 illustrates an example of a 4  4 folded torus network with the augmenting access points. The access points for the gateways are designed with two goals in mind: 1) to facilitate injection and ejection without interference with the through traffic on the torus and 2) to avoid blocking between injected and ejected traffic which may be caused by the switches internal blocking. Injection-ejection blocking can be detrimental to the performance and may also cause deadlocks. The access points are designed such that gateways (i.e., the optical transmitters and receivers) are directly connected to a 4  4 switch (the gateway switch) through its West port (see Fig. 4). We assume, without loss of generality, that all of the Fig. 4. A 4-ary 2D folded torus network (thick lines and dark ovals), access points (thin lines and light ovals), and 16 gateways (rectangles). One access point is shaded and enlarged. Fig. 5. Deadlock-avoiding path on the augmented folded torus network. gateways are connected to the same port in their respective switches. To avoid internal blocking, a set of injection-ejection rules must be followed: Injected messages make a turn at the gateway switch, according to their destination, and then enter the torus network through an injection switch. Messages are ejected from the torus network when they arrive at the ejection switch associated with their final destination. The ejection switches are located on the network, in the same row as the gateway switch, and this is the place where the ejecting messages turn. Finally, ejected messages pass through the gateway switch without making turns. In Fig. 5, the switches are marked, along with an example of a path. Since torus networks are edge-symmetric [30], injection can be done at any port of the gateway switch as long as the structure of the access point is rotated accordingly. An explanation of how this structure can be exploited to reduce contentions and avoid deadlocks is given in Section 5.2. The design of the access points contributes to a larger switch count in the network because every access point requires three additional switches. However, each switch is rather small in footprint and power consumption. Consequently, as shown in Section 6, the overall penalty is minimal compared to the global power savings enabled by the photonic technology. Topological means can also be exploited to reduce contention-generated latency. A network designer, however, may take advantage of the small footprint to improve the performance by increasing the PM in the network: Specifically, the torus network can be augmented with additional paths, without changing the number of access points, so that the probability of blocking is lowered and the path-setup latency is accordingly reduced. Due to the 1252 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 small footprint of the switches, the simplicity of the routers, and the fact that the PSEs only consume power when they cause messages to turn, the power and area cost of adding parallel paths is not large. The latency penalty that results from the increased hop-count should be balanced against the latency reduction achieved by mitigating contention such that an optimal latency point is found. This issue is studied in detail in Section 5.4. 4.3 Routing Dimension order routing is a simple routing algorithm for mesh and torus networks. It requires minimal logic in the routers and, being an oblivious algorithm, it simplifies the router design in terms of area and power consumption. We use XY dimension-order routing on the torus network, with a slight modification required to accommodate the injection/ejection rules described in Section 4.2 above. Each message is encoded with three addresses: two intermediate addresses and a final address, encapsulated within one another. The first address directs the message to the injection switch on the torus network, causing the message to make the turn at the gateway switch, as required by the injection rules (see Fig. 5). The message is then routed on the torus, using plain XY dimension-order routing, to the second intermediate address, i.e., the ejection switch, in the final destination’s row, one column away from it. Only then is the final address “decapsulated” and the message is forwarded to the destination gateway, where it arrives without having to turn, according to the ejection rules. The address encapsulation mechanism relieves the routers from processing system-scale considerations when setting up a path and preserves the simplicity of dimension-order routing in the torus network. When the torus network is path-multiplied such that several parallel lanes exist in each row/column, the address encapsulation mechanism can be used to take advantage of the PM while preserving the simplicity and obliviousness of dimension-order routing [30]. The encoding of intermediate addresses can be done with the goal of balancing the load between parallel lanes, thus reducing the contention. According to this method, the first intermediate address will be an injection switch on one of the lanes, as chosen by the gateway. The ejection among the several parallel lanes is also chosen by the gateway and encoded on the second intermediate address. The final address, of course, does not change. The selection of intermediate addresses is equivalent to choosing, at random, one among several torus subnetworks, thus balancing the load among them. In Section 5.4, we use the load-balancing approach when evaluating the effect of PM. Alternative methods to select an intermediate address can be used such as restricting one lane to high priority traffic or allocating lanes to sources or designated flows. 4.4 Flow Control The flow control technique in our NoC differs remarkably from flow control methods that have been previously proposed for NoCs. The dissimilarity stems from the fundamental differences between electronic and photonic technologies and, particularly, from the fact that memory elements (such as flip-flops and SRAM) cannot be used to Fig. 6. Qualitative timing diagram of (left) a successful message setup and (right) a blocked setup request. buffer messages or even to delay them while contention resolution and header processing are done. Electronic control packets are, therefore, exchanged to acquire photonic paths and the data are only transmitted, with a very high bandwidth, once the path has been acquired. The path acquisition procedure requires the path-setup packet to travel a number of ERs and undergo some processing in each hop. Additionally, the packet may experience blocking at certain points in its path, further contributing to the setup latency. Once the path is acquired, the transmission latency of the optical data is very short and depends only on the group velocity of light in a silicon waveguide: approximately 6:6  107 m/s [40] or 300 ps for a 2 cm-path crossing a chip. Hence, the overall NoC essentially becomes a fast circuit-switched network, where the path-setup latency is much longer than the transmission latency. Still, path-setup latency is on the order of nanoseconds, a very short time compared to conventional circuit-switched networks where the typical setup time is in the millisecond range. Therefore, when packet sizes are fairly large, the setup time in our NoC can be considered fast and the network can handle packet-switched traffic with reasonable latency. The timing diagram in Fig. 6 illustrates the timing discrepancy. For short messages, in a lightly loaded network, the largest latency component is the zero-load path-setup latency. If, conversely, the NoC is heavily loaded, the path-setup latency is contention dominated. Namely, most of the latency is the time spent by the path-setup packets in the routers’ internal buffers . Path-setup packets are buffered when they are blocked by contention and are only released when the blocking message has been cleared. This approach, however, suffers from increased latency, especially for large message sizes. An alternative solution is to reduce the buffering depth in the router while relying on path multiplicity. In the extreme case, the buffer depths in the routers are reduced to zero, path-setup packets are dropped on contention, and the originating sources are immediately notified by a packet-dropped packet. The sources can then exploit the network’s PM to attempt transmission on a different path and throughput can be improved significantly. Experimental results on a study comparing these methods are reported in Section 5.5. The optimal size of a photonic message in a given implementation of the photonic NoC depends on the network size, on the latency of the individual components (routers, photonic links, electronic links, etc.), and on the bandwidth of the gateways. Further, it is critical to account for the path-setup latency. While one would want to SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1253 minimize the setup time overhead by using large messages, their size should be kept small enough to allow for good flexibility and link utilization and to avoid excessive serialization latencies. Clearly, exchanges of small messages, such as memory read requests, write acknowledgments, and cache-coherency snoop messages, pose a challenge in terms of efficiency. When large memory pages or long cache lines are exchanged, instead, the photonic network is utilized much more efficiently. Our hybrid NoC microarchitecture represents a communication medium with unique performance features for the latter case (i.e., large messages) while making it possible to address the problem of exchanging small packets in an elegant way. In fact, small messages can be exchanged on the control network, which is essentially a low-bandwidth electronic NoC, while not requiring large resources in terms of additional circuitry or power dissipation. Long-lasting connections can be set up between processing cores that are expected to communicate frequently, thus providing a high-bandwidth link with minimal latency and low power consumption on wh ich packets of any s ize can be transmitted. Another favorable communication model for communications between processing cores is DMA, where large blocks of data are exchanged between memory modules with minimal CPU overhead. Considering the path-setup overhead in the photonic NoC, DMA can be configured to use memory transactions that are fairly large and are planned in advance. The DMA overhead messages can be transmitted over the control network while the optical path is being set up. Hence, some of the path-setup latency can overlap with the DMA overhead to reduce the total latency. In Section 5.3, we present experimental results for DMA communications on the proposed photonic NoC and look at optimal block sizes. 5 DESIGN ANALYSIS AND OPTIMIZATION A key stage in the development of the ideas presented above is their functional validation using simulation. Further, a quantitative performance study, using a variety of traffic loads, must be carried out to evaluate alternative topologies, routine algorithms, and flow control techniques. We developed a new event-driven simulator that is specifically tailored to provide support for the design exploration of the proposed photonic NoC. After describing the simulation setup, in the next sections, we report the results of several studies performed using the simulator. The first study is about avoiding deadlock, while the others explore various performance optimization techniques to increase PM, limit the path-setup procedure overhead, and determine the optimal message size. 5.1 Simulation Setup We developed POINTS (Photonic On-chip Interconnection Network Traffic Simulator), an event-driven simulator based on OMNET++ [41]. OMNET++ is an open-source simulation environment that provides good support for modu lar structures , message-based commun icat ions between modules, and accurate modeling of physical layer factors such as delay, bandwidth, and error rate. We implemented a highly parameterized model, which enables a broad exploration of the design space, and we use it to analyze the case study of a 36-core CMP, organized in a 6  6 planar layout, built in a future 22-nm CMOS process technology. The chip size is assumed to be 20 mm along its edge, so each core is 3:3  3:3 mm in size. The network is a 6  6 folded-torus network augmented with 36 gateway network—for clarity purposes), so it uses a matrix of 12  access points (Fig. 4 presents a similar, albeit smaller, 12 switches. The ERs, each located at the center of a switch, are spaced by 1.67 mm and the PSEs (576 are used) are spaced by 0.83 mm. The area and spacing considerations dictate the timing parameters of the network, as modeled in simulation. We assume a propagation velocity of 15.4 ps/mm in a silicon waveguide for the optical signals [40] and 131 ps/mm in an optimally repeated wire at 22 nm for the electronic signals traveling between ERs [42]. The inter-PSE delay and interrouter delay are, therefore, 13 and 220 ps, respectively. The PSE setup time is assumed to be 1 ns and the router processing latency is 600 ps, or three cycle times of a 5 GHz clock. Message injection processes in NoC simulation models are typically Bernoulli or modulated-Bernoulli processes, which work well with packet-switched slotted network. Since our microarchitecture resembles circuit switching more than packet switching, we model the intermessage gap as an exponential random variable with a parameter IMG . In the simulations reported in this paper, we use uniform traffic. While this traffic pattern does not necessarily model the actual loads presented to the network in a CMP, it serves well as an initial measurement technique to demonstrate the capacity of the network and as a reference to use in future measurements. 5.2 Dealing with Deadlock Deadlock in torus networks has been studied extensively. When dimension-order routing is used, no channeldependency cycles are formed between dimensions, so deadlock involving messages traveling in different dimensions cannot occur [30]. Virtual channel flow control has been proven successful in eliminating intradimension deadlocks [43] and make dimension-order routing deadlock free. These results assume that each router in the torus network is internally nonblocking. As described in Section 4, this is not the case in our network . Area and technology constraints lead us to use a 4  4 switch which has some internal blocking between messages. We recall that every wide turn in the switch may block two other wide turns. Messages that make narrow turns and messages that pass straight through do not block other messages and cannot be blocked. U-turns are forbidden. Hence, we are required to 1) evaluate the topology, 2) find when deadlocks may occur, and 3) develop solutions to avoid them. In Section 4, we explained the injection-ejection mechanisms that are illustrated in Fig. 5. They include the separation of injection and ejection to different switches so that turns that may block other messages cannot occur in the same switch. To prove this, we inspect each of the three switches comprising the access point and show that, by design, deadlock cannot occur in any of them: 1254 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 7. (a) Gateway, (b) injection, and (c) ejection switches. All possible message-paths are marked to demonstrate that no blocking interactions occur. . . . Gateway switch. Injected messages are required to make a turn toward the injection switches. Ejected messages arrive from the ejection message and pass straight through. Therefore, blocking cannot happen. Injection switch. Messages traveling on the torus network do not turn to the injection paths, so no blocking interactions exist between them and the injected messages. Ejection switch. Messages may arrive only from the torus network and either turn for ejection or continue straight through. Since no messages arrive from the gateway switch, none of the blocking interactions may happen. In Fig. 7, the three switches are shown with all possible paths marked on them. One could verify that none of the internal blocking scenarios (listed in Table 1) can occur. Even though injection-ejection blocking situations are completely avoided and so are the associated performance penalty and possible deadlocks, the problem of intradimensional blocking of dimension-order routing still remains. The accepted solution for this problem is virtual channel flow control where the channel dependencies are removed by splitting the physical channel into several virtual channels that compete with each other for router bandwidth [43]. This approach is difficult to implement in a circuit-switched network where the channel bandwidth cannot be divided between several circuits. One way to solve the intrad imensional dead lock problem is to use path-setup timeouts. When a path-setup packet is sent, the gateway sets a timer to a predefined time. When the timer expires, a terminate-on-timeout packet is sent after the path-setup packet. The timeout packet follows the path acquired by the path-setup packet until it reaches the router where it is blocked. At that router, the path-setup packet is removed from the queue and a path-blocked packet is sent on the reverse path, notifying the routers that the packet was terminated and the path should be freed. This allows the system to recover from a potential deadlock. While this method suffers from some inefficiency because paths and gateway injection ports are blocked for some time until they are terminated without transmission, it guarantees deadlock-recovery. In an alternative method, the path-setup packet is not deadlocked but merely delayed and it reaches its destination while the timeout packet is en route. In these cases, the timeout packet reaches the destination gateway where it is ignored and discarded and the path is acquired as if the timeout has not expired. This method has been tested in extensive simulations and has been shown to be effective in resolving deadlocks. 5.3 Optimizing Message Size In order to maintain the network efficiency as well as its flexibility and link utilization, the message duration should be carefully picked. If too large messages are used, then link utilization is compromised and serialization latency is increased. On the other hand, if messages are too small, then the relative overhead of the path-setup latency becomes too large and efficiency is degraded. Of course, there is no technical reason preventing us from granting full freedom in message-sizing to each core, but this may cause starvation and unfairness. In this section, we study the optimal size with respect to the overhead incurred in the path-setup process under the assumption that it is constant across all messages. We define the overhead ratio as  ¼ Tpath reservation Tmessage duration ; where Tpath reservation is defined as the time between the transmission of the path-setup packet and the transmission of the path-teardown packet and Tmessage duration is the time during which actual transmission takes place, corresponding to the size of the message (see Fig. 6). Obviously,   1 and the smaller the value of , the higher the network efficiency. We pick the message size by setting a desired overhead ratio and finding the smallest message size for which the selected ratio is not exceeded. In an unloaded network, if the maximum allowed overhead is 20 percent, then the maximum overhead ratio is  ¼ 1:25. This limit is met by messages with duration larger than 50 ns for the longest path, which consists of 13 hops. The next step is to simulate a loaded network when the global message duration is 50 ns. Naturally, the overhead will be larger when the network becomes loaded with traffic from other cores as path acquisition is expected to take longer due to blocking. To evaluate the effect of congestion on the message setup overhead, we transmit 50 ns messages from all cores with uniformly distributed addresses. The load on the network is regulated by controlling the distribution parameter of the exponentially distributed intermessage gap ðIMG Þ. The load offered ðÞ to the network is then given as  ¼ Tmessage duration Tmessage duration þ 1 IM G : IMG IMG ð 1 At the limit of constant transmission by all sources ! 0Þ, the offered load approaches 1 and, when the intermessage gap is very large ð 1 ! 1Þ, the offered load approaches zero. The results of the congestion experiment are reported in Fig. 8, showing that the overhead in a loaded network, even lightly loaded, is larger, as was expected. The overhead ratio rises quickly to a value of 3 (or a path-setup latency of 100 ns) for loads exceeding a 0.6 value. Clearly, the increased congestion and its detrimental effects on the latency must be dealt with. Adaptive routing algorithms, which use information about the availability of adjacent paths when making a routing decision, can be used to locate alternative paths for messages and reduce the blocking SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1255 Fig. 8. Overhead ratio as a function of offered load for 50 ns messages in a 36-core photonic NoC (6  6 torus, no PM). probability. One must also remember that the network is simulated under uniform traffic. Typical application in CMP environments is expected to generate more localized traffic patterns which can be routed more efficiently by the network. To allow better understanding of the effect of the message size on the network’s performance and to confirm the choice of the overhead threshold (20 percent), we completed additional simulations using a more realistic DMA model. We note that, with a peak transmission rate of 960 Gbps (using WDM, see Section 6.2), 50 ns can be used to transmit a 6 Kbyte message, e.g., a DMA block. Accurate modeling of a DMA transaction requires the knowledge of the specific implementation of the DMA hardware [7]. However, interesting data points can be obtained by simulating the effects of the block size on the latency and on the average bandwidth of the photonic NoC for the cases of an unloaded network and a heavily loaded network ðoffered load ¼ 0:85Þ. Using the POINTS simulator, we obtained the results reported in Fig. 9 for a peak transmission bandwidth equal to 960 Gbps. As predicted, for small block sizes ð 1 KbyteÞ, the overall latency is dominated by the path-setup overhead, which is greater than the serialization latency, because of the extremely large transmission bandwidth. DMA blocks of this size will clearly be inefficient. On the other hand, whenever very large blocks ð 65 KbytesÞ are used, the increased serialization and contention latencies overshadow the gain in bandwidth, which is diminishing for large blocks. Therefore, in the presence of this trade-off, the optimal DMA block size for the transactions over the photonic NoC ranges between 4 and 16 Kbytes. This result is consistent with the 50 ns result obtained earlier. An alternative technique to reduce the path-setup latency by relieving contention is increasing the PM by augmenting the network with parallel lines. This approach is considered in the next section. 5.4 Increasing Path Multiplicity One of the advantages of packet-switched networks lies in the statistical multiplexing of packets across channels and its extensive usage of buffers. These allow for distribution of loads across space and time. In a photonic circuitswitched network, there is no statistical multiplexing and buffering is impractical. Additional paths, however, can be provisioned, over which the load can be distributed using either random load-balancing techniques or adaptive Fig. 9. (a) Average latency and (b) bandwidth for network transaction of different sizes in 36-core photonic NoC (12  12 torus). TABLE 2 NoC Switch Counts as Function of Path Multiplicity Values algorithms that use current information on the network load. As discussed in Section 4, the topology chosen for the proposed network, a torus, can be easily augmented with additional parallel paths that provide path multiplicity and facilitate this distribution of the load. The performance metric used to evaluate the improvement gained by adding the paths is again the path-setup overhead ratio, which is derived directly from the path-setup latency. Like in the previous experiment, we set Tmessage duration at 50 ns. TIM G is exponentially distributed with a parameter IMG which is, again, varied to control the offered load. Networks with path multiplicity values of 1-4 are simulated, where a value of 1 represents the baseline 6  6 torus with 36 access points and a value of 4 represents a 24  24 torus, also with 36 access points. Naturally, PM presents an overhead in terms of hardware and increased zero-load latency as a result of the larger network diameter. Table 2 lists the numbers of switches required to implement each of the networks simulated. If we assume that the area of the 4  4 switch is about 5,000 m2 , then, theoretically, more than 80,000 such switches can be integrated in the photonic layer of a 400 mm2 die. The power dissipated by the diversified network scales sublinearly with the number of switches as switches only consume power when they cause 1256 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 10. Overhead ratio versus offered load for varying values of path multiplicity (PM). The corresponding network sizes are given in Table 2. a message-turn . The number of turns is fixed and independent of the number of switches, thereby setting a strict upper bound on the power expended in forwarding the photonic message regardless of the actual physical distance traveled. A more detailed power analysis is given in Section 6. The simulation results are reported in Fig. 10. First, as expected, the increased network diameter caused by the provisioning of paths actually increases the latency when the network is lightly loaded and blocking is not frequent. As the network becomes congested, message blocking starts to dominate the path-setup latency and the additional paths, which reduce the blocking, dramatically reduce the latency, thus contributing to a more efficient network. Second, path multiplicity clearly has a diminishing return beyond a 3 factor. When the path multiplicity is too large, the additional paths lead to a large network diameter and zero-load latency, while making only a minor reduction in network blocking. In fact, for the simulated test case, achieved by a 3 path multiplicity is too small to justify the it can be argued that the performance gain increase in the optical layer density and fabrication complexity. In any case, a 2 path multiplicity increase does offer dramatic performance gains. Clearly, for any system, these design issues should be modeled, studied, and evaluated carefully against physical design constraints (e.g., waveguide routing space limits) in the preliminary design and microarchitecture phases. 5.5 Evaluating Path-Setup Procedures In Section 5.3, we showed how the network throughput and performance is determined by the path-setup overhead. Reductions in path-setup latency translate to improved efficiency of the network interfaces and to higher average bandwidth. be expressed as D ¼ ðH   1Þ  tp þ tq , where H is the For a given source-destination pair, the setup latency can number of hops in the packet’s path, tp is the processing latency in each router, and tq is the total additional latency due to contentions. As discussed in Section 4.4, contention in the path-setup phase can be handled by blocking the path-setup packet until the path is cleared. Simulations show that tq is a major contributor to the overall setup latency, especially when the network is heavily loaded. Notice, however, that the actual processing latency in the path-setup phase, which is equal to ðH   1Þ  tp , is typically Fig. 11. (a) Average path-setup latency and (b) bandwidth as a function of buffer depth in a 36-core photonic NoC (12  12 torus). much lower than the contention-based latency. Hence, in order to decrease the contention-based setup latency tq , one can use an alternative method that consists of immediately dropping any path-setup packet that is blocked instead of buffering it. This allows reducing the buffering depth in the ER down to zero, thus simplifying its circuitry. On the other hand, it requires that a packet-dropped packet be sent on the control network in the opposite direction to notify the sender. Then, the sender can immediately attempt to set up an alternative path, exploiting the network’s path multiplicity. With an adequate level of path multiplicity, it is reasonable to assume that an alternative path can be found faster than it would take for the message obstructing the original path to be torn down. We used the POINTS simulator to evaluate this idea in the case of the same 36-core CMP system discussed above and assuming an optical message size equal to 16 Kbytes and a path multiplicity factor equal to 2. The simulation results are reported in Fig. 11: By setting the buffer depth to 0, i.e., dropping every blocked packet and immediately notifying the sender, the path-setup latency can be reduced by as much as 30 percent when compared to the case where path-setup packets are not dropped on contention (buffer depth of 2). When a buffer depth of 1 is simulated, i.e., a single path-setup packet may be queued in each direction in each electronic router, the latency reduction is smaller. The peak optical bandwidth per port in the simulations, using WDM, is set at 960 Gbps. The average bandwidth is calculated as the product of the peak bandwidth and the fractional time, in steady state, that can be allocated for actual transmission of the optical messages, after messages have been set up. The average bandwidth results are also shown in Fig. 11, demonstrating a maximum sustained SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1257 TABLE 3 Predictions for Future Technology Nodes TABLE 4 Power Consumption of Electronic NoC bandwidth, or throughput, of approximately 53 Gbytes/s. This result, 45 percent of the peak possible bandwidth, is considered quite good for an interconnection network and can even be improved with better routing algorithms and when more realistic and localized traffic patterns are applied onto the network. 6 COMPARATIVE POWER ANALYSIS The main motivation for the design of a photonic NoC is the potential dramatic reduction in the power dissipated on high-bandwidth communications. To evaluate this power reduction, we perform a comparative high-level power analysis between two equivalent on-chip interconnection networks for CMPs: a photonic NoC and a reference electronic NoC. They are equivalent in the sense that both networks must provide the same bandwidth to the same number of processing cores. For our case study, we assume a CMP implemented in a future 22 nm CMOS technology and hosting 36 processing cores, each requiring a peak bandwidth of 800 Gbps and an average bandwidth of 512 Gbps. These numbers match widely accepted predictions on future on-chip bandwidth requirements in highperformance CMPs. We will see that, in this highbandwidth realm , photonic technologies can offer a significant reduction in the interconnect power. We assume a uniform traffic model , a mesh topology , and XY dimension-order routing. Of course, different conditions can be used, but, as our goal is to provide an equal comparison plane, this choice provides a simple “apples-toapples” comparison. 6.1 Electronic NoC The reference electronic network is a 6  6 mesh, where each router is integrated in one processor tile and is connected to four (or fewer) neighboring tiles. A router microarchitecture that is based on an input-queued crossbar with a 4-flit buffer2 on each input port has been widely proposed in the NoC literature [10], [39]. The router has five I/O ports: one for the local processor and one for each of the four network connections with a neighbor tile (N, S, E, and W). We estimate the power expended in an electronic NoC under a given load using the method developed by Eisley and Peh in [44]: This assumes that, whenever a flit traverses a link and the subsequent router, five operations are performed: 1. 2. 3. reading from a buffer, traversing the routers’ internal crossbar, transmission across the interrouter link, 2. A flit is the minimal flow control unit, equal to the number of bits that cross the link in a clock cycle, i.e., the link width. 4. writing to a buffer in the subsequent router, and 5. triggering an arbitration decision. The energy required for a single hop through a link and a router ðEF LI T  HOP Þ is the sum of the energies spent in these operations. Table 3 reports the values of the energy spent in these operations (buffer reading and writing energies are combined, arbiter energy is neglected) that were obtained with the ORION NoC simulator [45]. ORION accounts for the static energy dissipated in the router and converts it to a per-bit scale. EF LI T  HOP , the energy expended to transmit one flit across a link and a subsequent router, is computed based on the energy estimates in Table 3 as well as the link length and flit-width, which vary for different technology nodes. The total energy expended in a clock cycle can be computed as EN ET W ORK CY CLE ¼ ULj  EF LI T  HOP ; X NL j¼1 where ULj is the average number of flits traversing link j per clock cycle, an estimate on the utilization of link j. Then, the power dissipated in the network is equal to PN ¼ EN ET W ORK CY CLE  f ; where f is the clock frequency. For a 6  6 mesh under uniform traffic using XY routing and an injection rate of  ¼ 0:625, the global average link utilization is U ¼ 0:75. Hence, the energy expended in a clock cycle in the reference electronic NoC (which has 120 links) is EN ET W ORK CY CLE ¼ 0:75  120  EF LI T  HOP and the total power dissipated is estimated as PE N oC ¼ EN ET W ORK C Y CLE  f : The results are given in Table 4. The main conclusion that can be drawn from this analysis is that, when a truly high communication bandwidth is required for on-chip data exchange, even a dedicated, carefully designed NoC may not be able to provide it with in reasonable power constraints. Since the electronic transmission is limited in bandwidth to a few gigahertz at most, high transmission capacity requires the use of many parallel lines and wide buffers [10], which lead to high power dissipation for transmission and buffering. Admittedly, the above analysis is based on a simple circuit implementation, but, even if aggressive electronic circuit techniques such as low-swing current mode signaling are employed, the overall NoC power consumption that is necessary to meet the communication bandwidth requirements in future CMPs will likely be too high to manage within the tight packaging constraints [1]. 1258 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 6.2 Proposed Photonic NoC Since our NoC is based on a hybrid microarchitecture, its power dissipation can be estimated as the sum of three components: 1) the photonic data-transfer network, 2) the electronic control network, and 3) the O/E and E/O interfaces. 6.2.1 Photonic Data-Transmission Network Path multiplicity is a low-power cost-effective solution to compensate for the lack of buffers in the photonic network. In this design, we assume a path multiplicity factor of 2, meaning a 12  12 photonic mesh, comprised of 576 PSEs (144 4  4 switches), serves the 6  6 CMP. The power analysis of a photonic NoC is fundamentally different from the electronic network analysis since it mainly depends on the state of the PSEs: In the ON state, when the multiwavelength message is forced to turn, the power dissipated is approximately 10 mW [15], [18], while there is no dissipation in the OFF state when a message proceeds undisturbed or when no message is forwarded. Hence, the total power consumption in the network depends on the number of switches in the ON state, which can be estimated based on network statistics and traffic dynamics. We assume that, in the photonic NoC, each message makes, at most, four turns, based on the 3-stage routing algorithm described in Section 4.3. In the photonic network, we assume a peak bandwidth of 960 Gbps, exceeding the 800 Gbps requirement, and an injection rate of 0.6, so the average bandwidth is 576 Gbps. The average calculated as 36  0:6 ¼ 21:6. The average number of PSEs number of messages in the network at any given time is in the ON state is about 86 in a 576-PSE NoC. Hence, the total power consumption is estimated as PP  N oC ;transmission ¼ 86  10 mW ¼ 860 mW; dramatically lower than anything that can be approached by an electronic NoC. 6.2.2 Electronic Control Network The power analysis of the electronic control network is based on the fact that this is essentially an electronic packetswitched NoC, i.e., similar to the reference electronic NoC that we discussed in Section 6.1 except for the larger dimensions (12  12 compared to 6  6). We assume that each photonic message is accompanied by two 32-bit control packets and the typical size of a message is 2 Kbytes. Then, the total power consumed by the electronic control network can be approximated as PP  N oC ;control ¼ PE N oC  2  32 16; 384  2 ¼ 0:82 W: If the electronic control network is utilized lightly, the impact of static power becomes more dominant in the overall NoC power budget. However, recent technological breakthroughs in semiconductor processes, namely, Intel’s 45 nm process leveraging high-K dielectrics, have been shown to reduce the gate leakage more than 10-fold [46]. Having dramatically reduced the gate leakage, channel leakage remains the major challenge. Given past trends in semiconductor technology, it is reasonable to expect that a solution will be found. 6.2.3 Network Interfaces To generate the 960 Gbps peak bandwidth, we assume a modulation rate of 40 Gbps on 24 wavelengths, as was demonstrated in [34]. The modulated data streams are grouped using passive WDM multiplexers, so power is dissipated mainly in the 24 modulators and 24 receiver circuits in each gateway. Since there is presently no equivalent to the International Technology Roadmap for Semiconductors (ITRS) [1] for the photonic technology, predictions on the power consumption of photonic elements vary greatly. A reasonable estimate for the energy dissipated by a modulator/detector pair, at 10 Gbps, today is about 2 pJ/bit, based on recent results reported by IBM [16]. We estimate that, using silicon ring-resonator modulators and SiGe photodetectors, the energy will decrease to about 0.2 pJ/bit in the next 8-10 years. Consequently, the total power dissipated by 36 interfaces under the conditions described above is PP  N oC ;gateways ¼ 0:2 pJ=bit  36  576 Gbps ¼ 4:2 W: Supplementary circuits that are usually required for the implementation of optical receivers (e.g., clock-data recovery, serializer/deserializer, and dispersion compensation), are not needed in an ultrashort link in which the modulation rate is equal to the chip clock rate [13]. As most of the power consumed by optical receivers is usually due to these circuits [24], the power saving potential is large. The off-chip laser sources consume an estimated power of 10 mW per wavelength. Although a large number of lasers are required to exploit the bandwidth potential of the optical NoC, their power is dissipated off-chip and does not contribute to the chip power density. Putting things together, the estimated power consumed by the photonic NoC to exchange data between 36 cores at an average bandwidth of 576 Gbps is given by the sum of the three components and is equal to  6 W. Although the power analysis used here is rather simplistic and uses many assumptions to ease the calculation and work around missing data, its broader conclusion is clear. The potential power difference between photonics-based NoCs and their purely electronic counterparts is significant. Importantly, once generated, the power consumed by propagating the optical signals off-chip across the system is essentially negligible and can enable true scaling for off-chip CMP high-bandwidth communications. Even when one accounts for inaccuracies in our analysis and considers predicted future trends, the advantages offered by photonics represent a clear leap in terms of bandwidth-per-watt performance. 7 CONCLUDING REMARKS We have proposed the idea of building a photonic NoC for future generations of CMPs. The motivation behind our work is rooted in the intersection of several technological trajectories from different fields. First, multicore processors step into an era where highbandwidth communications between large numbers of cores is a key driver of computing performance. Second, power dissipation has clearly become the limiting factor in the design of high-performance microprocessors. SHACHAM ET AL.: PHOTONIC NETWORKS-ON-CHIP FOR FUTURE GENERATIONS OF CHIP MULTIPROCESSORS 1259 Moreover, the power dissipated on intrachip communication is a large and growing fraction of the total power budget. Third, recent breakthroughs in the field of silicon photonics suggest that the integration of optical elements with CMOS electronics is likely to become viable in the near future. The intersection of these three factors suggests that silicon photonic technology can be used to construct NoCs, offering a promising low-power solution for high-performance on-chip communication. The design of photonic NoC presents interesting and challenging problems. To address these problems, we proposed a hybrid NoC m icroarch i tec ture tha t comb ines a pho ton ic c ircu i t switched network with an electronic packet-switched network so that each technology is used advantageously: photonics for bulk-data transmission and electronics for network control. Electronic packets are used to establish transparent lightpaths that carry high-bandwidth optical messages across a network of broadband optical switches. The proposed microarchitecture has been analyzed and optimized through extensive simulations: a torus topology, augmented with multiple paths and gateway access points, has been shown to provide large average transmission bandwidth and low latency while avoiding injectiontriggered deadlocks. Techniques of recovering from interdimension deadlocks were also suggested. Several performance-related parameters were modeled and simulated and their effects on the bandwidths and the message latency were quantified. A power analysis was conducted, demonstrating the potential power reduction of the proposed design over traditional NoCs. When very large bandwidths are required, the power dissipated on intrachip communication can easily exceed 100 W in regular electronic NoCs. The proposed photonic NoC can potentially reduce this figure to a few watts. From the photonic NoC design and optimization viewpoint, there is still much work that can be done. The POINTS simulator can be used to further explore the vast photonic NoC design space and evaluate modification to the flow control, topology, switch design, and routing algorithms. Most importantly, real computing applications need to be mapped on the network model to generate traffic patterns that accurately represent real cases. Scientific benchmarks or real applications should be used to validate the network design and assist in exploring routing algorithms, topology, flow control, and other design decisions. Much of this is ongoing work as we plan to address many of these challenges in follow-up publications. The technology required to implement the photonic devices (PSEs and 4  4 switches) and their integration in large-scale NoCs is still immature. We have carefully reviewed the recent major progress made in both academia and industry and we expect that, within a small number of years, the enabling technologies will gradually become available to the designers of silicon-integrated circuits. Detailed study of other design issues such as process integration, design complexity, and area overhead is also important to evaluate the feasibility of this project and is an interesting area for future research. Based on our continuous interactions with researchers working on silicon photonic devices, we believe that, to have a system-level perspective on how they can be composed in a future NoC is of critical importance to their design. This paper aims at laying the groundwork for future research progress by providing a complete discussion of the fundamental issues that need to be addressed to design a photonic NoC for CMPs. ACKNOWLEDGMENTS A. Shacham and K. Bergman acknowledge the support of the US National Science Foundation (NSF) under Grant CCF-0523771 and the US Department of Defense under subcontract B-12-664. L.P. Carloni acknowledges the support of the NSF under Grant 0541278. "
2008,An 80-Tile Sub-100-W TeraFLOPS Processor in 65-nm CMOS.,"This paper describes an integrated network-on-chip architecture containing 80 tiles arranged as an 8x10 2-D array of floating-point cores and packet-switched routers, both designed to operate at 4 GHz. Each tile has two pipelined single-precision floating-point multiply accumulators (FPMAC) which feature a single-cycle accumulation loop for high throughput. The on-chip 2-D mesh network provides a bisection bandwidth of 2 Terabits/s. The 15-FO4 design employs mesochronous clocking, fine-grained clock gating, dynamic sleep transistors, and body-bias techniques. In a 65-nm eight-metal CMOS process, the 275 mm <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>  custom design contains 100 M transistors. The fully functional first silicon achieves over 1.0 TFLOPS of performance on a range of benchmarks while dissipating 97 W at 4.27 GHz and 1.07 V supply.",
2005,Energy- and performance-aware mapping for regular NoC architectures.,"In this paper, we present an algorithm which automatically maps a given set of intellectual property onto a generic regular network-on-chip (NoC) architecture and constructs a deadlock-free deterministic routing function such that the total communication energy is minimized. At the same time, the performance of the resulting communication system is guaranteed to satisfy the specified design constraints through bandwidth reservation. As the main theoretical contribution, we first formulate the problem of energy- and performance-aware mapping in a topological sense, and show how the routing flexibility can be exploited to expand the solution space and improve the solution quality. An efficient branch-and-bound algorithm is then proposed to solve this problem. Experimental results show that the proposed algorithm is very fast, and significant communication energy savings can be achieved. For instance, for a complex video/audio application, 51.7% communication energy savings have been observed, on average, compared to an ad hoc implementation.",
2007,An 80-Tile 1.28TFLOPS Network-on-Chip in 65nm CMOS.,"A 275mm <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>  network-on-chip architecture contains 80 tiles arranged as a 10 times 8 2D array of floating-point cores and packet-switched routers, operating at 4GHz. The 15-F04 design employs mesochronous clocking, fine-grained clock gating, dynamic sleep transistors, and body-bias techniques. The 65nm 100M transistor die is designed to achieve a peak performance of 1.0TFLOPS at 1V while dissipating 98W.",
2007,A 5-GHz Mesh Interconnect for a Teraflops Processor.,"A multicore processor in 65-Nm technology with 80 single-precision, floatingpoint cores delivers performance in excess of a Teraflops while consuming less than 100 W. A 2D on-die mesh interconnection network operating at 5 GHz provides the high-performance communication fabric to connect the cores. The network delivers a bisection bandwidth of 2.56 Terabits per second and a per hop fall-through latency of 1 nanosecond.",
2009,"Outstanding Research Problems in NoC Design - System, Microarchitecture, and Circuit Perspectives.","To alleviate the complex communication problems that arise as the number of on-chip components increases, network-on-chip (NoC) architectures have been recently proposed to replace global interconnects. In this paper, we first provide a general description of NoC architectures and applications. Then, we enumerate several related research problems organized under five main categories: Application characterization, communication paradigm, communication infrastructure, analysis, and solution evaluation. Motivation, problem description, proposed approaches, and open issues are discussed for each problem from system, microarchitecture, and circuit perspectives. Finally, we address the interactions among these research problems and put the NoC design process into perspective.",
2003,Energy-aware mapping for tile-based NoC architectures under performance constraints.,"In this paper, we present an algorithm which automatically maps the IPs/cores onto a generic regular Network on Chip (NoC) architecture such that the total communication energy is minimized. At the same time, the performance of the mapped system is guaranteed to satisfy the specified constraints through bandwidth reservation. As the main contribution, we first formulate the problem of energy-aware mapping, in a topological sense, and then propose an efficient branch-and-bound algorithm to solve it. Experimental results show that the proposed algorithm is very fast and robust, and significant energy savings can be achieved. For instance, for a complex video/audio SoC design, on average, 60.4% energy savings have been observed compared to an ad-hoc implementation.","Energy-Aware Mapping for Tile-based NoC Architectures Under Performance Constraints (cid:3) Jingcao Hu Radu Marculescu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA e-mail: fjingcao, radumg@ece.cmu.edu Abstract — In this paper, we present an algorithm which automatically maps the IPs/cores onto a generic regular Network on Chip (NoC) architecture such that the total communication energy is minimized. At the same time, the performance of the mapped system is guaranteed to satisfy the speci ﬁed constraints through bandwidth reservation. As the main contribution, we ﬁrst formulate the problem of energy-aware mapping, in a topological sense, and then propose an efﬁcient branch-and-bound algorithm to solve it. Experimental results show that the proposed algorithm is very fast and robust, and signi ﬁcant energy savings can be achieved. For instance, for a complex video/audio SoC design, on average, 60.4% energy savings have been observed compared to an ad-hoc implementation. I . IN TRODUCT ION With the advance of the semiconductor technology, the enormous number of transistors available on a single chip allows designers to integrate dozens of IP blocks together with large amounts of embedded memory. These IPs can be CPU or DSP cores, video stream processors, high-bandwidth I/O, etc[1]. The richness of the computational resources places tremendous demands on the communication resources as well. Additionally, the shrinking feature size in the deep-sub-micron (DSM) era is continuously pushing interconnection delay and power consumption as the dominant factors in the optimization of modern systems. Another consequence of the DSM effects is the difﬁculty in optimizing the interconnection because of the ensued worsening effects such as crosstalk, etc. To mitigate these problems, Dally and Towles [2] have recently proposed a regular tile-based architecture where communication can be efﬁciently realized using an on-chip network (Fig. 1)1 . As shown in the left part of Fig. 1, the chip is divided into regular tiles where each tile can be a general-purpose processor, a DSP, a memory subsystem, etc. A router is embedded within each tile with the objective of connecting it to its neighboring tiles. Thus, instead of routing design-speciﬁc global wires, the inter-tile communication can (cid:3)Research supported by NSF CCR-00-93104 and DARPA/Marco Gigascale Research Center (GSRC), and SRC 2001-HJ-898. 1 This implementation is slightly different from the example implementation given in [2], where a torus topology is adopted. Tile (cid:13) Network(cid:13) Logic(cid:13) (3,0)(cid:13) (3,1)(cid:13) (3,2)(cid:13) (3,3)(cid:13) (2,0)(cid:13) (2,1)(cid:13) (2,2)(cid:13) (2,3)(cid:13) (1,0)(cid:13) (1,1)(cid:13) (1,2)(cid:13) (1,3)(cid:13) (0,0)(cid:13) (0,1)(cid:13) (0,2)(cid:13) (0,3)(cid:13) Mapping (cid:13) ASIC1(cid:13) DSP1(cid:13) DSP3(cid:13) DSP2(cid:13) ASIC2(cid:13) CPU1(cid:13) Tile-based Architecture(cid:13) Communication Task Graph(cid:13) Fig. 1. Tile-based architecture and the mapping problem be achieved by routing packets via these embedded routers. Three key concepts come together to make this tile-based architecture very promising: structured network wiring, modularity and standard interfaces. More precisely, since the network wires are structured and wired beforehand, their electrical parameters can be very well controlled and optimized. In turn, these controlled electrical parameters make possible to use aggressively signaling circuits which reduce power dissipation and propagation delay signi ﬁcantly . Modularity and standard network interfaces facilitate re-usability and interoperability of the modules. Moreover, since the network platform can be designed in advance and later used for many applications, it makes sense to highly optimize this platform as its development cost can be amortized across many applications. To exploit this regular tile-based architecture, the design ﬂo w needs the following three steps: First, the application needs to be divided into a graph of concurrent tasks. Second, using a set of available IPs, the application tasks are assigned and scheduled. Finally, the designer needs to decide to which tile each selected IP should be mapped such that the metrics of interest are optimized. More precisely, given the assigned/scheduled task graph which has been generated from previous two steps, this last phase determines the topological placement of these IPs onto different tiles. For instance, referring to Fig. 1, this step determines onto which tile (e.g. (3,0), (2,1), (1,3) etc.) each IP (e.g. ASIC2, DSP3, CPU1, etc.) should be placed. The ﬁrst two steps described above are not new to the CAD community, as they have been addressed in the area of hardware/software co-design and IP-reuse [3]. However, the mapping phase (that is, the topological placement of the IPs onto the on-chip tiles) represents a new problem, especially in the context of the regular tile-based architecture, as it signiﬁcantly 233 impacts the energy and performance metrics of the system. In this paper, we address this very issue. To this end, we ﬁrst formulate the mapping problem and show the impact of different mappings on the communication energy consumption of a given system. An efﬁcient branch-and-bound algorithm is then proposed to solve this problem under tight performance constraints. Experimental results show that signiﬁcant energy savings can be achieved, while guaranteeing the speciﬁed system performance. Compared to a simulated annealing algorithm, our algorithm is orders of magnitude faster, while the energy consumption of the solution is almost the same (less than 10% difference). The paper is organized as follows: Section II brieﬂy introduces the related work. The platform of the targeted system and its associated power model are described in Section III. Sections IV and V illustrate the energy-aware mapping algorithm. Experimental results are shown in Section VI. Finally, Section VII summarizes our contribution and outlines some directions for future work. I I . R E LAT ED WORK In their paper [2], Dally et al. suggest using the on-chip interconnection networks instead of ad-hoc global wiring to structure the top-level wires on a chip and facilitate modular design. In [4], Hemani et al. present a honeycomb structure in which each processing core (resource) is located on a regular hexagonal node connected to three switches while these switches are directly linked to their next nearest neighbors. In [5], Kumar et al. describe a physical NoC architecture implemented by a direct layout of a 2D mesh of switches and resources. Although different in topology and some other aspects, all the above papers essentially advocate the advantages of using NoCs and regularity as effective means to design high performance SoCs. While these papers mostly focus on the concept of regular NoC architecture (discussing the overall advantages and challenges), to the best of our knowledge, our work is the ﬁr st to address the mapping problem for tile-based architecture and provide an efﬁcient way to solve it. I I I . P LAT FORM D E SCR I P T ION In this section, we describe the regular tile-based architecture and the power model associated to the communication network. A.TheArchitecture The chip under consideration in this paper is composed of n (cid:2) n tiles which are inter-connected by a 2D mesh network2 . Fig. 2 shows an abstract view of a tile in this architecture. As shown in Fig. 2, each tile is composed of a processing core and a router. The router embedded onto each tile One(cid:13) tile(cid:13) (cid:13)h t r o N t u p n I r (cid:13)e f f u b (cid:13)h (cid:13)t r o N t u (cid:13)p u t O Processing(cid:13) Core(cid:13) Router (cid:13) West(cid:13) Input(cid:13) buffer(cid:13) West(cid:13) Output(cid:13) Crossbar (cid:13) Switch(cid:13) buffer(cid:13) East(cid:13) Input(cid:13) East(cid:13) Output(cid:13) b(cid:13)u(cid:13)f(cid:13)f(cid:13)e(cid:13)r(cid:13) P(cid:13)r(cid:13)o(cid:13)c(cid:13).(cid:13) I(cid:13)n(cid:13)p(cid:13)u(cid:13)t(cid:13) P(cid:13)r(cid:13)o(cid:13)c(cid:13).(cid:13) O(cid:13)u(cid:13)t(cid:13)p(cid:13)u(cid:13)t(cid:13) t u (cid:13)p u t O r e (cid:13)f f u b h t u o (cid:13) S t u p n I h t u (cid:13)o S Fig. 2. The typical structure of a tile is connected to the four neighboring tiles and its local processing core via channels. Each channel consists of two onedirectional point-to-point links between two routers or a router and a local processing core. Compared to typical macro-networks, an on-chip network is by far more resource limited. To minimize the implementation cost, the on-chip network should be implemented with very little area overhead. This is especially important for those architectures composed of tiles with ﬁne-le vel granularity. Thus, instead of having huge memories (e.g. SRAM or DRAM) as buffer space for those routers/switches in the macro-network, it’s more reasonable to use registers as buffers for on-chip routers3 . For the architecture in Fig. 2, a 5 (cid:2) 5 crossbar switch is used as the switching fabric because of its nice cost/performance trade-offs for switches with small number of ports. To be able to direct the information appropriately, a tilebased architecture requires a method of routing the data packets through the network. There are quite a few routing algorithms proposed so far. In general, they can be divided into two categories: static routing and adaptive routing [6]. For the tile-based architecture, we believe that the static routing is more suitable than the adaptive routing because: 1. Compared to static routers, implementing adaptive routers requires by far more resources because of their complexity. 2. Since in adaptive routing packets may arrive out of order, huge buffering space is needed to reorder them. This, together with the protocol overhead, leads to prohibitive cost overhead, extra delay and jitter. Based on the above considerations, static XY routing is assumed for the on-chip network. In a few words, for 2D mesh networks, XY routing ﬁrst routes packets along the X-axis. Once it reaches the column wherein lies the destination tile, the packet is then routed along the Y-axis. Obviously, XY routing is a minimal path routing algorithm and is free of deadlock and livelock [6]. 2We use the 2D mesh network simply because it naturally ﬁts the tile-based architecture. However, our algorithm can be extended for other topologies. 3As we will see later, this leads to a much simpler power model compared to its macro-network peer. 234 (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) B.TheEnergyModel In [7], Ye et al. propose a new model for evaluating the power consumption of switch fabrics in network routers. To this end, the bit energy (Ebit ) metric is deﬁned as the energy consumed when one bit of data is transported through the router. Ebit can be calculated by the following equation: Ebit = ESbit + EBbit + EWbit (1) where ESbit , EBbit and EWbit represent the energy consumed by switch, buffering and interconnection wires, respectively. (Note that the authors in [7] assume the buffers are implemented in SRAM or DRAM.) Although the above power model is targeted for network routers where the entire chip is occupied by just one router, it can be adapted to the tile-based architecture with the following modiﬁcations: (cid:15) First, in [7], EBbit becomes dominant when congestion happens since accessing and refreshing the memory are very expensive in terms of power consumption. This is no longer true for on-chip networks where the buffers are implemented using regular registers. (cid:15) Second, in [7], EWbit is the energy consumed on the wires inside the switch fabric. For the on-chip network, the energy consumed on the links between tiles should also be included; in the following this is denoted by ELbit . Thus, the average energy consumed in sending one bit of data from a tile to its neighboring tile can be calculated as: Ebit = ESbit + EBbit + EWbit + ELbit (2) Since the link between each pair of nodes is typically in the order of mm, the energy consumed by buffering and internal wires is negligible4 compared to ELbit (EBbit + EWbit (cid:28) ELbit ). Thus, Eq. (2) reduces to: (3) Consequently, the average energy consumption of sending one bit of data from tile ti to tile tj can be calculated as: Ebit = ESbit + ELbit E ti ;tj bit = nhops (cid:2) ESbit + (nhops (cid:0) 1) (cid:2) ELbit (4) where nhops is the number of routers the bit passes on its way along a path. Eq. (4) gives the energy model for the regular tile-based NoC architecture. Without loss of generality, in what follows, we focus on 2D mesh network. Note that, for the 2D mesh network with XY routing, Eq. (4) shows that the average energy consumption of sending one bit of data from tile ti to tile tj is determined by the Manhattan distance between these two tiles. IV. TH E PROBL EM O F EN ERGY-AWARE MA P P ING A.ProblemFormulation Simply stated, our objective is to ﬁgure out, after the designer has selected a set of IPs and assigned/scheduled the 4We implemented a 4 (cid:2) 4 crossbar switch and then evaluated its power consumption with Synopsys design compiler for a 0.18(cid:22)m technology. The results show that EBbit = 0:075pJ , which is indeed negligible compared to ELbit (typically in the order of pJ ). tasks onto these IPs, how to map these IPs onto different tiles such that the total communication energy consumption is minimized, while guaranteeing the performance of the system. To formulate this problem in a more formal way, we need to ﬁrst introduce the following two new concepts: Deﬁnition 1 An Application Characterization Graph (APCG) G = G(C; A) is a directed graph, where each vertex ci represents one selected IP/core, and each directed arc ai;j represents the communication from ci to cj . The following quantities are associated with each ai;j as arc properties: (cid:15) v(ai;j ): arc volume from vertex ci to cj , which stands for the communication volume (bits) from ci to cj . (cid:15) b(ai;j ): arc bandwidth requirement from vertex ci to cj , which stands for the minimum bandwidth (bits/sec.) that should be allocated by the communication network. Deﬁnition 2 An Architecture Characterization Graph (ARCG) G 0 = G(T ; P ) is a directed graph, where each vertex ti represents one tile in the architecture, and each directed arc pi;j represents the routing path from ti to tj 5 . The following quantities are associated with each pi;j as arc properties: (cid:15) e(pi;j ): arc cost from vertex ti to tj , which represents the average energy consumption (joule) of sending one bit of data from tile ti to tj , i. e., E . (cid:15) L(pi;j ): the set of links that make up the path pi;j . ti ;tj bit Using the above graph representations, the problem of minimizing the communication energy consumption under performance constraints can be formulated as: Given an APCG and an ARCG that satisfy size(AP CG) (cid:20) size(ARCG) (5) ﬁnd a mapping function map() from APCG to ARCG which minimizes: minfEnergy = X8ai;j such that: v(ai;j ) (cid:2) e(pmap(ci );map(cj ) )g 8ci 2 C; map(ci ) 2 T 8ci 6= cj 2 C; map(ci ) 6= map(cj ) 8 link lk ; B (lk ) (cid:21) X8ai;j b(ai;j ) (cid:2) f (lk ; pmap(ci );map(cj ) ) where B (lk ) is the bandwidth of link lk , and: (6) (7) (8) (9) f (lk ; pm;n ) = (cid:26) 0 1 : : lk 62 L(pm;n ) lk 2 L(pm;n ) Conditions (7) and (8) mean that each IP should be mapped to exactly one tile and no tile can host more than one IP. Eq. (9) guarantees that the load of any link will not exceed its bandwidth. 5 For 2D mesh network with static routing, this suggests a complete connected graph with exactly one arc from each vertex to any other vertex. 235 B.Signiﬁcance of theProblem To prove that the mapping heavily affects the communication energy consumption, we carried out the following experiment. A series of task graphs are generated using TGFF [8]. Then the output graph is randomly assigned to a given number of IPs, with the computational times and communication volumes randomly generated according to the speci ﬁed distribution. Our tool is then used to pre-process and annotate these task graphs and build the Communication Task Graphs (CTG), which characterizes the partitioning, task assignment, scheduling, communication patterns, task execution time, of the application. Also, the bandwidth requirements between any communicating IP pairs are calculated. The number of IPs used in the experiment ranges from 3 (cid:2) 3 to 13 (cid:2) 13. For each benchmark, we randomly generate 3000 mapping con ﬁgurations and the corresponding energy consumption values are calculated. In parallel, an optimizer using simulated annealing (SA) was also developed with the goal of ﬁnding a legal mapping which consumes the least amount of communication energy. The resulting energy ratios are plotted in Fig. 3. 4.5 4 o i t Random_min/SA_sol Random_med/SA_sol a r 3.5 n o i t p m 3 u s n o c 2.5 2 y g r e n E 1.5 1 0 50 100 Number of tiles 150 200 Fig. 3. The impact of mapping on energy consumption The dashed line in Fig. 3 shows the energy consumption ratio of the best solution among the 3000 random mappings (Random min) to the solution found by the simulated annealing (SA sol). The solid line shows the ratio of the median solution among the 3000 random mappings (Random med) to SA sol. As we can see, although the simulated annealing optimizer does not necessarily ﬁnd the optimal solution, it still saves around 50% energy compared to the median solution for the system with 3 (cid:2) 3 tiles. Moreover, the savings increase as the system size scales up. For systems with 13 (cid:2) 13 tiles, the savings can be as high as 75%. Another observation is that the best solution among the 3000 random mappings is far from satisfactory, even with a system as small as 3 (cid:2) 3 tiles. Unfortunately, the mapping problem is an instance of constrained quadratic assignment problem which is known to be NP-hard [9]. The search space of the problem increases factorially with the system size. Even for a system with 4 (cid:2) 4 tiles, there can be 16! mappings which are already impossible to enumerate, not to mention systems with 10(cid:2) 10 tiles that are anticipated in ﬁ ve years or less [5]. In the following section, we propose an efﬁcient branch-and-bound algorithm which can be used to ﬁnd nearly optimal solutions in reasonable run times. V. TH E A LGOR I THM O F EN ERGY-AWARE MA P P ING A.TheDataStructure Our approach is based on a branch-and-bound algorithm. The algorithm is used to efﬁciently walk through the search tree which represents the whole searching space. Fig. 4 shows an example of the searching tree for mapping an application with 4 IPs onto a 2 (cid:2) 2 tile architecture. To keep the ﬁgure simple, we do not show all the nodes. Root Node xxxx 0xxx 1xxx 2xxx 3xxx Internal Node 01xx 02xx 03xx 20xx 21xx 23xx Leaf Node 031x 032x 0312 0321 230x 231x 2301 2310 Fig. 4. An example search tree In Fig. 4, each node belongs to one of the three categories: root node, internal node, and leaf node. The root node corresponds to the state where no IP has been mapped. Each internal node represents a partial mapping which is tagged by a label. Each number in the label represents which tile the corresponding IP is mapped to. For example, the node with the label “ 23xx” represents a partial mapping where I P0 and I P1 are mapped to T ile2 and T ile3 respectively, while I P2 and I P3 are still unmapped. Each leaf node represents a complete mapping of the IPs to the tiles. To explain how our algorithm works, the following terms need to be deﬁned: Deﬁnition 3 The cost of a node is the energy consumed by the communication among those IPs that have already been mapped. For instance, the cost of the node labeled “ 23xx” can be calculated as v(a0;1 ) (cid:2) e(p2;3 ) + v(a1;0 ) (cid:2) e(p3;2 ). We can infer from deﬁnition 3 that any child node’s cost is no less than its parent node’s cost. This property will later be used in the algorithm to trim away unqualiﬁed sub-trees. Deﬁnition 4 Let M be the set of vertices in the APCG that have already been mapped. A node is called a legal node if and only if, for any link lk , it satisﬁes the following condition: B (lk ) (cid:21) X8ai;j ;ci cj 2M b(ai;j ) (cid:2) f (lk ; pmap(ci );map(cj ) ) (10) Eq. (10) guarantees that all the bandwidth requirements between the currently mapped IPs are satisﬁed. Also, if a node is illegal, then all of its descendant nodes are illegal. Deﬁnition 5 The Upper Bound Cost (UBC) of a node is deﬁned as a value that is no less than the minimum cost of its legal, descendant leaf nodes. 236     Deﬁnition 6 The Lower Bound Cost (LBC) of a node is deﬁned to be the lowest cost that its descendant leaf nodes can possibly achieve. Differently stated, this means that if a node has the LBC equal to x, then each of its descendant leaf nodes has at least a cost of x. B.TheBranch-and-BoundAlgorithm Given the above deﬁnitions, ﬁnding the optimal mapping is equivalent to ﬁnding the legal leaf node which has the least cost6 . To achieve this, our algorithm searches the optimal solution by alternating the following two steps: Branch: In this step, an unexpanded node is selected from the tree, the next unmapped IP is enumeratively assigned to the set of remaining unoccupied tiles and then the corresponding new child nodes are generated. Bound: Each of the newly generated child nodes are inspected to see if it is possible to generate the best leaf nodes later. A node can be trimmed away without further expansion if either its cost or its LBC is higher than the lowest UBC that has been found during the searching (since it is guaranteed that other nodes will eventually lead to a better solution). Obviously, the calculation of the UBC and LBC signi ﬁcantly impacts the speed of the algorithm. Primarily, we want to have tight UBC and LBC for each node so that more nonpromising nodes can be detected and trimmed away early on during the search. Unfortunately, calculating a tight UBC or LBC usually demands more computational time. Next, we describe our method for computing UBC and LBC, which offers a satisfactory trade-off between the average time for processing one node and the number of nodes that need to be processed. (cid:15) UBC calculation By deﬁnition 5, the cost of any legal descendant leaf node can be used as the UBC of that node. Since we want to select the legal descendant leaf node with the smallest cost, we choose the descendant leaf node using a greedy method for mapping the remaining unmapped IPs to the unoccupied tiles. For each step in the greedy mapping procedure, the next unmapped IP ck with the highest communication demand is selected and its ideal topological location (x; y) on the chip is calculated as: i x = P8ci2M (v(ak;i ) + v(ai;k )) (cid:2) cx P8ci2M (v(ak;i ) + v(ai;k )) y = P8ci2M (v(ak;i ) + v(ai;k )) (cid:2) cy P8ci2M (v(ak;i ) + v(ai;k )) (11) (12) i where cx i and cy i represent the row id and column id of the tile that ci is mapped onto, respectively, and M is the set of mapped IPs which is updated at each step. ck is then mapped to an unoccupied tile whose topological location has the smallest Manhattan distance to (x; y). 6 The performance constraints are guaranteed to be satisﬁed by the legality of the node. This step is repeated until all IPs have been mapped. This leads to a complete mapping and thus identi ﬁes a single descendant leaf node. If this leaf node is illegal, then the UBC of the node under inspection is set to be in ﬁnitely large; otherwise, it is set to be the cost of that descendant leaf node. (cid:15) LBC calculation The LBC cost of a node n can be decomposed into three components, as shown in Eq. (13): LBC = Cm;m + Cu;u + Cm;u (13) Cm;m is the cost of the intercommunication among mapped IPs. Since the location of these IPs is known, Cm;m can be calculated exactly. Cu;u is the cost of the intercommunication among unmapped IPs. Eq. (14) is used to calculate Cu;u , where (cid:22)M stands for the set of unmapped IPs and (cid:22)O stands for the set of tiles that have not been occupied yet. Cu;u = 1 2 (cid:2) X8ci2 (cid:22)M X8cj 2 (cid:22)M v(ai;j ) (cid:2) min 8tm tn2 (cid:22)O e(pm;n ) (14) The last item Cm;u stands for the cost of the intercommunication between the mapped IPs and the unmapped IPs. Let M, (cid:22)M and (cid:22)O be the sets of mapped IPs, unmapped IPs and unoccupied tiles, respectively. Cm;u can be derived by: Cm;u = X8ci2M X8cj 2 (cid:22)M v(ai;j ) (cid:2) min 8tk 2 (cid:22)O e(pmap(ci );k ) + X8ci2 (cid:22)M X8cj 2M v(ai;j ) (cid:2) min 8tk 2 (cid:22)O e(pk;map(cj ) ) (15) C.Speed-upTechniques In order to speed up the searching process, it is critical to trim away as many non-promising nodes as possible, as early as possible during the search process. We propose the following techniques for this purpose. (cid:15) IP ordering: We can sort the IPs according to their communication demand7 so that the IPs with higher demand will be mapped earlier. Since the positions of the IPs with higher demand generally have a larger impact on the overall communication energy consumption than those of IPs with lower demand, ﬁxing their positions earlier helps exposing those nonpromising internal nodes at earlier times in the searching; this reduces the number of nodes to be expanded. As most applications have non-uniform trafﬁc patterns, this heuristic is quite useful in practice. (cid:15) Priority queue (PQ): A priority queue is used to sort those nodes that are waiting to be branched based on their cost. The lower the cost of the node, the higher the priority the node has for branching. Intuitively, expanding a node with lower cost will more likely decrease the minimum UBC so that more non-promising nodes may be detected. (cid:15) Symmetry Exploitation: To further speed up our algorithm, the symmetry property of the architecture is exploited. Considering the system with 16 tiles and nodes of depth 1 in the search tree as an example, we only need to investigate those nodes 7 For IP ci , this is calculated as P8j 6=i fv(ai;j ) + v(aj;i )g 237 which map the ﬁrst IP to the tiles denoted by (0; 0), (0; 1) and (1; 1) (see Fig. 1), as the other nodes are just mirrors of these nodes. D.ThePseudocode Fig. 5 gives the pseudo code of our algorithm which also shows how the above speed-up techniques are employed. p u d e e p S 100 50 0 o i t a r y g r e n E 1.5 1 0.5 0 1 2 3 4 5 6 7 8 9 Benchmark 1 2 3 4 5 6 7 8 9 Benchmark Sort the IPs by communication demand root node = new node(NULL) min UBC = +1, best mapping cost = +1 PQ.Insert(root node) while(!PQ.Empty()) f cur node = PQ.Next() for each unoccupied tile ti f generate child node nnew if(nnew ’s mirror node exists in the PQ) continue if(nnew .LBC>min UBC) continue if(nnew .isLeafNode) f if(nnew .cost < best mapping cost) f best mapping cost = nnew .cost best mapping = nnew gg else f if(nnew .UBC<min UBC) min UBC = nnew .UBC PQ.insert(nnew ) gg g Fig. 6. Comparison between SA and our algorithm for category III benchmarks Fig. 6 shows the comparison between our algorithm and simulated annealing for the benchmarks in category III. The left ﬁgure gives the speed up ratios of our algorithm over the simulated annealing algorithm. The right ﬁgure shows the energy ratios of the solutions provided by our algorithm to that generated using simulated annealing. Note that although we have 10 benchmarks for category III, we only show the results for 9 benchmarks here since neither of them can ﬁnd a mapping solution which meets the speciﬁed performance constraints for one of the benchmarks. As it can be seen, our algorithm runs much faster (72 times on average) over SA with very competitive solutions (the difference of the communication energy consumption between the solutions generated by these two algorithms are within 6%, on average). Fig. 5. The pseudo code of the algorithm Energy ratio vs. system size 1 0.5 ) A S / g a l r u o ( o i t a r y g r e n E 238 Obviously, the code shown in Fig. 5 will always ﬁnd the optimal solution. However, as the system size scales up, the run time of this algorithm will also increase drastically. Thus, the following heuristic needs to be used to trade-off the solution quality with run time. The length of the PQ is monitored during the process. When it reaches a threshold value, strict criteria are applied to select the child nodes for insertion into the queue. Suppose we are currently expanding node n. If n is the node in the PQ which has the minimal UBC, then all of its child nodes will be evaluated by the code in Fig. 5 for insertion into the PQ. Otherwise, only the child with the lowest cost among its siblings and the child generated by the greedy mapping will be evaluated for insertion. V I . EX P ER IM EN TA L R E SU LT S A.EvaluationExperiments We ﬁrst compare the run-time and quality of the solution generated by our algorithm to a simulated annealing optimizer (SA)8 . Four categories of benchmarks are generated by the technique described in subsection IV.B. Categories I, II, III and IV contain 10 applications with 9, 16, 25 and 36 IPs, respectively. These need to be mapped onto architectures with the same number of tiles. 8 To make the comparison fair, SA was optimized by carefully selecting parameters such as number of moves per temperature, cooling schedule, etc. Speedup ratio vs. system size 100 50 ) A S / g a l r u o ( o i t a r p u d e e p S 40 0 0 20 0 0 20 40 System size(number of tiles) System size(number of tiles) Fig. 7. Comparison between SA and our algorithm with system size scales up Fig. 7 shows how our algorithm performs compared to SA as the system size scales up. For benchmark applications using 36 tiles, our algorithm runs 127 times faster than SA, on average. Meanwhile, the solutions produced by our algorithm remain very competitive compared to those generated by SA. On average, the energy consumption of the solution generated by our algorithm is only 3%, 6% and 10% for category II, III and IV, respectively. For category I, our algorithm can even ﬁnd better solutions than SA because it can in general walk through the whole search tree due to the small size of the problem. B.AVideo/AudioApplication To evaluate the potential of our algorithm for real applications, we applied this algorithm to a generic MultiMedia System (MMS). MMS is an integrated video/audio system which includes an h263 video encoder, an h263 video decoder, an mp3 audio encoder and an mp3 audio decoder. We partitioned the application into 40 distinct tasks and then these tasks were             assigned and scheduled onto 25 selected IPs [10]. These IPs range from DSPs, generic processors, embedded DRAMs to customized ASICs. Real video and audio clips are then used as inputs to derive the communication patterns among these IPs. Fig. 8 shows the derived CTG of this system based on the simulation result. ME(cid:13) ASIC1(cid:13) Q(cid:13) DSP2(cid:13) Filter (cid:13) DSP6(cid:13) FFT(cid:13) DSP5(cid:13) FP(cid:13) DSP4(cid:13) FS0(cid:13) MEM1(cid:13) FP(cid:13) DSP3(cid:13) VLE(cid:13) ASIC2(cid:13) DCT(cid:13) DSP1(cid:13) MC(cid:13) CPU1(cid:13) IDCT(cid:13) 1(cid:13)6(cid:13)6(cid:13)9(cid:13)1(cid:13) IQ(cid:13) ADD(cid:13) FS1(cid:13) FS2(cid:13) Iterative Encoding1(cid:13) CPU2(cid:13) Iterative Encoding2(cid:13) Bit reservoir1(cid:13) ASIC3(cid:13) 2(cid:13)5(cid:13) Bit reservoir 2(cid:13) PsychoAccoustic Model(cid:13) 2(cid:13)6(cid:13)9(cid:13)2(cid:13)4(cid:13) MDCT(cid:13) 3(cid:13)8(cid:13)0(cid:13)1(cid:13)6(cid:13) 3(cid:13) 6(cid:13)8(cid:13)7(cid:13) 1(cid:13)1(cid:13) 1 9 7 (cid:13) (cid:13) (cid:13) 3(cid:13)3(cid:13)8(cid:13)4(cid:13)8(cid:13) 3(cid:13)3(cid:13)8(cid:13)4(cid:13)8(cid:13) 3(cid:13)3(cid:13)8(cid:13)4(cid:13)8(cid:13) 1(cid:13)6(cid:13)6(cid:13)9(cid:13)1(cid:13) 7(cid:13)5(cid:13)2(cid:13)0(cid:13)5(cid:13) 3 (cid:13) 8 (cid:13) 0 (cid:13) 1 (cid:13) 6 (cid:13) 7(cid:13)0(cid:13)6(cid:13)1(cid:13)7 0 6 1 (cid:13) (cid:13) (cid:13) (cid:13) 2(cid:13)8(cid:13)2(cid:13)4(cid:13)8(cid:13) 8(cid:13) 0(cid:13) Synchronziation(cid:13) ASIC2(cid:13) Multiplexing(cid:13) IDCT(cid:13) DSP6(cid:13) IQ(cid:13) DSP5(cid:13) VLD(cid:13) DSP4(cid:13) MC(cid:13) CPU2(cid:13) ADD(cid:13) FS4(cid:13) MEM2(cid:13) FS5(cid:13) IMDCT(cid:13) DSP6(cid:13) Bit reservoir 1(cid:13) DSP5(cid:13) Huffman(cid:13) Decoding 1 (cid:13) 6(cid:13)4(cid:13)1(cid:13) DSP4(cid:13) 7(cid:13)0(cid:13)6(cid:13)5(cid:13) Buffering(cid:13) Mem4(cid:13) Huffman(cid:13) Decoding 2(cid:13) Bit reservoir 2(cid:13) SUM(cid:13) 3 (cid:13) 6 (cid:13) 7 (cid:13) 2 (cid:13) 3(cid:13)6(cid:13)7(cid:13)2(cid:13) 1 (cid:13) 9 (cid:13) 7 (cid:13) 3(cid:13)6(cid:13)7(cid:13)2(cid:13) 8 5 5 7 4 3(cid:13)8(cid:13)0(cid:13)1(cid:13)6(cid:13) 3(cid:13) 8(cid:13) 0(cid:13) 1(cid:13) 6(cid:13) 1(cid:13)4(cid:13)4(cid:13) 8(cid:13) 0(cid:13) 2(cid:13)5(cid:13) 2(cid:13)8(cid:13)2(cid:13)6(cid:13)5(cid:13) Demulplexi(cid:13) ng(cid:13) ASIC2(cid:13) 7(cid:13)6(cid:13) 4(cid:13) Synchronziation(cid:13) ASIC5(cid:13) 7(cid:13)0(cid:13)6(cid:13)5(cid:13) H263 (cid:13) Encoder(cid:13) MP3 (cid:13) Encoder(cid:13) Mem2(cid:13) Buffering(cid:13) 6(cid:13)4(cid:13)0(cid:13) 6 (cid:13) (cid:13) (cid:13) 4 0 H263 (cid:13) Decoder(cid:13) MP3 (cid:13) Decoder(cid:13) Fig. 8. Communication Task Graph for MMS Applying our algorithm to MMS, the solution is found in less than 7 seconds CPU time. An ad-hoc implementation9 was also developed to serve as reference. The results are shown in Table I. TABLE I POW ER COM PAR I SON B E TW E EN AD -HOC SO LU T ION AND OUR SO LU T ION Movie clips Ad-hoc(mW ) Our alg(mW ) box/hand 374.5 148.3 akiyo/cup 440.5 187.3 man/phone 327.5 120 Savings 60.4% 57.5% 63.4% In Table I, each row represents the power consumption of using two movie clips as simulation inputs, with one clip for the video/audio encoder and the other for the video/audio decoder. Compared to the ad-hoc solution, we observe around 60.4% energy savings, on average, which demonstrates the effectiveness of our algorithm. Simulated annealing is also applied to MMS, and the power consumption of the solution and the run time are shown in Table II together with the results of our algorithm for comparison. TABLE II COM PAR I SON B E TW E EN SA AND OUR A LGOR I THM U S ING MMS SA 181.67 148.8 Our alg. 6.52 148.3 Ratio 27.864 0.997 Run Time (sec) Power (mW ) As shown in Table II, for this complex application, our algorithm generates a better solution with signiﬁcantly less run time compared to the simulated annealing. We should point 9We randomly generated 3000 solutions, from which the one that consumes median energy consumption was chosen as the ad-hoc implementation. out that although for this system which has only 5 (cid:2) 5 tiles, the solving time of SA is affordable, the run time of SA increases dramatically as the system size scales up. For systems with 7 (cid:2) 7 tiles, the average run time of SA increases to 2.2 hours, on average. For systems with 10(cid:2) 10 tiles (which will be available in the near future), our algorithm needs just a few minutes to complete while the run time of SA becomes prohibitive (in our experiments on systems with 10 (cid:2) 10 tiles, the SA did not ﬁnish in 40 hours of CPU time). V I I . CONCLU S ION AND FU TURE WORK In this paper, we addressed the mapping problem for regular tile-based architectures. An efﬁcient algorithm which automatically maps the IPs to the tiles so that the total communication energy consumption is minimized under speciﬁed performance constraints was proposed. By using simulated annealing as reference, we have shown that we can generate high quality solutions with signi ﬁcantly less computational time. Although in this paper we focus on the tile-based architecture interconnected by 2D mesh network with XY routing, our algorithm can be adapted to other regular architectures with different network topologies and different static routing schemes. We plan to advance this research in several directions. Due to the short run time of our algorithm, one possible extension is to combine the IP selection and the task partitioning/scheduling into our framework such that the computation and communication energy consumption can be optimized at the same time. ACKNOW L EDGM EN T S The authors would like to thank Dr. John Darringer and Dr. Youngsoo Shin of IBM T.J. Watson Research Center for insightful comments on this work. "
2009,GARNET - A detailed on-chip network model inside a full-system simulator.,"Until very recently, microprocessor designs were computation-centric. On-chip communication was frequently ignored. This was because of fast, single-cycle on-chip communication. The interconnect power was also insignificant compared to the transistor power. With uniprocessor designs providing diminishing returns and the advent of chip multiprocessors (CMPs) in mainstream systems, the on-chip network that connects different processing cores has become a critical part of the design. Transistor miniaturization has led to high global wire delay, and interconnect power comparable to transistor power. CMP design proposals can no longer ignore the interaction between the memory hierarchy and the interconnection network that connects various elements. This necessitates a detailed and accurate interconnection network model within a full-system evaluation framework. Ignoring the interconnect details might lead to inaccurate results when simulating a CMP architecture. It also becomes important to analyze the impact of interconnection network optimization techniques on full system behavior. In this light, we developed a detailed cycle-accurate interconnection network model (GARNET), inside the GEMS full-system simulation framework. GARNET models a classic five-stage pipelined router with virtual channel (VC) flow control. Microarchitectural details, such as flit-level input buffers, routing logic, allocators and the crossbar switch, are modeled. GARNET, along with GEMS, provides a detailed and accurate memory system timing model. To demonstrate the importance and potential impact of GARNET, we evaluate a shared and private L2 CMP with a realistic state-of-the-art interconnection network against the original GEMS simple network. The objective of the evaluation was to figure out which configuration is better for a particular workload. We show that not modeling the interconnect in detail might lead to an incorrect outcome. We also evaluate Express Virtual Channels (EVCs), an on-chip network flow control proposal, in a full-system fashion. We show that in improving on-chip network latency-throughput, EVCs do lead to better overall system runtime, however, the impact varies widely across applications.",
2004,QNoC - QoS architecture and design process for network on chip.,"We define Quality of Service (QoS) and cost model for communications in Systems on Chip (SoC), and derive related Network on Chip (NoC) architecture and design process. SoC inter-module communication traffic is classified into four classes of service: signaling (for inter-module control signals); real-time (representing delay-constrained bit streams); RD/WR (modeling short data access) and block-transfer (handling large data bursts). Communication traffic of the target SoC is analyzed (by means of analytic calculations and simulations), and QoS requirements (delay and throughput) for each service class are derived. A customized Quality-of-Service NoC (QNoC) architecture is derived by modifying a generic network architecture. The customization process minimizes the network cost (in area and power) while maintaining the required QoS.The generic network is based on a two-dimensional planar mesh and fixed shortest path (X-Y based) multiclass wormhole routing. Once communication requirements of the target SoC are identified, the network is customized as follows: The SoC modules are placed so as to minimize spatial traffic density, unnecessary mesh links and switching nodes are removed, and bandwidth is allocated to the remaining links and switches according to their relative load so that link utilization is balanced. The result is a low cost customized QNoC for the target SoC which guarantees that QoS requirements are met.",
2004,HERMES - an infrastructure for low area overhead packet-switching networks on chip.,"The increasing complexity of integrated circuits drives the research of new on-chip interconnection architectures. A network on chip draws on concepts inherited from distributed systems and computer networks subject areas to interconnect IP cores in a structured and scalable way. The main goal pursued is to achieve superior bandwidth when compared to conventional on-chip bus architectures. This paper reviews the state of the art in networks on chip. Then, it describes an infrastructure called Hermes, targeted to implement packet-switching mesh and related interconnection architectures and topologies. The basic element of Hermes is a switch with five bi-directional ports, connecting to four other switches and to a local IP core. The switch employs an XY routing algorithm, and uses input queuing. The main design objective was to develop a small size switch, enabling its immediate practical use. The paper also presents the design validation of the Hermes switch and of a network on chip based on it. A Hermes NoC case study has been successfully prototyped in hardware as described in the paper, demonstrating the functionality of the approach. Quantitative data for the Hermes infrastructure is advanced.",
2006,Multiprocessor Systems-on-Chips.,"Moore’s Law has reached the point at which we can build single-chips with multiple processors and significant amounts of memory. Multiprocessor systems-on-chips (MPSoCs) have opened up new application areas, such as low-power and real-time embedded systems. This talk will review the architectures of multiprocessor systems-on-chips and the design methodologies used to create them. MPSoCs make use of advanced processors, memory systems, and on-chip networks, often delivered as intellectual property modules. The design methodologies required to design these complex systems build on earlier VLSI techniques but must address many new problems as well.",
2007,Research Challenges for On-Chip Interconnection Networks.,"On-chip interconnection networks are rapidly becoming a key enabling technology for commodity multicore processors and SoCs common in consumer embedded systems, the National Science Foundation initiated a workshop that addressed upcoming research issues in OCIN technology, design, and implementation and set a direction for researchers in the field.",
2013,A detailed and flexible cycle-accurate Network-on-Chip simulator.,"Network-on-Chips (NoCs) are becoming integral parts of modern microprocessors as the number of cores and modules integrated on a single chip continues to increase. Research and development of future NoC technology relies on accurate modeling and simulations to evaluate the performance impact and analyze the cost of novel NoC architectures. In this work, we present BookSim, a cycle-accurate simulator for NoCs. The simulator is designed for simulation flexibility and accurate modeling of network components. It features a modular design and offers a large set of configurable network parameters in terms of topology, routing algorithm, flow control, and router microarchitecture, including buffer management and allocation schemes. BookSim furthermore emphasizes detailed implementations of network components that accurately model the behavior of actual hardware. We have validated the accuracy of the simulator against RTL implementations of NoC routers.",
2007,3-D Topologies for Networks-on-Chip.,"Several interesting topologies emerge by incorporating the third dimension in the design of networks-on-chip (NoC). An analytic model for the zero-load latency of each network that considers the effect of the topology on the performance of a 3-D NoC is developed. A tradeoff between the number of nodes utilized in the third dimension of the network, which reduces the average number of hops traversed by a packet, and the number of physical planes used to integrate the processing elements (PE) of the network, which decreases the wire delay of the communication channel, is evaluated. A performance improvement of up to 33% is demonstrated for 3-D NoC as compared to a traditional 2-D NoC topology for a network size of N= 128 nodes.",
2009,Networks-on-Chip in a Three-Dimensional Environment - A Performance Evaluation.,"The Network-on-Chip (NoC) paradigm has emerged as a revolutionary methodology for integrating a very high number of intellectual property (IP) blocks in a single die. The achievable performance benefit arising out of adopting NoCs is constrained by the performance limitation imposed by the metal wire, which is the physical realization of communication channels. With technology scaling, only depending on the material innovation will extend the lifetime of conventional interconnect systems a few technology generations. According to International Technology Roadmap for Semiconductors (ITRS) for the longer term, new interconnect paradigms are in need. The conventional two dimensional (2D) integrated circuit (IC) has limited floor-planning choices, and consequently it limits the performance enhancements arising out of NoC architectures. Three dimensional (3D) ICs are capable of achieving better performance, functionality, and packaging density compared to more traditional planar ICs. On the other hand, NoC is an enabling solution for integrating large numbers of embedded cores in a single die. 3D NoC architectures combine the benefits of these two new domains to offer an unprecedented performance gain. In this paper we evaluate the performance of 3D NoC architectures and demonstrate their superior functionality in terms of throughput, latency, energy dissipation and wiring area overhead compared to traditional 2D implementations.","32 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 Networks-on-Chip in a Three-Dimensional Environment: A Performance Evaluation Brett Stan ley Feero, Member, IEEE, and Partha Prat im Pande, Member, IEEE Abstract—The Network-on-Chip (NoC) paradigm has emerged as a revolutionary methodology for integrating a very high number of intellectual property (IP) blocks in a single die. The achievable performance benefit arising out of adopting NoCs is constrained by the performance limitation imposed by the metal wire, which is the physical realization of communication channels. With technology scaling, only depending on the material innovation will extend the lifetime of conventional interconnect systems a few technology generations. According to the International Technology Roadmap for Semiconductors (ITRS) for the longer term, new interconnect paradigms are in need. The conventional 2D integrated circuit (IC) has limited floorplanning choices, and consequently, it limits the performance enhancements arising out of NoC architectures. Three-dimensional ICs are capable of achieving better performance, functionality, and packaging density compared to more traditional planar ICs. On the other hand, NoC is an enabling solution for integrating large numbers of embedded cores in a single die. Three-dimensional NoC architectures combine the benefits of these two new domains to offer an unprecedented performance gain. In this paper, we evaluate the performance of 3D NoC architectures and demonstrate their superior functionality in terms of throughput, latency, energy dissipation, and wiring area overhead compared to traditional 2D implementations. Index Terms—Network-on-chip, 3D integrated circuits, throughput, latency, energy, area, wormhole routing. Ç 1 INTRODUCTION W ITH shrinking geometries, global interconnects are becoming the principal performance bottleneck for high-performance Systems-on-Chip (SoCs) [1], [2], [3]. These long interconnects are quickly becoming a performance impediment in terms of communication latency and power [4]. The Network-on-Chip (NoC) model is emerging as a revolutionary methodology in solving the performance limitations arising out of long interconnects, outperforming more mainstream bus architectures [5], [6]. In addition to providing a solution for the global wire delay problem, the NoC paradigm also eases integration of high numbers of intellectual property (IP) cores in a single SoC. However, restricted floorplanning choices of the 2D integrated circuits (ICs) limit the performance enhancements arising out of NoC architectures. As shown in Fig. 1, 3D ICs, which contain multiple layers of active devices, have the potential for enhancing system performance [7], [8], [9], [10]. According to [7], 3D ICs allow for performance enhancements even in the absence of scaling. This is the result of the reduction in interconnect length. Besides this clear benefit, package density is increased significantly, power is reduced from shorter wires, and circuitry is more immune to noise [7]. The performance improvement arising from the architectural advantages of NoCs will be significantly enhanced if 3D ICs are adopted as the basic fabrication methodology. The amalgamation of two emerging paradigms, NoC and 3D IC, allows for the creation of new structures that enable . B.S. Feero is with ARM Ltd., 110 Fulbourn Road, Cambridge CB2 0NU, UK. E-mail: brett.feero@arm.com. . P.P. Pande is with the School of Electrical Engineering and Computer Science, Washington State University, PO Box 642752, Pullman, WA 99164-2752. E-mail: pande@eecs.wsu.edu. Manuscript received 26 June 2007; revised 21 Feb. 2008; accepted 20 May 2008; published online 6 Aug. 2008. Recommended for acceptance by F. Lombardi. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TC-2007-06-0260. significant performance enhancements over more traditional solutions. With freedom in the third dimension, architectures that were impossible or prohibitive due to wiring constraints in planar ICs are now possible, and many 3D implementations can outperform their 2D counterparts. In this paper, we characterize the performance of multiple 3D NoC architectures in the presence of realistic traffic patterns through cycle-accurate simulation and establish the performance benchmark and related design trade-offs. This paper is organized as follows: Section 2 covers previous research and developments pertinent to this study. Section 3 is an introduction to the different 3D NoC architectures evaluated in this paper. Section 4 reviews the performance metrics used to evaluate the network architectures. Section 5 details the experimental analysis, and finally, Section 6 concludes this paper. 2 RELATED WORK Current SoCs are implemented predominantly following 2D architectures. However, the emergence of 3D ICs will present a fundamental change. Topol et al. [7] describe, in detail, the challenges of manufacturing in a 3D IC process. It shows that 3D ICs are capable of improvements in power, noise, logical span, density, performance, and functionality. One major advantage of the 3D IC paradigm is that it allows for the integration of “dissimilar technologies,” e.g., memory, analog, MEMS, and so forth, in a single die. This paper describes the benefits and drawbacks of different fabrication methods including face-to-face bonding and face-to-back bonding. With an SOI face-to-back process, the via pitch is minimized, at 0.4 m with a separation of 2 m between layers of SOI devices [7]. Jacob et al. [11] propose using 3D ICs to improve the performance of microprocessors by forming a processormemory stack. They show that the integration of processor 0018-9340/09/$25.00 ß 2009 IEEE Published by the IEEE Computer Society FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 33 concerns by applying real traffic patterns in a cycle-accurate simulation and by measuring performance through established metrics for 3D NoC structures. 3 3D NOC ARCHITECTURES Enabling design in the vertical dimension permits a large degree of freedom in choosing an on-chip network topology. Due to wire-length constraints and layout complications, the more conventional 2D ICs have placed limitations on the types of network structures that are possible. With the advent of 3D ICs, a wide range of on-chip network structures that were not explored earlier are being considered [12], [14]. This paper investigates five different topologies in 3D space and compares them with three wellknown NoC architectures from 2D implementations. We consider a SoC with a 400-mm2 floorplan and 64 functional IP blocks. We selected this system size to reflect the state of the art of emerging SoCs. At ISSCC 2007, the design of an 80-core processor arranged in an 8  10 regular grid built on fundamental NoC concepts was demonstrated [15]. Therefore, we believe that the system size assumed in this 3D SoC are mapped onto four 10 mm  10 mm layers, work is representative of the current trends. IP blocks for in order to occupy the same total area as a single-layer, 20 mm  20 mm layout. 3.1 Mesh-Based Networks One of the well-known 2D NoC architectures is the 2D Mesh, as shown in Fig. 2a. This architecture consists of an m  n mesh of switches interconnecting IP blocks placed along with them. It is known for its regular structure and short interswitch wires. From this structure, a variety of 3D topologies can be derived. The straightforward extension of this popular planar structure is the 3D Mesh. Fig. 2b shows an example of 3D Mesh-based NoC. It employs seven-port Fig. 1. Three-dimensional IC from an SOI process. and memory in a stack enables a large increase in performance. In particular, 3D integration enables the use of very wide buses (> 1,024 bits) for vertical communication. In addition to ultrawide buses, a stack provides a very short distance between the processor and memory, decreasing memory access times considerably. In [12], 3D ICs were proposed to improve performance of chip multiprocessors. Drawing upon 3D IC research, they chose a hybridization of buses and networks to provide the interconnect fabric between CPUs and L2 caches. The performance of this fusion of NoC and bus architectures was evaluated using standard CPU benchmarks. However, this analysis pertains only to chip multiprocessors and does not consider the use of 3D network structures for application-specific SoCs. Three-dimensional NoCs are analyzed in terms of temperature in [13]. Pavlidis and Friedman [14] compared 2D MESH structures with their 3D counterparts by analyzing the zero-load latency and power consumption of each network. This is an evaluation that shows some of the advantages of 3D NoCs, but it neither applies any real traffic pattern nor does it measure other relevant performance metrics. We aim to address these Fig. 2. Mesh-based NoC architectures. (a) Two-dimensional mesh. (b) Three-dimensional mesh. (c) Stacked mesh. (d) Ciliated 3D mesh. 34 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 Fig. 3. Switches for mesh-based NoCs. (a) Three-dimensional mesh. (b) Stacked mesh. (c) Ciliated 3D mesh. switches: one port to the IP block, one each to switches above and below, and one in each cardinal direction (North, South, East, and West), as shown in Fig. 3a. A second derivation, Stacked Mesh (Fig. 2c), takes advantage of the short interlayer distances that are characteristics of a 3D IC, which can be around 20 m [7]. Stacked Mesh is a hybrid between a packet-switched network and a bus. It integrates multiple layers of 2D Mesh networks by connecting them with a bus spanning the entire vertical distance of the chip. As the distance between the individual 2D layers in 3D IC is extremely small, the overall length of the bus is also small, making it a suitable choice for communicating in the z-dimension [12]. Furthermore, each bus has only a small number of nodes (i.e., equal to the number of layers of silicon), keeping the overall capacitance on the bus small and greatly simplifying bus arbitration. For consistency with [12], our analysis considers the use of a dynamic , time-division multiple-access (dTDMA) bus, although any other type of bus may be used as well. A switch in a Stacked Mesh network has, at most, six ports: one to the IP, one to the bus, and four for the cardinal directions (Fig. 3b). Additionally, it is possible to utilize ultrawide buses similar to the approach introduced in [11] to implement cost-effective, high-bandwidth communication between layers. A third method of constructing a 3D NoC is by adding layers of functional IP blocks and restricting the switches to one layer or a small number of layers. With this in mind, we introduce a new architecture, ciliated 3D Mesh. This structure is essentially a 3D Mesh network with multiple IP blocks per switch. For the ciliated 3D Mesh, we consider a 4  4  2 3D Mesh network with two IPs per switch, where the two functional IP blocks occupy, more or less, the same footprint but reside at different layers. This is shown in Fig. 2d. In a ciliated 3D Mesh network, each switch contains seven ports (one for each cardinal direction, one either up or down, and one to each of the two IP blocks), as shown in Fig. 3c. This architecture will clearly exhibit lower overall bandwidth than a complete 3D Mesh due to multiple IP blocks per switch and reduced connectivity; however, we will show that this type of network offers an advantage in terms of energy dissipation, especially in the presence of specific traffic patterns. It is important to note that each mesh-based network introduced in this section can be easily translated into a toroidal structure. 3.2 Tree-Based Networks Two types of tree-based interconnection networks that have been considered for NoC applications are butterfly fat tree (BFT) [16], [17] and the generic fat tree, or SPIN [18]. This paper endeavors to quantify the enhancements achieved when these networks are instantiated in a 3D IC environment. Unlike the work with mesh-based NoCs, we do not propose any new topologies for tree-based systems. Instead, we investigate the achievable performance benefits by instantiating already-existing tree-based NoC topologies in a 3D environment. The BFT topology we consider is shown in Fig. 4a. For a 64-IP SoC, a BFT network will contain 28 switches. Each switch (Fig. 5a) in a BFT network consists of six ports, one to each of four child nodes and two to parent nodes, with the exception of the switches at the topmost layer. When mapped to a 2D structure, the longest interswitch wire length for a BFT-based NoC is l2DIC =2, where l2DIC is the 20 mm  20 mm die, then the longest interswitch wire is die length on one side [17], [5]. If the NoC is spread over a 10 mm [5], as shown in Fig. 4c. Yet, when the same BFT network is mapped onto a four-layer 3D SoC, wire routing becomes simpler, and the longest interswitch wire length is reduced by at least a factor of two, as can be seen in Fig. 4d. This will lead to reduced energy dissipation as well as less area overhead. The fat tree topology in Fig. 4b will have the same advantages when mapped on to a 3D IC as the BFT. 4 PERFORMANCE ANALYSIS AND DESIGN COST In order to properly analyze the various 3D NoC topologies, a standard set of metrics must be used [19]. We assume wormhole routing [20] as the data transport mechanism where the packet is divided into fixed length flow control units or flits. The header flit holds the routing and control information. It establishes a path, and subsequent payload or body flits follow that path. Our comparative analysis focuses on the four established benchmarks [19] of throughput, latency, energy, and area overhead. Throughput is a metric that quantifies the rate in which message traffic can be sent across a communication fabric. It is defined as the average number of flits arriving per IP block per clock cycle, so the maximum throughput of a system is directly related to the peak data rate that a system can sustain. Accordingly, it is important to note that a throughput of 1 corresponds to every node accepting one flit in every clock cycle. FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 35 Fig. 4. Tree architectures. (a) BFT. (b) SPIN. (c) Two-dimensional BFT floorplan. (d) Three-dimensional BFT floorplan for the first two layers. (e) The first three layers of a 3D BFT floorplan as seen in elevation view. Next, latency refers to the length of time elapsed between the injection of a message header at the source node and the reception of the tail flit at the destination. The transport of messages across a network leads to a quantifiable amount of energy dissipation. Activity in the logic gates of the network switches as well as the charging and discharging of interconnection wires lead to the consumption of energy. Last, the amount of silicon area used by an interconnection network is a necessary consideration . Network switches, layer-to-layer vias, interswitch wires, and buffers incurred by relatively longer wires all use a certain amount of area of the chip. 4.1 Performance Analysis in 3D Mesh-Based NoCs In this section, we analyze the performance of the 3D Mesh-based NoC architectures in terms of the parameters mentioned above. Throughput is given in the number of accepted flits per IP per cycle. This metric, therefore, is closely related to the maximum amount of sustainable traffic in a certain network type. Any improvements in throughput in 3D networks are principally related to two factors: the number of physical links and the average number of hops. In general, for a Mesh-based NoC, the number of links is given as follows: links ¼ N1N2 ðN3   1Þ þ N1N3 ðN2   1Þ þ N2N3 ðN1   1Þ; ð1Þ where Ni represents the number of switches in the ith dimension. For instance, in an 8  8 2D Mesh-based NoC, this yield 112 links. In a 4  4  4 3D Mesh-based NoC, the number of links turns out to be 144. With a greater number of links, a 3D Mesh network, for example, is able to contain a greater number of flits and therefore transmit a greater number of messages. However, only considering the number of links will not characterize the overall throughput of a network. The average hop count also has a definitive effect on throughput. Following [14], the average number of hops in a mesh-based NoC is given by hopsN oC ¼ n1n2n3 ðn1 þ n2 þ n3 Þ   n3 ðn1 þ n2 Þ   n1n2 3ðn1n2n3   1Þ ð2Þ ; Fig. 5. Switches for tree networks. (a) BFT. (b) SPIN. where ni is the number of nodes in the ith dimension. This equation applies both to the 4  4  4 3D Mesh and 36 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 ð3Þ hopsS tacked ¼ n1 þ n2 4  4  2 ciliated 3D Mesh networks. The number of hops for the Stacked Mesh is equal to þ n3   1 : 3 n3 For our 4  4  4 3D Mesh and 8  8 2D Mesh, average hop counts are 3.81 and 5.33, respectively. There are 40 percent more hops in the 2D Mesh compared to that in the 3D Mesh. Consequently, flits in 3D Mesh needs to traverse less number of stages between a pair of source and destination than the 2D counterpart. As a result of this, we expect a corresponding increase in throughput. A lower average hop count will also allow more flits to be transmitted through the network. With a lower hop count, a wormholerouted packet will utilize fewer links, thus leaving more room to increase the maximum sustainable traffic. Transport latency, like throughput, is also affected by average hop count. It is also affected heavily by the number of links and the injection load. In 3D architectures, a decrease in latency is expected due to a lower hop count and an increased number of links. In the SoC realm, energy dissipation characteristics of the interconnect structures are crucial, as the interconnect fabric can consume a significant portion of the overall energy budget [13]. The energy dissipation in an NoC depends on the energy dissipated by the switch blocks and the interswitch wire segments. Both of these factors depend on the network architecture. Additionally, the injection load has a significant contribution as it is the cause for any activity in the switches and interswitch wires. Intuitively, it is clear that with more packets traversing the network, power will increase. This is why packet energy is an important attribute for characterizing NoC structures. The energy dissipated per flit per hop is given by Ehop ¼ Eswitch þ Ewire ; ð4Þ where Eswitch and Ewire are the energy dissipated by each switch and interswitch wire segments, respectively. The energy of a packet of length n flits that completes h hops is given by Epacket ¼ n Ehop;j : j¼1 ð5Þ X h P P P hi j¼1 P From this, a formula for packet energy can be realized. If P packets are transmitted, then the average energy dissipated per packet is given as ! P P Epacket ¼ i¼1 Epacket;i P ni i¼1 ¼ Ehop;j : ð6Þ Now, it is clear that a strong correlation exists between packet energy and the number of hops from source to destination. Consequently, a network topology that exhibits smaller hop counts will also exhibit correspondingly lower packet energy. As all 3D mesh-based NoC architectures exhibit a lower hop count, they should also dissipate less energy per packet. Last, the area overhead must be analyzed for mesh-based NoCs. Area overhead for an NoC includes switch overhead TABLE 1 Interswitch Wire Lengths in 3D Tree-Based NoCs and wiring overhead. Switch area is affected by the overall number of switches and the area per switch, which is highly correlated to the number of ports. Since all 3D mesh-based NoCs have more ports, the area per switch will increase. However, the ciliated structure has a reduced number of switches, which should significantly reduce the overall switch area. For 3D NoCs in general, wiring overhead includes the interlayer via footprint in addition to the area incurred by horizontal and vertical wirings. The addition of interlayer vias and their corresponding area overhead is a characteristic that is unique to 3D ICs, and it is included in the area overhead calculations presented in Section 5. Wire overhead is reduced when moving to a 3D IC. However, this is not due to reductions in the length of most interswitch wires. Horizontal wire length is given by lIC =nside , where nside represents the number of IPs in one dimension of the IC and lIC is the die length on one side, as shown in Figs. 2a and 2b. For the 8  8 2D Mesh, this evaluates to 20 mm/8 or 2.5 mm, and for all 3D mesh-based architectures, the expression evaluates to 10 mm/4, also 2.5 mm. With this in mind, reductions in wire overhead come from the interlayer wires. The 3D structures have a reduced number of horizontal links due to the presence of interlayer wires. These interlayer wires are very small, and hence, they are the source of wire overhead savings in mesh-based 3D NoCs. 4.2 Performance Analysis in 3D Tree-Based NoCs Unlike the previous discussion pertaining to mesh-based NoCs , the tree-based networks we cons ider for 3D implementations have identical topologies to their 2D counterparts. The only variable is the interswitch wire length. As a result, there are significant improvements both in terms of energy and area overhead. In 2D space, the longest interswitch wire length in a BFT or SPIN network is equal to l2DIC =2 [17], [5], where l2DIC is the die length on one side. This interswitch wire length corresponds to the topmost level of the tree. In a 3D IC, however, this changes significantly. For instance, as shown in Figs. 4d and 4e, the longest wire length for 3D, tree-based NoC is equal to the length of the horizontal travel in addition to the length of the vertical via. Considering a 20 mm  20 mm 2D die, the longest interswitch wire length is equal to 10 mm, whereas with a 10 mm  10 mm stack of four layers, the maximum wire length is equal to the sum of l3DIC =4, or 2.5 mm, and the span of two layers, 40 m. This is almost a factor-of-four reduction compared to 2D implementations. Similarly, mid-level wire lengths are reduced by a factor of 2. As a result, this reduction in wire length, shown in Table 1, causes a significant reduction in energy.   FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 37 TABLE 2 Wire Delays TABLE 3 Architectural Parameters In addition to the benefits in terms of energy, 3D ICs effect area improvements for tree-based NoCs. Again, as with energy, area gains pertain only to the interswitch wire segments; there is neither a change in the number of switches nor in the design of the switch. As with the 3D mesh-based NoCs, wire overhead in a 3D tree-based NoC consists of the horizontal wiring in addition to the area incurred by the vertical wires and vias. Also, the longer interswitch wires, which are characteristics of 2D tree-based NoCs, require repeaters, and this is taken into account. For a BFT, the number of wires in an arbitrary tree level l as defined in [16] is   wireslayerl ¼ wlink  N 2l 1 ; ð7Þ where N is the number of IP blocks, and wlink is the link width in bits. For a generic fat tree, the number of wires in a tree level l is given by wireslayerl ¼ wlink  N : ð8Þ For instance, in a 64-IP BFT network with 32-bit-wide bidirectional interswitch links, there are 2,048 wires in the first level, 1,024 wires in the second level, and 512 wires in the third. Similarly, a 64-IP fat tree will have 2,048 wires in every level. 5 EXPERIMENTAL RESULTS To model the performance of different NoC structures, a cycle-accurate network simulator is employed that can also simulate dTDMA buses. The simulator is flit-driven and uses wormhole routing. In this work, we assume a self-similar injection process [19], [21], [22], [23]. This type of traffic has been observed in the bursty traffic typical of on-chip modules in MPEG-2 video applications [23], as well as various other networking applications [22]. It has been shown to closely model real traffic [23]. In terms of spatial distribution, it is capable of producing both uniform and localized traffic patterns for injected packets. In order to acquire energy and area characteristics, the network switches, dTDMA arbiter, and FIFO buffers were modeled in VHDL. The network switches were designed in such a way that their delay can be constrained within the limit of one clock cycle. We assume the clock cycle to be equal to 15 fan-out-of-four (FO4) delay units. With the 90-nm standard cell library from CMP [24], this corresponds to a clock frequency of 1.67 GHz. As the switches were designed with differing numbers of ports, their delays vary with one another. However, it was important to ensure that all the delay numbers were kept within the 15 FO4 timing constraint. Consistent with [5], the longest delays were in the 2D/3D Fat Tree switches as they had the highest number of ports. Yet, even it can be run with a clock frequency of 11 FO4, well within the 15 FO4 limit. To have a consistent comparison, all the switches were run with a 15-FO4 clock. Similarly, all interswitch wire delays must hold within the same constraints. As shown in Table 2, wire RC delays remain within the clock period of 600 ps [24]. For Stacked Mesh, even considering the bus arbitration, the delay is constrained within one clock cycle. For the vertical wires, the via resistance and capacitance are included in the analysis. Thus, all network architectures are able to run at the same clock frequency of 1.67 GHz. Additional architectural parameters for each topology is shown in Table 3. Although the simulator is capable of running with an arbitrary specification, each switch was designed with four virtual channels per port and two-flit-deep virtual channel buffers, as discussed in [19]. Synopsys Design Analyzer was used to synthesize the hardware description using a 90-nm standard cell library from CMP [24], and 38 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 Fig. 6. Experimental results for mesh-based NoCs. (a) Throughput versus injection load. (b) Latency versus injection load. (c) Cycle energy versus injection load. (d) Packet energy. Synopsys PrimePower was used to gather energy dissipation statistics. To calculate Eswitch and Einterconnect from (4), we follow the methodology discussed in [19] . We determine the energy dissipated by each switch, Eswitch , by running its gate-level netlist through Synopsys PrimePower using large sets of input data patterns. In order to determine the interconnect energy, Einterconnect , we estimate the interconnects’ capacitance, taking into account each interswitch wire’s specific layout, by the following expression [19]: Cinterconnect ¼ Cwire  waþ1;a þ n  m  ðCG þ CJ Þ; ð9Þ where Cwire represents the capacitance per unit length of the wire, waþ1;a is the wire length between two consecutive switches, n is the number of repeaters, m represents the size of those repeaters with respect to minimum size devices, and last, CG and CJ represent the gate and junction capacitances, respectively, of a minimum size inverter. We consider a worst case scenario where adjacent wires switch in opposite directions while determining Cwire [25]. The simulation is initially run for 10,000 cycles to allow the 64-IP network to stabilize, and it is subsequently run for 100,000 more cycles. The simulator provides statistics for energy, throughput, and latency. 5.1 Mesh-Based Networks We first consider the performance of 3D mesh-based NoC architectures. Fig. 6a shows the variation of throughput as a function of the injection load. A network cannot accept more traffic than is supplied, and limitations in routing and collisions cause saturation before throughput reaches unity. From Fig. 6a, we see clearly that both the 3D Mesh and Stacked Mesh topologies exhibit throughput improvements over their 2D counterparts. It is also clear that the ciliated 3D Mesh network shows only a small throughput improvement. However, this is not where a ciliated structure exhibits the best performance. It will be shown later that this network topology has significant benefits both in terms of energy dissipation and silicon area. These results coincide with the analysis of 3D meshbased NoC provided in Section 4.1. We have shown in (1) that a 3D mesh will have 29 percent more interconnection links than a 2D version; hop count calculations have shown that a flit in a 2D mesh network will, on average, traverse 40 percent more hops than a flit navigating a 3D mesh (according to Table 4); and 3D mesh switches have higher connectivity with the increased number of ports. These all account for throughput improvements. In general, the lower hop count allows a wormhole-routed packet to occupy fewer resources, freeing up links for additional packets. Consequently, there is a corresponding increase in throughput. FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 39 TABLE 4 Average Hop Count in Mesh-Based NoCs Next, we consider the Stacked Mesh architecture. An increase in throughput is evident, as shown in Fig. 6a. However, with a 32-bit bus (corresponding to the flit width) connecting the layers of the NoC, throughput improvements are not as substantial as with the 3D mesh. Contention issues in the bus limit the attainable performance gains. Yet, since communication between layers is bus based, we can increase the size of the bus without modifying the switch architectures. As a result, the bus width is increased to 128 bits. Any further increase did not have any significant impact on throughput, except to increase the total capacitance on the bus. With this improvement, Stacked Mesh saturates at a slightly higher injection load than a 3D Mesh network. The Stacked Mesh topology also offers a lower hop count in comparison to a strict 3D mesh. From (3), we see that the average hop count is equal to 3.42. With the lower hop count in addition to the wide, 128-bit bus for vertical transmission, this architecture offers the highest throughput among all the 3D mesh-based networks. Throughput characteristics of the ciliated 3D Mesh topology differ significantly from the other 3D networks. This network has a saturating throughput that is slightly higher than a 2D Mesh network and considerably less than both 3D Mesh and Stacked Mesh networks. This is true despite having the lowest hop count at an average of 3.10 hops. However, with only 64 interswitch links, compared to 144 in the 3D Mesh and 112 in the 2D Mesh, throughput improvements due to hop count are negated by the reduced number of links. The fact that there are multiple functional IP blocks for every switch is also responsible for considerably lower throughput due to contention issues in the switches. Fig. 6b depicts the latencies for the architectures under consideration. Here, it is seen that 3D mesh-based NoCs have superior latency characteristics over the 2D versions. This is a product of the reduced hop count characteristic of 3D mesh-based topologies. Energy dissipation characteristics for 3D mesh-based NoCs reveal a substantial improvement over planar NoCs. The energy dissipation profiles of the mesh-based NoC architectures under consideration are shown in Fig. 6c. Energy dissipation is largely dependent on two factors: architecture and injection load. We consider these two parameters as the independent factors in our analysis. As shown in (4), the energy dissipation in an NoC depends on the energy dissipated by the switch blocks and the interswitch wire segments. Both these factors depend on the architectures. The design of the switch varies with the architecture, and interswitch wire length is also architecture dependent [19]. Besides the network architecture, injection load has a clear effect on the total energy dissipation of a Fig. 7. Area overhead for mesh-based NoCs. NoC, in accordance with Fig. 6c. Intuitively, it is clear that with more packets traversing the network, power will increase. This is why packet energy, in Fig. 6d, is an important attribute for characterizing NoC structures. Notice that, at saturation, a 2D Mesh network dissipates less power than both Stacked Mesh and 3D Mesh networks. This is the result of the lower 2D Mesh throughput, and the 3D networks consume more energy because they transmit more flits at saturation. Packet energy is a more accurate representation of the cost of data transmission. With packet energy in mind, it can be seen that every 3D topology provides a very substantial improvement over 2D mesh. Also, the energy dissipation of the ciliated mesh topology is less, still, than that of the 3D mesh network. These results follow closely the hop count calculations summarized in Table 4, with the exception of the packet energy for a Stacked Mesh network. Energy is heavily dependant on interconnect energy, and this is where the Stacked Mesh suffers. Since vertical communication takes place through wide buses, the capacitive loading on those buses results in a significant amount of energy. As a result, though 3D Stacked Mesh has a lower hop count compared to 3D Mesh, it dissipates more packet energy on average. Regardless, the profound energy savings possible in these 3D architectures provides serious motivation for a SoC designer to consider a 3D IC. The final performance metric considered in this study is the overall area overhead incurred with the instantiation of the various networks. Fig. 7 shows the area penalty from each NoC design, both in terms of switch area and interconnect area. We see that while the 3D Mesh and Stacked Mesh NoCs reduce the amount of wiring area, switch overhead is increased. For both 3D Mesh and Stacked Mesh NoCs, the number of longer interswitch links in x y plane is reduced. There are 96 x y links for both topologies, for Stacked Mesh, 16 buses are present, and for the 3D Mesh, 48 vertical links are present. In comparison, the conventional 2D mesh-based NoC has 112 links in the horizontal plane. As the 3D NoCs have fewer long horizontal links, they incur less wiring area overhead. Although there are a large number of vertical links, the amount of area incurred by them is very small due to the 2 m  2 m interlayer vias. However, an increased number of ports per switch results in larger switch overhead for 40 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 Fig. 8. Experimental results for tree-based NoCs. (a) Throughput versus injection load. (b) Latency versus injection load. (c) Cycle energy versus injection load. (d) Packet energy. both of these NoC architectures, ultimately causing the 3D Mesh and Stacked Mesh topologies to incur more silicon area in spite of wiring improvements. On the other hand, ciliated 3D Mesh shows a significant improvement in terms of area. The 4  4  2 ciliated 3D Mesh structure involves half the number of switches as the other mesh-based architectures in addition to only 64 links. As a result, the area overhead is accordingly smaller. 5.2 Tree-Based Networks In this section, we evaluate the performance of the 3D treebased NoCs. It has already been established that 2D and 3D versions of the tree topologies should have identical throughput and latency characteristics, and Figs. 8a and 8b support this. Consistent with the analysis of mesh-based NoCs, Fig. 8a shows the variation of throughput as a function of injection load, and Fig. 8b shows the effect of injection load on latency. The assumption here was that the switches and the interswitch wire segments are driven by the same clock as explained earlier. Consequently, under this assumption, in terms of throughput and latency there is no advantage to choosing a 3D IC over a traditional planar IC for a tree-based NoC. However, this is eclipsed by the superior performance achieved in terms of energy and area overhead. If the NoC switches can be designed to operate as fast as the interswitch wires, then we will show in Section 5.4 that the 3D tree-based architectures will have significant benefit in terms of even latency and bandwidth. The energy profiles for 3D tree-based NoCs (Fig. 8c) reveal significant improvements over 2D implementations. Both BFT and fat tree (SPIN) networks show a very large reduction in energy when 3D ICs are used. Once again, we see that energy dissipation is largely dependant both on architecture and injection load. Each NoC shows that energy dissipation increases with injection load until the network becomes saturated, similar to the throughput curve shown in Fig. 8a. From the energy profiles, we also see that the fat tree networks cause higher energy dissipation than the BFT instantiations, but this is universally true only at high injection load. Again, this is the motivation to consider packet energy of the networks as a relevant metric for comparison, as shown in Fig. 8d. Energy savings in excess of 45 percent are achievable by adopting 3D ICs as a manufacturing methodology, and both BFT and fat tree networks show similar improvements. In case of tree-based NoCs, where the basic network topology remains unchanged in 3D implementations, all improvements in energy dissipation are caused by the shorter wires. As we showed earlier in Table 1, a 3D structure greatly reduces the interswitch wire length. The overall energy dissipation in a NoC is heavily dependant on the interconnect energy, and this reduction in interswitch wire length effects very large savings. FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 41 5.3 Effects of Traffic Localization Until this point, we have assumed a uniform spatial distribution of traffic. In a SoC environment, different functions would map to different parts of the chip and the traffic patterns would be expected to be localized to different degrees [26]. We therefore studied the effect of traffic localization on the performance of the 3D NoCs and considered the illustrative case of spatial localization where local messages travel from a source to the set of the nearest destinations. In the case of BFT and fat tree, localized traffic is constrained to within a cluster consisting of a single subtree, while, in the case of 3D Mesh, it is constrained to within the destinations placed at the shortest Manhattan distance [19]. On the other hand, the 3D Stacked Mesh architecture is created simply to take advantage of the inexpensive vertical communication. The research pursued by Li et al. [12] suggested that in a 3D multiprocessor SoC, much of the communication should take place vertically, taking advantage of the short interlayer wire segments. This is a result of a large proportion of network traffic occurring between the processor and the closest cache memories, which are often placed along the z-dimension. Consequently, in these situations, the traffic will be highly localized, and we therefore consider localized traffic to be constrained to within a pillar for Stacked Mesh. Fig. 10 summarizes these Fig. 9. Area overhead for tree-based NoCs. Besides advantages in terms of energy, 3D ICs enable tree-based NoCs to reduce silicon area overhead by a sizable margin. Fig. 9 shows the overall area overhead of tree-based NoCs. We see that although no improvements are made in terms of switch area, the reductions in interswitch wire lengths and amount of repeaters are responsible for substantial reductions in wiring overhead. This is especially true for the fat tree network, which has more interconnects in the higher levels of the tree; wiring overhead is reduced more than 60 percent by instantiating the network into a 3D IC. Fig. 10. Localization effects on mesh-based NoCs in terms of (a) throughput and (b) packet energy and localization effects on tree-based NoCs in terms of (c) throughput and (d) packet energy. 42 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 Fig. 11. The pipelined nature of NoCs. effects, revealing the benefits of traffic localization. More packets can be injected into the network, improving the throughput characteristics of each topology, as shown in Figs. 10a and 10c, which also shows the throughput profile of the 2D topologies for reference. Analytically, increasing localization reduces the average number of hops that a flit must travel from source to destination. Fig. 10a reveals that the stacked mesh network provides best performance in terms of throughput in the presence of localized traffic. However, this is achieved by using a wide bus for vertical communication. Let us consider what occurs when the bus size is equal to the flit width of 32 bits. With low localization, the achieved throughput is higher than that in a 2D Mesh network. However, when the fraction of localized traffic in the vertical pillars is increased, a huge performance degradation is seen. This is due to the contention in the bus. When the bus width is increased to 128 bits, throughput increases significantly with increase in localized traffic. This happens due to less contention in a wider communication channel. Figs. 10b and 10d depict the effects of localization on packet energy, and unsurprisingly, there is a highly linear relationship between these two parameters. Packet energy is highly correlated with the number of hops from source to destination, and the resultant reduction of packet energy with localization supports this correlation. For the meshbased networks, ciliated 3D Mesh exhibits the lowest packet energy due to its low hop count and very short vertical wires. In fact, at highest localization, the packet energy for a ciliated 3D Mesh topology is less than 50 percent of that of the next-best-performing topology: 3D Mesh. For the treebased NoCs, both 3D networks have much-improved packet energy with traffic localization. As can be seen from Fig. 10, there are trade-offs between packet energy and throughput. For instance, the bestperforming topology in terms of energy, ciliated 3D Mesh, operates at the lowest throughput even when traffic is highly localized. On the other hand, although a 3D Stacked Mesh network with wider bus width achieves superior throughput without necessitating a highly local traffic distribution, it incurs more energy dissipation than other structures under local traffic due to the capacitive loading on the interlayer buses. However, the other topologies lie in some middle ground between these two extremes, and in general, it is clear that 3D ICs continue to effect improvements on NoCs under localized traffic. 5.4 Effects of Wire Delay on Latency and Bandwidth In NoC architectures, the interswitch wire segments, along with the switch blocks, constitute a pipelined communication medium, as shown in Fig. 11. The overall latency (in nanoseconds) will be governed by the slowest pipelined stage. We had shown earlier, in Table 2, that the maximum Fig. 12. Latency in nanoseconds at hypothetical clock frequencies. wire delays for the network architectures are different. Though the vertical wire delays are very small, still the overall latency will be depended on the delay of the switch blocks. Though the delays of the switch blocks were constrained within the 15-FO4 limit, they were still the limiting stages in the pipeline, specifically when compared to the fast vertical links. Yet, if we consider a hypothetical case, which ignores the implications of switch design, where the clock period of the network is equal to the interswitch wire delay, then the clock frequency can be increased, and hence, the latency can be reduced significantly. With this in mind, latency in nanoseconds (instead of latency in clock cycles) and bandwidth (instead of throughput) are calculated. All other network parameters are kept consistent with our previous analysis. A plot of latency for all network topologies is shown in Fig. 12, and Table 5 depicts the network bandwidth in units of terabits per second. To calculate bandwidth, we follow the following expression: BW ¼ T Pmax  f  wf lit  N ; ð10Þ where T Pmax represents the throughput at saturation, f represents the clock frequency, wf lit is the flit width, and N is the number of IP blocks. In Table 5, we show the performance difference achieved by running the NoC with a clock as fast as the interswitch wire, disregarding the TABLE 5 Bandwidth of Network Architectures at Simulated and Hypothetical Frequencies (Terabits per Second) FEERO AND PANDE: NETWORKS-ON-CHIP IN A THREE-DIMENSIONAL ENVIRONMENT: A PERFORMANCE EVALUATION 43 Fig. 13. Comparing two 2-layer NoCs. (a) Throughput versus injection load. (b) Latency versus injection load. (c) Cycle energy versus injection load. (d) Packet energy. switch design constraints. It is evident that the tree-based architectures show the greatest performance improvement in this scenario going from 2D to 3D implementations, as the horizontal wire lengths are also reduced. 5.5 Network Aspect Ratio The ability to stack layers of silicon is not without nuances. Upcoming 3D processes have a finite number of layers due to manufacturing difficulties and yield issues [7]. Furthermore, it is speculated [7] that the number of layers in a chip stack is not likely to scale with transistor geometries. This has a nontrivial effect on the performance of 3D NoCs. Consequently, future NoCs may have a greater number of IP blocks in the horizontal dimensions than vertically. The effect of this changing aspect ratio must be characterized. For an illustration of these effects, we will examine, more in depth, the performance of a mesh-based NoC in a two-layer IC in comparison to the previously analyzed 3D 4  4  4 Mesh and 2D 8  8 Mesh. Here, we consider a 64-IP 8  4  2 Mesh to match the 64-IP network size, in order to make the comparison of latency and energy as fair as possible, and a 60-IP 6  5  2 Mesh to show a network that more square overall footprint than the 8  4  2 Mesh. is similar in size and that results in a Fig. 13 summarizes our analysis of these two-layer ICs. Throughput characteristics are seen in Fig. 13a. We the 6  5  2 Mesh ach ieves a see c lear ly tha t significantly higher throughput than the 2D 8  8 Mesh and the 8  4  2 Mesh, which suffers from a high average hop count (4.44 versus 4.11 for the 6  5  2 Mesh), while achieving a lower maximum throughput than the fourlayer mesh. Likewise, the two-layer mesh NoCs outperform the 2D Mesh in terms of latency, as shown in Fig. 13b, without exceeding the performance of the four-layer 3D instantiation. This trend continues when considering cycle energy (Fig. 13c) and packet energy (Fig. 13d). These results are as expected. With the first layer added, we see significant improvements in terms of each performance metric over the 2D case. Though the multilayer NoC exhibits superior performance characteristics compared to a 2D implementation, it will have to circumvent significant manufacturing challenges. Yet, even if we are limited to a two-layer 3D realization, that will still significantly outperform the planar NoCs. 5.6 Multilayer IPs Throughout this paper, we have assumed each IP block to be instantiated in one layer of silicon. However, as discussed in [14], it is certainly possible for the IP blocks to be designed using multiple layers. So, each network architecture is analyzed with multilayer IPs. We assume the pipelined communication shown in Fig. 11, i.e., the NoCs are constrained by the switch delay and it cannot be driven 44 IEEE TRANSACTIONS ON COMPUTERS, VOL. 58, NO. 1, JANUARY 2009 "
2003,Power-driven Design of Router Microarchitectures in On-chip Networks.,"As demand for bandwidth increases in systems-on-a-chip and chip multiprocessors, networks are fast replacing buses and dedicated wires as the pervasive interconnect fabric for on-chip communication. The tight delay requirements faced by on-chip networks have resulted in prior microarchitectures being largely performance-driven. While performance is a critical metric, on-chip networks are also extremely power-constrained. In this paper, we investigate on-chip network microarchitectures from a power-driven perspective. We first analyze the power dissipation of existing network microarchitectures, highlighting insights that prompt us to devise several power-efficient network microarchitectures: segmented crossbar, cut-through crossbar and write-through buffer. We also study and uncover the power saving potential of existing network architecture: express cube. These techniques are evaluated with synthetic as well as real chip multiprocessor traces, showing a reduction in network power of up to 44.9%, along with no degradation in network performance, and even improved latency-throughput in some cases.","Power-driven Design of Router Microarchitectures in On-chip Networks Hangsheng Wang Li-Shiuan Peh Sharad Malik Department of Electrical Engineering, Princeton University, Princeton, NJ 08544 (cid:0)hangshen,peh,sharad(cid:1)@ee.princeton.edu Abstract As demand for bandwidth increases in systems-on-a-chip and chip multiprocessors, networks are fast replacing buses and dedicated wires as the pervasive interconnect fabric for on-chip communication. The tight delay requirements faced by on-chip networks have resulted in prior microarchitectures being largely performance-driven. While performance is a critical metric, on-chip networks are also extremely power-constrained. In this paper, we investigate on-chip network microarchitectures from a power-driven perspective. We ﬁrst analyze the power dissipation of existing network microarchitectures, highlighting insights that prompt us to devise several power-efﬁcient network microarchitectures: segmented crossbar, cut-through crossbar and writethrough buffer. We also study and uncover the power saving potential of an existing network architecture: express cube. These techniques are evaluated with synthetic as well as real chip multiprocessor traces, showing a reduction in network power of up to 44.9%, along with no degradation in network performance, and even improved latencythroughput in some cases. 1 Introduction On-chip networks have been widely proposed as the interconnect fabric for high-performance systems-on-a-chip (SoCs) [3, 9, 15], and demonstrated in several chip multiprocessors (CMPs) [14, 20]. As these networks are facing tight delay requirements [21], prior designs and microarchitecture studies have been heavily performance-driven, aiming towards lowering network delay to that of pure wire transmission latency [13, 14, 20]. However, the targeted systems of on-chip networks are increasingly becoming power-constrained. Battery life is of primary concern in embedded SoCs in PDAs, laptops and other mobile devices. In enterprise and desktop environments, system power budget, pressured by cooling and packaging costs, is the key constraint faced by designers today in systems such as server blades, storage bricks and PCs. With the increasing demand for interconnect bandwidth, on-chip networks are taking up a substantial portion of system power budget, e.g. the MIT Raw on-chip network which connects 16 tiles of processing elements consumes 36% of total chip power, with each router dissipating 40% of individual tile power. This drove us to rethink network microarchitecture design from a power-driven perspective and investigate what constitutes the ideal transmission energy in networks. To understand the power characteristics of prior performancedriven network microarchitectures, we modeled the on-chip networks of two CMPs – the MIT Raw [20] and the UT Austin TRIPS [14] and obtained their power proﬁle by using Orion [24], a power-performance simulator for interconnection networks. Our modeling highlights the signiﬁcant power dissipation of on-chip networks, and brings valuable insights on the relative power composition of different microarchitecture components in on-chip networks. Based on our analysis and insights, we devise three new microarchitectures: segmented crossbar, cut-through crossbar and write-through buffer. We also study the power saving potential of an existing network architecture: express cube. These techniques target energy reduction of key router components towards the ideal network transmission energy. Each mechanism’s impact on power, performance and area is ﬁrst analyzed in-depth through power modeling and probabilistic analysis, then evaluated with a cycle-accurate network simulator. Our simulations show that these mechanisms can achieve signiﬁcant power savings of 44.9% for synthetic uniform random trafﬁc, and 37.9% for the TRIPS trafﬁc traces, as compared to a baseline network conﬁguration based on current on-chip network designs, with no performance degradation. The rest of this paper is organized as follows: section 2 introduces the power characteristics of prior performancedriven on-chip network designs, along with a characterization of ideal network energy consumption, and the power proﬁles of the Raw and TRIPS on-chip networks. Section 3 describes four power-efﬁcient network microarchitectures, Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  analyzing the power-performance-area impact of different points in the design space for each mechanism. Section 4 delves into our simulation results of the proposed mechanisms, evaluated against synthetic and real trafﬁc traces. A discussion of prior related work follows in section 5, and section 6 concludes the paper. 2 Background and analysis 2.1 Background on on-chip networks On-chip networks have been proposed for chip multiprocessors (CMPs) as well as heterogeneous systemson-a-chip [15]. In this work, we focus on ﬁne-grained CMPs [14, 20] that transport operands instead of more traditional multiprocessors [1, 2, 22] that carry cache lines or user messages, as such ﬁne-grained CMPs with on-chip networks have already been demonstrated and fabricated, providing invaluable access to design details for power characterization and analysis. In these ﬁne-grained CMPs, whose networks are also named scalar operand networks [21], operand bypassing and forwarding delay between processing elements is absolutely critical to system performance, so network delay stands out as the most important performance metric. This has resulted in prior designs of on-chip network microarchitectures being heavily performance-driven, geared towards lowering network delay as much as possible. In the drive towards lower network delay, on-chip networks tend to choose simple, fast routing protocols, such as dimension-ordered routing. For example, Raw’s dynamic network uses a routing algorithm similar to dimensionordered routing in that each ﬂit1 can turn at most once. Onchip networks also tend to opt for two-dimensional topologies such as meshes and tori. While high-dimensional topologies have shorter average hop count, they are less desirable for the small scale of on-chip networks of today that tend to range from 44 to 88 nodes. This is due to constraints on chip size and hop delay, as they lead to longer channels as well as uneven channel delay [6]. Both Raw and TRIPS use 2-D topologies. 2.2 Power analysis of on-chip networks As characterized previously in [24], the energy consumed when transmitting a data ﬂit2 is: E f l it (cid:0) Ewrt  Erd  Earb  Exb  Elnk   H (cid:0) Ebu f  Earb  Exb  Elnk   H (1) 1A ﬂit is short for ﬂow control unit, a ﬁxed-length segment of a packet. 2We use data ﬂits in our discussion for simplicity. where Ewrt is the average energy dissipated when writing a ﬂit into the input buffer, Erd is the average energy dissipated when reading a ﬂit from the input buffer, Ebu f (cid:0) Ewrt  Erd is average buffer energy, Earb is average arbitration energy, Exb is average crossbar traversal energy, Elnk is average link traversal energy and H is the number of hops traversed by this ﬂit. Equation (1) can be reformulated as: E f l it (cid:0) ER  H  Ewire  D (2) where ER (cid:0) Ebu f  Earb  Exb is average router energy, Ewire is average link wire transmission energy per unit length assuming optimally-placed repeaters and D is the Manhattan distance between source and destination. The ideal ﬂit transmission energy is that dissipated by a dedicated wire linking source and destination, corresponding to the minimum physical activity required to complete the transmission: E f l it id eal (cid:0) Ewire  D (3) But in reality, more than ideal energy is consumed as the network shares and multiplexes links between multiple source-destination ﬂows, thus requiring intermediate routers that dissipate additional energy ER . To understand the power proﬁle of on-chip networks, we used Orion to model the power consumption of the Raw and TRIPS networks. Orion’s power models have been validated against Raw to be within 10% error of circuit-level power estimations. Details of the power proﬁling can be found in [23], here we only give summaries: Network power vs. total system power. In the Raw multiprocessor system, interconnection networks consume 7.1W power, which is 36% of total chip power, as estimated by the Raw designers using circuit-level tools [10]. This result highlights that networks consume a substantial portion of total system power in CMPs. Network power composition. Table 1 summarizes the average power composition of the Raw and TRIPS data networks. These numbers will vary with different network paTable 1. Raw and TRIPS average network power composition. Raw TRIPS input buffer 31% 35% crossbar 30% 33% arbiter (cid:2)0% 1% link 39% 31% rameters, but they clearly convey that unlike off-chip networks, where link power dominates, buffers, crossbars and links are equally important for reducing on-chip network power. Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  3 Power-efﬁcient network microarchitectures Our power analysis of on-chip networks as encapsulated in Equation (2) highlights several avenues that can be targeted for reducing ﬂit transmission energy – router energy ER , hop count H and wire transmission energy per unit length Ewire . ER mainly consists of buffer energy and crossbar energy. Source-destination distance D is largely determined by physical placement and is considered an input to network microarchitecture design. Many circuit techniques have been proposed for reducing Ewire , such as low-swing signaling [9, 25] and bus encoding schemes [19]. In this paper, we focus on the architecture level instead, devising, analyzing and evaluating four network microarchitectural/architectural techniques that target different components of ER and H . 3.1 Segmented crossbar Matrix crossbar is a common crossbar design. Figure 1(a) shows the schematic of a 44 matrix crossbar. Each line in the ﬁgure represents a ﬂit-wide bus, with tristate buffers at cross points, enabling connections from input ports to output ports. From the ﬁgure we can see that when a ﬂit enters from input port E and leaves through output port W , the entire input lines and output lines switch. Useful switching, however, is indicated by the dotted line – less than half of the actual switching capacitance. This prompted us to propose segmented crossbars, a simpliﬁed application of segmented buses [4]. Figure 1(b) shows its schematic. Each input/output line is evenly divided into M segments by tri-state buffers. Switch arbiters generate and conﬁgure the control signals of these tri-state buffers so that only the minimally needed wire segments switch, thus reducing Exb . Power analysis. Crossbar traversal energy Exb can be formulated as: Exb (cid:0) Exb in  Exb out  Exb ct r (4) where Exb in is the energy dissipation of crossbar input lines, Exb out is the energy dissipation of crossbar output lines, and Exb ct r is the energy dissipation of control lines of tri-state buffers. Exb in is determined by the input line capacitance Cin , switching activity Ain , and ﬂit size F ; while Exb out is similarly determined by the output line capacitance Cout , switching activity Aout and F . A segmented crossbar reduces Cin and Cout , and has no impact on switching activities Ain and Aout . As it requires more control lines for segment tri-state buffers, Exb ct r increases. The negative impact on power is minimal, given far fewer control lines than input/output N W E S F columns d w d w F rows N W E S N W E S N W E S (a) A 44 matrix crossbar. (b) A 44 segmented crossbar with 2 segments per line. Figure 1. Schematic of a matrix crossbar and a segmented crossbar. F is ﬂit size in bits, dw is track width, E , W, N , S are ports. lines unless M is larger than ﬂit size. All these details are modeled by extending Orion’s crossbar power model. We deﬁne Cin to be the input line capacitance of a normal, unsegmented matrix crossbar, Ct i to be the input capacitance of one tri-state buffer and Ct o to be the output capacitance of one tri-state buffer. Assuming that trafﬁc is evenly distributed among all input and output ports, the probability of the it h segment being traversed by incoming ﬂits is: Pi (cid:0) M   i  1 M (cid:0) i (cid:2) (cid:2)1(cid:0) M (cid:3) and the switching capacitance of the it h segment is: C1 (cid:0) Ci (cid:0) CM (cid:0) Cin M Cin M Cin M  Ct i  Ct i  Ct o (cid:0) i (cid:0) 2(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) M   1  Ct o So total effective switching capacitance is: C (cid:0) in (cid:0) M∑ i(cid:0)1 Pi  Ci M  2M   1  Ct i  2M (cid:0)  Cin  M  1 2M M   1 2 The same analysis can be applied to Cout :  Ct o C (cid:0) out (cid:0) M  1 2M M   1 2  Cout   Ct o M  2M   1 2M  Ct i  (5) (6) From Equations (5) and (6), an upper bound of power savings with 2, 3 and 4 segments is 25%, 33.3% and 37.5% respectively, which is calculated by ignoring Ct i , Ct o and Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  relative power savings 30% 25% 20% 15% 10% 10 8 6 number of crossbar ports  4  3 segments per line  2 4 Figure 2. Segmented crossbar power savings (relative to matrix crossbar). control lines. As M increases, these ignored terms become more signiﬁcant and the bound becomes looser. So we can conclude that adding more segments beyond 2 or 3 does not buy enough power savings to compensate for the overhead. Figure 2 shows the power savings of several segmented crossbar conﬁgurations relative to matrix crossbar, estimated by our power models, assuming 64-bit ﬂit and 0.1µm technology. Note that several conﬁgurations are not quite valid, e.g. 3 does not divide 4, but are shown to reﬂect general trends. From the ﬁgure we can see that large-scale crossbars tend to gain higher power savings from segmentation since the overhead of tri-state buffers gets relatively smaller. On the other hand, for a ﬁxed crossbar size, increasing the number of segments does not always result in higher power savings, e.g. a 3-segment 44 crossbar saves more power than a 4-segment 44 crossbar. Impact on performance. A 2-segment segmented crossbar has negligible impact on performance since a single tri-state buffer can be easily absorbed into the existing repeater chains and will not affect the duration of the crossbar traversal pipeline stage. More segments may increase crossbar delay, but they do not necessarily save more power either. Impact on area. Segmenting has no impact on area. Crossbar area is determined by the width and height of the matrix grid, and since cross point tri-state buffers and repeater chains can ﬁt within the grid, so can segment tri-state buffers. 3.2 Cut-through crossbar Cut-through crossbar is another microarchitectural mechanism we propose for reducing crossbar traversal energy Exb . While segmented crossbars are motivated by the inherent operation of a crossbar, cut-through crossbars leverage insights on network trafﬁc patterns and routing N N F columns inject E W N S W W S S E E d w wd F rows (a) A 44 cut-through crossbar. E W N S eject (b) Extending to a 55 crossbar. Figure 3. Schematic of cut-through crossbars. F is ﬂit size, dw is track width, E , W, N , S are ports. protocols in on-chip networks. Figure 3(a) sketches a 44 cut-through crossbar, where each input port is directly connected to the output port of the opposite direction by a ﬂit-wide bus, e.g. E(cid:1)W , N(cid:1)S, so only turns from one dimension to another go through tristate buffers at cross points. Essentially, cut-through crossbars optimize for the common case – straight-through trafﬁc, so straight-through trafﬁc incurs lower energy consumption as well as faster traversal. However, it does so at the expense of the connectivity of the crossbar switch. A cut-through crossbar supports almost the same connectivity as the original matrix crossbar, with the exception of a few combinations of turns as they share common wires. One example is shown by the two dotted lines in Figure 3(a) – connections E(cid:1)N and N(cid:1)W conﬂict because they both use a common line segment (shown in bold). In this case, one ﬂit needs to wait for the next crossbar traversal cycle. An observation is that any connectivity restriction induced by cut-through crossbars consists of at least two turns: one from the horizontal dimension to the vertical dimension, another from the vertical dimension to the horizontal dimension. Therefore, cut-through crossbars incur no performance penalty when a simple, dimension-ordered routing protocol is used, because with such protocols, ﬂits can only turn from one dimension to another, but not vice versa, hence inherently preventing any conﬂict. The trend towards simplistic routing protocols in on-chip networks thus makes cut-through crossbar a feasible choice. Cut-through crossbars target 44 fabrics, a common switch size in on-chip 2-D torus or mesh topologies. When injection port and ejection port are considered, since a cutthrough crossbar is not easily scalable to support a 55 fabric, a 4:1 mux and a 1:4 demux are used in parallel with the crossbar, as shown in Figure 3(b). Each input port and output port is properly muxed or demuxed to prevent interference among the three components. Power analysis. Recall Equation (4), Exb (cid:0) Exb in  Exb out  Exb ct r . Cut-through crossbars reduce Exb in and Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  Exb out by reducing the input/output line length and capacitance. The input line capacitance is: Cin (cid:0) CL  CT where CL is wire capacitance and CT is the capacitance of attached tri-state buffers. In Figure 1(a) each line represents an F -bit bus, where F is ﬂit size. So a 44 matrix crossbar can be regarded as a 4F  4F grid, and the line length is: LM (cid:0) 4F  dw where dw is track width. Similarly, a cut-through crossbar can be regarded as a 2F  2F grid, and its line length is: increase in power savings as technology scales down is due to the increasing impact of wire coupling capacitance. Impact on performance. To get an upper bound of latency increase due to the connectivity restrictions of a cutthrough crossbar, we assume uniform random trafﬁc and a worst-case routing algorithm which gives each incoming ﬂit the same probability of leaving from any other direction. This is a reasonable assumption because, although not impossible, it is unrealistic to design a routing algorithm which makes twice as many turns as straight trafﬁc. Assume a 44 router and let λ denote the ﬂit arrival rate at each input port. Then, for each input port, the probabilities of trafﬁc turning and not turning at any cycle (assuming no u-turns) are: LC (cid:0) 2F  dw pt urn (cid:0) λ 2 3 CL is proportional to line length, and is in turn proportional to ﬂit size. Assuming large enough ﬂit size, hence CT (cid:2) CL and Cin (cid:3) CL , and since LC (cid:0) 1 2 LM , Exb in of a cut-through crossbar is one half of that of a matrix crossbar. Similarly, we can derive that the average control line length is one half of that of a matrix crossbar, and so is Exb ct r . Exb out (cid:0) 0 in cut-through crossbars since each input line extends directly to its opposite output port and there is no separate output line. Relative to matrix crossbar traversal energy, cut-through crossbar traversal energy is: E (cid:0) xb (cid:0) 1 2 Exb in  1 2 Exb ct r (7) 1 For a matrix crossbar with the same number of input ports and output ports, Exb in (cid:3) Exb out . Also since there are far fewer control lines than input/output lines, which implies Exb ct r (cid:2) Exb in , a cut-through crossbar consumes roughly 4 energy of a matrix crossbar, and an upper bound of power saving is 75%. We extended Orion’s power models for cut-through crossbars and Table 2 shows the estimated power savings relative to matrix crossbar, for varying ﬂit sizes and technologies, assuming 0.5 switching probability and 0.5 ﬂit arrival rate. Table 2. Cut-through crossbar power savings (relative to matrix crossbar). ﬂit size 64 bits 128 bits 0.1µm 39.4% 47.2% 0.18µm 33.6% 43.0% 256 bits 52.0% 50.0% Since each line is connected with 4 tri-state buffers, whose capacitance contribution is ﬁxed, and line length is proportional to ﬂit size, larger ﬂit size leads to greater signiﬁcance of wire capacitance and higher power saving. The pnot t urn (cid:0) 1   2 3 With two input ports per dimension, the following equations derive the probabilities of each dimension having two turns, one and only one turn, and any one turn respectively: λ P2 t urn (cid:0) pt urn  pt urn P1 t urn (cid:0) 2  pt urn  pnot t urn Pany t urn (cid:0) 1   pnot t urn  pnot t urn Now consider the conﬂicting condition which contributes additional delay, of which there are three scenarios: (cid:5) The horizontal dimension has two turns and the vertical dimension has turning trafﬁc. They conﬂict as two turns from one dimension use up all wire resources of this dimension, preventing them from being used by turns from another dimension. (cid:5) The horizontal dimension has one turn and the vertical dimension has two turns. (cid:5) Both the horizontal dimension and the vertical dimension have exactly one turn. They conﬂict with probability pxy . A simple enumeration reveals that pxy (cid:0) 3 4 . So the conﬂicting probability (plotted in Figure 4) is: PC (cid:0) P2 t urn  Pany t urn  P1 t urn  P2 t urn  P1 t urn  P1 t urn  pxy λ(cid:1)2  λ   λ2(cid:1) (cid:0) (cid:0) 2  (cid:0) 3 5 3 4 9 From this equation, we can see that PCmax (cid:0) PC (cid:6)λ(cid:0)1 (cid:0) 43 which means that at full load (λ (cid:0) 1), the latency of the crossbar is increased by 53%. With a typical 3-stage router pipeline and a single cycle link propagation delay, a cutthrough crossbar will introduce at most 20% additional delay, which is a favorable trade-off for energy-delay product, even with such an unrealistic worst-case routing algorithm. 81 , Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  y t i l i b a b o r p g n i t c i l f n o c  0.6  0.5  0.4  0.3  0.2  0.1  0  0  0.2  0.4  0.6  0.8 flit arrival rate (flit/cycle)  1 write wordline read wordline e n i l t i b d a e r e t i r w e n i l t i b sense amplifier e n i l t i b e t i r w e n i l t i b d a e r Figure 4. Conﬂict probability vs. ﬂit arrival rate for a cut-through crossbar. (a) (b) (c) Impact on area. A cut-through crossbar clearly takes up less area than a matrix crossbar of the same scale. 3.3 Write-through input buffer As pointed out in our analysis, buffer energy Ebu f constitutes a signiﬁcant portion of total router energy ER , and is thus another target for power optimization. In a typical wormhole router [8], when a ﬂit enters an input port, it is written to the input buffer queue, and makes a request for switch traversal when it reaches the head of the queue. When the request is granted, the ﬂit is read out of the input buffer, traverses the crossbar switch fabric and makes its way through the link to the next hop. Bypassing input buffer is a common optimization for performance – when the ﬂit arrives, if the buffer is empty, the ﬂit heads straight to switch arbitration, and if it succeeds, the ﬂit gets sent directly to the crossbar switch, circumventing the input buffers. Figure 5(a) illustrates how bypassing is typically implemented – with a separate bypass path connecting the router input port with the crossbar input port, and a ﬂit-width register latching the data between consecutive pipeline stages of ﬂit arrival and crossbar traversal. The incoming ﬂit is still written into the buffer so that if bypassing cannot be done, it will not be overwritten by the next ﬂit. So bypassing only saves buffer read operations, at the expense of a separate bypass path. Since buffer write operations are not saved and the bypass path consumes extra energy and area, we propose an improved microarchitecture: write-through buffer, which realizes bypassing by overlapping the bypass path and buffer write bitlines, as sketched in Figure 5(b). Figure 5(c) shows the detailed schematic of a write-through buffer. Here the SRAM write bitlines are used as the bypass path and extend beyond the buffer. A write-through buffer essentially removes buffer read energy when bypassing can be done, at the expense of minimal hardware cost: pipeline registers and muxes. Power analysis. Equation (1) can be augmented to reFigure 5. (a) Bypassing without overlapping. (b) Bypassing with overlapping. (c) Schematic of a write-through input buffer. ﬂect the power saving ability of write-through buffers: E f l it (cid:0) Ewrt  α  Erd  Earb  Exb  Elnk   H (8) where α is the probability of a ﬂit being unable to bypass the input buffer. By using queuing theory, we can derive an upper bound of the power savings of write-through buffers. The probability of the buffer being empty is: λ p0 (cid:0) 1   µ where λ is the ﬂit arrival rate and µ is the ﬂit service or departure rate. Assuming no switch competition, so that µ (cid:0) 1, and we have: α (cid:0) 1   p0 (cid:0) λ From [24], Erd (cid:0) Ewl  F Ebr  2Echg Ewrt (cid:0) Ewl  δbwEbw  δbcEbc where Ewl is wordline energy, F is ﬂit size, Ebr is read bitline energy, Echg is pre-charging energy, Ebw is write bitline energy, Ebc is memory cell energy, and δbw and δbc are write bitline switching activity factor and memory cell switching activity factor respectively. Let r denote Ewrt , so the energy consumed by a normal buffer is: Erd Ebu f (cid:0) Ewrt  Erd (cid:0) r  1Erd When using write-through buffers, E (cid:0) bu f (cid:0) Ewrt  λ  Erd (cid:0) r  λErd Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE          thus, the relative power saving is 1 λ r1 . When buffer size is large enough, Ebr (cid:0) Ebw and Ewl (cid:0) Echg (cid:0) Ebc (cid:1) Ebr . Assuming uniform random trafﬁc, so that δbw (cid:0) 1 2 F and r (cid:0) 1 2 . At very low ﬂit arrival rate (λ (cid:2) 0), the buffer power saving can reach 60%. In reality, because on-chip networks tend to have small buffer size and also due to switch competition, writethrough buffers achieve much less power savings than the upper bound. Impact on performance. A write-through buffer can bypass buffer operations when the required conditions are met, otherwise it acts like a normal buffer, so it has no negative impact on network performance. In fact, a writethrough buffer saves on buffer read/write delay at times, and improves network performance. Impact on area. With overlapped bypass path and write bitlines, a write-through buffer only incurs marginal area overhead due to the additional registers and muxes. 3.4 Express cube Express cube was ﬁrst proposed in [7] to lower network latency by reducing average hop count. The main idea is to add extra channels between non-adjacent nodes, so that packets spanning long source-destination distances can shorten their network delay by traveling mainly along these express channels, thus reducing the average hop count. We recognize that besides its performance beneﬁt, an express cube can also reduce network power, since it reduces H , effectively removing intermediate router energy ER completely. By targeting H , and eradicating ER instead of lowering it as in the previous microarchitectural techniques, express cubes stand to reap the largest power savings. Figure 6(a) shows a 2-D torus augmented with express channels. Express nodes are those connected by both local and express channels. Non-express nodes are referred to as local nodes. Express interval is the distance in hops between two adjacent express nodes. Figure 6(b) compares the size of a local node and an express node. An express node has twice as many network ports as a local node, which implies double buffer space and a larger crossbar, so an express node consumes more power than a local node. We take this into account in our power modeling of express cubes. Power-performance analysis. Since the utilization of express channels heavily depends on network trafﬁc, cycleaccurate simulation is needed to obtain actual power savings. Here, we analyze the reduction of hop count as an approximation of potential energy and delay savings, so we can explore the trade-offs in the design space of express cubes. To simplify the analysis, we target ring topology. A normal ring with N nodes has average hop count H (cid:0) N 2 N is even, or H (cid:0) N1 if N is odd. For a ring augmented 4N 1 if 4 A e E e w n s N n S s W w B (a) A torus with express channels (shown bold), express interval is 2. (b) Comparison of a local node and an express node. Lower case letters represent local ports, upper case letters represent express ports. Figure 6. Express cube topology and microarchitecture. with express channels, we deﬁne the following routing algorithm: given source node S and destination node D, 1. For S, locate its two closest express nodes: SL and SR . If S itself is an express node, SL (cid:0) SR (cid:0) S. 2. For D, locate DL and DR in the same fashion. 3. Compute the hop counts of ﬁve routes: S (cid:2) SL (cid:2) DL (cid:2) D, S (cid:2) SL (cid:2) DR (cid:2) D, S (cid:2) SR (cid:2) DL (cid:2) D, S (cid:2) SR (cid:2) DR (cid:2) D and S (cid:2) D directly. For each step of the route, if both nodes are express nodes, the route takes only express channels, otherwise it takes only local channels. 4. The route with the minimum hop count is a shortest path. This routing algorithm is not very efﬁcient, but it guarantees ﬁnding a shortest path. By implementing this algorithm in C, we can compute the average hop count of an express ring and the reduction of the average hop count compared to a normal ring. Figure 7 shows some results. From the ﬁgure, we can see that express cubes have a wide range of hop count reduction (1060%). For a ﬁxed express interval, large networks tend to gain more beneﬁt from express cubes since express channels have a higher chance of being used. For a ﬁxed network size, the optimum express interval value lies between the smallest and largest valid interval values. This is because a large express interval can bypass more local nodes and yield more hop count reduction, but a large express interval also reduces the density of express nodes so that less trafﬁc can beneﬁt from them. N -dimensional express cube routing is not as simple as the combination of N orthogonal express ring routings. For a 2-D express cube, the routing algorithm needs to locate the four closest express nodes to the source/destination node Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  hop count reduction 70% 50% 30% 10% 64 32 16 ring size 8  2 4  4  32  16  8 express interval packet, 2 virtual channels per port and 16-ﬂit input buffer per virtual channel, and dimension-ordered routing. We assume that each virtual channel has a separate buffer, rather than two virtual channels sharing one buffer, to lower power consumption. We assume 1.2V voltage and 2GHz clock frequency at 0.1µm technology. The link length between adjacent nodes is 3mm. Based on the voltages suggested by [9, 25], we assume 300mV low-swing signaling for onchip links. This baseline conﬁguration is named net base, and conﬁgurations extended with power saving techniques are as follows: Figure 7. Relative hop count reduction of express cubes (cid:0) net seg: extends net base with 2-segment segmented crossbars. and then enumerate 17 routes to ﬁnd the shortest path. This also means more opportunities of hop count reduction. The dashed line in Figure 6(a) shows such an example, routing from node A to node B. This shortest path cannot be achieved by routing within one dimension, then another, but it does not lead to deadlocks as express channels and local channels belong to different virtual channels. Essentially, with the same express interval and same number of nodes per dimension, higher-dimensional express cubes can lead to larger hop count reduction. Impact on area. Both express channels and larger express nodes require more area. However, their area overhead can be partially compensated by reducing ﬂit size, and this is elaborated in the next section. 4 Simulation results 4.1 Experiment setup We evaluated the four power-efﬁcient network microarchitectures/architectures using our extension of Orion’s power models plugged into PoPNet, a publicly available C++ network simulator [16]. In our discussion below, packet latency is deﬁned as the number of cycles since the ﬁrst ﬂit of the packet is injected into the network until the last ﬂit of the packet is ejected from the network. 0-load latency is the packet latency when the network is not congested at all, i.e. packet injection rate is close to 0. Throughput has several different deﬁnitions in different contexts, we use the deﬁnition that throughput is the data rate where packet latency reaches double the 0-load latency. While we generally use energy as a metric in our analysis, in this section, we use average total power since it is more relevant for a whole system. Using Raw [20], TRIPS [14] and the on-chip network proposed in [9] as references, we deﬁne the baseline network as follows: 2-D torus topology, 128-bit ﬂits, 5 ﬂits per (cid:0) net cut: extends net base with cut-through crossbars. (cid:0) net wrt: extends net base with write-through buffers. (cid:0) net exp: extends net base with express channels (express interval = 2). We assume that router pipeline is not lengthened for express nodes. For a fair comparison, we keep network bisection bandwidth constant. Since every other channel is augmented with express channels, a ﬂit size of 128  2 3 (cid:0) 85 bits is used for express cubes to equalize bisection bandwidth with that of a 128-bit wide torus. Packet size thus needs to be adjusted to 1285 85 (cid:0) 7(cid:0)5 ﬂits so that each packet still contains the same number of bits. This is emulated by having 50% 7-ﬂit packets, and 50% 8-ﬂit packets. (cid:0) net all: extends net base with all four mechanisms, using express channels (express interval = 2), writethrough input buffers, 2-segment segmented crossbars in express nodes, and cut-through crossbars in local nodes. Flit size and packet size are adjusted as in net exp. By keeping bisection bandwidth constant, net exp uses the same link area as net base. According to the area model built in our power model, an express node as conﬁgured in net exp occupies 30% more area than a normal node as conﬁgured in net base. With express interval being 2, 25% of network nodes are express nodes, so net exp uses 7.5% more router area than net base, and the overall network area overhead is even less. Since the other three mechanisms have no or negligible negative area impact, net all has roughly identical area overhead as net exp. 4.2 Synthetic uniform random trafﬁc With uniform random trafﬁc, each node injects packets to any other node with same probability and same data rate. Figures 8(a) and 8(b) show average total network power of all conﬁgurations for an 88 and a 44 torus network Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE   0  2  4  6  8  10  12  14  0  0.5  1  1.5  2  2.5  3 packet injection rate (packet/cycle)  3.5  4 t o t a l o p w e r ( W ) net_base net_cut net_seg net_wrt net_exp net_all (a) 88 network power under random trafﬁc.  0  0.5  1  1.5  2  2.5  3  3.5  0  0.2  0.4  0.6  0.8  1  1.2  1.4 packet injection rate (packet/cycle)  1.6  1.8  2 t o t a l o p w e r ( W ) net_base net_cut net_seg net_wrt net_exp net_all (b) 44 network power under random trafﬁc. 5% 10% 15% 20% 25% 30% 35% 40% 45% 50% 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 packet injection rate (packet/cycle) o p w e r r c u d e i t n o net_seg net_cut net_exp net_all (c) 88 network power savings of 4 conﬁgurations. 4% 4.2% 4.4% 4.6% 4.8% 5% 5.2% 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 packet injection rate (packet/cycle) 1.8 2 o p w e r r c u d e i t n o net_wrt (d) 88 network power savings of net wrt.  20  40  60  80  100  120  140  160  180  0  0.5  1  1.5 packet injection rate (packet/cycle)  2  2.5 e v a r e g a l a t y c n e ( e c y c l ) net_base net_wrt net_exp net_all (e) 88 network latency under random trafﬁc.  20  25  30  35  40  45  50  55  60  65  0  0.2  0.4  0.6 packet injection rate (packet/cycle)  0.8  1 e v a r e g a l a t y c n e ( e c y c l ) net_base net_wrt net_exp net_all (f) 44 network latency under random trafﬁc. Figure 8. Network power/performance under uniform random trafﬁc. Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE                      respectively. Figure 8(c) shows power savings relative to net base of net seg, net cut, net exp and net all for the 88 torus network. Since net wrt has relatively low power savings, it is separately shown in Figure 8(d) with a small scale for better legibility. Figures 8(e) and 8(f) show average packet latency of all conﬁgurations for an 88 and a 44 torus network respectively. Power savings. From Figure 8(c), we see that both segmented crossbars and cut-through crossbars result in noticeable power savings (7% and 22% respectively), and their power savings stay relatively invariant as network size changes, as shown in Table 3. Cut-through crossbars have higher power savings than segmented crossbars, which matches our analysis. However, cut-through crossbars do not scale well beyond 44, so the two microarchitectures can be used complementarily. Write-through buffers only yield marginal power savings under uniform random trafﬁc for the following two reasons: (cid:1) We observe that in our baseline conﬁguration, input buffers consume 23% of total network power, less than crossbars (33%) and links (44%), so reduction in input buffer power does not translate to much total power reduction. (cid:1) When we derive the power saving upper bound in section 3.3, we assume large enough buffer size and no switch competition. Our baseline conﬁguration has moderate buffer size, and switch competitions reduce chances of bypassing, both leading to less power savings. Figure 8(d) shows the decreasing trend of write-through buffer power savings as packet rate increases, which implies more switch competitions. Express cube is the winner. It single-handedly reduces network power by 27% for a 44 torus and 36% for an 88 torus. From Figure 7, we see that the average hop count reduction of express cubes is greater at larger network size, so the 88 torus receives higher power savings. In Figure 8(a), express cubes have less power savings at high packet injection rates. This is because a network with express channels has larger saturation throughput, so the network can still sustain more trafﬁc, which leads to more power consumption, while the baseline conﬁguration is already saturated and its power consumption does not quite follow data rate increase. This phenomena is not obvious in Figure 8(b) because express channels are less effective for smaller networks. Applying the other three techniques to an express cube network does not give as much power saving as they do to the baseline network. Cut-through crossbar, segmented crossbar and write-through buffer together produce an additional 8-9% power reduction beyond what is achieved with just express cubes. This is because the following two reasons: (cid:1) Our analysis in section 3.4 shows that some techniques produce higher power savings with larger ﬂit sizes, and both net exp and net all have smaller ﬂit size than other conﬁgurations. (cid:1) Express cubes reduce H , the number of routers traversed by a packet. Since all other three mechanisms target ER , a lower H implies fewer opportunities to take advantage of them. Impact on performance. According to our analysis, segmented crossbars have no performance impact. Cutthrough crossbars have no performance impact either provided dimension-ordered routing is used. Express cubes reduce average latency by reducing average hop count, and write-through buffers can potentially improve performance by removing some buffer read operations. From Figures 8(e) and 8(f), we see that express cubes reduce 0-load latency by 23% for an 88 torus and by 3.3% for a 44 torus. These simulation results match our analysis in section 3.4 that express cubes have better performance improvements for larger networks. Write-through buffers have no noticeable performance improvement, which leads us to believe that the bypassing condition is rarely satisﬁed under uniform random trafﬁc. 4.3 Chip multiprocessor trafﬁc traces from the TRIPS benchmark suite We ran a set of network traces extracted from a suite of sixteen benchmarks executed on one tile of the TRIPS CMPs to see the impact of the four power-efﬁcient network microarchitectures/architectures on real trafﬁc. Our simulator models the fairly unique topology of TRIPS [14]. Power savings relative to net base are shown in Figure 9. The power savings of segmented crossbars and cut-through crossbars are almost invariant across all traces because they mainly depend on network conﬁgurations and are less trafﬁc dependent. On the other hand, the power savings of express cubes vary greatly from trace to trace because the utilization of express channels is largely correlated with trafﬁc patterns, which are determined by the applications. The power savings of write-through buffers vary slightly across traces, suggesting similar buffer occupancies across all traces. We are now conducting a more detailed investigation on the relations between the applications and the achievable power savings. Table 3 summarizes the power savings of all experiments. For uniform random trafﬁc, we use the average values of all data points before network congestion. Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE  50% 45% 40% 35% 30% 25% 20% 15% 10% 5% s g n v a s i r e w o p e v i t a e l r write-through buffer segmented crossbar cut-through crossbar express cube all adpcm ammp art bzip2 compress dct equake gzip hydro2d mcf mgrid mpeg2encodeparser swim tomcatv turb3d Figure 9. Power savings for network traces of the TRIPS benchmark suite. Table 3. Average total network power savings (relative to net base conﬁguration). 88 torus (random) 22.4% 7.2% 4.9% 36.3% 44.9% 44 torus (random) 21.6% 6.9% 4.5% 27.2% 36.3% TRIPS traces 20.4% 6.6% 3.8% 30.9% 37.9% net cut net seg net wrt net exp net all 5 Related work Power modeling. Patel et al. ﬁrst noted the need to consider power constraints in interconnection network design, and proposed a power model of routers and links [12]. Wang et al. developed architectural power models for interconnection network routers and built Orion [24], a powerperformance interconnection network simulator, which is used in this work as our power modeling framework. Low power component designs. Most prior low power designs focus on reducing link power because that dominates power in off-chip interconnection networks. In 2000, Zhang, George and Rabaey proposed low-swing on-chip links [25], and Lee, Dally and Chiang proposed novel low power link designs [11]. Many low power bus encoding techniques have also been proposed and can be readily used on network links. However, these encoding techniques may not be readily applied to router components such as buffers and crossbars whose wire lengths are short relative to links, and thus unable to offset the overhead of encoding/decoding circuitry. While most previously proposed low power designs are circuit level techniques, our work targets the problem at the network microarchitecture level. To the best of our knowledge, this direction has not been previously explored for interconnection networks. Clearly, circuits and architectural techniques are synergistic and can lead to larger combined power savings. Power management. Another dimension to lower power is to embed dynamic power management ability into routing and ﬂow control policies. Shang, Peh and Jha explored dynamic voltage scaling with links to reduce network power dynamically [17]. They also developed PowerHerd [18], a framework which maintains global power budgets dynamically, sharing power budgets between adjacent nodes so as to maximize network performance while not exceeding peak power constraints. Chen and Peh targeted leakage power instead, with power-aware buffers that dynamically shut off in response to changes in utilization [5]. 6 Conclusions Unlike prior approaches that are primarily performancedriven, in this paper we adopt a power-driven perspective towards the design of on-chip network microarchitectures. As systems interconnected with on-chip networks become increasingly power-constrained, it is critical that we explore power-efﬁcient network microarchitectures. We ﬁrst characterize the power proﬁle of the on-chip network designs of two CMPs – the MIT Raw [20] and the UT Austin TRIPS [14], demonstrating that on-chip networks take up a signiﬁcant percentage of total system power (36% in Raw). This motivated us to propose three powerefﬁcient router microarchitectures and investigate the power efﬁciency of an existing network architecture, evaluating their power-performance-area impact with detailed power modeling and probabilistic analysis. We then evaluated the proposed network microarchitectures with synthetic as Proceedings of the 36th International Symposium on Microarchitecture (MICRO-36’03)  0-7695-2043-X/03 $ 17.00 © 2003 IEEE      well as real CMP benchmark trafﬁc traces, realizing 44.9% power savings with uniform random trafﬁc, and 37.9% with TRIPS CMP traces as compared to a baseline network microarchitecture based on current on-chip network designs. This substantial power saving is obtained with no degradation in network performance, and even improved performance in some cases. Our study highlights the importance of a power-driven approach to on-chip network design. We will continue to investigate the interactions between trafﬁc patterns and onchip network architectures, and seek to reach a systematic design methodology for on-chip networks. Acknowledgments The authors would like to thank the MIT Raw group and the UT Austin TRIPS group for providing information on their on-chip networks and detailed benchmark traces. The authors would also like to thank all the anonymous reviewers for their invaluable comments. This work is partially funded by the DARPA MARCO Gigascale Silicon Research Center, NSF ITR grant CCR-0086031 and NSF CAREER grant CCR-0237540. "
2006,"""It's a small world after all"" - NoC performance optimization via long-range link insertion.","Networks-on-chip (NoCs) represent a promising solution to complex on-chip communication problems. The NoC communication architectures considered so far are based on either completely regular or fully customized topologies. In this paper, we present a methodology to automatically synthesize an architecture which is neither regular nor fully customized. Instead, the communication architecture we propose is a superposition of a few long-range links and a standard mesh network. The few application-specific long-range links we insert significantly increase the critical traffic workload at which the network transitions from a free to a congested state. This way, we can exploit the benefits offered by both complete regularity and partial topology customization. Indeed, our experimental results demonstrate a significant reduction in the average packet latency and a major improvement in the achievable network through with minimal impact on network topology",
2005,Key research problems in NoC design - a holistic perspective.,"Networks-on-Chip (NoCs) have been recently proposed as a promising solution to complex on-chip communication problems. The lack of an unified representation of applications and architectures makes NoC problem formulation and classification both difficult and obscure. To remedy this situation, we provide a general description for NoC architectures and applications and then enumerate several outstanding research problems (denoted by P1-P8) organized under three topics: communication infrastructure synthesis, communication paradigm selection, and application mapping optimization. Far from being exhaustive, the discussed problems are deemed essential for future NoC research.","Key Research Problems in NoC Design: A Holistic  Perspective Umit Y. Ogras, Jingcao Hu, Radu Marculescu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA {uogras,jingcao,radum}@ece.cmu.edu ABSTRACT Networks-on-Chip (NoCs) have been recently proposed as a promising solution to complex on-chip communication problems. The lack of an unified representation of applications and architectures makes NoC problem formulation and classification both difficult and obscure. To remedy this situation, we provide a general description for NoC architectures and applications and then enumerate several outstanding research problems (denoted by P1P8) organized under three topics: communication infrastructure synthesis, communication paradigm selection, and application mapping optimization. Far from being exhaustive, the discussed problems are deemed essential for future NoC research. Categories and Subject Descriptors J .6 [Computer Applications]: Computer-Aided Design – computer-aided design (CAD) . General Terms Algorithms , Performance , Design Keywords Systems-on-Chip, Multi-processor systems, Networks-on-Chip 1.  INTRODUCTION Emerging Network-on-Chip (NoC) designs consist of a number of interconnected heterogeneous devices (e.g. general or special purpose processors, embedded memories, application specific components, mixed-signal I/O cores) where communication is achieved by sending packets over a scalable interconnection network.  The design of NoCs trades-off several important choices, such as topology selection, routing strategy selection and application mapping to network nodes. Developing a design methodology for NoC-based communication poses novel and exciting challenges to the EDA community. While a handful of design problems have been recently addressed by several researchers [1-5], a formal presentation of the major research themes is still missing. Having such a unifying formalism available can not only catalyze the research towards improving the already existing solutions, but also inspire new solutions to many outstanding research problems in NoC design. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. CODES+ISSS’05, Sept. 19-21, 2005, Jersey City, New Jersey, USA. Copyright 2005 ACM 1-59593-161-9/05/0009…$5.00. Rather than simply surveying prior work, the objective of this paper is to debunk some fundamental issues in NoC design and, more importantly, provide a roadmap for future research. Due to space limitations, this paper focuses primarily on the design methodologies aimed at the architectural-level of abstraction, only touching upon tightly coupled physical-level issues in NoC design. This way, this paper creates the basis for followup work that could target precisely these other levels of abstraction to complete the picture of NoC design. To this end, we formally define a 3D design space that involves issues related  to communication  infrastructure synthesis, communication paradigm selection and application mapping optimization, then deal explicitly with each and every issue belonging to this problem space. In each case, we discuss motivation, problem formulation, proposed solutions and open research problems. The paper is organized as follows: First, we introduce a novel formalism for application and architecture description. Then, in sections 3, 4 and 5, we discuss several outstanding research issues and suggest some open problems that deserve further consideration. Finally, we analyze the interaction among these research ideas and summarize our main contribution.  2.  APPLICATION AND ARCHITECTURE  DESCRIPTION In this section, we propose an unified representation for NoC applications and architectures. At different stages in the design process (e.g. whether or not the application has been mapped, scheduled, etc.), the target application can be specified in one of the following two representations: Definition 1 A Communication Task Graph  (CTG) G ′ = G ′ T D,(  is a directed acyclic graph, where each vertex represents a computational module in the application referred to as task  t i T∈ . Each task  t i  is annotated with relevant information, such as execution time on each type of Processing Element (PE) in the network, task i energy consumption ( e j ) when executed on the j-th PE, individual task deadlines ( d l t i( ), periodicity of the task graphs, etc. Each directed arc D∈  between tasks  t i  and  t j characterizes either data or control dependencies. Each   has associated a value  , which stands for the communication volume (bits) exchanged between tasks  t i  and  t j . Definition 2 An Application Characterization Graph (APCG) G = G C A,  is a directed graph, where each vertex  c i C∈ represents a selected IP/core, and each directed arc  characterizes the communication process from core  c i  to core c j . Each   can be  tagged with application-specific information (e.g. communication volume, communication rate, etc.) and specific design constraints (e.g. communication bandwidth, latency requirements, etc.). Also, the size/shape of cores  c i C∈  is assumed to be known. v d i j, d i j, a i j, d i j, ( ) a i j, i ) ( ) ) ( ( ) ) ∀ ) ℜ Ω C( , , Compared to the CTG (Definition 1) which models applications at task- and communication transaction level, the APCG models the application at a coarser level, namely at IP/core level. Intuitively, the APCG can be derived from the CTG by binding and scheduling the tasks in the CTG onto different IPs. Based on these background definitions, we can now introduce a novel description for NoC architectures which is one of the contributions of this paper. Definition 3 Different NoC architectures can be uniquely described by the triple  ℵ A R C h, , where the components have the following meanings: • The directed graph A(R,Ch) describes the communication infrastructure; the routers (R) and the channels (Ch) in the network have attributes such as, c h( ) C h∈ , W(ch) gives the width of the ne twork channe ls  r R∈∀ , l(d,r) gives the input buffer size (depth) for the communication port d at router  r R∈ . r R∈∀ , P(r) specifies the posi tion of the router r. ℜ RD r s d ρ n( ) ) Sw, describes  the  communication paradigm adopted  in  the network.  RD r s d ρ n( ) , s d r R , n R⊆ , defines the routing policy at router r for all packets with source s and destination d. In this function,  denotes the utilization of the neighboring routers, which can be used by an adaptive algorithm. Finally, Sw specifies the packet switching technique implemented in the network. Ω : C R→  maps each core  c i C∈  to a router. For direct topologies, each router is connected to a core, while in indirect topologies some routers are connected only to other routers. We can regard the architectural choices in the design of NoCs as representing a 3D design space, where each component of the triple  ℵ A R C h,  defines a separate dimension. In the design automation community, design space exploration along each dimension has been performed to some extent without explicitly considering such a formalism. We present next a few approaches proposed to date and a number of open problems which are crucial for advancing the NoC research. ) ℜ Ω C( , , ρ n( ) ∈ • • ) ) ( , ( , , ( ( , , , , ) ( , ) 3. FIRST DIMENSION IN NOC DESIGN:  COMMUNICATION  INFRASTRUCTURE SYNTHESIS The  infrastructure  synthesis aims at determining  the communication architecture A(R,Ch), given a particular application characterized by  G = G C A,  or  G ′ = G ′ T D,( (definitions 1 and 2). This design problem can be divided into four separate subproblems (P1-P4) which are addressed next.  ( ) ) 3.1 P1: The Topology Synthesis Problem 3.1.1 Motivation The ability of  the network  to efficiently disseminate information depends largely on the underlying topology. Besides having a paramount effect on the network latency, throughput, area, fault-tolerance and power consumption, the topology plays an important role in designing the routing strategy and mapping the cores to the network nodes [6-15].  3.1.2 Problem Formulation Given an appl ica tion graph  G  (or  G ′ ), find the topology captured by A(R,Ch) which optimizes O(A,G), subject to the constraints specified by Const(A,G).  In this formulation, O(A,G) can be a metric for performance, area or reliability of the network, while the constraints Const(A,G) may be given by the amount of needed resources (e.g. area, wiring, etc.), bandwidth, and latency requirements imposed by the application. If the floorplan, channel lengths and widths are all known, more complex objective functions and/or constraints (e.g. power consumption, network latency, etc.) can also be utilized. 3.1.3 Proposed Approaches  The simplicity of grid-like structures, as opposed to the complexity of custom  topologies,  inspired many design approaches where a mesh network is chosen a priori. Once the topology is fixed, the design problem reduces to application mapping to the given topology, while exploring different routing options [6-9] (also sections 4, 5). Such an approach may not satisfy  the design objectives, or produce  infeasible solutions, for some applications. Consequently, towards a better design space exploration, a richer set of standard network topologies is considered and the best one is selected [11,12]. The highest degree of flexibility is provided by customized topology synthesis which is desirable for several reasons. First, for application-specific NoCs, the detailed understanding of the communication workload can be exploited for optimization purposes [13-15]. Moreover, if the size/shape of the cores varies a lot, regular topologies waste area. Finally, the communication requirements of the components can vary widely. Designing the network to meet the requirements of highly communicating cores typically results in severe under utilization of other components, while designing it for average case may result in severe performance bottlenecks [10].  3.1.4 Open Problems Generally speaking, de termining the optimal topology to implement any given appl ica tion does not have a known theoretical solution. Al though the synthesis of custom ized architectures is desirable fo r improved performance , power consumpt ion and reduced area , al tering the regular grid-l ike structure brings into the picture significant implementation issues , such as floorplanning , uneven wire lengths (hence, poorly controlled electrical parame ters), etc. Consequent ly, ways to determine efficient topo logies that trade-off high-leve l performance issues against detailed implementa tion constra ints at micro- or nano-scale level need to be developed.  3.2 P2: The Channel Width Problem 3.2.1 Motivation [1] The width (W(ch)=W) of the network channels comes into the picture in a number of places. Firs t, the bandwidth of a network channel is given by  BW f c h W× = where fch is the channel operating frequency. Moreover, in the absence of contention, increasing W reduces the message latency (L0). For instance, for a message consisting of SP bits (assuming wormhole routing and a flit size of W, see Section 4.2), when the source and destination nodes are H hops away, L0 is given by,  ) SP L0 = H t r + + t s tL ) m a x t s + tL+( ------W where tr, ts and tL are the times needed to make the routing decision, traverse the router and link, respectively [16]. While these relations suggest increasing W, we note that this can have side effects such as increasing the area (Section 3.3.1).  [2] (   3.2.2 Problem Formulation  Given an appl icat ion graph  G  (or  G ′ ), and a communication architecture A(R,Ch), determine the individual channel widths such that • min(network latency)   and/or   max(network throughput) • subject to constraints  C o n s t A G, {area, total wire length, maximum wire length, power consumption, etc.}.  ) ⊂ ( 3.2.3 Proposed Approaches Besides the aforementioned area effects, the choice of W has implications on wire sizing and spacing which determine the channe l operat ing frequency. Hence, BW cannot be simply optimized by considering fch and W separate ly. Pileggi et . al . [25] discuss maximizing the channel throughput by controlling the number , size, and spac ing of wires. Yet another problem is the issue of parallel vs. serial links in NoCs [38] under power/area constra ints.  3.2.4 Open Problems The selection of the channel width in NoC design has not been addressed to date. Dally et. al in [3] project a data width of 256 bits, while current NoC prototypes [26] use only 32-bit channel widths. Besides determining the optimal channel width for a given application,  tools for analyzing various  trade-offs involving the channel width, subject to wiring and area constraints, are needed for a fair comparison between different communication architectures. 3.3 P3: The Buffer Sizing Problem 3.3.1 Motivation The input channel buffers at each router in the NoC have a serious impact on the overall area. For instance , by increasing the buffer size a t each input channel from 2 to 3 words, the router area of a 4x4 NoC increases by 30% or more . Thus, the overall use of buffering resources has to be minimized to reduce the implementation overhead in NoCs. At the same time, depending on the network workload, increasing the buffer size can reduce the network latency by orders of magnitude. However, due to the heterogeneity of traffic patterns in most application-specific NoCs, it makes sense to allocate more buffering resources only to the heavy loaded channels. Indeed, the values for average packet latency that can be obtained for the same total amount of buffering space are very different [24].  3.3.2 Problem Formulation Given: • Application communication characteristics defined by  G  (or G ′ ), such as packet injection rate at each IP, probability distribution of packet destinations, etc. • Architecture specific parameters, such as routing function, router arbitration delay, link delay, etc. and the total available buffering space  B . Determine: • Buffer size  l d r,(  for each input channel at each router in the network which minimizes the average packet latency. ) 3.3.3 Proposed Approaches The properties of on-chip buffers are studied in [22]. The authors report gate-level area estimates and analyze the performance of the network and buffers utilization across the network. Chandra et al. in [23] investigate the impact of FIFO sizing on the interconnect throughput for single source, single sink interconnect scenarios.  An efficient algorithm for the buffer size allocation problem is proposed [24]. The approach assumes deterministic or oblivious routing, store-and-forward or cut-through switching schemes, and a Poisson distribution for all packets injected in the network. Under these assumptions, the authors derive the blocking rate of each individual channel and then add more buffering resources only to the highly utilized channels. 3.3.4 Open Problems Although queuing  theory can help achieving significant performance improvements through smart buffer allocation, many problems remain to be solved. The critical issue is the development of appropriate performance models that support • NoCs with wormhole routing. Since the header flit and the payload  flits are  tightly coupled, deriving analytical performance models for NoCs under wormhole routing is a considerably more difficult problem. • Realistic traffic patterns. Since real applications exhibit traffic patterns (e.g. [29]) which are very different compared to the Poisson model,  the derivation of analytical models for performance evaluation becomes much more difficult. • NoCs with adaptive routing. Adaptive routing is more difficult to analyze due to the increased traffic uncertainties. 3.4 P4: The Floorplanning Problem 3.4.1 Motivation Due to the ir predictabi li ty , the communicat ion architectures based on mesh or torus topologies a lleviate the need to dea l explic itly wi th issues at physical-level. However, if the size of the t iles in the ne twork varies a lot , or arbi trary topologies are used , dealing with a floorplanning step becomes inevitable. 3.4.2 Problem Formulation ( , , ( ) Ω C(  and the sizes of the cores, Given A(R,Ch), a mapping  find a floorplan such that • min( O A C Ω C( {area, total wire length, etc.}) • subject to constraints  C o n s t A G, {area, total wire length, maximum wire length, etc.}.  ) ⊂ ) ⊂ ) 3.4.3 Proposed Approaches & Open Problems Floorplanning for NoCs needs to consider placement of routers and repeaters for  latency  insensitive operation [10,36]. Furthermore, the routablity of the global network channel for maximum performance and well-controlled coupling effects needs to be taken into account. Floorplanning for regular topologies is addressed in [37]. Likewise, integrating the floorplanning with an application mapping algorithm is discussed in [11]. However, the floorplanning problem for arbitrary network topologies remains an open problem. 4. SECOND DIMENSION IN NOC DESIGN:  COMMUNICATION PARADIGM  SELECTION The communication infrastruc ture alone does not capture the dynamic behavior of the network; this is determined by the commun ica tion traff ic . The traff ic f low is primarily governed by the communication paradigm, as de tailed in this section , and the implementation of the target appl icat ion, as discussed in Sec tion 5 (Figure 1).  Stochastic routing for fault-tolerance in NoCs has been discussed in [20,21]. These studies are mostly experimental so theoretical results, performance models and prototypes are needed to justify the promise and energy overhead caused by redundant packet dissemination.  A power-aware, adaptive routing strategy that regulates the routing decisions to satisfy peak power constraints is proposed in [19]. Besides sharing  the disadvantages of adaptive strategies, this approach does not address timing constraints, which are likely to coexist with power constraints. Hence, a power- and performance-aware technique is needed. 4.2 P6: The Switching Problem 4.2.1 Motivation A problem related to rout ing is the switching technique used in the network. The switching technique determ ines when the routing decisions are made , how the swi tches inside the routers are set /reset, and how the packe ts are transferred a long the switches [16] . Consequent ly , satisfying the constraints imposed by the application under different switching techniques results in trade-offs between implementation complexity (typically area) and performance. 4.2.2 Problem Formulation Given an application graph  G G ′  ( ), and a communication architecture A(R,Ch), determine  the switching  technique Sw ∈ {store-and-forward , cut-through , wormhole , etc .} • subject to  C o n s t A G, {end-to-end latency requirements, bandwidth requirements, area constraints, buffering and wiring resources, etc.} ) ⊂ ( 4.2.3 Proposed Approaches & Open Problems Among the commonly used switching techniques, wormhole switching seems to be the most promising one for typical NoC applications due to limited buffering resources and stringent latency requirements [3,6,7,31,32].  In data networks, wormhole routing is preferred to circuit switching due to the poor performance of the latter under dynamic traffic. However, for application-specific NoCs, this does not represent a major handicap. Moreover, guaranteed service operation, as required by some applications,  is relatively easier to satisfy by using circuit switching [33,34] as opposed to wormhole routing [31,32]. Therefore, circuit switching is a promising alternative, despite its implementation complexity and static nature. It remains to be seen whether or not a particular switching technique, or a hybrid combination [35], is more advantageous. 5. THIRD DIMENSION IN NOC DESIGN:  APPLICATION MAPPING  OPTIMIZATION The mapping problem aims at determ ining how to map an application onto the NoC pla tform, whi le certain metrics of interest (energy, performance, etc .) are optimized. Depending on the flexibi lity of the given NoC platform , the mapping problem may have different flavors as we discuss below. 5.1 P7: The Scheduling Problem 5.1.1 Motivation We use the term hard NoC to represent NoC platforms where both computation and communication have been pre-designed. Since such platforms offer no real flexibility for architectural Figure 1. Classification of design choices for  communication paradigm, similar to the one in [16]. 4.1 P5: The Routing Problem 4.1.1 Motivation An important problem in NoC design is deciding the type of routing; indeed, this greatly affects the ne twork performance and power consumption [16-19] . Moreover, more complicated routing strategies result in larger design. Hence , this introduces interest ing trade-offs be tween area and performance . 4.1.2 Problem Formulation ( , , , ) ) ρ n( ) O ℜ( Given an applicat ion graph  G  (or  G ′ ), a communication architecture A(R,Ch), the source and destination routers , find a decision function at router r,  RD r s d ρ n( ) , for selecting an output port to route the current packe t(s), while achieving a certa in objective function  .   above represents the utilization of the channels connected to the routers in the set  n R⊆ , or the input buffers in those routers. Note that oblivious routing functions do not need  this information, while adaptive algorithms usually check the congestion in the immediate neighbors. The routing decision can be solely based on local information, as well as on the global connectivity of the network specified by A(R,Ch). The objective function   can be selecting the minimal routing paths, avoiding congestion (while producing minimal paths or dropping minimal path requirement), avoiding deadlock, maintaining uniform power consumption across routers, improving fault-tolerance, etc. O ℜ( ) 4.1.3 Proposed Approaches & Open Problems Implementation complexity and performance requirements are two ma jor concerns  in se lect ing  the rout ing s trategy. Compared to adaptive rout ing, determin istic rout ing requires less resources while guaranteeing an orderly packet arrival . On the other hand, adaptive rout ing provides better throughput and lower latency by allowing alternate paths based on the ne twork congest ion [18] . However , out-of-order message arriva l remains an  important problem associated with adapt ive algorithms. Freedom from deadlock and livelock [16] are also cruc ial for NoCs, since deadlock (l ivelock) de tect ion and recovery mechanisms are expensive and they may lead to unpredictable de lays . Determ inistic and partially adaptive algorithms based on the turn mode l [17] , guarantee free deadlock and  livelock operation , whi le  fully adapt ive strategies require extra precaution.  Deterministic routing is also more appropriate if the traffic generated by the application under consideration is predictable. Being so application dependent, the routing algorithm can indeed be customized (e.g. routing table allocation [6], traffic splitting [7], etc.) to match the application traffic pattern.  customization, the mapping issue reduces to solving the communication and task scheduling problems. Although the scheduling problem is a traditional topic in computer science, most previous work neglects the interprocessor communication. Alternatively, it assumes a fixed delay proportional to the communication volume, without taking into consideration subtle effects (e.g. communication congestion) which change dynamically  throughout  tasks execution. Thus, the scheduling problem remains an important problem for NoC design. 5.1.2 Problem Formulation , ( A simple but important category of problems is off-line static scheduling. To this end, we first give the definition of Architecture Characterization Graph by extending Definition 3 to include the behavior of the computational nodes. Then, we formulate  the problem of energy-aware scheduling  for heterogeneous NoCs under deterministic routing.  Definition 4 A NoC Architecture Characterization Graph (ACG)  can be uniquely described by  the 4-tuple ℵ C A R C h, . Here  C  represents the set of cores/PEs in the NoC, while  A R C h, ,   and   remain the same as in Definition 2. Let   denote the energy required to send one bit from PE  C i  to  C j . Using these definitions, the energy-aware scheduling problem for heterogeneous NoCs is formulated as: Given a CTG ( G ′ ) and an ACG, find a mapping  M ( )  from the set of tasks ( T ) to the set of PEs ( C ), together with a starting time for each task and communication transaction, which minimizes. e rC i C j ) ℜ Ω C( , , ) ℜ Ω C( ) ) ( ) ( ( ) , m i n E n e r g y ⎧ ⎨ ⎩ = eM t i( ) i + ∑ t i∀ ∑ d i j,∀ v d i j, ( ) e× ( rM t i( ) M t j( , ) ) ⎫ ⎬ ⎭ [3] such that • All the control and data dependencies are satisfied. • All tasks  t i  for which individual deadlines  d l t i(  are specified finish execution before or at their respective deadlines. ) 5.1.3 Proposed Approaches Architectural support for compile-time scheduling for on-chip communication is presented in [26]. This approach optimizes data transfers that can be determined at compile-time using scheduling, and provides a software-based dynamic routing. An algorithm for the energy minimization problem is proposed in [27]. The algorithm first allocates more slack to those tasks which have a larger impact on energy consumption and performance. A level-based scheduling mechanism is then used to schedule the tasks and communication transactions in parallel. Finally, a search and repair procedure iteratively improves the solution by fixing possible deadline misses in the schedule generated by the first two steps.  5.1.4 Open Problems The algorithm in [27] targets real-time or DSP applications where the worst-case task execution time and inter-task communication volume are pre-characterized. Thus, such applications can be modeled as CTGs which expose the inherent inter-node parallelism existing in the application. However, such a fully static scheduling, can not be directly applied to applications containing conditional branches [28]. When applications behavior can not be predicted at compile time, on-line scheduling approaches are usually needed. Significant work is needed to develop efficient performanceand energy-aware on-line scheduling algorithm for NoCs. 5.2 P8: The IP Mapping Problem 5.2.1 Motivation Another important category of NoC platforms, called firm NoCs in this paper, are those where the communication architecture has been pre-designed, but the designer can still decide how to embed different IPs onto different tiles that act as placeholders in the architecture. More precisely, given an application described by a set of concurrent tasks, already bounded and scheduled onto a list of selected IPs, the problem is to determine how to topologically map the selected IPs onto the network, such that certain metrics of interest are optimized.  To optimally use a firm NoC platform,  the  task and communication scheduling/binding and the IP mapping should be ideally performed in parallel. However, such a task would be too complex in practice. Therefore, the task and communication scheduling/binding can be fixed before the IP mapping stage and then, the results after mapping can be used as feedback to further tune the scheduling and binding.  5.2.2 Problem Formulation ) ( ) ( ⊆ Given an APCG,  G = G C A, , and a network architecture A R C h, , determine a mapping  Ω : C R→  such that: • min(O(A,G) {energy, performance, thermal behavior, faulttolerance etc.}) • subject to  C o n s t A G, requirements, etc.} • each IP/core  c i C∈ {area, bandwidth and/or latency  is mapped to a router  r R∈ ) ⊆ ( , 5.2.3 Proposed Approaches IP mapping for regular NoCs is addressed by Hu et. al. [6] where a branch and bound algorithm is proposed to map a given set of IPs onto a NoC architecture, while minimizing the total communication energy. Similarly, Murali et. al. [7] propose an efficient mapping algorithm for NoC architectures which supports traffic splitting. These techniques use the average packet hop value as a cost function by relating it to the communication energy consumption [6] or communication cost [7]. Multi-objective mapping to mesh-based NoC architectures is discussed in [9]. If the IPs have different sizes, the communication latency and power consumption (per data unit) between any two neighboring routers may differ significantly. To calculate the energy or latency, it is therefore necessary to embed the floorplanning right inside the mapping loop in order to get better results at the expense of increased complexity [11]. With the increasing power density and cooling costs, it is important to reduce, or even eliminate, the potential hotspots and obtain a thermally-balanced design. In [8], a genetic algorithm is proposed to design a thermal balanced design while minimizing the communication cost via placement. 5.2.4 Open Problems Simulation is, in general, too costly to use in an optimization loop, so a key component to have in solving the IP mapping problem is a good analytical model for performance evaluation. Depending on the optimization objective, different analytical models may be needed. For instance, for communication energy minimization, an accurate energy model is essential. An energy model based on average packet hop is presented in [6], but other models are required if the underlying architecture (e.g. for irregular architectures) or the optimization objective changes (e.g. IP mapping to maximize performance). Nevertheless, there are no good analytical models readily available to use for performance-aware mapping since, compared to energy models, deriving a good performance model is much more difficult. The 8. "
2011,Design Issues and Considerations for Low-Cost 3-D TSV IC Technology.,"In this paper key design issues and considerations of a low-cost 3-D Cu-TSV technology are investigated. The impact of TSV on BEOL interconnect reliability is limited, no failures have been observed. The impact of TSV stress on MOS devices causes shifts, further analysis is required to understand their importance. Thermal hot spots in 3-D chip stacks cause temperature increases three times higher than in 2-D chips, necessitating a careful thermal floorplanning to avoid thermal failures. We have monitored for ESD during 3-D processing and have found no events take place, however careful further monitoring is required. The noise coupling between two tiers in a 3-D chip-stack is 20 dB lower than in a 2-D SoC, opening opportunities for increased mixed signal system performance. The impact on digital circuit performance of TSVs is accurately modeled with the presented RC model and digital gates can directly drive signals through TSVs at high speed and low power. Experimental results of a 3-D Network-on-Chip implementation demonstrate that the NoC concept can be extended from 2-D SoC to 3-D SoCs at low area (0.018 ) and power (3%) overhead.",
2002,An Interconnect Architecture for Networking Systems on Chips.,"Network processor systems on chips meet the speed and flexibility requirements of next-generation internet routers. The octagon on-chip communication architecture, with its cost, performance, and scalability advantages, supports these network processor SOCs.",
2003,A Two-step Genetic Algorithm for Mapping Task Graphs to a Network on Chip Architecture.,"Network on Chip (NoC) is a new paradigm for designing core based System on Chip which supports high degree of reusability and is scalable. In this paper we describe an efficient two-step genetic algorithm that has been used to build a tool for mapping an application, described by a parameterized task graph, on to a NoC architecture with a two dimensional mesh of switches as a communication backbone. The computational resources in NoC consist of a set of heterogeneous IP cores. Our algorithm finds a mapping of the vertices of the task graph to available cores so that the overall execution time of the task graph is minimized. We have developed a NoC architecture specific communication delay model to estimate the execution time. Our algorithm is able to handle large task graphs and provide near optimal mapping in a few minutes on a PC platform. Our tool also provides facilities for specifying NoC architecture, generation and viewing synthetic task graphs and viewing the progress of the genetic algorithm as it converges to a solution.",
2003,SoCBUS - Switched Network on Chip for Hard Real Time Embedded Systems.,"With the current trend in integration of more complex systems on chip there is a need for better communication infrastructure on chip that will increase the available bandwidth and simplify the interface verification. We have previously proposed a circuit switched two-dimensional mesh network known as SoCBUS that increases performance and lowers the cost of verification. In this paper, the SoCBUS is explained together with the working principles of the transaction handling. We also introduce the concept of packet connected circuit, PCC, where a packet is switched through the network locking the circuit as it goes. PCC is deadlock free and does not impose any unnecessary restrictions on the system while being simple and efficient in implementation. SoCBUS uses this PCC scheme to set up routes through the network. We introduce a possible application, a telephone to voice-over-IP gateway, and use this to show that the SoCBUS have very good properties in bandwidth, latency, and complexity when used in a hard real time system with scheduling of the traffic. The simulations analysis of the SoCBUS in the application show that a certain SoCBUS setup can handle 48000 channels of voice data including buffer swapping in a single chip. We also show that the SoCBUS is not suitable for general purpose computing platforms that exhibit random traffic patterns but that the SoCBUS show acceptable performance when the traffic is mainly local.",
2006,Linear-programming-based techniques for synthesis of network-on-chip architectures.,"Application-specific system-on-chip (SoC) design offers the opportunity for incorporating custom network-on-chip (NoC) architectures that are more suitable for a particular application, and do not necessarily conform to regular topologies. This paper presents novel mixed integer linear programming (MILP) formulations for synthesis of custom NoC architectures. The optimization objective of the techniques is to minimize the power consumption subject to the performance constraints. We present a two-stage approach for solving the custom NoC synthesis problem. The power consumption of the NoC architecture is determined by both the physical links and routers. The power consumption of a physical link is dependent upon the length of the link, which in turn, is governed by the layout of the SoC. Therefore, in the first stage, we address the floorplanning problem that determines the locations of the various cores and the routers. In the second stage, we utilize the floorplan from the first stage to generate topology of the NoC and the routes for the various traffic traces. We also present a clustering-based heuristic technique for the second stage to reduce the run times of the MILP formulation. We analyze the quality of the results and solution times of the proposed techniques by extensive experimentation with realistic benchmarks and comparisons with regular mesh-based NoC architectures.",
2003,SoCIN - A Parametric and Scalable Network-on-Chip.,"Networks-on-chip (NoCs) interconnection architectures, to be used in future billion-transistor systems-on-chip (SoCs), meet the major communication requirements of these systems, offering, at the same time, reusability, scalability and parallelism in communication. Furthermore, they cope with other issues like power constraints and clock distribution. Currently, there are a number of research works which explore different features of NoCs. In this paper, we present SoCIN, a scalable network based on a parametric router architecture to be used in the synthesis of customized low cost NoCs. The architecture of SoCIN and its router are described, and some synthesis results are presented.",
2006,ViChaR - A Dynamic Virtual Channel Regulator for Network-on-Chip Routers.,"The advent of deep sub-micron technology has recently highlighted the criticality of the on-chip interconnects. As diminishing feature sizes have led to increases in global wiring delays, network-on-chip (NoC) architectures are viewed as a possible solution to the wiring challenge and have recently crystallized into a significant research thrust. Both NoC performance and energy budget depend heavily on the routers' buffer resources. This paper introduces a novel unified buffer structure, called the dynamic virtual channel regulator (ViChaR), which dynamically allocates virtual channels (VC) and buffer resources according to network traffic conditions. ViChaR maximizes throughput by dispensing a variable number of VCs on demand. Simulation results using a cycle-accurate simulator show a performance increase of 25% on average over an equal-size generic router buffer, or similar performance using a 50% smaller buffer. ViChaR's ability to provide similar performance with half the buffer size of a generic router is of paramount importance, since this can yield total area and power savings of 30% and 34%, respectively, based on synthesized designs in 90 nm technology","ViChaR: A Dynamic Virtual Channel Regulator for Network-on-Chip Routers*  Chrysostomos A. Nicopoulos, Dongkook Park, Jongman Kim,  N. Vijaykrishnan, Mazin S. Yousif †, Chita R. Das  †Corporate Technology Group, Intel Corp.   Dept. of CSE, The Pennsylvania State University  University Park, PA 16802, USA  Hillsboro, OR 97124, USA   {nicopoul,dpark,jmkim,vijay,das}@cse.psu.edu  mazin.s.yousif@intel.com  Abstract  The advent of deep sub-micron technology has  recently highlighted  the criticality of  the on-chip  interconnects. As diminishing feature sizes have led to  increases in global wiring delays, Network-on-Chip  (NoC) architectures are viewed as a possible solution to  the wiring challenge and have recently crystallized into  a significant research thrust. Both NoC performance  and energy budget depend heavily on the routers' buffer  resources. This paper introduces a novel unified buffer  structure, called the dynamic Virtual Channel Regulator  (ViChaR), which  dynamically  allocates Virtual  Channels (VC) and buffer resources according to  network  traffic  conditions. ViChaR maximizes  throughput by dispensing a variable number of VCs on  demand. Simulation results using a cycle-accurate  simulator show a performance increase of 25% on  average over an equal-size generic router buffer, or  similar performance using a 50% smaller buffer.  ViChaR's ability to provide similar performance with  half the buffer size of a generic router is of paramount  importance, since this can yield total area and power  savings of 30% and 34%, respectively, based on  synthesized designs in 90 nm technology.   1. Introduction  Rapidly diminishing feature sizes into the nanoscale  regime have resulted in dramatic increases in transistor  densities. While gate delays are  scaling down  accordingly, wiring delays are, in fact, increasing; as  wire cross-sections decrease, resistance increases. This  undesirable behavior has transformed the interconnect  into a major hindrance. A signal would require multiple  clock cycles to traverse the length of a large System-onChip (SoC). To combat the delay issues emanating from  slow global wiring, researchers have proposed the use of  packet-based communication networks, known as  Networks-on-Chip (NoC) [1-4]. NoCs, much like macro  networks, can scale efficiently as the number of nodes  (i.e.  processing  elements)  increases. Besides  performance, current designs indicate an additional  alarming trend pertaining to the on-chip interconnect: the  * This research was supported in part by NSF grants CCR-0208734,  EIA-0202007,  CCF-0429631,  CNS-0509251,  CRI-0454123,  CAREER 0093085, SRC grant 00541, and a grant  from  DARPA/MARCO GSRC.  chip area and power budgets are increasingly being  dominated by the interconnection network [5-7]. As the  architectural focus shifts from monolithic, computationcentric designs to multi-core, communication-centric  systems, communication power has become comparable  to logic and memory power, and is expected to  eventually surpass them [6]. This ominous trend has  been observed by several researchers [1, 5, 8] and the  realization of its ramifications has fueled momentum in  investigating NoC architectures. Researchers have  proposed  sophisticated  router  architectures with  performance  enhancements  [9],  area-constrained  methodologies [7], power-efficient and thermal-aware  designs [5, 10], and fault-tolerant mechanisms [11].  It is known that router buffers are instrumental in the  overall operation of the on-chip network. However, of  the different components comprising the interconnection  fabric of SoCs, buffers are the largest leakage power  consumers in an NoC router, consuming about 64% of  the total router leakage power [12]. Similarly, buffers  consume significant dynamic power [8, 13] and this  consumption increases rapidly as packet flow throughput  increases [13]. In fact, it has been observed that storing a  packet in a buffer consumes far more energy than  transmitting the packet [13]. Furthermore, the area  occupied by an on-chip router is dominated by the  buffers [2, 14, 15]. Consequently, buffer design plays a  crucial role in architecting high performance and energy  efficient on-chip interconnects, and is the focus of this  paper.  1.1. Importance of Buffer Size and Organization  Decreasing the buffer size arbitrarily to reclaim  silicon area and minimize power consumption is not a  viable solution, because of the intricate relationship  between network performance and buffer resources.  Buffer size and management are directly linked to the  flow control policy employed by the network; flow  control,  in turn, affects network performance and  resource utilization. Whereas an efficient flow control  policy enables a network to reach 80% of its theoretical  capacity, a poorly implemented policy would result in a  meager 30% [16]. Wormhole flow control [17] was  introduced  to  improve performance  through finergranularity buffer and channel control at the flit level  instead of the packet level (a flit is the smallest unit of  flow control; one packet is composed of a number of              s t e k c a p o w T o t e u d d e k c o b l s C V w o l l a h s DDT DT D Remaining  buffer slots are  not utilized! Inefficient! Efficient! Efficient! Inefficient! H VC0 H VC1 VC v d e v r e s e r a s t e k c a p l l A DDT DT D H VC0 H VC1 Both packets  accommodated  by deep VCs DDT H VC0 HDDT VC1 Two packets  accommodated  by deep VCs DDT H VC0 HDDT VC1 Buffer slots  are fully  utilized DDT H VC v Buffer slots  are fully  utilized DDT H DDT H Remaining  packets  blocked due to  lack of VCs! (a) Light Traffic  Many/Shallow VCs  (b) Heavy Traffic  Many/Shallow VCs  (c) Light Traffic  Few/Deep VCs  (d) Heavy Traffic  Few/Deep VCs  Figure 1. Limitations of a Statically Assigned Buffer Organization (H=Head flit, D=Data/Middle flit, T=Tail flit)  flits). This technique relaxes the constraints on buffer  size at each router, allowing for a more efficient use of  storage space than store-and-forward and virtual cutthrough [18] switching. However, the channel capacity is  still poorly utilized; while the buffers are allocated at the  flit level, physical paths are still allocated at the packet  level. Hence, a blocked packet can impede the progress  of other packets waiting in line and may also cause  multi-node link blocking (a direct consequence of the  fact that the flits of a single packet are distributed across  several nodes in wormhole routers). To remedy this  predicament, Virtual Channel (VC) flow control [19]  assigns multiple virtual paths (each with its own  associated buffer queue) to the same physical channel. It  has been shown that VC routers can increase throughput  by up to 40% over wormhole routers without VCs [16].  As a side bonus, virtual channels can also help with  deadlock avoidance [20]. The work in this paper  assumes, without loss of generality, the use of VC-based  wormhole flow control, which suits the low buffer  requirements of NoC routers.  The way virtual channels – and hence buffers – are  organized within a router is also instrumental in  optimizing performance. The number of VCs per  physical channel and the VC depth are two parameters  that  form an elaborate  interplay between buffer  utilization, throughput and latency. Researchers in the  macro-network field have identified the decisive role of  virtual  channel organization  in overall  system  performance [21, 22]. Detailed studies of the relation  between virtual channels and network latency indicate  that for low traffic intensity, a small number of VCs can  suffice. In high traffic rates, however, increasing the  number of VCs is a more effective way of improving  performance than simply increasing the buffer depth  [22]. Under light network traffic, the number of packets  traveling through a router is small enough to be  accommodated by a limited number of VCs; increasing  the number of VCs yields no tangible benefits. Under  high traffic, many packets are contenting for router  resources; increasing VC depth will not alleviate this  contention because of Head-of-Line (HoL) blocking.  Increasing the number of VCs, though, will allow more  packets to share the physical channels. This dichotomy  in VC organization implies that routers with fixed buffer  structures will either be underutilized or will  underperform under certain  traffic conditions, as  illustrated in the examples of Figure 1. This figure  highlights  the weaknesses of statically-partitioned  buffers.  Since buffer resources come at a premium in  resource-constrained NoC environments (they consume  valuable power and silicon real-estate), it is imperative  to limit the buffer size to a minimum without severely  affecting performance. This objective function can only  be achieved through the use of efficient management  techniques which optimize buffer utilization. Since size  and organization are design-time decisions, they cannot  be dynamically changed during operation based on  observed traffic patterns. However, the use of a carefully  designed buffer controller can significantly affect the  efficiency of storing and forwarding of the flits.  Therefore, the throughput of a switch can be maximized  through dynamic and real-time throttling of buffer  resources.  1.2. A Dynamic Virtual Channel Regulator  Given the aforementioned significance of the NoC  buffers in the area, power and performance triptych, we  thereby introduce ViChaR∗: a dynamic Virtual Channel  Regulator, which dispenses VCs according to network  traffic. The ViChaR module is a very compact unit  operating at the granularity of one router input/output  port; therefore, a conventional 5-port NoC router would  employ five such units to oversee buffer management.  ViChaR's operation revolves around two intertwined  concepts which constitute  the  two  fundamental  contributions of this work:  (1) ViChaR uses a Unified Buffer Structure  (UBS), instead of individual and statically partitioned  First-In-First-Out (FIFO) buffers. While the unified  buffer concept is not new, in this work we are revisiting  the concept within the confinements of the strict resource  limitations of on-chip networks. This is the first attempt  to incorporate a unified buffer management in NoC  routers. The new flavor in our endeavor stems from a  fundamentally different implementation approach: we  introduce a novel, table-based design which provides  single-clock operation without incurring prohibitive  overhead. Most importantly though, it enables the use of  a flexible and dynamically varying virtual channel  management scheme, thereby replacing the conventional,  static resource allocation.  (2) ViChaR provides each individual router port  with a variable number of VCs, each of which is  dispensed dynamically according to network traffic  conditions. This translates into fewer but deeper VCs  ∗ The name ViChaR was intentionally chosen to echo the word Vicar,  who is someone acting as a substitute or agent for a superior.                                                                                        under light traffic, and more but shallower VCs under  heavy traffic. This attribute successfully marries two  contradicting buffer organizations, which are impossible  to combine in conventional, statically-allocated buffers.  Furthermore, ViChaR's dynamic allocation scheme  ensures a smooth continuum between these two extremes  (few/deeper VCs versus more/shallower VCs) as the  network intensity fluctuates.  The proposed ViChaR architecture and a generic  buffer architecture were synthesized  in 90 nm  technology. Area and power extracts indicate that a  modest overhead in area and power due to more  elaborate control logic in ViChaR is amortized by  greater area and power gains through the use of fewer  virtual channel arbiters. Thus, overall ViChaR allows for  4% area reduction and incurs a minimal 2% power  increase compared to an equal-size generic buffer  implementation. Further, simulations with a cycleaccurate NoC simulator under various traffic patterns  show that ViChaR reduces network latency by 25% on  average compared to a generic buffer of equal size.  Alternatively, ViChaR  can  achieve  the  same  performance as a conventionally buffered router by  using 50% less buffer space. This result is of profound  significance because it allows the designer to reduce the  buffer size by half without affecting performance. This  yields net area and power benefits of around 30% and  34%, respectively, over the entire NoC router.  The rest of the paper is organized as follows: a  summary of related work is presented in Section 2, the  proposed ViChaR architecture is analyzed in Section 3,  simulation results are discussed in Section 4, and the  concluding remarks are given in Section 5.  2. Related Work in Buffer Design  Interest in packet-based on-chip networks has rapidly  gained momentum over the last few years, and analysis  and optimization of on-chip interconnect architectures  have garnered great attention. In this section, we focus  solely on buffer related aspects. Within the realm of onchip buffer design, both size and organization have been  shown to be directly related to network performance  [14]. Buffer sizing in particular has been investigated in  [14, 15]. However, these papers adopt a static approach,  where optimal buffer sizes are pre-determined at designtime based on a detailed analysis of application-specific  traffic patterns. The sizing is optimal for only one  particular application and one hardware mapping.  However, a technique to dynamically alter the buffer  organization at run-time is more desirable for a general  purpose and reconfigurable SoC executing different  workloads. A dynamic scheme would maximize  utilization regardless of the traffic type in the NoC.  Centralized buffer organizations have been studied  extensively  in  the macro-network realm, but  the  solutions proposed are not amenable  to resource  constrained on-chip implementations. In particular, a  unified and dynamically-allocated buffer structure was  originally presented  in [23]  in  the form of  the  Dynamically Allocated Multi-Queue (DAMQ) buffer.  However, whereas the DAMQ architecture was part of a  single-chip communication coprocessor  for multicomputer systems, the proposed implementation in this  paper is aimed at area- and power-constrained, ultra-low  latency on-chip communication. This profoundly  affected our design considerations as follows:  (1) The DAMQ used a fixed number of queues (i.e.  virtual channels) per input port. Specifically, four queues  were used, one for each of three output ports and a local  processor interface. Consequently, all packets in the  same queue had to obey the FIFO order, i.e. all packets  in the same queue could still get stuck behind a blocked  packet at the head of the queue.  (2) The control logic of the DAMQ buffer was very  complex, relying on a system of linked lists to organize  the data path. These linked lists were stored in pointer  registers which had to be updated constantly. This  caused  a  three-cycle  delay  for  every  flit  arrival/departure, mainly because data had to be moved  between pointer registers, and a so-called ""free list"" had  to be updated (a linked list keeping track of available  buffer slots) [24]. This three-cycle delay – while  acceptable for inter-chip communication – would prove  intolerable in an on-chip router.  The DAMQ project spawned a few other designs,  which aimed to simplify the hardware implementation  and lower overall complexity. Two notable examples of  these designs were the DAMQ with self-compacting  buffers [25] and the Fully Connected Circular Buffer  (FC-CB) [26]. Both designs have less overhead than the  linked-list approach of [23] by employing registers,  which selectively shift some flits inside the buffer to  enable all flits of one VC to occupy a contiguous buffer  space. The FC-CB design [26] improves on [25] by  using a circular structure, which shifts in only one  direction and ensures that any flit will shift by at most  one position each cycle. However, the FC-CB has two  main disadvantages when applied to an on-chip network.  First, being fully connected, it requires a P2 x P crossbar  instead of the regular P x P crossbar for a P-input  switch. Such large and power-hungry crossbars are  unattractive for on-chip routers. Second, the circular  shifter allows an incoming flit to be placed anywhere in  the buffer and requires selective shifting of some parts of  the buffer while  leaving  the rest of  the buffer  undisturbed. This functionality  inflicts considerable  increases in latency, area and power over a simple, nonshifting buffer  implementation,  like  the proposed  ViChaR design. The overhead is due to the large  MUXes which are required between each buffer slot to  enable both shifting and direct input.  The circular-shift buffer of  the FC-CB was  implemented in Verilog HDL and synthesized in 90 nm  commercial TSMC libraries to assess its viability in onchip designs. The circular buffer implementation of the  FC-CB increases the datapath delay by 26% compared to  ViChaR's stationary (i.e. non-shifting) buffer. Increases  in datapath delay may affect the pipeline period in  deeply pipelined router designs; a longer period will  adversely affect throughput. Moreover, the FC-CB's  large MUXes incur an increase of approximately 18% in  buffer area. More importantly, though, the continuous  shifting of  the FC-CB buffer every clock cycle  (assuming continuous incoming traffic) increases the  dynamic power budget by 66%. Obviously,  this  overhead  renders  the  FC-CB  implementation  unattractive for on-chip applications. Finally, the FC-CB  still works with a fixed number of VCs, just like the  DAMQ design. In this paper, we will show that a  dynamically variable number of VCs optimizes  performance.  The notion of dynamically allocating VC resources  based on traffic conditions was presented in  [27],  through  the VCDAMQ and DAMQ-with-recruitregisters (DAMQWR) implementations. However, both  designs were coupled to DAMQ underpinnings; hence,  they employed the linked-list approach of the original  DAMQ, which is too costly for an on-chip network.  Nevertheless,  the work of  [27] highlighted  the  significance of dynamic allocation of buffer resources,  which forms the premise of the design proposed in this  paper.  Finally, the Chaos router [28] and BLAM routing  algorithm [29] provide an alternative technique to saving  buffer space. They employ packet misrouting, instead of  storage, under heavy load. However, randomized (nonminimal) routing may make it harder to meet strict  latency guarantees required  in many NoCs (e.g.,  multimedia SoCs). Moreover, these schemes do not  support dynamic VC allocation to handle fluctuating  traffic.  3. The Proposed Dynamic Virtual Channel  Regulator (ViChaR)  3.1. A Baseline NoC Router  A generic NoC router architecture [9] is illustrated in  Figure 2. The router has P input and P output  channels/ports. In most implementations, P=5; four  inputs from the four cardinal directions (North, East,  South and West) and one from the local Processing  Element (PE). The Routing Computation unit, RC, is  responsible for directing the header flit of an incoming  packet to the appropriate output Physical Channel/port  (PC) and dictating valid Virtual Channels (VC) within  the selected PC. The routing  is done based on  destination information present in each header flit, and  can be deterministic or adaptive. The Virtual channel  Allocation unit (VA) arbitrates amongst all packets  requesting access to the same VCs and decides on  winners. The Switch Allocation unit (SA) arbitrates  amongst all VCs requesting access to the crossbar and  grants permission to the winning flits. The winners are  then able to traverse the crossbar and are placed on the  respective output links. Simple router implementations  require a clock cycle for each component within the  router. Lower-latency router architectures parallelize the  RC, VA and SA using speculative allocation [30], which  predicts the winner of the VA stage and performs SA  based on that. Further, look-ahead routing can also be  employed to perform routing of node i+1 at node i.  These two modifications have led to two-stage, and even  single-stage [9], routers, which parallelize the various  stages of operation.  So far, as a result of scarce area and power resources  and ultra-low latency requirements, on-chip routers have  relied on very simple buffer structures. In the case of  virtual channel-based NoC routers, these structures  consist of a specified number of FIFO buffers per input  port, with each FIFO corresponding to a virtual channel.  This is illustrated in Figure 2. Such organization  amounts to a static partitioning of buffer resources.  Hence, each input port of an NoC router has v virtual  channels, each of which has a dedicated k-flit FIFO  buffer. Current on-chip routers have small buffers to  minimize their overhead; v and k are usually much  smaller than in macro networks [9]. The necessity for  very low latency dictates the use of a parallel FIFO  implementation, as shown in the bottom right of Figure  2. As opposed to a serial FIFO implementation [31], the  parallel flavor eliminates the need for a flit to traverse all  slots in a pipelined manner before exiting the buffer  [31]. This fine-grained control requires more complex  logic, which relies on read and write pointers to maintain  the FIFO order. Given the small sizes of on-chip buffers,  though, the inclusion of a parallel FIFO implementation  is by no means prohibitive. The buffers within an NoC  router can be  implemented as either registers or  SRAM/DRAM memory [32, 33]. However, given the  relatively small buffer sizes employed, it is more  reasonable to use small registers as buffers to avoid the  address decoding/encoding latencies of big memories  VC 1 VC v Crossbar (P x P) Routing  Computation  (RC) VC Allocator (VA) Switch  Allocator (SA) Credits  in VC Identifier Input  Port P I u p n t C e n n a h l 1 C r d e t i u o t Output  Channel 1 Output  Channel P Generic NoC Router Input  Port 1 VC 2 VC Identifier VC 1 F t i l 1 F t i l 2 F t i l 3 F t i l k VC 2 F t i l 1 F t i l 2 F t i l 3 F t i l k VC v F t i l 1 F t i l 2 F t i l 3 F t i l k Input  Channel P Input Port P F r o m A S o T C r a b s s o r One FIFO buffer per VC VC 1 Flit 1 Flit 2 Flit 3 Flit k Control Logic (Read/Write  Pointers) R d a e n o P i t e r W r t i e n o P i t e r From  Input  DEMUX o T O u t u p t M X U VC Identifier SA Control Parallel FIFO  Implementation I u p n t C e n n a h l P C r d e t i u o t VC0 H H H H VC1 VC2 VC3 Head-of-Line  (HoL) Blocking Blocked flits at the head of the queue block  following packets H H VC0 H H VC1 VC2 VC3 These slots  cannot be used  by other packets  (to avoid packet  mixing) DD DD DD Buffers are  underutlized H=Head flit, D=Data flit, T=Tail flit DD T D *Atomic buffer  allocation assumed *Non-atomic buffer  allocation assumed Figure 2. A Generic NoC Router Architecture  Figure 3. Limitations of Existing FIFO Buffers                                          and  the access  latencies associated with global  bitlines/wordlines [32]. To this extent, the NoC buffers  in this paper were implemented as registers.  FIFO buffers in statically assigned buffer structures  have two inherent disadvantages. First, a packet at the  head of a VC whose designated output port is busy will  block all subsequent packets in that VC from being  transmitted (assuming non-atomic buffer allocation)  even if their designated output ports are free. This Headof-Line (HoL) blocking can severely affect network  performance in congested conditions, similar to the  previously discussed DAMQ. This scenario is illustrated  at the top of Figure 3. Second, if only part of a packet  occupies a VC buffer at a given time, then any vacant  slots in that buffer cannot be reassigned to a new packet  for as long as that VC is reserved by the partial packet to  avoid packet/message mixing. Thus, a VC buffer may  only be occupied by a single header flit because the  remaining flits happen to be blocked in preceding routers  due to congestion. In such a scenario, the remaining free  slots in the buffer cannot be assigned to other packets  until the tail flit of the current packet releases the VC.  This attribute of FIFO buffers can lead to substantial  under-utilization of the buffers, as shown at the bottom  of Figure 3, and cripple network performance.  3.2. The ViChaR Architecture  Figure 4 illustrates the buffer organization of a  conventional NoC router (left) and our proposed  alterations (right). The crux of ViChaR is composed of  two main components: (1) the Unified Buffer Structure  (UBS), shown in Figure 4, and (2) the associated control  logic, called Unified Control Logic (UCL).  Figure 4 shows only one of the five sub-modules of  UCL, the Arriving/Departing Flit Pointer Logic. This  sub-module constitutes the interface between the UBS  and the UCL; the UCL controls the unified buffer (UBS)  through  the Arriving/Departing Flit Pointer Logic  module. A top-level block diagram of the entire ViChaR  architecture is shown in Figure 6. This figure illustrates  all  five of  the UCL  sub-modules:  (1)  the  Arriving/Departing Flit Pointers Logic, (2) the Slot  Availability Tracker, (3) the VC Availability Tracker, (4)  the VC Control Table, and (5)  the Token (VC)  Dispenser. The operation of each component and the  interaction between the UBS and its controlling entity  (the UCL) are described in detail in section 3.2.2. All  five modules function independently and in parallel,  which is of critical importance to the ultra-low latency  requirements of the router. The UCL components work  in tandem with the unified buffer (UBS), providing  dynamic allocation of both virtual channels and their  associated buffer depth. As illustrated in Figure 6, the  two main ViChaR components (UBS and UCL) are  logically separated into two groups: the unified buffer  (UBS) and  two of  the five UCL modules (the  Arriving/Departing Flit Pointers Logic and the Slot  Availability Tracker) are situated at the input side of the  router (i.e. to accept all incoming flits), while the  remaining modules of the control logic (UCL) are  responsible for the VC arbitration of all flits destined to  a particular output port. Based on incoming traffic and  information from the Slot and VC Availability Trackers,  the Token (VC) Dispenser grants VC IDs to new packets  accordingly. The VC Control Table is the central hub of  ViChaR's operation, keeping track of all in-use VCs and  a detailed status of the unified buffer (UBS). When flits  arrive and/or depart, the Arriving/Departing Flit Pointers  Logic controls the UBS's MUXes and DEMUXes in  accordance with the VC Control Table.  It is important to realize that the UBS is physically  identical  to  the generic buffer structure:  the v  independent k-flit FIFO buffers of a  traditional  implementation are simply logically grouped in a single  vk-flit entity (the UBS in Figure 4). Hence, other than  the control logic, there is no additional hardware  complexity, since the vk-flit UBS is NOT a large,  monolithic structure; it groups the existing buffers  together, and it is only through the use of its control  mechanism (the UCL) that the buffers appear as a  logically unified structure. As shown in Figure 4, UBS  retains the same number of MUXes/DEMUXes as the  generic implementation, i.e. one MUX/DEMUX per k  flits, to avoid large (and hence slower) components.  3.2.1. Variable Number of Virtual Channels. Whereas a conventional NoC router can support only a fixed,  statically assigned number of VCs per input port (namely  v, as shown in Figure 4), the ViChaR architecture can  have a variable number of assigned VCs, based on  C V 1 Flit 1 Flit 2 Flit 3 Flit k R d a e n o P i t e r W r t i e n o P i t e r VC Identifier SA Control C V v Flit 1 Flit 2 Flit 3 Flit k VC Identifier SA Control I u p n t E D M X U I u p n t o P t r P O u t u p t M X U Unified Buffer  Structure (UBS) Flit 1 Flit 2 Flit 3 Flit k Flit k+1 Flit k+2 Flit k+3 Flit vk VC Identifier SA Control I u p n t E D M X U I u p n t o P t r P O u t u p t M X U Flit 2k VC  Identifier SA  Control One DEMUX per k  buffer slots (just  like generic case )  to avoid oversized  components Generic Buffer Organization Proposed ViChaR Buffer Organization Parallel FIFO  Implement. Arriving/Departing Flit Pointers Logic Control Logic (R/W Pointers) Control Logic (R/W Pointers) R d a e n o P i t e r W r t i e n o P i t e r Part of  UCL Rest of UCL H H H H H H H H H H H H 1 2 3 4 vk k k k H H H H H vk in-use  VCs (1 slot/VC) v in-use VCs (k slots/VC) Between v  and vk in-use VCs H=Head flit ViChaR ’s UBS Figure 4. The Proposed ViChaR Architecture  Figure 5. Possible VC Configurations in ViChaR                                  Input Port P Logic For Output Port P (See Figure 7) (See Figure 7) Flit  In X U M E D t u p n I UBS X U M t u p t u O r a b s s o r C o T 1st Stage (Local) VC  Arbitration (VA) 2nd Stage  (Global) VC  Arbitration (VA) UCL VC Availability  Tracker VC Control Table Arriving/Departing  Flit Pointers Logic Slot Availability  Tracker Winners of 1st Stage  (Local) VA from other  Input Ports UCL-UBS  Control Signals Token (VC)  Dispenser Part of UCL From/To Other Input Ports Unified Control Logic (UCL) Figure 6. ViChaR Block Diagram (Only One of P Ports Shown Here)  network conditions. ViChaR assigns at most one packet  to each VC so as to enable fine flow control granularity;  on the contrary, the sharing of a single VC by multiple  packets can lead to situations where a blocked packet  impedes the progress of another packet which happens to  use the same VC (known as HoL blocking, as described  in Section 3.1). A vk-flit ViChaR structure can support  anywhere between v VCs (when each VC occupies the  maximum of k flits) and vk VCs (when each VC  occupies the minimum of 1 flit) at any given time under  full load. This variability in the number of in-use VCs is  illustrated in Figure 5. To aid understanding, each VC in  Figure 5 is shown to occupy a contiguous space in the  buffer (UBS); in reality, however, this may not be the  case because the UBS allows the VCs to include nonconsecutive buffer slots (this fact will be explained in  more detail in Section 3.2.2). Hence, the system can  support a variable number of in-flight packets per port,  dynamically allocating new VCs when network  conditions dictate it. Dynamic variability in in-flight  messages can increase throughput under heavy traffic.  As a result of its unified buffer and dynamic  behavior, the ViChaR structure alters the Virtual channel  Allocation (VA) logic of the router. Since the router  function may return multiple output VCs restricted to a  single physical channel [30], two arbitration stages are  required in both the generic and ViChaR cases, as shown  in Figure 7. In the generic case, the first stage reduces  the number of requests from each input VC to one (this  ensures the request of a single VC at a particular output  port by each input VC). Subsequently, the winning  request from each input VC proceeds to the second  arbitration stage. Details of the VA operation are omitted  for brevity, but can be found in [30].  In the proposed ViChaR architecture, VA takes a  different approach due to the dynamic VC allocation  scheme: the first arbitration stage reduces the number of  requests for a particular output port to one request per  input port. The generic router (Figure 7(a)) requires v:1  arbiters, since the number of VCs supported is fixed to v.  ViChaR, on the other hand, supports anywhere between  v and vk VCs per port at any given time. To  accommodate the worst case scenario (i.e. vk in-flight  VCs), ViChaR needs larger vk:1 arbiters in stage 1 of the  allocation (Figure 7(b)). The second arbitration stage in  ViChaR produces a winner for each output port among  all the competing input ports. Therefore, while the  proposed ViChaR architecture uses larger Stage 1  arbiters (vk:1 vs. v:1), it uses much smaller and fewer  Stage 2 arbiters. The reason for the simplified second  stage is that ViChaR dynamically allocates VCs as  needed, instead of accepting requests for specific VCs  (which would necessitate one arbiter per output VC, just  like the generic case). It is this attribute that helps the  ViChaR implementation incur only a slight increase in  power consumption (and even achieve a small area  decrease), compared to a generic architecture, as will be  shown shortly.  The variable number of VCs supported by ViChaR  also necessitates bigger arbiters in the first stage of  Switch Allocation (SA), as shown in Figure 8. Similar to  VA, switch allocation is performed in two stages. The  first stage accounts for the sharing of a single port by a  number of VCs. Again, ViChaR needs larger vk:1  arbiters. The second stage arbitrates between  the  winning requests from each input port (i.e. P ports) for  each output port;  thus,  it  is  the same for both  architectures. The ViChaR overhead due to the bigger  stage-1 SA arbiters (illustrated in Table 1's detailed  breakdown) is almost fully amortized by the bigger  savings resulting from the smaller VA stage discussed  previously.  To analyze the area and power overhead, NoC  routers with (a) a generic buffer and (b) the proposed  ViChaR buffer were implemented in structural RegisterTransfer Level (RTL) Verilog and then synthesized in  Synopsys Design Compiler using a TSMC 90 nm  standard cell library. The resulting designs operate at a  supply voltage of 1 V and a clock frequency of 500  MHz. The routers have 5 input ports (i.e. P=5), 4 VCs  per input port (i.e. v=4), each VC is four-flit deep (i.e.  k=4), and each flit is 128 bits long. Both area and power  estimates were extracted from the synthesized router  implementations. A comparison of the area and power  overhead of the two schemes is shown in Table 1. Note  that both routers have equal buffer space (vk=16 buffer  slots per input port) for fairness. It is evident that while  ViChaR incurs an overhead in terms of control logic and  switch allocation  (SA),  this overhead  is overcompensated (in terms of area) by a larger reduction in  the VA logic. Thus, the ViChaR model provides area  savings of around 4%. In terms of power, ViChaR  consumes slightly more power (1.75%). This power  increase, however,  is negligible compared  to  the  performance benefits of ViChaR,  as will be  demonstrated in Section 4.          3.2.2. ViChaR Component Analysis. The key  challenges in designing ViChaR were to avoid (a)  deepening the router's pipeline, and (b) decreasing the  operating frequency. To circumvent the multi-cycle  delay induced by a linked-list approach [23] to ViChaR,  we opted  instead for a table-based approach, as  illustrated in Figure 10. This logic is required for each  output port in the router. Following is a break-down of  the control logic (UCL) sub-modules of the proposed  ViChaR architecture:  VC Control Table: The VC Control Table (see  Figure 10) forms the core of the control logic of  ViChaR. It is a compact table, holding the slot IDs of all  flits currently in the buffers, which are requesting the  particular output port (e.g. West). Note that since the  number of buffer slots in on-chip routers is resourceconstrained, the size of the table is minimal, as  demonstrated by the low overhead in the control logic in  Table 1. The VC Control Table is organized by VC ID,  with each VC having room for at most a single packet.  Without loss of generality, in this work we assumed a  packet to consist of four flits: a Head flit, two Data  (middle) flits, and a Tail flit. The packet size is assumed  to be constant, but the table can trivially be changed to  accommodate a variable-sized packet protocol. As seen  in the VC Control Table box of Figure 10 (right-hand  side), the VCs can include non-consecutive buffer slots  (e.g. VC1 comprises of slots 2, 4, 6 and 7) of the South  input port (i.e. flits arriving from the South). This  attribute allows full-flexibility in buffer utilization and  avoids the issues encountered in statically-allocated  buffers. VC3 only occupies one slot (10) in Figure 10. In  a static buffer, 3 additional slots would have to be  reserved for the remaining flits of VC3; those slots  would remain unused if the remaining flits happened to  be blocked in previous routers. Instead, in ViChaR those  slots can be used by other VCs, thus maximizing the  buffer utilization. Furthermore, the use of a table-based  controller makes the management of a variable number  of VCs very easy: non-used VCs are simply NULLed out  in the VC Control Table (e.g. VC4 in Figure 10).  Arriving/Departing Flit Pointers Logic: The Flit  Pointers Logic directly controls the Input and Output  MUXes/ DEMUXes of the unified buffer (UBS), as  illustrated in Figure 9, and is directly linked to the VC  Control Table module. Once a flit departs, its location in  the VC Control Table is invalidated by asserting a  NULL bit. There is a set of such pointers for each VC in  the table. However, the overhead is minimal due to the  simplicity of the pointer logic; both Departing and  Arriving Flit Pointers are implemented in combinational  logic and simply have to observe the non-NULL  locations in their VC. For example, the Departing Flit  pointer points at the first non-NULL location (in its  particular VC) starting from the left of the table, as  shown on the right side of Figure 10 for VC2 (in the VC  Control Table box). If all the entries in a single row of  the VC Control Table are NULL, then the VC must be  empty; thus, the pointer logic releases the VC by  notifying the VC Availability Tracker (Release Token  signal in Figure 9). When a new flit arrives, the pointer  logic guides the flit to the appropriate slot in the unified  buffer (UBS), based on the flit's VC ID and information  from the Slot Availability Tracker. Finally, newly  arrived header flits in the UBS can request an output VC  by first undergoing local (1st stage) arbitration (top right  of Figure 9), and then global (2nd stage) arbitration  (bottom left of Figure 10).  VC and Slot Availability Trackers: The VC  Availability Tracker simply keeps track of all the VCs in  the VC Control Table that are not used. The Token (VC)  Dispenser dynamically assigns VCs to new incoming  packets based on information provided by the VC  Availability Tracker. Similarly, the Slot Availability  Tracker keeps track of all the UBS slots which are not in  use. When a new flit arrives, it is stored into a slot  indicated by the Slot Availability Tracker. The VC and  Slot Availability Trackers are functionally identical.  They consist of a small table, as shown at the bottom  right of Figure 9 (Slot Availability Tracker) and the top  left of Figure 10 (VC Availability Tracker). Each row of  the table corresponds to one VC ID (in the VC  Availability Tracker) or one buffer slot (in the Slot  Availability Tracker). For each entry in the table, one bit  indicates that the VC/Slot is available (logic 1) or  occupied (logic 0). Both trackers have a pointer which  points to the top-most available entry. If all VCs are  occupied (i.e. all-zero table in the VC Availability  v:1 Arbiter 1 v:1 Arbiter v 1st stage arbiters I u p n t o P t r 1 Pv:1 Arbiter 1 Pv:1 Arbiter v O u t u p t o P t r 1 Pv:1 Arbiter 1 Pv:1 Arbiter v O u t u p t o P t r P v:1 Arbiter 1 v:1 Arbiter v I u p n t o P t r P 2nd stage arbiters One v:1 Arbiter  per Input VC (Total of Pv v:1  Arbiters) One Pv:1 Arbiter  per Output VC (Total of Pv Pv:1  Arbiters) vk:1 Arbiter 1 vk:1 Arbiter P 1st stage arbiters I u p n t o P t r 1 P:1 Arbiter O u t u p t o P t r 1 P:1 Arbiter O u t u p t o P t r P vk:1 Arbiter 1 vk:1 Arbiter P I u p n t o P t r P 2nd stage arbiters P vk:1 Arbiters  per Input Port (Total of P2  vk:1 Arbiters) One P:1 Arbiter  per Output Port (Total of P P:1  Arbiters) TableBased  Dynamic  VC  Arbitration (UCL) TableBased  Dynamic  VC  Arbitration (UCL) See Figure 10 v:1 Arbiter 1st stage arbiters I p n . o P t r 1 2nd stage arbiters One v:1 Arbiter  per Input Port (Total of P v:1  Arbiters) One P:1 Arbiter  per Output Port (Total of P P:1  Arbiters) v:1 Arbiter I p n . o P t r P P:1 Arbiter O u . t o P t r 1 P:1 Arbiter O u . t o P t r P vk:1 Arbiter 1st stage arbiters I p n . o P t r 1 2nd stage arbiters One vk:1 Arbiter  per Input Port (Total of P vk:1  Arbiters) One P:1 Arbiter  per Output Port (Total of P P:1  Arbiters) vk:1 Arbiter I p n . o P t r P P:1 Arbiter O u . t o P t r 1 P:1 Arbiter O u . t o P t r P (a) Generic Case [30]  (b) ViChaR Case  (a)  Generic Case  (b) ViChaR Case  Figure 7. Virtual Channel Arbitration (VA)  Figure 8. Switch Allocation (SA)                                                                          Tracker), the Token (VC) Dispenser stops granting new  VCs to requesting packets. Similarly, an all-zero table in  the Slot Availability Tracker implies a full buffer (UBS);  this is reflected in the credit information sent to adjacent  routers. The functionality of the VC/Slot Availability  Trackers is implemented in combinational logic, similar  to the Flit Pointers Logic described above.  Token (VC) Dispenser: The Token (VC) Dispenser  interfaces with the P:1 Arbiter and is responsible for  dispensing free VCs to requesting packets. VCs here are  like tokens; they are granted to new packets and then  returned to the dispenser upon release. The flow diagram  of the Dispenser's operation is illustrated on the righthand side of Figure 10. Based on information provided  by the VC Availability Tracker, the Token Dispenser  decides whether to grant a VC or not. The VC dispenser  keeps checking for possible deadlock situations among  the in-use VCs. Deadlocks may occur in networks which  employ adaptive routing schemes. If a pre-specified time  threshold is exceeded, the Token Dispenser can channel  an existing VC into one of the escape VCs to break the  deadlock. As a proof of concept of ViChaR's  functionality,  the experiments  in  this paper use  deterministic  (XY)  routing, which  is  inherently  deadlock-free. However, ViChaR was designed  to  operate under adaptive routing schemes as well.  Therefore, the Token (VC) Dispenser needs to account  for possible deadlock situations. Toward that extent, a  number of VCs can be designated as ""escape"", or ""drain""  channels to provide deadlock recovery in adaptive  routing  algorithms  (escape  channels  employ  a  deterministic routing algorithm to break the deadlock)  [34]. The Dispenser needs to switch deadlocked flits into  these escape channels if there is a need. One experiment  in Section 4.2 validates  the effectiveness of this  technique under adaptive routing.  Assuming that no deadlock situation exists, the  Token Dispenser can proceed with its normal operation.  The Dispenser grants new VCs on a First-Come-FirstServed (FCFS) basis; if a new header flit wins the VC  arbitration and the VC Availability Tracker indicates  that a free VC is available, then the new packet will be  granted a new VC. The Dispenser does not give priority  to flits of existing VCs. In principle, a more elaborate  mechanism could be used for dispensing new VCs,  which would monitor on-going traffic and reach a  decision based on some quantitative metric or prior  traffic history. However, given the highly restrictive  objective function of minimal area, power and latency  budgets in the design of on-chip networks, such complex  monitoring mechanisms were deemed infeasible. After  all, ViChaR was architected to operate within one clock  cycle. The use of an FCFS scheme in the Token  Dispenser turns out to be very efficient at maximizing  performance. The Dispenser is able to self-throttle the  dispensing of new VCs based on traffic conditions: if  more packets request a channel (high traffic) more VCs  are dispensed; if fewer packets are present (low traffic)  fewer VCs are granted and more buffer depth is allotted  to existing VCs.  ViChaR's Effect on the Router Pipeline: The  control logic (UCL) of ViChaR was designed in such a  way as to decouple the operation of the sub-modules  from each other. Thus, sub-modules are kept compact  and can all operate in parallel, hence completing the  entire operation in a single clock cycle. This is a  significant improvement over the three-clock cycle delay  of [23]. Figure 11 shows the pipeline stages of both a  generic and the ViChaR router pipelines. As previously  mentioned, the ViChaR architecture modifies the VA  and SA stages (Stages 2 and 3 in Figure 11). The darkcolored boxes indicate the components modified/added  in the ViChaR structure as compared to the generic case.  As shown in the figure, the additional hardware operates  in parallel without affecting the critical path of the  router. This fact is also verified by our studies of the  critical path delays of all major components of the router  architectures (extracted from the synthesized designs). In  both cases, the bottleneck that determines the minimum  clock period is the arbitration logic (for the VA and SA  stages, as shown in Figure 7 and Figure 8, respectively).  All the components of the ViChaR router remain within  the slack provided by the slower arbiters. Hence, the  ViChaR architecture does not affect the pipeline depth  or the clock frequency. Furthermore, since ViChaR does  not create any  interdependencies between pipeline  I u p n t E D M X U O u t u p t M X U UBS Arriving  Flit  Pointers Logic Departing  Flit  Pointers Logic NO YES o T C r a b s s o r Flit In empty VC? Next  Avail.  Slot Slot  Availability  Tracker C V I n e d i f i t e r Release  Slot Release  Token (VC) o T r s e t o f U n i f i d e C n o r t o l c g o L i ( C U L ) ( u g F i r e 0 1 ) vk:1 Arbiter 1 R s e u q e t s f o r O u t u p t o P t r 1 ( g e . . E s a ) t Grant 1 vk 1st stage arbiters  (Figure 7) Slot 0 1 2 vk-1 8 N x e t A a v . l i o S l t n o P i t e r Avail.? 0 0 0 1 1 Slot Avail. Tracker P C r d e t i s O u t Table 1. Area and Power Overhead of the ViChaR Architecture.  The results in this table assume equal-size buffers for both router  designs. However, ViChaR's efficient buffer management scheme  allows for a 50% decrease in buffer size with no performance  degradation (see Section 4). In such a case, area and power is  reduced by 30% and 34%, respectively, over the whole router.  Area (in µm2) Power (in mW)  12,961.16  5.36  54,809.44  15.36  27,613.54  8.82  6,514.90  2.06  101,899.04  31.60  10,379.92  5.12  54,809.44  15.36  38,958.80  9.94  2,032.93  0.64  106,181.09  31.06  - 4,282.05  + 0.54  4.03%  1.74%  SAVINGS  OVERHEAD  Component (one input port)  ViChaR Table-Based Contr. Logic  ViChaR Buffer Slots (16 slots)  ViChaR VA Logic  ViChaR SA Logic  TOTAL for ViChaR Architecture  Generic Control Logic  Generic Buffer Slots (16 slots)  Generic VA Logic  Generic SA Logic  TOTAL for Gen. Architecture  ViChaR Overhead / Savings  Figure 9.  The ViChaR UBS Architecture (One Input Port  Shown)                                                stages, it can also be used in speculative router  architectures which minimize the pipeline length.  4. Simulation Results  4.1. Simulation Platform  A cycle-accurate on-chip network simulator was used  to conduct detailed evaluation of the architectures under  discussion. The simulator operates at the granularity of  individual architectural components. The simulation testbench models  the pipelined  routers  and  the  interconnection links. All simulations were performed in  a 64-node (8x8) MESH network with 4-stage pipelined  routers. Each router has 5 physical channels (ports)  including the PE-router channel. The generic router  (shown as ""GEN"" in results graphs) has a set of 4 virtual  channels per port. Each VC holds four 128-bit flits (i.e. a  total of 5x4x4=80 buffer slots). The ViChaR router  (""ViC"" in results graphs) has a 16-flit unified buffer per  port (i.e. a total of 5x16=80 buffer slots, just like the  generic case). One packet consists of four flits. The  simulator keeps injecting messages into the network until  300,000 messages  (including 100,000 warm-up  messages) are ejected. Two network traffic patterns were  investigated: (1) Uniform Random (UR), where a node  injects messages into the network at regular intervals  specified by the injection rate, and (2) Self-Similar (SS),  which emulates  internet and Ethernet  traffic. For  destination node selection, two distributions were used:  (1) Normal Random (NR), and (2) Tornado (TN) [35].  In all cases, except one, deterministic (XY) routing and  wormhole switching were employed. One experiment  used minimal adaptive routing to evaluate the systems in  a deadlock-prone environment. Single link traversal was  assumed to complete within one clock cycle at 500 MHz  clock frequency. Both dynamic and leakage power  estimates were extracted from the synthesized router  designs and back-annotated into the network simulator.  4.2. Analysis of Results  Our simulation exploration starts with a latency  comparison between a conventional, statically assigned  buffer  architecture  and  the proposed ViChaR  implementation. We first assume that both designs have  equal-sized buffers; specifically, 16-flit buffers per input  port (i.e. a total of 80 flits per NoC router). In the  generic design (GEN), the 16 buffer slots are arranged as  4 VCs, each with a 4-flit depth. ViChaR (ViC), on the  other hand, can dynamically assign its 16 buffer slots to  a variable number of VCs, each with a variable buffer  depth. Figure 12(a) and Figure 12(b) show the average  network latency (in clock cycles) as a function of  injection rate (in flits/node/cycle) for Uniform Random  (UR) and Self-Similar (SS) traffic patterns, respectively.  The graphs include results for both Normal Random  (NR) and Tornado (TN) source-destination selection  patterns. In all cases, ViChaR substantially outperforms  the generic architecture; by 28% (NR) and 24% (TN) on  average for Uniform Random traffic, and 25% (NR) and  18% (TN) for Self-Similar traffic. More importantly,  though, ViChaR saturates at higher injection rates than  the generic case.  Figure 12(c) shows the buffer occupancy at injection  rates between 0.25 and 0.35 (i.e. before the onset of  saturation). Higher buffer occupancy indicates network  blocking. ViChaR is clearly much more efficient at  moving flits through the router; the buffer occupancy of  a 16-flit/port ViChaR design is considerably lower than  an equal-size static configuration. Buffer occupancy  alone, however, is not an indicative metric, since it does  not relay any information about network latency. To  validate ViChaR's highly efficient buffer management  scheme, its latency at these smaller buffer sizes should  also be investigated. To that extent, Figure 12(d) and  Figure 12(e) depict how the latency of ViChaR at  various buffer sizes compares to the latency of the  generic architecture with a fixed 16-flit/port buffer size.  It is evident from the graphs that the UBS can achieve  similar performance with less than half the buffer size of  VC ID VC 0 VC 1 VC 2 VC 3 VC 4 H D 0 1 2 4 N 9 10 N N N D T 3 5 6 7 11 N N N N N VC (vk-1) N N N N VC Avail.? 0 0 0 0 1 1 N x e t A a v . l i n o P C V i t e r VC 2 N 11 N 9 VC 2  Departing  Flit Pointer VC 2  Arriving  Flit Pointer VC Control Table A C V a v l i b a t i l i y T r e k c a r NULL Indicator  (denotes free slot) Slot ID H:   Head Flit D:   Data (middle) Flit T:   Tail Flit West VC ID VC 0 VC 1 VC 2 VC 3 VC 4 VC (vk-1) Token (VC) Dispenser VC Request Is Flit  Deadlocked? NO YES Escape  VCs Free? YES Grant  Escape VC Any VCs Free? NO YES NO Token (VC) Dispenser VC Availability Tracker VC Control Table P:1 Arbiter Grant Release Token (VC) [from Flit  Pointers Logic , Figure 9] Next Available VC ID of newly dispensed   VC 1 P A C V a v l i b a t i l i y S t a t s u Credits In (from adjacent router) F r o m / F o T t i l n o P i t e r d n a c g o L s i o S l t A a v l i b a t i l i y T r e k c a r ( u g F i r e 9 ) In Port East South West East N N 2nd Stage Arbiter (see Figure 7) Unified Control  Logic (UCL) Signals from/to Input Ports (UBS, Flit Pointers Logic, Slot  Availability Tracker) (see Figure 9) P Requests from 1st Stage Arbiters (see Figure 7) Grant VC NO VC  Grant Figure 10. ViChaR Table-Based UCL Architecture (Logic For One of P Ports Shown)  VC Arbitration Switch  Allocation (SA) Stage 2 Stage 3 G e n e r i c R u o t e r Slot Avail. Tracker C V i a h A R r h c t i c e t u r e VC Avail. Tracker Token (VC) Disp. VC Control Table VC Allocation Pointer Update of  each FIFO Buffer VC Arbitration Arriving/Departing  Flit Pointers Logic Routing  Computation  (RC) Stage 1 Crossbar Stage 4 Routing  Computation  (RC) Switch  Allocation (SA) Crossbar D a n y m i c A V S t a i t c A V Figure 11. Generic & ViChaR NoC Router Pipelines                                                the generic architecture. This is of profound importance,  since buffers dominate the area and power budgets of  NoC routers; reducing the buffer size by 50% will yield  significant savings. An alternative way to visualize this  phenomenon is illustrated in Figure 12(f). This graph  shows how the latency of ViChaR at various buffer sizes  compares to the latency of the generic architecture with a  16-flit/port buffer size (horizontal dashed line) at an  injection rate of 0.25. ViChaR has higher latency only  when its buffer size drops below 8 flits per port. On the  other hand, Figure 12(g) shows that decreasing the  buffer size in a generic, statically assigned buffer  structure always degrades performance.  Following on the very encouraging result that  ViChaR can achieve similar performance as a  conventional buffer by using only half the buffers,  Figure 12(h) shows the total average power consumption  of  the 8x8 MESH network for different buffer  configurations. For equally  sized configurations,  ViChaR consumes slightly more power  than a  conventional buffer structure. At injection rates up to  0.3, ViChaR consumes about 2% more power,  corroborating the results of Table 1. At higher injection  rates (when the network saturates), excessive switching  activity causes this difference to grow a bit more, even  though it never exceeds 5%. However, since ViChaR's  efficiency allows us to halve the buffer resources with no  discernible effect on performance, the overall power  drops by about 34% (ViC-8 in Figure 12(h)) for  equivalent performance. Similarly, the area occupied by  the router decreases by around 30%, based on synthesis  results. These decreases can lead to more power- and  area-efficient SoCs.  Figure 12(i) compares average network latency under  minimal adaptive  routing  to validate ViChaR's  effectiveness in handling deadlocks. Escape (drain)  channels, which employ deterministic (i.e. deadlockfree) routing, were used in both the generic and ViChaR  architectures to break deadlocks. Evidently, ViChaR was  able to handle all deadlock situations while significantly  outperforming the conventional design.  Figure 13(a) and Figure 13(b) present another metric  of network performance, namely throughput (in flits per  cycle). These graphs follow the same trend as the latency  experiments, with ViChaR clearly outperforming a  conventional buffer structure. Figure 13(c) includes the  throughput of two different (but of equal size) generic  configurations: 4 VCs each with a 3-flit depth, and 3  VCs with a 4-flit depth. The graph indicates that while  varying the statically-assigned VC configuration of a  0 20 40 60 80 1 00 1 20 1 40 1 60 1 80 2 00 0.0 5 0.1 0.15 0 .2 0 .25 0.3 0.3 5 0.4 0.45 0 .5 Injection Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) GEN-NR-16 V iC-NR-16 GEN-TN-16 V iC-TN-16 [Uniform Random] Buffer Size  (flits/port) (a) Average Latency (UR Traffic)  0 20 40 60 80 100 120 0.05 0.1 0 .15 0.2 0.25 0.3 0.35 0.4 0.45 0 .5 Inject ion Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) GEN-NR-16 V iC-NR-16 GEN-TN-16 V iC-TN-16 [Self-Similar] Buffer S ize  (flits/port) (b)  Average Latency (SS Traffic)  0 10 20 30 40 50 60 70 80 0.25 0.275 0.3 0.325 0.35 Inject ion Rate (flits/node/cycle) % B u f f e r O y c n a p u c c GEN-16 GEN-12 ViC-16 ViC-12 ViC-8 [Uniform Random] Buffer S ize  (flits/port) (c) % Buffer Occupancy  0 2 0 4 0 6 0 8 0 10 0 12 0 14 0 16 0 18 0 20 0 0.0 5 0 .1 0.1 5 0.2 0.2 5 0.3 0.3 5 0.4 0 .45 0.5 Inject ion Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) GEN-16 ViC-16 ViC-12 ViC-8 [Uniform Random] Buffer Size  (flits/port) (d) Avg. Latency for Diff. Buffer Sizes  (UR)  0 20 40 60 80 100 120 0 .05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0 .45 0.5 Injection Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) GEN-16 V iC-16 V iC-12 V iC-8 [Self-Similar] Buffer Size  (flits/port) (e)  Avg. Latency for Diff. Buffer Sizes  (SS)  0 20 40 60 80 100 120 140 6 7 8 10 12 14 16 ViChaR Buffer Size (flits/por t) a L t y c n e ( s e c y c l ) 50.49 - Generic (16 flits/port)  ViChaR  [Uniform Random] (Inj. Rate: 0.25) (f) ViChaR vs. Generic Efficiency (UR)  0 . 1 50 0 . 0 . 2 50 1 . 0 . 3 50 2 . 0 . 5 3 0 . 4 0 . 5 4 8 12 16 20 24 250 200 150 100 50 0 300 350 400 A g v . a L t y c n e ( s e c y c l ) Buffer Size  (flits/port)  Inj. Rate (flits/node/cycle) (g)   Avg. Latency for Diff. Generic Buff.  Sizes  0 1 2 3 4 5 6 7 8 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Inject ion Rate (flits/node/cycle) A g v . o P w e r C s n o . ( W ) GEN-16 ViC-16 ViC-12 ViC-8 [Uniform Random] Buffer S ize  (flits/port) (h)  Avg. Power Consumption  0 20 40 60 80 1 00 1 20 1 40 1 60 1 80 2 00 0. 05 0. 1 0 .15 0 .2 0.25 0 .3 0.3 5 0.4 0.4 5 0.5 Injection Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) GEN-NR-16 V iC-NR-16 GEN-TN-16 V iC-TN-16 [Uniform Random] Buffer Size  (flits/port) (i)  Average Latency under Adaptive  Routing (UR Traffic)  Figure 12. Average Latency, % Buffer Occupancy, and Average Power Consumption Simulation Results                                generic buffer does affect throughput, its performance  still trails that of the dynamically variable design of  ViChaR.  In the related work section (Section 2), we analyzed  in detail why the unified buffers of the DAMQ [23] and  FC-CB [26] would underperform compared to ViChaR's  dynamic design. Both the DAMQ and FC-CB structures  were implemented and incorporated into our cycleaccurate simulator. Figure 13(d) shows how all designs  fare against each other. DAMQ loses out because of its  3-cycle buffer delay, and its fixed number of VCs, as  previously explained. For a fair comparison, we assumed  that the FC-CB design completes its buffer management  procedure in one clock cycle (just like ViChaR). As seen  in Figure 13(d), at low injection rates, the FC-CB's  performance is almost identical to ViChaR's. However,  as network traffic increases, FC-CB's performance starts  to degrade compared to ViChaR. This is attributed to  FC-CB's fixed number of VCs (i.e. just like DAMQ).  Under heavier  traffic  loads, ViChaR's ability  to  dynamically dispense more VCs helps  improve  performance quite drastically. Note also that both FCCB and DAMQ would incur much higher area and  power penalties (as explained in Section 2). In terms of  throughput (not shown here), ViChaR's improvement  over DAMQ and FC-CB is a more modest 5% (on  average). However, ViChaR would perform substantially  better in latency-critical applications.  Finally, Figure 13(e) depicts the spatial variation in  the number of VCs used in the 8x8 MESH, while Figure  13(f) shows the temporal variation over simulation time.  The average number of VCs used varies continuously  according to network traffic. Figure 13(e) shows the  average number of VCs dispensed at each node of the  8x8 MESH network over the whole simulation time at an  injection rate of 0.25. As expected, the nodes situated at  the middle of the network exhibit higher congestion;  ViChaR successfully self-throttled its resources by  granting more VCs in these nodes in order to optimize  performance. In Figure 13(f), as the network fills up with  packets, the average number of VCs used over all nodes  increases accordingly to handle the traffic. These results  validate the effectiveness of our FCFS scheme employed  in the Token (VC) Dispenser (Section 3.2.2).  5. Conclusions  The continuing technology shrinkage into the deep  sub-micron era has magnified the delay mismatch  between gates and global wires. Wiring will significantly  affect design decisions in the forthcoming billiontransistor  chips, whether  these  are  complex  heterogeneous SoCs, or Chip Multi-Processors (CMP).  Networks-on-Chip (NoC) have surfaced as a possible  solution to escalating wiring delays in future multi-core  chips. NoC performance is directly related to the routers'  buffer size and utilization. In this paper, we introduce a  centralized buffer architecture, called  the Virtual  Channel Regulator  (ViChaR), which dynamically  allocates virtual channels and buffer slots in real-time,  depending on  traffic conditions. Unlike current  implementations, the ViChaR can dispense a variable  number of VCs at any given time to maximize network  throughput.  Simulation results using a cycle-accurate network  simulator indicate performance improvement of around  25% under various traffic patterns, as compared to a  conventional router with equal buffer size, with a modest  2% power increase. Most importantly, though, ViChaR  is shown to achieve performance similar to that of a  generic router, while using a 50% smaller buffer. This  attribute is a testament to ViChaR's efficient dynamic  buffer management scheme, and is a result of utmost  0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Injection Rate (flits/node/cycle) h T r u p h g u o t t i l f ( e c y c s / l ) GEN-16 ViC-16 ViC-12 ViC-8 [Uniform Random] Buffer S ize  (flits/port) (a) Throughput (UR Traffic)  0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0 .4 0.45 0.5 Injection Rate (flits/node/cycle) h T r u p h g u o t t i l f ( e c y c s / l ) GEN-16 V iC-16 V iC-12 V iC-8 [Self-Similar] Buffer Size  (flits/port) (b)  Throughput (SS Traffic)  0 5 10 15 20 25 0. 05 0.1 0.1 5 0.2 0.2 5 0.3 0.3 5 0 .4 0.45 0 .5 Inject ion Rate (flits/node/cycle) h T r u p h g u o t t i l f ( e c y c s / l ) GEN-12 (4x3) GEN-12 (3x4) V iC-12 [Uniform Random] 4 VCs, 3 flits/VC (c) Experimenting with Different Buff.  Sizes  0 2 0 4 0 6 0 8 0 10 0 12 0 14 0 16 0 18 0 20 0 0.0 5 0 .1 0 .15 0 .2 0. 25 0.3 0.35 0.4 0.45 0 .5 Injection Rate (flits/node/cycle) a L t y c n e ( s e c y c l ) ViC-16 DA MQ -16 FC-CB-16 [Uniform Random] Buffer Size  (flits/port) (d)  ViChaR vs. DAMQ [23] vs. FC-CB [26]  0 1 2 3 4 5 6 7 7 6 5 4 3 2 1 0 0 2 4 6 8 10 A g v . o # f C V s D i d e s n e p s Node X  Coordinate  Node Y  Coordinate (e)  ViChaR's Spatial Variation in # of  VCs  0 1 2 3 4 5 6 7 8 9 10 500 1000 1500 2000 2500 3000 3500 4000 4500 Simulation Time (cycles) A g v . N o . o f I n U e s C V s ViC-16 [Uniform Random] Buffer S ize  (flits/port) (f) ViChaR's Temporal Variation in # of  VCs  Figure 13. Simulation Results Demonstrating ViChaR's Efficient Virtual Channel Management Scheme                          significance in the NoC arena. Synthesized designs in 90  nm technology indicate that decreasing the ViChaR's  buffer size by 50% leads to area and power savings of  30% and 34%, respectively, with no degradation in  performance.  For  future work, we  intend  to evaluate  the  performance of ViChaR using workloads and traces  from existing System-on-Chip architectures.  6. "
2002,Chain - A Delay-Insensitive Chip Area Interconnect.,The increasing complexity of system-on-a-chip designs exposes the limits imposed by the standard synchronous bus. The authors propose a mixed system as a solution.,
2005,An Asynchronous NOC Architecture Providing Low Latency Service and Its Multi-Level Design Framework.,"The demands of scalable, low latency and power efficient system-on-chip interconnect cannot only be satisfied by point-to-point or shared-bus interconnects. In this paper, we propose a new asynchronous network-on-chip (NOC) architecture which provides low latency transfers. This architecture is implemented as a GALS system, where chip units are built as synchronous islands, connected together using a delay insensitive asynchronous network-on-chip topology. The proposed NOC protocol and its asynchronous implementation are presented as well as the multi-level modeling approach using SystemC language and transaction-level-modeling. Preliminary simulation results show that the asynchronous NOC can offer 5 Gbytes/s throughput in a 0.13 /spl mu/m CMOS technology.",
2007,A 4.6Tbits/s 3.6GHz single-cycle NoC router with a novel switch allocator in 65nm CMOS.,"As chip multiprocessors (CMPs) become the only viable way to scale up and utilize the abundant transistors made available in current microprocessors, the design of on-chip networks is becoming critically important. These networks face unique design constraints and are required to provide extremely fast and high bandwidth communication, yet meet tight power and area budgets. In this paper, we present a detailed design of our on-chip network router targeted at a 36-core shared-memory CMP system in 65 nm technology. Our design targets an aggressive clock frequency of 3.6 GHz, thus posing tough design challenges that led to several unique circuit and microarchitectural innovations and design choices, including a novel high throughput and low latency switch allocation mechanism, a non-speculative single-cycle router pipeline which uses advanced bundles to remove control setup overhead, a low-complexity virtual channel allocator and a dynamically-managed shared buffer design which uses prefetching to minimize critical path delay. Our router takes up 1.19 mm <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>  area and expends 551 mW power at 10% activity, delivering a single-cycle no-load latency at 3.6 GHz clock frequency while achieving apeak switching data rate in excess of 4.6 Tbits/sper router node.",
2011,Scalable Hybrid Wireless Network-on-Chip Architectures for Multicore Systems.,"Multicore platforms are emerging trends in the design of System-on-Chips (SoCs). Interconnect fabrics for these multicore SoCs play a crucial role in achieving the target performance. The Network-on-Chip (NoC) paradigm has been proposed as a promising solution for designing the interconnect fabric of multicore SoCs. But the performance requirements of NoC infrastructures in future technology nodes cannot be met by relying only on material innovation with traditional scaling. The continuing demand for low-power and high-speed interconnects with technology scaling necessitates looking beyond the conventional planar metal/dielectric-based interconnect infrastructures. Among different possible alternatives, the on-chip wireless communication network is envisioned as a revolutionary methodology, capable of bringing significant performance gains for multicore SoCs. Wireless NoCs (WiNoCs) can be designed by using miniaturized on-chip antennas as an enabling technology. In this paper, we present design methodologies and technology requirements for scalable WiNoC architectures and evaluate their performance. It is demonstrated that WiNoCs outperform their wired counterparts in terms of network throughput and latency, and that energy dissipation improves by orders of magnitude. The performance of the proposed WiNoC is evaluated in presence of various traffic patterns and also compared with other emerging alternative NoCs.","IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 1485 Scalable Hybrid Wireless Network-on-Chip Architectures for Multicore Systems Am lan Gangu ly, Member, IEEE, Kev in Chang, Student Member, IEEE, Su jay Deb, Student Member, IEEE, Partha Prat im Pande, Member, IEEE, Ben jam in Be lzer, Member, IEEE, and Chr istof Teuscher, Member, IEEE Abstract—Multicore platforms are emerging trends in the design of System-on-Chips (SoCs). Interconnect fabrics for these multicore SoCs play a crucial role in achieving the target performance. The Network-on-Chip (NoC) paradigm has been proposed as a promising solution for designing the interconnect fabric of multicore SoCs. But the performance requirements of NoC infrastructures in future technology nodes cannot be met by relying only on material innovation with traditional scaling. The continuing demand for low-power and high-speed interconnects with technology scaling necessitates looking beyond the conventional planar metal/dielectric-based interconnect infrastructures. Among different possible alternatives, the on-chip wireless communication network is envisioned as a revolutionary methodology, capable of bringing significant performance gains for multicore SoCs. Wireless NoCs (WiNoCs) can be designed by using miniaturized on-chip antennas as an enabling technology. In this paper, we present design methodologies and technology requirements for scalable WiNoC architectures and evaluate their performance. It is demonstrated that WiNoCs outperform their wired counterparts in terms of network throughput and latency, and that energy dissipation improves by orders of magnitude. The performance of the proposed WiNoC is evaluated in presence of various traffic patterns and also compared with other emerging alternative NoCs. Index Terms—Network-on-chip, multicore, wireless communication, on-chip antenna, small-world network. Ç 1 INTRODUCTION THE Network-on-Chip (NoC) paradigm has emerged as a communication backbone to enable a high degree of integration in multicore System-on-Chips (SoCs) [1]. Despite their advantages, an important performance limitation in traditional NoCs arises from planar metal interconnectbased multihop communications, wherein the data transfer between two distant blocks causes high latency and power consumption. To alleviate this problem, insertion of longrange links in a standard mesh network using conventional metal wires has been proposed [2]. Another effort to improve the performance of multihop NoC was undertaken by introducing ultralow-latency and low-power express channels between communicating nodes [3], [4]. But these communication channels are also basically metal wires, though they are significantly more power and delayefficient compared to their more conventional counterparts. According to the International Technology Roadmap for Semiconductors (ITRS) [5] for the longer term, improvements in metal wire characteristics will no longer satisfy . A. Ganguly is with the Department of Computer Engineering at Rochester Institute of Technology, Rochester, NY 14623-5603. E-mail: amlan.ganguly@rit.edu. . K. Chang, S. Deb, P.P. Pande, and B. Belzer are with the School of Electrical Engineering and Computer Science, Washington State University, Pullman, Washington 99164-2752. E-mail: {jchang, sdeb, pande, belzer}@eecs.wsu.edu. . C. Teuscher is with the Department of Electrical and Computer Engineering, Portland State University, PO Box 751, Portland, OR 97207-0751. E-mail: teuscher@pdx.edu. Manuscript received 8 May 2009; revised 30 Oct. 2009; accepted 8 June 2010; published online 10 Aug. 2010. Recommended for acceptance by R. Marculescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TC-2009-05-0201. Digital Object Identifier no. 10.1109/TC.2010.176. performance requirements and new interconnect paradigms are needed. Different approaches have been explored already, such as 3D and photonic NoCs and NoC architectures with multiband RF interconnect [6], [7], [8]. Though all these emerging methodologies are capable of improving the power and latency characteristics of the traditional NoC, they need further and more extensive investigation to determine their suitability for replacing and/or augmenting existing metal/dielectric-based planar multihop NoC architectures. Consequently, it is important to explore further alternative strategies to address the limitations of planar metal interconnect-based NoCs. Here, we propose an innovative and novel approach, which addresses simultaneously the latency, power consumption, and interconnect routing problems: replacing multihop wired paths in a NoC by high-bandwidth singlehop long-range wireless links. Over the last few years, there have been considerable efforts in the design and fabrication of miniature antennas operating in the range of tens of gigahertz to hundreds of terahertz, opening up the possibility of designing on-chip wireless links [9], [10], [11]. It is also predicted that the intrachip communication bandwidth achievable with conventional CMOS-based RF technology is not going to be sufficient [12]. Hence, the need to explore alternative technologies arises. Recent research has uncovered excellent emission and absorption characteristics leading to dipolelike radiation behavior in carbon nanotubes (CNTs), making them promising for use as antennas for on-chip wireless communication [11]. In this paper, the design principles of Wireless Network-on-Chip (WiNoC) architectures are presented. The performance benefits of these WiNoCs due to the utilization of high-speed wireless links are evaluated through cycle accurate simulations. On-chip wireless links 0018-9340/11/$26.00 ß 2011 IEEE Published by the IEEE Computer Society 1486 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 enable one-hop data transfers between distant nodes and hence reduce the hop counts in intercore communication. In addition to reducing interconnect delay, eliminating multihop long-distance wired communication reduces energy dissipation as well. In future, the number of cores in an SoC is expected to increase manifold. Consequently, it is imperative to have a scalable communication infrastructure without affecting system performance significantly. Our work proposes a scalable WiNoC architecture and evaluates its performance with respect to conventional wired NoCs. It is demonstrated that by utilizing the wireless medium efficiently, it is possible to minimize the effects of scaling up the system size on the performance of the WiNoCs. It is possible to create various configurations for the WiNoC depending on the number of available wireless channels and their placement in the network. All the different WiNoC architectures, considered in this paper, are shown to dissipate significantly less energy and to achieve notable improvements in throughput and latency compared to traditional wired NoCs. 2 RELATED WORK Conventional NoCs use multihop packet switched communication. At each hop, the data packet goes through a complex router/switch , which contributes considerable power , throughput, and latency overhead. To improve performance, the concept of express virtual channels is introduced in [3]. It is shown that by using virtual express lanes to connect distant cores in the network, it is possible to avoid the router overhead at intermediate nodes, and thereby greatly improve NoC performance in terms of power, latency, and throughput. Performance is further improved by incorporating ultralow-latency, multidrop on-chip global lines (G-lines) for flow-control signals [4]. In [2], performance of NoCs has been shown to improve by insertion of long-range wired links following principles of small-world graphs [13]. Despite significant performance gains, the schemes in [2], [3], [4] still require laying out long wires across the chip and hence performance improvements beyond a certain limit may not be achievable. The performance improvements due to NoC architectural advantages will be significantly enhanced if 3D integration is adopted as the basic fabrication methodology. The amalgamation of two emerging paradigms, namely NoCs and 3D ICs, allows for the creation of new structures that enable significant performance enhancements over traditional solutions [6], [14], [15]. Despite these benefits, 3D architectures pose new technology challenges such as thinning of the wafers, interdevice layer alignment, bonding, and interlayer contact patterning [16]. Additionally, the heat dissipation in 3D structures is a serious concern due to increased power density [16], [17] on a smaller footprint. There have been some efforts to achieve near speed-of-light communications through on-chip wires [18], [19]. Though these techniques achieve very low delay in data exchange along long wires, they suffer from significant power and area overheads from the signal conditioning circuitry. Moreover, the speed of communication is actually about a factor of one-half the speed of light in silicon dioxide. By contrast, on-chip data links at the true velocity of light can be designed using recent advances in silicon photonics [20], [21]. The design principles of a photonic NoC are elaborated in [6] and [21]. The components of a complete photonic NoC, e.g., dense waveguides, switches, optical modulators, and detectors, are now viable for integration on a single silicon chip. It is estimated that a photonic NoC will dissipate an order of magnitude less power than an electronic planar NoC. Although the optical interconnect option has many advantages, some aspects of this new paradigm need more extensive investigation. The speed of light in the transmitting medium, losses in the optical waveguides, and the signal noise due to coupling between waveguides are the important issues that need more careful investigation. Another alternative is NoCs with multiband RF interconnects [22]. Various implementation issues of this approach are discussed in [8]. In this particular NoC, instead of depending on the charging/discharging of wires for sending data, electromagnetic (EM) waves are guided along on-chip transmission lines created by multiple layers of metal and dielectric stack [22]. As the EM waves travel at the effective speed of light, low-latency and high-bandwidth communication can be achieved. This type of NoC too, is predicted to dissipate an order of magnitude less power than the traditional planar NoC with significantly reduced latency. On-chip wireless interconnects were demonstrated first in [23] for distributing clock signals. Recently, the design of a wireless NoC based on CMOS Ultra-Wideband (UWB) technology was proposed [24]. The particular antennas used in [24] achieve a transmission range of 1 mm with a length of a die area of 20 mm  20 mm, this architecture essentially 2.98 mm. Consequently, for a NoC spreading typically over requires multihop communication through the on-chip wireless channels. Moreover, the overheads of a wireless link may not be justifiable for 1 mm range of on-chip communication compared to a wired channel. We therefore propose to use relatively long-range on-chip wireless communication data links to achieve energy-efficient and low-latency wireless NoC architectures. 3 WIRELESS NoC ARCHITECTURE In a generic wired NoC, the constituent embedded cores communicate via multiple switches and wired links. This multihop communication results in data transfers with high energy dissipation and latency. To alleviate this problem, we propose long-distance high-bandwidth wireless links between distant cores in the chip. In the following sections, we will explain the design of a scalable architecture for WiNoCs of various system sizes. 3.1 Topology Modern complex network theory [25] provides us with a powerful method to analyze network topologies and their properties. Between a regular, locally interconnected mesh network and a completely random Erdo˜ s-Re´ nyi topology, there are other classes of graphs [25], such as small-world and scale-free graphs. Networks with the small-world property have a very short average path length, which is commonly measured as the number of hops between any pair of nodes. The average shortest path length of smallworld graphs is bounded by a polynomial in logðN Þ, where GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1487 might not be optimal. Hence, after the initial placement of the wireless links the network is further optimized for performance by using Simulated Annealing (SA) [30]. The particular probability distribution and the heuristics followed in establishing the network links are described in the next section. Key to our approach is establishing optimal overall network topology under given resource constraints, i.e., a limited number of wireless links. Fig. 1b shows a possible interconnection topology with eight hubs and three wireless links. Instead of the ring used in this example, the hubs can be connected in any other possible interconnect architecture. The size and number of subnets are chosen such that neither the subnets nor the upper level of the hierarchy become too large. This is because if either level of the hierarchy becomes too large then it causes a performance bottleneck by limiting the data throughput in that level. However, since the architecture of the two levels can be different causing their traffic characteristics to differ from each other, the exact hierarchical division can be obtained by performing system-level simulations as shown in Section 4.3. We propose a hybrid wired/wireless NoC architecture. The hubs are interconnected via both wireless and wired links while the subnets are wired only. The hubs with wireless links are equipped with wireless base stations (WBs) that transmit and receive data packets over the wireless channels. When a packet needs to be sent to a core in a different subnet it travels from the source to its respective hub and reaches the hub of the destination subnet via the small-world network consisting of both wireless and wired links, where it is then routed to the final destination core. For intersubnet and intrasubnet data transmission, wormhole routing is adopted. Data packets are broken down into smaller parts called flow-control units or flits [31]. The header flit holds the routing and control information. It establishes a path, and subsequent payload or body flits follow that path. The routing protocol is described in Section 3.4. 3.2 Wireless Link Insertion and Optimization As mentioned above, the overall interconnect infrastructure of the WiNoC is formed by connecting the cores in the subnets with each other and to the central hub through traditional metal wires. The hubs are then connected by wires and wireless links such that the second level of the network has the small-world property. The placement of the wireless links between a particular pair of source and destination hubs is important as this is responsible for establishing highspeed, low-energy interconnects on the network, which will eventually result in performance gains. Initially, the links are placed probabilistically; i.e., between each pair of source and destination hubs, i and j, respectively, the probability Pij of having a wireless link is proportional to the distance measured in number of hops along the ring, hij , as shown in (1). Pij ¼ hijP ð1Þ : i;j hij The probabilities are normalized such that their sum is equal to one. Such a distribution is chosen because in the presence of a wireless link, the distance between the pair Fig. 1. (a) Mesh topology of subnet with a hub connected to all switches in the subnet. (b) Network topology of hubs connected by a small-world graph with both wired and wireless links. N is the number of nodes, which makes them particularly interesting for efficient communication with minimal resources [26], [27]. This feature of small-world graphs makes them particularly attractive for constructing scalable WiNoCs. Most complex networks, such as social networks, the Internet, as well as certain parts of the brain exhibit the small-world property. A small-world topology can be constructed from a locally connected network by rewiring connections randomly to any other node, which creates shortcuts in the network [28]. These random long-range links between nodes can also be established following probability distributions depending on the distance separating the nodes [29]. It has been shown that such “shortcuts” in NoCs can significantly improve the performance compared to locally interconnected mesh-like networks [2], [27] with fewer resources than a fully connected system. Our goal here is to use the “small-world” approach to build a highly efficient NoC based on both wired and wireless links. Thus, for our purpose, we first divide the whole system into multiple small clusters of neighboring cores and call these smaller networks subnets. As subnets are smaller networks, intrasubnet communication will have a shorter average path length than a single NoC spanning the whole system. Fig. 1a shows a subnet with mesh topology. This mesh subnet has NoC switches and links as in a standard mesh-based NoC. The cores are connected to a centrally located hub through direct links and the hubs from all subnets are connected in a second-level network forming a hierarchical network. This upper level of the hierarchy is designed to have characteristics of small-world graphs. Due to a limited number of possible wireless links, as discussed in later sections, neighboring hubs are connected by traditional wired links forming a bidirectional ring and a few wireless links are distributed between hubs separated by relatively long distances. Reducing longdistance multihop wired communication is essential in order to achieve the full benefit of on-chip wireless networks for multicore systems. As the links are initially established probabilistically, the network performance 1488 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 becomes a single hop and hence it reduces the original distance between the communicating hubs through the ring. Depending on the number of available wireless links, they are inserted between randomly chosen pairs of hubs, which are chosen following the probability distribution mentioned above. Once the network is initialized, an optimization by means of SA heuristics is performed. Since the subnet architectures are independent of the top-level network, the optimization can be done only on the top-level network of hubs and hence the subnets can be decoupled from this step. The optimization step is necessary as the random initialization might not produce the optimal network topology. SA offers a simple, well established, and scalable approach for the optimization process as opposed to a brute-force search. If there are N hubs in the network and n wireless links to distribute, the size of the search space S is given by   jS j ¼ ðN 2 Þ   N n : ð2Þ Thus, with increasing N , it becomes increasingly difficult to find the best solution by exhaustive search. In order to perform SA, a metric has been established, which is closely related to the connectivity of the network. The metric to be optimized is the average distance, measured in number of hops, between all source and destination hubs. To compute this metric, the shortest distances between all hub pairs are computed following the routing strategy outlined in Section 3.4. In each iteration of the SA process, a new network is created by randomly rewiring a wireless link in the current network. The metric for this new network is calculated and compared to the metric of the current network. The new network is always chosen as the current optimal solution if the metric is lower. However, even if the metric is higher, we choose the new network probabilistically. This reduces the probability of getting stuck in a local optimum, which could happen if the SA process were to never choose a worse solution. The exponential probability shown in (3) is used to determine whether or not a worse solution is chosen as the current optimal: P ðh; h0 ; T Þ ¼ exp½ðh   h0 Þ=T : The optimization metrics for the current and new networks are h and h0 , respectively. T is a temperature parameter, which decreases with the number of optimization iterations according to an annealing schedule. In this work, we have used Cauchy scheduling, where the temperature varies inversely with the number of iterations [30]. The algorithm used to optimize the network is shown in Fig. 2. Here, we assume a uniform spatial traffic distribution where a packet originating from any core is equally likely to have any other core on the die as its destination. However, with other kinds of spatial traffic distributions, where the network loads are localized in different clusters, the metric for optimization has to be changed accordingly to account for the nonuniform traffic patterns as discussed later in Section 4.6. An important component in the design of the WiNoCs is the on-chip antenna for the wireless links. In the next section, we describe various alternative on-chip antenna choices and their pros and cons. ð3Þ Fig. 2. Flow diagram for the simulated-annealing-based optimization of WiNoC architectures. 3.3 On-Chip Antennas Suitable on-chip antennas are necessary to establish wireless links for WiNoCs. In [9], the authors demonstrated the performance of silicon integrated on-chip antennas for intraand interchip communication. They have primarily used metal zigzag antennas operating in the range of tens of GHz. Design of an ultra-wideband antenna for inter- and intrachip communication is elaborated in [32]. This particular antenna was used in the design of a wireless NoC [24] mentioned earlier in Section 2. The above-mentioned antennas principally operate in the millimeter wave (tens of GHz) range and consequently their sizes are on the order of a few millimeters. If the transmission frequencies can be increased to THz/ optical range, then the corresponding antenna sizes decrease, occupying much less chip real estate. Characteristics of metal antennas operating in the optical and near-infrared region of the spectrum of up to 750 THz have been studied [33]. Antenna characteristics of CNTs in the THz/optical frequency range have also been investigated both theoretically and experimentally [10], [11]. Bundles of CNTs are predicted to enhance performance of antenna modules by up to 40 dB in radiation efficiency and provide excellent directional properties in far-field patterns [34]. Moreover, these antennas can GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1489 achieve a bandwidth of around 500 GHz, whereas the antennas operating in the millimeter wave range achieve bandwidths of tens of GHz [34]. Thus, antennas operating in the THz/optical frequency range can support much higher data rates. CNTs have numerous characteristics that make them suitable as on-chip antenna elements for optical frequencies. Given wavelengths of hundreds of nanometers to several micrometers, there is a need for virtually onedimensional antenna structures for efficient transmission and reception. With diameters of a few nanometers and any length up to a few millimeters possible, CNTs are the perfect candidate. Such thin structures are almost impossible to achieve with traditional microfabrication techniques for metals. Virtually defect-free CNT structures do not suffer from power loss due to surface roughness and edge imperfections found in traditional metallic antennas. In CNTs, ballistic electron transport leads to quantum conductance, resulting in reduced resistive loss, which allows extremely high current densities in CNTs, namely 4-5 orders of magnitude higher than copper . This enables high transmitted powers from nanotube antennas, which is crucial for long-range communications. By shining an external laser source on the CNT, radiation characteristics of multiwalled carbon nanotube (MWCNT) antennas are observed to be in excellent quantitative agreement with traditional radio antenna theory [11], although at much higher frequencies of hundreds of THz. Using various lengths of the antenna elements corresponding to different multiples of the wavelengths of the external lasers, scattering and radiation patterns are shown to be improved. Such nanotube antennas are good candidates for establishing onchip wireless communications links and are henceforth considered in this work. Chemical vapor deposition (CVD) is the traditional method for growing nanotubes in specific locations by using lithographically patterned catalyst islands. The application of an electric field during growth or the direction of gas flow during CVD can help align nanotubes. However, the high-temperature CVD could potentially damage some of the preexisting CMOS layers. To alleviate this, localized heaters in the CMOS fabrication process to enable localized CVD of nanotubes without exposing the entire chip to high temperatures are used [35]. As mentioned above, the NoC is divided into multiple subnets. Hence, the WBs in the subnets need to be equipped with transmitting and receiving antennas, which will be excited using external laser sources. As mentioned in [7], the laser sources can be located off-chip or bonded to the silicon die. Hence, their power dissipation does not contribute to the chip power density. The requirements of using external sources to excite the antennas can be eliminated if the electroluminescence phenomenon from a CNT is utilized to design linearly polarized dipole radiation sources [36]. But further investigation is necessary to establish such devices as successful transceivers for on-chip wireless communication. To achieve line of sight communication between WBs using CNT antennas at optical frequencies, the chip packaging material has to be elevated from the substrate surface to create a vacuum for transmission of the high-frequency EM waves. Techniques for creating such vacuum packaging are already utilized for MEMS applications [37], and can be adopted to make creation of line of sight communication between CNT antennas viable. In classical antenna theory, it is known that the received power degrades inversely with the fourth power of the separation between source and destination due to ground reflections beyond a certain distance. This threshold separation, r0 between source and destination antennas assuming a perfectly reflecting surface, is given by (4). r0 ¼ 2H 2  : ð4Þ Here, H is the height of the antenna above the reflecting surface and  is the wavelength of the carrier. Thus, if the antenna elements are at a distance of H from the reflective surfaces like the packaging walls and the top of the die substrate, the received power degrades inversely with the square of the distance until it is r0 . Thus, H can be adjusted to make the maximum possible separation smaller than the threshold separation r0 for a particular frequency of radiation used. Considering the optical frequency ranges of CNT antennas, depending on the separation between the source and destination pairs in a single chip, the required elevation is a few tens of microns only. 3.4 Routing and Communication Protocols In the proposed WiNoC, intrasubnet data routing depends on the topology of the subnets. For example, if the cores within a subnet are connected in a mesh, then data routing within the subnet follows dimension order (e-cube) routing. Intersubnet data are routed through the hubs, along the shortest path between the source and destination subnets in terms of number of links traversed. The hubs in all the subnets are equipped with a prerouting block to determine this path through a search across all potential paths between the hubs of the source and destination subnets. In the current work, paths involving only a single wireless link and none or any number of wired links on the ring are considered. All such paths as well as the completely wired path on the ring are compared and the one with the minimum number of link traversals is chosen for data transfer. For a data packet requiring intersubnet routing, this computation is done only once for the header flit at the hub of the originating subnet. The header flit needs to have a field containing the address of the intermediate hub with a WB that will be used in the path. Only this information is sufficient as the header follows the default wireline path along the ring to that hub with the WB from its source, which is also the shortest path along the ring. Since each WB has a single, unique destination, the header reaches that destination and is then again routed via the wireline path to its final destination hub using normal ring routing. The rest of the flits follow the header, as wormhole routing is adopted in this paper. Considering only those paths that have a single wireless link reduces computational overheads in the WB routers as it limits the search space. As the wireless links are placed as long-distance shortcuts, they are always comparable in length to the diameter of the ring. Hence, the probability that a path with multiple wireless links between any source/destination pair will be shorter than paths with a single wireless link is extremely low. So, in order to achieve the best trade-off between the router complexity and network performance, only paths with single wireless link are considered. Also, if two alternatives 1490 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 Fig. 4. The optimal wireless link arrangement for (a) 1, (b) 6, and (c) 24 wireless links among 16 hubs. Note that symmetrical solutions with the same performance are possible. vary from 24 links, each with a single-frequency channel, to a single link with all 24 channels. Assigning multiple channels per link increases the link bandwidth. Currently, high-speed silicon integrated Mach-Zehnder optical modulators and demodulators, which convert electrical signals to optical signals and vice versa are commercially available [39]. The optical modulators can provide 10 Gbps data rate per channel on these links. At the receiver, a low-noise amplifier (LNA) can be used to boost the power of the received electrical signal, which will then be routed into the destination subnet. As noted in [38], this data rate is expected to increase manifold with future technology scaling. The modulation scheme adopted is noncoherent on-off keying (OOK), and therefore does not require complex clock recovery and synchronization circuits. Due to limitations in the number of distinct frequency channels that can be created through the CNT antennas, the flit width in NoCs is generally higher than the number of possible channels per link. Thus, to send a whole flit through the wireless link using a limited number of distinct frequencies, a proper channelization scheme needs to be adopted. In this work, we assume a flit width of 32 bits. Hence, to send the whole flit using the distinct frequency channels, time division multiplexing (TDM) is adopted. The various components of the wireless channel, viz., the electro-optic modulators, the TDM modulator/demodulator, the LNA, and the router for routing data on the network of hubs are implemented as a part of the WB. Fig. 3 illustrates the adopted communication mechanism for the intersubnet data transfer. In this WiNoC example, we use a wireless link with four frequency channels. In this case, one flit is divided into eight four-bit nibbles, and each nibble is assigned a 0.1 ns timeslot, corresponding to a bit rate of 10 Gbps. The bits in each nibble are transmitted simultaneously over four different carrier frequencies. The routing mechanism, discussed in this section, is easily extendable to incorporate other addressing techniques like multicasting. Performance of traditional NoC architectures incorporating multicasting have been already investigated [40] and it can be similarly used to enhance the performance of the WiNoC developed in this work. For example, let us consider a subnet in a 16-subnet system (as in Fig. 4), which tries to send packets to three other subnets such that one of them is diagonally opposite to the source subnet and the other two are on either side of it. In absence of long-range wireless links, using multicasting the zero load latency for the delivery of a single flit is nine cycles whereas without multicasting the same flit will need 11 cycles to be delivered Fig. 3. Adopted communication protocol for the wireless channel. have the same number of hops, the one with the wireless link is chosen, as this will have less energy dissipation. In this routing scheme, the path is predetermined at the source hub and hence no cycles are possible. Consequently, there is no possibility of a deadlock or livelock. An alternative routing approach is to avoid the one-time evaluation of the shortest path at the original source hub and adopt a distributed routing mechanism. In this scenario, the path is determined at each node by checking for the existence of a wireless link at that node, which if taken will shorten the path length to the final destination. If this wireless link does not exist or shorten the path in comparison to the wireline path from that node, then the default routing mechanism along the ring is followed to the next node. This mechanism performs a check at every node by computing and comparing the path lengths by using the default wireline routing or the wireless link. The adopted centralized routing performs all the checks at the original source hub, which includes all the wireless links and the wireline path from the source to the destination. We will present the comparative performance evaluation of these two schemes later in Section 4.3. By us ing mu lt iband laser sources to exc ite CNT antennas, different frequency channels can be assigned to pairs of communicating subnets. This will require using antenna elements tuned to different frequencies for each pair, thus creating a form of frequency division multiplexing (FDM) creating dedicated channels between a source and destination pair. This is possible by using CNTs of different lengths, which are multiples of the wavelengths of the respective carrier frequencies. High directional gains of these antennas, demonstrated in [11], [34], aid in creating directed channels between source and destination pairs. In [38], 24 continuous wave laser sources of different frequencies are used. Thus, these 24 different frequencies can be assigned to multiple wireless links in the WiNoC in such a way that a single-frequency channel is used only once to avoid signal interference on the same frequencies. This enables concurrent use of multiband channels over the chip. The number of wireless links in the network can therefore GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1491 to the respective destinations. Here, the communication takes place only along the ring. However, if a wireless link exists along the diagonal from the source to the middle destination subnet then with multicasting the flit can be transferred in five cycles if there are eight distinct channels in the link. Four cycles are needed to transfer a 32-bit flit to the diagonally opposite hub via the wireless links and one more hop along the ring to the final destinations on either side. The efficiency of using multicasting varies with number of channels in the link as it governs the bandwidth of the wireless link. 4 EXPERIMENTAL RESULTS In this section, we analyze the characteristics of the proposed WiNoC architectures and study trends in their performance with scaling of system size. For our experiments, we have considered three different system sizes, namely 128, 256, and 512 cores on a die of size 20 mm  20 mm. We observe results of scaling up the system size by increasing both the number of subnets as well as the number of cores per subnet. Hence, in one scenario, we have considered a fixed number of cores per subnet to be 16 and varied the number of subnets between 8, 16, and 32. In the other case, we have kept the number of subnets fixed at 16 and varied the size of the subnets from 8 to 32 cores. These system configurations are chosen based on the experiments explained later in Section 4.3. Establishment of wireless links using simulated annealing, however, depends only on the number of hubs on the second level of the network. 4.1 Establishment of Wireless Links Initially, the hubs are connected in a ring through normal wires and the wireless links are established between randomly chosen hubs following the probability distribution given by (1). We then use simulated annealing to achieve an optimal configuration by finding the positions of the wireless links which minimize the average distance between all source and destination pairs in the network. Fig. 4 shows the location of 1, 6, and 24 wireless links with 24, 4, and 1 channels, respectively, in a network of 16 hubs. We followed the same optimization methodology for all the other networks. The corresponding average distances for the TABLE 1 Average Distance for Optimized WiNoCs *In case of 8 subnets only 12 wireless links are used with 2 channels per link. optimized networks with different system sizes are shown in Table 1. It should be noted that the particular placement of wireless links to obtain the optimal network configuration is not unique because of symmetric considerations in our setup, i.e., there are multiple configurations with the same optimal performance. In order to establish the performance of the SA algorithm used, we compared the resultant optimization metric with the metric obtained through exhaustive search for the optimized network configuration for various system sizes. The SA algorithm produces network configurations with total average hop count exactly equal to that generated by the exhaustive search technique for the system configurations considered in this paper. However, the obtained WiNoC configuration in terms of topology is nonunique as different configurations can have the same average hop count. Fig. 5a shows the number of iterations required to arrive at the optimal solution with SA and exhaustive search algorithms. Clearly, the SA algorithm converges to the optimal configuration much faster than the exhaustive search technique. This advantage will increase for larger system sizes. Fig. 5b shows the convergence of the metric for different values of the initial temperature to illustrate that the SA approach converges robustly to the optmal value of the average hopcount with numerical variation in the temperature. This simulation was performed for a system with 32 subnets with one wireless link. With higher values of the initial temperature, it can take longer to converge. Naturally, for large enough values of the initial temperature, Fig. 5. (a) Number of iterations required to reach optimal solution by the SA and exhaustive search methods, (b) Convergence with different temperatures. 1492 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 the metric does not converge. On the other hand, lower values of the initial temperature make the system converge faster but at the risk of getting stuck in a local optimum. Using the network configurations developed in this section, we will now evaluate the performance of the WiNoC based on well-established performance metrics. 4.2 Performance Metrics To characterize the performance of the proposed WiNoC architectures, we consider three network parameters: latency, throughput, and energy dissipation. Latency refers to the number of clock cycles between the injection of a message header flit at the source node and the reception of the tail flit at the destination. Throughput is defined as the average number of flits successfully received per embedded core per clock cycle. Energy dissipation per packet is the average energy dissipated by a single packet when routed from the source to destination node; both the wired subnets and the wireless channels contribute to this. For the subnets, the sources of energy dissipation are the interswitch wires and the switch blocks. For the wireless channels, the main contribution comes from the WBs, which include antennas, transceiver circuits, and other communication modules like the TDM block and the LNA. Energy dissipation per packet, Epkt , can be calculated according to (5) below: Epkt ¼ NintrasubnetEsubnet;hophsubnet þ NintersubnetEswhsw ðNintrasubnet þ Nintersubnet Þ : ð5Þ In (5), Nintrasubnet and Nintersubnet are the total number of packets routed within the subnet and between subnets, respectively. Esubnet;hop is the energy dissipated by a packet traversing a single hop on the wired subnet including a wired link and switch, and Esw is the energy dissipated by a packet traversing a single hop on the second network level of the WiNoC, which has the small-world properties. Esw also includes the energy dissipation in the core to hub links. In (5), hsubnet and hsw are the average number of hops per packet in the subnet and the small-world network. 4.3 Performance Evaluation The network architectures, developed earlier in this section, are simulated using a cycle accurate simulator which models the progress of data flits accurately per clock cycle accounting for flits that reach destination as well as those that are dropped. One hundred thousand iterations were performed to reach stable results in each experiment, eliminating the effect of transients in the first few thousand cycles. The mesh subnet architecture considered is shown in Fig. 1a. The width of all wired links is considered to be same as the flit size, which is 32 in this paper. The particular NoC switch architecture, adopted from [41] for the switches in the subnets, has three functional stages, namely, input arbitration, routing/switch traversal, and output arbitration. The input and output ports including the ones on the wireless links have four virtual channels per port, each having a buffer depth of 2 flits [41]. Each packet consists of 64 flits. Similar to the intrasubnet communication, we have adopted wormhole routing in the wireless channel too. Consequently, the hubs have similar architectures as the NoC switches in the subnets. Hence, each port of the hub has same input and output arbiters, and equal number of virtual channels with same Fig. 6. (a) The components of a WB with multiple wired and wireless ports at input and output. (b) A wireless port. buffer depths as the subnet switches. The number of ports in a hub depends on the number of links connected to it. The hubs also have three functional stages, but as the number of cores increases in a subnet the delays in arbitration and switching for some cases are more than a clock cycle. Depending on the subnet sizes, traversal through these stages need multiple cycles and this has been taken into consideration while evaluating overall latency of the WiNoC. The wireless ports of the WBs are assumed to be equipped with antennas, TDM modules, and electro-optic modulators and demodulators. The various components of a WB are shown in Fig. 6. A hub consisting of only ports to wired links is also highlighted in the figure to emphasize that a WB has GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1493 Fig. 7. (a) Throughput and (b) latency of 256-core WiNoCs with different numbers of wireless links. delays incurred by the electro-optic signal conversions with the MZM devices are 20 ps. When computing the overall system latency and throughput of the WiNoCs, the delays of these individual components are taken into account. This particular hierarchical topology was selected as it provided optimum system performance. Fig. 8 shows the saturation throughputs for alternative ways of dividing the 256-core WiNoC into different numbers of subnets with a single wireless link. As can be seen from the plot, all alternative configurations achieve worse saturation throughput. The same trend is observed if we vary the number of wireless links. Using the same method, the suitable hierarchical division that achieves best performance is determined for all the other system sizes. For system sizes of 128 and 512, the hierachical divisions considered here achieved much better performance compared to the other possible divisions with either lower or higher number of subnets. By varying the number of channels in the wireless links, various WiNoC configurations are created. We have considered WiNoCs with 1, 6, and 24 wireless links in our additional components compared to a hub. A simple flowcontrol mechanism is adopted uniformly for wireless links in which, the sender WB stops transmitting flits only when a full signal is asserted from the receiver WB. This full signal is embedded in a control flit sent from the receiver to the sender only when the receiver buffer is filled above a predefined threshold. When the full signal is asserted, flits do not move and are blocked spanning multiple switches or hubs. This, in turn, can block other messages in the network as in wormhole routing. In case all buffers are full, the new injected packets from the cores are dropped until new buffer space is available. A more advanced flow-control mechanism could be incorporated to improve WiNoC performance further [4]. The NoC switches, the hubs, and the wired links are driven with a clock of frequency 2.5 GHz. Fig. 7 shows throughput and latency plots as a function of injection load for a system with 256 cores divided into 16 subnets, each with 16 cores. The delays incurred by the wired links from the cores to the hub for varying number of cores in the subnets for different system sizes are shown in Table 2. The delays in the interhub wires for varying number of subnets are also shown. As can be seen, these delays are all less than the clock period of 400 ps and it maybe noted that the lengths of both core-to-hub and interhub wireline links will reduce with increase in the number of subnets as then each subnet becomes smaller in area and the subnets also come closer to each other. The TABLE 2 Delays on Wired Links in the WiNoCs *for 8 and 32 subnets, the intersubnet distances are different along the two planar directions. Fig. 8. Throughput of 256-core WiNoC for various hierarchical configurations. NS ¼ number of subnets, SS ¼ subnet size. 1494 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 Fig. 9. Saturation throughput with varying (a) number of subnets and (b) size of each subnet. experiments. Since the total number of frequencies considered in this work is 24, the number of channels per link is 24, 4, and 1, respectively. As can be seen from Fig. 7, the WiNoCs with different possible configurations outperform the singlewired monolithic flat mesh architecture. It can also be observed that with increasing number of wireless links, throughput improves slightly. It should be noted that even though increasing the number of links does increase the number of concurrent wireless communication links, the bandwidth on each link decreases as the total number of channels is fixed by the number of off-chip laser sources. This causes the total bandwidth over all the wireless channels to remain the same. The only difference is in the degree of distribution across the network. Consequently, network throughput increases only slightly with increasing number of wireless links. However, the hardware cost increases with increasing numbers of links as discussed in Section 4.7. Thus, depending upon whether the demand on performance is critical the designer can choose to trade off the area overhead of deploying the maximum number of wireless links possible. However, if the constraints on area overhead are really stringent then one can choose to employ only one wireless link and consequently provide more bandwidth per link and have only a little negative effect on performance. In order to observe trends among various WiNoC configurations, we performed further analysis. Fig. 9a shows the throughput at network saturation for various system sizes while keeping the subnet size fixed for different numbers of wireless links. Fig. 9b shows the variation in throughput at saturation for different system sizes for a fixed number of subnets. For comparison, the throughput at network saturation for a single traditional wired mesh NoC of each system size is also shown in both of the plots. As in Fig. 7, it maybe noted from Fig. 9 that for a WiNoC of any given size, number of subnets and subnet size, the throughput increases with increase in number of wireless links deployed. As can be observed from the plots, the maximum achievable throughput in WiNoCs degrades with increasing system size for both cases. However, by scaling up the number of subnets, the degradation in throughput is smaller compared to when the subnet size is scaled up. By increasing the subnet size, we are increasing congestion in the wired subnets and load on the hubs and not fully using the capacity of the high-speed wireless links in the upper level of the network. When the number of subnets scales up, traffic congestion in the subnets does not get worse and the optimal placement of the wireless links makes the top-level network very efficient for data transfer. The effect on throughput with increasing system size is therefore marginal. To determine the energy dissipation characteristics of the WiNoCs, we first estimated the energy dissipated by the antenna elements. As noted in [11], the directional gain of MWCNT antennas we propose to use is very high. The ratio of emitted power to incident power is around  5 dB along the direction of maximum gain. Assuming an ideal line of sight channel over a few millimeters, transmitted power degrades with distance following the inverse square law. Therefore, the received power PR can be related to the transmitted power PT as PR ¼ GT AR 4R2 PT : In (6), GT is the transmitter antenna gain, which can be assumed to be  5 dB [11]. AR is the area of the receiving antenna and R is the distance between the transmitter and receiver. The energy dissipation of the transmitting antennas therefore depends on the range of communication. The area of the receiving antenna can be found by using the antenna configuration used in [11]. It uses a MWCNT of diameter 200 nm and length 7, where  is the optical wavelength. The length 7 was chosen as it was shown to produce the highest directional gain, GT , at the transmitter. In one of the setups in [11], the wavelength of the laser used was 543.5 nm, and hence the length of the antenna is around 3:8 m. Using these dimensions, the area of the receiving antenna, AT can be calculated. The noise floor of the LNA [42] is  101 dBm. Considering the MZM, demodulators cause an additional loss of up to 3 dB over the the operational bandwidth, the receiver sensitivity turns out to be  98 dBm in the worst case. The length of the longest possible wireless link considered among all WiNoC configurations is 23 mm. For this length and receiver sensitivity, a transmitted power of 1.3 mW is required. ð6Þ GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1495 Fig. 10. Packet energy dissipation with varying (a) number of subnets and (b) size of each subnet. Figs. 10a and 10b show the packet energy dissipation for each of the network configurations considered in this work. The packet energy for the flat wired mesh architecture is not shown as it is higher than that of the WiNoCs by orders of magnitude, and hence cannot be shown on the same scale. The comparison with the wired case is shown in Table 3 in the next section along with another hierarchical wired architecture. From the plots, it is clear that the packet energy dissipation increases with increasing system size. However, scaling up the number of subnets has a lower impact on the average packet energy. The reason for this is that the throughput does not degrade much and the average latency per packet also does not change significantly. Hence, the data packets occupy the network resources for less duration, causing only a small increase in packet energy. However, with an increase in subnet size, the throughput degrades noticeably, and so does latency. In this case, the packet energy increases significantly as each packet occupies network resources for a longer period of time. With an increase in the number of wireless links while keeping the number of subnets and subnet size constant, the packet energy decreases. This is because higher connectivity of the network results in higher throughput (or lower latency), which means that packets get routed faster, occupy network resources for less time, and consume less energy during the transmission. Since the wireline subnets pose the major bottleneck as is made evident by the trends in the TABLE 3 Packet Energy Dissipation for Flat Wired Mesh, WiNoC, and Hierarchical G-Line NoC Architectures Considering the energy dissipation at the transmitting and receiving antennas, and the components of the transmitter and receiver circuitry such as the MZM, TDM block, and the LNA, the energy dissipation of the longest possible wireless link on the chip is 0.33 pJ/bit. The energy dissipation of a wireless link, ELink is given as ELink ¼ ðEantenna;i þ Etransceiver;i Þ; ð7Þ X m i¼1 where m is the number of frequency channels in the link and Eantenna;i and Etransceiver;i are the energy dissipations of the antenna element and transceiver circuits for the ith frequency in the link. The network switches and hubs are synthesized from a RTL level design using 65 nm standard cell libraries from CMP [43], using Synopsys Design Vision and assuming a clock frequency of 2.5 GHz. A large set of data patterns were fed into the gate-level netlists of the network switches and hubs, and by running Synopsys Prime Power, their energy dissipation was obtained. The energy dissipation of the wired links depends on their lengths. The lengths of the interswitch wires in the subnets can be found by using the formula ð8Þ lM ¼ ledge : M   1 Here, M is number of cores along a particular edge of the subnet and ledge is the length of that edge. A 20 mm  20 mm die size is considered for all system sizes in our simulations. The interhub wire lengths are also computed similarly as these are assumed to be connected by wires parallel to the edges of the die in rectangular dimensions only. Hence, to compute interhub distances along the ring, parallel to a particular edge of the die, (8) is modified by changing M to the number of hubs along that edge and ledge to the length of that particular edge. In each subnet, the lengths of the links connecting the switches to the hub depend on the position of the switches as shown in Fig. 1a. The capacitances of each wired link, and subsequently their energy dissipation, were obtained through HSPICE simulations taking into account the specific layout for the subnets and the second level of the ring network. 1496 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 Fig. 11. Components of packet energy dissipation for a (a) flat mesh and (b) WiNoC. Values of energy dissipation are labeled in nJ units. plots of Figs. 9 and 10 their size should be optimized. In other words, smaller subnets imply better performance and lower packet energies. Hence, as a designer one should target to limit the size of the subnets as long as the size of the upper level of the network does not impact the performance of the overall system negatively. The exact optimal solution also depends on the architecture of the upper level of the network, which need not be restricted to the ring topology chosen in this work as an example. The adopted centralized routing strategy is compared with the distributed routing discussed in Section 3.4 for a WiNoC of size 256 cores split into 16 subnets with 16 cores in each. Twenty four wireless links were deployed in the exact same topology for both cases. With distributed routing, the throughput was 0.67 flits/core/cycle whereas with centralized routing it was 0.72 flits/core/cycle as already noted in Fig. 7, which is 7.5 percent higher. Centralized routing results in a better throughput as it finds the shortest path whereas the distributed routing uses nonoptimal paths in some cases. Hence, the distributed routing has lower throughput. The distributed routing dissipates a packet energy of 31.2 nJ compared to 30.8 nJ with centralized routing. This is because on an average the number of path length computation with the distributed routing is more per packet, as this computation occurs at every intermediate WB. However, with centralized routing each hub has additional hardware overhead to compute the shortest path by comparing all the paths using the wireless links. This hardware area cost is discussed in Section 4.7. 4.4 Comparison with Wired NoCs We evaluated the performance of the WiNoCs in terms of energy dissipation compared to different wired NoC architectures. As demonstrated in the last section, with increase in system size, increasing the number of subnets while keeping the subnet size fixed is a better scaling strategy; hence, we followed that in the following analysis. The first wired architecture considered was the conventional flat mesh architecture. Table 3 quantifies the energy dissipat ion per packet of the WiNoC and the wired architectures for various system sizes. The WiNoC configuration with 24 wireless links was chosen because it has the lowest packet energy dissipation among all the possible hybrid wired/wireless configurations. It is evident that the WiNoC consumes orders of magnitude less energy compared to the flat wired mesh network. Fig. 11 shows the contributions of the various components of the packet energy dissipation for the WiNoC with 24 wireless links and the flat mesh architecture for a system size of 256 cores. The contributions of the antenna and the transceiver, which constitute the wireless link energy, are shown separately from the wireline links of the upper level small-world network. The largest contribution to packet energy in WiNoC is from the wireless and wireline link traversals combined in the upper level small-world network. This is because on an average a large portion of the packets travel through the upper level of the WiNoC to reach other subnets. However, as this level has very small average path length due to its smallworld nature and due to the low-power wireless channels the absolute value of this energy dissipation is very small. The performance of the flat mesh NoC architectures can be improved by incorporating express virtual channels (EVCs), which connect the distant cores in the network by bypassing intermediate switches/routers. It is demonstrated that the switch/router energy dissipation of the baseline mesh architecture is improved by about 25-38 percent depending on the system size by using dynamic EVCs. The energy dissipation profile is improved by another eight percent over the EVC scheme by using low-swing, multidrop, ultralowlatency global interconnect (G-Lines) for the flow-control signals [4]. Recently, a number of papers have shown the possibility of communicating near speed of light across several millimeters on a silicon substrate. Among them, lowswing, long-range, and ultralow-latency communication wires as proposed in [44] achieve higher bandwidth at lower power consumption [4]. G-lines use a capacitive preemphasis transmitter that increases the bandwidth and decreases the voltage swing without the need of an additional power supply. To avoid cross talk, differential interconnects are implemented with a pair of twisted wires. A decision feedback equalizer is employed at the receiver to further increase the achievable data rate. It is evident that though introduction of EVCs improves the energy dissipation profile of a flat wired mesh NoC, the achievable performance gain is still limited compared to the gains achieved by the WiNoCs. This is because the basic architecture is still a flat mesh and the savings in energy principally arises from bypassing the intermediate NoC switches. GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1497 TABLE 4 Percentage of Packet Energy Dissipation on Long-Range Links Fig. 12. Energy dissipation per bit on G-line and wireless links with varying link lengths. As a next step, we undertook a study where we compared the energy dissipation profile of the proposed hybrid NoC architecture using wireless links to that of the same hierarchical network using G-Lines as long-range communication links. To do so, we replaced the wireless links of the WiNoCs by the G-Lines while maintaining the same hierarchical topology with shortcuts in the upper level. Here, each G-line link is designed such that it has the same bandwidth as the wireless link it replaces. Thus, the overall throughput and end-to-end latency of the hierarchical NoC with G-line links is the same as that of the WiNoC. We performed simulations in 65 nm technology. The lumped wire resistance is 20 ohms/mm, and the capacitance is 400 fF/ mm. The simulated power dissipation is found to be 0.6 mW/ transmitter and 0.4 mW/receiver. In order to achieve the same bandwidth as the wireless links in our experiments, multiple G-line links are used in place of a single wireless channel between a pair of source and destination hubs. For example, a single G-line can sustain a bandwidth of around 2.5 Gbps for a wire length of 11 mm, whereas each wireless channel can sustain a bandwidth of 10 Gbps. Therefore, to maintain the same data rate as provided by a single wireless channel, we need four G-lines between a source and destination pair separated by 11 mm. Moreover, since each G-line works on differential signals, we will need eight wires to replace a single wireless link in this case. The packet energy dissipation for a WiNoC and hierarchical NoC with G-line links are also shown in Table 3 for various system sizes. The WiNoC’s energy per packet consumption is one order of magnitude less compared to the hierarchical NoC with G-line links of the same bandwidth as the wireless channels. This experiment was conducted to highlight the savings in energy dissipation due to two factors, viz., the architectural innovation proposed here and the use of on-chip wireless links in place of highly optimized wired connections. The difference in energy dissipation between the flat wired mesh NoC and the hybrid NoC with G-Lines arises primarily due to the architecture proposed here. The difference in energy dissipation between the WiNoCs and the hybrid NoC with G-lines is solely due to the use of wireless channels. Fig. 12 shows the energy dissipation of a wireless link considered in this paper and that of the G-line link as a function of communication distance between source and destination WBs considered here. This shows how high the energy dissipation of a G-line link of the same bandwidth as the wireless link is. The impact of this is reflected in the packet energy dissipation profiles shown in Table 3, which is obtained after full system simulation using these links. Table 4 shows the percentage of total packet energy dissipated on the wired and wireless links for a WiNoC with 128 cores divided into 16 subnets. The percentage of packet energy dissipated on the G-line links replacing the wireless links are also shown to signify the trade-off in energy dissipation as more wireline (G-Line) links are replaced with the wireless links for a single-network configuration. As shown in Tables 3 and 4, the hierarchical NoC with G-line links dissipate higher packet energy than the WiNoC and the long-distance G-line links dissipate a considerably larger proportion of that high packet energy. Another wireline architecture developed in [2] uses longrange wired shortcuts to design a small-world network over a basic mesh topology. We considered a system size of 128 cores and eight wireline shortcuts were optimally deployed on a basic wireline mesh following the scaling trend outlined in [2]. The chosen WiNoC configuration was 16 subnets with eight cores in each with eight wireless links. The throughput of the wireline small-world NoC proposed in [2] was 0.26 flits/core/cycle, which is 18.7 percent more than that of a flat mesh NoC. In comparison, the WiNoC had a throughput of 0.75 flits/core/cycle. This huge gain was due to the hierarchical division of the whole NoC as well as the high-bandwidth wireless links used in creating the shortcuts. The packet energy dissipation for the NoC proposed in [2] for the configuration mentioned above is 984 nJ. This energy dissipation is about 25 percent less than the packet energy dissipation in a flat mesh. However, even this packet energy is an order of magnitude higher than that of the WiNoC for the same size of 128 cores as shown in Table 3. From the above analysis, it is clear that the proposed WiNoC architectures outperform their corresponding wired counterparts significantly in terms of all the relevant network parameters. Moreover, the WiNoC is much more energy-efficient compared to an exactly equivalent hierarchical wired architecture implemented with the recently proposed high-bandwidth low-latency G-lines as the longrange communication links. 4.5 Comparative Analysis with Other Emerging NoC Paradigms There are several emerging paradigms which enhance the performance of NoCs using nontraditional technology such as three-dimensional integration, photonic interconnects, RF interconnect (RF-I), and on-chip wireless communication using UWB links. In this section, we perform a comparative analysis to establish the relative performance benefits achieved by using these alternative techniques with specific system parameters. We consider a system with 128 cores and 1498 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 uniform traffic distribution, Corona with 256 cores is shown to achieve a bandwidth of 4.5 TBps. In comparison, a 256-core WiNoC segmented into 16 subnets with 24 wireless links can achieve a peak bandwidth of 1.8 TBps for the same traffic pattern. A more detailed performance benchmarking across all emerging NoC paradigms for various system parameters is the subject of a future investigation. 4.6 Traffic-Dependent Wireless Link Insertion So far, we assumed a uniformly random spatial distribution of traffic between the hubs. We also principally considered the distance between the hubs to be the deciding factor for choosing the positions of the wireless links. However, in reality, there could be nonuniform traffic distributions with a particular pair of hubs communicating more frequently between themselves than with the others. In order to optimize our network for such nonuniform traffic scenarios, we modify (1) and also the optimization metric, which was based only on distances between cores earlier. Equation (1) is modified as shown below in (9). Pij ¼ hij fijP i;j hij fij : ð9Þ In (9), fij is the frequency of communication between the ith source and jth destination. This frequency is expressed as the percentage of traffic generated from i that is addressed to j. This frequency distribution is based on the particular application mapped to the overall NoC and is hence set prior to wireless link insertion. Therefore, the a priori knowledge of the traffic pattern is used to optimize the WiNoC. This optimization approach establishes a correlation between traffic distribution across the NoC and network configuration as in [46]. The optimization metric, which was just the sum of distances between all possible source and destination pairs of hubs in the previous experiments, needs to be modified to factor in the effect of nonuniform traffic: X  ¼ hij fij ; i;j ð10Þ where,  is the optimization metric. In this particular case, equal weight is attached to distance as well as frequency of communication in the metric. Using this modified metric, the simulated annealing algorithm is used to insert the wireless links for optimized performance. To represent nonuniform traffic patterns, we considered both synthetic and application-specific traffic patterns. We considered two types of synthetic traffic to evaluate the performance of the proposed WiNoC architecture. First, a transpose traffic pattern [2] was considered where a certain number of hubs were considered to communicate more frequently with each other. We considered 1, 3, and 5 such pairs and called them transpose1, transpose3, and transpose5, respectively. The system size considered was 128 with 16 subnets and four wireless links. Fifty percent of packets generated from one of these hubs were targeted toward the other in the pair . The other synthetic traffic pattern considered was the hotspot [2], where each hub communicates with a certain number of hubs more frequently than with the others. We have considered three such hotspot locations to Fig. 13. Packet energy dissipation per bandwidth and achievable NoC bandwidth for various types of emerging NoC paradigms for system size of 128 cores. packet size of 64 flits. We map this to a 3D mesh-based NoC with four layers as in [14]. The photonic NoC architecture was adopted from [7]. For the RF-I NoC, we followed the architecture of [8] with eight sectors. For the UWB NoC, we followed the design shown in [24]. Fig. 13 shows the achievable overall network bandwidth and the packet energy dissipation per unit bandwidth for all the different NoCs using alternative interconnect technologies. We considered the packet energy dissipation per unit bandwidth as the various NoCs are capable of achieving different network throughputs. The WiNoC considered in this comparison had 16 subnets. Due to the multihop nature of communication, relatively higher transceiver energy, and lower achievable bandwidth, the UWB NoC dissipates 432.9 nJ/Tbps, which is orders of magnitude more compared to all the other alternative solutions. That’s why UWB NoC energy is not shown in the same plot. The achievable bandwidth of this architecture is 1.04 Tbps which is also lower than that of the other emerging alternatives considered here. It can be observed that among all the emerging NoC architectures, the hybrid WiNoC, proposed in this paper, has the lowest packet energy dissipation per unit bandwidth and it also has the highest peak bandwidth. This is because in the WiNoC, each of the 24 wireless channels can sustain a data rate of 10 Gbps. WiNoC reduces the average hop count compared to both the 3D and RF-I NoCs. The photonic NoC considered in the comparative evaluation requires an electrical control network to configure photonic switching elements which uses a flat wireline mesh NoC. This causes overheads and hence limits its performance. However, this overhead can be reduced for longer packets. The lower bandwidth of the RF-I NoC compared to the WiNoC is due to the fact that it is essentially a flat wireline architecture as it uses a waveguide overlayed on an existing wireline mesh. The drop points to the RF-I become hotspots limiting the performance of the RF-I NoC. However, an alternative photonic NoC architecture, Corona, demonstrated in [45] employs an optical network amalgated onto a 3D chip. This particular architecture achieves a higher bandwidth than the WiNoC as it takes advantage of both photonic links and 3D integration simultaneously. For a GANGULY ET AL.: SCALABLE HYBRID WIRELESS NETWORK-ON-CHIP ARCHITECTURES FOR MULTICORE SYSTEMS 1499 TABLE 5 Total Area Overhead of Wireless Ports Fig. 14. Throughput of 128-core WiNoC with various traffic patterns. which all other hubs send 50 percent of the packets that originate from them. To represent application-based traffic patterns, two scientific applications were mapped onto the 128-core NoC considered here. First, a 256-point fast Fourier transform (FFT) application was considered, wherein each core performs a two-point radix-2 FFT computation. Second, the traffic pattern generated in performing multiplication of two 128  128 matrices was considered. For all the above nonuniform traffic distributions, the SA algorithm achieves the optimal configuration faster than the exhaustive search, though it takes more iterations than the case with uniform traffic distribution. Fig. 14 shows the maximum throughput at network saturation for nonuniform traffic distributions with and without wireless links. For the transpose traffic, the pairs of nodes are chosen along the diagonals of the ring topology of the upper level of the network to incorporate the worst-case effect on the throughput due to nonuniform traffic. Without any long-range wireless links, the throughput of the network decreases with increase in the number of transpose pairs. As these pairs are placed along the diagonals of the ring the amount of multihop communication increases and that affects the throughput. But by inserting the wireless links between these highly communicating hubs, the throughput increases significantly. It is evident from Fig. 14 that with increase in the number of highly communicating pairs, insertion of the wireless links brings significantly more performance gain. When the traffic is uniform, insertion of the wireless links improves the performance by around 104 percent. In the case of nonuniform traffic distribution with 5 transpose pairs, the performance improvement is 243 percent. The optimization of the network configuration for hotspot traffic also yields similar results where the gain in throughput becomes 209 percent. For the FFT and the matrix multiplication applications, the percentage improvements in throughput are 209 and 226 percent, respectively. In case of the application-specific nonuniform traffic patterns, the wireless links are inserted depending on the mutual interactions among various cores of the system giving a preference to more frequently communicating subnets. For each application-specific traffic pattern, the wireless link insertion process finds a corresponding optimum network configuration. Due to this inherent correlation between the optimization of the network configuration and the traffic pattern, the gains in throughput with nonuniform traffic are larger than that with uniform traffic. 4.7 Area Overheads In this section, we present a detailed analysis of the area overhead involved in overall wireless deployment in the hierarchical WiNoC. A key advantage of CNT antennas is that they are nanoscale structures with diameters of only a few hundreds of nanometers. The length of the nanotubes required for the WiNoCs vary in the range of a few microns. Hence, the areas of the antenna elements themselves are very small. The area of the transceiver circuits required per wireless port is the total area required for the TDM modulator/demodulator, the MZM modulator/demodulator, and the LNAs. The area overhead for a link varies depending upon the number of channels per link as the TDM modulator/demodulator complexity changes with number of channels per link. Table 5 summarizes the area overheads required for different number of wireless links. The area complexity increases with increase in the number of wireless links deployed in the WiNoC but is significantly less than the silicon area of the hubs. The arbitration, data routing and storage components of the hubs have area cost depending upon the number of ports per hub. The number of wireline ports, in turn, varies with the number of cores in the subnets. The number of wireline ports is equal to two more than the number of cores in each subnet due to two neighboring hubs that each hub is connected with, in addition to the cores in the subnet. This area cost is independent of the deployment of the wireless links as the wireless links are just extra ports deployed to the hubs whose area is already quantified. Fig. 15 shows the total area cost of WiNoCs of various system sizes with different numbers of subnets. Since flat mesh switches still exist in the WiNoCs, the total area is the sum of the areas of the flat mesh switches and the hubs. The additional silicon area overhead due to the hubs is at the most 25 percent for the system configurations considered in this work. This area cost analysis is done for hubs which implement the centralized routing strategy adopted throughout the paper. However, due to the higher complexity of the routers in this strategy compared to that in the distributed routing strategy, the area of each hub is up to 10 percent higher with the centralized routing than with distributed routing. The core-hub and the interhub wireline links are additional wiring overheads, which depend on the number and size of subnets. Fig. 16 shows the total wiring requirements of various lengths for a 20 mm  20 mm die for the various system configurations considered in this 1500 IEEE TRANSACTIONS ON COMPUTERS, VOL. 60, NO. 10, OCTOBER 2011 Fig. 15. Total silicon area in WiNoC hubs and switches. NS ¼ number of subnets, SS ¼ subnet size. work. The wiring requirements for a flat mesh architecture are shown for comparison. There are only a very few 10 mm long links in the 128-core WiNoC and hence is not apparent in the figure. It maybe noted that in the WiNoC, there are no intersubnet direct core to core links as intersubnet communication occurs through the hubs. Hence, WiNoCs eliminate a number of wireline links along the subnet boundaries which are present in the flat mesh topology. 5 CONCLUSIONS AND FUTURE WORK In this work, we propose and evaluate the performance of the WiNoC architectures used as communication backbones for multicore systems. By establishing long-range wireless links between distant cores and incorporating small-world network architectures, the WiNoCs are capable of outperforming their more traditional wired counterparts in terms of network throughput, latency, and energy dissipation. With increase in system size, increasing the number of subnets provides an efficient scaling technique without significantly degrading system performance. The architectural innovations proposed in this work are made possible by the use of low-power and high-speed wireless links capable of communicating directly between distant parts of the chip in a single hop. The gains in network performance metrics are in part due to the architecture and the rest is due to the adopted high-bandwidth, energy-efficient wireless links. Optimum placement of the wireless links based on nonuniform traffic distribution improves the performance of the WiNoC significantly more compared to a uniform traffic scenario. As a part of this work, we evaluated performance of the WiNoC with respect to other emerging NoC architectures for a specific system configuration. In ongoing and future investigations, we intend to establish a detailed benchmarking methodology to compare and contrast the performance of WiNoCs with the other alternatives by varying system size, packet length, traffic patterns, and other relevant parameters. More efficient and scalable techniques will also be developed for optimizing the WiNoC architectures, specifically in presence of complex transient workloads. It Fig. 16. Wiring requirement of WiNoC. NS ¼ number of subnets, SS ¼ subnet size of WiNoC. is well known that manufacturing processes of CNTs are defect-prone and hence in order to make WiNoCs with CNT antennas a reality appropriate fault-tolerant mechanism need to be incorportated to fully leverage the highbandwidth and low-power wireless links. In the future, a hybrid NoC with wired as well as wireless links can deliver the target performance of multicore chips by utilizing the benefits of both. ACKNOWLEDGMENTS This work was supported in part by the US National Science Foundation (NSF) CAREER grant CCF-0845504 and NSF grant CCF-0635390. The authors thank Dr. Alireza Nojeh for his inputs regarding CNT antennas. This work was done when Amlan Ganguly was a PhD candidate in Washington State University. "
2006,System-on-Chip - Reuse and Integration.,"Over the past ten years, as integrated circuits became increasingly more complex and expensive, the industry began to embrace new design and reuse methodologies that are collectively referred to as system-on-chip (SoC) design. In this paper, we focus on the reuse and integration issues encountered in this paradigm shift. The reusable components, called intellectual property (IP) blocks or cores, are typically synthesizable register-transfer level (RTL) designs (often called soft cores) or layout level designs (often called hard cores). The concept of reuse can be carried out at the block, platform, or chip levels, and involves making the IP sufficiently general, configurable, or programmable, for use in a wide range of applications. The IP integration issues include connecting the computational units to the communication medium, which is moving from ad hoc bus-based approaches toward structured network-on-chip (NoC) architectures. Design-for-test methodologies are also described, along with verification issues that must be addressed when integrating reusable components.",
2006,Exploring Fault-Tolerant Network-on-Chip Architectures.,"The advent of deep sub-micron technology has exacerbated reliability issues in on-chip interconnects. In particular, single event upsets, such as soft errors, and hard faults are rapidly becoming a force to be reckoned with. This spiraling trend highlights the importance of detailed analysis of these reliability hazards and the incorporation of comprehensive protection measures into all network-on-chip (NoC) designs. In this paper, we examine the impact of transient failures on the reliability of on-chip interconnects and develop comprehensive counter-measures to either prevent or recover from them. In this regard, we propose several novel schemes to remedy various kinds of soft error symptoms, while keeping area and power overhead at a minimum. Our proposed solutions are architected to fully exploit the available infrastructures in an NoC and enable versatile reuse of valuable resources. The effectiveness of the proposed techniques has been validated using a cycle-accurate simulator",
2007,"On-chip communication architecture exploration - A quantitative evaluation of point-to-point, bus, and network-on-chip approaches.","Traditionally, design-space exploration for systems-on-chip (SoCs) has focused on the computational aspects of the problem at hand. However, as the number of components on a single chip and their performance continue to increase, a shift from computation-based to communication-based design becomes mandatory. As a result, the communication architecture plays a major role in the area, performance, and energy consumption of the overall system. This article presents a comprehensive evaluation of three on-chip communication architectures targeting multimedia applications. Specifically, we compare and contrast the network-on-chip (NoC) with point-to-point (P2P) and bus-based communication architectures in terms of area, performance, and energy consumption. As the main contribution, we present complete P2P, bus-, and NoC-based implementations of a real multimedia application (i. e. the MPEG-2 encoder), and provide direct measurements using an FPGA prototype and actual video clips, rather than simulation and synthetic workloads. We also support the experimental findings through a theoretical analysis. Both experimental and analysis results show that the NoC architecture scales very well in terms of area, performance, energy, and design effort, while the P2P and bus-based architectures scale poorly on all accounts except for performance and area, respectively.",
2009,A 167-Processor Computational Platform in 65 nm CMOS.,"A 167-processor computational platform consists of an array of simple programmable processors capable of per-processor dynamic supply voltage and clock frequency scaling, three algorithm-specific processors, and three 16 KB shared memories; and is implemented in 65 nm CMOS. All processors and shared memories are clocked by local fully independent, dynamically haltable, digitally-programmable oscillators and are interconnected by a configurable circuit-switched network which supports long-distance communication. Programmable processors occupy 0.17 mm<sup>2</sup> and operate at a maximum clock frequency of 1.2 GHz at 1.3 V. At 1.2 V, they operate at 1.07 GHz and consume 47.5 mW when 100% active, resulting in an energy dissipation of 44 pJ per operation. At 0.675 V, they operate at 66 MHz and consume 608 muW when 100% active, resulting in a total energy dissipation of 9.2 pJ per ALU or MAC operation.",
2004,The Nostrum Backbone - a Communication Protocol Stack for Networks on Chip.,"We propose a communication protocol stack to be used in Nostrum, our Network on Chip (NoC) architecture. In order to aid the designer in the selection process of what parts of protocols, and their respective facilities, to include, a layered approach to communication is taken. A nomenclature for describing the individual layers' interfaces and service definitions of the layers in the protocol stack is suggested and used. The concept includes support for best effort traffic packet delivery as well as support for guaranteed bandwidth traffic, using virtual circuits. Furthermore an application to NoC adapter is defined, as part of the Resource to Network Interface, and is used to communicate between the Nostrum protocol stack and the application. An industrial example has been implemented, simulated, and the results justifies the suggested layered approach.",
2004,Fault Tolerant Algorithms for Network-On-Chip Interconnect.,"As technology scales, fault tolerance is becoming a key concern in on-chip communication. Consequently, this work examines fault tolerant communication algorithms for use in the NoC domain. Two different flooding algorithms and a random walk algorithm are investigated. We show that the flood-based fault tolerant algorithms have an exceedingly high communication overhead. We find that the redundant random walk algorithm offers significantly reduced overhead while maintaining useful levels of fault tolerance. We then compare the implementation costs of these algorithms, both in terms of area as well as in energy consumption, and show that the flooding algorithms consume an order of magnitude more energy per message transmitted.",
2004,Multi-objective mapping for mesh-based NoC architectures.,"We present an approach to multi-objective exploration of the mapping space of a mesh-based network-on-chip architecture. Based on evolutionary computing techniques, the approach is an efficient and accurate way to obtain the Pareto mappings that optimize performance and power consumption. Integration of the approach in an exploration framework with a kernel based on an event-driven trace-based simulator makes it possible to take account of important dynamic effects that have a great impact on mapping. Validation on both synthesized traffic and real applications (an MPEG-2 encoder/decoder system) confirms the efficiency, accuracy and scalability of the approach.","Multi-objective Mapping for Mesh-based NoC Architectures Giuseppe Ascia Dipar timento di Ingegneria Informatica e delle Telecomunicazioni University of Catania, Italy gascia@diit.unict.it Vincenzo Catania Dipar timento di Ingegneria Informatica e delle Telecomunicazioni University of Catania, Italy vcatania@diit.unict.it Maurizio Palesi Dipar timento di Ingegneria Informatica e delle Telecomunicazioni University of Catania, Italy mpalesi@diit.unict.it ABSTRACT In this paper we present an approach to multi-objective exploration of the mapping space of a mesh-based network-on-chip architecture. Based on evolutionary computing techniques, the approach is an efﬁcient and accurate way to obtain the Pareto mappings that optimize performance and power consumption. Integration of the approach in an exploration framework with a kernel based on an event-driven trace-based simulator makes it possible to take account of important dynamic effects that have a great impact on mapping. Validation on both synthesized trafﬁc and real applications (an MPEG-2 encoder/decoder system) conﬁrms the efﬁciency, accuracy and scalability of the approach. Categories and Subject Descriptors B.4.3 [Input/Output and Data Communications]: Interconnections (Subsystems); I.6.7 [Simulation and Modeling]: Simulation Support Systems—Environments; G.1.6 [Numerical Analysis]: Optimization General Terms Performance, Design Keywords Network-on-chip, mapping, multi-objective optimization, genetic algorithms, simulation. 1. INTRODUCTION Continuous improvements in semiconductor technology mean that a whole processing system comprising processors, memories, accelerators, peripherals, etc. can now be integrated in a single silicon die. In addition, a reduction in the time-to-market has led researchers to deﬁne methods based on the reuse of pre-designed, pre-veriﬁed modules in the form of intellectual properties (IPs). Despite this, hardware designers are not yet able to fully exploit the abundance of transistors that can be integrated with current technology. Designer productivity, in fact, is growing by just 20% a year, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’04, September 8–10, 2004, Stockholm, Sweden. Copyright 2004 ACM 1-58113-937-3/04/0009 ...$5.00. as compared to an increase of over 60% a year by technology. Projections show that synchronous regions will occupy an increasingly lower fraction of a chip [13] giving rise to locally synchronous, globally asynchronous solutions [7]. Applications will be modeled as a set of communicating tasks with different characteristics and origins, which will make implementations extremely heterogeneous. A type of architecture which lays emphasis on modularity and is intrinsically oriented towards supporting such heterogeneous implementations is represented by Network-on-Chip (NoC) architectures [3]. These architectures loosen the bottleneck due to delays in signal propagation in deep-submicron technologies and provide a natural solution to the problem of core reuse by standardizing on-chip communications. In this paper we will focus on mesh-based NoC architectures, in which resources communicate with each other via a mesh of switches that route and buffer messages. A resource is generally any core: a processor, a memory, an FPGA, a speciﬁc hardware block or any other IP compatible with the NoC interface speciﬁcations. One of the most onerous tasks in this context is the topological mapping of the resources on the mesh in such a way as to optimize certain performance indexes (e.g. power, performance). It is therefore of strategic importance to deﬁne methods to search for a mapping that will optimize the desired performance indexes. The problem of mapping in mesh-based NoC architectures has been addrees in three previos papers. Hu and Marculescu [8] present a branch and bound algorithm for mapping IPs/cores in a meshbased NoC architecture that minimizes the total amount of power consumed in communications with the constraint of performance handled via bandwidth reservation. Murali and De Micheli [11] address the problem under the bandwidth constraint with the aim of minimizing communication delay by exploiting the possibility of splitting trafﬁc among various paths. Lei and Kumar [9] present an approach that uses genetic algorithms to map an application, described as a parameterized task graph, on a mesh-based NoC architecture so as to minimize the execution time. These papers do not, however, solve certain important issues. The ﬁrst relates to the mapping evaluation model used, which can be deﬁned as “static”. The exploration algorithm decides which mapping to explore without taking important dynamic effects of the system into consideration, such as the variation in delay due to the switch input buffers which, as we will see, have a great impact on choice of the mapping. In agreement with [12], we believe that analytical methods make too many assumptions about the network and trafﬁc to get accurate values for real systems. The second problem relates to the optimization method used. It refers in all cases to a single performance index (power in [8], performance in [11, 9]). As we will see in the section devoted to experiments, optimization of one performance index may lead to unacceptable values for another performance index (e.g. high performance levels but unacceptable power consumption). We therefore think that the problem of mapping can be more usefully solved in a multi-objective environment, i.e. one in which there is no single solution but a set of mapping alternatives (which we will indicate as Pareto mapping), each featuring a different tradeoff between performance indexes, from which the designer (or decision maker) will choose the most suitable. In this paper is to propose a multi-objective approach to solving the problem of mapping IPs/cores in mesh-based NoC architectures. The approach will use evolutionary computing techniques to explore the mapping space. The mappings visited during the exploration process will be evaluated using a simulation-based approach and the optimization objectives will be performance and power consumption. The simulation-based approach makes it possible to evaluate the impact of the main architectural and application parameters on performance and power. The rest of the paper is organized as follows. Section 2 presents the simulation and evaluation framework used. The impact of the architectural and application parameters on the performance indexes considered is assessed in Section 3. Section 4 presents the algorithm for exploration of the mapping space and evaluates it in terms of accuracy and efﬁciency in different trafﬁc scenarios. Finally, Section 5 summarizes our contribution and outlines some directions for future work. Figure 2: Behavioural annotated graph (BAG). ulation framework we will use a representation based on a variation of a ﬁnite-state machine which we will indicate as a behavioral annotated graph (BAG). Each machine state is identiﬁed by a name, a set of operations (o p1 , . . . , o pn ) and two attributes which we will call latency and power (Figure 2). Transition from one state to another is represented by an oriented arc associated with a condition (transition only occurs when the condition is met). The conditions are evaluated after a time equal to the value of the attribute l at ency, starting from the instant at which the state is entered. If none of the conditions on the arcs are met, the machine remains in the current state and the process is repeated. Otherwise there is a state transition and the total energy consumption is calculated as the product between power and the time spent in the state. Figure 3 Figure 3: Behavioural annotated graph of a generic core. Figure 1: Structure of a 3x3 mesh-based NoC architecture. 2. EVALUATION OF A MAPPING Figure 1 shows the NoC topology we will refer to. It is a twodimensional mesh of processing resources. Each processing resource is connected to the communication network by a switch. We will call the pair formed by a resource and a switch a tile. The term mapping will be used to indicate assignment of an IP/core to each tile in the NoC. In this section we will describe the simulation and power and delay estimation model used to evaluate a mapping. Each switch in the NoC is connected to the four adjacent switches except for those at the network boundaries. On each side of a switch there is an output and an input port. The input port has a ﬁnitelength FIFO buffer in which packets to be routed are queued. The routing algorithm features static XY routing in which a packet is ﬁrst routed in a horizontal direction (X ) and then, when it reaches the column where the destination tile is located, it is routed in a vertical direction (Y ). The point-to-point connections between two switches and between a switch and a resource are taken to be 256bit (which corresponds to the size of a packet). As a transmission scheme we use wormhole routing. To describe the functioning of the various components of the sim(core) (core) (core) (core) id l e (core) bu f f shows the BAG for a generic core. In the Idle state the average amount of power consumed by a core is P . If there is at least one packet in the input queue it passes to a ﬁctitious state (featuring l at ency = 0 and power = 0) in which the type of packet is evaluated. If it is the ﬁrst in a data ﬂow directed towards the core involved (head packet, H ) or an intermediate packet (body packet, B) the core switches to the Buffering state, with an average power consumption of P bu f f and a latency of T . This state allows us to simulate situations in which a core starts to process the data, not on a packet basis but on a set of data that cannot be contained in a single packet. If, on the other hand, the packet is the last in a communication ﬂow, the core switches to the Process state in which the packet is actually processed, with an average power consumption of P process and a latency of T process . The operation performed in both these states is to consume the packet at the head of the queue and then, when the latency time ends, to switch unconditionally back to the Idle state. Figure 4(a) shows the interface of a switch. Each of the ﬁve input ports has an associated queue (buffer). Each output port is associated with an input signal (with the sufﬁx Ready) which is asserted whenever the element connected to the relative port is ready to accept a packet. Figure 4(b) shows the BAG for a generic switch. In the Idle state a switch consumes on average P . If there is at least one packet in at least one of the 5 input queues the switch passes to a ﬁctitious state (with l at ency = 0 and power = 0) in (swit ch) id l e queue in the port β is not full, or (ii) the input queue in the port β is full. In the former case, A can forward the packet, thus freeing a slot in the queue in port α. In the latter case, A has to wait for B to eliminate at least one packet from the input queue in port β before it can forward the packet. In general, therefore, the overall performance of the network (measured as the time required to handle all the incoming trafﬁc) improves if the size of the switch input queues increases. With an increased input queue capacity, in fact, a generic switch needing to forward a packet to another switch will have a greater probability of being able to queue the packet in the input port of the other switch. Figure 5 shows the time required to handle trafﬁc versus the size c i r t e m l y a e d 1400 1350 1300 1250 1200 1150 1100 0 20 40 60 80 100 120 140 queue length (packet) Figure 5: Trafﬁc draining time vs. switch input queue size. of input queues in the switch ports. The values were obtained on a 5x5 network. The latency and power attributes of the core BAGs were randomly set between 0 and 1 for each core and 0.1 for all the switches. The trafﬁc was generated considering communication between the network nodes to be equally probable (that is, the probability that node A will communicate with node B is equal to the probability that node C will communicate with node D, however A, B, C and D are taken). The ﬂow of data exchanged between two nodes has a Gausssian distribution with an average of 128 bytes and a variance of 64 bytes. Eight different traces formed by 100 patterns were injected in parallel, so as to simulate 8 concurrent communications at each instant. Each point in the graph was obtained by measuring the time taken to handle the trafﬁc in 100 different mappings and calculating the average value. It can, however, be observed that in some cases an increase in the c i r t e m l y a e d 1500 1450 1400 1350 1300 1250 1200 1 queue length = 2 queue length = 4 2 3 4 5 6 7 8 9 10 mapping Figure 6: Trafﬁc draining time for 10 different mappings and two different networks (with switch input queues of 2 and 4 packets). size of the switch queues may increase the trafﬁc handling time. Figure 6 shows this possibility. It gives the trafﬁc handling time for 10 different mappings with switches having input queues that allow a maximum of two and four packets to be queued. The trafﬁc (a) (b) Figure 4: Switch interface (a), Behavioural annotated graph of a switch (b). (swit ch) (swit ch) (swit ch) (swit ch) which the packet is read and immediately afterwards to the Routing state. In this state (which features an average power consumption of P rout ing and a latency of T rout ing ) the output port on which to route the packet is determined and the relative ﬁctitious state (LOCAL, NORTH, SOUTH, EAST, WEST) is entered. Only when the packet is ready to be transmitted (ready=true) does the switch pass to the Transmit state in which the packet at the head of the input queue is extracted and then, on expiry of the latency time T t ransmit , unconditionally returns to the Idle state, with an average power consumption of P t ransmit , which models the power consumed on the interconnection buses between the switches. The simulation is event-based and is performed by stimulating the network with concurrent trace ﬁles. Each trace ﬁle is a sequential list of communication patterns. Each pattern comprises three ﬁelds: a source identiﬁer, a destination identiﬁer, and the amount of information exchanged. The amount of trafﬁc sent by the source core to the destination core is subdivided into packets and each packet is routed according to the routing scheme and BAGs described above. 3. MOTIVATION In this section we wish to demonstrate (using an experimentbased approach) that accurate modeling of the communication dynamics is essential in order to evaluate a network. We will begin our analysis by considering as our performance parameter the speed at which a network handles a certain amount of incoming trafﬁc. This mainly depends on the speed at which the switches route packets. If, for example a switch A has to forward the packet at the head of the input queue from its port α to the port β in the adjacent switch B, two events can occur: (i) the input     niques, speciﬁcally genetic algorithms (GAs), to obtain an approximation of the Pareto-optimal performance/energy front. 4.1 Exploration Framework Figure 8 shows the framework for exploration of the space of possible mappings in mesh-based NoC architectures. It comprises handling times for the second network are generally shorter than those for the ﬁrst network, with one exception. With mapping 6, in fact, the trafﬁc is handled faster in the ﬁrst network. This behavior can only be detected via a dynamic analysis of the system, that is by taking into account the dynamic interaction between the various trafﬁc ﬂows, which is only possible by performing trace-based simulations. It should also be observed that the optimal mapping is greatly affected by the architectural parameters of the network. Let us consider, for example, the size of the switch input buffers. In Figure 6 it can be seen that a mapping may be optimal for one network but not for another. Of the 10 mappings considered, in fact, mapping 5 is by far the best for the second network but the second worst for the ﬁrst network. To evaluate the impact of mapping and relate it to the trafﬁc char3x3 4x4 5x5 1.45 1.4 1.35 1.3 1.25 1.2 1.15 1.1 1.05 e m i t i g n n a i r d n i m / x a m 1 0 2 4 6 concurrent communications 8 10 12 Figure 7: Relation between maximum and minimum trafﬁc draining time for 1,000 random mappings with varying numbers of concurrent communications and different network sizes. acteristics the following experiment was performed. 1000 mappings were randomly generated for each network n× n, n ∈ {3, 4, 5}. (cid:2)n2 /2(cid:3) simulations were run for each mapping, relating to different trafﬁc scenarios. These scenarios differed in the number of pairs of cores simultaneously communicating with each other. They range from an absolute lack of concurrency (that is, one and only one pair of cores are communicating at any one time) to maximum concurrency (at any one time there are (cid:2)n2 /2(cid:3) pairs of cores communicating with each other). Figure 7 shows the relationship between the maximum and minimum trafﬁc draining times for 1,000 random mappings in the trafﬁc scenarios described above. As can be seen, when the size of the network increases, so does the impact of mapping on performance. For a 5x5 network, for example, choosing a suitable mapping can improve performance by over 40%. It should be pointed out that these values are extremely conservative. They were obtained considering only 1,000 random mappings as compared with the 25! (cid:4) 1025 that are possible. It should also be noted that the impact of mapping depends greatly on the trafﬁc characteristics. In all the cases considered, the maximum impact is obtained in trafﬁc scenarios in which the number of pairs of cores communicating concurrently is equal to half the maximum number of pairs that can communicate concurrently. 4. MULTI-OBJECTIVE EXPLORATION OF THE MAPPING SPACE In this section we will describe our proposal for multi-objective exploration of the mapping space. To the best of our knowledge, our work is the ﬁrst to address the mapping problem in an multiobjective fashion. The approach uses evolutionary computing techFigure 8: Framework for simulation and exploration of the mapping space. two macro blocks: a NoC simulator (to evaluate the performance indexes to be optimized for any mapping), and an Exploration engine (which determines the next mapping to be evaluated). The inputs to the framework are: • Architectural parameters: for example, topology, network size, communication protocols, size of buffers in switches, priority assignment schemes, etc. • Application parameters: these mainly refer to the characteristics of the communication trafﬁc involved in the application being considered. • Set of BAGs: these specify the functional behavior of each element in the NoC and also contain characterization information for estimation of the timing and power consumption parameters. The ﬂow of operations involved in exploration generally consists of repeating two phases: evaluation of one or more mapping alternatives, and determination of the next mapping/s to be evaluated. The ﬁrst phase is carried out using a NoC simulator, which evaluates the performance indexes to be optimized. These represent the input for the second phase, which implements the exploration algorithm and produces the next mapping/s to be evaluated. The mappings evaluated are stored and can be used by the exploration algorithm to decide the next step. This iterative process is concluded when a stop criterion is met. Then the non-dominated mappings (Pareto     mappings) are extracted from the mappings evaluated. In this paper we will focus on the second phase of the framework, the one referring to the mapping space exploration algorithms. 4.2 GA-based Multi-objective Exploration of the Mapping Space When the exploration space is too vast to be explored exhaustively, a solution is to use evolutionary computing techniques. Genetic Algorithms (GAs) have found application in various VLSI design environments [10]: in problems relating to layout such as partitioning, placement and routing; in design problems including power estimation, low-power synthesis, technology mapping and netlist partitioning and in reliable chip testing through efﬁcient test vector generation. All these problems are untreatable, in the sense that no polynomial time algorithm can guarantee an optimal solution. In this paper we propose to use GAs for multi-objective mapping space exploration in a mesh-based NoC architecture in order to obtain an accurate approximation of the Pareto-optimal front of the mappings that optimize performance and power consumption. The approach is general because the solution to any problem using GAs only requires deﬁnition of a representation of the conﬁguration, genetic operators and objective functions to be optimized. It is also an efﬁcient approach because, as we shall see below, it only needs to visit a very limited number of conﬁgurations to provide an accurate approximation of the Pareto-optimal set. More speciﬁcally, we chose SPEA2 [14], which is very effective in sampling from along the entire Pareto-optimal front and distributing the solutions generated over the trade-off surface. To apply a GA to the problem being examined, it is necessary to deﬁne the chromosome and genetic operators. The chromosome is a representation of the solution to the problem, which in this case is described by the mapping. Each tile in theNoC has an associated gene which encodes the identiﬁer of the core mapped in the tile. In an n × m NoC, for example, the chromosome is formed by n × m genes. The i-th gene encodes the identiﬁer of the core in the tile in row (cid:2)i/n(cid:3) and column i%n (where the symbol % indicates the modulus operator). We use single-point-crossover and mutation to generate the next new population. More speciﬁcally, the function performed by the genetic operators is to remap hot spot cores in a random fashion (a hot spot core being one whose switch has a greater average buffer occupation). The deﬁnition of suitable and more effective genetic operators has a great impact on the results of the optimization. This is not, however the aim of this paper and remains a topic for future research. 4.3 Experiments We will start by evaluating the performance of the exploration strategy on a synthesized case, i.e. one in which the trafﬁc is generated statistically without particular reference to a speciﬁc application. We considered a 4x4 network and 8 traces of concurrent communications. The statistical distribution of the destination addresses was randomly chosen for each trace, and the size of the data ﬂow exchanged between two nodes had a Gaussian distribution with an average of 128 bytes and a variance of 64 bytes. The attributes of the BAGs for the cores and switches were chosen at random between 0 and 1 and four input queues were assigned to each switch. As it is computationally unfeasible to explore each possible mapping exhaustively, the solutions obtained using the proposed approach were compared with those obtained by randomly sampling the mapping space in 200,000 different points. Figure 9 shows the 200,000 random mappings evaluated and the Pareto fronts obtained by the proposed approach after 10, 20, 50 random GA, 10 gens GA, 20 gens GA, 50 gens GA, 100 gens x 104 2.85 c i r t e m y g r e n e 2.8 2.75 2.7 2.65 2.6 2.55 2.5 2.45 1050 1100 1150 1200 1250 1300 delay metric 1350 1400 1450 1500 1550 Figure 9: Evaluation of 200,000 random mappings and Pareto fronts obtained using the proposed approach. and 100 generations. As can be seen, after only 10 generations (using a population size and archive size of 50 and 10 elements respectively), the solutions obtained are not dominated by any of the 200,000 random mappings. The solutions obtained after 10 generations are better than those obtained by evaluating 200,000 random mappings. 10 generations required evaluation of only 680 mappings, i.e. less than 0.7%, with a consequent speedup of 147. To evaluate the proposed approach on a real case study, it was applied to a system comprising an MPEG-2 encoder and decoder [1]. The encoder was subdivided into 9 separate tasks and the decoder into 4 tasks, communicating with each other using a shared memory. They were assigned and scheduled on 12 IPs [4, 5, 6] comprising DSPs, generic processors, embedded DRAMs and customized ASICs. Figure 10 shows the partitioning of the application and assignment of the IPs. Figure 10: Partitioning of the MPEG-2 (encoder and decoder) application. The trafﬁc traces were obtained directly by executing the encoder/decoder application on the ﬁrst 5 frames of two different movie clips. The application was partitioned by identifying the parts that were to be implemented by the IPs chosen and then adding monitoring code in order to capture the inter-communication trafﬁc between the IPs. The data for characterization of the IPs were taken from their respective datasheets. To characterize the switches, a 5x5 switch was implemented in VHDL following the architecture described in [2]. It was synthesized with Synopsys Design Compiler using the Virtual Silicon 0.13µm, 1.2V technological library   High performance 0 1 2 0 ASIC2 ASIC5 ASIC1 1 ASIC3 ASIC4 MEM1 2 DSP3 DSP2 CPU2 3 MEM2 CPU1 DSP1 Execution time: 40.6 ms Energy: 18.9 mJ (a) Low energy 0 1 2 0 ASIC2 ASIC5 ASIC1 1 ASIC3 ASIC4 MEM1 2 CPU1 DSP1 CPU2 3 MEM2 DSP3 DSP2 Execution time: 41.4 ms Energy: 16.2 mJ (b) Figure 12: High performace mapping (a), and low energy mapping (b). and analyzed using Synopsys Design Power. Figure 11 shows the power and execution time values for 100,000 random GA, 5 gens GA, 20 gens GA, 100 gens 0.034 0.032 0.03 0.028 ) J ( y g r e n e 0.026 0.024 0.022 0.02 0.018 0.016 0.04 0.042 0.044 0.046 0.048 0.05 time (sec) 0.052 0.054 0.056 0.058 0.06 Figure 11: Evaluation of 100,000 random mappings and Pareto fronts obtained using the proposed approach on a 4x3 NoC in which an MPEG-2 encoder and decoder are mapped. random mappings. It also gives the Pareto front of the mappings obtained by the proposed approach after 5, 20 and 100 generations. As can be seen, after only 20 generations (which correspond to just over 1,000 simulations), the solutions obtained by the proposed approach are not dominated by any of the 100,000 random mappings and are very close to those obtained after 100 generations. Figure 12 shows the two mappings relating to the end points of the Pareto front which respectively determine maximum performance and minim power consumption. This example clearly shows the usefulness of multi-objective exploration Mono-objective exploration aiming at optimizing performance alone, for example, would have produced the mapping shown in Figure 12(a), neglecting the mapping in Figure 12(b) which, although it performs 2% less well, is 17% more efﬁcient from the point of view of power consumption. In Figure 12 the cores for the decoder subsystem are shown in bold type. It is interesting to note that the two subsystems are mapped in two disjoint partitions of the mesh. The genetic algorithm generally partitions the mesh into highly interactive clusters of cores and then optimizes the positioning of the cores in each cluster. At the same time it also optimizes inter-cluster communications, as can be seen by observing the two mappings shown in Figure 12. In both cases DSP1, which implements calculation of the DCT and IDCT, is mapped on the boundary between the two partitions as the core is used by both subsystems. 5. CONCLUSIONS In this paper we have proposed a strategy for topological mapping of IPs/cores in a mesh-based NoC architecture. The approach uses heuristics based on multi-objective genetic algorithms to explore the mapping space and ﬁnd the Pareto mappings that optimize performance and power consumption. The experiments carried out on both synthesized trafﬁc and real applications (an MPEG-2 encoder/decoder system) conﬁrm the efﬁciency, accuracy and scalability of the approach. Future developments will mainly address the deﬁnition of more efﬁcient genetic operators to improve the precision and convergence speed of the algorithm. Evaluation will also be made of the possibility of optimizing mapping by acting on other architectural parameters such as routing strategies, switch buffer sizes, etc. 6. "
2012,ORION 2.0 - A Power-Area Simulator for Interconnection Networks.,"As industry moves towards multicore chips, networks-on-chip (NoCs) are emerging as the scalable fabric for interconnecting the cores. With power now the first-order design constraint, early-stage estimation of NoC power has become crucially important. In this work, we present ORION 2.0, an enhanced NoC power and area simulator, which offers significant accuracy improvement relative to its predecessor, ORION 1.0.",
2013,A survey on application mapping strategies for Network-on-Chip design.,"Application mapping is one of the most important dimensions in Network-on-Chip (NoC) research. It maps the cores of the application to the routers of the NoC topology, affecting the overall performance and power requirement of the system. This paper presents a detailed survey of the work done in last one decade in the domain of application mapping. Apart from classifying the reported techniques, it also performs a quantitative comparison among them. Comparison has been carried out for larger sized test applications also, by implementing some of the prospective techniques.",
2012,Wireless NoC as Interconnection Backbone for Multicore Chips - Promises and Challenges.,"Current commercial systems-on-chips (SoCs) designs integrate an increasingly large number of predesigned cores and their number is predicted to increase significantly in the near future. For example, molecular-scale computing promises single or even multiple order-of-magnitude improvements in device densities. The network-on-chip (NoC) is an enabling technology for integration of large numbers of embedded cores on a single die. The existing method of implementing a NoC with planar metal interconnects is deficient due to high latency and significant power consumption arising out of long multi-hop links used in data exchange. The latency, power consumption and interconnect routing problems of conventional NoCs can be addressed by replacing or augmenting multi-hop wired paths with high-bandwidth single-hop long-range wireless links. This opens up new opportunities for detailed investigations into the design of wireless NoCs (WiNoCs) with on-chip antennas, suitable transceivers and routers. Moreover, as it is an emerging technology, the on-chip wireless links also need to overcome significant challenges pertaining to reliable integration. In this paper, we present various challenges and emerging solutions regarding the design of an efficient and reliable WiNoC architecture.",
2003,Design of a switch for network on chip applications.,"System on Chip (SoC) design in the forthcoming billion transistor era will involve the integration of numerous heterogeneous semiconductor intellectual property (IP) blocks. Some of the main problems in the ultra deep sub micron technologies characterized by gate lengths in the range of 50-100 nm arise from non-scalable global wire delays, failure to achieve global synchronization, errors due to signal integrity issues, and difficulties associated with non-scalable bus-based functional interconnect. These problems are addressed in this paper by introducing a new design methodology. A switch-based network-centric architecture to interconnect IP blocks is proposed. We introduce a butterfly fat tree architecture as an overall interconnect template. In this new interconnect architecture, switches are used to transfer data between IP blocks. To reduce overall latency and hardware overhead, wormhole routing is adopted. The proposed switch architecture supports this routing method. Initial implementation of the switch reveals that the total switch area is expected to amount to less than 2% of a large SoC.",
2004,Spidergon - a novel on-chip communication network.,"Summary form only given. The SoC (System on Chip) design demands for novel architectural and circuital solutions to cope with the global wires issue, pushing the on-chip communication as a crucial and precious resource. In the context of the communication centric paradigm and according to a layered based design, it is foreseen that current on-chip shared bus will be, at least partially, replaced by a micronetwork interconnection implementing a flexible packet-based communication (A. Jantsch and H. Tenhunen, ""Networks on Chip"", Kluwer Academic Publishers, 2003). We state that the availability of an efficient on-chip communication platform is one of the most important enabling factors for the development of efficient and cost effective multi processor SoC in the near and long-term future. This summary presents the low cost, high performance on-chip communication network, called Spidergon, developed by the AST (Advanced System Technology) of STMicroelectronics as the possible evolution of STBus technology.",
2007,Predator - a predictable SDRAM memory controller.,"Memory requirements of intellectual property components (IP) in contemporary multi-processor systems-on-chip are increasing. Large high-speed external memories, such as DDR2 SDRAMs, are shared between a multitude of IPs to satisfy these requirements at a low cost per bit. However, SDRAMs have highly variable access times that depend on previous requests. This makes it difficult to accurately and analytically determine latencies and the useful bandwidth at design time, and hence to guarantee that hard real-time requirements are met. The main contribution of this paper is a memory controller design that provides a guaranteed minimum bandwidth and a maximum latency bound to the IPs. This is accomplished using a novel two-step approach to predictable SDRAM sharing. First, we define memory access groups, corresponding to precomputed sequences of SDRAM commands, with known efficiency and latency. Second, a predictable arbiter is used to schedule these groups dynamically at run-time, such that an allocated bandwidth and a maximum latency bound is guaranteed to the IPs. The approach is general and covers all generations of SDRAM. We present a modular implementation of our memory controller that is efficientlyintegrated into the network interface of a network-on-chip. The area of the implementation is cheap, and scales linearly with the number of IPs. An instance with six ports runs at 200 MHz and requires 0.042mm2 in 0.13μm CMOS technology.","Predator: A Predictable SDRAM Memory Controller Benny Akesson Technische Universiteit Eindhoven The Netherlands k.b.akesson@tue.nl Kees Goossens NXP Semiconductors Research & Delft University of Technology The Netherlands kees.goossens@nxp.com Markus Ringhofer Graz University of Technology Austria markus.ringhofer@tugraz.at ABSTRACT Memory requirements of intellectual property components (IP) in contemporary multi-processor systems-on-chip are increasing. Large high-speed external memories, such as DDR2 SDRAMs, are shared between a multitude of IPs to satisfy these requirements at a low cost per bit. However, SDRAMs have highly variable access times that depend on previous requests. This makes it difﬁcult to accurately and analytically determine latencies and the useful bandwidth at design time, and hence to guarantee that hard real-time requirements are met. The main contribution of this paper is a memory controller design that provides a guaranteed minimum bandwidth and a maximum latency bound to the IPs. This is accomplished using a novel two-step approach to predictable SDRAM sharing. First, we deﬁne memory access groups, corresponding to precomputed sequences of SDRAM commands, with known efﬁciency and latency. Second, a predictable arbiter is used to schedule these groups dynamically at run-time, such that an allocated bandwidth and a maximum latency bound is guaranteed to the IPs. The approach is general and covers all generations of SDRAM. We present a modular implementation of our memory controller that is efﬁciently integrated into the network interface of a network-on-chip. The area of the implementation is cheap, and scales linearly with the number of IPs. An instance with six ports runs at 200 MHz and requires 0.042 mm2 in 0.13μm CMOS technology. Categories and Subject Descriptors: B.8.2 [Performance and reliability]: Performance Analysis and Design Aids General Terms: Design, Reliability, Veriﬁcation Keywords: System-on-Chip, Memory Controller, SDRAM, Predictability 1. INTRODUCTION Chip design is getting increasingly complex, as technological advances allow highly integrated systems on a single piece of silicon. A contemporary multi-processor system-on-chip (SoC) features a large number of intellectual property components (IP), such as streaming hardware accelerators and processors with caches, which communicate through shared memory. The resulting memPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’07, September 30–October 3, 2007, Salzburg, Austria. Copyright 2007 ACM 978-1-59593-824-4/07/0009 ...$5.00. ory trafﬁc is dynamic and the arrivals of requests at the memory controller are not fully known at design time. Some of the IPs have hard real-time requirements that must be satisﬁed to ensure the functional correctness of the SoC [5]. High-speed external memories, such as DDR2 SDRAMs [10], are used, as the memory capacity requirements of these systems cannot be satisﬁed in a cost-effective way by on-chip SRAM. These memories must be efﬁciently utilized, as they are one of the main SoC performance bottle-necks [5]. A difﬁculty when sharing SDRAM is that they have a highly variable access time that depends on previous requests, resulting in interference between the IPs sharing the resource, hereafter referred to as requestors. As a consequence, the amount of available bandwidth to/from external memory that is useful to the IP, referred to as net bandwidth, also depends on trafﬁc [19]. These effects complicate analytical design-time veriﬁcation, which is required to guarantee that hard real-time requirements are satisﬁed. Existing external memory controllers are either not sufﬁciently ﬂexible to handle the increasing complexity of SoCs, or do not support analytical design-time veriﬁcation of hard real-time requirements. Statically scheduled memory controllers execute precomputed schedules, which makes them predictable, but also unable to adapt to changes in trafﬁc and distinguish latency requirements of critical requestors without over-allocating. Other controllers use dynamic scheduling [13] that is ﬂexible and maximize the offered net bandwidth, but where it is difﬁcult to bound the latency of a request analytically. As a result, the offered net bandwidth can only be estimated by simulation, making bandwidth allocation a difﬁcult task that must be re-evaluated every time a requestor is added, removed or changes conﬁguration. The main contribution of this paper is a memory controller design that provides a guaranteed minimum net bandwidth and a maximum latency bound to the requestors. This is accomplished using a novel two-step approach to predictable shared SDRAM access that combines elements of statically and dynamically scheduled memory controllers. First, we deﬁne read and write groups, corresponding to static sequences of SDRAM commands, with known efﬁciency and latency. This allows a lower bound on the offered net bandwidth to be determined. Second, requestors are scheduled dynamically at run-time by a Credit-Controlled Static-Priority (CCSP) [1] arbiter that is composed of a rate regulator and a scheduler. The rate regulator isolates requestors and guarantees their allocated net bandwidths independently of each other’s behavior. The static-priority scheduler provides a maximum latency bound that is decoupled from the allocated bandwidth. The implementation of the design is modular and the area scales linearly with the number of requestors. An instance with six ports runs at 200 MHz and requires 0.042 mm2 in 0.13μm CMOS technology. This paper is organized as follows. In Section 2, we review related work. We proceed in Section 3 by brieﬂy explaining the basic operation of an SDRAM and deﬁning the concept of memory efﬁciency. In Section 4, we propose a solution to the problem that allows us to verify at design time that bandwidth and latency requirements are satisﬁed. We show the implementation of our memory controller in Section 5, before discussing experimental results in Section 6. Finally, we present conclusions and future work in Section 7. 2. RELATED WORK External memory controllers can be statically or dynamically scheduled. The level of predictability is high for statically scheduled controllers, as the latency of a request and the offered net bandwidth can be computed at design time. For this reason, statically scheduled memory controllers are used in some embedded systems with very strict real-time requirements, such as TV picture improvement ICs [15]. However, the precomputed schedule makes these controllers unable to adapt to any changes in trafﬁc. Requestors have to wait for their reserved slots in the schedule before they receive service, which makes latency inversely proportional to the allocated bandwidth. This coupling between latency and allocated bandwidth makes these controllers unable to distinguish requestors with low latency requirements without reserving more slots in the schedule, resulting in low memory utilization. Finally, a large number of schedules have to be computed and stored in memory, as convergence of application domains in new SoCs causes a combinatorial explosion with respect to the number of usecases [8]. These properties prevent statically scheduled controllers from scaling to larger systems with more requestors and more dynamic applications. Dynamically scheduled memory controllers are more prevalent in areas where the trafﬁc is not known up front, and target high ﬂexibility and efﬁciency, at the expense of predictability. They offer sophisticated features, such as support for preemption and reordering [13], to optimize the offered net bandwidth and average latency. These features complicate design-time analysis and make it very difﬁcult to provide analytical latency bounds. The dynamically scheduled SDRAM controllers in [9, 11, 18] all use priorities to decouple latency and rate, and provide rate regulation to isolate requestors and prevent starvation. The arbitration in [11] supports preemption for high-priority requestors to reduce latency. Like [12, 18], it furthermore considers the memory state when scheduling to increase the amount of net bandwidth. No analytical bounds are presented on latency or on net bandwidth for any of these controllers thus preventing analytical design-time veriﬁcation of hard real-time requirements. A streaming memory controller is presented in [2] that uses an access granularity of a full row (1 KB) to minimize power. Although this granularity allows the amount of net bandwidth to be determined at design time, it results in high latencies and large buffering. The scheduler is similar to weighted round-robin, which provides isolation of requestors through rate regulation, but does not decouple latency and rate. No general latency bounds are presented for this controller. 3. SHARING SDRAM This section addresses the difﬁculties with sharing SDRAM in a predictable manner. First, Section 3.1 brieﬂy presents the basics of SDRAM operation. We proceed in Section 3.2 by deﬁning memory efﬁciency, and giving some insight into the complexities of determining the net bandwidth provided by an SDRAM at design time. 3.1 SDRAM operation SDRAMs have a three dimensional layout. The three dimensions are banks, rows and columns. A bank stores a number of word-sized elements in rows and columns, as shown in Figure 1. Description ACT to ACT cmd delay (same bank) ACT to ACT cmd delay (diff. bank) ACT to RD or WR cmd delay PRE to ACT cmd delay Average REF to REF cmd delay REF to ACT cmd delay CAS latency Write recovery time Write-to-read turn-around time Read-to-write turn-around time Parameter Min. cycles 11 2 3 3 1560 15 3 3 2 4 / 6a tRC tRRD tRCD tRP tREFI tRFC CL tWR tWTR tRTW Table 1: Relevant timing parameters for a 32Mb x16 DDR2400B memory device. a 4 cycles if BL = 4 and 6 cycles if BL = 8 On an SDRAM access, the address of the request is decoded into bank, row and column addresses using a memory map. A bank has two states, idle and active. The bank is activated from the idle state by an activate (ACT) command that loads the requested row onto a row buffer, which stores the most recently activated row. Once the bank has been activated, column accesses such as read (RD) and write (WR) bursts can be issued to access the columns in the row buffer. These bursts have a programmable burst length (BL) of 4 or 8 words (for DDR2 SDRAM). Finally, a precharge (PRE) command is issued to return the bank to the idle state. This stores the row in the buffer back into the memory array. Read and write commands can be issued with an auto-precharge ﬂag resulting in an automatic precharge at the earliest possible moment after the transfer is completed. In order to retain data, all rows in the SDRAM have to be refreshed regularly, which is done by precharging all banks and issuing a refresh (REF) command. If no other command is required during a clock cycle, a no-operation (NOP) command is issued. bank activate precharge row buffer read write Figure 1: The multi-banked architecture of SDRAM. SDRAMs have timing constraints deﬁning the required minimum delay between different commands. Table 1 summarizes the most relevant constraints for a 64 MB DDR2-400B [10] device, which serves as example memory throughout this paper. The core of this memory runs at 200 MHz and the data bus at 400 MHz, as it transfers data on both the rising and falling edges of the core clock. A beneﬁt of a multi-bank architecture is that commands to different banks can be pipelined. While data is being transferred to or from a bank, the other banks can be precharged and activated with another row for a later request. This process, called bank preparation, sometimes completely hides the precharge and activate delays. 3.2 Memory efﬁciency The bandwidth available from a memory ideally corresponds to the product of the word width and the clock frequency, referred to as the peak bandwidth (800 MB/s for our device). SDRAMs cannot, however, be fully utilized due to stall cycles caused by the timing constraints of the memory or memory controller policies. This is captured by the concept of memory efﬁciency. Memory efﬁciency is deﬁned as the fraction of the amount of clock cycles in which requested data is transferred, and the total number of clock cycles. Net bandwidth is hence the product of the peak bandwidth and the memory efﬁciency. A useful classiﬁcation of memory efﬁciency into ﬁve categories is presented in [19]. The categories are: 1) refresh efﬁciency, 2) read/write efﬁciency, 3) bank efﬁciency, 4) command efﬁciency, and 5) data efﬁciency. Memory efﬁciency can be expressed as the product of these efﬁciencies. All of these categories, except refresh efﬁciency, are trafﬁc dependent, and hence difﬁcult to determine at design time. We proceed by brieﬂy looking into the different categories. Refresh efﬁciency An SDRAM needs to be refreshed regularly in order to retain data integrity. A refresh command that requires tRFC cycles to complete must be issued every tREFI cycles on average. Before the refresh command is issued, all banks have to be precharged. Refresh efﬁciency, eref , is independent of trafﬁc, and can be calculated at design time. Refresh efﬁciency depends on the memory size, and is typically between 95-99% for DDR2 memories. Read/write efﬁciency SDRAMs have a bi-directional data bus that requires time to switch from read to write and vice versa. This results in lost cycles as the direction of the data bus is being reversed. In order to use the data bus of a DDR SDRAM at maximum efﬁciency, a read or write command must be issued every BL/2 cycles. We quantify the cost of switching directions as the number of extra cycles before the read or write command can be issued, which can be derived from [10]. The cost of a read/write switch is trtw = tRTW − BL/2 and for a write/read switch twtr = CL−1+tWTR , corresponding to 2 cycles and 4 cycles, respectively, for our example memory. Read/write efﬁciency, erw , depends on the number of read/write switches, and cannot be determined at design time, unless the read and write mix is known. The worst-case read/write efﬁciency for trafﬁc consisting of 70% reads and 30% writes equals 93.8%, according to a formula presented in [19]. Bank efﬁciency The access time of an SDRAM is highly variable. A read or write command can be issued immediately to an active row. If a command, however, targets an inactive row (row miss), it ﬁrst requires a precharge followed by an activate command. This requires at least an additional tRP +tRCD cycles (6 cycles for our memory) before the read or write command can be issued. The penalty can be even larger, as tRC cycles must separate one activate command from another within the same bank, according to Table 1. This overhead is captured by bank efﬁciency, ebank , which is highly dependent on the target addresses of requests, and how they are mapped to the different banks of the memory by the memory map. Command efﬁciency Even though a DDR device transfers data on both the rising and the falling edge of the clock, commands can only be issued once every clock cycle. Sometimes a required activate or precharge command has to be delayed because another command is already issued in that clock cycle. This results in lost cycles when a read or write command has to be postponed due to a row miss. The impact of this is connected to the burst length, where smaller bursts result in lower efﬁciency. Command efﬁciency, ecmd , is trafﬁc dependent and can generally not be calculated at design time, but is estimated in [19] to be between 95-100%. Data efﬁciency Data efﬁciency, edata , is deﬁned as the fraction of a memory access that actually contains requested data. This can be less than 100% since external memories are accessed with a minimum burst length; four words for a DDR2 SDRAM. The problem is not only related to ﬁne-grained requests, but also to how data is aligned with respect to a memory burst. This is because a burst is required to access BL words from an address that is evenly divisible by the burst length. Data efﬁciency is trafﬁc dependent, but can be computed at design time if the minimum access granularity of the memory, and the size and alignment of requests are known. For example, a large aligned cache line from an L2 cache typically has a data efﬁciency of 100%. On the other hand, [19] computes a data efﬁciency of 75% for an MPEG2 stream. For the purpose of this paper, we assume aligned requests with a size that is a multiple of the ﬁxed access granularity, unless otherwise noted, which results in a data efﬁciency of 100%. We conclude from this section that it is, in general, difﬁcult to determine memory efﬁciency analytically at design time. Figure 2 shows the worst-case memory efﬁciency (excluding data efﬁciency), resulting from simple worst-case analysis, for burst lengths of four and eight words. The calculated efﬁciency assumes that every burst targets a different row in the same bank, and that there is a read/write switch between every burst. This results in unacceptably low efﬁciency, less than 40% for all memories in the ﬁgure, due to bank conﬂicts (that hide the read/write switching cost). We conclude from the ﬁgure that we must be able to guarantee at design time that fewer bank conﬂicts occur to improve efﬁciency and provide a tighter bound than that of simple worst-case analysis. We furthermore see that the worst-case efﬁciency drops as the memories become faster, indicating that the problem is becoming more severe. The reason is that the timings in the memory core are more or less the same for all DDR2 memories. Increasing clock frequencies hence results in longer timings measured in clock cycles. This trend is expected to continue into the DDR3 generation of SDRAM. Burst size 8 Burst size 4 ] % [ y c n e c i i f f e e s a c t s r o W  100  80  60  40  20  0 D D D D D D D D R R R R 2 4 0 0 B 2 5 3 3 B 2 6 6 7 2 8 0 0 C C Memory device Figure 2: Worst-case memory efﬁciency for a number of DDR2 memories. 4. PROPOSED SOLUTION In this section we present a novel approach to memory controller design that allows us to provide a net bandwidth guarantee and a maximum bound on latency. We present three memory access groups in Section 4.1 and derive a lower bound on memory efﬁciency based on the classiﬁcation in Section 3.2. We proceed in Section 4.2 by explaining how a predictable arbiter schedules these groups dynamically at run-time to provide a guaranteed net bandwidth and maximum latency bound, while keeping requestors isolated.     4.1 Memory access groups Memory access in our memory controller design is based on three memory access groups, a read group, a write group, and a refresh group. In this section, we show how to construct these groups to account for the different categories of memory efﬁciency, such that the efﬁciency of an arbitrary combination of groups can be bounded at design time. The groups used in this paper have been composed manually for our example memory, although the method is general and applies to all SDRAMs. The read and write groups are composed of one read or write burst to all banks in sequence. This is a highly efﬁcient way to access memory that makes maximum use of bank preparation. A granularity of BL × nbanks × wmem B, where nbanks correspond to limitation of this approach is that memory is accessed with a ﬁxed the number of banks and wmem to the width of the memory interface. This equals 64 B for our example memory with a burst length of eight words and four banks. Some SoCs, such as [4], are designed with the efﬁciency of SDRAM in mind, and choose the request sizes of the IPs as a multiple of this granularity where possible. This access granularity also ﬁts well with the size of a typical L2 cache line, and even with the L1 cache line size of certain processors, such as the TriMedia 3270 [17]. Smaller grained accesses are supported by applying a read or write mask and throwing away unwanted data, which impacts the data efﬁciency of the solution. The read and write groups are designed to eliminate interference between requestors. This is accomplished by ensuring that an arbitrary row can be activated without delay cycles caused by previous requests. According to [10], two timing constraints must be satisﬁed for this to hold. First, there must be at least tRC cycles between consecutive activate commands to the same bank. Second, there must be at least tWR + tRP cycles from the completion of the last write burst to a bank, before a new activate command can be issued to that bank. All bank conﬂicts are accounted for once these constraints are met. One read or write burst to each bank with burst length 8 satisﬁes these requirements for our example memory and yield a bank efﬁciency of 100%. Figure 3 shows a read and a write group for our example memory. The numbers in the ﬁgure correspond to the number of the corresponding bank. We have wrapped the elements on the data bus with respect to the length of the groups. This shows that the groups are pipelined and very efﬁcient, as they transfer data during all cycles when groups of the same type follow each other. All read and write commands are issued with auto precharge, since we want to be able to activate an arbitrary row as fast as possible. There is no contention on the command bus in these groups, and the command efﬁciency is hence 100%. Unlike [19], we do not use the average read/write mix to compute the read/write efﬁciency, as this average may not be representative for shorter intervals. This may result in less available net bandwidth than computed during these intervals, potentially violating the bandwidth guarantees of the requestors. Our bound on read/write efﬁciency is computed according to Equation (1), where tgroup corresponds to the number of cycles in the read and cmd data ACT RD ACT RD ACT RD ACT 0 NOP NOP 0 1 NOP NOP 1 2 NOP NOP 2 3 NOP NOP 2 2 2 2 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 RD 3 cmd data ACT WR ACT WR ACT WR ACT 0 NOP NOP 0 1 NOP NOP 1 2 NOP NOP 2 3 NOP NOP 2 2 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 WR 3 22 Figure 3: Read group (above) and write group (below) with burst length 8 for DDR2-400. write groups. The equation determines the fraction of cycles during one read and one write group that data is transferred, assuming a maximum number of switches. This results in a lower bound on read/write efﬁciency of 84.2%. erw = 2 × BL/2 × nbanks 2 × tgroup + trtw + twtr (1) The refresh group consists of a single refresh command issued after 10 NOP commands. This gives just enough time for the last auto precharge from a write group to ﬁnish. This is the worst case, as auto precharge after a read group ﬁnishes faster. The refresh requires tRFC cycles to ﬁnish, giving the refresh group for our example memory a total length tref = 25 cycles. A refresh group is scheduled as soon as possible after tREFI − twtr − tgroup cycles. This avoids preempting a group in progress, while ensuring that a refresh command is issued at least every tREFI cycles. The switching cost from write to read is used in the expression, as it is larger than its counterpart in the other direction for all DDR2 memories. It furthermore takes four cycles before the ﬁrst read or write command is issued after the refresh group is ﬁnished, as shown in Figure 3. Refresh efﬁciency, for our example, hence equals 98.1%, according to Equation (2). eref = 1 − 10 + 4 + tRFC tREFI − twtr − tgroup (2) conclude that our solution provides a guaranteed efﬁciency of eref × Having accounted for all categories of memory efﬁciency, we erw × ebank × ecmd × edata = 0.981 × 0.842 × 1 × 1 × 1 = 82.6% for aligned requests with a size that is a multiple of the ﬁxed access granularity. This corresponds to 660.9 MB/s for our memory. Read and write groups with burst length 4 have also been composed. These groups require 12 cycles to satisfy all timing requirements, and result in a memory efﬁciency of 60.3%. This choice may be beneﬁcial for systems with smaller request sizes, as the access granularity is reduced to 32 B, which may increase data efﬁciency. 4.2 Arbitration A predictable arbiter is required to schedule the memory access groups in order to bound latency. Our approach is valid for any arbiter providing a maximum latency bound, but we have chosen a Credit-Controlled Static-Priority arbiter [1] for our implementation. A CCSP arbiter consists of a rate regulator and a static-priority scheduler. This particular scheduler ﬁts well with our requirements for ﬁve reasons: 1) it isolates requestors by means of rate regulation, 2) it guarantees an allocated bandwidth and a maximum latency bound, 3) it decouples latency and rate using priorities, 4) it has negligible over-allocation, and 5) it has a cheap RTL implementation and runs at high speed. Requestors are characterized according to the (σ, ρ) model [3], which uses a linear function to bound the amount of requested data in an interval. The bounding function is determined by two parameters, burstiness, σ , and average request rate, ρ. Burstiness can be interpreted as the maximum amount of data that can be requested at any instant in time. Since memory requests are served by the memory controller in a non-preemptive manner, the maximum request size, ˆs, for each requestor is also required to be speciﬁed. A graphical interpretation of this terminology is shown in Figure 4. The characterization of requestors is deﬁned in Deﬁnition 1, where R is the set of requestors sharing the resource. An abstract resource view is used in [1], where a service unit corresponds to the access granularity of the resource. We hence express σ and ˆs in units of the ﬁxed granularity of the read and write groups. We furthermore express ρ as the required fraction of the available net bandwidth. e v i t a u l m u C a t a d σ ˆδ ρ Time [cycles] e s s n e o u p e s u e Q R ˆw w w(cid:2) ˇw(cid:2) Network Interface Memory Controller logical addr Memory Mapping t s s e e u u e q u e R Q physical addr write data t s e u q e r i g n d n e p Arbiter Controller Engine Command Generator cmd M A R D S read data Figure 4: Request curve and service curve along with their corresponding bounds. Figure 5: Memory controller architecture. D E FIN I T ION 1. The amount of requested data, w , by a requestor r ∈ R is characterized as (σ , ρ, ˆs). The amount of requested data is in any time interval [τ , t] upper bounded by ˆw(t − τ ) = σ + ρ × (t − τ ). The rate regulator isolates requestors from each other and protects requestors that behave according to their speciﬁcation from those that do not, by enforcing the speciﬁed rate and burstiness. A requestor that does not behave according to its speciﬁcation hence only invalidates its own latency guarantee. This is a key property in providing guaranteed service to requestors with timing constraints [20], and ﬁts with the requirement that requestors must be isolated. latency-rate (LR) servers [16] and guarantees a requestor its alloIt is shown in [1] that a CCSP arbiter belongs to the class of cated bandwidth, ρ, and a maximum delay bound, ˆδ . Delay is deﬁned as the time a request spends from entering the request queue until it is scheduled. The maximum delay for a requestor with priority level p (lower level indicates higher priority) is computed according to Equation (3), where max∀r∈R ˆsr accounts for that requests in progress are not allowed to be preempted. This is a standard delay bound [3] for static-priority schedulers in combination with (σ, ρ)-constrained requestors that deﬁnes a guaranteed service curve, ˇw (cid:4) , as shown in Figure 4. 1 − (cid:2)p−1 Due to the abstract resource view, the maximum delay in Equation (3) is expressed as the maximum number of read or write groups that are scheduled before the ﬁrst group of the considered request. Equation (5) translates this into clock cycles. It is straightforward to compute the time before the ﬁrst or last data word of the request is available in the response queue of the requestor, considering that the exact compositions of the groups are known. Equation (4) computes the time of the read and write groups, plus the maximum additional time required for read/write switches. This considers read requests, which is the worst-case, as their experienced switching cost is slightly higher than that of a write group. Equation (5) adds the maximum interference from refreshes during this interval. j=0 σj j=0 ρj max∀r∈R ˆsr + (cid:2)p ˆδp = (3) (cid:3) (cid:4) (cid:5) (cid:6) taux (x) = x × tgroup + x + 1 2 × twtr + x + 1 2 × trtw (4) (cid:3) ttot (x) = (cid:4) taux (x) tREFI − twtr − tgroup × tref + taux (x) (5) 5. CONTROLLER ARCHITECTURE The proposed memory controller has been implemented in VHDL in the context of a multi-processor SoC that is interconnected using the Æthereal NoC [6]. The memory controller architecture, shown in Figure 5, is modular and consists of four functional blocks: 1) Controller Engine, 2) CCSP Arbiter, 3) Memory mapping, and 4) Command Generator. Requests arrive at a network interface (NI) [14] on the edge of the network, where they are buffered in separate request queues per requestor. The requestors are mapped to request queues, according to their priorities. Priorities are changed between use-cases by using the reconﬁguration abilities of Æthereal [7] to change the mapping of requestors to queues. The NI signals to the arbiter, for each requestor, the size of the request at the head of the queue and if it is a read or a write. Once the memory controller is ready for a new group, the controller engine instructs the arbiter to schedule a requestor. The static-priority scheduler is implemented by a tree of multiplexors that grants access to the highest priority requestor that has a pending request that is considered eligible by the rate regulator. An index identifying the scheduled requestor is returned to the controller engine along with a read/write identiﬁer. The controller engine uses this information to route the destination address to the memory mapping and data to and from the appropriate queue in the NI. The memory mapping decodes the logical memory addresses of the requestors, into a physical SDRAM address consisting of bank, row and column. An interleaving memory map is used to map the bursts of a group to different banks, as mentioned in Section 4.1. For our example groups with burst length 8, this is implemented by letting bits 3 to 4 in the logical memory address index the bank, 12 to 24 index the row, and 0 to 2 and 5 to 11 index the column. The command generator generates the SDRAM commands corresponding to the scheduled memory access group. This is the only part of the design that requires modiﬁcation if the target memory is changed. The design is small for two reasons. First, because there are no data buffers in the controller, as it re-uses buffering already present in the network interface. Second, unlike [9, 11], the command generator does not need to use registers to track the memory state, since the memory access groups are designed with the timing constraints of the memory in mind. Synthesis results in 0.13μm CMOS technology with six ports and a speed target of 200 MHz resulted in a total area of 0.042 mm2 . The arbiter is the dominant block of the synthesized instance, as it accounts for almost half the total area. Figure 6 shows a linear increase in the area of the arbiter as the number of ports increase. The sizes of the memory mapping, command generator and controller engine are constant and hence unaffected by the number of ports. ] 2 m m [ a e r A  0.07  0.06  0.05  0.04  0.03  0.02  0.01  0 2 4 6 8 10 12 Ports Figure 6: Controller area depending on the number of ports. Requestor r0 r1 r2 r3 Bandwidth [B] Max [ns] Bound [ns] 16499968 204 340 16500032 304 615 16499968 463 1185 16499968 732 2810 Table 2: Results for use-case with four requestors with identical behavior. 6. EXPERIMENTAL RESULTS We demonstrate the analysis of the memory controller by observing simulation results from a SystemC model. The model is implemented on the level of basic groups and is timing accurate. For ease of understanding, we choose a simple use-case with four hard real-time requestors, mimicked by trafﬁc generators. The requestors have identical behavior with net bandwidth requirements of 165 MB/s (ρ = 0.249) and burst sizes of 64 B (ˆs = 1). This corresponds to a total load of 660 MB, or 82.5% of the peak bandwidth. Priorities are assigned to the requestors in ascending order, such that r0 have the highest priority, and r3 the lowest. Requests are issued periodically, although jitter is introduced by the network. Setting σ = 1.3 accounts for this jitter and prevents the rate regulator from slowing down the requestors, as long as they behave according to their speciﬁcation. The use-case was simulated during 108 ns. Table 2 shows that all requestors receive their allocated bandwidth, and that the maximum measured delay is less than the calculated bound for all requestors. We observe that the difference between the maximum measured delay and the bound gets larger for lower priority requestors. A reason for this is that the risk of maximum interference from higher priority requestors becomes increasingly unlikely for every requestor. To illustrate the beneﬁts of rate regulation, we doubled the requested bandwidth of r0 without changing the requestor characterization in the rate regulator. Table 3 shows that this causes the maximum measured delay to explode for r0 , while the others still enjoy their guarantees. All requestors still receive their allocated bandwidth, and r0 even receives some extra, since there is slightly more offered net bandwidth than indicated by the lower bound. This is because the worst-case amount of read/write switches did not occur. These results conﬁrm that rate regulation allows us to give hard real-time guarantees to requestors that behave according to their speciﬁcation in the presence of, for example, soft real-time requestors that cannot be accurately characterized. 7. CONCLUSIONS AND FUTURE WORK In this paper, we present a memory controller design that provides a guaranteed minimum bandwidth and a maximum latency bound to the IPs. This is accomplished using a novel two-step approach to predictable SDRAM sharing. First, we deﬁne memory access groups, corresponding to precomputed sequences of SDRAM Requestor r0 r1 r2 r3 Bandwidth [B] Max [ns] Bound [ns] 17327104 5316 340 16500032 303 615 16499968 364 1185 16499968 737 2810 Table 3: Results for use-case where r0 is over-asking. commands, with known efﬁciency and latency. Second, a predictable arbiter is used to schedule these groups dynamically at run-time, such that an allocated bandwidth and a maximum latency bound is guaranteed to the IPs. We present a modular implementation of our memory controller that is efﬁciently integrated into the network interface of a network-on-chip. The area of the implementation is cheap, and scales linearly with the number of IPs. An instance with six ports runs at 200 MHz and requires 0.042 mm2 in 0.13μm CMOS technology. Future work in this direction involves developing an algorithm for automatic generation of memory access groups, given a set of memory timings and a burst size. With this it is possible to generate the VHDL code for the corresponding command generator. This signiﬁcantly reduces the effort to provide a low-cost predictable memory controller design for an arbitrary SDRAM memory. 8. "
2010,ATAC - a 1000-core cache-coherent processor with on-chip optical network.,"Based on current trends, multicore processors will have 1000 cores or more within the next decade. However, their promise of increased performance will only be realized if their inherent scaling and programming challenges are overcome. Fortunately, recent advances in nanophotonic device manufacturing are making CMOS-integrated optics a reality-interconnect technology which can provide significantly more bandwidth at lower power than conventional electrical signaling. Optical interconnect has the potential to enable massive scaling and preserve familiar programming models in future multicore chips. This paper presents ATAC, a new multicore architecture with integrated optics, and ACKwise, a novel cache coherence protocol designed to leverage ATAC's strengths. ATAC uses nanophotonic technology to implement a fast, efficient global broadcast network which helps address a number of the challenges that future multicores will face. ACKwise is a new directory-based cache coherence protocol that uses this broadcast mechanism to provide high performance and scalability. Based on 64-core and 1024-core simulations with Splash2, Parsec, and synthetic benchmarks, we show that ATAC with ACKwise out-performs a chip with conventional interconnect and cache coherence protocols. On 1024-core evaluations, ACKwise protocol on ATAC outperforms the best conventional cache coherence protocol on an electrical mesh network by 2.5x with Splash2 benchmarks and by 61% with synthetic benchmarks.",
2012,Xpipes - A latency insensitive parameterized network-on-chip architecture for multi-processor SoCs.,"The growing complexity of customizable embedded multi-processor architectures for digital media processing will soon require highly scalable network-on-chip based communication infrastructures. In this paper, we propose xpipes, a scalable and high-performance NoC architecture for multi-processor SoCs, consisting of soft macros that can be turned into instance-specific network components at instantiation time. The flexibility of its components allows our NoC to support both homogeneous and heterogeneous architectures. The interface with IP cores at the periphery of the network is standardized (OCP-based). Links can be pipelined with a flexible number of stages to decouple data introduction speed from worst-case link delay. Switches are lightweight and support reliable communication for arbitrary link pipeline depths (latency insensitive operation). xpipes has been described in synthesizable SystemC, at the cycle-accurate and signal-accurate level.",
2004,On-chip traffic modeling and synthesis for MPEG-2 video applications.,"The objective of this paper is to introduce self-similarity as a fundamental property exhibited by the bursty traffic between on-chip modules in typical MPEG-2 video applications. Statistical tests performed on relevant traces extracted from common video clips establish unequivocally the existence of self-similarity in video traffic. Using a generic tile-based communication architecture, we discuss the implications of our findings on on-chip buffer space allocation and present quantitative evaluations for typical video streams. We also describe a technique for synthetically generating traces having statistical properties similar to those obtained from real video clips. Our proposed technique speeds up buffer simulations, allows media system designers to explore architectures rapidly and use large media data benchmarks more efficiently. We believe that our findings open new directions of research with deep implications on some fundamental issues in on-chip networks design for multimedia applications.",
2004,"On-chip networks - A scalable, communication-centric embedded system design paradigm.","As chip complexity grows, design productivity boost is expected from reuse of large parts and blocks of previous designs with the design effort largely invested into the new parts. More and more processor cores and large, reusable components are being integrated on a single silicon die but reuse of the communication infrastructure has been difficult. Buses and point to point connections, that have been the main means to connect components on a chip today, will not result in a scalable platform architecture for the billion transistor chip era. Buses can cost efficiently connect a few tens of components. Point to point connections between communication partners is practical for even fewer components. As more and more components are integrated on a single silicon die, performance bottlenecks of long, global wires preclude reuse of buses. Therefore, scalable on-chip communication infrastructure is playing an increasingly dominant role in system-on-chip designs. With the super-abundance of cheap, function-specific IP cores, design effort will focus on the weakest link: efficient on-chip communication. Future on-chip communication infrastructure will overcome the limits of bus-based systems by providing higher bandwidth, higher flexibility and by solving the clock skew problem on large chips. It may, however, present new problems: higher power consumption of the communication infrastructure and harder-to-predict performance patterns. Solutions to these problems may result in a complete overhaul of SOC design methodologies into a communication-centric design style. The envisioning of upcoming problems and possible benefits has led to intensified research in the field of what is called NoCs: Networks on Chips. The term NoCs is used in a broad meaning, encompassing the hardware communication infrastructure, the middleware and operating system communication services, and a design methodology and tools to map applications onto a network on chip. This paper discusses trends in system-on-chip designs, critiques problems and opportunities of the NoC paradigm, summarizes research activities, and outlines several directions for future research.",
2008,SD-MAC - Design and Synthesis of a Hardware-Efficient Collision-Free QoS-Aware MAC Protocol for Wireless Network-on-Chip.,"To bridge the widening gap between computation requirements and communication efficiency faced by gigascale heterogeneous SoCs in the upcoming ubiquitous era, a new on-chip communication system, dubbed Wireless Network-on-Chip (WNoC), is introduced by using the recently developed CMOS UWB wireless interconnection technology. In this paper, a synchronous and distributed medium access control (SD-MAC) protocol is designed and implemented. Tailored for WNoC, SD-MAC employs a binary countdown approach to resolve channel contention between RF nodes. The receiver_select_sender mechanism and hidden terminal elimination scheme are proposed to increase the throughput and channel utilization of the system. Our simulation study shows the promising performance of SD-MAC in terms of throughput, latency, and network utilization. We further propose a QoS-aware SD-MAC to ensure the serviceability of the entire system and to improve the bandwidth utilization. As a major component of simple and compact RF node design, a MAC unit implements the proposed SD-MAC that guarantees correct operation of synchronized frames while keeping overhead low. The synthesis results demonstrate several attractive features such as high speed, low power consumption, nice scalability and low area cost.","1230 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 SD-MAC: Design and Synthesis of a Hardware-Efficient Collision-Free QoS-Aware MAC Protocol for Wireless Network-on-Chip Dan Zhao, Member, IEEE, and Yi Wang, Student Member, IEEE Abstract—To bridge the widening gap between computation requirements and communication efficiency faced by gigascale heterogeneous SoCs in the upcoming ubiquitous era, a new on-chip communication system, dubbed Wireless Network-on-Chip (WNoC), is introduced by using the recently developed CMOS UWB wireless interconnect technology. In this paper, a synchronous and distributed medium access control (SD-MAC) protocol is designed and implemented. Tailored for WNoC, SD-MAC employs a binary countdown approach to resolve channel contention between RF nodes. The receiver_select_sender mechanism and hidden terminal elimination scheme are proposed to increase the throughput and channel utilization of the system. Our simulation study shows the promising performance of SD-MAC in terms of throughput, latency, and network utilization. We further propose a QoS-aware SD-MAC to ensure the serviceability of the entire system and to improve the bandwidth utilization. As a major component of simple and compact RF node design, a MAC unit implements the proposed SD-MAC that guarantees correct operation of synchronized frames while keeping overhead low. The synthesis results demonstrate several attractive features such as high speed, low power consumption, good scalability, and low area cost. Index Terms—Wireless Network-on-Chip, media access control, binary countdown, differentiated service, QoS. Ç 1 INTRODUCTION A typical multiprocessor system-on-chip (MPSoC) consists of multiple storage components and processing elements, such as general-purpose CPUs, specialized cores (e.g., DSPs or VLIW cores), and embedded hardware (e.g., FPGA or application specific intellectual property) connected together over a complex communication architecture. When moving into the billion-transistor era, everincreasing complexity, heterogeneity, performance, and productivity requirements put a heavy burden on next generation MPSoC design that may utilize several hundreds or even thousands of processors, yielding a “sea of processors.” The performance of gigascale MPSoCs will be limited by the ability to efficiently interconnect heterogeneous IP cores to accommodate their communication requirements. While design productivity boosts the reuse of plug-n-play IP cores, the reuse of communication fabric had been difficult. The state-of-the-art shared-bus and point-to-point connections have been shown to be unable to supply nanoscale SoCs with both sufficient bandwidth and low latency under a stringent power consumption limitation [1]. A scalable communication infrastructure with predictable bandwidth and latency is essential to providing plug-n-play interconnection of heterogeneous IP cores. . The authors are with the Center for Advanced Computer Studies, University of Louisiana at Lafayette, 301 East Lewis Street, ACTR Hall, PO Box 44330, Lafayette, LA 70504-4330. E-mail: {dzhao, yxw4316}@cacs.louisiana.edu. Manuscript received 3 July 2007; revised 17 Dec. 2007; accepted 20 Mar. 2008; published online 20 May 2008. Recommended for acceptance by R. Marlescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TCSI-2007-07-0301. Digital Object Identifier no. 10.1109/TC.2008.86. Recently, the concept of Network-on-Chip (NoC) [2], [3], [4] has been proposed as the communication platform for complex multiprocessor SoCs. NoC features prominent characteristics, such as transmitting packets instead of words, supporting parallel transaction, and solving clock skew problem in large-scale SoCs. In the meantime, the speed improvements of silicon and SiGe bipolar transistors and MOS transistors have made the implementation of integrated circuits operating at 20 GHz and higher feasible [5]. According to ITRS [6], the cut-off frequency target for nMOS transistors is 280 GHz by 2009 or at the 50 nm CMOS node. With such transistors, it is possible to build radio frequency (RF) circuits operating at 90 GHz or higher. Accordingly, quarter wave antennas for use in silicon will be only 240 m long [7]. Consequently, as CMOS and BiCMOS technologies improve, the cost of onchip antenna and required circuits will decrease dramatically, providing greater freedom to use on-chip radio. Moreover, at such a high operating frequency, the typical bandwidth efficiency of 1 bps/Hz leads to a data rate of 150 Gbps to 1.5 Tbps [7]. As a result, the new RF/ microwave technology is investigated for future intra/ interchip communication [8]. A few initial steps have been taken to demonstrate the Radio-on-Chip (RoC) technology, including wireless interconnect for intrachip clock network to relieve the bottleneck for global signal distribution [9], [10] and interchip wireless connection for data communication over a distance of a few centimeters [10], [11], [12]. As reported so far, RF interconnect for on-chip or inpackage communication with 1-20 Gbps data rate, tens of microns to millimeter transmission range, and several milliwatts power consumption has been achieved. Using the RoC technology, the chip-based wireless radios can be employed to replace the wires for increasing 0018-9340/08/$25.00 ß 2008 IEEE Published by the IEEE Computer Society ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1231 accessibility, improving bandwidth utilization, and eliminating delay and cross-talk noise in conventional wired interconnects. This brings forth a revolutionary on-chip communication infrastructure based on RF interconnection, which we name Wireless Network-on-Chip (WNoC) in contrast to NoC. WNoC will provide higher flexibility, higher bandwidth, reconfigurable integration, and freed-up wiring when compared to NoC. Envisioning the unique opportunity of WNoC, we have carried out a series of feasibility studies from physical modeling to architecture design to protocol development. The introduction of ultra-wideband (UWB) brings in new opportunity for high-data rate low-power short-range communication, which renders itself a perfect solution for the physical layer of WNoC. With the uniqueness of wireless interconnection, the WNoC design paradigm calls for effective solutions to overhaul the on-chip communication infrastructure of nanoscale MPSoCs. System architecture and data transmission protocol must adapt to the critical challenges posed by both large-scale integration and small device geometries. The major contributions of this paper are as follows: . With recent advances in RFCMOS and ITRS projection, we introduce UWB interconnect for physical layer design of WNoC in appreciation of its supereminent data rate low-power ultrashort communication and low-cost implementation (Section 2). . We present the WNoC architecture design with the emphasis on RF infrastructure design by addressing two critical issues: RF nodes placement and core clustering (Section 3). . We take a cross-layer design approach to develop the WNoC data transmission protocol, which fulfills the functions of medium access control (MAC), network, and transport layers, aiming at delivering simple and efficient RF node implementation (Section 4). . As one of the challenging design issues in WNoC protocol stack, this paper focuses on developing an efficient MAC protocol for resolving channel contention and minimizing collision probability. We propose a synchronized and distributed MAC protocol (SD-MAC) that achieves 100 percent collision-free performance while having the features of high efficiency, simplicity, robustness, fairness, and quality-of-service (QoS) capability (Section 5). . We further propose a prioritized SD-MAC to ensure the serviceability of the entire system and to improve the bandwidth utilization (Section 7). The developed SD-MAC protocol is implemented into a MAC unit with high performance, low power consumption, and low hardware overhead. We further estimate the performance and cost of an RF node and the whole WNoC to demonstrate the feasibility and applicability of WNoC and acquire insight into the WNoC paradigm (Section 8). . 2 UWB-BASED ON-CHIP WIRELESS INTERCONNECTION Two essential elements are required to realize on-chip wireless interconnection, i.e., high bandwidth and lowpower RF wireless communication and RF on-chip integration capability. A few initial steps have been taken to develop RF interconnect technologies (such as free-space transmission [9], guided-wave transmission [13], UWB [10], and direct near-field coupling [14]) for inter or intrachip communication since RF was identified as an alternative interconnect technology by ITRS in 1999. Among them, the introduction of UWB brings in new opportunity for high data rate, low-power, and short-range communication. Given its ultrashort transmission range and the isolated communication environment, an extremely wide spectrum is available for the use of WNoC, leading to great potential of achieving supereminent data rate, ranging from 150 Gbps to 1.5 Tbps. With recent advances in RFCMOS, we employ a carrierfree impulse radio-based UWB transceiver for WNoC, aiming at delivering low-power and low-cost implementation [8]. The transmitter is designed to generate the desired pulse with proper driving strength so that the signal can be radiated from the on-chip antenna efficiently. A CMOS integrated Gaussian monocycle pulse (GMP) generator generates an ultrashort pulse that results in extremely low power spectrum density. The generated pulses can be sent individually, in bursts, or in near-continuous streams. They can encode information by pulse position modulation (PPM) or biphase modulation (BPM). Moreover, multiple access capability can be provided by directly applying modulation techniques for channelization and separation of users, such as direct sequence coding and time-hopped PPM (TH-PPM) [15]. The receiver consists of a wideband low-noise amplifier (LNA), a correlator (including a multiplier and integrator), an analog-to-digital converter (ADC), and synchronization circuits. The data are recovered by the correlator. A pulse template is employed to correct the incoming pulses for coherent demodulation. ADC design usually sets a performance bottleneck for the receiver, especially the data rate. Using simplified architectures such as comparator, inverter buffer as an ADC has been further explored [16]. Since a very high data rate is needed in WNoC, the synchronization scheme, which consists of phase synchronization and frequency synchronization, is applied. One major challenge is the efficient integration of onchip antennas and the realization of required circuits fabricated in mainstream silicon processes. Migration of short-range wireless communication to higher frequency allows smaller antennas and thus facilitates their on-chip integration. In fact, according to ITRS, the cut-off frequency and unity maximum available power gain frequency targets for the year 2015 are about 490 and 710 GHz, respectively. As the maximum operating frequency of RFCMOS circuits increases with technology scaling, it is poss ib le to imp lement RF c ircu i ts operat ing up to  500 GHz, achieving a data rate as high as  500 Gbps (with 1 bps/Hz bandwidth efficiency) in 32 nm CMOS technology. With multiple access, we could easily increase the aggregate data rate to above 2 Tbps. With such scaling, the required antenna and circuit areas will scale down. For example, at 24 GHz, quarter wave antennas for use in silicon is about 0.9 mm. When scaling at 500 GHz, it will be only about 40 m long. This will dramatically reduce the cost of on-chip wireless interconnects and greatly increase the flexibility of on-chip antennas. The most recently reported intrachip UWB interconnection implementation has achieved 1.16 Gbps data rate for single channel at central frequency of 3.6 GHz in 0.18 m 1232 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 TABLE 1 UWB Interconnect Implementation in 0.18 m CMOS CMOS technology [16], [17]. A Si-integrated meander-type dipole antenna has been implemented for 1 mm range data transmission at antenna length of 2.98 mm. Table 1 summarizes the area and power overhead for the transmitter and receiver designs at 0.18 m. 3 ARCHITECTURAL OVERVIEW OF WNOC 3.1 WNoC Building Components Based on the UWB interconnect technology, we propose establishing the WNoC for the communication among highly integrated heterogeneous IP cores with diverse functionalities, sizes, and communication requirements in the gigascale MPSoC. A WNoC consists of two basic components, namely, the Transparent Network Interface (TNI) and the RF node [18]. The RF node has a radiofrequency interface (i.e., low-cost low-power transceivers and tiny antennas) for (two-way) communication among IP cores. As shown in Fig. 1, a number of RF nodes (equipped with Routing Decision Logic, MAC Unit, buffers, and Buffer Management Unit) are dispersed on-chip to form a multihop wireless micronetwork. The data are transmitted in packets, each of which includes the destination position and the data payload. The IP cores access the network via TNI and their packets are delivered to destinations through multiple hops across the network. The distribution of RF nodes chipwide provides the coverage of the entire on-chip wireless communication. TNI can effectively decouple the designs of IP cores and WNoC, thus supporting not only component reuse but also WNoC plug-n-play, which is highly desirable from the design integration point of view. Through TNI, along with the so-called point-to-point transfer protocol, each core may deem itself directly connected to other heterogeneous cores, Fig. 1. A hypothetical WNoC for heterogeneous SoCs. Fig. 2. Illustration of a WNoC topology formation. as if the WNoC is completely transparent. We adopt a VCIcompatible interface, where the VCI [19] embedded split protocol can ease the round-trip latency constraints between a request-response pair. Serving as the interface between the IP cores and the WNoC, TNI diminishes the heterogeneity of the cores and interacts with the network fabric for packet assembly, delivery, and disassembly. 3.2 RF Infrastructure Design RF infrastructure design aims at determining WNoC communication architecture that consists of a collection of RF nodes connected by wireless links, i.e., WNoC topology. Two major design issues are addressed, namely, RF nodes distribution and core clustering, to establish a flexible RF network infrastructure tailored for gigascale MPSoCs that comprise heterogeneous IP cores with various computation needs, communication workload, and sizes. The problem of RF node distribution is to find the minimum number of RF nodes to support communication needs of all cores on chip and to determine their placement. We formulate this problem into geometric disk covering where a clustered wireless micronetwork can be abstracted as a set of disks, each centered at an RF node with a radius of R (i.e., the maximum RF node assistant distance), which covers a set of embedded IP cores (wireless clients) on the chip plane. This problem is strongly NP-complete. By formulating RF node distribution into disk covering, we may apply greedy set covering or grid disk covering algorithms to solve it [20]. Meanwhile, the cores are properly clustered in order to minimize the routing cost in terms of hard-wiring cost (between cores and RF nodes) and wireless communication cost (determined by the number of hops along the wireless routing paths) and to balance the communication load accordingly. Fig. 2 illustrates a hypothetical WNoC topology with 15 RF nodes formed for a sample MPSoC of 30 IP cores. 4 WNOC DATA TRANSMISSION PROTOCOL Data transmission protocol is an integral part of WNoC. With the objective of making the hardware implementation simple and efficient, we propose taking a cross-layer design approach for developing the data transmission protocol, which fulfills the functions of MAC, network, and transport layers in a traditional OSI layered structure. The protocol stack is hardware implemented into Routing Decision Logic, MAC Unit, buffers, and Buffer Management Unit for routing, wireless channel contention, flow control, and ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1233 network congestion control, respectively, which constitute the major components of an RF node. We have observed several unique characteristics of data transmission in WNoC summarized as follows: First, the traffic in WNoC is typically intensive, naturally calling for optimization of the protocol stack under high traffic load. Second, data traffic between two IP cores is usually bursty, which motivates us to design the network with shared high bandwidth channels for enabling efficient data transmission. Third, data transmission in WNoC follows the Request-Response model, forming a stream from source to destination. These characteristics directly impact the design of the transport layer protocol. The transport layer of WNoC may adopt a simple UDP-like protocol, which leaves out complex flow control and error control by resource overprovisioning. The VCI protocol embedded in the VCI-compliant TNI provides Lossless data delivery and In-order data delivery through handshaking between the Requestor and Responser. Thus, the transport layer is merely an interface between the network independent layer (i.e., application layer) and the network dependent layers (including all lower layers). The major task of the network layer is to determine the path for data transmission from the source to the destination, which may involve single hop or multiple hops. In [21], we have proposed a simple location-based routing (LAR), where each node makes routing decision based solely on the location of itself, its neighbors, and the destination node. Neither the routing table nor the network topology needs to be maintained. The routing algorithm can be implemented by a few simple logic operations, effectively minimizing the overhead. However, this basic algorithm may fail if an intermediate node is a concave node and more complex flooding schemes need to be implemented to improve the delivery rate. In order to ensure 100 percent delivery and, at the same time, to achieve the QoS required by a wide range of on-chip applications, we have developed a region-aided routing (RAR) protocol [22]. The basic idea is that each node divides the entire chip area, from its own perspective, into several regions with its n neighbors as the region headers, and maintains an n-entry routing table. Upon receiving a data packet, the node checks the destination’s location address contained in the packet header and calculates in which region the destination is located. Then, a proper next-hop node is chosen to forward the packet toward that region. The RAR protocol achieves minimum path cost and guarantees it is loop-free but at the expense of more complex hardware implementation than the LAR. As the nodes in WNoC communicate over the shared wireless medium, it is highly possible that two or more nearby RF nodes transmit data simultaneously, which leads to collisions. The receiver in the collision region (i.e., an area where all nodes are within each other’s transmission range) cannot receive the data packet correctly. Thus, it is a key design issue to develop an efficient MAC protocol for resolving channel contention and minimizing collision probability, with two special requirements to be considered due to the uniqueness of WNoC. First, the MAC protocol should have very low hardware implementation overhead, which prohibits the use of any conventional MAC protocols. Second, it should achieve very low collision probability and packet delivery delay in order to meet the QoS requirement of various on-chip applications. In this work, we mainly propose an SD-MAC protocol that ensures 100 percent collision-free performance while having the features of high efficiency, simplicity, robustness, fairness, and QoS capability. In order to alleviate network congestion and improve end-toend performance, we present a distributed flow control and buffer management strategy involving multiple mechanisms: credit-based backpressure congestion control, output queuing with a shared buffer, and conditional round-robin output scheduling. We further propose a prioritized SDMAC to ensure service differentiation and to improve bandwidth utilization. 5 SD-MAC PROTOCOL FOR WNOC In this section, we introduce the proposed SD-MAC protocol for WNoC. In SD-MAC, channel contention is based on a binary countdown medium access mechanism. The WNoC system needs to be synchronized so that the neighboring RF nodes within a collision region can compete for the wireless media beginning at a close enough time point. Such a contention time point synchronization is far looser than the time synchronization required by TDMA or CDMA (which requires the same time clock readings for all nodes). This synchronization can be achieved by applying existing network-wide decentralized synchronization methods [23], [24]. The development of a distributed time synchronization mechanism is out of the scope of this paper. Each RF node employs a four-step approach to access the shared wireless channel: initialization, channel contention, channel access authorization, and data transmission. The short distance between neighboring RF nodes (within the wireless transmission range) makes it feasible to achieve wired controlling without considerable cost set of n control lines ðRx=T x½n   1 : 0Þ connected to its and, thus, a separate control channel. Each RF node has a n neighbors. Each pair of control lines consists of a single bit input ðRx½iÞ=output ðT x½iÞ line for handshaking between an RF node and its ith neighbor. Based on this hybrid interconnection infrastructure, the multiple access controlling is performed on these control wires while the data are transmitted through the network wirelessly. Having separate wired controlling channels and wireless data transmission channels induces a number of benefits. First of all, we may avoid expensive data synchronization. Only the control signals are synchronized. Second, the control logic can be simplified to bit operations and, thus, is faster and simpler to implement. Third, since no control packets are sent through the wireless media, more useful data packets are transmitted. Fourth, by decoupling the media of data transmission and MAC, the MAC protocol control of the current packet can be launched at the same time as the data transmission of the previous packet, thus increasing the channel efficiency. The SD-MAC protocol is based on synchronized time frames, where each frame consists of two intervals: the competition interval and the data transmission interval. With separate control and data transmission channels, the RF nodes that have data to send compete with the wireless media of the next time frame through the wired control channel. In the meantime, the RF nodes that win the wireless channel competition in the previous frame transmit data packets through the wireless channel. The 1234 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 3. SD-MAC frame format for the control channel. competition interval is further divided into three periods, as shown in Fig. 3. It starts with a initialization period (INIP) that includes a state initialization slot and a register initialization slot. It is then followed by the channel contention period (CP), which consists of a series of Ncs contention slots used for a binary countdown approach. The competition ends with a channel access authorization per iod (CAAP) . The operat ions of each per iod are described as follows. 5.1 Initialization Each RF node contains a 2-bit status register SR½1 : 0 to indicate its state changing via control handshaking. A node may be in one of four states: T X , a transmitter, where SR½1 : 0 ¼ ð1; 1Þ; RX , a receiver, where SR½1 : 0 ¼ ð1; 0Þ; I nA, node inactive, where SR½1 : 0 ¼ ð0; 1Þ; and SND, node state not determined, where SR½1 : 0 ¼ ð0; 0Þ. In the initialization period, any RF nodes that have data to send (by checking the waiting signal associated with the buffer pool, asserted when packets are waiting in the buffer pool) is identified as a potential sender by setting SR½1 : 0 ¼ ð1; 1Þ. SR½1 : 0 ¼ ð0; 0Þ. A node may change from one state to All other nodes are initialized in the state of SND by setting another in the CAA period. Each node also maintains an n-bit potential sender record register P SR½n   1 : 0 corresponding to its n neighbors. If bit P SRi ¼ 1, the ith neighbor is recorded as a potential sender of the node. A node may have multiple potential senders. The P SR registers are constructed in such a way that each sender asserts only one outgoing T X line connected to the receiver (determined by the RDL) while negating the remainder. All nodes check their incoming RX lines and all of their potential senders are recorded in P SR if the corresponding RX lines are asserted. In order to keep a history of channel contention throughout a sequence of contention slots in the contention period, an n-bit survived sender record register SSR½n   1 : 0 is maintained by each node and its content is updated at each contention slot. If bit SSRi ¼ 1, the ith neighbor is indicated as a neighboring competing sender which survived through the contention. In the initialization period, all senders simply broadcast logic “1” to their neighbors by asserting their T X lines and each node check their RX lines by performing an OR operation of RX ½n   1 : 0, i.e., T x:exist. If a node has at least one sender in its neighborhood ðT x:exist ¼ 1Þ, its SSR register is initialized to all ones, SSR½n   1 : 0 ¼ ð1; . . . ; 1Þ; otherwise, all zeros, SSR½n   1 : 0 ¼ ð0; . . . ; 0Þ. For example, nine RF nodes form a WNoC, as shown in Fig. 4. Two nodes are connected by a link if they are within the transmission range of each other. Assume nodes 1, 2, 5, and 7 have data to send to nodes 3, 4, 4, and 8, respectively. Note that, due to the limited transmission range, some nodes compete for the wireless channel with each other, such as nodes 1 and 2. Initially, all potential senders, such Fig. 4. Example of node contention. Fig. 5. Illustration of hidden and exposed terminal problems. (a) Hidden terminal scenerio. (b) Exposed terminal scenerio. as nodes 1, 2, 5, and 7, are in a state of T X while all other nodes are in a state of SND. Each node also maintains a P SR. The P SRs of nodes 3, 4, and 8 are initialized to P SR3 ¼ ð0; 1; 0; 0Þ, P SR4 ¼ ð0; 1; 0; 1; 0Þ, and P SR8 ¼ ð1Þ, respectively, while all other nodes have their P SRs recorded as all zeros. In addition, nodes 0, 5, and 7 have their SSR registers initialized to all zeros, while all other SSR registers have the initial value of all ones. 5.2 Channel Contention In the CP, all potential senders contend for the wireless medium by employing a binary countdown scheme. We observe that collisions occur at the receiver, not the sender. In other words, it is the presence of two or more interfering signals at the receiver that constitutes a collision. Competition at the sender using binary countdown may not appropriately avoid collision, as in “hidden terminal” problem, or defer possible transmission, as in an “exposed terminal” problem. For example, as illustrated in Fig. 5a, both of the two senders A and C are not within each other’s contention region; thus, both could win the contention and attempt to transmit data simultaneously. A “hidden terminal” scenario results. An “exposed terminal” scenario results when both of the two senders B and C (in Fig. 5b) are within each other’s contention region and only one (say, B) wins the contention. However, there is no reason to defer the data transmission from C to D. As the relevant contention is at the receiver, not the sender, we let a receiver choose one among a set of neighboring competing senders. Such a receiver_select_sender mechanism assures more concurrent data transmission by efficiently resolving the exposed terminal problem. At the beginning, all incoming RX lines of a node in the collision region are initialized to logic “0.” A potential sender (say, X) generates i .e . , fCBi j1  i  Ncs g. I f an Ncs -bit random numbe r , CBi ¼ 1, node X asserts all of its outgoing T X lines T X ½n   1 : 0 ¼ ð1; . . . ; 1Þ in contention slot CSi . if CBi ¼ 0, Otherwise, all T X lines are negated, ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1235 T X ½n   1 : 0 ¼ ð0; . . . ; 0Þ. T h e R F n o d e s ( w i t h T x:exist ¼ 1) check all of their RX lines at each slot and update their SSR registers by calculating the bitwise AND of RX ½n   1 : 0 and SSR½n   1 : 0. For a particular node A, the bitwise AND operation masks off its neighboring senders with a smaller contention number (with their current contention bit CBi ¼ 0) after each contention slot CSi . Its neighboring senders surviving until CSi are indicated with logic “1” in dedicated bit positions in the SSRA register (i.e., they have equally large contention numbers so far). Note that, if the bitwise AND operation results in all zeros, it is likely that the contention bits of all survived senders are zero at CSi . Again, the survived senders have the same large contention number until CSi and no survived sender should be masked off. In other words, the SSRA register will not be updated in CSi . Clearly, only one neighboring sender with the largest contention number will survive at last (assume each sender generates a distinct random contention number).1 Finally, the SSRA register has only 1 bit asserted, indicating the only survived sender. Node A then ignores further contention bits it receives and its SSRA register will not be further updated. As shown in Fig. 4, the channel contention is carried out with the random contention numbers generated for senders 1, 2, 5, and 7. Let us use node 4 for illustration. Four out of five neighbors are senders. Among them, nodes 2 and 5 are its potential senders. After the first contention slot CS1 , all four neighboring senders indicate themselves as the survived sender by setting SSR4 ¼ ð1; 1; 0; 1; 1Þ. Then, node 2 with 2 ¼ 0 loses contention in CS2 as its contention bit CB2 SSR4 ¼ ð1; 0; 0; 1; 1Þ. Similarly, node 5 loses contention in contention number is the smallest. SSR4 is updated, CS3 that results in SSR4 ¼ ð1; 0; 0; 0; 1Þ. We cannot determine which node between 1 and 7 survives until slot CS6 . As node 7 has the largest contention number, it survives at the end with the updated SSR4 ¼ ð0; 0; 0; 0; 1Þ. Similarly, all nodes will choose their survived sender using such a binary countdown-based contention scheme. Only the neighboring sender with the largest contention number survives at the end and is indicated in the SSR register. 5.3 Channel Access Authorization After the contention period, each node selects exactly one neighboring sender as the survived sender. In the channel access authority period, we need to determine if the survived sender is a potential sender of the node and grant channel access if it finally wins the contention. The CAA period contains two steps. In the first step, each node performs bitwise AND of SSR½n   1 : 0 and P SR½n   1 : 0 and records the result in SSR. Then, it follows an OR operation to the bits in SSR½n   1 : 0, i.e., T x:survive. The state of each node is transformed according to the state diagram in Fig. 6. For a node with an initial state of SN D, there are two possible state transformations: If SSR contains all zeros, i.e., T x:survive ¼ 0, the node transforms its state to I nA. . 1. It is possible that two or more senders may generate the same largest random number within a contention region. Thus, two or more senders may survive after channel contention. It relies on the following CAA mechanism to resolve the collision that may occur. Fig. 6. State diagram for the competition interval. . . Otherwise, if T x:survive ¼ 1, the node transforms its state to RX . In other words, the survived sender of the node is its potential sender. The node is in turn the receiver of the survived sender. Note that more than 1 bit may be asserted in SSR as the node may have more than one potential sender generating the same largest contention number and they may all survive after the contention period. The node is then marked. There are also two cases for a node in the initial state T X : If T x:survive ¼ 0, the node remains as a potential sender (in T X state). . Otherwise, if T x:survive ¼ 1, the node transforms its state to RX . Again, the node is marked if more than one potential sender survives. All nodes will finalize their states in the next step. In Step two, we will resolve channel contention and eliminate hidden terminals. At the beginning, all T X lines are initialized to logic “0.” Each potential sender (in state T X) first asserts the only T X line connected to its next hop while negating all others. Each potential receiver (in state RX) checks its RX lines by calculating OR of RX ½n   1 : 0, i.e., Rx:lose. If Rx:lose ¼ 0, the node remains as a receiver (in the RX state); otherwise, the node changes its state to I nA. It is simply used to avoid those cases where a receiver’s potential sender has changed to RX state in Step one. All remaining receivers then compute bitwise OR of SSR½n   1 : 0 and P SR½n   1 : 0 and output the results to their T X lines so that the receivers can inform their potential senders. If a receiver is marked (as more than one of its potential senders survive), only one of these senders that share the receiver will be randomly picked as the final winner. Especially, before sending bitwise OR of SSR½n   1 : 0 and P SR½n   1 : 0 to its potential senders, the marked receiver will first mask off all other “1”s in SSR½n   1 : 0 except for one randomly picked “1,” which ensures that only one winner remains. All potential senders (in state T X) check their incoming RX lines and compute OR operation of RX ½n   1 : 0, i.e., T x:win. . If none of the incoming lines is asserted, i.e., T x:win ¼ 0, the node loses contention and simply changes its state to I nA. Such as nodes 1 and 2 in the same contention region, collision is avoided in such a way that a node (e.g., node 1) with a larger contention number wins the channel access, while node 2 gives up its attempt to gain access to the channel in this frame. 1236 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 finally and concurrent transmission will result in collision. In this case, we apply an additional step in the channel access authorization period that allows only one of them to remain. tu Proposition 2. There is no hidden terminal problem in the proposed SD-MAC protocol. Proof. The hidden terminals are eliminated in two steps. We use Fig. 5a for explanation. If node A generates a smaller contention number than C , A loses contention in CP and is implicitly eliminated. Thus, only node C will win the channel access and send data to D. If node A generates a larger or the same contention number as C , both A and C will survive after the contention period. We then ask the receivers to broadcast a message to their neighbors. If a sender (e.g., C ) receives messages from indicates that the data transmission from the sender ðC Þ other than its intended receiver (both B and D), it to its intended receiver ðDÞ conflicts with the other transmission to its neighboring receiver ðBÞ. Thus, node C is explicitly eliminated and A finally wins. tu Proposition 3. The exposed terminal problem is resolved by the proposed SD-MAC protocol. Proof. The proposed receiver_select_sender mechanism followed by channel authorization efficiently resolves the exposed terminal problem. We use Fig. 5b for explanation. Even though the two senders are within each other’s contention region, their next hops are not within each other’s transmission range. In other words, A cannot hear C while D cannot hear B. Both A and D will choose their potential sender as their survived sender after the contention period. Then, in the channel access authorization period, as the handshaking is operated between each separate pair of A and B or C and D, both B and C w in the con ten t ion and transm i t da ta simultaneously. tu 6.2 Channel Efficiency By separating the control channel and the data channel, the control handshaking is decoupled from the wireless data transmission, which renders zero protocol overhead for the wireless channel. Moreover, the proposed SD-MAC protocol achieves 100 percent collision-free performance; thus, no overhead may be induced by avoiding packet retransmission. In order to ensure 100 percent wireless channel efficiency, the control handshaking should be conducted concurrently with the wireless data transmission and the time spent on wired controlling should be compatible with the high-speed data transmission time. We may thereby determ ine the appropr iate packet s ize that ensures 100 percent channel efficiency. Assume the data rate of the wireless channel is D bps and the packet size is S bits. The time required to transmit a packet is TD ¼ S D . Assume the minimum time we may achieve to finish a competition interval is TC I . In order to render complete overlapping between handshaking and data transmission, the actual competition interval should be determined by PC I ¼ maxfTC I ; TD g. The wireless channel efficiency is defined by Echannel ¼ TD . To reach 100 percent channel efficiency, TC I should be no greater than TD . In other words, S  D  TC I . As the control handshaking in the proposed SD-MAC is realized ¼ S TC I DTC I Fig. 7. Contention resolution. . If a potential sender receives the asserted signal from more than its next hop (i.e., a potential sender has more than two RX lines asserted or the only asser ted RX l ine is no t from i ts nex t hop ) , T x:match ¼ 0, the sender (e.g., node 5) considers itself as a hidden terminal and gives up its attempt to access the channel in this frame by changing to state I nA. . Otherwise, if only one asserted signal is sent from its next hop, T x:match ¼ 1, the sender is a final winner and remains in state T X . Only the sender that remained in state T X can transmit data in the following data transmission interval. Finally, nodes 1 and 7 will transmit data simultaneously, as shown in Fig. 7. 6 PERFORMANCE EVALUATION 6.1 Performance Analysis of SD-MAC Protocol In a WNoC, the medium is shared by all RF nodes. There are two sources of data collision: One is due to the neighboring nodes concurrently sending packets. The other comes from the hidden terminals. The SD-MAC protocol can achieve 100 percent collision-free performance. In addition, the exposed terminal problem is efficiently resolved to improve data transmission parallelism. Proposition 1. No two or more nodes within the collision region of a receiver could win the medium at the same time. Proof. The binary countdown-based channel contention is performed by bitwise AND operation that masks off its neighboring senders with smaller contention numbers at each contention slot. If distinct random numbers are generated for the neighboring senders of a receiver, obviously only the sender with the largest number will survive at last. If two or more senders generate the same largest contention number within a collision region, they could all survive after the channel contention period. There are three cases to be considered. Case 1: If neither sender’s intended receiver is with in each other’s transmission range, both senders can survive by the receiver_select_sender contention mechanism and transmit data simultaneously. Case 2: If any sender’s intended receiver is within another sender’s transmission range, at least one sender will be eliminated by the hidden terminal elimination scheme. Case 3: If the two senders have the same intended receiver, they both could win ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1237 with bitwise logic operations, the implementation is simple and fast. TC I is dominated by the time spent in the channel contention period that consists of several contention slots. For a sample implementation using 0.18 m technology (explained in Section 8), the operating frequency of SD-MAC is around 400 MHz. The resulting TC I is about 30 ns when the number of contention slots is 8. Assuming 10 Gbps data rate of the wireless channel, the packet size is thus estimated to be no less than 300 bits to assure 100 percent channel efficiency. 6.3 Network Throughput and Network Utilization The data transmission concurrency is significantly improved by resolving the exposed terminal problem. However, the transmission concurrency is still quite restricted by the contention or, as we say, the interference among wireless links. We introduce network capacity as an important merit to evaluate the performance of the proposed MAC protocol. The network capacity is defined as the maximum possible concurrent data transmission, i.e., the maximum number of active links without any interference. Network capacity can be estimated by constructing a link compatible graph. The basic idea is to first identify the links that are not compatible with a particular link, say lA!B . An incompatible link of lA!B is found if the link falls within the following three categories: . Any link connected with node A or B. . Any outgoing link of receiver B’s neighbor as its neighbor cannot be a sender. . Any incoming link of sender A’s neighbor as its neighbor cannot be a receiver. A link compatible graph (LCG) can thus be derived, where each node represents a wireless link and two nodes are connected by an edge if the two associated links are compatible. A maximum clique2 can be found from LCG that implies the maximum possible data transmission carried out concurrently without the occurrence of any collision. The size of the maximum clique is used to estimate the capacity of a particular network configuration. We further define the network throughput as the number of packets that can be transmitted successfully at a time frame at a given wireless bandwidth by applying the SDMAC protocol. The network utilization is determined by the ratio of network throughput over network capacity, which indicates how efficiently we are utilizing network resources. The packet latency is defined as the number of competition intervals it takes to be sent out successfully since the packet was ready for transmission. In addition, the average or maximum end-to-end packet latency is defined as the average or maximum number of clock cycles it takes to be sent successfully to the destination since the packet was injected into the network. 6.4 Buffering Strategy We implement an output queuing strategy with first-in first-out buffers. Each node contains n dedicated output queues, each corresponding to one neighboring node. Assume each queue has the same length (lnp , or one buffer unit) that is one or multiples of packet size. Each queue 2. A clique is a maximal complete subgraph where any two nodes are connected [25]. temporarily stores the packet going to the dedicated neighbor. A node also contains a shared buffer with a size of n   2 buffer units to temporarily store the packets if their dedicated queues are full. The shared buffer ensures that there would be virtually n   1 buffer units available for a particular multihop flow so that deadlock-free transmission is achievable. All nonempty output queues are served in a round-robin fair manner. In order to prevent network blocking and buffer overflow, we propose an efficient buffer management and flow control strategy. More precisely, an lnp -credit-based backpressure congestion control mechanism is applied, which prevents an upstream node on a node’s flow from relaying packets unless the upstream packet has been released or consumed by the downstream node, thus resolving the intraflow contention problem. In order to restrict the flow source to inject redundant packets into the network, we regard local IP (processing element) as the same packet source as other network nodes. Therefore, the local packet injection is also restricted by the backpressure scheme. In other words, the local IP can inject a new packet only when the previously injected packet has been released and the corresponding output queue has space available. In this way, we ensure no packet loss. The packets are never dropped and are forwarded from one node to another only if there is space available in the dedicated output queue corresponding to the downstream node along the flow (path) of the packet. To this end, the total buffer size for a node is determined by ð2n   1Þ  lnp . Denoting the network degree of a WNoC, Nnd , the average buffer size is ð2Nnd   1Þ  lnp . 6.5 Control Channel Handshaking Overhead In order to establish one successful data transmission, the sender needs to send logic “1” twice to its next hop to initialize registers P SR and SSR, respectively. It then sends Ncs contention bits for channel contention. At the end of a competition interval, the receiver issues one bit channel authorization to the sender. Therefore, the total number of control bits transferred between a sender and a receiver ðBct Þ per successful packet is Bct ¼ 3 þ Ncs . Note that each control bit is transmitted in a broadcast fashion. Thus, the total number of handshaking bits transferred by a node approximates Bct 1 ¼ ð3 þ Ncs Þ  Nnd , where Nnd is the average network degree. However, a node may compete several times until it wins. Now, let us consider the worst case. It occurs when each node has Npt packets to send in a single collision region of Nrf nodes. It requires a total of Npt  Nrf competition intervals to finish all of the packet transmission. Note that a sender without packets to transmit will drop out of the competition after it wins. The total number of handshaking bits transferred within a collision region is Bct N ¼ ðNpt   1ÞNrf Bct 1 þ Nrf i¼1 iBct 1 NptNrf   ¼ 1 þ Nrf   1 2Npt ð3 þ Ncs ÞNnd : ð1Þ The actual control bits required depend on the traffic pattern. The resulting value falls within the range of fBct 1 ; Bct N g. For example, the overall number of controlling bits varies between 11 and 33 for a single collision region of five nodes when using 8-bit contention slots. 1238 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 8. Performance evaluated at various injection rates, Ncs , and topologies. (a) Network throughput versus injection rate. (b) Packet latency versus injection rate. (c) Network utilization versus injection rate. (d) Network throughput versus Ncs . Assuming the packet size of 300 bits, the control overhead resides between 3.7 percent to 11 percent. 6.6 Simulation Study A WNoC with identical and omnidirectional radio range is built up to cover the communication among the IP cores within an MPSoC model. We use eight contention bits for SD-MAC. The WNoC adopts the region-aided routing protocol, as we developed in [22], to determine the next hop of each sender, which could be simplified into XY-routing for a regular quadrilateral grid (QG) topology. Assume that there is sufficient buffer space to temporarily store the packets in an intermediate RF node. No additional flow control and buffer management schemes are implemented so far. The experiments are run under uniformly distributed traffic patterns. We introduce a parameter called injection rate, which is defined as the number of packets generated per traffic pattern distribution. When a packet is generated at a node, the node randomly assigns the destination for the packet. The trade-off between architectural design and network concurrency is studied based on two typical grid network topologies, QG and triangular grid (TG), as explained in [26]. We run extensive simulations with the consideration of various network topologies; the results are taken on an average of more than 60 different randomly generated network configurations per topology per injection rate. As the number of contention slots ðNcs Þ in the channel contention period determines collision probability, we also evaluate the MAC protocol by varying Ncs . The simulation results are illustrated in Fig. 8. From the simulation results, we observe that, when a small number of RF nodes ðNrf Þ are act ive in WNoC , the throughput is low. As the contention is low as well, data transmission concurrency is largely ensured, which results in low latency and high network utilization. With the increase of Nrf , throughput increases. However, the latency increases because more channel contentions restrict the transmission concurrency. As a result, the network utilization decreases sharply. When the injection rate reaches 0.2, the throughput, latency, and network utilization become quite stable. Even though the number of active nodes keeps on increasing, the network capacity is quite saturated; thus, no significant improvement over throughput and latency results. When increasing the network density from 4  4 QG to 6  6 QG, the throughput increases significantly while the latency and network utilization do not change much. When comparing the WNoC in TG (25 TG) to the one in QG (5  5 QG) with the same Nrf , we can see that 25 TG induces much lower throughput, higher latency, and lower network utilization. It is simply because 25 TG results in higher network degrees and, thus, higher channel contention. When observing the average throughput changing over the different number of contention slots, the throughput increases with the increase of Ncs due to the decline of the collision probability. We further implement the buffering strategy proposed in Section 6.4 to resolve network congestion and control traffic injection. The WNoC utilizes the minimum buffer size that can assure deadlock-free transmission, where a un i t bu f fe r s iz e i s equa l to on e pack e t s iz e and ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1239 Fig. 9. Performance evaluated at uniform traffic pattern under different network scales. (a) Network throughput versus injection rate. (b) Average E2E packet delay versus injection rate. (c) Maximum E2E packet delay versus injection rate. Fig. 10. Performance evaluated under different traffic patterns for 4  4 QG. (a) Network throughput versus injection rate. (b) Average E2E packet delay versus injection rate. (c) Maximum E2E packet delay versus injection rate. one-credit-based backpressure is employed. For example, a 4  4 QG network uses a total of 80 buffering resources, i.e., ð2Nnd   1ÞNrf ¼ ð2  3   1Þ  16 ¼ 80. Each RF node is associated with a random traffic generator that generates three different traffic patterns: uniform, one-hot spot, and two-hot spot. Under a uniform traffic pattern, each RF node has the same chance to receive a packet. Under a one-hot (or two-hot) spot traffic pattern, one randomly selected node (or two nodes) will accept 50 percent (or 1 3 per node) of the total generated traffic while the remaining traffic is uniformly distributed among all other nodes. The experiments are carried out in such a way that we run 1,000 frame times as the warm-up period and then check the performance on 20,000 packets generated under different traffic patterns and injection rates. We wait until all packets reach the destination. Given a 10 Gbps network bandwidth (single channel), we evaluate WNoC system performance in terms of throughput, average, and maximum end-to-end delay. The simulation results are illustrated in Figs. 9 and 10. As we can see, the network throughput increases with the increase of Nrf . However, the end-to-end latency increases as well. It is because more and more channel contentions will restrict the transmission concurrency. In addition, greater average hop count resulted from larger network density. When comparing the throughput and latency under different traffic patterns, the throughput under uniform traffic is better than the others as the contention for the buffering resources becomes more severe under hot spot traffic patterns. The latency under uniform traffic is, however, the largest among the three traffic patterns. The network performance is significantly improved by implementing the buffering scheme by alleviating the intraflow and interflow congestion problems in MAC contention. 7 QOS-AWARE SD-MAC The binary countdown-based SD-MAC protocol inherently ensures fairness among the RF nodes in a single collision region. As any nodes that have data to send can generate a random number for channel access contention, no nodes have unwanted priority over the others. Such a property of fairness can be easily confirmed by biased and unbiased configurations of random contention bits. Assuming a collision region of Nrf ¼ 16 RF nodes, each node generates a random number of Ncs ¼ 8 contention bits. A random number is called biased if almost all contention bits are randomly generated except for some dedicated bits fixed at “1”; otherwise, it is unbiased. Fig. 11 illustrates the effect on network throughput by biased versus unbiased random numbers, where the MSB of node 7, the fourth bit of node 8, and the LSB of node 9 are fixed at “1” in the biased configuration. Clearly, the SD-MAC protocol provides quite good fairness where every node has very close throughput with unbiased CNs. However, many factors will affect fairness among the RF nodes at network level. First, limited transmission range renders several overlapped collision regions with different sizes dispersed in a WNoC. The competition is not only confined within a single collision region but also the adjacent ones. In other words, the nodes at the edge of the network may have much less contention than the nodes located in the center of the network, which is referred to as edge effect. Second, irregular topology indicates a different 1240 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 short memory and register accesses; and block-transfer service level is used for transmitting long messages and large blocks of data, such as cache refill and DMA transfers. We develop a priority scheme by appropriately configuring the contention numbers (CNs) in our SD-MAC protocol to differentiate these SCs. An Ncs -bit CN consists of two parts: higher order Np priority bits to support service differentiation and lower order Nr random bits for fairness and collision control. Thus, the prioritized SD-MAC protocol supports 2Np SCs and each SC is associated with an Np -bit priority prefix. For the above four-SC model, each SC is associated with a 2-bit priority prefix from “11” to “00.” A larger prefix indicates a higher priority level. The input buffer of a node contains 2Np first-in first-out queues, each corresponding to a different SC. A priority decoder checks the priority prefix contained in the packet header of an arrival packet and inserts the packet into the corresponding priority queue. A node has to transmit both relayed and its own traffic. Assume that the forwarded traffic at each node is queued together with the traffic originated at the node. The entry into the output buffer from the input queues is based on a highest-priority-firstserve scheduling discipline. At the beginning of each frame, the priority prefix of the packet at the head of the output buffer is loaded into the prefix register for CN generation. While the priority can be easily maintained within a node, prioritized channel access should be ensured among multiple nodes; otherwise, we cannot provide small and bounded delay to high-priority packets. To ensure that data packets in higher SCs are transmitted quickly, they should win the channel access earlier. The prioritized SD-MAC employs synchronized frames similar to SD-MAC. Specifically, a contention period is divided into Ncs ð¼ Np þ Nr Þ slots with Np priority slots and Nr contention slots. If a node has a packet to send, it generates an ðNp þ Nr Þ-bit CN, i.e., an Nr -bit random number appended with the priority prefix of the packet’s SC. It then follows the channel contention and authorization schemes as described in SD-MAC. 7.2 Performance Evaluation We first evaluate fairness and service differentiation performance of the proposed priority scheme. We apply the prioritized SD-MAC to a single collision region of eight nodes. The traffic is uniformly distributed among the nodes with injection rates of 0.15, 0.4, and 0.8, respectively. As shown in Fig. 12, the prioritized SD-MAC exhibits fairness and service differentiation among all nodes. At low traffic load, the packets in different SCs have chances to be sent out and the four SCs are highly differentiated, while, in a heavily loaded network, the packets in high SC have a higher priority of being served and transmitted. We further evaluate the performance in terms of network throughput, average service time, and average endto-end delay. The service time is measured from the time when the packet is put into the queue until the time it is sent out. The end-to-end delay is the time span from when a The experiments are carried out on a 4  4 QG. We assume packet is generated until when it reaches its destination. that the buffer size is set to multiples of packet size per node. The input queues maintain varying queue length, depending on their priority level. The queues corresponding to higher priority are assigned with smaller buffer space as those high priority packets tend to be sent out quickly Fig. 11. Fairness simulation with biased versus unbiased nodes. network degree for each node, thereby indicating different contention hardness. Moreover, certain QoS requirements should be met such that the MAC layer is able to support different priorities. As a result, an enhanced SD-MAC protocol is highly demanded in order to control fairness in the network and to differentiate services of the system. As shown in Fig. 11, the throughput of some biased nodes is improved due to their likely larger contention numbers. In other words, the network services can be differentiated by properly generating the random numbers. Let us consider the winning probability of a node in a collision region. Assume that exactly one node chooses j as its random number and the node wins the contention if j is the only largest number generated among the nodes. The winning probability of a node is     P Nrf Ncs ¼ 2Ncs  1 j¼0 1 2Ncs j 2Ncs Nrf  1 : ð2Þ If the ith bit of a random number is asserted to “1,” the resulting winning probability is     P Nrf Ncs ¼ 2Ncs  1 j¼2i 1 1 2Ncs   2i 1 j 2Ncs Nrf  1 : ð3Þ For example, if we assert the MSB of an 8-bit random number in a collision region of 16 nodes, the winning probability is aggrandized from 0.05812 to 0.12113. Instead, if the LSB is set to “1,” the probability is only increased by 0.00991. It concludes that multiple levels of priority can be provided by properly setting the higher order bits of a random number. In this section, we propose a prioritized SD-MAC protocol to further address fairness and QoS. 7.1 Prioritized SD-MAC In prioritized SD-MAC, we incorporate the QoS features, aiming to differentiate packets in different service classes (SCs) and providing different services to them according to their priority levels. The packet priority is identified by looking into the packet type embedded in the packet header. We plan to consider four SCs, namely, signaling, real time, read/write (RD/WR), and block transfer [27]. Signaling covers urgent messages and very short packets (such as interrupts and control signals) that are given the highest priority in the network to assure the shortest latency; realtime service level guarantees bandwidth and latency for realtime applications, such as streamed audio and video processing; RD/WR service level is designed to support ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1241 Fig. 12. Evaluation of fairness and service differentiation. (a) At injection rate of 0.15. (b) At injection rate of 0.4. (c) At injection rate of 0.8. Fig. 13. Performance evaluation for prioritized SD-MAC. (a) Network throughput versus injection rate. (b) Average service time versus injection rate. (c) Average E2E delay versus injection rate. and these queues are rarely filled up before the traffic is overloaded. One valid bit is associated with each queue, indicating whether or not it is empty. Once a packet arrives at an input queue, it is served in a highest-priority-firstserved manner. From Fig. 13, we can see that the prioritized SD-MAC effectively differentiates the service quality of different priorities. At unsaturated loads, throughput increases fairly linearly with applied traffic load. The throughput and delays of all four SCs begin to be differentiated simultaneously when the respective saturation point is reached. The throughput of the lower three SCs declines quickly when the network is heavily loaded as the transmission of the packets in the highest priority is overwhelming. Consequently, the delay curve corresponding to the highest priority is quite flat, while the delays of the lower three SCs quickly soar beyond saturation, which resulted from massive contention loss of low priority packets across the network. 8 MAC UNIT SYNTHESIS 8.1 Hardware Implementation The MAC unit implements our proposed MAC protocol, with a primary task of guaranteeing correct clocking of the synchronous time frames while keeping the hardware overhead low. The MAC unit includes four major blocks, namely, the phase control logic, the state control unit, the contention number generator, and the handshaking message generator. The MAC unit is inherently a sequential logic to ease synchronization. A sequence of critical signals that are imperative for correct protocol function is generated by a phase control logic (PCL) to ensure accurate clocking based on the global network clock. In particular, PCL 1) indicates the beginning and the end of a frame period, 2) specifies appropriate period length, and 3) indicates the operation time for a contention slot. Basically, the PCL consists of a 5-bit shift register and a counter (as shown in Fig. 14) to form a one-hot state machine to ease phase decoding ðP hase½4 : 0Þ and fasten operations. P hase½0 triggers the operation in the initialization period. A counter is associated with the second phase such that the contention period is divided into several contention slots. Reset by P hase½0, the counter starts counting when P hase½1 ¼ ‘‘1’’ and disables the shift register until the counter counts to the number of contention slots. Two dummy phases ðP hase½3 : 2Þ are inserted between P hase½1 and P hase½4 to compensate for the timing required for handshaking and decision making in P hase½1. P hase½4 controls the timing for channel authorization period. The contention number generator (CNG) is another building block of the MAC unit, which generates the random contention signals used during contention slots and is appended with priority prefix for service differentiation. It Fig. 14. The phase control logic block diagram. 1242 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 TABLE 2 Cost and Performance of the MAC Unit Fig. 15. The handshaking message generator block diagram. is implemented via an eight-level linear feedback shift register (LFSR) and a priority prefix shift register. In order to minimize the probability that two senders in the same contention region generate the same random number, different generation functions and initial values can be assigned to the MAC units by applying the vertex-coloring algorithm [25]. The state control unit (SCU) is a simple state machine that implements the state transformation according to the state diagram (in Fig. 6). The states are stored in 2-bit state registers ðSR½1 : 0Þ. The encoding of the state is controlled by the phase control signals and the state change control signals. The key component of the MAC unit is the handshaking message generator (HMG) based on a finite state machine (FSM), which takes the phase and state signals and last operation (from RX lines) as the inputs and outputs of the controlling (to T X lines) for the RF node. It also controls the updating of SSR registers. As illustrated in Fig. 15, an HMG mainly consists of a P SR register, an SSR register, a single_one_detection (SOD) logic, two multiplexes, several latches, and logic gates. The P SR register is set up in the INIP; thus, it is enabled by P hase½0 ¼ 1 and the content is kept during the whole competition interval. The RN_REG and other gates (within dashed box 1) are simply used to sending contention bits ðCB ¼ÞRN and to make sure that allow only the potential senders to join the contention by RN will be masked off after the CP period. The 5-to-1 multiplexer (MUX1) chooses proper inputs to initialize and update the SSR register by setting the sel1 signal. The 4-to1 multiplexer (MUX2) outputs proper handshaking control messages to the T X lines by setting the sel2 signal. Both of the multiplexer selection signals, sel1 and sel2 , are decoded from the 7-bit combinations of phase signals P hase½4 : 0 and states SR½1 : 0. Taking into consideration signal propagation delay along control wires, the operation of HMG is interleaved, where the MAC unit is processing the message received from the neighboring nodes while sending out the next handshaking message. 8.2 Synthesis Results The MAC unit is implemented by VHDL and synthesized by Cadence PKS and then place-and-routed by Cadence First Encounter based on the OSU 0.18 m standard cell library. For illustration, the clock constraint is set to 400 MHz and the number of contention slots Ncs is set to ted MAC unit with different network degrees ðNnd Þ. As we 4. Table 2 lists the cost and performance of the implemencan see from the results, the area increases about 10 percent on average at every degree increment, which demonstrates good scalability in terms of hardware overhead. It is worth mentioning the very low area overhead. Even at the largest network degree, the area cost is just about 0.15 percent of a 1 cm2 chip area. The actual operating frequency for a MAC unit is relevant to the data rate of the wireless transceiver associated with each RF node. To ensure 100 percent channel efficiency, we set the competition interval to be short enough to accommodate the data transmission of a packet. As seen from the worst slack time, the MAC unit implemented at various Nnd works properly at a frequency slightly different from 400 MHz. Since WNoC targets at gigahertz technology node, there is still enough design space available to adopt a higher operating frequency by design optimization and using more advanced technology. In addition, the power consumption estimated from the synthesis tool is proportional to the gate count of the MAC unit. The overall power dissipation for a MAC unit is quite low due to the small area overhead. In our approach, one-packet contention energy consumption is calculated by Tclk  TC I  Pmac , where Tclk is the operating clock cycle time, TC I is the number of clock cycles per Competition Interval, and Pmac is the power consumption of the MAC unit. Considering a typical MAC unit with network degree of 4, operating under 411.8 MHz and eight contention slots, the per packet power consumption of the MAC unit is determined by 2:4  10 9  12  2:525  10 3 ¼ 7:27  10 11 J. The typica l one -packe t arb i tra t ion energy based on the 0.18 m CMOS technology is around 1:79  10 13  ðnumber of switch portsÞ [28]. Compared to the typical energy value, the power consumption for SD-MAC to establish a packet is quite low. We show the comparison of SD-MAC with other routing and arbitration units in terms of power consumption, area cost, and operation frequency in Table 3. From the comparison, we can see that our approach has lower area cost and energy consumption than the existing comparable units. 8.3 Cost and Performance Estimation of WNoC In order to study the feasibility of WNoC for MPSoC applications, we estimate the power and area cost of an RF node using a power and area estimation tool called “InCyte Lite.” We further estimate the total power and area cost for a 10  10 QG WNoC for an MPSoC with 100 IPs on a 2  2 cm2 chip. It is feasible to assume that an NoC total For a die size of 2  2 cm2 , a 100 node NoC consumes about area cost should be less than 5 percent of the total chip area. 20 mm2 a r ea o r 0 .2 mm2 p e r n e two rk nod e . Ou r implementation of the MAC unit based on the 0.18 m CMOS requires at most 17,288 m2 (720 logic gates) with node degree as large as 10, while, scaling to the 0.13 m ZHAO AND WANG: SD-MAC: DESIGN AND SYNTHESIS OF A HARDWARE-EFFICIENT COLLISION-FREE QOS-AWARE MAC PROTOCOL FOR... 1243 TABLE 3 Area and Power Cost Comparison technology node, the MAC unit will cost 9,050 m2 , which is about 4.5 percent of a 0.2 mm2 node area. The area cost of the MAC unit is very low. Using “InCyte Lite,” we estimate the area cost of other major components of an RF node including Routing Decision Logic (RDL), buffers, and Buffer Management Unit (BMU). The RDL that implements the RAR protocol in [22] requires about 200 gates (40 gates for routing decision and 160 gates for neighbor list). The BMU implementing the buffering strategy in Section 6.4 requires  1,000 gates to implement all flow control, buffer management, congestion control, and traffic injection control hardware. Thus, the overall area occupancy for the control units including MAC unit, RDL, and BMU is about 25,140 m2 for 1,920 logic gates at 0.13 m technology. It only occupies 12.5 percent of the node area. In order to facilitate high bandwidth wireless data transmission, we acquire large packet size of 300 bits for data transmission. For a 10  10 QG network with an 10 Gbps data rate to fully utilize the whole frame time for average network degree of 3.6, we need to maintain an average of seven-packet buffer size at each RF node, which means 2 ,800 bits of storage space . We est imate the equivalent size of an SRAM core for 37,710 m2 at 0.13 m technology, which could be used to estimate the buffer area cost of an RF node. To this end, we estimate the overall area cost of an RF node at about 62,850 m2 , which results in the whole WNoC area cost of 6.28 mm2 , leading to  1.57 percent an RF node ( 60 percent), more cost-efficient buffering chip area cost. As buffer sizing occupies the most area cost of strategy will be further studied as well as the proper packet sizing by optimizing control speed. Moreover, we estimate the total power consumption of the RF node including all control logic and buffer storage running at 550 MHz control operation frequency at 0.13 m technology. The power consumption of an RF node is 8.2657 mW. For a 60 percent network utilization, the whole WNoC power consumption is 595.13 mW, which is reasonable as fewer parallel transmissions can be carried out than wired NoC due to single channel shared medium contention. Table 4 lists the estimation of power and area cost of WNoC. We further look into the end-to-end latency for WNoC. It is reasonable to assume that the end-to-end packet latency under high traffic load and optimal buffer sizing can be formulated as Te2e ¼ Nhop i¼1 DiPCF , where Nhop is the hop count for a packe t f low , Di is the ne twork degree o f the ith intermediate node along the flow and PCF is the number of clock cycles required for each Competition Interval. For example, in a 4  4 QG WNoC, the average hop count for all of the source-destination pairs is 2.5 and the average network degree is 3. Given that eight contention slots are used for under uniform traffic is estimated as 3  2:5  12 ¼ 90 clock channel competition, the ideal average end-to-end delay cycles, which is slightly worse than the optimal latency of 68.6 clock cycles for an NoC approach at the same network topology [32]. When the traffic gets heavier, the contention for buffering resources will dominate the end-to-end delay. In order to avoid network congestion and buffer overflow, we implement the credit-based backpressure buffer management and traffic injection control scheme, which, however, increases the average one-hop contention time to 25 frame times. Consequently, the average end-to-end delay is about 300 clock cycles. We compare the WNoC performance with popular NoC approaches in Table 5 and acquire insights into the WNoC paradigm. TABLE 5 Performance Comparison of WNoC versus NoC TABLE 4 Area and Power Estimation of WNoC 1244 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 9 CONCLUSION We have proposed in this paper an SD-MAC protocol tailored for WNoC. Based on the binary countdown scheme, SD-MAC has attractive features, such as being distributed, efficient, and simple, while ensuring 100 percent collisionfree performance for data transmission. The proposed receiver_select_sender and CAA mechanisms efficiently resolve both exposed terminal and hidden terminal problems. The prioritized SD-MAC is able to enable differentiated services and restore network efficiency while maintaining fairness. An efficient and low-cost MAC unit is implemented, aimed at devising simple and compact RF nodes for establishing WNoC under extremely limited resources. ACKNOWLEDGMENTS This research was supported in part by the Louisiana BOR Research Competitive Subprogram. A preliminary version of this paper was presented at the IEEE International Conference on Computer Aided Design 2007. "
2006,Designing application-specific networks on chips with floorplan information.,"With increasing communication demands of processor and memory cores in systems on chips (SoCs), scalable networks on chips (NoCs) are needed to interconnect the cores. For the use of NoCs to be feasible in today's industrial designs, a custom-tailored, application-specific NoC that satisfies the design objectives and constraints of the targeted application domain is required. In this work, we present a design methodology that automates the synthesis of such application-specific NoC architectures. We present a floorplan aware design method that considers the wiring complexity of the NoC during the topology synthesis process. This leads to detecting timing violations on the NoC links early in the design cycle and to have accurate power estimations of the interconnect. We incorporate mechanisms to prevent deadlocks during routing, which is critical for proper operation of NoCs. We integrate the NoC synthesis method with an existing design flow, automating NoC synthesis, generation, simulation and physical design processes. We also present ways to ensure design convergence across the levels. Experiments on several SoC benchmarks are presented, which show that the synthesized topologies provide a large reduction in network power consumption (2.78 times on average) and improvement in performance (1.59 times on average) over the best mesh and mesh-based custom topologies. An actual layout of a multimedia SoC with the NoC designed using our methodology is presented, which shows that the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC from input specifications to layout in 4 hours, a process that usually takes several weeks","Designing Application-Speciﬁc Networks on Chips with Floorplan Information Srinivasan Murali(cid:1) , Paolo Meloni§ , Federico Angiolini‡ , David Atienza†+ , Salvatore Car ta¶ , Luca Benini‡ , Giovanni De Micheli† , Luigi Raffo§ (cid:1)CSL, Stanford University, Stanford, USA, smurali@stanford.edu §DIEE, University of Cagliari, Cagliari, Italy, {paolo.meloni, luigi}@diee.unica.it ‡DEIS, Univerity of Bologna, Bologna, Italy, {fangiolini, lbenini}@deis.unibo.it ¶DMI, University of Cagliari, Cagliari, Italy, salvatore@unica.it † LSI, EPFL, Lausanne, Switzerland,{david.atienza, giovanni.demicheli}@epﬂ.ch +DACYA, Complutense University of Madrid (UCM), Madrid, Spain. ABSTRACT With increasing communication demands of processor and memory cores in Systems on Chips (SoCs), scalable Networks on Chips (NoCs) are needed to interconnect the cores. For the use of NoCs to be feasible in today’s industrial designs, a custom-tailored, application-speciﬁc NoC that satisﬁes the design objectives and constraints of the targeted application domain is required. In this work, we present a design methodology that automates the synthesis of such application-speciﬁc NoC architectures. We present a ﬂoorplan aware design method that considers the wiring complexity of the NoC during the topology synthesis process. This leads to detecting timing violations on the NoC links early in the design cycle and to have accurate power estimations of the interconnect. We incorporate mechanisms to prevent deadlocks during routing, which is critical for proper operation of NoCs. We integrate the NoC synthesis method with an existing design ﬂow, automating NoC synthesis, generation, simulation and physical design processes. We also present ways to ensure design convergence across the levels. Experiments on several SoC benchmarks are presented, which show that the synthesized topologies provide a large reduction in network power consumption (2.78× on average) and improvement in performance (1.59× on average) over the best mesh and mesh-based custom topologies. An actual layout of a multimedia SoC with the NoC designed using our methodology is presented, which shows that the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC from input speciﬁcations to layout in 4 hours, a process that usually takes several weeks. Keywords Networks on chips, deadlock-free routing, topology, ﬂoorplan 1. INTRODUCTION With technology scaling, the number of processor, memory and hardware cores on a chip is increasing. This has resulted in increased computation and communication complexity of the design, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. ICCAD’06, November 5-9, 2006, San Jose, CA Copyright 2006 ACM 1-59593-389-1/06/0011 ...$5.00. 355 and scalable approaches are needed to design the system. Networks on Chips (NoCs) have emerged as the paradigm for designing scalable communication architecture for Systems on Chips (SoCs) [4], [5]. In NoCs, instead of the traditional non-scalable buses, on-chip micro-networks are used to interconnect the various cores. NoCs have better modularity and design predictability when compared to bus based systems. Some of the most important phases in designing the NoC are the synthesis of the topology or structure of the network and setting of various design parameters (such as frequency of operation or link-width). The standard topologies (mesh, torus, etc.) that have been used in macro-networks result in poor performance and have large power and area overhead when used for SoCs. Such topologies are required for on-chip systems where the trafﬁc characteristics of the system cannot be predicted statically, as in chipmultiprocessors. However, for most SoCs the system is designed with static (or semi-static) mapping of tasks to processors and hardware cores and hence the communication trafﬁc characteristics of the SoC can be obtained statically. This is true from SoC designs that are small to state-of-the art SoCs, such as, the Philips Nexperia platform [1], ST Nomadik [2], TI OMAP [3], etc. Another motivation for the use of NoCs is the fact that the interconnect structure and wiring complexity can be well controlled. When the interconnect is structured, the number of timing violations that occur during the physical design (ﬂoorplanning and wire routing) phase is minimum. Such design predictability is critical for today’s SoCs for achieving timing closure. It leads to faster design cycle, reduction in the number of design re-spins and faster time-to-market. As the wire delay as a fraction of gate delay is increasing with each technological generation, having shorter wires is even more important for future SoCs. Early works on NoC topology design assumed that using regular topologies (such as mesh) would lead to regular and predictable layouts [16]. While this may be true for designs with homogeneous processing cores and memories, this is not true for most SoCs as they are typically composed of heterogeneous cores. This is due to the fact that the core sizes of the SoC are highly non-uniform and the ﬂoorplan of the design does not match the regular, tile-based ﬂoorplan of standard topologies [7]. An application-speciﬁc NoC with structured wiring, which satisﬁes the design objectives and constraints is important to have feasible NoC designs. As a motivating example, the network power consumption (switch and link power consumption), hop-count, wire-length and design area of two different NoC topologies for a video processor SoC with 42 cores is presented in Table 1. The ﬁrst topology is a Table 1: Topology Comparisons Parameter Mesh Application-speciﬁc Power (mW) 301.78 79.64 Hop-Count 2.58 1.67 Total wire-length (mm) 185.72 145.37 Design Area (mm2 ) 51.0 47.68 mesh, while the second is a custom topology generated using the methodology presented in this paper. The wire-lengths and design area are obtained from ﬂoorplanning of the NoC designs. The detailed explanation of the topologies and the ﬂoorplanning process is described later in this paper (Sections 5, 6 B). The custom topology leads to a 3.8× reduction in network power consumption, a 1.55× reduction in average hop-count and a 1.28× reduction in total length of wires when compared to the mesh. In this work, we present a methodology to design the best topology that is tailor-made for a speciﬁc application and satisﬁes the communication constraints of the design. Our topology design process supports two objective functions: minimizing network power consumption and hop-count for data transfer. The designer can optimize for one of the two objectives or a linear combination of both. The topology design process supports constraints on several parameters such as the hop-count (when the objective is power minimization), network power consumption (when the objective is hop-count minimization), design area and total wire-length. The topology synthesis process uses a ﬂoorplanner to estimate the design area and wire-lengths. The wire-length estimates from the ﬂoorplan are used to evaluate whether the designed NoC satisﬁes the target frequency of operation and to compute the power consumption of the wires. As deadlock-free routing is critical for proper operation of custom topologies, we integrate methods to ﬁnd deadlock free paths during the topology design process. We have built accurate analytical models for power consumption and area of the network components. The power consumption values are obtained from layouts with back-annotated resistance, capacitance information and from the switching activity of the components. We also automatically tune several NoC architectural parameters (such as the NoC operating frequency, link-width) in the design process. The methodology can be streamlined with existing tool ﬂows for instantiation, synthesis, FPGA emulation and layout of the NoC design. We present ways to close the design gap across the various levels of the ﬂow: from topology design to ﬂoorplanning to simulation of the design. The methodology also supports manual intervention, if needed, at several levels (like manually setting up frequency, link-width). To the best of our knowledge, this is the ﬁrst work that presents a streamlined design methodology for NoC topology synthesis that is completely integrated with the state-of-the commercial tools for back-end physical design. Unlike all earlier works (please refer to Section 2), we present a ﬂoorplan aware topology design method for NoCs that leads to detecting timing violations on the NoC links early in the design cycle, with the resulting designs fully veriﬁed for timing correctness using standard place&route tools. This is also the ﬁrst work on custom NoC topology synthesis that guarantees a complete deadlock-free network operation without requiring special hardware mechanisms, which is critical for using NoCs in real designs. Our topology synthesis process is integrated with NoC architectural parameter setting and uses accurate switch area, power models and link power models that are obtained from layouts of the components. The presented topology synthesis process is both performance and power consumption aware, which are two of the important design objectives in SoC design. Finally, the topology design process is integrated with an existing design ﬂow and we present ways to ensure design convergence across the levels. The tool ﬂow presented automates the entire NoC design process, including topology synthesis, routing and path computation, RTL code generation and layout generation; thereby bridging an important gap in the design of application-speciﬁc NoCs. An actual layout obtained from an industrial tool (Cadence SoC Encounter [37]) of a 30-core multi-media SoC with the NoC designed using our methodology is presented in Sub-section 6 A. At the layout level, the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC architecture from input speciﬁcations to layout in 4 hours, a process that used to take several weeks. A layout level comparison with a hand-designed architecture for this example is also presented, which shows that our automatic design methodology produces excellent results (in terms of power consumption and performance), matching those of carefully hand-crafted designs. Experiments on several SoC benchmarks show large power, performance and wire-length improvements when compared to standard topologies. Despite the very large design space considered, due to the use of fast algorithms and tools, the design process completes in reasonable time for all the experiments (see Sub-section 6 B). 2. PREVIOUS WORK A large body of research works exists in synthesizing and generating bus-based systems [9]-[14]. A ﬂoorplan-aware point-to-point link design and bus design methodologies are presented in [15] and [14]. While some of the design issues in the NoCs are similar to bus based systems (such as link-width sizing), a large number of issues such as ﬁnding the number of required switches, sizing the switches, ﬁnding routes for packets, etc. are new in NoCs. Methods to collect and analyze trafﬁc information that can be fed as input to the bus and NoC design processes have been presented in [12] and [13]. Mappings of cores onto standard NoC topologies have been explored in [16]-[19]. In [17], [19] a ﬂoorplanner is used during the mapping process to get area and wire-length estimates. Unlike the method presented here, these works only select topologies from a library of standard topologies. In [18], a uniﬁed approach to mapping, routing and resource reservation has been presented. However, the work does not explore topology design process. The NoC design process for supporting multiple applications has been presented in [20]. This research complements our work and its methods can be applied here to support multiple applications as well. Important research in macro-networks has considered the topology generation problem [21]. As the trafﬁc patterns on these networks are difﬁcult to predict, most approaches are tree-based (like spanning or Steiner trees) and only ensure connectivity with node degree constraints [21]. Hence, these techniques cannot be directly extended to address the NoC synthesis problem. Applicationspeciﬁc custom topology design has been explored earlier in [22][25]. The works from [22], [23] do not consider the ﬂoorplanning information during the topology design process. In [24], a physical planner is used during topology design to reduce power consumption on wires. However, the work does not consider the area and power consumption of switches in the design. Also, the number and size of network partitions are manually fed. In [25], a slicing tree based ﬂoorplanner is used during the topology design process. This work assumes that the switches are located at the corners of the cores and it does not consider the network components (switches, network interfaces) during the ﬂoorplanning process. Also, deadlock free routing, which is critical for custom NoC designs is not 356 User Objective: power, hop−delay, combination Constraints: area, power,  wire−length, hop−delay Application characteristics switch area, switch, link power models phase 1 phase 2 NoC Architecture Synthesis mismatch parameter switch link NI SystemC library RTL simulations RTL synthesis Placement & Routing  phase 3 FPGA emulation Layout To Fab Network  generation Processor models Figure 1: NoC Design Flow Vary NoC frequency from a range Vary link−width from a range Vary the number of switches from one to number of cores Synthesize the best topology with the particular frequency, link−width, switch−count Perform floorplan of synthesized topology, get link power consumption, detect timing violations  Choose topology that best optimizes user objectives  satisfying all design constraints Figure 2: NoC architecture synthesis (phase 2 of design ﬂow) supported in the work. Moreover, a complete design space exploration, from architectural parameter setting to simulation is not presented. Several works exist on automatically generating the Register Transfer Level (RTL) code of a designed topology for simulation and synthesis [26]-[28]. These works again complement ours, as the input to them is a designed topology. Building area, power models for on-chip networks has been addressed in [29]-[32]. 3. DESIGN FLOW Our ﬂow for designing NoCs is presented in Figure 1. In the ﬁrst phase, the user speciﬁes the objectives and constraints that should be satisﬁed by the NoC. The application trafﬁc characteristics, size of the cores, and the area and power models for the network components are also obtained (see Section 4). In the second phase of the ﬂow, which is the main contribution of this work, the NoC architecture that optimizes the user objectives and satisﬁes the design constraints is automatically synthesized. The different steps in this phase are presented in Figure 2. The steps are explained in detail in Section 5. In the outer iterations, the key NoC architectural parameters (NoC frequency of operation and link-width) are varied in a set of suitable values. The bandwidth available on each NoC link is the product of the NoC frequency and the link-width. During the topology synthesis, the algorithm ensures that the trafﬁc on each link is less than or equal to its available bandwidth value. The synthesis step is performed once for each set of the architectural parameters. In this step, several topologies with different number of switches are explored, starting from a topology where all the cores are connected to one switch, to one where each core is connected to a separate switch. The synthesis of each topology includes ﬁnding the size of the switches, establishing the connecMem ory 100 FFT 200 ARM 10 100 100 100 100 Disp lay Filter 100 IFFT v1 v4 100 100 v5 v2 200 100 100 100 100 v6 v3 100 critical stream weighted by 10 sustained traffic rates Figure 4: Core graph with sustained rates and critical streams Figure 3: Filter application tivity between the switches and connectivity with the cores, and ﬁnding deadlock-free routes for the different trafﬁc ﬂows. In the next step, to have an accurate estimate of the design area and wirelengths, the ﬂoorplanning of each synthesized topology is automatically performed. The ﬂoorplanning process ﬁnds the 2D position of the cores and network components used in the design. For this, we use Parquet, a fast and accurate ﬂoorplanner [35]. Based on the frequency point and the obtained wire-lengths, the timing violations on the wires are detected and the power consumption on the links is obtained. In the last step, from the set of all synthesized topologies and architectural parameter design points, the topology and the architectural conﬁguration that best optimizes the user’s objectives, satisfying all the design constraints is chosen. Thus, the output of phase 2 is the best application-speciﬁc NoC topology, its frequency of operation and the width of each link in the NoC. In the last phase of the design (phase 3 in Figure 1), the RTL (SystemC) code of the switches, network interfaces and links for the designed topology is automatically generated. For this, we use the ×pipes library [8], [34], a library of soft macros for the network components and the associated tool ×pipesCompiler [26] to interconnect the network elements with the cores. At this phase, we also obtain a synthesizable RTL design that can also be emulated on FPGA. From the ﬂoorplan speciﬁcation of the designed topology, the synthesis engine automatically generates the inputs for placement&routing. The placement&routing of the design is performed using SoC Encounter [37] for obtaining the layout, including the global and detailed routing of wires. The output of this phase is a complete layout of the NoC design that can be sent to a foundary. As the ﬂow has several steps, it is important to close the design gap across the different steps. To ensure that the designed topology will satisfy the timing constraints after place&route, we evaluate the wire-lengths for detecting timing violations early in the design process, i.e. during the topology synthesis phase itself. To bridge the gap between the initial trafﬁc models and the actual observed trafﬁc after simulating the designed NoC, we use a mismatch parameter. The parameter is read as part of the input speciﬁcations by the topology synthesis engine. The user can manually tune the parameter and re-design the NoC to suit the actual trafﬁc characteristics (explained in Sub-section 6 C). Several other options are also supported by the topology synthesis engine, such as support for cores with ﬁxed locations in the layout (due to pin/pad constraints). Due to lack of space, here we only present the major features of the synthesis process. 4. INPUT MODELS The trafﬁc characteristics of the application are represented by a graph [16], [17], [19], deﬁned as follows: D E FIN I T ION 1. The core graph is a directed graph, G(V , E ) with each vertex vi ∈ V representing a core and the directed edge (vi , vj ), denoted as ei,j ∈ E , representing the communication between the cores vi and vj . The weight of the edge ei,j , denoted 357 Table 2: Component Area-Power Component Parameter Analytical Experimental 4x4 area(mm2 ) 0.036 0.035 switch power(mW) 22.16 22.54 area(mm2 ) 5x5 0.048 0.047 switch power(mW) 28.38 28.70 link (2mm) power(mW) 0.57 0.57 by commi,j , represents the sustained rate of trafﬁc ﬂow from vi to vj weighted by the criticality of the communication. The set fk , ∀k ∈ 1 · · · |F |, representing the sustained rate of ﬂow between F represents the set of all trafﬁc ﬂows, with value of each ﬂow, the source (sk ) and destination (dk ) vertices of the ﬂow. The core graph for a small ﬁlter example (Figure 3) is shown in Figure 4. The edges of the core graph are annotated with the sustained rate of trafﬁc ﬂow, multiplied by the criticality level of the ﬂow, as done in [19]. We built accurate analytical models for the power consumption and area of the network components, based on the ×pipes architecture [8]. To get the power estimates, the place&route of the components is performed using SoC Encounter and accurate wire capacitances and resistances are obtained, as back-annotated information from the layout, with 0.13µm technology library. The switching activity in the network components is varied by injecting functional trafﬁc. The capacitance, resistance and the switching activity report are combined to estimate power consumption using Synopsys PrimePower [38]. A huge number of implementation runs were performed, varying several parameters such as the number of input, output ports, link-width and the amount of switching activity at the layout level. Linear regression was used to build analytical models for the area and power consumption of the components as a function of these parameters. Due to the intrinsic modularity and symmetry of NoC components, the models built are very accurate (with maximum and mean error of less than 7% and 5%, respectively) when compared to the actual values. Power consumption on the wires is also obtained at the layout level. The analytical and experimental area, power consumption values for some components (with 900 MHz frequency, link-width of 32 bits, buffer depth of 3 in the switches) are presented in Table 2. 5. DESIGN ALGORITHMS The algorithms for the topology design process are explained in this section. In the ﬁrst step of Algorithm 1, a design point θ is chosen from the set of available or interesting design points φ for the NoC architectural parameters. In our current implementation, the synthesis engine automatically tunes two critical NoC parameters: operating frequency (f reqθ ) and link-width (lwθ ). As both frequency and link-width parameters can take a large set of values, considering all possible combinations of values would be infeasible to explore. The system designer has to trim down the exploration space and give the interesting design points for the parameters. The designer usually has knowledge of the range of these parameters. As an example, the designer can choose the set of possible frequencies from minimum to a maximum value, with allowed frequency step sizes. Similarly, the link data widths can be set to multiples of 2, within a range (say from 16 bits to 128 bits). Thus, we get a discrete set of design points for φ, as done in [14]. In all our experiments, we support 8 frequency steps and 4 link-width steps, providing 32 discrete design points in the set φ. The rest of the topology design process (steps 3-15 in Algorithm 1) is repeated for each design point in φ. As the topology synthesis and mapping problem is NP-hard [22], we present efﬁcient heuristics to synthesize the best topology for the design. For each design point θ , the algorithm synthesizes topologies with different numbers of switches, starting from a design where all the cores are connected through one big switch until the design point where each core is connected to only one switch. The reason for synthesizing these many topologies is that it cannot be predicted beforehand whether a design with few bigger switches would be more power efﬁcient than a design with more smaller switches. A larger switch has more power consumption than a smaller switch to support the same trafﬁc, due to its bigger crossbar and arbiter. On the other hand, in a design with many smaller switches, the packets may need to travel more hops to reach the destination. Thus, the total switching activity would be higher than a design with fewer hops, which can lead to higher power consumption. For the chosen switch count i, the input core graph is partitioned into i min-cut partitions (step 3). The partitioning is done in such a way that the edges of the graph that are cut between the partitions have lower weights than the edges that are within a partition (refer to Figure 5(a)) and the number of vertices assigned to each partition is almost the same. Thus, those trafﬁc ﬂows with large bandwidth requirements or higher criticality level are assigned to the same partition and hence use the same switch for communication. Hence, the power consumption and the hop-count for such ﬂows will be smaller than for the other ﬂows that cross the partitions. For partitioning, we use Chaco, an efﬁcient hierarchical graph partitioning tool [36]. At this point, the communication trafﬁc ﬂows within a partition have been resolved. In steps 5-9, the connections between the switches are established to support the trafﬁc ﬂows across the partitions. In step 5, the Switch Cost Graph (SCG) is generated. D E FIN I T ION 2. The SCG is a fully connected graph with i vertices, where i is the number of partitions (or switches) in the current topology. Please note that the SCG does not imply the actual physical connectivity between the different switches. The actual physical connectivity between the switches is established using the SCG in the PATH COMPUTE procedure, which is explained in the following paragraphs. In NoCs, wormhole ﬂow control [39] is usually employed to reduce switch buffering requirements and to provide low-latency communication [6], [7]. With wormhole ﬂow control, deadlocks can happen during routing of packets due to cyclic dependencies of resources (such as buffers) [39]. We pre-process the SCG and prohibit certain turns to break such cyclic dependencies. This guarantees that deadlocks will not occur when routing packets. For ﬁnding the set of turns that need to be prohibited to break cycles, we use the turn prohibition algorithm presented in [33], [18]. The algorithm has polynomial time complexity (very fast in practice, see Section 6) and guarantees that at most 1/3 of the total number of turns would be prohibited to remove cycles. The algorithm also guarantees connectivity between all nodes in the SCG after prohibiting the turns. From the algorithm, we build the Prohibited Turn Set (PTS) for the SCG, which represents the set of turns that are prohibited in the graph. To provide guaranteed deadlock freedom, any path for routing packets should not take these prohibited turns. These concepts are illustrated in the following example: EXAM P L E 1. The min-cut partitions of the core graph of the ﬁlter example (from Figure 3) for 3 partitions is shown in Figure 5(a). The SCG for the 3 partitions is shown in Figure 5(b). After 358 Partition 1 Partition 2 v1 v4 100 100 v5 v2 200 100 100 100 100 v6 v3 100 Partition 3 p2 p1 p3 prohibited turns 0.70 0.63 p2 0.63 0.63 0.70 p1 0.63 p3 (a) Min-cut partitions (b) SCG graph (c) Path selection Figure 5: Algorithm examples applying the turn prohibition algorithm from [33], the set of prohibited turns is identiﬁed. In Figure 5(b), the prohibited turns are indicated by circular arcs in the SCG. For this example, both the turns around the vertex P3 are prohibited to break cycles. So no path that uses the switch P3 as an intermediate hop can be used for routing packets. Our topology synthesis process also supports freedom from another type of deadlock, known as message-level deadlock [39], by routing the trafﬁc ﬂows of the different message types in the design onto different physical links. Due to lack of space, we do not explain this in detail in this paper. 5: 6: 7: 8: Algorithm 1 Topology Design Algorithm 1: Choose design point θ from φ: f reqθ , lwθ 2: for i = 1 to |V | do 3: Find i min-cut partitions of the core graph 4: Establish a switch with Nj inputs and outputs for each partition, ∀j ∈ 1 · · · i. Nj is the number of vertices (cores) in partition i. Check for bandwidth constraint violations. Build Switch Cost Graph (SCG) with edge weights set to 0 Build Prohibited Turn Set (PTS) for SCG to avoid deadlocks Set ρ to 0 Find paths for ﬂows across the switches using function PATH COMPUTE(i, SCG, ρ, PTS, θ) Evaluate the switch power consumption and average hopcount based on the selected paths Repeat steps 8 and 9 by increasing ρ value in steps, until the hop-count constraints are satisﬁed or until ρ reaches ρthresh If ρthresh reached and hop-count not satisﬁed, go to step 2. Perform ﬂoorplan and obtain area, wire-lengths. Check for timing violations and evaluate power consumption on wires If target frequency matches or exceeds f reqθ , and satisﬁes all constraints, note the design point 14: end for 15: Repeat steps 2-14 for each design point available in θ 16: For the best topology and design point, generate information for ×pipesCompiler and Cadence SoC Encounter 11: 12: 13: 9: 10: The actual physical connections between the switches are established in step 8 of Algorithm 1 using the PATH COMPUTE procedure. The objective of the procedure is to establish physical links between the switches and to ﬁnd paths for the trafﬁc ﬂows across the switches. Here, we only present the procedure where the user’s design objective is to minimize power consumption. The procedure for the other two cases (with hop-count as the objective and with linear combination of power and hop-count as objective) follow the same algorithm structure, but with different cost metrics. An example illustrating the working of the PATH COMPUTE procedure is presented in Example 2. In the procedure, the ﬂows are ordered in decreasing rate requirements, so that bigger ﬂows are assigned ﬁrst. The heuristic of assigning bigger ﬂows ﬁrst has been shown to provide better results (such as lower power consumption 359 Algorithm 2 PATH COMPUTE(i, SCG, ρ, PTS, θ) 1: Initialize the set P H Y (i1, j 1) to false and Bw avail(i1, j 1) to f reqθ × lwθ , ∀ i1, j 1 ∈ 1 · · · i 2: Initialize switch size in(j ) and switch size out(j ) to Nj , ∀ j ∈ 1 · · · i. Find switching activ ity(j ) for each switch, 3: for each ﬂow fk , k ∈ 1 · · · |F | in decreasing order of fc do based on the trafﬁc ﬂow within the partition. 4: for i1 from 1 to i and j1 from 1 to i do {Find the marginal cost of using link i1, j1} 5: {If physical link exists and can support the ﬂow} 6: 7: 8: if P H Y (i1, j 1) and Bw avail(i1, j 1) ≥ fc then Find cost(i1, j 1), the marginal power consumption to re-use the existing link else {We have to open new physical link between i1, j1} Find cost(i1, j 1), the marginal power consumption for opening and using the link. Evaluate whether switch frequency constraints are satisﬁed. end if end for Assign cost(i1, j 1) to the edge W (i1, j 1) in SCG Find the least cost path between the partitions in which source (sk ) and destination (dk ) of the ﬂow are present in the SCG. Choose only those paths that have turns not prohibited by PTS Update P H Y , Bw avail, switch size in, switch size out, switching activ ity for chosen path 9: 10: 11: 12: 13: 14: 15: 16: 17: end for 18: Return the chosen paths, switch sizes, connectivity and more easily satisfying bandwidth constraints) in several earlier works [17], [18]. For each ﬂow in order, we evaluate the amount of power that will be dissipated across each of the switches, if the trafﬁc for the ﬂow used that switch. This power dissipation value on each switch depends on the size of the switch, the amount of trafﬁc already routed on the switch and the architectural parameter point (θ) used. It also depends on how the switch is reached (from what other switch) and whether an already existing physical channel will be used to reach the switch or a new physical channel will have to be opened. This information is needed, because opening a new physical channel increases the switch size and hence the power consumption of this ﬂow and of the others that are routed through the switch. These marginal power consumption values are assigned as weights on each of the edges reaching the vertex representing that switch in the SCG. This is performed in steps 8 and 11 of the procedure. When opening a new physical link, we also check whether the switch size is small enough to satisfy the particular frequency of operation. As the switch size increases, the maximum frequency of operation it can support reduces (as the critical path inside the switch gets longer) [8]. This information is obtained from the placement&routing of the switches, taken as an input to the algorithms. Once the weights are assigned, choosing a path for the trafﬁc ﬂow is equivalent to ﬁnding the least cost path in the SCG. This is done by applying Dijkstra’s shortest path algorithm [40] in step 15 of the procedure. When choosing the path, only those paths that do not use the turns prohibited by PTS are considered. The size of the switches and the bandwidth values across the links in the chosen path are updated and the process is repeated for other ﬂows. EXAM P L E 2. For the SCG from Example 1, let us consider routing the ﬂow of value 100 between the vertices v1 and v2, across the partitions p1 and p2. Initially no physical paths have been established across any of the switches. If we have to route the ﬂow across a link between any two switches, we have to ﬁrst establish the link. The cost of routing the ﬂow across any pair of switches is obtained from step 11 of the PATH COMPUTE procedure. The SCG with the edges annotated with the costs is presented in Figure 5(c). The costs on the edges from p2 are different from the others due to the difference in initial switching activity in p2 compared to the other switches. This is because the switch p2 has to support ﬂows between the vertices v2 and v3 within the partition. The least cost path for the ﬂow, which is across switches p1 and p2 is chosen. Now we have actually established a physical path between these switches and this is considered when routing the other ﬂows. Also, the size and switching activity of these switches have changed, which is noted. The PATH COMPUTE procedure returns the sizes of the switches, connectivity between the switches and the paths for the trafﬁc ﬂows. The objective function for establishing the paths is initially set to minimizing power consumption in the switches. Once the paths are established, if hop-count constraints are not satisﬁed, the algorithm gradually modiﬁes the objective function to minimize the hop-count as well, using the parameter ρ (in steps 7, 10 and 11 of Algorithm 1). The upper bound for ρ, denoted by ρthresh , is set to the value of power consumption of the ﬂow with maximum rate, when it crosses the maximum size switch in the SCG. At this value of ρ, for all trafﬁc ﬂows, it is beneﬁcial to take the path with least number of switches, rather than the most power efﬁcient path. The ρ value is varied in several steps until the hop-count constraints are satisﬁed or until it reaches ρthresh . In the next step (step 12, Algorithm 1), the algorithm invokes the ﬂoorplanner to compute the design area and wire-lengths. The ﬂoorplanner minimizes a dual-objective function of area and wirelength, with equal weights assigned to both. The ﬂoorplanner used [35] also supports soft cores, ﬁxed pin/pad locations and aspect ratio constraints for the generated design. From the obtained wire-lengths, the power consumption across the wires is calculated. Also, the length of the wires is evaluated to check any timing violations that may occur at the particular frequency (f reqθ ). In the end, the tool chooses the best topology (based on the user’s objectives) that satisﬁes all the design constraints. At the last step, for the synthesized topology, the algorithm automatically generates the information required for the ×pipesCompiler tool for network instantiation and the SoC Encounter tool to perform placement&routing. The presented NoC synthesis process scales polynomially with the number of cores in the design. The number of topologies evaluated by the methodology also depends linearly on the number of cores. Thus, the algorithms are highly scalable to a large number of cores and communication ﬂows. The synthesis time for several different SoC benchmarks is presented in Section 6 B. 6. EXPERIMENTS AND CASE STUDIES 6.1 Layout-level Comparisons We had earlier manually developed a NoC design for a SoC that runs multi-media benchmarks [34]. The design consists of 30 cores: 10 ARM7 processors with caches, 10 private memories (a separate memory for each processor), 5 custom trafﬁc generators, 5 shared memories and devices to support inter-processor communication. The hand-designed NoC has 15 switches connected in a 5x3 quasi-mesh network (2 cores connected to each switch), shown in Figure 6(a). The design is highly optimized, with the private memories being connected to the processors across a single switch and the shared memories distributed around the switches. The layout of the design (presented in Figure 6(b)) was performed using SoC Encounter and the mesh structure was maintained in the layout. Each of the cores has an area of 1 mm2 [34] in the design. The entire process, from topology speciﬁcation to layout generation took several weeks. The post-layout NoC could support a maximum frequency of operation of 885 MHz, which is determined by the critical path in the switch pipeline. The power consumption of the topology for functional trafﬁc has been evaluated to be 368 mW. We apply our topology synthesis process with the objective of minimizing power consumption, to automatically synthesize the NoC for this application. We set the design constraints and the required frequency of operation to be the same (885 MHz) as that of the hand-designed topology. The synthesized NoC topology and the layout obtained using SoC Encounter are presented in Figures 6(c) and 6(d). The synthesized topology has fewer switches (8 switches) than the hand-designed topology. It can support the same maximum frequency of operation (885 MHz), without any timing violations on the wires. As we considered the wire-lengths during the synthesis process to estimate the frequency that could be supported, we could synthesize the most power efﬁcient topology that would still meet the target frequency. To reach such a design point manually would require several iterations of topology design and place&route phases, which is a very time consuming process. Layout level power consumption calculations on functional trafﬁc show that the synthesized topology has 277 mW power consumption, which is 1.33× lower than the hand-designed topology. Given the fact that the hand-designed topology is highly optimized, with much of the communicating trafﬁc (which is between the ARM cores and their private memories) traversing only one switch, these savings are achieved entirely from efﬁciently spreading the shared memories around the different switches. The layout of the hand-designed NoC was manually optimized to a large extent (by moving switches, network interfaces) to reduce the area of the design. The layout of the synthesized topology is obtained completely automatically, and still the area of the design is close to that of the manual design (only a marginal 4.3% increase in area). We perform cycle-accurate simulations of the hand-designed and the synthesized NoCs for two multimedia benchmarks. The total application time for the benchmarks (including computation time) and the average packet latencies for read transactions for the topologies are presented in Figures 7(a) and 7(b). The custom topology not only matches the performance of the hand-designed topology, but provides an average of 10% reduction in total execution time and of 11.3% in packet latency. 6.2 Experiments on SoC Benchmarks We have applied our topology design procedure to six different SoC benchmarks: video processor (VPROC-42 cores), MPEG4 decoder (12 cores), Video Object Plane Decoder (VOPD-12 cores), Multi-Window Display application (MWD-12 cores), Picture-inPicture application (PIP-8 cores) and IMage Processing application (IMP-23 cores). We refer the readers to [7] for the communication characteristics of some of these benchmarks. For comparison, we have also generated mesh topologies for the benchmarks by modifying the design procedure to synthesize NoCs based on mesh structure. To obtain mesh topologies, we generate a design with each core connected to a single switch and restrict the switch sizes to have 5 input/output ports. We also generated a variant of the basic mesh topology: optimized mesh (opt-mesh), where those ports and links that are unused by the trafﬁc ﬂows are removed. 360 M0 T3 T2 T1 S14 S13 S12 S11 S10 T0 M9 M8 M7 M6 P9 P8 P7 P6 P5 P4 P3 P2 P1 M5 M4 M3 M2 M1 P0 T4 (a) Hand-designed topology 6 . 5 9 m m 5.1 mm 2 1 mm (b) Layout P6 P5 P4 P3 P2 P1 M5 M4 M3 M2 M1 P0 M0 T4 T3 T2 T1 S14 S13 S12 S11 S10 T0 M9 M8 M7 M6 P9 P8 P7 (c) Automatically synthesized 5.05 mm 7 . 2 3 m m 2 1 mm (d) Layout Figure 6: (a), (b) Hand-designed topology and layout. M: ARM7 processors, T: trafﬁc generators, P, S: private and shared slaves (c), (d) Automatically synthesized topology and layout. In Figure (c), bi-directional links are solid and uni-directional links are dotted. 256B 1KB 4KB 256B 1KB 4KB 0 1 2 3 4 5 6 x 105 hand−design automatic E x e c u t i T n o i m e ( n s ) Benchmark 1 Benchmark 2 (a) Execution time (b) Average read latency Figure 7: Run time and latency for different cache sizes 256B 1KB 4KB 256B 1KB 4KB 0 50 100 150 200 250 300 A e v r e g a R y c n e a L d a e t ( s n ) hand−design automatic Benchmark 1 Benchmark 2 The core graph and the ﬂoorplan for the custom topology synthesized by our tool for one of the benchmarks (VOPD) are shown in Figure 8. The network power consumption (power consumption across the switches and links), average hop-count and design area results for the different benchmarks are presented in Table 3. Note that the average hop-count is the same for mesh and opt-mesh, as in the opt-mesh only the unused ports and links of the mesh have been removed and the rest of the connections are maintained. The custom topology results in an average of 2.78× improvement in power consumption and 1.59× improvement in hop-count when compared to the standard mesh topologies. The area of the designs with the different topologies is similar, thanks to efﬁcient ﬂoorplanning of the designs. It can be seen from Figure 8 that only very little slack area is left in the ﬂoorplan. This is because we consider the area of the network elements during the ﬂoorplanning process, and not after the ﬂoorplanning of blocks. The total run time of the topology synthesis and architectural parameter setting process for the different benchmarks is presented in Table 3. Given the large problem sizes and very large solution space that is explored (8 different frequency steps, 4 different link-widths, 42 cores for VPROC and several calls to the ﬂoorplanner) and the fact that the NoC parameter setting and topology synthesis are important phases, the run-time of the engine is not large. This is mainly due to the use of hierarchical tools for partitioning and ﬂoorplanning and our development of fast heuristics to synthesize the topology. We also performed comparisons of synthesized topology against several other standard topologies. For mapping the cores onto the standard topologies, we use the tool from [17]. As the power libraries used for switches, links in the tool are different from the Table 3: Comparisons with standard topologies Appl Topol. Power Avg. Area Time (mW) Hops mm2 (mins) 79.64 1.67 47.68 68.45 301.8 2.58 51.0 136.1 2.58 50.51 27.24 1.5 13.49 96.82 2.17 15 60.97 2.17 15.01 30.0 1.33 23.56 95.94 2.0 23.85 46.48 2.0 23.79 20.53 1.15 15 90.17 2.0 13.6 38.60 2.0 13.8 11.71 1 8.95 59.87 2.0 9.6 24.53 2.0 9.3 52.13 1.44 29.66 198.9 2.11 29.4 80.15 2.11 29.4 custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh VPROC 4.04 MPEG4 4.47 VOPD 3.21 MWD 2.07 PIP 31.52 IMP ones used in the synthesis process, we optimized the topologies for performance, subject to the design constraints. The comparisons against 5 standard topologies (mesh, torus, hypercube, Clos and butterﬂy) for an image processing benchmark with 25 cores is presented in Figure 9. The custom topology synthesized by 1.73×) over the standard topologies. our method shows large performance improvements (an average of As an interesting observation, we found that prohibiting certain turns to avoid deadlocks during routing had a negligible impact on the power and performance results for all of the benchmarks. This was because, even if some turns were avoided, the path computation procedure could easily ﬁnd other paths with low cost, as several alternative low cost paths exist between each source and destination in the SCG (refer to Section 5). 6.3 Handling Dynamic Effects When the designed NoC is simulated, there can be some mismatch between the observed trafﬁc patterns and the initial trafﬁc estimates. This may be either because of inaccurate trafﬁc models or because of dynamic effects, such as congestion. Note that it will be too time consuming to simulate each topology during the synthesis process. To bridge the gap between topology synthesis and simulation, we use the mismatch parameter; the input trafﬁc rates are multiplied by the value of this parameter. The parameter is fed as an input to the synthesis engine. It is initially set to 1 and the user can manually tune the parameter and re-design the NoC, until the simulations satisfy the required performance level. The 361               y l a e D p o H e g a r e v A 3 2.5 2 1.5 1 0.5 0 Mesh Tor Hyp Clos Bfly Cust ) s n n i ( y c n e a L t t e k c a P e g a r e v A 150 100 50 1 1.25 Mismatch parameter 1.5 1.75 2.0 Figure 8: VOPD custom topology ﬂoorplan and core graph effect of increasing the parameter on performance for the MPEG4 NoC is presented in Figure 10. Extensions of the concept to handle localized congestion effects in the NoC are currently underway. 7. CONCLUSIONS To have a power and latency efﬁcient design, the communication architecture should closely match the application trafﬁc characteristics, satisfying the different design constraints. Synthesizing such Network on Chip (NoC) architecture is non-trivial, given the large design space that needs to be explored. In this work, we have presented a methodology that automates the process, generating efﬁcient NoCs that satisfy the design constraints of the application. To have fewer design re-spins and faster time-to-market, we consider fast and accurate ﬂoorplan information early in the design cycle. This leads to detecting timing violations on the NoC links during the NoC synthesis phase, thereby leading to timing closure with quicker convergence between the high level design and the physical design phases. We use accurate switch and link power models that are based on layouts of the components and accurate link power estimates based on the wire-lengths obtained from ﬂoorplanning. We also integrate deadlock free routing methods in the NoC synthesis process, which is critical for proper NoC operation. Experiments on several SoC benchmarks show that the synthesized topologies are much better (an average of 2.78× power reduction, 1.59× hop-count reduction) than the best mesh topology and meshbased custom topologies for our case studies. 8. "
2006,Low-power network-on-chip for high-performance SoC design.,"An energy-efficient network-on-chip (NoC) is presented for possible application to high-performance system-on-chip (SoC) design. It incorporates heterogeneous intellectual properties (IPs) such as multiple RISCs and SRAMs, a reconfigurable logic array, an off-chip gateway, and a 1.6-GHz phase-locked loop (PLL). Its hierarchically-star-connected on-chip network provides the integrated IPs, which operate at different clock frequencies, with packet-switched serial-communication infrastructure. Various low-power techniques such as low-swing signaling, partially activated crossbar, serial link coding, and clock frequency scaling are devised, and applied to achieve the power-efficient on-chip communications. The 5 /spl times/5 mm/sup 2/ chip containing all the above features is fabricated by 0.18-/spl mu/m CMOS process and successfully measured and demonstrated on a system evaluation board where multimedia applications run. The fabricated chip can deliver 11.2-GB/s aggregated bandwidth at 1.6-GHz signaling frequency. The chip consumes 160 mW and the on-chip network dissipates less than 51 mW.",
2005,An Energy-Efficient Reconfigurable Circuit-Switched Network-on-Chip.,"Network-on-chip (NoC) is an energy-efficient on-chip communication architecture for multi-tile system-on-chip (SoC) architectures. The SoC architecture, including its run-time software, can replace inflexible ASICs for future ambient systems. These ambient systems have to be flexible as well as energy-efficient. To find an energy-efficient solution for the communication network we analyze three wireless applications. Based on their communication requirements we observe that revisiting of the circuit switching techniques is beneficial. In this paper we propose a new energy-efficient reconfigurable circuit-switched network-on-chip. By physically separating the concurrent data streams we reduce the overall energy consumption. The circuit-switched router has been synthesized and analyzed for its power consumption in 0.13 /spl mu/m technology. A 5-port circuit-switched router has an area of 0.05 mm/sup 2/ and runs at 1075 MHz. The proposed architecture consumes 3.5 times less energy compared to its packet-switched equivalent.",
2008,A low-overhead fault tolerance scheme for TSV-based 3D network on chip links.,"Three-dimensional die stacking integration provides the ability to stack multiple layers of processed silicon with a large number of vertical interconnects. Through Silicon Vias (TSVs) provide a promising area- and power-efficient way to support communication between different stack layers. Unfortunately, low TSV yield significantly impacts design of three-dimensional die stacks with a large number of TSVs. This paper presents a defect-tolerance technique for TSVs-based multi-bit links through an efficient and effective use of redundancy. This technique is ideally suited for three-dimensional network-on-chip (NoC) links. Simulation results demonstrate significant yield improvement, from 66% to 98%, with a low area cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase the total switch area) in 130 nm technology, with minimal impact of VLSI design and test flows.","A Low-overhead Fault Tolerance Scheme for TSV-based 3D Network on Chip Links Igor Loi† , Subhasish Mitra‡ , Thomas H. Lee‡ , Shinobu Fujita⋆ and Luca Benini† †DEIS, University of Bologna, Bologna, Italy ‡Stanford University, California, Usa ⋆Toshiba, San Jose, CA, USA (Kawasaki, Kanagawa, Japan) igor.loi@unibo.it, subh@stanford.edu, tomlee@smirc.stanford.edu, shinobu.fujita@toshiba.co.jp and lbenini@deis.unibo.it Abstract— Three-dimensional die stacking integration provides the ability to stack multiple layers of processed silicon with a large number of vertical interconnects. Through Silicon Vias (TSVs) provide a promising area- and power-efﬁcient way to support communication between different stack layers. Unfortunately, low TSV yield signiﬁcantly impacts design of three-dimensional die stacks with a large number of TSVs. This paper presents a defecttolerance technique for TSVs-based multi-bit links through an efﬁcient and effective use of redundancy. This technique is ideally suited for three-dimensional network-on-chip (NoC) links. Simulation results demonstrate signiﬁcant yield improvement, from 66% to 98%, with a low area cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase the total switch area) in 130nm technology, with minimal impact of VLSI design and test ﬂows. I . IN TRODUC T ION F OR future integrated system design, two major trends are emerging. Communication-centric architectures based on the Network on Chip (NoC) design paradigm [1], [2] to tackle interconnect and architectural scalability challenges. Three-Dimensional Integrated Circuits (3DICs) that provide a promising technological solution to alleviate the interconnect, I/O bandwidth and latency bottlenecks. 3DICs may enable heterogeneous integration and new classes of applications through signiﬁcantly improved performance and energy efﬁciency of complex system architectures (e.g. technologies from Tezzaron Semiconductor Corporation [3], IMEC, MIT Lincoln Labs, and IBM [4]). One of the most promising technologies for 3D integration is based on Through Silicon Vias (TSVs), which cut across thinned silicon substrates to establish inter-die connectivity after die-bonding. Three-Dimensional Network on Chips (3DNoCs) combine the beneﬁts of short vertical interconnects of 3DICs and the scalability of NoCs. 3DNoCs support both horizontal and vertical links. A vertical link can be physically implemented as a cluster of TSVs. TSVs allow ﬁne pitch, high density and high compatibility with the standard CMOS process. Unfortunately, currently available processes for TSV fabrication have relatively low yield (compared to standard 2D processes). Figure 1 shows limited yield of TSVs from three different process technologies: HRI [5], IMEC [6] and IBM [7]. In this paper, we describe the design of a defect-tolerant TSV-based multi-bit vertical link which enables signiﬁcant yield improvement with respect to random (complete or partial) open defects at an extremely low cost. Like traditional defect-tolerance techniques (such as those used for memories), our technique also relies on redundancy. Our major contribution is in a simple and efﬁcient design of such a defect-tolerant TSV-based link at lowest cost, and also with minimal impact on the overall integrated system design and production test ﬂows. While this TSV-based link design is generally applicable for both NOC-based and bus-based 3D interconnects, it is especially useful for 3DNoCs because it takes advantage of the NoC switch architecture to introduce minimal system-level area impact. The main contributions of this paper are: • Introduction of a robust, defect-tolerant, vertical link architecture (for TSVs) to overcome challenges of low yield for current TSV fabrication processes; • Integration of the defect-tolerant 3D link into a complete three-dimensional Network on Chip design ﬂow; • Experimental evaluation, performed at the layout level, including full placement and routing, to evaluate beneﬁts, feasibility and hardware costs. In our experiments, we achieve signiﬁcant yield improvements (from 66% to 98% for 4.2M TSVs design, arranged in 100K spots made up of 42 TSVs each) for random (complete and partial) open defects that pose major challenges for TSVs. Our layout results demonstrate the feasibility of this approach and its low cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase in the switch area). I I . R E LAT ED WORK Interconnect scaling has become one of the most crucial challenges in chip design, and is expected to get worse in the Fig. 1. Yield trend for TSVs in three different processes: IBM, HRI and IMEC. Only random (complete or partial) open defects are considered in this ﬁgure, since misalignments are well controlled during the bonding phase. Yield is evaluated using the Poisson distribution. in(cid:13) R(cid:13)routing(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)contact(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)routing(cid:13) out(cid:13) C(cid:13)routing(cid:13) C(cid:13)TSV(cid:13) C(cid:13)TSV(cid:13) C(cid:13)routing(cid:13) C(cid:13)Load(cid:13) Fig. 3. TSVs and global wire electrical model for two stacked vias(refer to Figure 2) The primary failure mechanisms for TSVs are misalignment and random (complete or partial) open defects [15]. Misalignment refers to unsuccessful wafer alignment prior to and during wafer bonding process (Figure 2), and is caused by shifts of bonding pads with respect to their nominal positions. Random defects comprise a variety of unpredictable physical phenomena related to the thermal compression process used in wafer stacking. Starting from these considerations and based on [12], we have conducted a detailed study to quantify the impact of TSV failures on overall chip yield. We use an electrical model of TSVs and the bonding mechanisms for this purpose. Figure 3 shows the electrical model of two stacked vias (rendered as a T network). The vias are driven by one inverter followed by a stretch of planar interconnect (global routing). The contact resistance is related to the quality and area of bonding. In case of misalignments (e.g. top wafer shifts along the X or Y axes or a small rotation), the bonded area decreases. This phenomenon has been modeled as a variable resistance (central resistor in Figure 3) between the two T networks, and the outcome is summarized in Table I. As can be seen, misalignments of even noticeable entity do not normally compromise functionality (which is dominated by the overall planar routing parasitics [12]) and have a minimum impact on delay. Extreme misalignment, like in the last row of table I are highly unlikely in state-of-the-art wafer bonding processes [3], [4], [16]. This motivates special emphasis on workarounds for the other main source of yield losses: random defects. Random (complete or partial) open defects affect single vias or a small area of the interface because of failure mechanisms such as dislocations, 02 trapped on the surface, void formation, or even mechanical failures in TSVs [17], [18], [18], [4], [19]. To model the effects of these defects, we assumed a uniform TSV defect distribution and performed several Monte Carlo simulations. Based on our results (Section V), we concluded that random (complete or partial) open defects are far more relevant compared to misalignment problems. For this reason, we focus on these defects in the following sections. 2x1(cid:13)XBAR(cid:13) TSVs(cid:13) IN_1(cid:13) IN_2(cid:13) IN_3(cid:13) 1(cid:13) 2(cid:13) 3(cid:13) E(cid:13)_1(cid:13) y(cid:13) OUT_1(cid:13) OUT_2(cid:13) OUT_3(cid:13) 1(cid:13) 2(cid:13) 3(cid:13) 4(cid:13) 5(cid:13) 6(cid:13) 7(cid:13) 8(cid:13) 9(cid:13) E(cid:13)_1(cid:13) E(cid:13)_2(cid:13) E(cid:13)_3(cid:13) ROM(cid:13) ROM(cid:13) (a)(cid:13) z(cid:13) x(cid:13) (b)(cid:13) Fig. 4. Redundant Routing scheme. (a) shows a simpliﬁed crossbar scheme for dynamic routing (functional scheme). (b) shows the TSVs obstruction and the routing crossbar (the orange squares are the TSV pads). Extra pads (E 1 E 2 ...) are spread around the TSV cluster, simplifying fault bypassing by means of a 2X multiplexers. Fig. 2. Cross-section of a vertical link across two tiers. The ﬁgure also shows the worst-case misalignment scenario future. 3D integration and Network on Chip design methodologies are expected to overcome many of these challenges. NoCs have been suggested as a scalable communication fabric [1], [2]. 3D integration has been proposed in different ways (e.g. Tezzaron Semiconductor Corporation [3], IMEC, MIT Lincoln Labs, and IBM Technologies [4]) providing promising solutions to enable connectivity along the vertical direction. Recently, some research has been undertaken on 3DNoCs. In [8], the authors propose a dimension decomposition scheme to optimize the cost of 3D NoC switches, and present some area and frequency ﬁgures derived from a physical implementation. Post-silicon nano-scale 3D interconnections have also been recently investigated [9], [10], but large scale availability of these technologies in the near future is uncertain. As technology scales, fault tolerance is becoming a key concern in on-chip communication. Optical Proximity Correction (OPC) and redundant via placement [11] have solved a huge number of cases of faults related, mainly, to interconnects. Recent experiments by HRI on 3DICs report very high yields of over 60%, and the redundancy scheme used realizes each vertical interconnect as a pair of vias (twins) [5]. Despite the research undertaken on 3DICs and recently on 3DNoCs, to date, yield improvements for vertical links of 3DNoCs have never been studied. In this paper, we propose a novel scheme to overcome this limitation. The starting point of this work is [12], [13], where a thorough physical and timing analysis of the vertical links has been conducted on a real 3DNoC. Further, it is worth stressing that the proposed scheme can also be applied successfully to alternative interconnection schemes, such as buses. I I I . PHY S ICA L L EV E L MOD E L ING AND ANA LY S I S O F TSV FAU LT IM PAC T In this paper we focus on the wafer stacking approach since it is very promising for the implementation of highperformance yet inexpensive 3DICs. Wafer stacking relies on Through-Silicon Vias (TSVs) [14] for vertical connectivity, guaranteeing low parasitics (i.e. low power and propagation delay) and, if needed, extremely high densities of vertical wires (i.e. high bandwidth-per-area ratio). The electrical connectivity between different tiers is provided by creating pads on the wafer surface, and then performing bonding by mechanical thermo-compression. Misalignment [µm] in X-Y 0 1 2 3 3.98 Contact Area [µm 2 ] 4x4 3x3 2x2 1x1 0.02x0.02 Contact Resistance ∆ Delay [%] 0 [Ω] 10m 19m 40m 160m 1K < 1% < 1% < 1% 22% TABLE I PAD CON TAC T R E S I S TANC E AND D E LAY INCR EA S ING FOR CU -CU WA F ER M E TA L BOND ING UND ER D I FF ER EN T M I SA L IGNM EN T CA S E S [17 ] , [20 ] IV. Y I E LD ENHANC EM EN T S FOR 3DNOC S In this section, we describe the target 3DNoC [12], [13] used for our experiments, and present our defect-tolerant solution for TSV-based vertical link design. As pointed out earlier, our solution can be applied not only to 3DNoCs, but also, more generally, to regular structures such as buses. A. The reference NoC architecture To make our study realistic, we developed our approach within the ×pipes [12], [21], [13] NoC library. To enable our NoC for 3D technology we extended the ×pipes switches by adding a couple of vertical ports, and we developed hard macros for the TSVs obstruction [12]. Vertical links are unidirectional, and are composed (as planar links) of data and ﬂow control signals, traveling in opposite directions. For this work we selected a data width of 32 bit, therefore for a pair of 3D links, 76 different signals are needed overall. B. Yield Enhancement Approaches Among the numerous techniques to increase wafer yield of VLSI designs, we focus on hardware redundancy, deployed at design time, with some amount of post-manufacturing conﬁguration. We use active redundancy in the form of spare pads and reconﬁgurable routing hardware in order to minimize the overall complexity, while gaining maximum beneﬁts in term of efﬁciency (Figure 4). The dynamic routing solution is designed to leverage postmanufacturing conﬁgurability of the TSV interconnect map. This allows us to achieve high yield while minimizing the overhead in terms of the number of pads and extra logic. Combining testing resources (e.g., scan chains 1 ) with such reconﬁgurability plays the key role in achieving yield. This solution allows us to test each vertical interconnect and diagnose defects, to isolate any failed TSV, and ﬁnally to restore functionality through reconﬁguration by routing the affected signals over to the spare pads. As we see in Figure 4 (a), in our proposed Dynamic Routing scheme, all pads are driven by a 2×1 crossbar, and each signal can be routed to two different TSVs. We explore conﬁgurations with one extra pad for each cluster (i.e. for each pad column). The crossbar is extremely small, as a strategic choice to keep the area overhead as low as possible - for each additional rerouting degree of freedom, the crossbar radix increases by a factor of one. With this lean architecture, faults are recovered by shifting affected signals to the neighboring pads, and further shifting the displaced connections over to other adjacent pads until all connections are across safe electrical structures. To clarify the recovery scheme, we shall consider Figure 4 (b). 1 The use of scan chains does not normally imply any extra cost, as they are typically integrated in every design Supposing that pad 2 is affected by some defects (resulting e.g. in an open circuit), we route signal 3 normally through its associated pad 3, while signal 2 gets rerouted through pad 1, and therefore signal 1 gets remapped to pad E 1. Signals outside this column are not shifted since the defect is contained inside the ﬁrst cluster; the recovery process is performed locally. The proper routing information is elaborated off-chip (to minimize hardware complexity and overhead) during chip testing, and is then stored on-chip into a small One Time Programmable (OTP) memory (e.g. a fuse ROM). The importance of the testing stage is evident, as it determines all the necessary inputs to correctly set the crossbar up. To test the physical interconnect, we reuse the scan chains which are normally inserted anyway in the design, thus incurring no overhead for this. Figure 5 illustrates the hardware facilities used to test the TSVs. The TSVs are tested by injecting Test Vectors (TVs) in one tier (e.g. the bottom one). The TV is propagated to the destination tier (e.g. the top one), where it is captured and transmitted off-chip. In summary, the approach is split into ﬁve steps: 1) Inject test vectors (e.g. bottom tier); 2) Propagate test vectors across TSVs and capture them (e.g. top tier); 3) Scan out the captured data (e.g. top tier); 4) Elaborate off-chip the interconnect map; 5) Reconﬁgure the crossbar (both bottom and top tier); The process can be performed at any speed allowed by the external I/O pins. Since the interconnect map is devised off-chip, minimal logic is required on-chip for the mapping procedure - mostly, the OTP memory to store the crossbar conﬁgurations. V. EX P ER IM EN TA L R E SU LT S A. Yield and Hardware Cost of the Redundant Solutions The alternative solutions, and a non-redundant baseline case, have been synthesized with the UMC 130nm technology library and inserted into the ﬂoorplan for a 3D chip stack. Placement, routing and post layout veriﬁcation have been performed. As depicted in Figure 8, the planar topology has been partitioned in two parts (dotted line), between the central routers. The topology under test (see Figure 8) includes six processors and six memories, placed on two layers. Vertical communication is achieved through the two central switches Fig. 6. Normalized area cost in case of No Redundancy and Dynamic Routing with 2, 3, 4, 7, 11 and 38 extra pads. The main contribution of this paper is resumed starting from the 2nd bar, which shows only 1.6% area overhead for 2 extra pads, 2.1% for 4 extra pads and 10.5% for full redundancy (38 extra pads) 1* NoC 2D NoC 2D NoC 2D NoC 2D 1* 5* 5* 2* 3* 5* 5 5* Fig. 5. TSV NoC Test Environment: in test mode, test vectors are injected from the Test Access Point (1*) into the switch input buffer (scan), then the path through the crossbar is enabled (1*) and ﬂow control is disabled. After some cycles the stimuli reach the next tier where they are captured (2*) from the input buffer, and then shifted out through the TAP (3*). This stream is analyzed off-chip then, based upon the failure map the OTP memories are programmed (5*), reconﬁguring the crossbar to isolate failed structures which act as a gateway for 3DNoC trafﬁc. The reconﬁgurable crossbars have been inserted between the TSV pads and the switch. For a 32-bit link, the NoC protocol uses 38 bits, where the remaining 6 bits belong to ﬂow control signaling and mesochronous handling (i.e. the clock and reset signals which are forwarded along with the data). The nature of the reference NoC switches, namely their ﬂow control, have inﬂuenced the adopted testing solution. During testing, a portion of the hardware works in scan mode (inject) and the other in capture mode; the ﬂow control has to be explicitly managed to avoid the formation of communication stalls. Four scan chain groups have been inserted, driven by a simple Finite State Machine (FSM), accomplishing high efﬁciency and reliability. The overhead of this approach is mainly due to the crossbar logic around the via bundles, to the OTP memory and to the small FSM. The scan chain cost is not taken into account since, as mentioned before, the design must be testable anyway, and this contribution is present as well on planar ICs. Several experiments have been conducted, especially with the dynamic routing technique, in order to evaluate how many extra pads and area may be needed for implementation, and in order to explore the trade-offs between yield and cost. We implemented six different conﬁgurations, respectively with 2, 3, 4, 7, 11 and 38 extra pads. It is worth noting that, in each unidirectional link of 38 signals, spare pads are separately needed for incoming (mostly, ﬂow control) and outgoing (mostly, data) wires; hence the need for at least 2 Fig. 7. Yield improvement over seven different hardware conﬁgurations: no-redundancy, 2, 3, 4, 7, 11 and 38 extra pads, which correspond to 38, 40, 41, 42, 45, 49, and 76 TSVs per 3D link. A ﬁxed defect frequency of 9.75 Defects Per Million Opportunities (DPMO) is assumed, and 4.2M TSVs design has been analyzed. Fig. 8. 3D NoC topology. Dash boxes indicate the resources involved in the TSV test process. spares. The latter group typically features many more wires than the former (35 vs. 3 in our example), so the correction performance is maximized with an asymmetric assignment of spares to the two groups. For example, with only 2 extra pads, no choice is available; there is only one spare for 35 outgoing signals, while the 3 incoming wires share the second spare. With 4 spares, the optimal arrangement is to assign 3 to the outgoing bundle, and the fourth to the incoming bundle. In the extreme case of 38 spares, each TSVs has a backup. Figure 7 illustrates the yield improvement in case of 2, 3, 4, 7, 11 and 38 extra pads and based on experimental data, assuming a ﬁxed defect frequency of 9.75 Defect Per Million Opportunities (HRI TSV process [5]). We emulated 100K TSVs links with and without redundancy. Without postmanufacturing processing, the system is unable to recover damaged vias, and tolerates only small misalignments, thus exhibiting a yield of only 68%. When Dynamic Routing redundancy is adopted, the recovery algorithm shows excellent results, especially with 2 to 7 extra pads. Further increasing the number of extra pads brings minimal yield beneﬁts, and the increase in cost of TSV obstructions, TSV crossbar and the OTP memory may be unjustiﬁed. With only four extra pads per 3D link, yield increases from 68% to 98%. Concerning the silicon cost, Figure 6 shows the normalized area cost in case of different degrees of redundancy applied to a single 3D link. As the number of extra pads increases, the TSVs spot and the routing logic grow in a linear fashion. The increasing area, with reference to a baseline composed of the Switch and the non-redundant TSVs link is 1.6% in case of 2 extra pads, 2.1% on 4 extra pads, and 10.5% in case of 38 extra pads. As a stand-alone component, the redundant links with 2 extra pads impacts for the 17% on a non-redundant Link. The physical implementation of the redundant hardware is depicted in Figure 9, where a pair of 3D links (42 TSVs each) is surrounded by the routing crossbar, guaranteeing low latency and better area utilization. To evaluate the impact of the Dynamic Routing solution uses advanced technology nodes, we performed an experiment using 65nm technology library. As we can see in Table II, by scaling the technology the Dynamic Routing logic scales as well. But, the TSV obstructions show the same area, since we conservatively assumed that the TSV process is independent from the technology node used for the 2D chip and it does’t scale. Therefore, the area overhead of our solution increases from 2.1% on 130nm to 3.8% on 65nm, which is still very affordable. V I . CONC LU S ION S AND FU TUR E WORK 3DICs, especially those based on Through-Silicon Vias, are gaining traction as a workaround against the increasing costs of chip miniaturization. However, the manufacturing technology is not mature enough, resulting in issues such as misalignments and random defects. Misalignment-reduction techniques have undergone signiﬁcant improvements, so that today random defects must be considered the main source of yield losses. For this reason, minimizing their impact is crucial. In this paper, we study some baseline redundancy schemes and we notably propose a novel Dynamic Routing approach. The latter scheme is based on post-manufacturing study and reconﬁguration of the electrical resources, leveraging a small amount of on-chip spares. The scheme proves capable of yields up to 98% with a minimum silicon cost of just 17% per TSV link in 130nm. This cost is further projected to decrease to just 12% in the newest 65nm technologies. Future work may revolve around timing faults, which are an often underestimated source of failures. ACKNOW L EDGM EN T S This work is the result of a strict collaboration between University of Bologna, Toshiba and Stanford Center for Integrated Systems. This work is supported by European project 214364 ICT-GALAXY for DEIS. "
2006,System-Level Buffer Allocation for Application-Specific Networks-on-Chip Router Design.,"In this paper, a novel system-level buffer planning algorithm that can be used to customize the router design in networks-on-chip (NoCs) is presented. More precisely, given the traffic characteristics of the target application and the total budget of the available buffering space, the proposed algorithm automatically assigns the buffer depth for each input channel, in different routers across the chip, such that the overall performance is maximized. This is in deep contrast with the uniform assignment of buffering resources (currently used in NoC design), which can significantly degrade the overall system performance. Indeed, the experimental results show that while the proposed algorithm is very fast, significant performance improvements can be achieved compared to the uniform buffer allocation. For instance, for a complex audio/video application, about 80% savings in buffering resources, can be achieved by smart buffer allocation using the proposed algorithm",
2013,SpiNNaker - A 1-W 18-Core System-on-Chip for Massively-Parallel Neural Network Simulation.,"The modelling of large systems of spiking neurons is computationally very demanding in terms of processing power and communication. SpiNNaker - Spiking Neural Network architecture - is a massively parallel computer system designed to provide a cost-effective and flexible simulator for neuroscience experiments. It can model up to a billion neurons and a trillion synapses in biological real time. The basic building block is the SpiNNaker Chip Multiprocessor (CMP), which is a custom-designed globally asynchronous locally synchronous (GALS) system with 18 ARM968 processor nodes residing in synchronous islands, surrounded by a lightweight, packet-switched asynchronous communications infrastructure. In this paper, we review the design requirements for its very demanding target application, the SpiNNaker micro-architecture and its implementation issues. We also evaluate the SpiNNaker CMP, which contains 100 million transistors in a 102-mm <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>  die, provides a peak performance of 3.96 GIPS, and has a peak power consumption of 1 W when all processor cores operate at the nominal frequency of 180 MHz. SpiNNaker chips are fully operational and meet their power and performance requirements.",
2009,CoMPSoC - A template for composable and predictable multi-processor system on chips.,"A growing number of applications, often with firm or soft real-time requirements, are integrated on the same System on Chip, in the form of either hardware or software intellectual property. The applications are started and stopped at run time, creating different use-cases. Resources, such as interconnects and memories, are shared between different applications, both within and between use-cases, to reduce silicon cost and power consumption. The functional and temporal behaviour of the applications is verified by simulation and formal methods. Traditionally, designers resort to monolithic verification of the system as whole, since the applications interfere in shared resources, and thus affect each other's behaviour. Due to interference between applications, the integration and verification complexity grows exponentially in the number of applications, and the task to verify correct behaviour of concurrent applications is on the system designer rather than the application designers. In this work, we propose a Composable and Predictable Multi-Processor System on Chip (CoMPSoC) platform template. This scalable hardware and software template removes all interference between applications through resource reservations. We demonstrate how this enables a divide-and-conquer design strategy, where all applications, potentially using different programming models and communication paradigms, are developed and verified independently of one another. Performance is analyzed per application, using state-of-the-art dataflow techniques or simulation, depending on the requirements of the application. These results still apply when the applications are integrated onto the platform, thus separating system-level design and application design.",
2006,Implementation and Evaluation of On-Chip Network Architectures.,"Driven by the need for higher bandwidth and complexity reduction, off-chip interconnect has evolved from proprietary busses to networked architectures. A similar evolution is occurring in on-chip interconnect. This paper presents the design, implementation and evaluation of one such on-chip network, the TRIPS OCN. The OCN is a wormhole routed, 4x10, 2D mesh network with four virtual channels. It provides a high bandwidth, low latency interconnect between the TRIPS processors, L2 cache banks and I/O units. We discuss the tradeoffs made in the design of the OCN, in particular why area and complexity were traded off against latency. We then evaluate the OCN using synthetic as well as realistic loads. We found that synthetic benchmarks do not provide sufficient indication of the behavior of realistic loads on this network. Finally, we examine the effect of link bandwidth and router FIFO depth on overall performance.",
2009,Application-aware prioritization mechanisms for on-chip networks.,"Network-on-Chips (NoCs) are likely to become a critical shared resource in future many-core processors. The challenge is to develop policies and mechanisms that enable multiple applications to efficiently and fairly share the network, to improve system performance. Existing local packet scheduling policies in the routers fail to fully achieve this goal, because they treat every packet equally, regardless of which application issued the packet. This paper proposes prioritization policies and architectural extensions to NoC routers that improve the overall application-level throughput, while ensuring fairness in the network. Our prioritization policies are application-aware, distinguishing applications based on the stall-time criticality of their packets. The idea is to divide processor execution time into phases, rank applications within a phase based on stall-time criticality, and have all routers in the network prioritize packets based on their applications' ranks. Our scheme also includes techniques that ensure starvation freedom and enable the enforcement of system-level application priorities. We evaluate the proposed prioritization policies on a 64-core CMP with an 8×8 mesh NoC, using a suite of 35 diverse applications. For a representative set of case studies, our proposed policy increases average system throughput by 25.6% over age-based arbitration and 18.4% over round-robin arbitration. Averaged over 96 randomly-generated multiprogrammed workload mixes, the proposed policy improves system throughput by 9.1% over the best existing prioritization policy, while also reducing application-level unfairness.","Application-Aware Prioritization Mechanisms for On-Chip Networks Reetuparna Das§ Onur Mutlu† Thomas Moscibroda‡ Chita R. Das§ §Pennsylvania State University †Carnegie Mellon University ‡Microsoft Research {rdas,das}@cse.psu.edu onur@cmu.edu moscitho@microsoft.com Abstract Network-on-Chips (NoCs) are likely to become a critical shared resource in future many-core processors. The challenge is to develop policies and mechanisms that enable multiple applications to efﬁciently and fairly share the network, to improve system performance. Existing local packet scheduling policies in the routers fail to fully achieve this goal, because they treat every packet equally, regardless of which application issued the packet. This paper proposes prioritization policies and architectural extensions to NoC routers that improve the overall application-level throughput, while ensuring fairness in the network. Our prioritization policies are application-aware, distinguishing applications based on the stall-time criticality of their packets. The idea is to divide processor execution time into phases, rank applications within a phase based on stall-time criticality, and have all routers in the network prioritize packets based on their applications’ ranks. Our scheme also includes techniques that ensure starvation freedom and enable the enforcement of system-level application priorities. We evaluate the proposed prioritization policies on a 64-core CMP with an 8x8 mesh NoC, using a suite of 35 diverse applications. For a representative set of case studies, our proposed policy increases average system throughput by 25.6% over age-based arbitration and 18.4% over round-robin arbitration. Averaged over 96 randomlygenerated multiprogrammed workload mixes, the proposed policy improves system throughput by 9.1% over the best existing prioritization policy, while also reducing application-level unfairness. Categories and Subject Descriptors C.1.2 [Computer Systems Organization]: Multiprocessors; Interconnection architectures; C.1.4 [Parallel Architectures]: Distributed architectures General Terms Design, Algorithms, Performance Keywords On-chip networks, multi-core, arbitration, prioritization, memory systems, packet scheduling 1. Introduction Packet-based Network-on-Chips (NoCs) are envisioned to be the solution for connecting tens to hundreds of components in a future many-core processor executing hundreds of tasks. Such an NoC is a critical resource, likely to be be shared by diverse applications running concurrently on a many-core processor. Thus, effective utilization of this shared interconnect is essential for improving overall system performance and is one of the important challenges in many-core system design. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. MICRO’09, December 12–16, 2009, New York, NY, USA. Copyright 2009 ACM 978-1-60558-798-1/09/12 ...$10.00. Traditionally, NoCs have been designed [22, 14, 16, 13, 17] to optimize network-level performance metrics, such as saturation throughput or average packet latency. These metrics capture inherent performance characteristics of the network itself, but they are not directly related to the performance metrics observable at the application-level or system-level. There are various reasons as to why optimizing for network parameters may not be adequate to improve system performance. First, average packet latency may not be indicative of network-related stall-time at the processing core (i.e. number of cycles during which the processor cannot commit instructions waiting for an in-transit network packet [19]). This is because much of the packets’ service latencies might be hidden due to memory-level parallelism [11]. Second, the network’s saturation throughput might not be critical given the self-throttling nature of CMPs: a core cannot inject new requests into the network once it ﬁlls up all of its miss request buffers). Third, average network throughput may not accurately reﬂect system performance because the network throughput demands of different applications can be vastly different. To exemplify these points, Figure 1 shows performance in terms of different metrics for a 64-node multicore processor, with 32 copies of two applications, leslie and omnetpp, running together. The ﬁgure contrasts three network-level performance metrics (throughput demanded/offered and average packet latency) with two applicationlevel performance metrics (execution-time slowdown and network related stall-time slowdown each application experiences compared to when it is run alone on the same system; these metrics correlate with system-level throughput as shown in [27, 8]). Even though the network-level performance metrics of the two applications are very similar, the slowdown each application experiences due to sharing the NoC is vastly different: leslie slows down by 3.55X, whereas omnetpp slows down by 7.6X. Hence, designing the network to optimize network-level metrics does not necessarily provide the best application and system-level throughput. Leslie Omnetpp Leslie 2.0% Omnetpp Leslie Omnetpp 200 Leslie Omnetpp 8 Leslie Omnetpp 30 8% 6% 4% 2% 0% (a) Throughput Demand (packets/instruction) 1.5% 1.0% 0.5% 0.0% (b)  Throughput Offered (packets/cycle) 150 100 50 0 (c) Packet Latency (cycles) 6 4 2 20 10 0 (d) Execution T ime Slowdown 0 (e)   Network Stall T ime Slowdown Figure 1: Different Metrics for Network Performance Analysis A key component of a router that can inﬂuence application-level performance is the arbitration/scheduling unit. Commonly-used arbitration policies in NoCs are application-oblivious and local. Such application-oblivious local policies lead to reduced overall system performance because they 1) fail to harness application properties to improve system throughput, 2) can lead to un-coordinated and contradictory decision-making by individual routers. First, once a packet is injected into the network, scheduling decisions taken by routers do not consider which applications issued the packets. As a result, packets from applications that are particularly sensitive to network packet latency are treated with the same priority as other, less-critical packets, which can substantially decrease applicationlevel performance of the sensitive application. Second, each router makes packet scheduling decisions using information local to that router. For example, a router can schedule packets from different vir280 tual channels in a round-robin fashion over cycles, schedule a packet from the least recently used virtual channel, or schedule the locallyoldest packet ﬁrst. As a result, a packet may be prioritized in one router only to be delayed by the next router. Consequently, one application might be prioritized in one router and delayed in a second one, whereas another application can be prioritized by the second router and delayed in the ﬁrst, which leads to an overall degradation in system throughput. To mitigate the above disadvantages of existing approaches, we propose a new substrate to enable application-aware prioritization in an NoC by coordinating the arbitration/scheduling decisions made by different routers. Our approach is based on the concept of stalltime criticality (STC). A network packet has high stall-time criticality if an increase in its network latency results in a high increase of application-level stall-time. In our approach, each router schedules packets based on which application the packets belong to. Speciﬁcally, the STC-policy combines two mechanisms: application ranking and packet batching. Applications are ranked based on the stalltime criticality of their network packets. Each router prioritizes packets according to this rank: packets of an application where network performance is critical (higher-ranked applications) are prioritized over packets from lower-ranked applications. Prioritization is enforced across the network in a coordinated and consistent fashion because all routers use the same ranking. The packet batching mechanism ensures starvation freedom: periodically, a limited number of network packets are grouped into batches. Each router prioritizes packets belonging to older batches, thereby ensuring that no application starves due to interference from other, higher-ranked (or potentially aggressive) applications. Experimental evaluations show that our proposal effectively increases overall system throughput and application-level fairness in the NoC. In addition, our application-level prioritization substrate can be seamlessly extended to enforce application priorities assigned by the operating system. In comparison to existing application oblivious routing policies that cannot easily enforce system-level priorities, this is an added advantage. Thus, the main contributions of this paper are the following: • We observe that common network-level metrics can differ substantially from application-level performance metrics and identify the stall-time criticality of network packets as a key concept that affects overall system performance. • We show that local, application-oblivious arbitration policies in NoC routers can degrade application-level system throughput and fairness. We further show that global policies based on network parameters lead to poor application performance, and can lead to unfair performance between applications with different memory access patterns. • We propose novel prioritization mechanisms to improve application-level system throughput without hurting application-level fairness in NoCs. Our key idea is to dynamically identify applications that beneﬁt the most from prioritization in the network due to higher stall-time criticality of their packets and coordinate the routers to prioritize these applications’ packets. • We qualitatively and quantitatively compare our mechanisms to previous local and global arbitration policies, including age-based prioritization and globally synchronized frames [17]. We show that our proposal provides the highest overall system throughput (9.1% higher than the best existing policy over 96 diverse workloads) as well as the best application-level fairness. 2. Background In this section, we provide a brief background on NoC architectures along with current packet scheduling and arbitration policies. For an in-depth introduction to NoCs, we refer the reader to [5]. A Typical Router: A generic NoC router architecture is illustrated in Figure 2(a). The router has P input and P output channels/ports; typically P = 5 for a 2D mesh, one from each direction and one from the network interface (NI). The Routing Computation unit, RC, is responsible for determining the next router and the virtual channel within the next router for each packet. The Virtual channel Arbitration unit (VA) arbitrates amongst all packets requesting access to the same VCs and decides on winners. The Switch Arbitration unit (SA) arbitrates amongst all VCs requesting access to the crossbar and grants permission to the winning packets/ﬂits. The winners are then able to traverse the crossbar and are placed on the output links. A Typical Network Transaction: In a general-purpose chip multiprocessor (CMP) architecture, the NoC typically interconnects the processor nodes (a CPU core with its outermost private cache), the secondary on-chip shared cache banks, and the on-chip memory controllers (See Figure 2(b)). The processor sends request packets to cache bank nodes and receives data packets via the NoC. If the requested data is not available in the cache, the cache bank node sends request packets to the on-chip memory controller nodes via the NoC, and receives response data packets from the controller once data is fetched from off-chip DRAMs. Each packet spends at least 2-4 cycles at each router depending on the number of stages in the router. Packet Arbitration Policies within an NoC Router: Each incoming packet is buffered in a virtual channel (VC) of the router, until it wins the virtual channel arbitration stage (VA) and is allocated an output VC in the next router. Following this, the packet arbitrates for the output crossbar port in the switch arbitration stage (SA). Thus, there are two arbitration stages (VA and SA) where the router must choose one packet among several packets competing for either a common 1) output VC or 2) crossbar output port.1 Current routers use simple, local arbitration policies to decide which packet should be scheduled next (i.e., which packet wins arbitration). A typical policy, referred to as LocalRR in this paper, is to choose packets in different VCs in a round-robin order such that a packet from the next non-empty VC is selected every cycle. An alternative policy, referred to as LocalAge in this paper, chooses the oldest packet. Why scheduling and arbitration policies impact system performance? In addition to the router pipeline stages, a packet can spend many cycles waiting in a router until it wins a VC slot and gets scheduled to traverse the switch. While its packets are buffered in remote routers, the application stalls waiting for its packets to return. Thus, packet scheduling or arbitration policies at routers directly impact application performance. Why scheduling and arbitration policies impact system fairness? A scheduling or arbitration policy dictates which packet the router chooses and hence also which packet is penalized. Thus, any policy which gives higher priority to one packet over another might affect the fairness in the network. Current routers use locally fair policies that are application-agnostic. Locally fair policies need not be globally fair. For example, the LocalRR might seem a very fair policy locally, but could lead to high unfairness in asymmetric topologies. 3. Motivation Existing NoC routing policies are implicitly built on the paradigm that every packet in the network is equally important and hence, packets from one application should not a-priori be prioritized over packets from other applications. In this paper, we challenge this paradigm by observing how different packets (even within the same application, but particularly across different applications) can have vastly different impact on application-level performance. In this section, we describe three reasons that can cause differences in stall-time criticality (STC) of packets. Combined, they provide the motivation for our application-aware approach to NoC packet scheduling, which is described in Section 4. 1Note that in wormhole switching only the head ﬂit arbitrates for and reserves the VC; the body ﬂits thus do not require VC allocation. However, all ﬂits have to compete for the switch. For simplicity, our discussions will be in terms of packets instead of ﬂits. 281 VC Identifier VC 1 VC v Crossbar (P x P) Routing  Computation  (RC) VC Arbiter (VA) Switch Arbiter  (SA) I u p n t e n n a h C l 1 C r d e t i u o t Output  Channel  1 Output  Channel  P Input Port 1 Input Port P I u p n t e n n a h C l P Scheduler R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI R NI Memory  Controller CPU + L1 Caches CACHE BANK Figure 2: Generic NoC router and topology: (a) Baseline Router (b) Example CMP Layout for a 4x4 Mesh. Different Stall-Time Criticality due to Different Memory-Level ets of applications with higher stall-time criticality to gain overall Parallelism: Modern microprocessors employ several memory laapplication-level system throughput. tency tolerance techniques [7, 15, 31, 21] to hide the penalty of load Different Stall-Time Criticality due to Different Memory Acmisses. These techniques issue several memory requests in paralcess Latency: An application’s STC is also affected by the averlel in the hope of overlapping future load misses with current load age latency of memory accesses. Load misses that have high lamisses. The notion of issuing and servicing several requests in partency expose more number of stall cycles due to smaller probability allel is called Memory Level Parallelism (MLP) [11]. The concept of of overlap with other misses. Therefore, if an application’s packets MLP affects the criticality of load requests. Although there might be frequently access remote nodes in the network or off-chip DRAM, multiple outstanding load misses in the system, not every load miss the application is likely to have higher STC. In Figure 1, Omnetpp is the bottleneck-causing (i.e. critical) miss [9]. Typically the oldest has higher stall-time criticality than Leslie3d because many of its load is the most critical to the processor, whereas many other misses memory accesses are L2 misses whereas Leslie3d’s are L2 hits. might be completely overlapped with earlier requests. Previous reDifferent Stall-Time Criticality due to Different Network Load: search [28, 25] has established that not all load misses are equally Applications can differ signiﬁcantly in the amount of load they inject critical to the processor. Hence, increasing the latency of these noninto the network. Applications can be “light” (low injection rate) or critical misses (i.e. packets) in the network will have less impact “heavy” (high injection rate). Hence, applications can demand difon application execution time, compared to increasing the latency of ferent bandwidth from the network. Naturally, packets from light critical misses. applications with few outstanding packets tend to be more stall-time Moreover, every application has different degrees of MLP. For excritical because their cores can be better utilized if serviced faster. ample Figure 3(a) shows the execution timeline of an application Prioritizing such “shorter jobs” (from the viewpoint of the network) with no MLP (e.g. libquantum): it sends one packet to the netahead of more intense applications can increase system throughput. work after a number of instructions. In the absence of other concurrent requests, all of the packet latency is directly exposed as stall-time to the processor. Consequently, each packet is stall-time critical to the application execution time. Figure 3(b), on the other hand, shows an application with a high degree of MLP (e.g. Gems). It sends bursts of concurrent packets to the network. Much of the packet latency for this application is overlapped with other packets. Hence, the application stalls for much fewer cycles per packet (e.g. stall cycles of packet C is zero because it is delivered long before it is needed by the processor). Thus, on an average, a packet of the second application (Gems) is less stall-time critical than a packet of the ﬁrst application (libquantum). Consider a scenario when we run Gems and libquantum together on a shared multi-core system. The packet latencies for all applications will increase considerably due to contention in the network, shared caches, and main memory. However, the increase in latency is likely to have a worse impact on libquantum than Gems, because each packet of the former is more critical than that of the latter. Thus, in a shared system it makes sense to prioritize packA Packet A Latency A A B Packet B Latency B B C Packet C Latency C C Compute Blocks Stall Blocks A B Packet A Latency Packet B Latency Packet C Latency STALL of Packet C = 0 BA C A BC (a) (b) Figure 3: Execution timeline for: (a) an application with few packets, which do not overlap with each other, hence the packet latency is completely exposed to the processor as stall cycles, making each packet critical to the processor. (b) an application with packets that overlap with each other, hence some of the packet latency is hidden from the processor, accruing fewer stall cycles per packet. The packets are thus less critical. Light Application Heavy Application (a)   (b) 200 Stall Cycles 50 Instructions /50 Cycles 200 Instructions /200 Cycles 200 Stall Cycles 100 Stall Cycles Saved  cycles 200 Instructions /200 Cycles 50 Instructions /50 Cycles 300 Stall Cycles 200 Stall Cycles Light    IPC = 1000/(1000+1000) = 0.5 Heavy  IPC = 400/(400+1600)  = 0.2 Light    IPC = 1000/(1000+500) = 0.67 Heavy  IPC = 400/(400+2100)  = 0.16 Figure 4: The left ﬁgure (a) shows execution timeline of two applications: a light application and a heavy application. The right ﬁgure (b) shows the potential savings with shortest-job-ﬁrst scheduling of the two applications within the network. Figure 4(a) illustrates this concept by showing the execution timelines of two applications. The light application has compute blocks of 200 instructions/200 cycles and stall blocks of 200 cycles. The heavy application has compute blocks of 50 instructions/50 cycles and stall blocks of 200 cycles (hence, 4x the injection rate of the ﬁrst). Assume that the network prioritizes the lighter application (the striped packets in the network), and as a result each of its packets takes 100 cycles less, whereas each of the heavy application’s contending packets takes equally (100 cycles) more, as shown in Figure 4(b). At the application level, this prioritization results in a signiﬁcantly higher IPC throughput gain for the light application than the IPC throughput loss for the heavy application. As a result, overall system throughput improves by 18.6%/21.4% (as measured respectively by average IPC and total number of instructions completed in the a ﬁxed number of cycles). This example shows that prioritizing light applications (i.e. “shorter jobs”) within the network leads to better overall system performance by prioritizing applications that are likely to beneﬁt more from faster network service in terms of application-level throughput (i.e. IPC). 282     4. Application-Aware Prioritization Substrate 4.1 Overview Our goal is to improve application-level throughput by prioritizing packets belonging to stall-time critical applications over others in the network-on-chip. To enable this prioritization, we use two principles: application ranking and packet batching. Application Ranking: In order to prioritize stall-time-critical applications, a central decision logic periodically forms a “ranking,” i.e. an ordering of all applications. This ranking is determined using heuristics that capture the stall-time criticality of each application. We describe speciﬁc heuristics for maximizing overall system performance and enforcing system-level application priorities in Section 4.2. Once determined, ranks are then communicated to the routers. Routers use this ranking to determine which application’s packets are prioritized at any given cycle in a router. Packet Batching: Clearly, always prioritizing high-ranked applications can cause starvation to low-ranked applications. To prevent starvation, we propose using the concept of batching. Network packets are grouped into ﬁnite-size batches. A packet belonging to an older batch is always prioritized over a packet in a younger batch. As a result, reordering of packets across batches is not possible within a router. A batch also provides a convenient granularity in which the ranking of the applications is enforced. Several batching schemes are possible, and we describe the most effective ones we found in Section 4.3. 4.2 Ranking Framework The goal of ranking is to enable the differentiation of applications within the network based on their characteristics. There are three important issues related to the ranking framework: 1) how to determine relative ranking of applications, 2) how frequently to recompute the ranking (i.e., the ranking interval size), and 3) how many ranking levels to support. How to determine application ranking? In order to determine a good ranking, we need to estimate the stall-time-criticality (STC) of each application. We have explored a large number of heuristics to estimate the STC of applications. We describe the three bestperforming heuristics below, along with their advantages and disadvantages. Note that each of the metrics used by these heuristics is computed over a time interval (called ranking interval) and the computed values are used to determine application rankings in the next interval. 1. Private cache misses per instruction (MPI): This heuristic ranks an application with a smaller number of L1 cache misses per instruction higher. The insight is twofolds: an application with a small number of L1 misses is 1) likely to issue requests relatively infrequently and hence prioritizing this application’s requests allows the application’s core to make fast progress without needing to wait for the network, and 2) likely to have low MLP and hence its requests are likely to be stall-time critical. This heuristic is not affected by system state or network characteristics such as which other applications are running on the system or the arbitration policy used within the routers. Therefore, it provides an easy-to-compute, accurate and stable characterization of the application’s network demand. 2. Average number of outstanding L1 misses in Miss Request Queues (ReqQueue): The average number of outstanding L1 misses in the MSHRs [15] (i.e., miss request queues) of a core is indicative of 1) the overlap among memory accesses and hence the MLP of the application running on the core, and 2) the intensity of the application from the network perspective. The lower the number of outstanding misses in MSHRs for an application, the lower that application’s MLP and the smaller its instantaneous demand from the network, and hence the higher its stall-time criticality. Using these observations, this heuristic ranks an application with a smaller average number of outstanding L1 misses higher. In contrast to MPI, the ReqQueue heuristic is affected by the system state as well as the behavior of the network. It is important to be aware that this can have detrimental feedback effects: applications with higher number of L2 requests in their local queues (MSHRs) will get de-prioritized (since each request is considered less stalltime-critical). This causes these applications’ queues to become longer, which in turn results in the applications to be assigned even lower ranks during the next ranking interval. In addition, we experimentally observe that the ReqQueue-based STC estimates are less stable than MPI-based estimates, ﬂuctuating frequently across ranking intervals because the absolute number of outstanding L1 misses varies widely at any instant during the execution of an application even though L1 MPI can be relatively constant in a given phase. 3. Average stall cycles per packet (ASCP): This heuristic computes for each application the average number of cycles the application cannot commit instructions due to an outstanding packet that is being serviced by the network. Intuitively, ASCP is a direct indication of the network stall-time-criticality for the application. Therefore, the heuristic ranks the application with the largest ASCP the highest. Unfortunately, ASCP suffers from the same disadvantages as ReqQueue: the number of stall cycles a packet experiences is heavily inﬂuenced by 1) how much contention there is in the on-chip network, which depends on what other applications are concurrently running, and 2) the prioritization/arbitration policies used within the network. As such, the value of ASCP can ﬂuctuate and is not fully indicative of an application’s stall-time criticality in the network. Supporting the above expected disadvantages, our evaluations in Section 8.5 show that the ﬁrst heuristic, MPI, provides the best performance on average. Therefore, we use MPI as our default ranking heuristic. Enforcing system-level priorities in the network via OS-determined application ranking: So far, we have discussed the use of the ranking substrate as a mechanism to improve system performance by ranking applications based on stall-time-criticality. We implicitly assumed that all applications have equal system-level priority. In a real system, the system software (the OS or VM monitor) may want to assign priorities (or, weights) to applications in order to convey that some applications are more/less important than others. We seamlessly modify the ranking scheme in our technique to incorporate system-assigned application weights. The system software converts the weight of applications to a ranking of applications, and conveys the rank assigned to each application to our mechanism via privileged instructions added to the ISA. This system-softwareconﬁgurable ranking scheme allows system-level priorities to be enforced in the network, a functionality that does not exist in existing, application-oblivious prioritization mechanisms. Section 8.9 quantitatively evaluates and shows the effectiveness of this system-level priority enforcement. How frequently to recompute ranking? Application behavior (and hence, network-related stall-time criticality) varies considerably over execution time [24]. Therefore, application ranking should be recomputed periodically to adapt to ﬁne-grained phase changes within application behavior. To accomplish this, our mechanism divides the execution time into ﬁxed time intervals (called ranking intervals), and re-computes the ranking at the beginning of each time interval. Intuitively, too large a ranking interval could miss changes in the phase behavior of applications and might continue to enforce a stale ranking that no longer optimizes system performance. On the other hand, too small a ranking interval could lead to high ﬂuctuations in ranking. This can cause the rank of an application to change while many packets tagged with the application’s previouslycomputed rank(s) are in the network, which has a negative effect on system throughput. The ranking interval can either be a static system parameter or can be computed adaptively at run-time. An adaptive 283 ranking interval might capture phase changes more accurately, and is likely to give superior performance than a static ranking interval, but it is more complex to implement. In this work, we use an empiricallydetermined static ranking interval for lower complexity. The number of ranking priority levels R: Ideally, we would like to have as many ranking priority levels as applications (e.g., N=64 in a 64 core CMP), as this allows the network to distinguish between applications in a ﬁne-grained manner. Speciﬁcally, each application can (if desired) be assigned a unique rank. In practice, however, the number of ranking levels may have to be constrained, especially in many-core systems consisting of large on-chip networks, because it negatively affects 1) ﬂit and ﬂit buffer sizes (as each ﬂit needs to carry an encoded ranking with it) and 2) arbitration logic complexity and latency in the router (routers need to compare the encoded ranking of each ﬂit to determine which one is of higher priority). In addition, in many cases it may not be desirable to assign different ranks to different applications, for example, if the applications have similar characteristics. For these reasons, we use fewer ranking levels than the number of applications, which imposes a partial rank order among applications by creating rank-equivalence classes.2 4.3 Batching Framework In order to prevent starvation, we combine application-aware prioritization with a “batching” mechanism. Each packet is added to a batch depending on its time of arrival; and packets belonging to older batches are prioritized over packets from younger batches. Only if two packets belong to the same batch, they are prioritized based on their applications’ rank order as described in the previous section. There are four important issues related to the batching substrate: 1) how to group packets into different batches, 2) how to prioritize among different batch numbers, 3) how frequently to group packets into batches (i.e., the batching interval size), and 4) how many batching levels to support. How to group packets into batches? We consider two ways in which routers form batches in a coordinated fashion: 1. Time-Based (TB) Batching: In TB-batching, new batches are formed in a periodic, synchronous manner across all nodes in the network. All packets injected into the network (regardless of the source) during a T cycle interval (called batching interval) are grouped into the same batch. At the end of a batching interval, a new batch is started—all newly arriving packets are added to a new batch. Thus, packets injected in the ﬁrst T cycles are assigned batch number 0, those injected during the next T cycles are assigned batch number 1, and so on. Assuming that the clocks of different nodes are synchronized, the same batch number is assigned by different nodes to packets injected in the same clock cycle. Hence, there is no need for global coordination or communication between routers for batch formation. TB-batching is our default batching policy. 2. Packet-Based (PB) Batching: Instead of starting a new batch based on a pre-determined, ﬁxed time-interval, PB-batching starts a new batch whenever a certain number N packets have been injected into the current batch. That is, with PB-batching, the ﬁrst N injected packets are assigned the batch number 0, the next N packets the batch number 1, and so on. Since the number of packets injected in each node is different, but batches are formed globally across all nodes, this scheme requires coordination among routers to keep the current batch number synchronized across all nodes. Each router communicates the number of newly injected packets (in the current batch) to a centralized decision logic, which keeps track of the total number of injected packets in this batch. Once N new packets have been injected, the centralized decision logic notiﬁes the network routers to increment their batch IDs. As such, the hardware complexity of this mechanism is higher than TB-batching. In both TB- and PB-batching, batch IDs start at 0 and are incremented at the end of every batching interval. After reaching the maximum supported batching level B , a batch number wrap-around occurs and the next batch number restarts from 0. Youngest Batch Youngest Batch Youngest Batch 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 Oldest Batch Oldest Batch Oldest Batch Figure 5: The concept of batch number wrap-around (a) Initial snapshot (b) Intermediate snapshot (c) Snapshot after wrap-around How to prioritize across batches? Clearly, due to batch number wrap-around, the router cannot simply prioritize packets with lower batch numbers over others with higher batch numbers (see Figure 5). Instead, each router prioritizes packets based on relative order of their batch numbers. This relative order can easily be computed locally in the router using the current batch-ID and the packet’s batchID. Speciﬁcally, if B ID is the current injection batch-ID and P ID is the packet’s batch ID, a router can compute a packet’s relative batch priority (RBP) as RBP = (B ID − P ID) modulo B . The packet with higher RBP is prioritized by the router. Note that priority inversion does not occur unless the number of batches present in the network exceeds the number of supported batching levels. By selecting a sufﬁciently large value for B , this can be easily ensured. How frequently to group packets into batches? The size of the batching interval determines for how long some applications are prioritized over others (assuming rankings do not change). In general, the shorter the batching interval, the lower the possible starvation of lower-ranked applications but also the smaller the system-level throughput improvements due to the prioritization of higher-ranked applications. Hence, the choice of batching interval determines the trade-off between system performance and fairness, and can be tuned to accomplish system requirements. Note that the batching interval size can be made conﬁgurable by the operating system to dynamically trade-off between system performance and fairness. How many batching levels B to support? As the number of supported batching levels B increases, the probability of priority inversion among batches decreases, but the ﬂit size and router arbitration latency/complexity increases. Hence, B (in combination with the batching interval) should be chosen large enough to ensure that the number of incomplete batches never exceeds B . Based on our empirically determined batching interval size, we empirically set B = 8 in our evaluated system. 4.4 Putting It All Together: Application-Aware Prioritization Rules in a Router Rule 1 summarizes the prioritization order applied by each router in order to enable application-aware prioritization. Each router prioritizes packets/ﬂits in the speciﬁed order when making packet scheduling, arbitration, and buffer allocation decisions. Rule 1 Packet/ﬂit prioritization rules in each router 1: Oldest Batch First: Packets belonging to older batches are prioritized over packets belonging to younger batches (the goal is to avoid starvation). 2: Highest Rank First: Packets with higher rank values (belonging to higher-ranked applications) are prioritized over packets with lower rank values (the goal is to maximize system performance) 3: Local Router Rule: If the above two rules do not distinguish the packets, then use the local policy at the router, e.g. LocalAge or LocalRR. Our default policy is LocalAge, but LocalRR performs very similarly (see Section 8.7). 2We have determined that 8 ranking priority levels does not add signiﬁcant overhead to the router complexity, while providing sufﬁcient granularity to distinguish between applications with different characteristics, so we set R=8 (see Section 6). 5. Comparison with Existing Policies Local, Application-Oblivious Policies: We demonstrate the difference between application-oblivious policies and our mechanism 284 Applications A : Heavy B: Bursty  C: Sensitive(Critical) I c e n j i t n o C s e c y l A5 A4 A8 A7 A6 A2 A1 A3 B1 B2 C1 Batch 0 Batch 1 Batch 2 0 1 2 3 5 6 4 7 Batch Interval = 3 cycles Increasing Rank (A lowest, B medium, C highest) A5 A4 B1 A8 A7 A6 A2 A1 A3 C1 B2 A5 A4 B2 A3 A2 B1 A1 C1 A8 A7 A6 STC Scheduling Router A5 A4 B2 A3 A2 B1 A1 C1 A8 A7 A6 LocalRR Scheduling Appl ication A S tall Cyc les 11 B 6 C 8 Avg 8.3 Applicat ion A S tall Cy c les 11 B 6 C 4 Avg 7.0 Batch 0 Batch 1 *RR within batch local policy Application A S tall Cyc les 11 B 3 C 1 Avg 5.0 Routing  Computation  (RC) VC Arbiter (VA) Switch Arbiter  (SA) A5 A4 B2 A3 A2 B1 A1 C1 A8 A7 A6 LocalAge Scheduling VC0 VC7 Batch 2 Figure 6: Example: (a) Injection order at cores (b) Scheduling order and timeline at a router for different policies (STC) with a simpliﬁed example. This example abstracts away many details of the network and focuses on a single router, to simplify explanations and to provide insight. The example shows that our mechanism signiﬁcantly reduces average stall time of applications within a single router compared to application-oblivious local policies. As our mechanism ensures that all routers prioritize applications in the same order, stall time reductions in each router are preserved across the entire NoC, thereby leading to an increase in overall system performance. Consider an application mix of three applications: 1) A, a networkintensive application which injects packets at a steady rate, 2) B, a bursty application, and 3) C, a light, stall-time-critical application that infrequently injects packets. Figure 6(a) shows all the packets injected by each of these applications at their cores. To simplify the example, suppose that all these packets happen to arrive at the same router. Figure 6(b) shows this router in the network, where all injected packets are buffered. We examine the amount of time the router takes to service all packets of each application using three prioritization schemes: 1) LocalRR, 2) LocalAge, and 3) STC. The timelines in Figure 6(b) show for each scheme the service order of the packets in the router, the time it takes to service each application (i.e., each application’s stall-time in this router), and the average time it takes to service all applications (i.e,. the average stall-time within this router).3 LocalRR services each VC in round-robin order in consecutive cycles and results in the topmost scheduling order. This order is completely application agnostic. It picks C’s only packet (C1) after all other virtual channels are serviced since C1 occupies the last VC. Hence, LocalRR results in 8 stall cycles for the critical application C (11 cycles for A, 6 cycles for B). The average application stall time for LocalRR is 8.33 cycles. LocalAge prioritizes the packets in oldest-ﬁrst order (and uses LocalRR policy for equal-age packets). C1 is scheduled in the 4th cycle since it is one of the oldest packets. Thus, LocalAge improves the stall cycles of C by 2 cycles over LocalRR, thereby reducing average application stall time in this router to 7 cycles. Note, however, that LocalAge would have increased the average stall time had C1 been injected into the network much later than shown in this example. The key observation is that the oldest packet in the network is not necessarily the most critical packet. Even though A1 is the oldest packet in the network and it is scheduled ﬁrst, it is not critical and its early scheduling does not help average stall time of applications. Our mechanism, STC, ranks C higher than B, and B higher than A based on the MPI of each application. The router schedules the packets of applications in rank order. C1 is scheduled in the ﬁrst cycle, which reduces C’s stall time to 1 cycle; and B’s packets are 3 For the purposes of this example, we make the simplifying assumption that an application stalls until all of its network packets are serviced, which is shown to be a reasonable assumption for long-latency cache misses [18]. scheduled next, which reduces B’s stall time to 3 cycles. Application A still stalls for the same amount of time because its last packet is serviced after 11 cycles. The average stall time reduces to 5 cycles, improving by 28% compared to the best previous local policy. The example shows that unlike application-oblivious prioritization policies, STC can effectively prioritize critical applications that beneﬁt the most from prioritization, and can therefore improve overall system performance. Globally Synchronized Frames (GSF): GSF [17] provides prioritization mechanisms within the network to ensure 1) guarantees on minimum bandwidth and minimum network delay each application experiences and 2) each application achieves equal network throughput. To accomplish this, GSF employs the notion of frames, which is similar to our concept of batches. Time is quantized into equalsize frames (which are of limited number). Each source node (application) can inject an equal –yet limited– number of packets into a frame. Once an application ﬁlls its quota in a frame, it injects packets into the next frame. If an application runs out of the maximum number of supported frames to inject to (usually the case with very network intensive applications), it stalls until the oldest frame gets recycled. Each packet carries its frame number in the network. In the routers, packets belonging to the older frames are prioritized over others. Among packets belonging to the same frame, there is no prioritization based on sources, hence, there is no prioritization based on the application a packet belongs to. Even though the concept of batching is similar to the concept of frames, our mechanism has several key differences from GSF. While the purpose of GSF is to provide bandwidth-fairness and guarantee a minimum level of bandwidth to each application, the purpose of STC is to improve system-level throughput within the network by prioritizing packets in an application-aware manner. There are four major advantages of our proposal compared to GSF: 1. Application-aware prioritization within batches: GSF does not employ any application-aware (or coordinated) prioritization in routers among packets belonging to the same frame. As a result, applications with non-critical packets can be prioritized over applications with critical packets. In contrast, STC employs criticalityaware ranking within each batch, enabling the fast servicing of critical packets over others. Hence, STC signiﬁcantly improves system performance over GSF (see Section 8). 2. No quota per application: GSF imposes a quota on the number of packets each application can inject into a given frame (to ensure equal bandwidth across ﬂows). However, this requirement can cause signiﬁcant degradation in application-level throughput, especially when applications have largely different network intensity. Consider the case when a very network-intensive application is sharing the network with a bursty application. GSF divides each frame equally between them. The intensive application can inject only half of the packets within a frame, while bursty application might not in285   ject any packets. Due to the limited number of available frames, the intensive application soon runs out of frames and stops injecting. As a result, the network becomes under-utilized even though half of every frame was not used at all. In fact, the intensive application is penalized even though the light application is not using any network bandwidth. In contrast to GSF, STC does not impose any quota on the number of packets injected into a batch by any application. Due to this, the probability of the system running out of batches is significantly smaller than in GSF. In the rare case when all batch numbers are exhausted, STC suffers from temporary priority inversion instead of stopping some applications from injecting. As a result, STC’s application-level throughput is higher than GSF, especially with heterogeneous mixes of applications. 3. No reserved buffer slots: To provide tight latency guarantees and reduce frame completion time, GSF reserves a VC per port for the oldest frame. The reserved VC cannot be utilized by any other frame, even if the VC is empty. This reduces system throughput compared to our scheme, which does not require the reservation of any buffer slots. 4. No global synchronization on the critical path of execution: When the oldest frame completes in GSF, routers need to synchronize to update their local copies of the oldest frame number. This synchronization latency is on the critical path of execution in GSF due to two reasons: 1) the reserved VC goes unutilized and 2) an application that has run out of frames cannot start injection until this synchronization completes. In contrast, we do not use any global barrier network for synchronization, since we do not reserve any buffer for the oldest batch. Also, rank/batch formation updates are not on the critical path of execution in STC, because the routers are never prevented from injecting into the network and are allowed to use stale values for ranking. The major advantage of GSF over STC is that it can provide hard bandwidth and latency guarantees to applications, at the expense of system-level throughput. STC does not provide any bandwidth or latency guarantees to applications; however, it uses batching to ensure a level of fairness. While hard guarantees are likely to be useful for real-time systems, high system throughput combined with high fairness and the ability to enforce system-level application priorities could be sufﬁcient in general-purpose many-core systems. Hence, STC takes advantage of the relaxed constraints of general-purpose systems to improve system performance without degrading fairness. 6. Implementation We use a central decision logic (CDL) that periodically gathers information from each node, determines a global application ranking and batch boundaries (for packet-based batching), and communicates the batch number and the node’s rank back to each node. We assume the CDL hardware is located in the central node (i.e. (4,4) coordinate in an 8x8 mesh) of the NoC. Rank Formation: Each core maintains a “rank-register” that contains the rank of the application running on this core. A new rank is computed at the end of every ranking interval. For this purpose, each processing core has additional logic and a set of hardware counters to measure the ranking metric (e.g., MPI) value that will be used by the CDL to compute rank of the nodes.4 The counters are reset at the beginning of each ranking interval. At the end of the ranking interval, each core forms a rank-control information packet (RCIP) containing the ranking metric value(s) measured during that interval.5 Each core then sends its RCIP packet to the CDL. Upon receiving all RCIP packets, the CDL computes the ranking among applications (see Section 4.2). In our implementation, there are N = 64 processors, but 4MPI ranking heuristic uses only two 16 bit registers, one for L1 misses and one for number of retired instructions. 5 To bound the number of bits in RCIP to one ﬂit size, all counters are scaled down. We divide all counters by 32, a value analytically determined assuming maximum bounds on ranking interval and L1 MPI. only R = 8 ranking levels. We use the standard k-means clustering algorithm [12] with four iterations (O(4 ∗ R ∗ N ) operations) to map the N processors to the R ranks. The CDL then sends the rank to each processing core using a rank-control update packet (RCUP), and upon receipt of this packet, a core updates its rank-register with the new rank. Note that the rank formation process is not on the critical path because the ranking interval is signiﬁcantly larger than the time needed to compute a new ranking. Until a new ranking is received, each core simply uses the old ranking. Batch Formation: Each node keeps a local copy of the Batch ID (BID) register containing the current (injection) batch number and maximum supported batch ID (MBID) register containing the maximum number of batching priority levels. Note that BID values across all nodes are the same. For Time-Based Batching, BID is simply incremented every T cycles. For Packet-Based Batching, BID is updated after every P packets that have been injected across all nodes. As this requires coordination among nodes, we use CDL for BID updates in this case. Each node periodically (every U = 4000 cycles6 ) sends a batch-control information packet (BCIP) to CDL. BCIP contains the number of packets that the router injected in the last U cycles. The CDL has a global packet counter register, which is incremented by BCIP data bits. When the CDL’s counter reaches or exceeds P packets, CDL sends out a batch control update packet (BCUP) to each router. Upon receiving a BCUP packet, each router increments its BID. All control packets (BCIP, BCUP, RCUP) are very short (few bits of data) and sent infrequently, thus adding negligible load to the network and not hurting performance. Finally, note that BCIP and BCUP packets are needed only for PB-batching, not for our default TB-batching. Priority Assignment and Enforcement: Before a packet is injected, a router tags it with a priority level using the rank and BID registers (3 bits each in our implementation). At each router, the priority bits in the ﬂit header are utilized by the priority arbiters to allocate VCs and the switch. Each priority arbiter must support at least 6 bits of priority. Fast priority arbiters can be designed using high speed adders as comparators within the arbiters. We use adder delays in [23] to estimate the delay of an 8-bit priority arbiter (P = 5,V = 6) to be 138.9 picoseconds and the delay of an 16-bit priority arbiter to be 186.9 ps at 45nm technology. 7. Methodology 7.1 Experimental Setup We evaluate our techniques using a trace-driven, cycle-accurate x86 CMP simulator. Table 1 provides the conﬁguration of our baseline, which contains 64 cores in a 2D, 8x8 mesh NoC. The memory hierarchy uses a two-level directory-based MESI cache coherence protocol. Each core has private write-back L1 caches. The network connects the cores, L2 cache banks, and memory controllers. Each router uses a state-of-the-art two-stage microarchitecture. We use the deterministic X-Y routing algorithm, ﬁnite input buffering, wormhole switching, and virtual-channel ﬂow control. We faithfully model all implementation details of the proposed prioritization framework (STC) as well as previously proposed GSF, LocalAge and LocalRR. The parameters used for GSF are: 1) active window size W = 6, 2) synchronization penalty S = 16 cycles, 3) frame size F = 1000 ﬂits. The default parameters used for STC are: 1) ranking levels R = 8, 2) batching levels B = 8, 3) ranking interval = 350,000 cycles, 4) batching interval = 16,000 cycles, 5) BCIP packet sent every U = 4000 cycles. We model all extra control packet trafﬁc. Section 8 evaluates important parameter sensitivity. 7.2 Evaluation Metrics We evaluate our proposal using several metrics. We measure application-level system performance in terms of weighted and 6 This value is determined empirically to balance the overhead of BCIP packets and batching interval. 286 Processor Pipeline Fetch/Exec/Commit width L1 Caches L2 Caches Main Memory Network Router Network Topology 2 GHz processor, 128-entry instruction window 2 instructions per cycle in each core; only 1 can be a memory operation 32 KB per-core (private), 4-way set associative, 128B block size, 2-cycle latency, write-back, split I/D caches, 32 MSHRs 1MB banks, shared, 16-way set associative, 128B block size, 6-cycle bank latency, 32 MSHRs 4GB DRAM, up to 16 outstanding requests for each processor, 320 cycle access, 4 on-chip Memory Controllers. 2-stage wormhole switched, virtual channel ﬂow control, 6 VC’s per Port, 5 ﬂit buffer depth, 8 ﬂits per Data Packet, 1 ﬂit per address packet. 8x8 mesh, each node has a router, processor, private L1 cache, shared L2 cache bank (all nodes) 4 Memory controllers (1 in each corner node), 128 bit bi-directional links. Table 1: Baseline Processor, Cache, Memory, and Network Conﬁguration # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Benchmark wrf applu perlbench dealII sjeng namd gromacs calculix gcc h264ref povray tonto barnes art gobmk astar ocean hmmer NST/packet 7.75 16.30 8.54 5.31 8.35 4.59 5.19 7.10 2.14 12.41 2.07 3.35 7.58 42.26 4.97 6.73 9.21 6.54 Inj Rate 0.07% 0.09% 0.09% 0.31% 0.37% 0.65% 0.67% 0.73% 0.89% 0.96% 1.06% 1.18% 1.24% 1.58% 1.62% 2.01% 2.03% 2.12% Load low low low low low low low low low low low low low low low low low high NSTP low high high low high low low low low high low low low high low low high low Bursty low low low high low high high low high high high high high low high low high high # Benchmark 19 sjbb 20 libquantum 21 bzip2 22 sphinx3 23 milc 24 sap 25 sjas 26 xalancbmk 27 lbm 28 tpcw 29 leslie3d 30 omnetpp 31 swim 32 cactusADM 33 soplex 34 GemsFDTD 35 mcf NST/packet 8.92 12.35 5.00 8.02 14.73 4.84 5.15 15.72 8.71 5.64 5.78 2.92 10.13 8.30 8.66 4.82 5.53 Inj Rate Load 2.20% high 2.49% high 3.28% high 3.64% high 3.73% high 4.09% high 4.18% high 4.83% high 5.18% high 5.62% high 5.66% high 5.72% high 6.06% high 6.28% high 6.33% high 11.95% high 19.08% high NSTP high high low high high low low high high low low low high high high low low Bursty high low high high low high high low high high low low low low low low low Table 2: Application Characteristics. NST/packet: Average network stall-time per packet, Inj Rate: Average packets per 100 Instructions, Load: low/high depending on injection rate, Network Stall Cycles per Packet (NSTP): high/low, Bursty: high/low. harmonic speedup [8], two commonly used multi-program performance metrics based on comparing the IPC of an application when it is run alone versus when it is run together with others. Hmeanspeedup balances performance and fairness. W. Speedup = X I P C shared i I P C alone i i , H. Speedup = N umT hreads 1 IP C shared i /IP Calone i Pi Network stall cycles (NST) is the number of cycles the processor stalls waiting for a network packet [19]. To isolate effects of only the on-chip network, NST does not include the stall cycles due to off-chip DRAM access or on-chip cache access. We deﬁne network-related slowdown of an application as the network-stall time when running in a shared environment (N ST shared ), divided by, network-stall time when running alone (N ST alone ) on the same system. The application-level network unfairness of the system is the maximum network-related slowdown observed in the system: N etS lowdowni = , U nf airness = max i N etS lowdowni N ST shared i N ST alone i 7.3 Application Characteristics We use a diverse set of multiprogrammed application workloads comprising scientiﬁc, commercial, and desktop applications. We use the SPEC CPU2006 benchmarks, applications from SPLASH-2 and SpecOMP benchmark suites, and four commercial workloads traces (sap, tpcc, sjbb, sjas). In total, we study 35 applications. We choose representative execution phases using PinPoints [24] for all our workloads excluding commercial traces, which were collected over Intel servers. In order to have tractable simulation time, we choose a smaller representative window of instructions (5 million per application), obtained by proﬁling each application. All our experiments study multi-programmed workloads, where each core runs a separate application. We simulate at least 320 million instructions across 64 processors. Table 2 characterizes our applications. The reported parameters are for the applications running alone on the baseline CMP system without any interference. We categorize applications into three groups based on their network characteristics: applications with 1) high/low load are called heavy/light, 2) high Network Stall Cycles per Request Packet (NSTP) are called sensitive, and 3) bursty injection patterns are called bursty. Our aggregate results are based on 96 different workload combinations. 8. Performance Evaluation We ﬁrst compare our base approach (STC-MPI ranking with TBbatching) to three existing packet prioritization schemes: 1) local round-robin arbitration (LocalRR), 2) age-based arbitration (LocalAge) and 3) globally synchronized frames (GSF), using three case studies to provide insight into the behavior of each scheme with different types of workloads. Figure 7 shows the network slowdowns (the lower the better) of the individual applications. Figures 8 (a) and (b) show the system performance (weighted speedup7 and harmonic speedup) of the four schemes for different case studies. Section 8.4 reports aggregate results averaged over 96 different workloads, showing that the beneﬁts of our scheme hold over a wide variety of workloads. 8.1 Case Study I: Heavy applications mixed with network-sensitive applications We mix 16 copies each of two heavy applications (cactus and lbm) and two network-sensitive applications (art and libquantum). The following observations are in order: • The baseline LocalRR policy slows down all applications other than art, which has very high NST/packet when run alone (the potential negative impact of interference in the network is lower for art than for other applications). LocalRR slows down other applications in hard-to-predict ways as round-robin port allocation is application-oblivious. • LocalAge policy signiﬁcantly reduces the network slowdown of the heaviest application (cactus) compared to LocalRR, while increasing the slowdowns of all other applications. LocalAge implicitly prioritizes heavier applications because older packets in the network are more likely to be from the heavier applications. Overall, LocalAge reduces performance by 5.9%/3.8% (weighted/harmonic 7Weighted speedup is divided by number of cores (=64) for clarity. 287 9 8 7 6 5 4 3 2 1 0 LocalRR LocalAge GSF STC N e t w o r k S l o w o d w s n art libquantum cactus lbm 0 2 4 6 8 10 12 LocalRR LocalAge GSF STC N e t w o r k S l o w o d w s n astar barnes Gems mcf 10 9 8 7 6 5 4 3 2 1 0 LocalRR LocalAge GSF STC N e t w o r k S l o w o d w s n xalan sphinx cactus sjas Figure 7: Network slowdown of applications: (a) Case Study I (b) Case Study II (c) Case Study III 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 case1 case2 case3 Avg W h g e i t d e S p u d e e p LocalRR LocalAge GSF STC 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 case1 case2 case3 Avg H a r m c n o i S p u d e e p LocalRR LocalAge GSF STC 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 weighted harmonic S p u d e e p LocalRR GSF LocalAge STC 0 2 4 6 8 10 airthmetic  mean harmonic  mean U n f a i r s s e n LocalRR GSF LocalAge STC Figure 8: System performance results: (a) Weighted speedup of case studies (b) Harmonic speedup of case studies (c) Aggregate Speedup for 96 workloads and (d) Aggregate Unfairness for 96 workloads speedup) over LocalRR as it delays light applications in the network. These applications could have made fast progress had their packets been quickly serviced. Hence, implicitly prioritizing network-heavy applications in the network leads to a loss of system throughput, motivating the need for better prioritization mechanisms. On the other hand, LocalAge is a fair policy, leading to the smallest maximum network slowdown: the heaviest application has the highest network slowdown in LocalRR (because it gets delayed signiﬁcantly by other copies of cactus running on the system) and LocalAge reduces this maximum slowdown by implicitly prioritizing the heavy application. • GSF unfairly penalizes the heavy applications, as explained in Section 5, because they quickly run out of frames and stop injecting. Thus, the network slowdowns of cactus and lbm increase by 1.6X and 2.4X over LocalRR. Since GSF guarantees minimum bandwidth to all applications, it improves the network slowdown of networksensitive applications over both of the local policies (by 24.2% for art and 22.3% for libquantum over LocalRR) by ensuring that heavier applications do not deny service to the lighter applications. However, GSF does not prioritize any application within a frame, thus there is scope for further reducing the slowdowns of networksensitive applications. Overall, GSF signiﬁcantly degrades system throughput (by 16.6% over LocalRR) and application-level fairness (by 1.8X over LocalRR) because it unfairly penalizes the heavy applications, causing their cores to make very slow progress, thereby reducing system utilization. • STC prioritizes the network-sensitive applications using ranking, and ensures, using batching, that the heavy applications are not overly penalized. The result is that it signiﬁcantly reduces the slowdown of network-sensitive applications as their packets’ prioritization reduces their network stall cycles per packet (NSTP), e.g. art’s NSTP reduces from 219.5 cycles (LocalRR) to 99.8. STC slightly degrades the network slowdown of the heavy applications (by 6.2%/9.4% over LocalAge). This increase is small for two reasons: 1) batching prevents the starvation of heavy applications, 2) heavy applications are more latency tolerant due to the lower stall-time criticality of their requests: for example, compared to the NSTP of art (219.5 cycles), lbm’s NSTP is only 36.2 cycles. Overall, STC improves system throughput by 12.8%/8.2% (weighted/harmonic) over LocalRR and 19.8%/12.4% over LocalAge, because it enables network-sensitive applications to make faster progress without signiﬁcantly slowing down heavy applications that are slow to begin with. 8.2 Case Study II: Heavy applications mixed with light applications We run 16 copies each of two heavy applications (Gems and mcf) with 16 copies each of two light applications (astar and barnes). The purpose is to show the behavior of STC when network-intensive applications are run together with compute-intensive applications, a likely scenario in future multi-core systems. We make the following key observations: • LocalRR’s network slowdowns are in general higher than in Case Study I, since mcf and Gems are much heavier workloads than cactus and lbm, thus slowing down themselves (i.e. other copies of mcf and Gems) and other applications more. • The local policies and GSF show similar behavior compared to Case Study I. LocalRR is agnostic of applications, and hence, slows down different type of applications in difﬁcult-to-predict ways: astar (light) and mcf (heavy) experience the highest slowdowns. LocalAge implicitly prioritizes heavy applications as packets from those applications are likely to be older. As a result, LocalAge reduces system performance by 9.1% (weighted speedup) compared to LocalRR. In contrast, GSF has the opposite effect: it implicitly slows down heavy applications, reducing both system performance (by 10.6% over LocalRR) and fairness (by 1.5X over LocalRR). Hence, we conclude that neither LocalAge nor GSF work well with a heterogeneous mix of applications as they tend to implicitly penalize light or heavy applications respectively, which leads to reduced overall system utilization. • STC provides large system throughput improvements over all previous schemes by prioritizing light applications over heavy applications. Overall, STC’s system performance improvement is 29.5% over LocalAge and 21.7% over LocalRR. STC greatly reduces the packet-latency/NSTP of the lighter applications (from 112.8/109.8 cycles with LocalAge to 41.9/38.4 for barnes) while only slightly increasing the packet-latency/NSTP of heavy applications (from 119.7/27.0 cycles to 123.4/29.4 for Gems). As a result, average stalltime of the applications in the network reduces, leading to the observed system throughput improvements. As batching ensures that no application’s packets are delayed indeﬁnitely, STC also provides the best fairness. We conclude that STC can provide both the best system throughput and system fairness when a set of memory-intensive and compute-intensive applications are executed concurrently. 288                                       8.3 Case Study III: Mix of heavy applications We run 16 copies each of four heavy applications (xalan, sphinx, cactus, and sjas). The purpose of this case study is to show the dynamic behavior of STC: applications may have similar average behavior (e.g., all are heavy), but if their transient behaviors are sufﬁciently different, STC can still provide high performance gains. The following observations are in order: • sjas is extremely bursty, as shown in Figure 9(c). It is penalized severely by GSF during its ""heavy"" bursts by running out of frames and being throttled, causing GSF to lose throughput (Figure 8(a)) and fairness (Figure 7(c)). As in previous case studies, LocalAge slows down the applications with relatively low injection rates (sphinx and sjas). • The average injection rates (Figure 9(a)) of the four applications are similar: the ratio of the minimum and maximum injection rates in the mix is 1.6X (vs. 3.9X in Case Study II). The average L1 miss ratios (Figure 9(b)) of the four applications are also similar: the ratio of the minimum and maximum L1 miss rates in the mix is 1.9X (vs. 5.8X in Case Study I). One might, therefore, conclude that prioritizing lighter applications or those with lower MLP (i.e., ""critical applications"") might not be very advantageous. However, STC improves system throughput by 12.2% over LocalRR and 18.1% over LocalAge. This is because STC is able to adapt to the dynamic changes in the behavior of applications: even though average miss rates of applications are similar, each application’s instantaneous miss rate varies over time (Figure 9(c)). Because STC determines application priorities on an interval basis, it is able to adapt its prioritization to correctly identify the applications that beneﬁts from prioritization in each interval. For example, in Figure 9(c), during intervals 0-21, STC improves system throughput by prioritizing sphinx’s packets, whereas during intervals 40-60, STC similarly improves system throughput by prioritizing sjas’s packets. Hence, STC is able to identify and prioritize the lightest/critical application in a given interval, leading to improvements even when all applications seemingly have the same average behavior. 8.4 Overall Results Across 96 Multi-Programmed Workloads Figures 8 (c) and (d) compare the four prioritization techniques averaged across 96 workload mixes. 48 workloads have a mix with four applications (16 copies each) and 48 workloads have a mix with eight applications (8 copies each). Each set of 48 workloads is spread out across the design space: 16 workloads represent low network utilization (all applications are light), 16 workloads represent medium network utilization (half light, half heavy) and 16 workloads represent high network utilization (all heavy). Within each of the three categories, applications are randomly picked to form the 16 workloads. The aggregate results are consistent with the observations made in the three case studies. On average, STC improves system throughput by 9.1%/4.3% (weighted/harmonic) compared to the best previous scheme (LocalAge), while also improving network fairness by 5.7%. The highest performance improvement of our mechanism is 33.7%, the lowest -1.8% over the best existing prioritization policy. We conclude that STC provides the best system performance and network fairness over a very wide variety of workloads. 8.5 Effect of Ranking Heuristics Figures 10(a) and 11(a) show the effect of different ranking heuristics: ASCP, ReqQueue, and MPI (Section 4.2) and two further heuristics to provide comparison points, RoundRobin (assign ranks in a round-robin manner that changes every ranking-interval) and Random (assign ranks randomly every interval). First, all the heuristics perform better than or at least equivalent to LocalRR, LocalAge, and GSF. ASCP, which ranks the applications according to NST/packet, is the most inefﬁcient and unfair STC-aware heuristic. There are two reasons: 1) the positive feedback loop discussed in Section 4.2, which leads to some applications to be unfairly stuck in a low rank for a long period of time and 2) ASCP accelerates applications with higher stall-time per packet even if these applications are heavy. As we saw before, prioritizing a heavy application in the network slows down almost all other applications. MPI provides the best performance because it effectively prioritizes light applications over heavy ones from the perspective of the network. We conclude that prioritizing only ""light and stall-time-critical"" applications can be done effectively in the network without signiﬁcantly hurting other applications’ performance. Overall, MPI provides a good trade-off between performance, fairness, and implementation complexity. Finally, note that RoundRobin and Random ranking, which do not take into account application behavior in ranking, result in much lower system performance than other ranking techniques. This further indicates that MPI is effective in capturing applications’ network criticality and intensity. 8.6 Effect of Batching Policy Figures 10(b) and 11(b) show the effect of different batching policies, discussed in Section 4.3, as well as not using batching. Not using batching (rightmost bars) results in the lowest system performance because it starves low-ranked applications for long periods of time. Note that there is not a signiﬁcant performance or fairness difference between packet-based or time-based synchronized batching. Since time-based synchronized batching is simpler to implement, we conclude that synchronized time-based batching provides the best tradeoff between performance, fairness, and implementation complexity. 8.7 Effect of Local Arbitration Policy Figures 10(c) and 11(c) show the effect of different local arbitration policies used with our mechanism. The local arbitration policy is invoked only if the rank and batch numbers of two packets are equal (this is the ""Local Router Rule"" speciﬁed in Section 4.4). We compare three local polices 1) Age (packet-age based prioritization) 2) RoundRobin (RR; round-robin port prioritization) and 3) InstAge (a new policy where a packet is assigned the age, i.e. current time minus the fetch time, of the instruction it is initiated by). Overall, there is no single best policy in terms of performance, fairness, and implementation complexity. The Age policy is the fairest and provides slightly better performance than the other two. However, it is more complex to implement because it requires 1) the age of a ﬂit to be tracked in the network and 2) more complex arbitration logic to compare ﬂit ages. The RoundRobin policy, has the lowest implementation cost, but has slightly lower performance and is slightly more unfair than the other two. The InstAge policy is in-between in terms of performance, fairness, and complexity. We conclude that our proposal’s performance or fairness is not signiﬁcantly affected by the local arbitration policy of the routers. 8.8 Effect of Ranking and Batching Intervals The graphs in Figure 12 show the effect of different ranking and batching intervals on STC performance and fairness. Both intervals have a higher impact on fairness than performance. Figure 12 shows that: 1) performance is lower with smaller ranking intervals because highly ﬂuctuating ranks eliminate the beneﬁts of ranking, 2) unfairness increases for very large ranking intervals because it fails to adapt to changes in applications’ network intensity, thereby unfairly penalizing bursty applications. The two rightmost graphs in Figure 12 show that batching interval B determines the trade-off between fairness and performance. A smaller B leads to high fairness by reducing starvation to a minimum, especially for Case Study III, which contains applications with bursty behavior. On the other hand, a smaller B also leads to reduced system performance as the granularity at which higher-ranked applications are prioritized within the network (and hence system throughput maximized) becomes smaller. When B becomes too large, fairness starts to degrade since batching is essentially eliminated for long time periods. 289 0 10 20 30 40 50 60 70 Applications P e p s e k c a t r K l i o I s n r t c u i t s n o xalan sphinx cactus sjas 0 5 10 15 20 25 30 35 40 45 50 Applications 1 L m i s e s s e p r K l i o I s n r t c u i t s n o xalan sphinx cactus sjas 0 40 80 120 160 200 0 10 20 30 40 50 60 70 Instruction  interval number (in10K instructions) 80 90 100 P e k c a t e p s r K l i o I n r t c u i t s n o sjas cactus sphinx xalan Figure 9: Injection rate (packets per kilo instructions) of Case Study III applications for an intermediate one million instructions window (a) Average Injection Rate (b) Average L1 mpki (c) Injection rate during each 10K-instruction interval 0.3 0.4 0.5 0.6 0.7 0.8 case1 case2 case3 Avg W d e h g e i t S p u d e e p STC-ASCP STC-MPI Random STC-ReqQueue RoundRobin 0.3 0.4 0.5 0.6 0.7 0.8 case1 case2 case3 Avg W h g e i t d e S p u d e e p STC-TB STC-PB STC-nobatch 0.3 0.4 0.5 0.6 0.7 0.8 case1 case2 case3 Avg W h g e i t d e S p u d e e p STC-InstAge STC-RR STC-Age Figure 10: Performance impact of different (a) Ranking Heuristics (b) Batching Policies (c) Local Arbitration Polices 9 8 7 6 5 4 3 2 1 0 case1 case2 case3 Avg M x a N e t w o r k S l o w o d w n STC-ASCP STC-MPI Random STC-ReqQueue RoundRobin 10 9 8 7 6 5 4 3 2 1 0 case1 case2 case3 Avg M x a N e t w o r k S l o w o d w n STC-TB STC-PB STC-nobatch 8 7 6 5 4 3 2 1 0 case1 case2 case3 Avg M x a N e t w o r k S l o w o d w n STC-InstAge STC-RR STC-Age Figure 11: Fairness impact of different (a) Ranking Heuristics (b) Batching Policies (c) Local Arbitration Polices 8.9 Effect of Enforcing System-Level Application Weights/Priorities We evaluated the effectiveness of our prioritization substrate in enforcing system-software-assigned application priorities for a variety of scenarios and present three representative case studies. Figure 13(a) shows the network slowdown of four groups of 16 xalan applications (8x8 network) where, each group has weights of 1, 2, 2, and 8, respectively. Figure 13(b) shows the network slowdown of eight groups of 8 xalan applications where each group respectively has weights of 1, 2, 3, ..., 8. LocalAge and LocalRR schemes treat all different-weight applications the same because they are applicationunaware. As a result, all applications slow down similarly. In contrast, our mechanism enforces application weights as conﬁgured by the OS. Each application slows down inverse-proportionally to its weight: higher-weight (i.e., more important) applications experience the smallest slowdowns whereas lower-weight (i.e., less important) applications experience the highest slowdowns in the network. Figure 13(c) shows that our proposal is also able to enforce application weights in a heterogeneous workload consisting of different applications. We conclude that our mechanism is effective at enforcing system-level application priorities within the network by allowing application-aware prioritization to be conﬁgurable by the system software. Note that we also evaluated GSF by ensuring it allocates network bandwidth proportionally to each application’s weight. While GSF is able to enforce application weights in the network, it does so at signiﬁcantly reduced system throughput compared to STC, as shown in Figure 13(d). GSF also slows down the lowest-weight application signiﬁcantly more than STC (see Figures 13(b) and 13(c)) because when this application runs out of frames, it cannot inject into the network. 9. Related Work To our knowledge, no previous work proposed application-level prioritization mechanisms to optimize application-level system throughput in NoCs. Here, we brieﬂy describe the most closely related previous work. Prioritization and Fairness in On-Chip/Off-Chip Networks: We have already compared our approach extensively, both qualitatively and quantitatively, to existing local arbitration (LocalAge,LocalRR) and state-of-the-art QoS-oriented prioritization (GSF [17]) policies in NoC. Other frameworks for QoS [2, 26] have been proposed in onchip networks. Mechanisms for QoS can possibly be combined with our approach. Similarly, a large number of arbitration policies [32, 4, 10, 1] have been proposed in multi-chip multiprocessor networks and long-haul networks. The goal of these mechanisms is to provide fairness or guaranteed service, while ours is to improve overall system throughput without degrading fairness, while being sufﬁciently conﬁgurable to allow the operating system to enforce application priorities. Bolotin et al. [3] propose prioritizing control packets over data packets in the NoC, but do not distinguish packets based on which application they belong to. Our mechanism can be combined with their simple prioritization heuristic. Flow-Based Prioritization in Off-Chip Networks: Previous work [32, 6, 33] explored mechanisms that statically assign priorities/bandwidth to different ﬂows in off-chip networks to satisfy real-time performance and QoS guarantees. These works assume that each ﬂow’s priority is known a priori, and hence each packet’s priority is simply set to this known priority. In contrast, our mechanism does not assume an application’s priority is known. STC can dynamically determine the relative priority of each application (and hence each packet) to optimize overall system performance. Note that our scheme is still 290                                                       0.36 0.46 0.56 0.66 0.76 25K 50K 100K 150K 200K 250K 300K 350K 400K W d e h g e i t S p u d e e p Ranking Interval (Kilo cycles) case1 case2 case3 0 2 4 6 8 25K 50K 100K 150K 200K 250K 300K 350K 400K U n f a i r s e n Ranking Interval (Kilo cycles) case1 case2 case3 0.36 0.46 0.56 0.66 0.76 0.5K 1K 2K 4K 8K 16K 32K W d e h g e i t S p u d e e p Batching Interval (Kilo packets) case1 case2 case3 0 2 4 6 8 0.5K 1K 2K 4K 8K 16K 32K U n f a i r s e n Batching Interval (Kilo packets) case1 case2 case3 Figure 12: Effect of Ranking and Batching Intervals 0 2 4 6 8 10 12 14 LocalRR LocalAge GSF-1-2-2-8 STC-1-2-2-8 N e t w o r k S l o w o d w n xalan-1 xalan-2 xalan-2 xalan-8 20 18 16 14 12 10 8 6 4 2 0 LocalRR LocalAge GSF STC N e t w o r k S l o w o d w n xalan-1 xalan-2 xalan-3 xalan-4 xalan-5 xalan-6 xalan-7 xalan-8 0 2 4 6 8 10 12 14 16 18 20 22 LocalRR LocalAge GSF-1-2-2-8 STC-1-2-2-8 N e t w o r k S l o w o d w n xalan-weight-1 lbm-weight-2 leslie-weight-2 tpcw-weight-8 0.0 0.1 0.2 0.3 0.4 0.5 0.6 xalan1228 xalan1to8 hetero1228 Avg W d e h g e i t S p u d e e p LocalRR GSF LocalAge STC Figure 13: Enforcing OS Priorities:(a) A homogenous workload mix with weights 1-2-2-8 (b) A homogenous workload mix with weights 1-to-8 (c) A heterogeneous workload mix with weights 1-2-2-8 (d) Weighted Speedup of all mechanisms for the three workloads able to enforce statically-known priorities, as Section 4.2 shows. Criticality of Memory Accesses and Memory Level Parallelism: There has been extensive research on predicting criticality of memory accesses [28, 9, 29] and prioritizing critical accesses in the processor core and caches. It has also been shown that system performance can be improved by designing MLP-aware cache replacement [25] and memory scheduling policies [20]. Our work is related to these works only in the sense that we also exploit criticality and MLP to improve system performance. However, our mechanisms are very different due to the distributed nature of on-chip networks. To our knowledge, the concepts of criticality and MLP were not previously exploited in on-chip networks to improve system performance. Batching: We propose packet batching in NoC for starvation avoidance. The general concept of batching has been used in disk scheduling [30] and memory scheduling [20] to prevent the starvation of I/O and memory requests. The concept of frames used in [17] is analogous to packet batching. 10. Conclusion We introduce a novel, comprehensive application-aware prioritization framework to improve application-level system throughput in NoCs. We identify the concept of stall-time criticality of packets, and provide mechanisms to prioritize applications with critical packets across routers, while guaranteeing starvation freedom. Averaged over 96 randomly-generated multiprogrammed workload mixes on a 64-core 8x8-mesh CMP, the proposed policy improves overall system throughput by 9.1% on average (and up to 33.7%) over the best existing prioritization policy, while also reducing application-level unfairness. While effective at improving both system performance and fairness, our proposal is also conﬁgurable and thus enables the enforcement of system-level application priorities, without hurting overall performance. We conclude that the proposed prioritization framework provides a promising way to build many-core NoCs that provide high system performance, fairness, and ﬂexibility. Acknowledgments This research is supported in part by NSF grant CCF 0702519. The authors would like to thank Microsoft for their generous support. We thank Miray Kas and the anonymous reviewers for suggestions. "
2004,"Thermal Modeling, Characterization and Management of On-Chip Networks.","Due to the wire delay constraints in deep submicron technology and increasing demand for on-chip bandwidth, networks are becoming the pervasive interconnect fabric to connect processing elements on chip. With ever-increasing power density and cooling costs, the thermal impact of on-chip networks needs to be urgently addressed. In this work, we first characterize the thermal profile of the MIT Raw chip. Our study shows networks having comparable thermal impact as the processing elements and contributing significantly to overall chip temperature, thus motivating the need for network thermal management. The characterization is based on an architectural thermal model we developed for on-chip networks that takes into account the thermal correlation between routers across the chip and factors in the thermal contribution of on-chip interconnects. Our thermal model is validated against finite-element based simulators for an actual chip with associated power measurements, with an average error of 5.3%. We next propose ThermalHerd, a distributed, collaborative run-time thermal management scheme for on-chip networks that uses distributed throttling and thermal-correlation based routing to tackle thermal emergencies. Our simulations show ThermalHerd effectively ensuring thermal safety with little performance impact. With Raw as our platform, we further show how our work can be extended to the analysis and management of entire on-chip systems, jointly considering both processors and networks.","Thermal Modeling, Characterization and Management of On-chip Networks Li Shang Li-Shiuan Peh Amit Kumar Department of Electrical Engineering Princeton University, Princeton, NJ 08544 Niraj K. Jha Abstract Due to the wire delay constraints in deep submicron technology and increasing demand for on-chip bandwidth, networks are becoming the pervasive interconnect fabric to connect processing elements on chip. With ever-increasing power density and cooling costs, the thermal impact of onchip networks needs to be urgently addressed. In this work, we ﬁrst characterize the thermal proﬁle of the MIT Raw chip. Our study shows networks having comparable thermal impact as the processing elements and contributing signiﬁcantly to overall chip temperature, thus motivating the need for network thermal management. The characterization is based on an architectural thermal model we developed for on-chip networks that takes into account the thermal correlation between routers across the chip and factors in the thermal contribution of on-chip interconnects. Our thermal model is validated against ﬁnite-element based simulators for an actual chip with associated power measurements, with an average error of 5.3%. We next propose ThermalHerd, a distributed, collaborative run-time thermal management scheme for on-chip networks that uses distributed throttling and thermalcorrelation based routing to tackle thermal emergencies. Our simulations show ThermalHerd effectively ensuring thermal safety with little performance impact. With Raw as our platform, we further show how our work can be extended to the analysis and management of entire on-chip systems, jointly considering both processors and networks. 1 Introduction Chip reliability and performance are increasingly impacted by thermal issues. Circuit reliability depends exponentially upon operating temperature. Thus, temperature variations and hotspots account for over 50% of electronic failures [29]. Thermal variations can also lead to signiﬁcant timing uncertainty, prompting wider timing margins, and poorer performance. Traditionally, cooling system design is based on worst-case analysis. As heat density and system complexity scale further, worst-case design becomes increasingly difﬁcult and infeasible. This has led to recent processor designs, such as the Intel Pentium4-M [1] and the IBM Power5 [6], moving to average-case thermal design and employing run-time thermal management schemes upon occurrence of thermal emergencies. As we move towards application-speciﬁc multiprocessor systems-on-a-chip (SoCs) [2, 7, 18] and general-purpose chip-multiprocessors (CMPs) [16, 26] where a chip is composed of multiple processing elements interconnected with a network fabric, system chip temperature becomes an accumulated effect of both processing and communication components. With networks consuming a signiﬁcant portion of the chip power budget [2, 10, 27], and hence having a substantial thermal impact, understanding the joint thermal behavior of all on-chip components, both processors and networks, is the key to achieving efﬁcient thermal design. Researchers [3, 22, 24] have started addressing thermal issues in microprocessors. Unlike centralized microprocessors, networks are distributed in nature, which imposes unique requirements on thermal modeling and management. Moreover, multiprocessor on-chip systems share the distributed nature of on-chip networks. Therefore, we see addressing of on-chip network thermal issues providing valuable insights for managing entire on-chip systems. For networks, recent studies mainly focus on power issues, including modeling and characterization [10, 15, 28], design [27], and management [11, 20]. Even though both power and temperature are a function of the communication trafﬁc, the network thermal and power consumption proﬁles exhibit different run-time behavior. Power-oriented optimization techniques cannot fully address network thermal issues. We need to tackle the thermal impact of on-chip networks directly. In this paper, we ﬁrst construct an architecture-level thermal model for on-chip networks. We then build a network simulation platform that enables rapid evaluation of network performance, power consumption, and thermal proﬁle within a single run-time environment. Using this model, we characterize the thermal behavior of the on-chip networks in the MIT Raw CMP. We then propose ThermalHerd, a distributed run-time mechanism that dynamically regulates network temperature. ThermalHerd consists of three on-line mechanisms: dynamic trafﬁc prediction, distributed temperature-aware trafﬁc throttling, and proactive/reactive thermal-correlation based routing. The performance of ThermalHerd is evaluated using on-chip network trafﬁc traces from the UT-Austin TRIPS CMP [16]. Our results demonstrate that ThermalHerd can effectively regulate network temperature and eliminate thermal emergencies. Furthermore, ThermalHerd proactively adjusts and balances the network thermal proﬁle to achieve a lower junction temperature, thus minimizing the need for throttling and its impact on network performance. Finally, using Raw as a case study, we extend our work to address the thermal issues of on-chip systems, incorporating on-chip processing elements. A brief summary of our contributions is as follows. • First work targeting run-time thermal impact of onchip networks. • Characterization of the relative thermal impact of computation and communication resources in Raw. Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  • An architectural thermal model and integrated simulation platform that facilitates trace-driven performance, power and temperature analysis of networks. • A run-time thermal management technique for on-chip networks that effectively regulates temperature with little performance degradation. • Extension of network thermal characterization and management to entire on-chip systems, jointly considering both processors and networks. The rest of this paper is organized as follows. In Section 2, we ﬁrst use Raw as a motivating case study for demonstrating the thermal impact of on-chip networks. In Section 3, we describe the thermal modeling methods for on-chip networks. In Section 4, we give details of ThermalHerd and evaluate its performance in Section 5. In Section 6, we discuss extending our work from on-chip networks to on-chip systems. In Section 7, we present prior related work and discuss related research issues, and Section 8 concludes the paper. 2 Motivating Case Study: On-chip Network Thermal Impact in Raw We ﬁrst motivate the need for run-time thermal management of on-chip networks by studying the thermal impact of the on-chip networks in the MIT Raw CMP. The Raw chip accommodates 16 tiles connected in a 4x4 mesh topology, clocked at 425MHz frequency and a nominal voltage of 1.8V. The die size is 18.2x18.2mm2. In each 4x4mm2 tile, the processor is a single-issue MIPS-style processing element consisting of an eight-stage pipeline equipped with 32KB data and 32KB instruction caches. Tiles are connected by four 32-bit on-chip networks, two statically-scheduled by the compiler through a 64KB switch instruction memory and two dynamically-routed. The chip is manufactured using the IBM CMOS7SF Cu6 0.18µm technology. As shown in Figure 1, it uses the IBM ceramic column grid array (CCGA) package with direct lid attach (DLA) thermal enhancement. The thermal performance of the packaging ranges from 9oC/W to 5oC/W under different air-cooling conditions. In Raw, the thermal impact of the on-chip network is governed by various design issues. Performance requirements govern the network complexity, and hence the peak power consumption. The chip layout affects the thermal interaction between the network and other computation/storage tiles. The chip temperature is also directly affected by cooling solutions, which vary under different application scenarios and cooling budgets. In this section, we focus on analyzing the thermal impact of just the on-chip network. Complete thermal characterization for the entire chip will be discussed in Section 6. In Raw, the two static networks contain the following components: switch instruction memory, switch pipeline Air flow C C C C C C C C C C C C C C C C DLA thermal enhancement Thermal interface material Silicon die Multi-layer ceramic carrier logic, crossbars, FIFOs, and wires. The two dynamic networks are composed of crossbars, FIFOs, wires, and routing control logic. We use Raw Beetle, a validated cycleaccurate simulator [26], to capture the run-time activities of different network components. Combining the simulation results with the capacitances estimated using an IBM placement tool by Kim [9], we derive network run-time power consumption. Based on the chip layout and packaging information, we construct an architectural thermal model for the on-chip network using the model described in Section 3. Thermal characteristics, including thermal conductivities and capacitances, and geometric information of the package materials including the interface material, DLA, ceramic carrier, etc., and air-cooling conditions are provided by the packaging manual [25]. The ambient temperature is set to 25oC 1 . Figure 2 shows the chip peak temperature contributed by typical-case network power dissipation under different air-cooling conditions (linear feet per minute, or lfpm), where, as explained in [9, 10], the typicalcase power assumes the activity factor of 0.25 in each of the four on-chip networks. With poor air-cooling, the network power alone can push the chip temperature up to about 90oC. Even at a typical air cooling of 300lfpm, the network temperature alone can reach a signiﬁcant 77oC. Next, we characterize the thermal impact of the on-chip network using three classes of benchmarks provided by the Raw binary distribution. Details of these benchmarks are available in [26]. ﬁr and stream are stream benchmarks. 8b 10b enc. and 802.11a enc. are bit-level computation benchmarks. gzip and mpeg are ILP computation benchmarks. Each study is based on the typical (300lfpm) and best (600lfpm) air-cooling conditions. Detailed benchmark explanation and complete characterization results are given in Section 6. As shown in Figure 3, the two stream and two bit-level computations benchmarks lead to a high peak temperature. This is due to the heavy utilization of static network resources, which have a higher capacitance than the dynamic network in Raw as they are used as the primary communication fabric in the chip. gzip and mpeg result in a lower peak temperature due to two reasons. First, the limited parallelism in these benchmarks leads to low resource utilization. Second, limited by the available compiler, the trafﬁc is mainly relayed by the dynamic networks. The above studies demonstrate that on-chip networks can have a signiﬁcant thermal impact on overall chip tem1Ambient temperature varies across different systems. Relative trends are preserved for other typical settings. 95 90 85 80 75 70 65 60 100 200 ) C ( e r u t a r e p m e T ) C ( e r u a t r e p m e t k a e p p i h C Max. chip temperature 400 600 300 Air flow velocity (lfpm) Figure 2. On-chip network thermal analysis I. 80 70 60 50 40 30 20 10 0 Typical- case air- cooling (300lfpm) Best-case air- cooling(600lfpm) Figure 1. MIT Raw CMP with cooling package. fir stream 8b_10b enc. 802.11a enc. gzip mpeg Figure 3. On-chip network thermal analysis II. Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  perature. As will be discussed in Section 6, in Raw, the thermal contributions of both processors and networks are comparable, and can be substantial, depending on application characteristics. Based on the benchmarks we used with typical air-cooling conditions, networks or processors alone can reach peak temperatures of 68.6oC and 77.9oC, respectively. When networks and processors are jointly considered, certain stream and bit-level computation benchmarks can push chip peak temperature up to 104.7oC under typical air-cooling conditions. Therefore, more sophisticated cooling solutions and thermal management techniques are required to guarantee safe on-line operation. On the other hand, the SPEC and Mediabench benchmarks result in low power and thermal impact on both networks and processors due to underutilized on-chip resources. 3 Thermal Modeling of On-chip Networks The cooling package of today’s high-performance onchip systems is complex due to high power density and strict cooling requirements. To facilitate characterization of chip architectures, we need thermal models that can accurately capture the characteristics of these sophisticated thermal packages with only the limited architectural input parameters available at an early-stage design. Skadron et al. ﬁrst proposed an architectural thermal model for microprocessors, HotSpot [22], which constructs a multi-layer lumped thermal RC network to model the heat dissipation path from the silicon die through the cooling package to the ambient. In HotSpot, the silicon die is partitioned into functional blocks based on the ﬂoorplan of the microprocessor, with a thermal RC network connecting the various blocks. HotSpot can be readily used to model on-chip network routers – with each router within the chip ﬂoorplan modeled as a block, and a thermal RC network constructed in the same fashion as when the blocks were functional units within a microprocessor. However, certain characteristics of on-chip networks are not accurately captured by HotSpot. First, lateral thermal correlation is modeled using lateral thermal resistors connecting adjacent blocks, and solved using a closed-form thermal equation [23]. This equation was originally proposed to model the spreading thermal resistance for a large symmetric slab area. As the geometric and thermal boundary conditions of a silicon die do not match the above scenario, thermal correlation tends to be underestimated. The temperature of an on-chip router is affected by its own power consumption, and that of its neighborhood and also remote routers. In on-chip networks, the power and thermal impact of each individual router is limited. Inter-router thermal correlation plays an important role in shaping the overall chip temperature proﬁle. Hence, accurately characterizing the spatial thermal correlation is critical for understanding network thermal behavior. Second, the current release of HotSpot does not model the thermal impact of metal interconnects. Due to the high thermal resistance of the silicon dioxide and low dielectric constant (low-k) materials, the contribution of the interconnects to overall chip temperature is of increasing concern [5] and needs to be considered. The above issues prompted us to develop an architectural thermal model that handles the thermal characteristics of on-chip networks – one that aptly captures inter-router thermal correlation and models on-chip link circuitry. Heat source Heat source Heat source R-silicon R-spreader R-sink R-ambient K1 K2 Heat source p a t h i d s s p a i t i o n H e a t T1 T2 R1 Q1 R2 Q2 R31 R32 R33 T1 T2 R1 R2 Q2 Q1 R3 Figure 4. heat spreading angle and interrouter thermal correlation. 3.1 Inter-router Thermal Correlation Modeling Our model is based on the notion of the heat spreading angle – the angle at which heat dissipates through the different layers of packaging. In microelectronic packages, the heat ﬂow from the silicon surface to the ambient is threedimensional – heat dissipates in the vertical direction and also spreads along horizontal directions, which can be described by Fourier’s law. The heat spreading angle forms the basis of calculations of thermal resistances and thermal correlations of the thermal RC network (that is constructed in the same fashion as in HotSpot). Heat dissipation path: First, let us analyze the thermal resistance of the heat dissipation path of each on-chip router. The heat spreading angle, θ, (see Figure 4) can be estimated based upon the ratio of the thermal conductivities of the current packaging layer’s material, k1 , and the underlying packaging layer’s material, k2 [13]: θ = tan−1 (k1 /k2 ) (1) Then, as shown in Figure 4, the thermal resistance, R, of a rectangular heat source on a carrier, that includes the thermal spreading effect is [12]: R = 1 2k tan θ(x − y ) ln y + 2L tan θ x + 2L tan θ x y (2) where x and y are the length and width of the heat source, L is the height of the carrier, and k is the thermal conductivity. For each on-chip router i, the thermal resistance, Ri , is the summation of the thermal resistance of each thermal component along the heat dissipation path, as follows: Ri = Ri silicon + Ri spreader + Ri sink + Ri ambient (3) where Ri silicon , Ri spreader , Ri sink , and Ri ambient are the thermal resistance of the on-chip router through silicon die, heat spreader, heat sink and ambient, respectively. Both Ri silicon and Ri spreader can be obtained using Equations (1) and (2). For Ri silicon , the area of the heat source is equal to the size of the on-chip router, and the heat spreading angle in the silicon die can be determined by the thermal conductivity ratio of the silicon die and the heat spreader2 . For Ri spreader , the area of the heat source is the original router area plus the area expansion due to heat spreading in the silicon die, which equals (x + 2Lsilicon tan θsilicon )(y + 2Lsilicon tan θsilicon ). The heat spreading angle is affected by the thermal conductivity 2 If an interface material is used, the heat spreading angle can be determined similarly, and Equation (3) should also take thermal resistance in the interface material into account. Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  ratio of the heat spreader and heat sink. For Ri sink , the other side of the heat sink is attached to a cooling fan, and the heat dissipation is based on heat convection. Previous work has proposed a closed-form thermal equation to address the heat spreading issue in heat sinks. The thermal resistance of a heat sink can be determined by the following equation [23]: Ri sink = 1 πka (τ + (1 − ) tanh(λτ ) + λ Bi 1 + λ Bi tanh(λτ ) ) (4) where k is the thermal conductivity of the heat sink, a is the source radius, , τ , λ are dimensionless parameters deﬁned in [23], and Bi is a Biot number. The thermal resistance along the heat convection path can be estimated as follows [17]: Ri ambient = 1 hcAs (5) where hc is the convection heat transfer coefﬁcient and As is the effective surface area. Inter-block thermal correlation: In general, the steadystate temperature of each location across the silicon die is a function of the power consumption of all the on-chip heat sources: T (x, y) = N(cid:1) k=1 CiPi (6) where T (x, y) is the temperature at location (x, y) on the silicon die, N is the total number of on-chip heat sources, Pi is the power consumption of heat source i, and Ci is the thermal correlation (thermal resistance) between heat source i and location (x, y). The thermal correlation among on-chip blocks (routers) can be characterized based on the cooling structure, the heat spreading angle in each cooling package layer, and the interrouter distance. There exists a duality between heat transfer and electrical phenomena. The linearized superposition principle in electrical circuits can be extended to thermal circuits to analyze the inter-router thermal effect. As shown in Figure 4, Q1 and Q2 denote the power consumption of two on-chip routers. The corresponding heat dissipation paths of these two routers are initially separate but will ﬁnally merge into one path due to the heat spreading effect. Then, using the linearized superposition principle, for these two routers, the heat dissipation paths can be divided into two parts from the merged point – before this point, the heat dissipation paths can be modeled with two separate thermal resistors, R1 and R2. After this point, the heat dissipation paths are modeled with a shared thermal resistor R3. The thermal correlation between two heat sources is determined by the value of R3, which is the thermal resistance of the shared heat dissipation path from the point where the two heat dissipation paths are merged together to the ambient environment. The position of the merged point can be estimated based on the heat spreading angle in each packaging material and the inter-router distance. The junction temperature of each router, T 1 and T 2, including inter-router thermal correlation, can then be estimated using thermal superposition: T 1 = Q1R1 + (Q1 + Q2)R3 T 2 = Q2R2 + (Q1 + Q2)R3 (7) 1 4 7 1 4 7 s i o 5.0 4.0 3.0 2.0 1.0 0 E r r o r ( % ) xdimension y d i m e n n (a) Estimation error. / / 1 2 3 4 5 6 7 8 9 1 3 5 y 7 d i m e 9 s i o 5.0 4.5 4.0 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0 E r r o r ( % ) xdimension n n (b) Estimation error. Figure 5. Thermal model validation against FEMLAB. 1 4 7 11 1 3 5 7 9 90 87 84 81 78 75 72 69 66 63 60 11 T e m p e r a t u r e ( C ) x dimension y d i m e n s i o n (a) Chip thermal proﬁle. / / 1 4 7 11 1 4 y 7 e 14 12 10 8 6 4 2 0 11 n n s i o E r r o r ( % ) xdimension d i m (b) Estimation error. Figure 6. Thermal model validation against IBM in-house ﬁnite-element based simulator. 3.1.1 Validation In this section, we discuss validation of our thermal models. FEMLAB, a ﬁnite-element based simulator: To evaluate the accuracy of our thermal model, we ﬁrst use a commercial ﬁnite-element based simulator, FEMLAB [8]. We assume the silicon die’s dimension is 18mm × 18mm × 0.6mm, the thermal conductivity is 100W/mK , the heat spreader’s dimension is 30mm × 30mm × 1mm, and the heat sink’s dimension is 60mm × 60mm × 6.8mm. Both the heat spreader and heat sink are assumed to be made of copper, whose thermal conductivity is 400W/mK . The silicon die is partitioned into 9 × 9 blocks evenly. We set the ambient temperature to 25oC. In the ﬁrst scenario, we assume the central block, (5,5), is the only heat source and has a 2.5W power consumption. We use this setup to evaluate the accuracy of modeling a single heat source. Using our model, the temperature distribution on the silicon surface varies from 32.6oC to 28.2oC. Block (5,5) is the hottest spot, and the four boundary blocks have the lowest temperature. Figure 5(a) shows the modeling error of our thermal model against FEMLAB. The error is consistently less than 5% (the average being 2.9%). To evaluate the accuracy of our model in capturing interrouter thermal correlation, we assume three heat sources situated at (5,5), (3,5) and (7,5), each with a power consumption of 2.5W. Using our model, the temperature varies from 39.8oC to 34.7oC. The estimation error of our thermal model against FEMLAB is shown in Figure 5(b), where the maximum error is less than 5% (the average being 1.0%). Actual chip with power measurements: Next, we evaluate our thermal model against an actual chip design from IBM [4]. In this design, a 13mm × 13mm × 0.625mm chip is soldered to a multilayer ceramic carrier. This chip is attached to a heat sink and placed inside a wind tunnel. The power consumption proﬁle across the silicon die is based on physical measurements. We use our thermal model to evaluate the temperature proﬁle of this IBM design. Figure 6(a) Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  shows the temperature simulation result using our thermal model. Comparing it against an in-house ﬁnite-element based thermal simulator at IBM, Figure 6(b) shows the estimation errors in the on-chip thermal proﬁle. As shown in this ﬁgure, the maximum error is less than 10%, and the average error is 5.3%. Using our thermal model, the junction temperature of the silicon die varies within [70.2, 85.4]oC. The IBM thermal simulator shows the junction temperature varying within [73.2, 87.8]oC. Both validation studies demonstrate the importance of accurately modeling the spatial variance of temperature across the silicon surface. While our model and the ﬁniteelement based simulators show the spatial thermal variance to be around 15oC, HotSpot [22] reports only 8oC. 3.2 Thermal Modeling of Links The power consumed in the on-chip link circuitry affects the temperature of both silicon and metal layers. As on-chip links are typically fairly long, buffers are inserted to reduce signal propagation delay. The inserted buffers not only affect network performance and power consumption, but also its temperature. Buffers split on-chip links into multiple segments, with each segment connected to silicon through two vias. In copper processes, vias have much better thermal conductivity than the dielectrics and thus serve as efﬁcient heat dissipation paths. To model on-chip link temperature effectively, buffer insertion effects need to be considered. Previous research work has calculated the optimal length of interconnect at which to insert repeaters as [14]: (cid:2) lopt = const r0 (c0 + cp ) rc (8) where r0 and c0 are the effective driver resistance and input capacitance for a minimum-sized driver, cp is the output parasitic capacitance, and r and c are the interconnect resistance and capacitance per unit length. Given the length of link segments, the temperature along each segment can be calculated using the following equation [5]: T (x) = T0 + j 2ρL2 kM H (1 − cosh( x LH cosh( L 2LH ) ) ) (9) where T0 is the underlying layer temperature, j is the current density through the link segment, and ρ, L and kM are the resistivity, length and thermal conductivity of the link segment, respectively. LH denotes the thermal characteristic length. Based on our analysis, the major thermal contribution of the link circuitry lies in the silicon (buffers). Due to the limited self-heating power, when the secondary heat dissipation path from top silicon dioxide and low-k material layers to the printed circuit board is considered, thermal hotspots are located in the silicon layer instead of the metal layers. 3.3 Sirius: Network Thermal Simulation Environment The thermal model described above is built into a network simulation environment, called Sirius, which provides an architecture-level platform for rapid exploration of the performance, power consumption, and thermal proﬁle of on-chip networks. Network model: We use a ﬂit-level on-chip network model, which speciﬁes the topology and resource conﬁguration of the network. Currently, two-dimensional directnetwork topologies are supported. Each router is speciﬁed with a pipeline model. Various routing schemes, including deterministic, oblivious, adaptive, etc., are integrated. Power model: This model is adapted from Orion [28], an architecture-level network power (dynamic/leakage) model. Network power consumption is determined by the network architecture, implementation technology, and trafﬁc activity. The ﬁrst two parameters are deﬁned in the network model. The last is captured during run-time simulation. Thermal model: This is the model presented in this section. It is created, based on the network architecture and cooling structure, during compilation. Timing-driven simulator: This is built on top of a timingdriven simulation engine. During on-line simulation, trafﬁc activities are gathered and fed into the power model to estimate network power consumption. This is then fed into the thermal model periodically to estimate the network temperature proﬁle. Timing information is also gathered to monitor network latency and throughput. 4 ThermalHerd: Distributed, Collaborative Run-time Thermal Management The thermal behavior of on-chip networks is inherently distributed in nature. Thermal emergencies can occur in different locations and change dynamically. In addition, onchip networks are heavily performance-driven. Here, we explore run-time management of network temperature, using ThermalHerd, a distributed scheme where routers collaboratively regulate the network temperature proﬁle and work towards averting thermal emergencies while minimizing performance impact. 4.1 ThermalHerd: Overall Architecture The microachitecture of a ThermalHerd router consists of ﬁve key components: • Temperature monitoring: At run-time, temperature monitors, such as thermal sensors or on-line thermal models, periodically report the local temperature to each router, triggering an emergency mode when the local temperature exceeds a thermal threshold. • Trafﬁc monitoring and prediction: ThermalHerd’s throttling and routing relies on trafﬁc activity counters embedded in each router that facilitates prediction of future network workload. • Distributed throttling: Upon a thermal emergency, the routers at the hotspot will throttle incoming trafﬁc in a distributed way, reducing power consumption in the region, thus cooling the hotspot. • Reactive routing: In addition, each router reacts by adapting the routing policy to direct trafﬁc away from the hotspots, relying on the thermal correlation information that is exchanged between routers periodically. • Proactive routing: During normal operation, routers will proactively shape their routing decisions to reduce trafﬁc to potential thermal hotspots, based on thermal correlation information. Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  4.2 Run-time Thermal Monitoring There are two different mechanisms that can be used to monitor network temperature: thermal sensors and on-line thermal estimation. Thermal sensors have been widely used in high-performance systems. For instance, Power5 [6] employs 24 digital temperature sensors to obtain the chip temperature proﬁle. Another approach is dynamic thermal modeling and estimation. In [22], an architecture-level thermal model is used to estimate and monitor the temperature proﬁle of microprocessors. Since thermal transitions are fairly slow, the computation overhead introduced by on-line thermal estimation is tolerable. In this work, we focus on dynamic thermal management. Either of the above temperature monitoring techniques can be used. For thermal sensors, if one sensor per router is not affordable for large on-chip networks, the network can be partitioned into regions and multiple adjacent routers within a region could share the same sensor. For the on-line thermal modeling based approach, on-line power and temperature models are required. An efﬁcient on-line power estimation mechanism for networks is proposed in [20]. This can then be fed into thermal models implemented with dedicated hardware or executed on on-chip processing elements for temperature estimation. 4.3 Dynamic Trafﬁc Estimation and Prediction In ThermalHerd, each router is equipped with two sets of trafﬁc counters to dynamically estimate the trafﬁc workload. Trafﬁc counter, cntlocal , is integrated with the injection buffer to monitor locally-generated trafﬁc. Trafﬁc counter, cntneighbor , is used to monitor the trafﬁc arriving from the neighborhood. Two other counters, cnthis local and cnthis neighbor , are used for trafﬁc bookkeeping. Both trafﬁc and bookkeeping counters are updated based on a predeﬁned timing window, Ttraf f . Within each Ttraf f , trafﬁc counters, cntlocal and cntneighbor , count the total amount of incoming ﬂits from the injection and input ports, respectively. At the end of each Ttraf f , the trafﬁc information in the trafﬁc and bookkeeping counters are combined using weighted average ﬁltering to eliminate transient trafﬁc ﬂuctuations. 4.4 Distributed Trafﬁc Throttling The key challenges faced in designing a distributed trafﬁc throttling mechanism is that it has to effectively regulate overall network temperature, averting thermal emergencies, while minimizing performance impact. Exploring the design space for distributed throttling: As shown in Equation (6), the temperature contributed by each heat source is affected by the thermal correlation, which is determined by the cooling structure and distance. Neighboring heat sources have more thermal impact than remote ones. Therefore, to effectively alleviate the thermal emergency, trafﬁc throttling around the hotspot locations requires less throughput reduction, and hence less performance penalty. Trafﬁc throttling within a router also affects the power consumption of neighboring routers – throttling the router injection port decreases the trafﬁc through neighboring routers; throttling the router input and output ports decreases the available network bandwidth. We study the power throttling effect on a 9×9 on-chip network using uniform random trafﬁc. Router R4,4 is chosen to be the only trafﬁc regulation point. Figure 7 shows the power savings of ) W ( r e w o P 8 7 6 5 4 3 2 1 0 Power savings of the network (W) Power savings of the throttled router (W) Ratio of power savings 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Throttling ratio Figure 7. Power impact of localized throttling. R a t i o router R4,4 and the whole network as router R4,4 throttles an increasing percentage of incoming trafﬁc (we call this the trafﬁc throttling ratio). The black and gray bars show the power savings of router R4,4 and the whole network, respectively. The line shows the ratio of the power savings of router R4,4 to that of the total network. It shows that when R4,4 is throttling only a small percentage of its arriving trafﬁc, most of the power reduction comes from the throttled router, and the power reduction in the remaining part of the network is negligible. As R4,4 throttles more and more of its arriving trafﬁc, the power savings of the local router increases, while at the same time, the throttling effect spreads from the local router to its neighborhood, much like trafﬁc congestion on a local street spreading beyond its initial location to other roads feeding into this street. Thus, power reduction at other routers also increases and begins to dominate the total power savings, with neighboring routers seeing a sharper power reduction than remote ones. Distributed throttling in ThermalHerd: Based on the above observations, we propose the following distributed throttling mechanism in ThermalHerd. When a thermal hotspot is detected at the local router Ri , this router begins to decrease the local workload by throttling the input trafﬁc. The policy of trafﬁc throttling is controlled by an exponential factor k and local trafﬁc estimation, as follows: Quotai = k × (Nhis local + Nhis neighbor ), k ≤ 1 (10) where Quotai is the trafﬁc quota used to control the total amount of workload that is allowed to pass through this router. At the beginning of each thermal timing window, a new temperature is reported. If the temperature still increases, in the next timing window, the trafﬁc quota is further multiplied by k , otherwise, the throttling ratio is kept the same. Thus, the overall trafﬁc throttling ratio, K , equals kn , where n is the number of thermal timing windows in which the temperature continuously increases. This procedure continues till the thermal emergency is removed. Furthermore, each router uses the following policy to split the quota, Quotai , between the trafﬁc injected locally, Quotalocal , and the trafﬁc arriving from the neighborhood, Quotaneighbor . (cid:3) Quotalocal = Quotaneighbor = (cid:3) Nhis local Quotai if Nhis local ≤ Quotai if Nhis local > Quotai Quotai − Nhis local 0 if > 0 if ≤ 0 (11) This policy is biased towards providing enough trafﬁc quota to the trafﬁc generated locally. The rationale behind the policy is as follows. Without enough trafﬁc quota, the locallygenerated trafﬁc will be blocked in the injection buffer, Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  which increases network latency. Trafﬁc from neighboring nodes, on the other hand, can be redirected through other paths, thus avoiding a performance penalty. Hence, the above-mentioned bias towards local trafﬁc reduces the performance penalty. 4.5 Thermal-Correlation Based Routing Algorithm Trafﬁc throttling achieves a lower junction temperature by reducing network trafﬁc and power consumption. While distributed throttling is efﬁcient, it is not without a performance penalty. Since network thermal hotspots are often a result of imbalanced trafﬁc, thermal-aware routing algorithms that can redirect trafﬁc from throttled routers to minimize performance penalty and then shape network trafﬁc patterns suitably will potentially balance the network temperature proﬁle and avoid or reduce trafﬁc throttling. Our routing protocols rely on the thermal information exchanged within the network. At run-time, when thermal hotspots are detected, routers located at hotspot regions are marked as hotspots, and send special packets across the network. Since temperature transition is a very slow process, a noticeable temperature variation takes at least hundreds of microseconds. The power consumption and delay overhead introduced by these messages are thus negligible. For instance, in a 4×4 network, encoding the location of each hotspot takes four bits. Using a 100µs temperature report interval, the communication overhead for each hotspot is about 1bits/µs. When no thermal emergency occurs, the location information with the highest chip temperature is relayed through the network. We discuss both proactive and reactive routing protocols next. Proactive routing protocol: The proactive routing scheme continuously monitors the network temperature proﬁle. When the maximum chip temperature is below the thermal emergency limit, it dynamically adjusts trafﬁc to balance the network temperature proﬁle and reduces the peak temperature. Reactive routing protocol: Upon receiving the thermal emergency information, the reactive routing protocol replaces the proactive routing protocol. It tries to steer packets away from throttled regions to minimize the performance penalty due to throttling. In addition, reactive routing tries to balance the network temperature proﬁle to reduce the hotspot temperature, hence the need for throttling. Both routing schemes use trafﬁc reduction to achieve their goals. Since non-minimal path routing results in more hops and links being traversed, and thus higher power consumption and hence potentially higher junction temperatures, we use minimal-path adaptive routing functions. For both routing schemes, in order to balance the network temperature proﬁle, they should choose the routing paths which have minimal thermal correlation with the regions with the highest temperature. Since the interrouter thermal effect is based on distance, among all of the minimal-path routing candidates, the routing path with the farthest thermal distance should be chosen. However, this approach signiﬁcantly reduces path diversity and pushes trafﬁc workload towards the coolest boundaries, which can result in an unbalanced trafﬁc distribution and may also generate new thermal hotspots in the future. Detailed thermal analysis shows that inter-router thermal correlation dramatically decreases with increasing interrouter distance. Furthermore, the thermal correlation with remote routers is very small. We thus use a thermal correlation threshold, α, to select routing candidates. The thermal correlation of each routing candidate is determined as in Equation (7). Intuitively, ThermalHerd’s routing protocol jointly considers thermal correlation and trafﬁc balancing. It tries to eliminate routing paths with a high thermal correlation while leaving enough alternative routing candidates to balance the network trafﬁc. It does so by picking paths where the thermal correlation between the source and every hop along the path is below the thermal correlation threshold α. Since we use minimal-path routing, routing candidates satisfying such a thermal correlation threshold criterion may not be available. If so, the candidate routing path with the least thermal correlation is chosen. To strike a good balance between temperature and performance, in our implementation, we use different thermal correlation thresholds between proactive and reactive routing policies. When the maximum network temperature is below the thermal emergency limit, to minimize performance penalty, a less aggressive trafﬁc redirection policy is used for proactive routing (in this work, we set the thermal correlation threshold to be equivalent to 2L, in which L is the physical distance between neighboring routers). When a thermal emergency occurs, we set the threshold to be equivalent to 4L for reactive routing, since at that time, reducing the chip temperature is the ﬁrst-order issue, and also most of the performance penalty is due to trafﬁc throttling. 5 ThermalHerd Evaluation In this section, we evaluate the performance of ThermalHerd using CMP trafﬁc traces generated from the TRIPS CMP. We use Sirius as the simulation platform, which was described in Section 3.3. Performance evaluation focuses on the following two major design metrics. Effectiveness of run-time thermal management: First and foremost, as an on-line thermal management scheme, ThermalHerd should effectively alleviate thermal emergencies and ensure safe on-line operation. Two temperature-related parameters are introduced here – network thermal emergency threshold and network thermal trigger threshold. The former is a hard temperature upperbound, which is the maximum allowable network temperature depending on various factors, such as thermal budget and cooling solutions, and timing/reliability issues. For different systems, the chip temperature typically varies from 60oC to 95oC. In mobile applications or application scenarios with tight cooling budgets and space, the thermal budget could reach 105oC. In other applications, such as supercomputing, where cooling cost is not critical, and the mean time to failure of hundreds of parallel computation nodes needs to be maximized, the thermal budget could be lower than 60oC. Here, we set the thermal emergency threshold across a wide temperature range. The latter parameter, thermal trigger threshold, is used to activate ThermalHerd. When the chip peak temperature exceeds the thermal trigger threshold, distributed trafﬁc throttling is enabled and the proactive routing scheme is replaced by the reactive routing scheme. We set the thermal trigger threshold to 1oC lower than the thermal emergency threshold. Network performance impact: On-chip networks have very tight performance requirements in terms of latency and throughput. Hence, the performance impact of thermal management should be minimal. The network performance is evaluated as follows. Latency spans the creation of the ﬁrst ﬂit of the packet to ejection of its last ﬂit at the destination router, including source Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  queuing time and assuming immediate ejection. Network throughput is the total number of packets relayed through the network per unit time. For comparison purposes, we also introduce the following alternative run-time thermal management techniques. • GlobalThermal: When the temperature exceeds the thermal trigger threshold, all the routers throttle the same percentage of incoming trafﬁc. GlobalThermal is an approximation of the chip-level thermal management technique in Pentium4-M [1], in which, as the processor temperature reaches the temperature limits, the thermal control circuit throttles the processor clock. • DistrThermal: This scheme is equipped with the same distributed trafﬁc throttling technique as ThermalHerd. However, the thermal-correlation based routing algorithms are not enabled. This scheme is used here to differentiate the performance impact between the throttling and routing techniques. Throttling individual functional units has also been proposed for microprocessors – Power5 uses a dual-stage thermal management scheme [6], where in its second stage, temperature reduction is achieved by throttling the processor throughput via individual functions. • PowerHerd: It is the only available architecture-level run-time power management scheme targeting network peak power [20]. Unlike ThermalHerd, PowerHerd is power-aware instead of being thermal-aware. It controls network peak power based on a global power budget that mimics the thermal threshold. 5.1 Evaluation Using TRIPS On-chip CMP Trafﬁc Traces We evaluate the performance of ThermalHerd using trafﬁc traces extracted from the on-chip operand networks of TRIPS CMP by running a suite of 16 SPEC and Mediabench benchmarks. Since thermal transition is a slow process, to study the accumulated impact of ThermalHerd on both performance and chip temperature, trafﬁc traces generated by different benchmarks are concatenated together, forming a 200ms test trace. Using Raw [26], TRIPS [16] and the on-chip network proposed in [7], we deﬁne a 5×5 on-chip mesh network, as the TRIPS network architecture is currently in design stage. We assume a typical cooling solution here – the silicon die uses ﬂip-chip packaging and is attached to a 15mmx15mm heat spreader and a 30mmx30mm heat sink. The ambient temperature is 25oC. The initial temperature is determined by the average network power consumption over the whole simulation trace. Figure 8 shows the network peak temperature without any thermal management. As different benchmarks have different network workload and trafﬁc patterns, we can see that network peak temperature varies from 70.1oC to 94.0oC along the 200ms simulation. Peak temperature 100 ) C ( e r u t a r e p m e T 90 80 70 60 50 40 0 40 80 Time (ms) 120 160 Figure 8. Network peak temperature using the TRIPS trafﬁc trace. Table 1. Temperature management. TT (oC) TA (oC) 89 86.2 87 86.1 85 84.1 83 82.5 82 81.3 79 78.8 77 76.5 75 74.7 To evaluate the effectiveness of ThermalHerd in maintaining the chip temperature below the emergency point, we choose eight thermal emergency thresholds, TT . The simulation results are shown in Table 1. In this table, the ﬁrst row shows these eight thermal emergency thresholds, the second row shows the actual network peak temperature, TA , regulated by ThermalHerd. Comparing these two rows, we can see that using ThermalHerd, network run-time temperature is always below the corresponding thermal constraint, which means ThermalHerd can guarantee safe on-line operation. As shown in Table 1, when TT is at or below 87oC, the difference between TT and TA is always less than 1oC, which implies that the network peak temperature has exceeded the corresponding thermal trigger threshold. Hence, both distributed throttling and reactive routing are enabled. At TT = 89oC, the network peak temperature is below the thermal trigger threshold. Therefore, only proactive routing is enabled in this case. As compared to the peak temperature (94.0oC) when ThermalHerd is disabled, proactive routing alone can reduce the peak temperature by 7.8oC through balancing of the chip thermal proﬁle. Figure 9 shows network throughput degradation introduced by ThermalHerd under different thermal constraints. The throughput degradation, Thrdeg , is deﬁned as follows. T hrdeg (t) = (T hrinit (t) − T hrT hermal (t))/T hrinit (t) (12) where ThrThermal (t ) and Thrinit (t ) are network run-time throughputs with and without ThermalHerd. From this ﬁgure, we have two observations. First, when the thermal threshold is higher than 84.0oC, throughput degradation introduced by ThermalHerd is less than 1%. Therefore, compared to 94.0oC network peak temperature, ThermalHerd reduces network peak temperature by 10oC with negligible performance penalty. This signiﬁcant improvement is achieved by effective proactive and reactive routing schemes in collaboration with efﬁcient distributed trafﬁc throttling. Second, as the thermal threshold decreases, throughput degradation increases. This indicates that proactive routing alone cannot sufﬁciently avert the need for throttling which impacts performance. As we can see, the proactive routing scheme is an effective mechanism to balance the network temperature proﬁle and reduce the network peak temperature, which reduces the need for thermally-induced throttling and hence network throughput degradation. As discussed in Section 4.5, this routing scheme affects network latency. Here, latency overhead, Latovd , is deﬁned as follows. Latovd (t) = (LatT hermal (t) − Latinit (t))/Latinit (t) (13) where LatThermal (t ) and Latinit (t ) are network run-time latencies with and without ThermalHerd. Figure 10 shows the run-time latency impact of ThermalHerd. It shows that the latency overhead introduced by the proactive routing scheme is consistently less than 1.2%. 5.2 Comparison of ThermalHerd Against Alternative Thermal Management Schemes Next, we seek to isolate the impact of the various features of ThermalHerd – distributed throttling, reactive routing, Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  and proactive routing. Figure 11 shows network throughput degradation under different peak thermal constraints. We compare four schemes: GlobalThermal, DistrThermal (ThermalHerd with only distributed throttling), DistrThermal plus reactive routing, and ThermalHerd (Distributed throttling, reactive and proactive routing). The results show that under the same peak thermal constraints, DistrThermal is much more efﬁcient than GlobalThermal by selectively reducing the trafﬁc with high thermal contribution to thermal hotspots. With reactive routing on top of distributed throttling, the temperature proﬁle is further smoothed and throughput degradation reduces by more than 2X. Finally, with proactive routing, throughput degradation is negligible even at a thermal emergency threshold of 84oC. We next compare ThermalHerd with PowerHerd. PowerHerd is power-aware instead of thermal-aware. It controls network power consumption based on a global power budget that mimics the thermal threshold. However, under the same global power budget, different trafﬁc can result in very different network temperature proﬁles. In order to guarantee safe on-line operation, PowerHerd has to assume worst-case power distribution that results in the maximum chip temperature. To obtain such a worst-case power distribution, we partition the TRIPS network trace into slots of 10µs and calculate the average network power consumption for each time slot. With that, we derive the worst-case average power distribution which results in the maximum chip temperature. Figure 12 shows the maximum temperature under the worst-case power distribution as compared to the actual network peak temperature. We can see that worstcase estimation overestimates network peak temperature by about 5oC, which implies PowerHerd will begin to throttle network trafﬁc when the network peak temperature is 5oC lower than the thermal trigger threshold. Therefore, by targeting the temperature directly, ThermalHerd is much more efﬁcient than PowerHerd. 6 From On-chip Networks to Entire On-chip Systems On-chip systems, such as SoCs and CMPs, consist of computation and storage elements interconnected by onchip networks. Therefore, the chip temperature is an accuThres ho ld = 86C Thres ho ld = 84C Thres ho ld = 82C Thres ho ld = 80C 0.0% 1.0% 2.0% 3.0% 4.0% 5.0% 0 40 80 120 160 T ime (ms) T h r u p h g u o t g e d r a d a i t n o ( % ) Threshold = 86C Threshold = 84C Threshold = 82C Threshold = 80C Figure 9. Throughput degradation. 0.0% 0.2% 0.4% 0.6% 0.8% 1.0% 1.2% 0 40 80 120 160 T ime (ms) L a t y c n e e v o r d a e h ( % ) Figure 10. Latency overhead. GlobalThermal DistrThermal DistrThermal + reactive routing ThermalHer d 10.0% 9.0% 8.0% 7.0% 6.0% 5.0% 4.0% 3.0% 2.0% 1.0% 0.0% 84 85 86 87 88 89 90 91 92 93 94 Thermal emergency threshold (C) T h r u p h g u o t g e d r a d a i t n o ( % ) GlobalThermal DistrThermal DistrThermal + reac tive routing Therma lHer d Figure 11. Performance impact of throttling. 110 105 100 95 90 85 80 75 70 65 60 0 40 80 120 160 Time (ms) T e m e p r u a t r e ( C ) Wors t-case es timation Ac tual peak temperature Figure 12. Worst-case temperature estimation by PowerHerd vs. actual temperature proﬁle. mulated effect of the thermal interactions across all on-chip components. The relative thermal contribution of the different components varies depending on the chip architecture as well as application scenarios. The chip architecture determines the complexity of processing vs. storage vs. communication elements and thus the peak power consumption of these elements. A chip with complex processing elements (e.g., wide-issue, multi-threaded) will require larger storage elements (e.g., large multi-level caches, register ﬁles) as well as sophisticated communication elements (e.g., multi-level, wide buses, networks with wide link channels, deeply-pipelined routers and signiﬁcant router buffering). On the other extreme, there are chip architectures where processing elements are single ALUs serviced by a few registers at ALU input/output ports, interconnected with simple single-stage routers with little buffering. Application characteristics dictate how the above elements are used, thus inﬂuencing the power and thermal proﬁle of the chip. Essentially, the amount of computation and communication per data bit affects the relative power and thermal contribution of processing, memory and network elements. Here, we use the MIT Raw chip as a platform for analyzing the absolute and relative thermal impact of all components of a chip. The Raw chip, with its singleissue processing elements, 32KB caches and registers per tile, and networks with fairly narrow 32-bit channels, 8stage pipelines, and limited router buffering sits in the middle of two possible architectural extremes – a chip where processing elements are fat multi-threaded cores vs. one where processing elements are single ALUs, such as TRIPS cores. 6.1 Thermal Characterization of the Raw Chip In Raw, the chip temperature is affected by both on-chip processors and networks. In each tile, the processor power is mainly due to instruction and data caches, ALU, register ﬁle, fetch, and control logic. For each of these components, the capacitance is obtained from the estimates from an IBM placement tool [9]. Its run-time activities are captured using the Raw Beetle simulator. Based on the chip layout, we extend our network thermal model to on-chip Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  processors by representing each functional component as a thermal block and construct a lumped thermal RC network covering all the power-consuming components in the Raw chip. In Raw, switch memories, and instruction/data caches are synchronous SRAM modules that initiate read operations every clock cycle. Raw proposed a power-aware technique allowing individual SRAM lines to be disabled when not in use. Here, we characterize the chip temperature in both the power-aware and non-power-aware modes. As shown in Table 2, the current Raw binary distribution contains three sets of benchmarks – SPEC and Mediabench, stream computations, and bit-level computations. We choose benchmarks from all the three categories and study the thermal behavior of Raw 3 . In order to reveal the thermal impact of the run-time activities of the benchmarks themselves, we ﬁrst assume the power-aware feature is supported – switch memories are only active when static networks are used; instruction caches are only active during processor execution; data caches are accessed by both load and store operations. Figure 13 shows the thermal characterization of Raw using these benchmarks. For each benchmark, we consider both typical (300lfpm) and best (600lfpm) air-cooling conditions. The chip peak temperature is further characterized under three different power dissipation scenarios – processor power only, network power only, and processor plus network power. These results highlight the following observations: • First and foremost, the chip temperature is the joint contribution of all on-chip components. As we can see, among all the benchmarks, the processors or networks alone may not tip chip temperature over the thermal emergency point. However, together, the networks and processors can push the chip peak temperature to higher than 100oC. • The chip temperature is the result of thermal correlations between all on-chip components. For each onchip component, its thermal contribution is affected by its own power consumption as well as thermal correlation with other components. The former varies with architecture and applications. The latter is determined by the cooling package and physical distance. • Different benchmarks demonstrate different thermal behavior. Among the three sets of benchmarks, both the stream and bit-level computation benchmarks exhibit excellent scalability – they can effectively utilize on-chip parallel computation and communication resources, leading to a high chip temperature. Due to the limitation of the available compiler (rgcc) and the available ILP in the programs, the ILP in the SPEC and Mediabench benchmarks cannot be explored efﬁciently. Therefore, these benchmarks result in the on-chip resources being underutilized, thus having a lower thermal impact. The thermal impact of networks 3As thermal behavior is similar within a benchmark group, we arbitrarily picked just 2-3 benchmarks in each group to highlight differences across groups. vs. processors also varies for the different benchmarks. For instance, in 802.11a enc., 8b 10b enc., and ﬁr, due to the high utilization of the static networks and low access rate of on-chip data caches, the networks alone result in a comparable or higher temperature than the processors. On the other hand, stream results in high utilization of its processing resources; fft only uses the dynamic network partially. In these two cases, the processor thermal impact is more signiﬁcant. Figure 14 shows the chip peak temperature without power-awareness in the SRAM modules. Here, on-chip memories result in a signiﬁcant power and thermal overhead. 6.2 Extending ThermalHerd to Thermal Management of Entire On-Chip Systems The observations from the previous section highlight that coordinating and regulating the behavior of all on-chip components is the key to achieving effective thermal management for the entire chip. Since on-chip systems are distributed in nature, the distributed, collaborative nature of ThermalHerd lends readily to the thermal management of the entire chip. We discuss the extension of the two key features of ThermalHerd next – distributed throttling and thermal-correlation based routing. Distributed joint throttling: For Raw, effective thermal regulation requires jointly considering both the networks and processors. We extend the distributed trafﬁc throttling mechanism in ThermalHerd to distributed joint throttling of processing, storage and network elements in Raw. When the temperature monitors ﬂag a thermal emergency, the hotspot tile begins to throttle both the processor (processing and memory elements) and the network by controlling the grant signal of crossbar, instruction issue logic, and memory disable signals. Thermal-correlation based placement: Thermal emergencies are often a result of an unbalanced temperature proﬁle. Therefore, workload migration can potentially balance the temperature proﬁle and reduce the peak temperature. The thermal-correlation based routing scheme proposed in Section 4.5 targets network trafﬁc migration. For ) C ( e r u a t r e p m e T 120 100 80 60 40 20 0 (I): 300lfpm (II): 600lfpm Processor+network Processor alone Network alone fir(I) fir(II) fft(I) fft(II) str e a m (I) str e a m (II) 8 b _ 1 0 b e n c.(I) 8 b _ 1 0 b 8 0 2 . 1 1 a e n c .(I) e n c.(II) 8 0 2 . 1 1 a e n c .(II) v p r(I) v p r(II) g zi p (I) g zi p (II) a d p c m (I) a d p c m (II) m p e g (I) m p e g (II) Figure 13. Thermal characterization of Raw. (I): 300lfpm (II): 600lfpm 120 100 80 60 40 20 0 fir(I) fir(II) fft(I) fft(II) str e a m (I) str e a m (II) 8 b _ 1 0 b e n c.(I) 8 b _ 1 0 b e n c.(II) 8 0 2 .1 1 a e n c.(I) 8 0 2 .1 1 a e n c.(II) v p r(I) v p r(II) g zi p (I) g zi p (II) a d p c m (I) a d p c m (II) m p e g (I) m p e g (II) Figure 14. Peak temperature of Raw for various benchmarks, without power-awareness in SRAMs. ) C ( e r u a t r e p Table 2. Benchmarks provided by the Raw binary distribution. Benchmark set SPEC & Mediabench Stream Bit-level computations Description of benchmarks Targets instruction-level parallelism (ILP) Targets real-time I/O Targets comparisons with FPGAs and ASICs m e T Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  processors, previous work has explored computation migration in CMPs to improve the performance with a migration interval in the range of tens of microseconds [21], which matches the thermal time constant of on-chip thermal hotspots. Therefore, computation migration can be used to track and balance run-time thermal variations for on-chip computation resources – scheduler/OS dispatches computation jobs based on the thermal correlation matrix of processing elements to balance the run-time chip thermal proﬁle. Preliminary investigations: Concurrent tasks running on a parallel architecture, such as Raw, are more or less logically correlated. The inter-tile program correlation has a significant impact on run-time thermal management. First, distributed throttling minimizes performance degradation by only throttling those tiles that have the highest thermal impact locally. However, the inter-tile program correlation spreads the localized throttling effect to other tiles, thus degrading the throttling efﬁciency and overall performance. Second, to balance the chip thermal proﬁle, task placement needs to avoid adjacent tiles to minimize the inter-tile thermal impact. This increases not only the latency but also the power and thermal overhead for supporting data communication among correlated tasks. We explore the advantages and limitations of the above thermal management techniques. We design synthetic benchmarks to emulate two typical CMP applications: • Benchmark I: Tasks running on different tiles are independent, which emulates server-like workloads – onchip resources support multiple independent applications for different users. • Benchmark II: All tiles form a tightly coupled computation pipeline stream, which emulates multimedia streaming applications. As we can see, these two benchmarks are the two extreme cases in terms of inter-tile program correlation. First, we evaluate the performance of distributed joint throttling (DJT). We compare it with global throttling (GT), in which when a thermal emergency occurs, all the tiles are throttled in the same fashion. Figure 15 shows the performance degradation for these two techniques. For GT, each tile throttles 5% to 30% of system throughput, which is deﬁned as the overall ﬁnished workload. The x-axis shows the corresponding chip peak temperature reduction. As shown in the ﬁgure, for Benchmark I, to achieve the same temperature reduction, DJT results in much lower performance degradation by more efﬁciently throttling trafﬁc on those tiles that have a higher thermal impact on thermal hotspots. As the required temperature reduction increases further, more tiles need to be throttled in order to achieve enough temperature reduction. Hence, the gain of DJT reduces. For Benchmark II, since all the tiles are tightly correlated, throttling any individual tile results in the same performance impact on all the other tiles. Therefore, DJT has the same performance impact as GT. To evaluate the impact of thermal-correlation based placement on inter-tile program correlation, for each benchmark, we reduce the number of parallel tasks to four. As shown in Figure 16, for both benchmarks, initially, four tasks are placed in the four center tiles in Raw. To balance the thermal proﬁle, these four tasks are moved to the corner tiles. For Benchmark I, task reallocation effectively balances the chip thermal proﬁle and reduces the chip peak temperature by 13.8%. For Benchmark II, task reallocation also reduces the chip thermal gradient. However, the extra communication power results in a signiﬁcant power and thermal overhead, and increases the overall chip temperature. As a result, the chip peak temperature increases by 6.9%. In this case, placing the tasks as in Figure 16 achieves a temperature reduction of 3.5% by reducing the inter-task thermal correlation and avoiding the extra communication overhead. 7 Discussion and Related Work We next present discussions and related work. Interconnection networks: Substantial research has explored power consumption issues in interconnection networks. Patel et al. [15] ﬁrst developed power modeling techniques for routers and links. Wang et al. [28] developed an architecture-level power model, called Orion, for interconnection networks. In our work, we have integrated Orion into our network evaluation platform. For design optimization, most prior works used circuit-level techniques to improve the power efﬁciency of the link circuitry, such as low-swing on-chip links. Recently, power-efﬁcient onchip network design has also been addressed at the microarchitecture level [27]. Power-aware techniques, such as dynamic voltage scaling and dynamic power management, have been proposed [11, 19] to minimize the power consumption in the link circuitry. All the above techniques target average power, not peak power. Recently, a dynamic power management scheme, called PowerHerd [20], has been proposed to address network peak power issues. However, PowerHerd is power-aware instead of being thermal-aware. Even though power and temperature are correlated, they are still fundamentally different in nature. Thus, as demonstrated in the experimental results section, PowerHerd cannot address network thermal issues efﬁciently. Microprocessors: Power and thermal concerns in modern processors have led to signiﬁcant research efforts in power-aware and temperature-aware computing. Brooks et al. [3] ﬁrst proposed a dynamic thermal management scheme. Skadron et al. [22] further explored controltheoretic techniques for this purpose. They also developed an architecture-level thermal model, called HotSpot. In our work, we constructed a thermal model for on-chip networks, which is an improvement over HotSpot. Recently, Srinivasan et al. [24] used a predictive dynamic thermal management scheme targeting multimedia applications. J ) % ( n o i t a d a r g e d t u p h g u o r h T 35 30 25 20 15 10 5 0 Benchmark I (GT) Benchmark I (DJT) Benchmark II (GT) Benchmark II (DJT) 3.6 7.2 10.8 14.4 Peak temperature reduction (C) Figure 15. Distributed joint global throttling. 18 21.6 throttling vs. (a) Benchmark I(A) (b) Benchmark I(B) (c) Benchmark II(A) (d) Benchmark II(B) (e) Benchmark II(C) Figure 16. Thermal-correlation based placement. Proceedings of the 37th International Symposium on Microarchitecture (MICRO-37’04)  1072-4451/04 $ 20.00 IEEE  8 Conclusions Power and cooling costs are critical constraints in highperformance on-chip systems. With networks replacing onchip buses and becoming the pervasive on-chip interconnection fabric in SoCs and CMPs, we need to seriously address network thermal issues to guide on-chip network design and improve its thermal efﬁciency. In this work, we built an architecture-level thermal model, and constructed an architecture-level platform for jointly evaluating the network performance, power, and thermal proﬁle. We then characterized the computation and communication thermal impact in the MIT Raw CMP and revealed the importance of jointly considering both networks and processors for efﬁcient thermal design of onchip systems. To overcome the deﬁciencies of designing for the worst-case thermal signature, we proposed a distributed on-line thermal management scheme, called ThermalHerd, which can dynamically regulate the network temperature proﬁle and guarantee safe on-line operation. Finally, using Raw as a testbed, we explored extensions of our work to address the thermal issues for entire on-chip systems. This work is the ﬁrst study addressing thermal issues in on-chip networks. We hope this work will lead to thermal-efﬁcient network design, enabling network designers to build temperature-aware high-performance network microarchitectures. In this paper, we also illustrated how the distributed, collaborative nature of on-chip networks leads to distinct similarities with distributed on-chip systems and showed how thermal management of on-chip networks can be extended to entire on-chip systems. We see this work forming the foundation for studies of complete networked on-chip processing systems in the future. Acknowledgments The authors would like to thank Kevin Skadron and Wei Huang of University of Virginia for their help in our understanding of HotSpot. We wish to thank the MIT Raw group, especially Michael B. Taylor, for the help with the Raw simulation platform as well as providing us with critical packaging and power information of their chip. We also wish to thank Doug Burger of University of Texas at Austin for supplying us with TRIPS network trafﬁc traces. In addition, we wish to thank Howard Chen of IBM for helping us validate our thermal model. This work was supported in part by Princeton University’s Wallace Memorial Honoriﬁc, National Science Foundation under Grant No. CCR0237540 (CAREER) and CCR-0324891, as well as the MARCO Gigascale Systems Research Center. "
2013,Methods for fault tolerance in networks-on-chip.,"Networks-on-Chip constitute the interconnection architecture of future, massively parallel multiprocessors that assemble hundreds to thousands of processing cores on a single chip. Their integration is enabled by ongoing miniaturization of chip manufacturing technologies following Moore's Law. It comes with the downside of the circuit elements' increased susceptibility to failure. Research on fault-tolerant Networks-on-Chip tries to mitigate partial failure and its effect on network performance and reliability by exploiting various forms of redundancy at the suitable network layers. The article at hand reviews the failure mechanisms, fault models, diagnosis techniques, and fault-tolerance methods in on-chip networks, and surveys and summarizes the research of the last ten years. It is structured along three communication layers: the data link, the network, and the transport layers. The most important results are summarized and open research problems and challenges are highlighted to guide future research on this topic.",
2005,A unified approach to constrained mapping and routing on network-on-chip architectures.,"One of the key steps in Network-on-Chip (NoC) based design is spatial mapping of cores and routing of the communication between those cores. Known solutions to the mapping and routing problem first map cores onto a topology and then route communication, using separated and possibly conflicting objective functions. In this paper we present a unified single-objective algorithm, called Unified MApping, Routing and Slot allocation (UMARS). As the main contribution we show how to couple path selection, mapping of cores and TDMA time-slot allocation such that the network required to meet the constraints of the application is minimized. The time-complexity of UMARS is low and experimental results indicate a run-time only 20% higher than that of path selection alone. We apply the algorithm to an MPEG decoder System-on-Chip (SoC), reducing area by 33%, power by 35% and worst-case latency by a factor four over a traditional multi-step approach.","A Uni ﬁed Approach to Constrained Mapping and Routing on Network-on-Chip Architectures Andreas Hansson Dept. of Information Technology Lund University, Box 118, 221 00 Lund, Sweden hansson@natlab.research.philips.com Kees Goossens Philips Research Laboratories Prof. Holstlaan 4, 5656 AA Eindhoven, The Netherlands kees.goossens@philips.com Andrei R ˘adulescu Philips Research Laboratories Prof. Holstlaan 4, 5656 AA Eindhoven, The Netherlands andrei.radulescu@philips.com ABSTRACT One of the key steps in Network-on-Chip (NoC) based design is spatial mapping of cores and routing of the communication between those cores. Known solutions to the mapping and routing problem ﬁrst map cores onto a topology and then route communication, using separated and possibly conﬂicting ob jective functions. In this paper we present a uniﬁed single-ob jective algorithm, called Uniﬁed MApping, Routing and Slot allocation (UMARS). As the main contribution we show how to couple path selection, mapping of cores and TDMA time-slot allocation such that the network required to meet the constraints of the application is minimized. The time-complexity of UMARS is low and experimental results indicate a run-time only 20% higher than that of path selection alone. We apply the algorithm to an MPEG decoder System-on-Chip (SoC), reducing area by 33%, power by 35% and worst-case latency by a factor four over a traditional multi-step approach. Categories and Sub ject Descriptors: B.4.3 [Input/Output and Data Communications]: Interconnections – Topology General Terms: Design, Algorithms, Performance Keywords: System-on-Chip, Network-on-Chip, Quality-ofService, Mapping, Routing 1. INTRODUCTION Systems-on-Chip (SoC) grow in size with the advance of semiconductor technology enabling integration of dozens of cores on a chip. The continuously increasing number of cores calls for a new communication architecture as traditional architectures are inherently non-scalable, making communication a bottleneck [1, 21]. System architectures are shifting towards a more communication-centric methodology [21]. Growing SoC complexity makes communication subsystem design as important as computation subsystem design [2]. The communication infrastructure must eﬃciently accommodate the communication needs of the integrated computation and storage elements. In application domains such as multi-media processing, the bandwidth requirements are already in the range of several hundred Mbps and are continuously growing [17]. Networks-on-Chip (NoC) have emerged as the design paradigm for design of scalable on-chip communication architectures, providing better structure and modularity [1, 3, 7, 21]. Although NoCs solve the interconnect scalability issues, SoC integration is still a problem. To enable cores to be designed and validated independently, computation and communication must be decoupled [20]. Decoupling requires well deﬁned communication services [13]. Service guarantees are essential in many SoCs as numerous application domains require real-time performance [20]. Quality-of-Service (QoS) guarantees enable independent design and validation of every part of the SoC by ensuring that real-time application requirements are met under all circumstances [7]. Creating a NoC-based system with guaranteed services requires eﬃcient mapping of cores and distribution of NoC resources. Design choices include core port to network port binding, routing of communication between cores and allotment of network channel capacity over time. These choices have signiﬁcant impact on energy, area and performance metrics of the system. Existing solutions rely on a multi-step approach where mapping is carried out before routing [7, 12, 19]. Routing and mapping ob jectives do hereby not necessarily coincide. The routing phase must adhere to decisions taken in the mapping phase which invariably limits the routing solution space. Mapping therefore signiﬁcantly impacts energy and performance metrics of the system [12]. We propose a uniﬁed algorithm, called Uniﬁed MApping, Routing and Slot allocation (UMARS), that couples mapping, path selection and time-slot allocation, using a single consistent ob jective. The time-complexity of UMARS is low and experimental results indicate a run-time only 20% higher than that of path selection alone. We apply the algorithm to an MPEG decoder SoC, reducing area by 33%, power by 35% and worst-case latency by a factor four over a traditional multi-step approach. The problem domain is described in Section 3 and formalized in Section 4. The UMARS algorithm, which solves the uniﬁed allocation problem under application constraints, is described in Section 5. Experimental results are shown in Section 6. Finally, conclusions are drawn in Section 7. 2. RELATED WORK Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’05, Sept. 19–21, 2005, Jersey City, New Jersey, USA. Copyright 2005 ACM 1-59593-161-9/05/0009 ...$5.00. QoS routing ob jectives are discussed in [9, 22] and implications with common-practice load-balancing solutions are addressed in [16]. In addition to spatial, temporal characteristics are included in path selection in [8, 10]. The problem of mapping cores onto NoC architectures is addressed in [7, 11, 12, 17, 18, 19]. In [11] a branch-and-bound algorithm is used to map cores onto a tile-based architecture, aiming to minimize energy while bandwidth constraints are satisﬁed. Static xy routing is used in this work. In [12] the algorithm is extended to route with the ob jective of balancing network load. In [17, 18, 19] a heuristic improvement method is used. An initial mapping is derived with ob jectives such as minimizing communication delay, area or power dissipation. This is succeeded by routing according to a predeﬁned routing function. Routing and evaluation is repeated for pair-wise swaps of nodes in the topology, thereby exploring the design space in search for an eﬃcient mapping. In [19] the algorithm integrates physical planning and QoS guarantees. Design space exploration is improved with a robust tabu search. In all these approaches [11, 12, 17, 18, 19], multiple mapping and routing solutions are evaluated iteratively to mitigate the negative eﬀects mapping decisions may have on routing. A greedy non-iterative algorithm is presented in [7]. Mapping is done based on core clustering whereafter communication is routed using static xy routing. Known mapping and routing algorithms that incorporate QoS guarantees [10, 19] assume static communication ﬂows, where traﬃc does not vary with input data. In this work, our methodology uniﬁes the three resource allocation phases: spatial mapping of cores, spatial routing of communication, and the restricted form of temporal mapping that assigns time-slots to these routes. We consider the communication real-time requirements, and guarantee that application constraints on bandwidth and latency are met. The proposed solution is fundamentally diﬀerent from [7, 11, 12, 17, 18, 19] in that mapping is no longer done prior to routing but instead during it. However, we compare UMARS only to [7], and a more extensive comparison with traditional algorithms [11, 12, 17, 18, 19] is of value. 3. PROBLEM DESCRIPTION We assume that the application is mapped onto cores. The bandwidth and latency constraints of the application ﬂows are determined beforehand by means of static analysis or simulation. Our problem is to: 1) map those cores onto any given NoC topology, 2) statically route the communication and 3) allocate TDMA time-slots on network channels so that application constraints are met. Services are provided on the level of ﬂows where a ﬂow is a sequence of packets being sent from a source to a destination. Regular, as well as irregular topologies are supported to enable dedicated solutions. Two important requirements can be identiﬁed and the onus is, in both cases, on the mapping and routing phases. Firstly, the constraints of individual ﬂows must be satisﬁed. These constraints must hence be reﬂected in the selection of mapping, path and time slots such that proper resources are reserved. Secondly, all ﬂows must ﬁt within the available network resources. Failure in allocating a ﬂow is attributable to non-optimal previous allocations or insuﬃcient amounts of network resources. This calls for conservation of the ﬁnite pool of resources, namely the channels and their time-slots. This paper shows how path selection can be extended to span also mapping and time-slot allocation. This enables the aforementioned requirements to be formulated as path selection constraints and optimization goals. 4. PROBLEM FORMULATION The application is characterized by an application graph. Deﬁnition 1. An application graph is a directed multigraph, A(P, F ), where the vertices P represent the set of cores, and the arcs F represent the set of ﬂows between cores. More than a single ﬂow is allowed to connect a given pair of cores and no core is isolated. Each ﬂow f ∈ F is associated with a minimum bandwidth constraint measured in number of slots, b(f ), and a maximum latency constraint, l(f ). Let s(f ) denote the source node of f and d(f ) destination node. To be able to constrain mapping according to physical layout requirements, we group the cores in P and map groups instead of individual cores. UMARS is thereby forced to map certain cores to the same spatial location. The mapping groups correspond to a partition PM of P , where the elements of PM are jointly exhaustive and mutual ly exclusive. The equivalence relation this partition corresponds to, considers two elements in P to be equal if they must be mapped to the same spatial location. The equivalence class of a core p is hereafter denoted by [p]. NoCs are represented by interconnection network graphs. Deﬁnition 2. An interconnection network graph I is a strongly connected directed multigraph, I (N , C ). The set of vertices N is composed of three mutually exclusive subsets, NR , NN I and NP containing routers, network interfaces (NI) and core mapping nodes as shown in Figure 1. The latter are dummy nodes to allow unmapped cores to be integrated in the interconnection graph. The number of core mapping nodes is equal to the number of core subsets to be mapped, |NP | = |PM |. The set of arcs C is composed of two mutually exclusive subsets, CR and CP containing physical network channels and virtual mapping channels. Channels in CR interconnect nodes in NR and NN I according to the physical router network architecture. Channels in CP interconnect every node in NP to al l nodes in NN I . More than a single physical channel is allowed to connect a given pair of routers. However, an NI nN I is always connected to a single router through one egress channel cE (nN I ) ∈ CR and one ingress channel cI (nN I ) ∈ CR , as depicted in Figure 1. The time division of network channel capacity is governed by slot tables. These tables are used to set up pipelined virtual circuits and divide bandwidth between ﬂows [20]. A slot table is a sequence of elements in T = F ∪ {∅}. Slots are either occupied by a ﬂow f ∈ F or empty, represented by ∅. The number of residual slots in a slot table t is denoted σ(t). The same slot table size ST is used throughout the entire network. Each channel c ∈ C is associated with the bandwidth not yet reserved (residual bandwidth) measured in number of slots, β (c), and a slot table, t(c). Let s(c) denote the source node of c and d(c) destination node. As residual bandwidth and slot tables change over iterations, I is subscripted with an index. I0 denotes the initial network where β (c) = ST and every slot in t(c) is empty for every channel c ∈ C . Deﬁnition 3. A path π ∈ seq C from source ns ∈ N to destination nd ∈ N is a non-empty sequence of channels (cid:4)c1 , . . . , ck (cid:5) such that: 1. d(ci ) = s(ci+1 ) for k = 1 . . k − 1 2. s(head π) = ns and d(last π) = nd . A path π = (cid:4)c1 , . . . , ck (cid:5) is associated with an aggregated slot table t(π). Every channel slot table t(ci ), i = 1 . . k , is shifted cyclically i − 1 steps left and a slot in t(π) is empty iﬀ it is empty in al l shifted slot tables [20]. (a) IP1 IP2 NM P P IP3 I0 map0 P (cid:2) 0 ∅ = cE (cid:4)∅, ∅, ∅(cid:5) cI (cid:4)∅, ∅, ∅(cid:5) R I1 map1 P (cid:2) 1 → → ⊆ NI NI → → ⊆ cE (cid:4)f1 , ∅, ∅(cid:5) cI (cid:4)∅, ∅, f1(cid:5) R (b) IP1 IP2 P P IP3 NI NI . . . . . . . . . (c) IP1 IP2 cE (cid:4)f1 , f2 , f2 (cid:5) cI (cid:4)f2 , ∅, f1(cid:5) R NI NI IP3 P P → → ⊆ Ik mapk P (cid:2) k = {IP1 , IP2 , IP3} = P Figure 1: Iteration and successive reﬁnement of mapping and interconnection network Deﬁnition 4. For a source and destination node ns , nd ∈ N , Π(ns , nd ) is the set of all possible paths from ns to nd . f on π whereafter mapi and Ii are reﬁned to reﬂect the new state. The procedure is repeated until all ﬂows are allocated. mappable nodes NM = NN I ∪ NP as shown in Figure 1(a). The NIs and core mapping nodes together form the set of NM contains all nodes to which the elements of PM can be mapped. We deﬁne a mapping function, mapi : PM → NM , that maps sets of cores (the elements in PM ) to mappable nodes. Like I , this function is iterated over, hence the index. [p] ∈ PM is mapped to a unique nP ∈ NP . Our starting point is an initial mapping, map0 , where every As seen in Figure 1(a), the range of map0 initially covers only NP . As the algorithm progresses (b), the range of mapi covers both NP and NN I partially. Successive iterations of mapi progressively replace elements of NP with elements of NN I until a ﬁnal mapping is derived (c), where the range of mapk contains elements of NN I exclusively. Let the set of mapped cores P (cid:2) i denote those elements of P where mapi ([p]) ∈ NN I . From our deﬁnition of map0 it follows that P (cid:2) 0 = ∅. 4.1 UMARS contribution We now introduce a ma jor change from previous work and formulate mapping and path selection problem as a pure path selection problem. Given an interconnection network I0 and an application graph A, we must select a path π for every ﬂow f ∈ F such that bandwidth (1) and latency (2) requirements of the ﬂow are met without overallocating the network channels (3). bandwidth of t(π) ≥ b(f ) latency of t(π) ≤ l(f ) β (c) ≥ 0, ∀c ∈ C The theory required to derive worst-case bandwidth and latency from a slot table is covered in [5]. (2) (3) (1) 5. UNIFIED MAPPING AND ROUTING The outmost level of UMARS is outlined in Algorithm 5.1 and brieﬂy introduced here, whereafter further explanations follow in Sections 5.1 and 5.2. UMARS iterates over the monotonically decreasing set of unallocated ﬂows F (cid:2) i and never back-tracks to reevaluate an already allocated ﬂow, as seen in Step 2a. This results in a low time-complexity at the expense of optimality. The ﬂow f is selected based on the current mapping mapi and network Ii . When a path π is selected for f in Step 2b, the ﬁrst and last channel implicitly determine what NI s(f ) and d(f ) should be mapped to respectively. Time-slots are allocated to Algorithm 5.1 Allocation of all ﬂows F 1. Let the set of unallocated ﬂows F (cid:2) 0 = F 2. While F (cid:2) i (cid:10)= ∅: (b) Select a path π ∈ Π(s(f ), d(f )) (a) Get ﬂow arg maxf ∈F (cid:2)(cid:2) b(f ) (c) F (cid:2) i+1 = F (cid:2) i \ {f } 5.1 Flow traversal order We order ﬂows by bandwidth requirements as it: 1) helps in reducing bandwidth fragmentation [16], 2) is important from an energy consumption and resource conservation perspective since the beneﬁts of a shorter path grow with communication demands [12], 3) gives precedence to ﬂows with a more limited set of possible paths [12]. Ordering by b(f ) alone may aﬀect resource consumption negatively as clusters of communicating cores are disregarded. Consideration is taken by limiting the selection to ﬂows having s(f ) or d(f ) mapped to a node in NN I . As a result, every cluster of communicating cores have their ﬂows allocated in sequence. A similar approach is used in [17, 18] where the next core is selected based on communication to already mapped cores. Due to the nature of the least-cost path selection algorithm, explained in Section 5.2.2, we restrain the domain even more and only consider ﬂows where s(f ) ∈ P (cid:2) i . This restriction can be removed if path selection is done also in the reverse direction, from destination to source. The next ﬂow is chosen according to Equation (4), where iﬀ f ∈ F (cid:2) i ∧ s(f ) ∈ P (cid:2) not fulﬁlled by any ﬂow, the entire F (cid:2) i . When the latter condition is i is used as domain. b(f ) arg max f ∈F (cid:2)(cid:2) f ∈ F (cid:2)(cid:2) (4) i 5.2 Path selection When a ﬂow f is chosen, we proceed to Step 2b of Algorithm 5.1 and select a path for f . This is done according to Algorithm 5.2, brieﬂy presented here, followed by in-depth discussions in Sections 5.2.1 through 5.2.5. Path selection for f is composed of three ma jor tasks: 1) Speculative bandwidth reservations for f are restored in Steps 1 and 2 to have Ii reﬂect what resources are available to f prior to its allocation. Speculative reservations are required as interdependent ﬂows are not allocated simultaneously and are further discussed in Section 5.2.1. 2) A path from s(f ) Algorithm 5.2 Path selection for a given f 1. If s(f ) ∈ P (cid:2) i , restore bandwidth reservation on egress channel by adding (cid:12)b(f )(cid:13) to β (cE (mapi ([s(f )]))) 2. If d(f ) ∈ P (cid:2) channel by adding (cid:12)b(f )(cid:13) to β (cI (mapi ([d(f )]))) i , restore bandwidth reservation on ingress 3. Select a constrained least-cost path πs from mapi ([s(f )]) to the router nR ∈ NR with lowest cost. Arity is used to distinguish between routers with equal cost. 4. If s(f ) /∈ P (cid:2) i , then (a) Reﬁne mapi+1 = mapi ⊕ {[s(f )] (cid:15)→ d(head πs )} (b) Reserve egress bandwidth for all ﬂows emanating P (cid:12)b(fE )(cid:13) from from [s(f )] by subtracting β (cE (d(head πs ))) where fE ∈ FE iﬀ s(fE ) ∈ [s(f )] and fE (cid:10)= f (c) Reserve ingress bandwidth for all ﬂows inciP (cid:12)b(fI )(cid:13) from dent to [s(f )] by subtracting β (cI (d(head πs ))) where fI ∈ FI iﬀ d(fI ) ∈ [s(f )] 5. Select a constrained least-cost path πd from d(last πs ) to mapi ([d(f )]) 6. If d(f ) /∈ P (cid:2) i , then (a) Reﬁne mapi+1 = mapi ⊕ {[d(f )] (cid:15)→ s(last πd )} (b) Reserve egress bandwidth for all ﬂows emanating P (cid:12)b(fE )(cid:13) from from [d(f )] by subtracting β (cE (s(last πd ))) where fE ∈ FE iﬀ s(fE ) ∈ [d(f )] (c) Reserve ingress bandwidth for all ﬂows inciP (cid:12)b(fI )(cid:13) from dent to [d(f )] by subtracting β (cI (s(last πd ))) where fI ∈ FI iﬀ d(fI ) ∈ [d(f )] and fI (cid:10)= f 7. Select a constrained set of slots TS in t(π) for the complete path π = πs (cid:5) πd and update t(c), ∀c ∈ π . Do a ﬁnal bandwidth reservation by subtracting |TS | from β (c), ∀c ∈ π . fE ∈FE fI ∈FI fE ∈FE fI ∈FI to d(f ) is selected in Steps 3 and 5, a procedure elaborated on in Section 5.2.2. If s(f ) or d(f ) are not yet mapped to NIs, these steps include reﬁnement of mapi , which is covered in Section 5.2.4. If mapi is reﬁned, then bandwidth reservations are made on ingress and egress channels for ﬂows other than f now having their source or destination mapped to an NI. 3) Time-slots are selected and reserved on the resulting path π , as discussed in Section 5.2.5. 5.2.1 Bandwidth reservation When s(f ) for a ﬂow f is mapped to an NI, the communication burden placed on the ingress and egress channels of the NI is not determined by f only. As every p in [s(f )] is ﬁxed to this NI, the aggregated communication burden of all ﬂows incident to those cores is placed on the ingress channel. The egress channel similarly has to accommodate all ﬂows emanating from those cores. When d(f ) is mapped, all ﬂows to or from [d(f )] must be accounted for accordingly. Failing to acknowledge the above might result in overallocation of network resources. Numerous ﬂows, still not allocated, may be forced to use the ingress and egress channel due to an already ﬁxed mapping. An NI would thereby be associated with an implicit load, not accounted for when evaluating possible paths. We make this load explicit by exploiting knowledge of ingress-egress pairs. Although we have no knowledge of exactly what time slots will be needed by future ﬂows, we can estimate the bandwidth required by (cid:12)b(f )(cid:13) and incorporate average load β (c) in the cost function, further discussed in Section 5.2.3. Steps 1 and 2 of Algorithm 5.2 restore the speculative reservations for f on egress and ingress channel to have Ii reﬂect what resources are available prior to its allocation. The corresponding bandwidth reservations on egress and ingress channels are carried out in Steps 4b, 4c and Steps 6b, 6c for source and destination NI respectively. 5.2.2 Selecting constrained least-cost path Steps 3 and 5 of Algorithm 5.2 select a constrained leastcost path using Dijkstra’s algorithm. Two minor modiﬁcations are done to the standard relaxation procedure, where πp denotes the partial path from s(f ) emanating channels where β (c) < b(f ) or σ(t(πp (cid:5) (cid:4)c(cid:5))) < to the current node: 1) Search space is pruned by discarding b(f ). Channels that cannot meet bandwidth constraints are thereby omitted. 2) As the ﬁnal path must contain only physical network resources, channels in CP may only be the ﬁrst or last element of a path. Hence, if d(last πp ) ∈ NP then all emanating channels are discarded. The NI architecture requires a path to incorporate at least one physical channel as packets cannot turn around inside an NI. From a least-cost perspective the best path from an NI to itself would be the empty path and we force the algorithm into leaving the NI by doing path selection in two steps. The ﬁrst part of the path πs is selected in Step 3 of Algorithm 5.2. We start at s(f ) and ﬁnd the router with the lowest cost. If several such routers exist, then arity is used to distinguish between them. Routing ﬂexibility is thereby maximized and the ﬂows with the highest communication volume have their s(f ) and d(f ) mapped to NIs connected to high arity routers as suggested in [18]. The second part of the path πd is selected in Step 5, starting where πs ended. From there we continue to the location where d(f ) is currently mapped. The complete path is then just the two parts concatenated, π = πs (cid:5) πd . Deriving π as two separate least-cost parts might, without further care, lead to a path which is not the least-cost path in Π(s(f ), d(f )) as minimization is done on the parts in isolation. However, if a ﬂow f has s(f ) ∈ P (cid:2) i then there is only one possible least-cost router and hence only one possible πs . As this πs is a part of any path in Π(s(f ), d(f )) and πd is a least-cost path, π must be a least-cost path in Π(s(f ), d(f )). We therefore prefer allocating ﬂows where s(f ) ∈ P (cid:2) i , as discussed in Section 5.1. 5.2.3 Choice of cost function The cost function plays a critical role in meeting the requirements discussed in Section 3. It therefore reﬂects both resource availability and resource utilization. We select a path with a low contention (high probability of successful allocation) and at the same time try to keep the path length short, not to consume unnecessarily many resources. Similar heuristics are suggested in [14, 15, 22]. Double ob jective path optimization in general is an intractable problem [9]. Combining ob jectives in one cost function allows for tractable algorithms at the cost of optimality. We therefore use a linear combination of the two cost measures, where two constants Γc and Γh control the importance (and normalization) of contention and hop-count respectively. Contention is traditionally incorporated by making channel cost inversely proportional to residual bandwidth, thereby considering only average load. When using pipelined virtual circuits [20], average load is not reﬂecting what resources are available to the current ﬂow. Not even the slot 1 β (c) , table t(c) itself provides an accurate view. We exploit knowledge of the partial path πp traversed so far and determine contention cost for a channel c by how much t(c) reduces the amount of available slots compared to t(πp ) if c is traversed. Available bandwidth is incorporated by taking the maximum of the two as contention measure, according to Equation (5). Γc max {SL − β (c), σ(t(πp )) − σ(t(πp (cid:5) (cid:4)c(cid:5)))} + Γh Channels in CP must not contribute to the path cost, as they are not physical interconnect components. We therefore make them zero-cost channels. (5) 5.2.4 Reﬁning mapping function When a path πs has been selected for a ﬂow f , we check in Step 4 of Algorithm 5.2, whether s(f ) is not yet mapped to an NI. If not, πs decides the NI to which the core is to be mapped. We therefore reﬁne the current mapping function with the newly determined mapping to a node in NN I as seen in Step 6a. This reﬁnement is ﬁxed and every core in [s(f )] is now in P (cid:2) i . Correspondingly we check if d(f ) is not yet mapped to an NI in Step 6 and if not, reﬁne the mapping according to πd in Step 6a. 5.2.5 Resource reservation When the entire path π is determined in Step 7 of Algorithm 5.2, we deduce the slots available to f by looking at t(π). From the empty slots we select a set of slots TS such that bandwidth and latency requirements of f are met [5]. All channels c ∈ π are then updated with a new t(c) and β (c). Slot tables hereafter reﬂect what slots are reserved to f and β (c) is updated with the actual number of slots used. 5.3 Algorithm termination P (cid:2) With each reﬁnement of the mapi , zero, one or two addiof NP , hence P (cid:2) tional sets of cores will be mapped to elements of NN I instead i+1 ⊇ P (cid:2) i , as depicted in Figure 1. Theorem 1. ∃k such that al l cores are mapped to NIs, k = P . so that s(f ) and d(f ) are guaranteed to be in P (cid:2) Proof. When a ﬂow is f allocated, mapi will be reﬁned i . Hence, for every allocated ﬂow f /∈ F (cid:2) i we know that s(f ), d(f ) ∈ P (cid:2) When all ﬂows are allocated F (cid:2) k = ∅, s(f ) and d(f ), ∀f ∈ F i . will be in P (cid:2) k . As no isolated cores are allowed in A it follows that P = P (cid:2) k . 5.4 Algorithm complexity Due to the greedy nature of UMARS the time-complexity is very low, as seen in Equation (6). The expression is dominated by the ﬁrst term that is attributable to Dijkstra’s algorithm, used for path selection. Experiments indicate that algorithm run-time is only 20% higher than that of loadbalancing path selection alone. O(|F |(|C | + |N | log |N |)) + O(|F |(|F | + |P | + ST )) (6) 6. EXPERIMENTAL RESULTS A cost function where Γc = 1 and Γh = 1 is used throughout the experiments. Those values favor contentionbalancing over hop-count as the slot table size is an order of magnitude larger than network diameter in all use-cases. All results are compared with the traditional multi-step algorithm in [7], referred to as original. a given slot table size ST , all unique n × m router networks For comparison, only mesh topologies are evaluated. For with less than 25 routers were generated in increasing size order. For every such router network, up to three NIs were attached to each router until all application ﬂows were allocated, or allocation failed. Slot table size was incremented until allocation was successful. Each design was simulated during 3 × 106 clock cycles in a ﬂit-accurate SystemC simulator of our NoC, using traﬃc generators to mimic core behavior. The mpeg use-case is a MPEG codec SoC, further described in Section 6.2. The uniform use-case features all-to-all communication with 20 cores and a total aggregated bandwidth of 750 Mbps per core. The remaining use-cases are internal designs, all having a hot-spot around a limited set of cores. 6.1 Evaluation experiments Silicon area requirements are based on the model presented in [6], assuming a 0.13 μm CMOS process. Figure 2 shows that area requirements can be signiﬁcantly reduced. Up to 33% in total area reduction is observed for the experiment applications. Slot table sizes are reduced why the buﬀer requirements, analytically derived as described in [7], decrease, and area savings up to 31% are observed for the NIs. The router network is reduced between 30% and 75%, but the impact on total area is much smaller. ) 2 m m ( a e r A 8 7 6 5 4 3 2 1 0 Network interfaces, original Network interfaces, UMARS Routers, original Routers, UMARS mpeg uniform s1m1p2 s1m2p2 s8m1p2 s8m2p2 Figure 2: Comparison of area requirements. The relative energy consumption of the router network, calculated according to the model in [4] is depicted in Figure 3. As the application remains the same and essentially the same bits are being communicated, the savings in energy consumption is attributable to ﬂows being allocated on paths with fewer hops. There is a clear correlation between energy saving ratio and relative reduction in number of routers. However, as the smaller router network is used more extensively, energy is reduced less than the number of routers. o i t a r l a n g i i r o / S R A M U 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Energy consumption Number of routers mpeg uniform s1m1p2 s1m2p2 s8m1p2 s8m2p2 Figure 3: Comparison of energy consumption. Figure 4 shows the average utilization of channels emanating from NIs and routers respectively. As expected, utilization increase as router network size is reduced and UMARS     consequently improves both NI and router utilization. Timedivision-multiplexed circuits imply bandwidth discretization, leading to inevitable over-allocation and complicating the task of achieving high utilization. This together with unbalanced hot-spot traﬃc, leaving some parts of the network lightly loaded and others congested, lead to inherent low utilization in some of the example use-cases. Note that utilization is only to be optimized after all constraints are met. ) % ( n o i t a z i l i t U 80 70 60 50 40 30 20 10 0 Network interfaces, original Network interfaces, UMARS Routers, original Routers, UMARS mpeg uniform s1m1p2 s1m2p2 s8m1p2 s8m2p2 Figure 4: Comparison of NoC resource utilization. 6.2 An MPEG application An existing MPEG codec SoC with 16 cores constitutes our design example and results are shown in Table 1. The architecture uses a single external SDRAM with three ports to implement all communication between cores. A total of 42 ﬂows tie the cores together. Using the design ﬂow presented in [7] (clustered mapping, xy routing and greedy slot allocation) results in a 2 × 3 mesh, referred to as clustering in Table 1, with a total estimated area of 2.35 mm2 . For comparison, a naive mapping with one core partition per NI is almost double in size, whereas the worst-case write latency remains more or less unaﬀected. A manually optimized mapping manages to reduce the network area with 21% and an almost four-fold reduction of the average worst-case write latency is observed [7]. UMARS arrives at a mesh of equal size to what is achieved using the manually optimized mapping. Fewer NIs are needed leading to reductions in router area. Smaller buﬀer requirements, attributable to less bursty time-slot allocation, results in reduced NI area. Total area is reduced by 17% and average worst-case latency by 4% compared to the optimized handcrafted design. The solution is achieved in less than 100 ms on a 500 MHz Solaris UltraSparc IIe. Only a 20% increase in run-time is observed when compared to pure load-balancing path selection, without mapping and slot allocation. Table 1: Comparison of MPEG NoCs NI Router Total Area Avg wc Generation Mesh Slots area area area diﬀ latency clustering 2x3 128 1.83 0.51 2.35 ref 1570 ns naive 3x6 128 2.17 2.32 4.49 +91% 1583 ns 1.86 −21% 399 ns optimized 1x3 8 1.51 0.35 1.57 −33% 383 ns UMARS 1x3 8 1.26 0.32 7. CONCLUSION AND FUTURE WORK In this work we have presented the UMARS algorithm which integrates the three resource allocation phases: spatial mapping of cores, spatial routing of communication and TDMA time-slot assignment. The algorithm is decomposed into a hierarchical structure where mapping is no longer done prior to routing but instead during it. UMARS improves over existing mapping and routing algorithms by using a single consistent ob jective-function. The time-complexity of UMARS is low and experimental results indicate a run-time only 20% higher than that of path selection alone. We apply the algorithm to an MPEG decoder SoC, improving area 33%, power 35% and worst-case latency by a factor four over a traditional multi-step approach. The importance of the ﬂow traversal order and the objective function are not yet fully evaluated and both play a critical role in improving on the moderate results achieved in some use-cases. To allow a more extensive design space exploration for both mapping and routing, UMARS can be extended to a k-path algorithm, enabling a trade-oﬀ between complexity and optimality. 8. "
2003,Towards on-chip fault-tolerant communication.,"As CMOS technology scales down into the deep-submicron (DSM) domain, devices and interconnects are subject to new types of malfunctions and failures that are harder to predict and avoid with the current system-on-chip (SoC) design methodologies. Relaxing the requirement of 100% correctness in operation drastically reduces the costs of design but, at the same time, requires SoCs be designed with some degree of system-level fault-tolerance. In this paper, we introduce a high-level model of DSM failure patterns and propose a new communication paradigm for SoCs, namely stochastic communication. Specifically, for a generic tile-based architecture, we propose a randomized algorithm which not only separates computation from communication, but also provides the required fault-tolerance to on-chip failures. This new technique is easy and cheap to implement in SoCs that integrate a large number of communicating IP cores.","Towards On-Chip Fault-Tolerant Communication∗ Tudor Dumitras¸ Sam Kerner Radu M ˘arculescu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA {tdumitra, skerner, radum}@ece.cmu.edu Abstract — As CMOS technology scales down into the deepsubmicron (DSM) domain, devices and interconnects are subject to new types of malfunctions and failures that are harder to predict and avoid with the current system-on-chip (SoC) design methodologies. Relaxing the requirement of 100% correctness in operation drastically reduces the costs of design but, at the same time, requires SoCs be designed with some degree of system-level faulttolerance. In this paper, we introduce a high-level model of DSM failure patterns and propose a new communication paradigm for SoCs, namely stochastic communication. Speciﬁcally, for a generic tile-based architecture, we propose a randomized algorithm which not only separates computation from communication, but also provides the required fault-tolerance to on-chip failures. This new technique is easy and cheap to implement in SoCs that integrate a large number of communicating IP cores. I . IN TRODUC T ION As modern VLSI chips are getting more complex, the designers are facing new challenges. Semi-custom ASICs have evolved into complicated systems-on-chip (SoCs) where dozens, and soon hundreds of pre-designed IPs are assembled together to form large chips with complex functionality. Extensive research on how to integrate and connect these IPs is currently being conducted [12], but many questions remain open, as these issues are very difﬁcult to address within the existing framework of CAD tools. It is clear that new design methodologies are required to deal with these arising problems. As emphasized in the ITRS 2001 document [14], it is very important, especially at system-level, to separate the computation from communication, as they are orthogonal issues which should remain separate whenever possible. Henceforth, SoC design should resemble the creation of large-scale communication networks rather than traditional IC design practice. Furthermore, as the CMOS technology scales down into the nanometer domain, many factors will inﬂuence the cost and performance of VLSI designs [11]. Critical leakage currents and high ﬁeld effects will lead to more transient and permanent failures of signals, logic values, devices, and interconnects [15]. These effects have a negative inﬂuence on ∗Research supported by NSF CCR-00-93104, DARPA/Marco Gigascale Research Center (GSRC), and SRC 2001-HJ-898. the interconnect delay and the existing timing models cannot be used anymore. Even with the emergence of new wiring technologies, like the recent copper wiring process developed by IBM [16], the IC designers are still facing the problem that the existing CAD tools and methodologies are no longer efﬁcient in preventing pathologic behavior. This suggests that chips have to be designed with some built-in fault-tolerance. Relaxing the requirement of 100% correctness in operation for devices and interconnects when designing chips may also dramatically reduce the costs of manufacturing, veriﬁcation, and test [14]. Distributed computing has dealt with fault-tolerance for a long time; unfortunately most of those algorithms are unlikely to be useful, because they need a lot of resources which are not available on-chip. Recently, it has been proposed to connect the IPs using a network-on-chip (NoC) architecture [4]. For example, various modules can be placed on a network of 16 tiles which are connected on a 4 × 4 grid (as in Fig. 1). Consequently, every tile can communicate directly with its four nearest neighbors, except for the tiles on the border/corners, which have only three/two neighbors. As such, the end-to-end communication between non-adjacent tiles will have to be implemented by a set of high-level protocols. These regular structures are very attractive because they can offer well-controlled electrical parameters (which enable high performance circuits by reducing latency and increasing bandwidth) and lower probabilities of failure for individual nodes. Fig. 1. Tile-based architecture The problem of deﬁning communication protocols for these NoCs has not been addressed yet and does not seem to be an easy matter, as the resources used in traditional networks are not available on-chip. Classic data link layer protocols, as the Internet Protocol or the ATM Layer [1], need retransmissions 225 in order to deal with incorrect data, thus signiﬁcantly increasing the overall latency. Generally speaking, simple deterministic algorithms do not cope very well with random failures [10]. On the other hand, the cost of implementing full-blown adaptive routing for the NoCs is prohibitive because of the need of very large buffers, lookup tables and complex shortest-path algorithms [1]. To address these problems, the present paper introduces a new communication paradigm called on-chip stochastic communication. We place ourselves in an NoC context, as in Fig. 1. The IPs communicate using a probabilistic broadcast scheme, similar to the randomized gossip protocols [5]. If a tile has a packet to send, it will forward the packet to a randomly chosen subset of the tiles in its neighborhood. This way, the packets are diffused from tile to tile to the entire NoC. Every IP then selects from the set of received messages only the ones that have its own ID as the destination. This simple algorithm achieves many of the desired features of the future NoCs. As shown later in this paper, the algorithm provides: • separation between computation and communication, as the communication scheme is implemented in the network logic and is transparent to the IPs; • fault-tolerance since a message can still reach its destination even under severe levels of DSM failures on the chip; • low latency since it does not require retransmissions (our results indicate great improvements over a bus-based solution); • design ﬂexibility since it provides a mechanism to tune the tradeoff between performance and energy consumption. In summary, we propose a fault-tolerant solution for the NoC communication which lowers the production costs, simpliﬁes the design, and can be customized for various applications and architectures. This paper is organized as follows: ﬁrst, we review previous work relevant to this paper. In Section III, we introduce our approach and present the metrics for performance evaluation. In Section IV, we show experimental results that clearly indicate the great potential of this approach. Finally, we conclude by summarizing our main contribution. I I . PR EV IOU S WORK Our communication scheme is derived from a class of randomized broadcast primitives called gossip algorithms [5], that have been used before in computer networks and distributed databases. The behavior of such a communication scheme is similar to the spreading of an epidemic, which usually is disseminated exponentially fast [2]. Demers et al. [5] proposed to use randomized gossip for the lazy update of data objects in a database replicated at many sites and proved that, with their algorithm, the updates are spread exponentially fast among the instances of the database. Several networking protocols have been developed based on the same principles, as the gossip protocols proved to be very scalable and to maintain a steady throughput [3, 1]. More recently, these types of algorithms have been applied to networks of sensors [6]. Their ability to limit the communication to local regions and to support light-weight protocols, while still accomplishing their task, is appealing to applications where power, complexity and size constraints are critical. We argue that this paradigm can be successfully applied to the SoCs as well, especially for NoC architectures like the one in Fig. 1. From a design perspective, in order to deal with node failures, Valtonen et al. [17] proposed an architecture based on autonomous, error-tolerant cells. In their approach, all cells can be tested at any time for errors and, if needed, disconnected from the network by the other cells. However, the authors do not specify the communication scheme which would ensure the desired fault-tolerance on such architectures. Furthermore, the problem of data upsets (see Section A) and their impact on NoC communication has not been addressed yet, so our paper ﬁlls an important gap in this research area of on-chip networks. I I I . D E SCR I P T ION O F PRO PO SED A P PROACH In what follows, we propose a failure model for NoCs and introduce a new class of protocols that we call on-chip stochastic communication. The properties and advantages of this communication scheme are discussed in detail in the following sections. A. A Failure Model for NoCs Several failure models have been identiﬁed in the traditional networking literature [7]. Crash failures are permanent faults which occur when a node halts prematurely or a link disconnects, after having behaved correctly until the failure. Transient faults can be either omission failures, when links lose some messages and nodes intermittently omit to send or receive, or arbitrary failures (also called Byzantine or malicious), when links and nodes deviate arbitrarily from their speciﬁcation, corrupting or even generating spurious messages. However, as some of these models are not very relevant to the on-chip networks, we have developed a fault model that is more suited to the NoC context. Because of crosstalk and electromagnetic interference, the most common type of failures in DSM circuits will be data transmission errors (also called upsets) [14]. Simply stated, if noise in the interconnect causes a message to be scrambled, a data upset error will occur; these errors are subsequently characterized by a probability pupset . Another common failure appears when a message is lost because of buffer overﬂow; this is modeled by probabilities psend miss if it happens in a send buffer and precv miss for a receive buffer. Since our algorithm treats scrambled messages as lost messages (see Section B), we can combine these three probabilities into one, plost , which gives the odds that a message transmission fails; that is: plost = pupset + psend miss + precv miss (1) 226 Furthermore, in order to show that our algorithm can work on partially defective chips (thus helping to reduce the veriﬁcation costs), we allow tiles and links to be manufactured unreliably. Summarizing, the fault model we propose depends on the following parameters: • plost , the probability a message is lost (either because of data upsets, or because of buffer overﬂows ); • ptiles , the probability a tile is non-functional from manufacturing; • plinks , the probability a link is defective from manufacturing. If the links are experiencing arbitrary failures, we must also consider how the information transmitted is altered. If a message contains n bits, the error vector is deﬁned as: e = (e1 , e2 , . . . , en ), where ei = 1 if an error occurs in the ith transmitted bit and ei = 0 otherwise. If all 2n − 1 non-null error vectors are equally likely to occur, we have the random error vector model. In this model the probability of e does not depend on the number of bit errors it contains, therefore: pupset = P [e] = (2n − 1) pv ≈ 2n pv ⇒ pv ≈ pupset 2n X e6=0 where pv is the probability of an error vector e. In contrast, in the random bit error model, e1 . . . en are independent of each other, so: P [e] = 1 − (1 − pb )n ≈ npb ⇒ pb ≈ pupset n pupset = 1 − X e=0 where pb is the probability of a bit error. We believe that considering this stochastic failure model is an important step towards solving the fault-tolerant communication problem, as it emphasizes the non-deterministic nature of DSM faults. This suggests that a stochastic approach (described subsequently) is best suited to deal with these realities. B. Stochastic Communication Traditionally, data networks have dealt with fault-tolerance by using complex algorithms, like the Internet Protocol or the ATM Layer [1]. However, these algorithms require a lot of resources that are not available on-chip and they are not always capable to guarantee a constant low latency, which is vital for SoCs. For example, in these protocols, the packets are protected by a cyclic redundancy code (CRC), which is able to detect if a packet contains correct or upset data. If an error is detected, the receiver will ask for the retransmission of the scrambled messages. This method is known as the automatic retransmission request (ARQ) paradigm, and it has the disadvantage that it increases the communication latency. Another approach is the forward error correction (FEC), where the errors are corrected directly by the receiver by using an error correction scheme, like the Reed-Solomon codes. FEC is appropriate when a return channel is not available, as for instance in deep-space communications or in audio CD recordings. FEC, however, is less reliable than ARQ and incurs signiﬁcant additional processing complexity [1]. In light of these considerations, we propose a fast and computationally lightweight paradigm for the on-chip communication, based on an error detection / multiple transmissions scheme. The key observation behind our strategy is that at chip-level bandwidth is less expensive than in traditional networks, because of existing high-speed buses and interconnection fabrics which can be used for the implementation of an NoC. Therefore, we can afford to have more packet transmissions than in the previous protocols in order to simplify the communication scheme and guarantee low-latencies. We implement the end-to-end communication between the tiles of an NoC using a probabilistic broadcast algorithm [3]. A message propagates from tile to tile until the entire network becomes aware of it. The message is spread exponentially fast, and after O(log2 n) stages it reaches all the tiles with high probability (w.h.p.)1 (see Section D). However, the message might reach its destination before the broadcast is completed, so the spreading could be terminated even earlier. In order to do this, we assign a time to live (TTL) to every message upon creation and decrement it at every hop until it reaches the value 0; then the message is destroyed. This will lead to important bandwidth and energy savings, as shown in Section IV. During transmission, packets are protected against data upsets by a CRC; if an error is discovered, then the packet will be discarded. Because a packet is retransmitted many times in the network, the receiver does not need to ask for retransmission, as it will receive the packet again anyway. Furthermore CRC encoders and decoders are easy to implement in hardware, as they only require one shift register [1]. An example of a simple Producer – Consumer application is shown in Fig. 2. On an NoC with 16 tiles, the Producer is placed on tile 6 and the Consumer on tile 12; tiles 4, 5, 13 and 15 are assumed dead. Suppose the Producer needs to send a message to the Consumer. Initially the Producer sends the message to a randomly chosen subset of its neighbors (e.g. tiles 2 and 7 in Fig. 2-a). At the second gossip round, tiles 6, 2, 7 (the Producer and the tiles that have received the message during the ﬁrst round) forward it in the same manner. After this round, eight tiles (6, 2, 7, 1, 3, 8, 10, 11) know the message and are ready to send it to the rest of the network. At the third gossip round, the Consumer ﬁnally receives the packet from tiles 8 and 11. Note that: • If one of the tiles tries to send the message to a faulty tile (in Fig. 2-(c) tile 3 tries to send to tile 4), nothing will happen because the receiver is not functioning correctly. • If the packet transmitted by tile 8 is affected by a data upset, the Consumer will discard it, as it receives from tile 11 another copy of the same packet. • The Producer needs not know the location of the Consumer, the message will still arrive at the destination (w.h.p.). • The message reaches the Consumer before the full broadcast is completed (tiles 14 and 16 have not yet received the message). 1 The term with high probability means with probability at 1 − O(n−α ) for some positive constant α. least 227 (a) =⇒ (b) =⇒ (c) Fig. 2. Producer – Consumer application implemented on a stochastically communicating NoC The pseudocode for this algorithm is shown in Fig. 3 (with standard set theory notations). The tasks executed by nodes and links are concurrent. A tile forwards the packet that is available to be sent to all four output ports, then every active link makes a random decision (with probability p) whether or not to transmit the message to its outbound tile. In Section IV, we will show how this probability can be used to tune the tradeoff between performance and energy consumption. In our implementation, the links are assumed to be active (they have some control logic that can choose randomly whether or not an incoming packet is to be transmitted or not). This design choice is not vital for the performance of the algorithm; the random decision could be implemented in the tiles instead of the links. However, this further emphasizes the separation between computation and communication in the on-chip networks. Every tile executes: msg list ← ∅ IN I T IA L I ZAT ION : AT EV ERY GO S S I P ROUND : msg list ← msg list ∪ {m received | CRC OK(m)} ∀m ∈ msg list m.TTL ← m.TTL - 1 msg list ← msg list \ {m ∈ msg list | m.TTL = 0} WH EN NEW M E S SAG E m I S G EN ERATED : m.TTL ← i ni t i al TTL msg list ← msg list ∪ {m} Every link executes: in ← inbound node out ← outbound node IN I T IA L I ZAT ION : AT EV ERY GO S S I P ROUND : with probability p: out receives in.msg list Fig. 3. The on-chip gossip algorithm C. Energy Metrics To estimate this algorithm’s energy consumption, we take into consideration the total number of packets sent in the NoC, since these transmissions account for the switching activity at network level. This is expressed by Eq. 2, where Npackets is the total number of messages generated in the network, S is the average size of one packet (in bits) and Ebit is the energy consumed per bit: Npackets can be estimated by simulation, S is applicationdependent, and Ebit is a parameter from the technology library. As shown in Eq. 2, the total energy consumed by the chip will be inﬂuenced by the activity in the computational cores as well (Ecomputation ). Since we are trying to analyze here the performance and properties of the communication scheme, estimating the energy required by the computation is not relevant to the present paper. This can be added, however, to our estimations from Section IV to get the combined energy values. D. Performance Metrics A broadcast round is the time interval in which a tile has to ﬁnish sending all its messages to the next hops; this will usually take several clock cycles. The optimal duration of a round TR can be determined using Eq. 3, where f is the maximum frequency of any link, Npackets/round is the average number of packets that a link sends during one round (which is application-dependent), and S is the average packet size. TR = Npackets/round S f (3) Although there are no references in the literature on how these algorithms should be implemented in a real system, the gossip-based broadcast has been theoretically studied for a fully connected mesh network [13]. It can be proved that, if Sn is the number of rounds until everybody receives the gossip, then: Sn = log2 n + ln n + O(1) as n → ∞ (4) with probability 1. Therefore, after O(log2 n) rounds (where n represents the number of nodes in the network) all the nodes have received the message w.h.p. [9] (see Fig. 4). However, as in the previous example, the message can reach its destination before the broadcast is completed, so the number of rounds actually needed for the end-to-end communication could be even smaller. Fig. 4. Message spreading using randomized gossip in a 1000 node network Etotal = Ecomputation + Ecommunication = Ecomputation + Npackets S Ebit Randomized gossip performs better than the deterministic algorithms under the presence of faults: F node crash failures (2) 228 result in only O(F ) nodes that do not receive the message [9]. Furthermore, the fact that we don’t store or compute the shortest paths (as in the case of dynamic routing) makes this algorithm computationally lightweight, simpler and easier to customize for every application and interconnection network. The following parameters are relevant to our analysis: • The number of broadcast rounds needed is a direct measure of the inter-IP communication latency; • The total number of packets sent in the network shows the bandwidth required by the algorithm and can be controlled by varying the message TTL; • The fault-tolerance evaluates the algorithm’s resilience to abnormal functioning conditions in the network; • The energy consumption, computed with Eq. 2. E. Possible Design Methodology for Stochastic Communication The design ﬂow for an SoC using stochastic communication would need the following steps: 1) identify and describe the concurrent modules that compose the application; 2) design the IPs that will implement these modules, or select them from an existing IP library; 3) map and place the IPs on an off-the-shelf NoC, which will take care of all the communication between them. The chip’s correct functional behavior still needs to be validated, but extensive veriﬁcation and integration tests can be completely avoided. The stochastic protocol makes the communication fault-tolerant in nature and, as shown in Section IV, in some cases the IPs can be duplicated in order to increase the fault-tolerance of the computation as well. It is obvious that such a methodology will lower drastically the costs of SoC design, especially if a large library of IPs is available. This would enable the mass production of low-cost, disposable devices which need not have the 100% robustness and reliability of traditional VLSI chips. IV. PRACT ICAL CON S ID ERAT ION S AND R E SU LT S Stochastic communication can have a wide range of applicability, ranging from parallel SAT solvers and multimedia applications, to periodic data acquisition from non-critical sensors. In order to demonstrate our technique, we choose a classic parallel application, the Fast Fourier Transform, and simulate it in a stochastically communicating NoC environment. In this section we discuss our results for this setup. We have implemented our algorithm in Matlab’s State ﬂow, a tool for describing and simulating concurrent behavior of complex systems, which uses a formalism deﬁned in [8]. In our simulations we assume the failure model described in Section A, which has the following parameters: ptiles and plinks , the proportions of tiles and links that are defective from construction, and plost , the combined probability that a packet is scrambled during transmission or dropped because of buffer overﬂow. As realistic data about failure patterns in regular SoCs are currently unavailable, we exhaustively explore here the parameter space of our failure model. Another important parameter that we vary is p, the probability that a packet is forwarded over a link (see Section B). We compare here four versions of the stochastic communication, obtained for different values of the parameter p: • the network ﬂooding , which is a deterministic algorithm where the tiles send the messages to all their neighbors all the time; • three versions of the randomized gossip algorithm described in Fig. 3, which differ in the probability that the links transmit the message to the neighbors (we have used p = 0.75, p = 0.5 and p = 0.25). The reason why we are comparing our protocol with the ﬂooding algorithm is because the latter is the simplest example of a deterministic broadcast protocol. The ﬂooding algorithm is also optimal with respect to latency; that is, the number of intermediate hops between source and destination is always equal to the Manhattan distance between the two tiles. We will show that our protocol has a latency close to this optimum. The ﬂooding is, however, extremely inefﬁcient with respect to the bandwidth used and the energy consumed, while the gossip algorithm allows us to tune the tradeoff between energy and performance by varying the probability of transmission p. A. Case Study: The Two-Dimensional Fast Fourier Transform The Fourier Transform has multiple applications in linear systems analysis, antenna studies or signal processing. Its most common implementation is known as the Fast Fourier Transform (FFT), which is currently one of the largest single consumers of ﬂoating-point cycles in modern CPUs and is extensively used in multimedia and wireless communication chips. The Discrete Fourier Transform of N samples is deﬁned as: N −1X n=0 (cid:16) (cid:16) 1 N  1 2 1 2 ˆx(k) = = x(n)e− 2iπ N kn ˆx1 (k) + e− 2iπ N k ˆx2 (k) ˆx1 (k) − e− 2iπ N k ˆx2 (k) (cid:17) (cid:17) (5) for k < N 2 for k > N 2 ˆx2 (k) = ˆx (2k + 1). where ˆx1 (k) = ˆx (2k) and Hence a recursive divide and conquer algorithm will be used to compute the FFT of N samples (Fig. 5). This reduces the number of operations from O(N 2 ) to O(N log2 N ). Using this scheme, the FFT algorithm can also be implemented on a parallel architecture. Every node in the tree from Fig. 5 represents a parallel process. The leaves compute the FFT on a small number of samples and send the results back up to the root, which will ﬁnally assemble the full FFT. Because of its wide-spread use in engineering problems and especially in image and multimedia processing, we have decided to analyze the two-dimensional FFT algorithm (FFT2), which is a generalization of the above scheme, where every node has 4 children instead of 2. We mapped this application onto a 4 × 4 NoC, running the gossip algorithm described in 229 Fig. 5. Parallel scheme for computing the FFT Section III. As mentioned before, the gossip algorithm provides a natural fault-tolerance to the inter-IP communication. In order to increase the computation’s fault-tolerance as well, each module can be duplicated, such that if one is located on a dysfunctional tile, the other one will still be able to ﬁnish the task. We test these algorithms in an unreliable NoC environment, assuming that failures occur according to the model in Section A. We evaluate the latency, the energy dissipation and the fault-tolerance of our approach. The results presented in this section were obtained after several repeated simulations. Since we are dealing with probabilistic protocols, we present average values for estimated parameters and indicate their standard deviation. A summary of our results is given in Tables I and II. For example, the second row of Table I shows that, when the probability of an unsuccessful transmission is plost = 0.2, depending on the algorithm used the broadcast of the ﬁrst message takes 5–30 rounds to reach all the tiles, FFT is computed after 5–16 rounds, there are 444–811 packets transmitted in the network, with an average energy consumption of 7.61–21.29 nJ per message bit2 . The second row of Table II shows the number of rounds needed to ﬁnish: the initial broadcast / the computation of FFT2, for different levels of tile and link failures, when plost = 0.2. A.1 Latency The evolution of the initial broadcast is shown in the upper half of Fig. 6. The spread soon reaches a stage of explosive growth and the whole network becomes aware of the message after a small number of rounds. The shape of these curves is similar for all four algorithms tested and is very close to the one predicted by theory (Fig. 4). The presence of transmission failures slows down the spreading (the dashed line in Fig. 6), but still the message reaches all the tiles. In the lower part of Fig. 6, we note that stochastic communication with probability of transmission p = 0.5 has a latency very close to the optimal one (displayed by the ﬂooding algorithm) when up to 50% of the sent packets get corrupted. On average, we notice that replies come back before the full broadcast of the original message is completed, which suggests that the spreading process could be stopped sooner by specifying a ﬁnite TTL value. The standard deviation (shown by the error bars in Fig 6) is small, which proves that stochastic 2 The total energy dissipation can be obtained by multiplying these ﬁgures with the packet size S (see Eq. 2). Fig. 6. Latency of the Stochastic Communication communication has a stable behavior and the results are can be reproduced across different runs of the algorithm. A.2 Energy Dissipation We have estimated the energy dissipation of our algorithms, using Eq. 2. Since our goal is to analyze a new communication paradigm, we do not include the energy consumed during the computation. Therefore all the results presented here reﬂect the performance of the NoC stochastic communication. In the upper part of Fig. 7 we compare the energy consumption of ﬂooding and gossip ( p = 0.5) algorithms. As expected, the gossip algorithm (which generates less messages than ﬂooding) displays a signiﬁcant reduction in the energy dissipation with respect to the ﬂooding algorithm. The energy dissipation drops to 0 when Plost ≈ 100% because the all the packets are corrupted and therefore they are not retransmitted anymore. The energy dissipation of the gossip algorithm also has a smaller variance across several runs of the protocol. Fig. 7. Energy dissipation of the Stochastic Communication Further energy savings can be achieved by stopping the spread of the messages after a certain number of rounds. This can be done by assigning a ﬁnite time to live (TTL) to the messages. For a small TTL, neither the broadcast of the initial message, nor the task of the application can be completed. However, after a certain threshold, the latency does not improve if the TTL is increased. Fig. 7 shows that the energy consumption increases almost linearly with the TTL. This suggests that the TTL can be set to the smallest value that guarantees the completion of the tasks, in order to keep the energy consumption at the minimum level required. 230 S TOCHA S T IC COMMUN ICAT ION IN AN NOC W I TH 6 .25% D E F EC T IV E T I LE S AND 8 .33% D E F EC T IVE L INK S TABLE I plost = pupset + psend miss +precv miss 0 0.2 0.4 0.6 0.8 1 Initial Broadcast [rounds] FFT2 Computed [rounds] Total Number of Packets Avg. Energy [×10−8 J/bit] Flood Gossip (p) 0.50 0.25 0.75 Flood Gossip (p) 0.50 0.25 0.75 5 5 9 19 22 7 9 11 11 18 12 17 46 16 30 38 85 5 5 5 10 23 6 7 13 16 25 9 11 16 18 34 16 16 20 39 84 Flood 471 444 387 1226 4158 1864 Gossip (p) 0.50 0.75 0.25 481 619 558 559 811 508 1417 1289 486 1997 1172 1700 2734 2080 3562 1410 1068 466 Flood Gossip (p) 0.50 0.75 2.261 1.924 1.651 2.129 1.917 1.768 1.858 2.616 1.934 2.942 2.995 1.562 4.339 2.624 1.468 0.334 0.253 0.191 0.25 0.836 0.761 0.583 1.046 1.018 0.083 IM PAC T O F FA I LURE S ON TH E LATENCY O F TH E GO S S I P A LGOR I THM W I TH p = 0.5 (ROUND S TO COM PL ET E : IN I T IA L BROADCA ST / FFT2 ) TABLE II plost = pupset + psend miss +precv miss 0 0.2 0.4 0.6 0.8 1 0 8 / 6 11 / 10 9 / 11 15 / 18 33 / 27 – / – ptiles = 0 ptiles = 0.125 ptiles = 0.25 plinks 0.083 9 / 9 10 / 8 16 / 14 21 / 13 46 / 33 – / – 0.166 15 / 8 – / 12 – / 14 – / 22 83 / 37 – / – 0.25 – / 9 – / 12 – / 25 – / 25 – / 69 – / – 0 8 / 10 9 / 12 15 / 10 43 / 15 24 / 53 – / – plinks 0.083 7 / 7 – / 10 15 / 16 – / 36 – / 49 – / – 0.166 13 / 13 23 / 19 – / 16 21 / 12 35 / 46 – / – 0.25 – / 11 – / 19 – / – – / – – / – – / – 0 6 / 8 8 / – – / 11 24 / 16 – / – – / – plinks 0.083 – / – – / 20 – / 37 – / 16 42 / – – / – 0.166 – / 14 – / 17 – / 9 – / 17 – / 39 – / – 0.25 – / – – / – – / 22 – / – – / 35 – / – A.3 Fault-Tolerance Different types of failures have different effects on the performance of stochastic communication (see Table II). The levels of defective links and tiles do not seem to have a big impact on latency, however the computation of FFT2 will fail completely if these levels are too high, because too many important modules are not working or entire regions of the chip are isolated. The computation of FFT2 succeeds in more cases than the initial broadcast, for instance even with 12.5% faulty tiles and 16.67% faulty links, FFT2 succeeds in almost all the runs of the protocol. The initial broadcast is especially affected by the number of defective links, which can disconnect a region of the chip from the network and prevent those tiles from sending/ receiving messages. However, because of the resource duplication, even in these cases the computation of FFT2 may succeed, if there are enough vital resources left that can communicate with each other. On the other hand, data upsets seem to have little inﬂuence on the chances that FFT2 has to succeed. However upsets do have an impact on the latency and energy dissipation, especially if plost > 0.5 (see Fig. 8). FFT2 cannot ﬁnish with more than 8 non-functional tiles; however, for less than 4 stopped tiles, it will eventually succeed with levels of data upsets as high as 90%, even if it requires 100 rounds to do so. V. D I SCU S S ION AND FU TUR E WORK The communication paradigm introduced in this paper has many interesting properties. Its main advantage over traditional interconnection schemes is the intrinsic tolerance to DSM failures, as stochastic communication tolerates high levels of data upsets without needing retransmissions. The protocol also ofFig. 8. Impact of data upsets on latency and energy dissipation fers a tradeoff between performance and energy consumption which can be tuned by varying the transmission probability. We have started an in-depth study of how synchronization faults affect our scheme’s performance, and the preliminary results indicate that stochastic communication has a very good tolerance to timing errors as well. We have also compared our technique with a bus-based solution for the FFT2 application. Both implementations use a 0.25µm technology. The length of the bus is equal to the side of the tile-based grid, and the modules were placed on both sides of the bus. Based on these parameters we calculated that the bus has a maximum working frequency of 43 MHz and it dissipates 21.6 · 10−10 J for every bit transmitted, while in working frequency of 381 MHz and it dissipates 2.4 · 10−10 J the case of the tile-based architecture a link has a maximum per bit. The links in this case are faster because they are shorter than the bus in the classical solution. Note that the bus-based 231 – – – – – – – – – – – "
2005,A technique for low energy mapping and routing in network-on-chip architectures.,"Network-on-chip (NoC) has been proposed as a solution for the global communication challenges of system-on-chip (SoC) design in the nanoscale technologies. NoC design with mesh based topologies requires mapping of cores to router ports, and routing of traffic traces such that the bandwidth and latency constraints are satisfied. The authors presented a novel automated design technique that solves the mesh based NoC design problem with an objective of minimizing the communication energy. In contrast to existing research that only take bandwidth constraints as inputs, the technique solves the NoC design problem in the presence of bandwidth as well as latency constraints. The technique was compared with a recent work called NMAP and an optimal MILP based formulation. It is proven that the complexity of the technique is lower than that of NMAP. For the latency constrained case, while NMAP fails on most test cases, the technique is able to generate high quality results. In comparison to the MILP formulation, the results produced by our technique are within 14 % of the optimal.","A Technique for Low Energy Mapping and Routing in Network-on-Chip Architectures∗ Krishnan Srinivasan and Karam S. Chatha Depar tment of Computer Science and Engineering Arizona State University Tempe, AZ, 85287 {ksrini,kchatha}@asu.edu ABSTRACT Network-on-chip (NoC) has been proposed as a solution for the global communication challenges of System-on-chip (SoC) design in the nanoscale technologies. NoC design with mesh based topologies requires mapping of cores to router ports, and routing of trafﬁc traces such that the bandwidth and latency constraints are satisﬁed. We present a novel automated design technique that solves the mesh based NoC design problem with an objective of minimizing the communication energy. In contrast to existing research that only take bandwidth constraints as inputs, our technique solves the NoC design problem in the presence of bandwidth as well as latency constraints. We compare our technique with a recent work called NMAP and an optimal MILP based formulation. We prove that the complexity of our technique is lower than that of NMAP. For the latency constrained case, while NMAP fails on most test cases, our technique is able to generate high quality results. In comparison to the MILP formulation, the results produced by our technique are within 14 % of the optimal. Categories and Subject Descriptors B.4 [Input/Output Data Communications]: Interconnections General Terms Algorithm, Performance, Design Keywords Network-on-Chip, Automated design, Mesh topology, Core mapping, Routing 1. INTRODUCTION The advent of deep sub-micron technology will pose many challenges for next generation high end System-on-Chip (SoC) design. The research presented in this paper was supported in part by a grant from the National Science Foundation (IIS-0308268) and Consortium for Embedded Systems. ∗ Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. ISLPED’05, August 8–10, 2005, San Diego, California, USA Copyright 2005 ACM 1-59593-137-6/05/0008 ...$5.00. P1 C1(B,L) P2 C6(B,L) C3(B,L) C2(B,L) C4(B,L) P4 P3 C7(B,L) C5(B,L) P5 C8(B,L) P6 P1 P2 P3 C2 C1,C6,C3 C4,C5 P4 P5 C7,C8 P6 C4 C6,C3 C7 Figure 1: Low energy mapping and routing In the future a SoC architecture is expected to consist of tens of computing cores operating in the multi-gigahertz range. The various cores would require a communication medium that can support simultaneous high bandwidth data transfers with low latencies. Current day bus based shared medium architectures will not be suitable as they would have to be implemented as hierarchical structures extending to multiple levels. The high signal propagation delays in deep sub-micron technologies will also make synchronous bus based global communication difﬁcult. Noise due to increased RLC effects in deep sub-micron technologies will lead to signal integrity issues which also cannot be easily addressed by bus based architectures. On-chip packet switched interconnection architectures or Networkon-Chip (NoC) have been proposed as a solution for the communication challenges in the nanoscale regime [1]. NoC is characterized by asynchronous communication between routers. NoC is inherently scalable and can be easily applied towards the design of larger sized SoC architectures. NoC supports easier application of error control schemes for increased signal integrity. In particular mesh based NoC architectures are especially attractive due to their regular two dimensional structure that results in IP re-use, easier layout, and predictable electrical properties. Consequently, in recent years a number of researchers have proposed architectures and tools for mesh based NoC [2, 3, 4]. NoC design for an application speciﬁc SoC architecture offers an opportunity for optimizing the mapping of cores to different routers, and incorporation of custom routing of the packets that do not necessarily conform to a pre-determined routing scheme. Periodic high performance applications with deadlines enforce bandwidth and latency requirements for data transfer on the communication medium. Further, each router also places an upper bound on the bandwidth of trafﬁc that can supported at every input/output port. In the nanoscale technologies energy minimization has emerged as a ﬁrst order design goal. The global communication energy is expected to account for a signiﬁcant portion of the total energy consumption [1]. Therefore, the objective of the interconnection design is to obtain an implementation that satisﬁes the performance requirements and minimizes the communication energy. The paper addresses automated NoC design for mesh based interconnection architectures. ) l s e c y c ( y c n e t a L 1600 1400 1200 1000 800 600 400 200 0 0 Latency 0.01 0.02 0.03 0.04 Injection rate (packets/cycle) 0.05 0.06 0.07 Figure 2: Latency versus injection rate The NoC design problem on mesh based interconnection networks is depicted in Figure 1. The input to the problem is a directed graph called the communication trace graph. Each node in the graph represents a computation or storage core, and the directed edges represent communication between the cores. Each communicating trace is annotated as “C m(B,L)” where ‘ m” represents the trace number, “B” represents the bandwidth requirement, and “L” is the latency constraint. The bandwidth and latency requirement on the communication traces can be easily obtained from the desired performance of the overall application and the individual task latencies of each node. The output of the NoC design problem is a mapping of cores onto different routers, a corresponding mesh based NoC, and a static packet route for each trafﬁc trace such that the total communication energy is minimized. On the right hand side of Figure 1, the static routing of a communication trace is shown by the corresponding annotation of physical links. We characterized the energy consumption of the unit router in 100nm technology with the help of a cycle accurate energy and performance evaluator [3]. In the interest of space, we have omitted the details of the experiments. We observed that over time, the energy consumption of the input and output ports varied linearly with the injection and acceptance rates, respectively. Quantitatively, we estimated the energy consumption of 2.07pJ/M bps for the input port, and 2.29pJ/M bps for the output port. The variation of average latency on a port with respect to injection rate is shown in Figure 2. We observe from the plot that average latency remains almost constant in the un-congested mode, and the onset of congestion is marked by a sharp increase in latency. Our technique prevents network congestion by static routing of the communication traces subject to the peak bandwidth constraint on the router ports. As the network is always operated in the un-congested mode, we can represent the network latency constraint as router hops (such as 1 or 2) instead of an absolute number (such as 60 cycles). Problem Deﬁnition : We deﬁne the mesh based NoC design problem as follows. Given: • A directed communication trace graph G(V , E ), where each vi ∈ V denotes either a processing element or a memory (vi , vj ) ∈ E denotes a communication trace from vi to vj . unit (henceforth called a node), and the directed edge ek = • For every ek = {vi , vj } ∈ E , ω(ek ) denotes the bandwidth requirement in bits per second, and σ(ek ) denotes the latency constraint in hops. • A mesh based topology of NoC I (N , L), where each ni ∈ N denotes a router, and each li ∈ L denotes a physical link. All routers are identical 5-port routers with 4 ports connected to neighboring routers via links and one open port for node mapping. • I is placed on a grid in the XY plane with unit distances between adjacent routers. x(ni ) and y(ni ) denote the x and y coordinates of a router ni ∈ N . • Each router architecture is characterized by: –Ω which denotes the peak input and output bandwidth that the router can support on any one port, –Ψi that denotes the energy consumed per M bps of trafﬁc bandwidth ﬂowing in the input direction for any port of the router, and –Ψo which denotes the energy consumed per M bps of trafﬁc bandwidth ﬂowing in the output direction for any port of the router. The objective of the NoC mapping and routing problem is to obtain: • a one to one mapping function M : V → I that denotes the mapping of a node to a router, • a set R of ordered tuples of routers, where each ri (cid:5)ni , nj , . . . , nk (cid:6) ∈ R, ni , . . . , nk ∈ I denotes a route for a trace e(vi , vk ) ∈ E (M(vi ) = ni , M(vk ) = nk ), such that • the bandwidth constraints on router ports are satisﬁed, • the bandwidth and latency constraints on the traces are satisﬁed, and • the total communication energy is minimized. As mentioned earlier, the energy consumption of the NoC in the un-congested mode varies linearly with the trafﬁc ﬂowing through the network. Therefore, the energy consumption of the NoC can be minimized by minimizing the cumulative trafﬁc ﬂowing through the ports of all routers. Bandwidth requirements and latency constraints of communication traces can be viewed as mutually independent. A trace such as a signalling event or a cache miss is not expected to have a high bandwidth requirement, but is bound by tight latency constraints. On the other hand, many non-critical multimedia streams have high bandwidth requirement, and their latency is bound only by the period constraint of the application. A mapping and routing technique has to perform a trade-off between placing high bandwidth trafﬁc traces close to each other to minimize energy, and placing tight latency traces close to satisfy the performance constraints. In this paper, we present a novel two phase technique that effectively performs energy versus latency trade-off in stage 1 to obtain a mapping of cores on the mesh based NoC, and then generates a custom route for each communication trace in stage 2 such that communication energy is minimized and performance constraints are satis ﬁed. We evaluate the performance of our technique by comparing it with a recent work called NMAP [4], and against an optimal MILP formulation. The paper is organized as follows: Section 2 discusses previous work, Section 3 presents our automated design technique, Section 4 discusses our experimental results, and ﬁnally Section 5 concludes the paper. 2. PREVIOUS WORK Hu et al. [2] and Ascia et al. [5] presented branch and bound and genetic algorithm based techniques, respectively, to map cores onto a regular mesh based NoC architecture. Murali et al. [4] presented a heuristic technique called NMAP for mapping cores and routing trafﬁc traces on mesh based NoC architectures. All existing research only accepts bandwidth constraints on communication traces. The novelty of our technique is that we address the problem of bandwidth and latency constrained NoC design. Unlike previous work, we trade off energy minimization (obtained by routing   high bandwidth traces in minimum hops), with the objective of obtaining legal solutions (by routing tight latency traces in minimum hops) to obtain a pareto optimal point. The results of NMAP were shown to be better than other existing research. We prove that the computational complexity of our technique is lower than NMAP. We also show that for the latency constrained designs, our technique is able to generate high quality solutions while NMAP fails in most cases. C1 B C2 A C5 C C4 D C3 E C6 C7 C8 F (A) Figure 3: Example CTG V H H V V V V A B C D E F Figure 4: Partitioning based slicing tree 3. LOW ENERGY MAPPING AND ROUTING ON NOC ARCHITECTURES This section presents our technique for design of low energy mesh based on-chip interconnection architectures, henceforth called MOCA. MOCA operates in two phases. In the ﬁrst phase, it invokes a bi-partitioning based slicing tree generation technique to map cores on to the different routers of the mesh. In the second phase, MOCA invokes a hierarchical router that generates routes for all the communication traces. 3.1 MOCA Phase I: Core to router mapping The MOCA core mapper (CM) takes a CTG and a mesh topology as inputs, and maps the cores to different routers of the given mesh. The mesh is assumed to be placed in the ﬁrst quadrant of the X-Y plane with the routers placed at unit distance apart. Therefore, the mesh can be denoted by a ﬁnite sized plane P deﬁned by bottom left hand side (x1 , y1 ) and top right hand side (x2 , y2 ) co-ordinates, respectively. Each integral location (x, y) (x1 ≤ x ≤ x2 , y1 ≤ y ≤ y2 ) in the plane denotes the co-ordinate of the respective router. The mapping of the cores to routers assigns a unique (x, y) co-ordinate to each core that corresponds to the router at that particular location. We determine the coordinates of the cores by recursively invoking the technique proposed by Fiduccia and Mattheyses [6] (FM) to solve the graph equicut problem. We restrict the FM technique to generate partitions with equal sizes. The input to the equicut problem is a graph with weights on its edges. The solution is a partition of the graph such that the two partitions have the same number of nodes, and the cumulative weight of the edges crossing the partition is minimized. Each partitioning step divides the mesh and the CTG into two halves to generate a slicing tree. On algorithm completion, the intermediate nodes of the tree are the directions of each cut (horizontal or vertical) and the leaf nodes are the cores. The CTG is modiﬁed through two pre-processing steps before it is mapped onto the mesh. 3.1.1 Core mapper pre-processing The core to router mapping algorithm performs two preprocessing steps. In the ﬁrst pre-processing step, CM adds m additional nodes to the n nodes in the CTG such that the total number of nodes in the graph is a power of 4. Mathematically, 22p < n < 22p+2 and n + m = 22p+2 for some p. This step is performed so that every recursive call to the FM partitioner divides the nodes into two equal halves. Note that m < 3n. The second pre-processing step performed by CM pertains to determining a new weight for each edge in the CTG for min-cut purposes. Bandwidth constraints can be satisﬁed by ﬁnding alternative (sometimes longer) route for the trace. Latency constraints, on the other hand, cannot be adhered to by ﬁnding alternative paths. Therefore, CM gives higher priority to latency compared to bandwidth. Let ei be a trace with the highest bandwidth requirement among all traces in the graph. Let ej be the trace with tightest A D A D A A D D B E X B Y E C F C F (A) (B) Y Y F F B B E E C C (C) A C B E D F (D) Figure 5: Output of MOCA Phase I: Core to router mapping σ(ei )k ≤ ω(ej ) (lowest) latency constraint among all traces in the graph. CM determines an integer k such that it is the minimum value required to ensure that ω(ei ) σ(ej )k . Once k is determined, CM assigns an edge weight to each edge given by: ∀e ∈ E , ρ(e) = ω(e) For two edges with the same edge weight, the one with tighter latency has higher priority. This heuristic ensures that traces with low bandwidth requirements but with tight latency constraints are given priority over those with high bandwidth requirement and relaxed latency constraints. σ(e)k . 3.1.2 Slicing tree based core mapping Given a mesh based interconnection network placed in the ﬁrst quadrant of the X-Y plane, the CM generates a slicing tree by recursively dividing the mesh into two equal halves by partitioning it either vertically, or horizontally. Figures 3, 4, and 5 give examples of the input CTG, slicing tree, and various stages of the algorithm execution, respectively. In the ﬁgure, the ﬁrst cut is a vertical cut, the two child cuts are horizontal, and so on. The leaves of the tree are occupied by the nodes of CTG. The position of the node in the tree indicates its coordinates after successive partitioning steps. Figure 6 shows the algorithm for mapping cores onto the routers of the mesh. The slicing tree based core mapping technique maintains a queue data structure (Q). Each element of the queue consists of a subgraph Gi , a sub-plane Pi , and a direction of cut dir cut. The queue is utilized to perform a breadth ﬁrst traversal of the slicing tree. Initially, the given X-Y plane P , the graph G, and a cut direction dir cut are enqueued. Without loss of generality, we assume that the ﬁrst cut is vertical. The slp function is invoked by passing the queue as a parameter to generate a mapping of nodes to routers. For the purpose of the discussion on slp, we denote the subgraph belonging to the element at the head of the queue as G, the corresponding sub-plane as P , and the corresponding cut as dir cut. The head of the queue is dequeued and stored in a temporary data structure. Initially, slp checks if the sub-plane is a point. If yes, the node in the corresponding subgraph is mapped to the router located at the location of the sub-plane, and the function returns. If the sub-plane is not a point, the slp function performs the following steps on the temporary data structure. First, slp invokes the FM technique to partition G into subgraphs G1 , and G2 . The second step partitions P into two sub-planes, P1 and P2 of equal size. If the direction of the cut is vertical (dir cut = v cut ), P is partitioned into left sub-plane and right sub-planes. On the other hand, if the direction of the cut is horizontal, P is partitioned into top and bottom sub-planes. CM (G) add extra nodes() / * Pre-processing step 1 */ assign edge weights() /* Pre-processing step 2 */ enqueue(Q,G,P,v cut) slp(Q) end slp(Q) (G,P,dir cut) = dequeue(Q) if (x1 = x2 AND y1 = y2 ) M(v) = n, s.t. x(n) = x1 , y(n) = y1 /* node → rtr */ return() end if (G1 , G2 ) = FM(G) if (dir cut = v cut) P1 = [(x1 , y1 ), ((cid:3) x1+x2 2 (cid:4)− 1, y2 )], P2 = [((cid:3) x1+x2 2 (cid:4), y1 ), (x2 , y2 )] else /* dir cut = h cut */ P1 = [(x1 , y1 ), (x2 , (cid:3) y1+y2 2 (cid:4)− 1)], P2 = [(x1 , (cid:3) y1+y2 2 (cid:4)), (x2 , y2 )] endif add dummy nodes(P1 , G1 , G2 ) if (dir cut = v cut) next cut = h cut else next cut = v cut end if enqueue(Q,G1 ,P1 ,next cut) enqueue(Q,G2 ,P2 ,next cut) if (|Q| (cid:5)= 0) slp(Q) end if return() end Figure 6: MOCA Phase I: Core to router mapper Assuming that the left partition is processed before the right partition, the partition of each left sub-plane is followed by placing dummy nodes at the intersection with the right sub-plane. Similarly, for a horizontal cut, the partition of each top sub-plane is followed by placing dummy nodes at the intersection with the bottom sub-plane. All crossing trafﬁc traces are captured by these dummy nodes. This dummy propagation step attracts connected nodes towards each other such that, in the ﬁnal mapping, nodes connected with large edge weights are placed close to each other. In order to place the dummy nodes effectively, the slicing tree should be traversed in a breadth ﬁrst manner. The next step determines the direction of next cut for P1 and P2 which is complement of dir cut. Finally, (G1 , P1 , next cut), and (G2 , P2 , next cut) are enqueued, followed by a recursive call to the slp function. The recursive call initiates a breadth ﬁrst traversal of the search space such that, when CM terminates, the mapping function M contains a node to router mapping for all nodes in the original graph G. Figure 5 presents the different stages of slicing tree based mapping of the nodes constituting the CTG. The empty circles in the ﬁgure denote the m additional nodes. The black circles denote the dummy nodes. In Figure 5(B), traces A-D, and A-E are captured by the dummy node on the top half plane, and trace C-E is captured by the dummy node on the bottom half plane. 3.2 MOCA Phase II: Route generation The MOCA route generator (RG) is a novel technique that operates on the slicing tree to formulate a unique route for each communication trace (see Figure 7 for pseudo code). RG operates in two stages, namely, RG hierarchical router (RGhier ) that generates a route for every trace by traversing the slicing tree, and RG shortest path router (RGsp ) that searches for a minimal distance route for a communication trace that was not successfully routed by RGhier . 3.2.1 RG hierarchical router The RGhier attempts to ﬁnd a minimal path from the source to the destination for each trafﬁc trace. RGhier traverses the slicing (cid:4), y1 ), (x2 , y2 )] 2 (cid:4)), (x2 , y2 )] 2 if (x1 = x2 AND y1 = y2 ) return() end if if (dir cut = v cut) 2 C1 = ( x1+x2 2 P1 = [(x1 , y1 ), ((cid:3) x1+x2 (cid:4)− 1, y2 )], P2 = [((cid:3) x1+x2 , y1 ), C2 = ( x1+x2 , y2 ) P1 = [(x1 , y1 ), (x2 , (cid:3) y1+y2 (cid:4)− 1)], P2 = [(x1 , (cid:3) y1+y2 ), C2 = (x2 , y1+y2 ) C1 = (x1 , y1+y2 2 else /* dir cut = h cut */ 2 2 2 endif for t ∈ trace list trace list = get traces(C1 , C2 ) /*list of traces*/ (n1 , n2 ) = get routers(t,P1 , P2 ) update routers(t, n1 , n2 , R) if (mapping fail(t)) remove(t, R) /* Remove trace from route */ add(t, tbd trace list) /* Add trace to list for next phase */ end if end for if (dir cut = v cut) next cut = h cut else next cut = v cut end if RGhier (P1 , next cut), RGhier (P2 , next cut) return() RG () RGhier (P,v cut) RGsp (tbd trace list) end RGhier (P, dir cut) end RGsp (tbd trace list) for t ∈ tbd trace list for e ∈ L /* For all physical links in I */ if (ω(e) + ω(t) > Ω) /* BW violation */ edge weight(e) = ∞ else edge weight(e) = 1 end if end for shortest path(t, I , R) end for end Figure 7: MOCA Phase II: Route generation tree generated by CM and routes traces that cross the cut at each level of the tree. The inputs to RGhier are a plane P that conpseudo code). RGhier returns a set of ordered tuples R, where stitutes the mesh, and a direction of cut dir cut (vertical in the each ri ∈ R = {(x1 , y1 ), (x2 , y2 ), . . .} denotes a unique route for every trafﬁc trace ei ∈ CTG. Each (xj , yj ) ∈ ri denotes the router through which the trace is routed. RGhier also returns a list of trafﬁc traces that could not be routed due to violation in either the bandwidth or latency constraints. Initially, RGhier checks if the plane passed to it is a point. If yes, the function returns as no routing is necessary. If the plane is not a point, RGhier generates a partial route for the traces. It considers two partitions of the given sub-planes, P1 and P2 as deﬁned by CM (discussed in Section 3.1.2). It generates the cut that deﬁnes the two partitions as ( C1 , C2 ), where C1 and C2 are the end points of the cut. Any trafﬁc trace that crosses the cut ( C1 , C2 ) to complete its route from source to sink, is added to the list of traces to be routed (trace list). A partial route for the traces in trace list is generated by assigning the traces on the routers adjacent to the cut. This step is equivalent to assigning the traces to physical links that are across the cut (C1 , C2 ) subject to the bandwidth constraints. Clearly, this is a knapsack problem and is known to be NP-Complete. We route traces on the respective routers by considering the traces in a decreasing order of their bandwidth requirement. The pair of routers that are connected to the physical links affected by the cut are considered for routing the trace. The trace is routed through the pair of routers that is closest to the source, and can support the trafﬁc without bandwidth violation. The selection of the pair of routers is performed by get router() in Figure 7. Once the trace is routed, the partial route of the trace in the set R is updated. A C A C B B D E F B D F E A D B B A C A C D F D F E E B E A C A C B B D E F D F E C F A C C4, C3 C1,C5 E C4 C3 D F C8 C1,C2 C6 G C7 Figure 8: MOCA Phase II: Route generation example Figure 8 gives an example of the algorithm execution on the mapping shown in Figure 5(D). In the ﬁgure the black squares represent the routers, the solid lines represent the links, and the labelled circles represent the cores from Figure 3. The dotted lines in Figure 8 refer to the successive cut lines that are generated during the algorithm execution. The NoC architecture at the end of the routing stages is shown in Figure 8(G). As an example of the traces that are selected to be routed across a cut, Figure 8(B) maps traces (A,B), (A,C), and (A,E) across the horizontal cut in the left hand side. We state the following theorem regarding the optimality of RGhier . Theorem: RGhier ﬁnds a minimal path if bandwidth constraints are not violated. Proof: Routing of traces through the routers adjacent to a cut take the trace closer to the sink in the X-direction for vertical cut, and Y-direction for horizontal cut. Since the trace is routed through the router closest to the source, at any point, the distance between the router and the source is minimum. This is Dijkstra’s shortest path algorithm, and therefore, the path is minimal. Q.E.D width violation, the partial route for the trace in the set R is reIf a trace cannot be mapped to any router in the cut due to bandmoved, and the trace is added to a list of unmapped traces. The RGhier function ﬁnally makes a recursive call on P1 and P2 by setting the dir cut parameter to be complementary to the corresponding value for its call with P . The recursive call initiates a depth ﬁrst traversal of the tree such that, when all instances of the function return, each trace in the edge set E of the CTG either has a route in R, or the edge is present in the list of unmapped traces called tbd trace list. 3.2.2 RG shortest path router The RG shortest path router is called for each trafﬁc trace that is left unmapped at the end of RGhier stage. For each trace in an edge weight of ∞ to all links that would see a bandwidth viotbd trace list, RGsp sweeps the links L of the mesh, and assigns lation on the corresponding ports constituting the links, if the trace was routed through that link. This step is followed by invoking the Dijkstra’s shortest path algorithm to ﬁnd a route for the trace on the mesh. The solutions generated by MOCA could have deadlocks that can be removed by a post-processing step that introduces additional virtual channels at selected routers [7]. Graph DSP ﬁlter H.263 encoder MP3 encoder H.263 enc MP3 dec MPEG4 decoder MWD VOPD MP3 enc MP3 dec H.263 enc MP3 enc H.263 enc H.263 dec Graph ID G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 Nodes 6 7 8 12 12 12 12 13 15 16 Edges 5 7 8 11 13 13 13 12 17 17 Table 1: Graph Characteristics 3.3 Complexity Analysis 1 for p ≥ 1, f = 2(u − u Complexity of CM : Let n be the number of nodes in the CTG, u be the number of nodes in the mesh, e be the number of edges in the CTG, and f be the number of links in the mesh. MOCA adds m nodes such that n + m = u. As explained in Section 3.1, n + m = u < 4n. In a square mesh based network with u = 22p 2 ). The initial processing in CM takes linear time. CM performs at most (u − 1) partitions as denoted by the number of internal nodes of a balanced binary tree. The FM technique has a linear time complexity in total number of pins when the input is a hypergraph [6]. In the case of a directed graph such as the CTG, the total number of pins is O(e). Therefore, the overall complexity of CM is O(ue). Complexity of RG : RGhier performs routing by traversing a slicing binary tree of height log2 (u) that denotes (u − 1) partitions. During the processing of each slice the algorithm explores at most e traces. Traces can be sorted during pre-processing. The complexity of the algorithm for processing each slice is given by the product of the maximum number of traces and the number of links. The number of links explored at a particular internal node of the tree are half that of the parent. However, the total number of links explored by RGhier at each level of the binary tree are equal, and are given by u 2 . Therefore the complexity of RGhier is given by: 1 1 2 + 2 · eu 2 eu 1 2 1 2 + 4 · eu 4 · · · log2 (u) terms = eu 1 2 log2 (u) RGsp calls the shortest path algorithm for each trace. The shortest path algorithm has a complexity of O(f + u). Hence, the complexity of RGsp is O(e(f + u)) = O(e(3u − 2u 1 2 )). Complexity of MOCA : From the analysis presented above, the overall complexity of MOCA is given by O(max(eu, eu 2 log2 (u), 1 e(3u − 2u 1 2 )) = O(eu). Comparison with NMAP : The authors of NMAP computed the complexity of NMAP to be O(eu3 log(f )). Substituting for f , the complexity of NMAP is given by O(eu3 log(2u − 2u 2 )) which is greater than the complexity of MOCA. 1 4. RESULTS In this section we present the results obtained by the execution of our technique on various multimedia benchmark applications. We generated custom NoC architectures for six combinations of four multimedia benchmarks: MP3 audio encoder, MP3 audio decoder, H.263 video encoder, and H.263 video decoder [2]. In addition, we obtained results for four other benchmarks: MPEG4 decoder, video object plane decoder (VOPD), multi-window display (MWD), and DSP ﬁlter application (DSP) [8][4]. Table 1 lists the graph IDs and sizes of the CTG of the various benchmarks. We compared the topologies generated by MOCA against those generated by NMAP, and an optimal MILP formulation [9]. Table 2 presents the results of the comparison in energy consumption of the topologies generated by MILP, NMAP, and MOCA for traces with latency constraints. In the table, the sixth column presents No. Graph Energy (nJ ) NMAP Ratio MOCA vs MOCA vs MILP NMAP 1.3 1.3 1.11 NA 1.12 NA 1.28 NA 1.45 NA 1.10 NA 1.11 NA 1.41 NA 1.27 NA 1.09 NA MILP MOCA 1 2 3 4 5 6 7 8 9 10 G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 20.935 2143.2 91.6 2203.6 70.93 10.16 35.29 154.23 2128.9 2166.4 20.935 FAIL FAIL FAIL FAIL FAIL FAIL FAIL FAIL FAIL 27.109 2400.2 103.13 2830.0 103.13 11.191 39.227 218.61 2724.3 2378.9 Table 2: Comparison of MILP, NMAP and MOCA: With latency constraints No. Graph Energy (nJ ) NMAP Ratio MOCA vs MOCA vs MILP NMAP 1.29 1.29 1 1 1.00 1.00 1 1 1.06 0.94 1.08 0.99 1.06 1.05 1.08 1.08 1 0.86 1.00 1.00 MILP TEMPO 1 2 3 4 5 6 7 8 9 10 G1 G2 G3 G4 G5 G6 G7 G8 G9 G10 20.935 1960.5 91.362 2018.6 64.059 9.7440 33.862 152.52 2047.8 2075.7 20.935 1960.5 91.362 2018.6 72.453 10.708 34.345 152.52 2366.4 2075.6 27.109 1960.5 91.738 2018.6 68.401 10.612 36.178 165.45 2047.8 2080.5 Table 3: Comparison of MILP, NMAP and MOCA: Without latency constraints Node 0 1 2 3 4 5 6 7 8 9 10 11 MPEG4 VU SDRAM ADSP AU UPSP MCPU SRAM1 RAST SRAM2 BAB IDCT RISC VOPD VLD RUN LEN DEC INV SCAN STRIPE MEM IQUANT ACDC PRED IDCT ARM UP SAMP VOP REC PAD VOP MEM Table 4: Node descriptions for MPEG4 and VOPD 0 1 2 3 (0.5, 2) (60, 4) 4 6 8 11 5 7 10 9 (150, 4) (0.5, 2) (910, 4) (600, 4) (40, 4) (40, 4) (32, 4) (670, 4) (500, 4) (173, 4) (250, 4) Figure 9: CTG for MPEG 4 decoder 0 1 4 8 5 (49, 4) 3 10 2 (70, 2) (362, 4) (27, 2) (362, 4) (357, 4) 7 6 9 (16, 2) (353, 4) (300, 4) (313, 4) 11 (94, 4) (500, 4) (313, 4) Figure 10: CTG for VOPD the ratio of the energy consumption of MOCA over MILP, and the seventh column presents ratio of energy consumption of MOCA over NMAP. Since NMAP does not consider latency constraint, the topologies produced by the technique violated latency constraints on most test cases. On the other hand, MOCA was able to generate topologies satisfying latency constraints for all test cases. On an average, the energy consumption of MOCA was within 22 % of the MILP. The solution time of MILP grows exponentially with input size unless P = N P . While MILP timed out for most input cases, MOCA was able to generate results within 0.01secs. Table 3 presents the comparison of MOCA with MILP and NMAP for the input traces without latency constraints. As is evident from the table, both NMAP and MOCA performed as well as MILP in many cases. On average, MOCA performed within 6 % of the solution generated by MILP. The overall variation of MOCA against NMAP was negligible. However, as we proved earlier the algorithmic complexity of MOCA is lower than that of NMAP. Figures 9, and 10 present trace graphs for MPEG4 decoder, and VOPD, respectively. The description of the various nodes in the two ﬁgures is shown in Table 4. The labels of the edges denote bandwidth requirement in Mbps, and latency constraint in router hops, respectively. Figures 11, and 12 present the mesh based NoC architectures for MPEG4 generated by MOCA for the latency constrained and latency unconstrained cases, respectively. The corresponding designs for VOPD are shown in Figures 13, and 14. Since MOCA gives higher priority to latency, traces with tight latency are routed through minimum hops. For example, in the case of MPEG4 decoder, trace (1,2) is routed in only two hops due to its tight latency (2 hops). Note that when latency is not a constraint, the same trace is routed in three hops due to its low bandwidth requirement. 5. CONCLUSION We presented a novel polynomial time heuristic technique called MOCA for automated design of low energy mesh based NoC architectures. We proved that the algorithmic complexity of MOCA is lower than that of NMAP [4]. MOCA takes latency constraint on the traces into consideration, and is able to generate valid topologies under tight latency constraints for all benchmarks while NMAP fails for many designs. The quality of results of MOCA and NMAP are comparable when latency is not a constraint. We also compared MOCA against an optimal MILP formulation, and it could produce solutions that were within 14% of the optimum. 2 7 0 6 1 3 5 4 10 9 8 11 Figure 11: MPEG4 with latency constraints 4 1 5 2 8 7 6 3 11 9 10 0 Figure 12: MPEG4 without latency constraints 0 4 6 7 1 3 8 5 10 9 2 11 Figure 13: VOPD with latency constraints 10 11 9 8 2 6 1 0 5 4 3 7 Figure 14: VOPD without latency constraints 6. "
2009,"Preemptive virtual clock - a flexible, efficient, and cost-effective QOS scheme for networks-on-chip.","Future many-core chip multiprocessors (CMPs) and systems-on-a-chip (SOCs) will have numerous processing elements executing multiple applications concurrently. These applications and their respective threads will interfere at the on-chip network level and compete for shared resources such as cache banks, memory controllers, and specialized accelerators. Often, the communication and sharing patterns of these applications will be impossible to predict off-line, making fairness guarantees and performance isolation difficult through static thread and link scheduling. Prior techniques for providing network quality-of-service (QOS) have too much algorithmic complexity, cost (area and/or energy) or performance overhead to be attractive for on-chip implementation. To better understand the preferred solution space, we define desirable features and evaluation metrics for QOS in a network-on-a-chip (NOC). Our insights lead us to propose a novel QOS system called Preemptive Virtual Clock (PVC). PVC provides strong guarantees, reduces packet delay variation, and enables efficient reclamation of idle network bandwidth without per-flow buffering at the routers and with minimal buffering at the source nodes. PVC averts priority inversion through preemption of lower-priority packets. By controlling preemption aggressiveness, PVC enables a trade-off between the strength of the guarantees and overall throughput. Finally, PVC simplifies network management through a flexible allocation mechanism that enables per-application bandwidth provisioning independent of thread count and supports transparent bandwidth recycling among an application's threads.","Preemptive Virtual Clock: A Flexible, Efﬁcient, and Cost-effective QOS Scheme for Networks-on-Chip Boris Grot Stephen W. Keckler Onur Mutlu† Depar tment of Computer Sciences The University of Texas at Austin {bgrot, skeckler@cs.utexas.edu} †Computer Architecture Laboratory (CALCM) Carnegie Mellon University onur@cmu.edu ABSTRACT 1. INTRODUCTION Future many-core chip multiprocessors (CMPs) and systemson-a-chip (SOCs) will have numerous processing elements executing multiple applications concurrently. These applications and their respective threads will interfere at the on-chip network level and compete for shared resources such as cache banks, memory controllers, and specialized accelerators. Often, the communication and sharing patterns of these applications will be impossible to predict oﬀ-line, making fairness guarantees and performance isolation diﬃcult through static thread and link scheduling. Prior techniques for providing network quality-of-service (QOS) have too much algorithmic complexity, cost (area and/or energy) or performance overhead to be attractive for on-chip implementation. To better understand the preferred solution space, we deﬁne desirable features and evaluation metrics for QOS in a network-on-a-chip (NOC). Our insights lead us to propose a novel QOS system called Preemptive Virtual Clock (PVC). PVC provides strong guarantees, reduces packet delay variation, and enables eﬃcient reclamation of idle network bandwidth without per-ﬂow buﬀering at the routers and with minimal buﬀering at the source nodes. PVC averts priority inversion through preemption of lower-priority packets. By controlling preemption aggressiveness, PVC enables a trade-oﬀ between the strength of the guarantees and overall throughput. Finally, PVC simpliﬁes network management through a ﬂexible allocation mechanism that enables perapplication bandwidth provisioning independent of thread count and supports transparent bandwidth recycling among an application’s threads. Categories and Subject Descriptors C.1.2 [Computer Systems Organization]: Multiprocessors—Interconnection architectures General Terms Design, Measurement, Performance Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. MICRO’09, December 12–16, 2009, New York, NY, USA. Copyright 2009 ACM 978-1-60558-798-1/09/12 ...$10.00. Power limitations of aggressive monolithic cores, design complexity considerations, and growing transistor budgets have recently pushed the semiconductor industry toward chip multiprocessors (CMPs) and complex Systems-On-aChip (SOCs). These single-die systems integrate execution cores, accelerators, custom IP blocks, and memories, providing an unprecedented degree of functionality on a single piece of silicon. Current commercial oﬀerings in this space range from Intel’s 8-core superscalar CMP [18] to a 64-core network and media processor from Tilera [21] to a 256-element reconﬁgurable processor array from Rapport, Inc. [16]. With continuing technology scaling, CMPs with hundreds to thousands of general and special-purpose cores are likely to appear in a variety of application domains in the near future. As the number of compute elements grows, so will the number of intra- and inter-application threads executing concurrently on a given substrate. These threads will compete for shared resources, such as cache space, specialized accelerators, on-chip network bandwidth, and oﬀ-chip memory bandwidth. As a result, ensuring application stability, scalability, and isolation in the face of increased resource sharing will become more important and more diﬃcult. Furthermore, a user or operating system may wish to increase the performance of one application at the expense of another by giving the former a greater share of some system resource. Thus, to ensure fairness and provide diﬀerentiated services, future CMP and SOC substrates will require an integrated quality-of-service (QOS) mechanism. Until recently, on-chip QOS research has focused on individual system end-points, such as cache banks or memory controllers, seeking to balance fairness, performance and cost when these resources are shared among multiple threads [12, 13, 11]. Unfortunately, such work ignores the shared interconnect used to access the individual resources. By ignoring the access medium, fairness at the end-points cannot be guaranteed. QOS research in conventional networks, on the other hand, has yielded elegant service disciplines that provide hard guarantees and good performance, but at high cost in terms of storage required at each routing node, buﬀer access energy, and in some cases, a scheduling algorithm’s computational complexity. These costs can be prohibitive in area-, energy- and latency-sensitive on-chip networks. Recent work on Globally Synchronized Frames (GSF) introduced a method to move much of the complexity from network routers into the source nodes [9]. Unfortunately, GSF suﬀers from several shortcomings, including 268 reliance on large source buﬀers, low throughput under some unstructured traﬃc patterns, and an inﬂexible bandwidth allocation mechanism. In this work, we seek to understand the qualities of an ideal QOS solution for networks-on-a-chip (NOCs). We draw on traditional QOS literature and supplement it with our own observations to enumerate the attribute set of an ideal NOC QOS scheme. We also consider the metrics for evaluating the diﬀerent approaches. Our insights lead us to propose Preemptive Virtual Clock (PVC), a novel QOS scheme speciﬁcally designed for cost- and performance-sensitive onchip interconnects. Unlike all prior approaches for providing network quality-of-service, PVC requires neither per-ﬂow buﬀering in the routers nor large queues in the source nodes. Instead, PVC provides fairness guarantees by tracking each ﬂow’s bandwidth consumption over a time interval and prioritizing packets based on the consumed bandwidth and established rate of service. PVC avoids priority inversion by preempting lower-priority messages. The system provides guarantees and low latency for preempted messages via a dedicated ACK/NACK network and a small window of outstanding transactions at each node. Unique to this approach is the ability to trade the strength of throughput guarantees of individual ﬂows for overall system throughput. Finally, PVC simpliﬁes network management by enabling perthread, per-application, or per-user bandwidth allocation. The rest of the paper is structured as follows. Section 2 motivates the work by outlining the requirements and the metrics for NOC QOS techniques and presents an overview of prior approaches for network quality-of-service. Section 3 introduces PVC and compares it to prior schemes based on the attributes from Section 2. Section 4 covers the evaluation methodology, while Section 5 presents the results of the evaluation. Section 6 concludes the paper. 2. MOTIVATION 2.1 NOC QOS Requirements An ideal NOC QOS solution should possess a number of attributes with regard to guarantees, performance and cost. In this section, we draw on traditional QOS literature and supplement it with our own observations to detail the desirable feature set. Items a, b, c, e, i, j are taken from or inspired by a similar list compiled by Stiliadis and Varma [20], while f comes from Demers et al. [3]. a) Fairness: Link bandwidth must be divided among requesting ﬂows equitably based on individual reserved rates for both guaranteed and excess service. b) Isolation of ﬂows: Rate-observing ﬂows should enjoy the illusion of a private network with bandwidth proportional to the speciﬁed rate, regardless of the behavior of other ﬂows. c) Eﬃcient bandwidth utilization: Flows should be free to claim idle network bandwidth regardless of their reserved rate or bandwidth usage history. d) Flexible bandwidth allocation: It should be possible to allocate bandwidth at granularity of a core, a multicore application, or a user. Coarser granularities simplify provisioning and improve bandwidth utilization. e) Low performance overhead: Compared to a similarly provisioned network with no QOS support, a QOSenabled network should enjoy approximately equal latency and overall throughput. f ) Delay proportional to bandwidth usage: Flows that observe their bandwidth share should enjoy faster service than bandwidth hogs. g) Low area overhead: Per-ﬂow buﬀering at each network node may be too expensive for on-chip networks that typically feature wormhole switching and a small number of virtual channels. h) Low energy overhead: Energy may be the biggest constraint in future CMPs and SOCs [14]. Minimizing buﬀering is one way to reduce the energy overhead of a QOS subsystem. i) Good scalability: As the network is scaled up in size, the QOS subsystem should be easy and cost-eﬀective to scale proportionately, without compromising performance or guarantees. j) Simplicity of implementation: Design and veriﬁcation time are important contributors to overall system cost, and a simpler QOS solution is generally preferred to one with greater complexity. 2.2 Metrics In addition to the standard area and energy metrics used for evaluating on-chip systems, QOS disciplines require dedicated metrics. Key among these are relative throughput, latency, and jitter. Relative throughput: The fairness criterion dictates that link bandwidth should be allotted equitably, in proportion to the speciﬁed rate. Given the mean throughput of a set of ﬂows with the same reserved rate, request rate and measurement interval, relative throughput can be measured by assessing the minimum, maximum, and standard deviation from the mean in the ﬂow set. A system provides strong throughput fairness when each node’s bandwidth consumption is close to the mean. Latency: The end-to-end latency of a ﬂow should be proportional to its hop count, reserved rate, and contention from other ﬂows. In the absence of contention, the delay imposed by the QOS mechanism should be minimal. On the other hand, when two or more ﬂows with the same speciﬁed rate converge on an output link, the QOS mechanism must ensure equal per-hop delay for the aﬀected ﬂows. As above, the key metrics are minimum, maximum, and standard deviation from the mean hop latency for a set of ﬂows sharing a port. Jitter: The variation in delay for a pair of packets in a ﬂow is commonly called jitter. Low jitter in the face of contention provides a strong illusion of a private network for each ﬂow, desirable for performance stability and isolation. QOS schemes that feature rate-proportional per-hop latency guarantees, as opposed to just end-to-end delay bounds, may naturally reduce jitter. The metric for jitter is termed packet delay variation (pdv), deﬁned for IP performance measurement as “the diﬀerence in end-to-end delay between selected packets in a ﬂow with any lost packets being ignored” [17]. The maximum pdv and standard deviation from the mean pdv within a ﬂow, as well as across ﬂows, are more important than the minimum observed jitter value. 2.3 QOS Service Disciplines A number of distinct disciplines have emerged over the years for providing fair and diﬀerentiated services at the network level. We partition these into three classes based on their bandwidth allocation strategy – ﬁxed, rate-based, and 269 frame-based – and cover the most important representatives of each class. 2.3.1 Fixed bandwidth allocation Approaches such as Weighted Round Robin use a static packet schedule to deliver hard guarantees at low implementation complexity. The cost, however, is potentially poor network utilization, as resources held by idle ﬂows cannot be rapidly redistributed to ﬂows with excess demand. 2.3.2 Rate-based approaches Rate-based service disciplines aim to allocate bandwidth to contending packets based on the provisioned rate. Idle bandwidth due to under-utilization by one or more ﬂows is instantaneously redistributed among the competing ﬂows. Service order is determined dynamically based on the set of active ﬂows and their respective reserved rates by computing the service time for each ﬂow and granting the ﬂow with the earliest deadline. In general, rate-based approaches excel at maximizing throughput and providing strong isolation, but necessitate per-ﬂow queueing and may require computationally expensive scheduling algorithms. Fair Queueing (FQ) is a well-known rate-based approach that emulates a bit-by-bit round-robin service order among active ﬂows on a packet basis [3]. Its generalized variant, Weighted Fair Queueing (WFQ), enables diﬀerentiated services by supporting diﬀerent service rates among the ﬂows. Both schemes oﬀer provably hard fairness guarantees at a ﬁne granularity and excellent bandwidth utilization. Unfortunately, computing the service time in FQ has O(N) complexity, where N is the number of active ﬂows at each scheduling step, making the algorithm impractical for most applications. In contrast, Virtual Clock [22] oﬀers a simple deadline computation that emulates a Time Domain Multiple Access (TDMA) scheduler but with ability to recycle idle slots. Packets are scheduled using virtual time slots, computed based on the assigned service rate. Packet service time is simply its ﬂow’s virtual clock value, which is incremented every time the ﬂow is serviced. In ﬂows that respect the reserved rate, termed rate-conformant ﬂows, virtual time tracks the service time under TDMA. Flows that exceed the speciﬁed rate “run ahead” of schedule by incrementing their virtual clock beyond the current round. Problematically, ﬂows that run ahead are sub ject to starvation by rate-conformant ﬂows until the rate-scaled real time catches up with their virtual clock. Both Fair Queueing and Virtual Clock require per-ﬂow queues and a sorting mechanism to prioritize ﬂows at each scheduling step, resulting in high storage overhead and scheduling complexity in networks with a large number of ﬂows. 2.3.3 Frame-based approaches Whereas rate-based disciplines aim for tight guarantees at a ﬁne granularity by scheduling individual packets, framebased approaches seek to reduce hardware cost and scheduling complexity by coarsening the bandwidth allocation granularity. The common feature of these schemes is the partitioning of time into epochs, or frames, with each ﬂow reserving some number of transmission slots within a frame. A disadvantage of frame-based disciplines lies in their coarse throughput and latency guarantees, which apply only at the frame granularity. Coarse-grained bandwidth allocation can cause temporary starvation of some ﬂows and high service rate for others, making jitter guarantees impossible. Frame-based approaches also require per-ﬂow buﬀering at each routing node, necessitating enough storage to buﬀer each ﬂow’s entire per-frame bandwidth allocation. Schemes such as Rotating Combined Queueing (RCQ) [7] that support multiple in-ﬂight frames to improve network bandwidth utilization incur additional area and energy overheads in the form of even greater buﬀer requirements. Globally Synchronized Frames (GSF) is a frame-based QOS approach recently proposed speciﬁcally for on-chip implementation [9]. GSF also employs a coarse-grained bandwidth reservation mechanism. However, it moves the buﬀering and much of the scheduling logic from the network routers into the source nodes, thereby reducing the routers’ area and energy overhead. Source nodes in GSF tag new packets with a frame number and slot them into their source queue. GSF supports bursts by allowing packets from future frames to enter the network, up to a maximum allowed burst size. A fast barrier network synchronizes the frames over the entire chip by detecting when the head frame has been drained and signaling a global frame roll-over. To ensure fast frame recycling, injection of new packets into the head frame is prohibited. Packets from multiple frames may be in the network at the same time, and age-based arbitration on the frame number is used to prioritize packets from older frames over younger ones. GSF does not specify the service order within a frame, preventing priority inversion by reserving a single virtual channel (VC) at each input port for the head frame; however, in-ﬂight packets from future frames may be blocked until their respective frames become the oldest. Although GSF signiﬁcantly reduces router complexity over prior approaches, it suﬀers from three important shortcomings that limit its appeal: performance, cost, and inﬂexible bandwidth allocation. The performance (throughput) limitations of GSF arise due to its source-based bandwidth reservation mechanism. With only limited support for excess service, bound by the ﬁnite number of in-ﬂight frames, GSF is inherently restricted in its ability to eﬃciently utilize network bandwidth. Once a source node has exhausted its burst quota, it is immediately throttled and restricted to its reserved allocation in each frame interval. Figure 1 highlights a scenario that compromises a node’s throughput despite idle network capacity. A set of nodes, in grey, all send traﬃc to a common destination, colored black. The combined traﬃc causes congestion around the black node, exerting backpressure on the sources and impeding global frame reclamation. As frame reclamation slows, an unrelated node, striped in the ﬁgure, in a diﬀerent region of the network suﬀers a drop in throughput. The striped node is only sending to its neighbor, yet is throttled upon exhausting its burst quota, letting the requested link go idle. We simulated this scenario on a 64-node network with an aggressive GSF conﬁguration (2000 cycle frame, 6-frame burst window, and 8 cycle frame reclamation) and equal bandwidth allocation among nodes, under the assumption that the actual communication pattern is not known in advance. We observed that throughput for the striped node saturates at around 10%, meaning that the link is idle 90% of the time. Increasing both the size of the frame and the burst window ten-fold made no diﬀerence in actual throughput once the striped node exhausted its burst capacity. 270                 ! ""# $%&           	   '()* +* '()* +* '()* +*  '()* +*  '()*+*  '()*+* ,-*.-( Figure 1: Scenario demonstrating poor bandwidth utilization with GSF. The grey nodes congest the center of the mesh, slowing down frame reclamation and compromising striped node’s throughput. Another drawback of GSF is the cost associated with the source queues, where packets are slotted to reserve bandwidth in future frames. Longer frames better amortize the latency of barrier synchronization and support bursty trafﬁc, but necessitate larger source queues. Our experiments, consistent with results in the original paper, show that in a 64-node network, a frame size of 1000 ﬂits or more is required to provide high throughput on many traﬃc patterns. To support asymmetric bandwidth allocation, whereby any node may reserve a large fraction of overall frame bandwidth, source queues must have enough space to buﬀer at least a full frame worth of ﬂits. Assuming a frame size of 1000 ﬂits and 16-byte links, GSF requires a 16 KB source queue at each network terminal. Scaling to larger network conﬁgurations requires increasing the frame size and source queues in proportion to the network size. Figure 2 shows the performance of GSF under the uniform random traﬃc pattern on a 256 node network with diﬀerent frame lengths and window sizes (number of in-ﬂight frames). To reach a level of throughput within 10% of a generic NOC network with no QOS support, GSF requires a frame size of 8000 ﬂits, necessitating 128 KB of storage per source queue. Finally, GSF is inﬂexible in its bandwidth allocation, as bandwidth may only be assigned at the granularity of individual nodes, complicating network management. For instance, a parallel application with a ﬂuctuating thread count running on multiple cores can cause a network to be reprovisioned every time a thread starts or ends, placing a burden on the OS or hypervisor. 3. PREEMPTIVE VIRTUAL CLOCK Our motivation in designing a new QOS system is to provide a cost-eﬀective mechanism for fairness and service differentiation in on-chip networks. Primary ob jectives are to minimize area and energy overhead, enable eﬃcient bandwidth utilization, and keep router complexity manageable to minimize delay. Another goal is to simplify network management through a ﬂexible bandwidth reservation mechanism to enable per-core, per-application, or per-user bandwidth allocation that is independent of the actual core/thread count. This section details the resulting scheme, which we term Preemptive Virtual Clock (PVC). 271 Figure 2: Performance of GSF with various frame (ﬁrst number in legend) and window (second number) sizes versus a similarly provisioned network without QOS support. 3.1 Overview Bandwidth allocation: As the name implies, PVC was partly inspired by Virtual Clock due its rate-based nature and low scheduling complexity. Each ﬂow in PVC is assigned a rate of service, which is translated into a certain amount of reserved bandwidth over an interval of time. Routers track each ﬂow’s bandwidth utilization, computing a packet’s priority based on its respective ﬂow’s bandwidth consumption and assigned rate. The packet with the highest priority at each arbitration cycle receives service. Similar to Virtual Clock, ﬂows may consume bandwidth beyond the reserved amount, potentially sub jecting them to subsequent starvation from rate-conformant ﬂows. This problem arises as a result of relying on past bandwidth usage in priority computation. To reduce the history eﬀect, PVC introduces a simple framing strategy. At each frame roll-over, which occurs after a ﬁxed number of cycles, bandwidth counters for all ﬂows are reset. Thus, PVC provides bandwidth and latency guarantees at frame granularity but uses rate-based arbitration within a frame. Note that because ﬂows are free to consume idle network bandwidth, PVC does not require multiple in-ﬂight frames or sophisticated frame completion detection to achieve good throughput. Figures 3 and 4 compare the framing schemes of GSF and PVC, respectively. GSF supports multiple in-ﬂight frames whose completion time is determined dynamically via a global barrier network that detects when all packets belonging to a frame have been delivered. In contrast, PVC has only one ﬁxed-duration frame active at any time. Packets in PVC are not bound to frames, and a given packet may enter the network in one frame interval and arrive in the next. Freedom from Priority Inversion: PVC uses relatively simple routers with a small number of virtual channels per input port. Without per-ﬂow queueing, packets from ﬂows that exceed their bandwidth allocation in a frame may block packets from rate-conformant ﬂows. Similarly, ﬂows that greatly exceed their assigned rate may impede progress for ﬂows that surpass their allocation by a small margin. Both situations constitute priority inversion. PVC uses a preemptive strategy to deal with such scenarios, removing lower priority packets from the network, thus allowing blocked packets of higher priority to make progress. To support retransmission of dropped packets, PVC re	 ;<=>?@A>B?< /0123452630 7 89: Figure 3: GSF framing strategy: multiple in-ﬂight frames; length determined dynamically via a global barrier network. quires a preemption recovery strategy. One option for preemption recovery is a timeout. Establishing a safe timeout interval is often diﬃcult, however. Additionally, timeouts necessitate large source buﬀers to support a suﬃcient number of outstanding transactions to cover the timeout delay. Instead, we choose to use a dedicated non-discarding ACK network for signaling packet completion and preemption events. The cost of such a network is low as its width is small compared to the wide on-chip data network. In addition, this cost may be amortized by integrating the network with the chip’s fault-tolerance logic to provide end-to-end data delivery guarantees, which may be required as substrates get less reliable due to technology scaling. As packets are sub ject to discard, they must be buﬀered at the source until an acknowledgement from the destination is received. In the case of dropped packets, preemption of the header ﬂit generates a NACK message to the source node. Once received at the source, the NACK triggers a retransmission of the dropped packets. Thus, PVC requires a small source window to buﬀer outstanding transactions. Advantageously, a smal l window size acts as a natural throttle, or rate-controller, preventing individual nodes from overﬂowing the network’s limited buﬀering. The window only needs to be big enough to support high throughput when the interconnect is congestion-free and allows for prompt ACK return. In our experiments, a 64-node network sees little beneﬁt from source windows larger than 30 ﬂits on most traﬃc patterns. As the network size is scaled up, the window size must increase in proportion to the network diameter to cover the longer ACK round-trip time. In a mesh topology, the diameter is proportional to the square root of the mesh size; thus, quadrupling a PVC network from 64 to 256 nodes requires doubling the source window to 60 ﬂits. Researchers have previously studied the use of preemption to overcome priority inversion in interconnection networks. Knauber and Chen suggest its use in wormhole networks for supporting real-time traﬃc [8]. Their work, however, does not consider impact on fairness, overall throughput, and recovery mechanisms. Song et al. also propose using preemption for real-time traﬃc [19]. Their scheme requires a dedicated FIFO at each router node where preempted packets are stored. The FIFO must have enough buﬀering to store a full-sized packet for each supported priority level, except the highest, requiring a signiﬁcant storage overhead in systems with a large number of priority levels. Their work also does not consider fairness and other QOS-related issues. Flow Tracking and Provisioning: Finally, PVC routers must track each ﬂow’s bandwidth utilization for scheduling and preemption purposes. While this requires additional storage, the presence of per-ﬂow state at each router oﬀers C DEF Figure 4: PVC framing strategy: frame; ﬁxed frame length. single in-ﬂight important advantages in network provisioning and bandwidth utilization. For instance, several threads from an application running on multiple cores can share the same ﬂow identiﬁer. The ability to combine multiple ﬂows into one enables per-application bandwidth allocation, reducing management overhead when the thread count changes over the lifetime of the application. In addition, coarser bandwidth allocation granularity enables better bandwidth utilization by allowing communication-intensive threads of an application to recover idle bandwidth from less active threads. 3.2 QOS Particulars 3.2.1 Preemption Throttling A common deﬁnition of priority inversion in a network is the presence of one or more packets of lower priority at a downstream node, impeding a higher priority packet’s progress. A PVC system based on this deﬁnition experiences very high preemption rates under congestion, considerably degrading throughput as a result. To address this problem, we use an alternative deﬁnition that potentially sacriﬁces some degree of fairness in exchange for improved throughput. Speciﬁcally, priority inversion in a PVC network occurs when a packet cannot advance because al l buﬀers (virtual channels) at the downstream port are held by packets of lower priority. Thus, as long as one or more downstream VCs belong to a packet of same or higher priority as the current one, preemption is inhibited. In addition, PVC employs three mechanisms for further controlling preemption aggressiveness and balancing fairness with throughput. The ﬁrst mechanism is the allocation of some reserved bandwidth per ﬂow per each frame interval. The amount of reserved bandwidth, in ﬂits, is a function of the frame size and the ﬂow’s reserved rate. Any ﬂit within the reserved envelope is not sub ject to preemption, forming the basis for PVC’s bandwidth guarantee. The second mechanism for preemption throttling is based on reducing the resolution of bandwidth counters by masking out some number of lower-order bits via a programmable coarsening mask. Doing so reduces the resolution of the computed priority values, eﬀectively forming coarser priority classes. Packets that map to the same priority class may not preempt each other. The ﬁnal preemption control technique built into PVC addresses a pathological case in which multiple retransmissions of a packet reduce a ﬂow’s priority by incrementing the bandwidth counters up to the preemption point. With each unsuccessful transmission attempt, the ﬂow’s priority is further reduced, compromising throughput. To avoid this pathology, PVC transmits the hop count up to the preemp272 OP Q RRHSTJHU GHIJ KLM NLKJ XY ZXY [ V W Q RRHSTJHU tion point as part of the NACK sent back to the source node. In turn, the source embeds the count in a dedicated ﬁeld of the retransmitted packet. This counter is decremented at each hop until it reaches zero and inhibits the update of the ﬂow’s bandwidth counter as long as it is non-zero. 3.2.2 Guarantees PVC is able to make four important guarantees: minimum bandwidth, fairness, worst-case latency, and non-preemption within a ﬂow. By combining the last guarantee with a deterministic routing function, the system can provide in-order delivery within a ﬂow. In order for these guarantees to be met, a PVC system must comply with the following requirements: 1. No link in the system is overbooked. Thus, for every link, the sum of provisioned rates across all ﬂows does not exceed 100%. 2. The number of reserved ﬂits for each ﬂow is no less than the size of the source window used for buﬀering outstanding transactions. 3. Resource arbitration collisions (multiple requesters with the same priority) are broken fairly (e.g., randomly). Similarly, when multiple packets at an input port have the same priority and one must be preempted, the selection mechanism is fair. The OS or hypervisor must satisfy the ﬁrst two requirements whenever the network is conﬁgured and rates are assigned to ﬂows. The last requirement is ensured at design time. Note that the ﬁrst requirement does not prevent ﬂows from exceeding the assigned rate whenever idle network bandwidth is available, as rate enforcement occurs only under contention. Minimum bandwidth: Each PVC ﬂow gets a certain number of reserved ﬂits, computed as a fraction of the frame size based on the ﬂow’s negotiated rate. These ﬂits are not preemptable. They also cannot be blocked by packets from other ﬂows that have exhausted their bandwidth reserve in the current frame, as preemption guarantees freedom from priority inversion. Finally, per the ﬁrst requirement above, no link in the system is overbooked. Thus, all reserved ﬂits that enter the system by the start of the frame are guaranteed to be delivered by the end. Fairness: A PVC network distributes excess bandwidth in a fair, rate-proportional manner, choosing the ﬂow with the lowest relative throughput (rate-adjusted bandwidth utilization) at each arbitration event. To resolve resource conﬂicts, PVC uses fair (per requirement 3) priority arbiters, described in Section 3.3. Note that the strength of this guarantee is a function of the resolution of the bandwidth counters used in priority computation. Worst-case Latency: Once a packet enters a source window, PVC guarantees its delivery by the end of the following frame interval. The guarantee is a direct outcome of requirement 2 and the minimum bandwidth guarantee. Basically, any packet in the source window will be within the reserved bandwidth cap in the new frame, thus assuring its delivery in that frame. Non-preemption within a ﬂow: In PVC, two packets belonging to the same ﬂow may never preempt each other. Monotonicity of the priority function guarantees freedom from priority inversion within a ﬂow. Priority is computed register. The resulting priority value is used for virtual channel and crossbar arbitration in subsequent cycles. Unfortunately, the above approach adds a new pipeline stage for priority computation, increasing router delay. To remove priority calculation from the critical path, we propose using the priority value computed at the previous hop for virtual channel arbitration in the ﬁrst cycle at a given node. Concurrent with VA, the ﬂow updates its bandwidth counter and priority, using the updated priority for any subsequent VA retries and switch arbitration requests. The resulting approach is safe if each source node has a unique ﬂow identiﬁer, as the ﬂow’s bandwidth utilization at the previous node is guaranteed to be no less than its usage through any output port at the current node. Thus, the new priority can never be lower than that of the previous hop. However, this technique is not safe if multiple sources share the same ﬂow identiﬁer, as the guarantee breaks down under a convergent traﬃc pattern. Fortunately, we can still use this approach with a minor modiﬁcation: if a ﬂow wins virtual channel arbitration in its ﬁrst cycle but the computed priority is lower than the value used for arbitration, the winning request is not granted and must rearbitrate with the updated priority. Priority arbiter: Allocation delay frequently determines the router’s clock frequency in conventional networks, necessitating fast arbiters. PVC beneﬁts from not requiring per-ﬂow buﬀering, which keeps arbitration complexity modest even as the network size is scaled up. At the core of our arbiter is a low-latency comparator design proposed by Harteros and Katevenis, which uses a binary comparison tree with several acceleration techniques based on fast adder circuits [5]. We anticipate that a single-cycle priority arbiter based on this comparator design can be realized for NOC networks that have up to 64 virtual channels per router. Preemption mechanism: To support preemption, PVC requires a modiﬁcation to the virtual channel allocator that enables it to assign a VC to a requester even when none of the VCs at a downstream port are free. For that purpose, PVC maintains Min priority and Max priority registers at each output port, corresponding to the downstream virtual channel with the minimum and maximum priority value, respectively. In parallel with virtual channel arbitration, each requester’s priority is compared to the value of the Max priority register. If the requester’s priority exceeds Max priority, the virtual channel corresponding to Min priority is tentatively marked for preemption. VA logic assigns this virtual channel to the winning requester if none of the legal VCs are free. Of course, any packet within the reserved bandwidth envelope is not eligible for preemption. In the next cycle, while the winning VC arbitrates for crossbar access, the resources associated with the preempted packet are released at the current node. If some part of the preempted packet has already been transferred, preemption logic sends a kil l signal to the downstream node over a dedicated wire. The process of releasing resources held by the packet is repeated at each downstream hop until the header ﬂit is encountered. Preemption of the header ﬂit generates a NACK message to the source, which triggers a retransmission of the message. 3.4 Comparison to Prior Approaches Table 1 compares three QOS schemes – WFQ, GSF, and PVC – on the feature set presented in Section 2.1. WFQ has Table 1: Feature comparison of QOS schemes. indicates good, ’o’ is fair, and ’-’ is poor. Feature WFQ GSF PVC + + + + o o + o + + + ’+’ a) Fairness b) Isolation c) Bandwidth utilization d) Flexible bandwidth allocation granularity e) Performance overhead f ) Delay proportional to bandwidth usage g) Area overhead h) Energy overhead i) Performance scalability j) Implementation complexity + + o + o o + + + + o o o excellent fairness guarantees and strong performance isolation that scale well with network size. However, it requires per-ﬂow queueing and complex scheduling, resulting in large area and energy cost, with potentially high per-hop latency. GSF, on the other hand, has simple routers and modest frame management hardware, yielding low router delay and low implementation complexity. However, by pushing much of the scheduling responsibility into the terminals, GSF sacriﬁces throughput and has no ﬂexibility in its bandwidth allocation. GSF’s other shortfall lies in its poor suitability to ﬁne-grained communication, as our experimental evaluation in Section 5 conﬁrms. Because injection into the head frame is disallowed, this scheme introduces additional latency under contention. Thus, delay is unrelated to bandwidth usage. In fact, aggressive senders can temporarily block network access to sources with low injection rates, making the scheme susceptible to a denial-of-service attack. PVC has good bandwidth eﬃciency, modest router complexity and low area overhead. A shortcoming of PVC compared to GSF is PVC’s higher implementation complexity, which stems from the distributed protocols associated with preemption and ACK/NACK handling, as well as the logic for per-ﬂow bandwidth tracking at each router node. Both PVC and GSF provide only fair isolation of ﬂows, which stems from their lack of per-ﬂow buﬀering at each router node. They also have some undesirable energy overheads. In PVC, the overhead results from re-transmission of packets, ﬂow table lookups, and the ACK network; in GSF, it is from source queue accesses. Finally, both approaches leave room for improvement with regard to performance scalability. As the network size is scaled up, GSF becomes increasingly prone to bandwidth coupling and other eﬃciency overheads that reduce its throughput. In PVC, more nodes increase the likelihood of contention which can cause preemptions and reduce throughput as a consequence. 4. METHODOLOGY We use a custom cycle-precise simulator to evaluate three QOS schemes – WFQ, GSF, and PVC – on performance and fairness using the metrics from Section 2.2. As a baseline, we use a generic NOC with no QOS support. Details of the simulation infrastructure are summarized in Table 2. Experiments: To evaluate the ability of diﬀerent schemes to meet fairness guarantees while maximizing throughput, we use hotspot and uniform random synthetic traﬃc pat274 Network Synthetic benchmarks PARSEC traces Baseline network WFQ network GSF network PVC network Table 2: Simulation methodology details; 64-node network (256 nodes). 64 and 256 nodes, 16 byte link width, dimension order routing hotspot and uniform random. 1- and 4-ﬂit packets, stochastically generated blackscholes, bodytrack, ferret, ﬂuidanimate, vips, x264: sim-medium datasets. 6 VCs per network port, 5 ﬂits per VC; 1 injection VC, 2 ejection VCs Per-ﬂow queueing at each router node: 64 (256) queues, 5 ﬂits per queue 2K (8K) frame size, 6 (24) frames in-ﬂight, 8 cycle frame reclamation delay; 6 VCs per network port with 1 reserved VC, 5 ﬂits per VC; 1 injection VC, 2 ejection VCs 50K cycle frame, 30 (60) ﬂit source window 6 VCs per network port with 1 reserved VC, 5 ﬂits per VC; 1 injection VC, 2 ejection VCs terns whose network behavior is easy to understand, simplifying analysis. The uniform random pattern is also used to understand how well the diﬀerent approaches scale when the network size is increased from 64 to 256 nodes. Additionally, we assess the ability of GSF and PVC, the two schemes without per-ﬂow buﬀering, to provide eﬃcient ﬁne-grained communication and performance isolation in the face of a denial-of-service attack. For this experiment, we dynamically combine traﬃc from PARSEC [1] application traces with synthetic “attack” traﬃc. The traces were collected using the M5 full-system simulator [2] executing PARSEC benchmarks in their entirety. Our infrastructure supports the six applications in Table 2; of these, we present results for blackscholes, ﬂuidanimate and vips as a representative subset. We also demonstrate PVC’s ability to provide diﬀerentiated services by specifying a custom bandwidth allocation on a hotspot traﬃc pattern. Finally, we evaluate energy and storage overheads of diﬀerent schemes. For energy analysis, we use modiﬁed versions of CACTI 6 [10] and ORION 2 [6]. For all conﬁgurations except PVC’s diﬀerentiated services experiment, we assume that the actual traﬃc pattern is not known ahead of time and allocate all ﬂows an equal share of network bandwidth. WFQ conﬁguration: Weighted Fair Queueing represents our ideal QOS solution with respect to fairness, performance isolation, and bandwidth utilization eﬃciency. Although we believe that WFQ is a poor ﬁt for most NOC substrates due its high buﬀer requirements and complex schedule computation, we use it as a yard-stick for evaluating the two other QOS schemes. We idealize the WFQ routers by endowing them with an unrealistically low 3-cycle pipeline latency in the contention-free case – the same latency enjoyed by GSF and PVC routers that have simple schedule computation and no per-ﬂow queueing. GSF conﬁguration: The baseline GSF conﬁguration in the 64-node network features a 2000-cycle frame, 6 in-ﬂight frames and an 8-cycle frame reclamation delay. The routers have 6 VCs per input port, with one reserved VC for the head frame. This conﬁguration is similar to the default setup in the original paper by Lee et al. [9], except that we use a shorter frame reclamation delay and larger frame size, both of which improve GSF’s performance. For the scalability experiment, we quadruple both the frame and window size to 8000 cycles/frame and 24 frames, ensuring good performance (as shown in Figure 2). PVC conﬁguration: In a PVC network, the choice of the frame size has important implications for both throughput and fairness. Larger frames are desirable to amortize various protocol overheads and minimize the eﬀect of gently relaxed fairness settings. On the other hand, longer frames may result in greater drift among the diﬀerent ﬂows’ bandwidth consumption, increasing the likelihood of preemption for ﬂows with high bandwidth utilization. Empirically, we found 50,000 cycles to be a good frame length for balancing these conﬂicting requirements. We compute each ﬂow’s reserved bandwidth quota by multiplying its rate by 95% of the frame size. Five percent of frame bandwidth is uncommitted, allowing PVC to tolerate various overheads, such as router delays and ACK return latencies, without compromising bandwidth guarantees. Our PVC baseline is conﬁgured to maximize fairness, potentially at the expense of throughput, using unmasked bandwidth counter values for priority computation. We also show the eﬀect of relaxed fairness settings on select experiments by increasing the bandwidth counter coarsening mask to 8 and 16 bits. The latter conﬁguration completely eliminates all preemptions by eﬀectively masking out the full value of the bandwidth counter. PVC’s router conﬁguration is similar to that of GSF with 6 VCs per port, including one for reserved ﬂits. Unlike GSF, PVC does not require a reserved VC, since preemption guarantees freedom from priority inversion. However, we found that reserving a VC can eliminate some preemptions, reducing energy and latency cost of retransmissions. PVC uses 30-ﬂit source windows for buﬀering outstanding packets for possible retransmission. In the 256-node network, we double the source window to 60 ﬂits. For the ACK network, we assume a simple design with single-ﬂit messages and a single 10-ﬂit buﬀer per input port. Message size is 16 bits in the 64 node network (20 bits with 256 nodes), which is suﬃcient to cover the address, index of the acknowledged packet, hop count to the preemption point (if applicable), and status (ACK or NACK). 5. EVALUATION 5.1 Quality-of-Service Results First, we evaluate the QOS schemes on their ability to provide fair bandwidth allocation in a highly congested network and compare them to a system without QOS support. We use a hotspot traﬃc pattern with a corner node as the epicenter, and simulate 5 million cycles after the warm-up interval. Per Section 2.2, we are interested in relative throughput of diﬀerent nodes. A tight distribution of throughput values across all ﬂows is desirable, indicating a fair allocation of bandwidth to all nodes. Table 3 shows the mean, minimum, and maximum throughput across the ﬂows for each conﬁguration. Both absolute throughput, in ﬂits, and relative, as a percentage of the 275 Table 3: Relative throughput of diﬀerent QOS schemes, in ﬂits. Maximum aggregate throughput in the measurement interval is 5 million ﬂits. total throughput (% of max) mean min (% of mean) max (% of mean) 4,999,972 (100%) 79,364 1,645 (2.1%) 100,966 (127.2%) 4,999,907 (100%) 79,363 79,333 (100.0%) 79,379 (100.0%) 4,763,217 (95.3%) 75,607 75,433 (99.8%) 75,737 (100.2%) 4,916,383 (98.3%) 78,038 77,042 (98.7%) 79,351 (101.7%) std dev (% of mean) 36,237 (45.7%) 10 (0.01%) 56 (0.07%) 607 (0.78%) No QOS WFQ GSF PVC Table 4: Packet delay variation (jitter). mean (cycles) max (cycles) std dev 264 20,675 214 63 63 0 63 1,949 239 63 1,645 30 No QOS WFQ GSF PVC schemes due to unordered packet service within a frame. In contrast, PVC’s standard deviation of jitter values is nearly eight times lower than GSF’s, thanks to PVC’s rate-based scheduling within a frame. Like GSF, PVC does not provide any jitter guarantees, as it is ultimately a frame-based approach. However, PVC’s rate-based features can reduce packet delay variation in many cases, as this example shows. mean, are depicted. We also include the standard deviation from the mean as well as aggregate system throughput (ﬁrst column). The latter is useful for assessing the eﬃciency of diﬀerent schemes in utilizing available bandwidth. In general, we see that all three QOS schemes are capable of fair bandwidth allocation. WFQ achieves the tightest distribution of bandwidth to nodes, beneﬁting from per-ﬂow queueing and a sophisticated scheduling policy. GSF also performs very well, as source-based bandwidth reservation ensures equitable bandwidth allocation within each frame. However, GSF has the lowest aggregate throughput of any scheme, exposing ineﬃciencies in its bandwidth allocation. PVC has the most slack in its bandwidth distribution, but still oﬀers good fairness with little deviation among nodes and standard deviation of just 0.8% of the mean throughput. Finally, a network with no QOS support oﬀers high aggregate throughput but no fairness, with the node farthest from the hotspot receiving just 2.1% of the mean bandwidth. Slack in PVC’s throughput fairness has two primary causes. The ﬁrst is due to ﬁxed frame length, which allows some ﬂows to be slightly ahead of their peers in bandwidth consumption by frame rollover. This favors nodes closer to the hotspot, as ﬂits from diﬀerent nodes progress in wavefronts. We attribute the second source of diminished fairness to our deﬁnition of priority inversion, described in Section 3.2.1, which inhibits preemptions whenever a downstream VC is held by a packet of same or higher priority as that of a requester upstream. Thus, multiple packets of lower priority can occupy other VCs at a given downstream port and make progress whenever the VC held by the higher priority packet experiences a stall. We also measure the packet delay variation, or jitter, associated with diﬀerent QOS approaches. We modify our experimental setup to generate only single-ﬂit packets, thus simplifying analysis. During the measurement phase, we compute the delay diﬀerence for each pair of consecutive packets within a ﬂow. We record all such diﬀerences, and use them to compute the metrics for each ﬂow. The aggregate mean, max and standard deviation across al l ﬂows is presented in Table 4. As expected, WFQ has the tightest distribution of jitter values, with virtually no variation across the ﬂows or within any ﬂow, beneﬁting from per-ﬂow queueing coupled with a powerful scheduling function. GSF, on the other hand, shows the worst distribution of jitter values among QOS 5.2 Throughput and Performance Scalability We use a uniform random traﬃc pattern to assess the performance of the diﬀerent QOS approaches in terms of latency and maximum throughput. This all-to-all workload is self-balancing, loading all bisection links uniformly and not favoring any particular node. In fact, no fairness mechanism is necessary to achieve equal bandwidth distribution among the network nodes. Thus, this pattern is eﬀective at exposing the performance overheads associated with the respective QOS approaches. Figure 6(a) shows the latency-throughput curves for the various schemes. Three PVC curves show the diﬀerence in throughput between our baseline (conservative) fairness setting and two relaxed conﬁgurations. Labels on the baseline PVC curve show the number of wasted hops due to dropped ﬂits as a percentage of all hop traversals at 20%, 25%, and 30% injection rates. The drop rate peaks at 35% injection rate with 5.9% of all hop traversals resulting in a preemption (not shown in the ﬁgure). The best throughput is achieved by the generic NOC due to high VC buﬀer utilization. In comparison, our WFQ implementation binds each ﬂow to a dedicated queue, causing head-of-line blocking within each ﬂow. GSF and the most lax PVC conﬁguration (PVC LAX16) have similar performance, but fall short of a QOS-oblivious network on throughput due to restrictions on VC utilization. In both of these schemes, multiple packets are not allowed to share a given virtual channel to avoid priority inversion. The NO QOS conﬁguration is not hampered by this restriction, allowing multiple packets to queue up behind each other in a VC, thereby improving buﬀer utilization and boosting throughput. The PVC network with the strictest fairness setting (PVC BASE) degrades throughput by 10% relative to the laxest conﬁguration (PVC LAX16) due to preemptions. Figure 6(b) shows the eﬀects of scaling the network size to 256 nodes. The relative performance of diﬀerent schemes remains unchanged. The fairest PVC conﬁguration again exhibits some throughput loss due to dropped packets, which result in 3.4% of hops wasted at a 15% injection rate and saturate near 30% injection rate (not shown in ﬁgure) with 9.5% of all hop traversals leading to a preemption. One way to combat the performance overhead of packet drop is through relaxed fairness settings, which the ﬁgure conﬁrms to be an eﬀective way to improve throughput. 276 ÍÎÏÐÑÒÏÓÑÔÕÏÖ×ÑÖÏØÔÙÚÔÙÔ×ÏÛÜ ÃÄÃÅÃÆÃÇÃÈÃÃ     (a) 64-node mesh ïðíñîðì òóì ô êëìíëî õö÷ì øùîú õö÷ì ûùüý õö÷ì ûùü þô  	      \377 ÈÃ ÈÊ ÈÆ ÈË ÄÄ ÄÌ ÄÇ ÊÈ ÊÅ ÝÞß àáâ ãäÞ åæâà çè é @ =@?(b) 256-node mesh Figure 6: Performance of WFQ, GSF and PVC on uniform random traﬃc. Labels on the PVC BASE curve show the number of retried hops as a percentage of total hop traversals. Table 5: Diﬀerential bandwidth allocation in PVC. min max standard throughput throughput deviation 98.8% 101.2% 1.6% 98.0% 104.5% 1.3% @ =A? < =>?  ! ""#$ % &'$"" () *  È Å É 5.3 Performance Isolation 10% allocation 1% allocation   01.2/1-	3-  +,-.,/ 456- 78/9 456- :8;	 456- :8;  To test the ability of NOC QOS schemes to provide performance isolation without per-ﬂow queueing, we orchestrate a denial of service (DOS) attack against multi-threaded applications from the PARSEC suite. Figure 7 shows the conﬁguration for this experiment. Black nodes in the left-most column are “aggressors” which send packets to the striped node in the lower-right corner of the mesh at an average rate of 20%. The rest of the nodes, including the striped node, belong to PARSEC threads. The aggressors may be a virus intentionally trying to disrupt network performance or may be benign threads accessing a shared cache bank at the noted location. We compare the average latency of PARSEC packets in this conﬁguration to their latency executing alone on a substrate without any interference. Our PVC baseline maps each core to a diﬀerent ﬂow with a distinct bandwidth allocation. However, PVC oﬀers the capability to map all threads of an application to a common ﬂow, allowing idle bandwidth from one application thread to be transparently used by another. This feature maximizes bandwidth utilization and reduces the likelihood of preemptions for communication-intensive threads. To evaluate the performance of PVC that maps all PARSEC threads to a single ﬂow, we provisioned the ﬂow with 7/8-ths of the network capacity, which is the sum of rates of individual PARSEC threads in our PVC baseline. The results of the evaluation are presented in Figure 8. Five bars for each of the three benchmarks show the average latency of PARSEC packets. The ﬁrst bar corresponds to a network with no QOS support; the second and third are for GSF and PVC baselines, respectively; the fourth bar shows the PVC conﬁguration with PARSEC threads aggregated into a single ﬂow; the last bar marks the performance of each PARSEC application executing with no attack traﬃc. Without QOS support, “aggressor” threads overwhelm network’s limited buﬀering, eﬀectively preventing PARSEC packets from entering the network. The rate at which PARSEC packets are able to acquire network resources is lower than their injection rate; as a result, their delays grow very large due to our open-loop simulation methodology. By comparison, both GSF and PVC oﬀer some degree of performance isolation. In a PVC network, the maximum latency increase for an average PARSEC packet over an isolated execution is 22%. This is signiﬁcantly better than the protection that GSF is able to oﬀer, which increases the latency over 500% in the worst case. The reason for GSF’s poor performance is its scheduling mechanism. Because GSF does not allow injection into the head (oldest) frame to accelerate frame reclamation, new packets are assigned to a future frame. This forces newly generated PARSEC packets to compete for buﬀer space with packets from aggressor threads that may belong to a more future frame, exposing PARSEC traﬃc to priority inversion. Importantly, GSF violates property (f ) from Section 2.1, which states that delay should be proportional to bandwidth usage and explains GSF’s poor performance in this scenario. Finally, we note that the aggregated PVC conﬁguration (PVC 1FLOW) shows even better resilience to the attack than the PVC baseline, increasing PARSEC’s average packet latency by just 6-7% over stand-alone execution. The improvement comes as a result of improved bandwidth utilization among PARSEC threads, as bandwidth reserved for threads that rarely communicate can be recycled among remaining threads. 5.4 Differentiated Services To better support concurrent execution of multiple applications on a single substrate, PVC allows for diﬀerential bandwidth allocation to satisfy applications’ diverse runtime requirements. To demonstrate PVC’s ability to enforce a diﬀerential bandwidth allocation, we modify our hotspot conﬁguration by provisioning each of four nodes with 10% of the bandwidth. These well-provisioned nodes are the three corners other than the hotspot, as well as a node in the center of the network at location h3, 3i. The rest of the nodes each get 1% of the bandwidth. The packet generators at the nodes exceed the provisioned rate, ensuring the relevance of the QOS mechanism. 277               KCIDLC BHG NOOOOOOO NOOOOOO NOOOOO NOOOO NNONOONOOO BCDDEC BFG BEB EJ PQRSTUSVWQXU ED EG MB BC BHGCIJD BBB Y QZ[ EL EI EKMJ HE EL ED EG MI Figure 7: PARSEC setup [5] K. Harteros and M. Katevenis. Fast Parallel Comparison Circuits for Scheduling. Technical Report TR-304, FORTH-ICS, March 2002. [6] A. Kahng, B. Li, L.-S. Peh, and K. Samadi. Orion 2.0: A fast and accurate noc power and area model for early-stage design space exploration. In Design, Automation, and Test in Europe, pages 423–428, April 2009. [7] J. H. Kim and A. A. Chien. Rotating Combined Queueing (RCQ): Bandwidth and Latency Guarantees in Low-Cost, High-Performance Networks. In International Symposium on Computer Architecture, pages 226–236, 1996. [8] K. Knauber and B. Chen. Supporting Preemption in Wormhole Networks. In COMPSAC ’99: 23rd International Computer Software and Applications Conference, pages 232–238, 1999. [9] J. W. Lee, M. C. Ng, and K. Asanovic. Globally-Synchronized Frames for Guaranteed Quality-of-Service in On-Chip Networks. In International Symposium on Computer Architecture, pages 89–100, 2008. [10] N. Muralimanohar, R. Balasubramonian, and N. Jouppi. Optimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0. International Symposium on Microarchitecture, pages 3–14, December 2007. [11] O. Mutlu and T. Moscibroda. Stall-Time Fair Memory Access Scheduling for Chip Multiprocessors. In MICRO, pages 146–160, 2007. [12] K. J. Nesbit, N. Aggarwal, J. Laudon, and J. E. Smith. Fair Queuing Memory Systems. In MICRO, pages 208–222, 2006. [13] K. J. Nesbit, J. Laudon, and J. E. Smith. Virtual private caches. In International Symposium on Computer Architecture, pages 57–68, 2007. [14] J. D. Owens, W. J. Dally, R. Ho, D. J. Jayasimha, S. W. Keckler, and L.-S. Peh. Research challenges for on-chip interconnection networks. IEEE Micro, 27(5):96–108, 2007. [15] L.-S. Peh and W. J. Dally. A Delay Model and Speculative Architecture for Pipelined Routers. In International Symposium on High-Performance Computer Architecture, pages 255–266, January 2001. [16] KC256. http://en.wikipedia.org/wiki/Kilocore. [17] IP Packet Delay Variation Metric for IP Performance Metrics. RFC 3393. http://www.ietf.org/rfc/rfc3393.txt. [18] S. Rusu, S. Tam, H. Muljono, J. Stinson, D. Ayers, J. Chang, R. Varada, M. Ratta, and S. Kottapalli. A 45nm 8-Core Enterprise Xeon Processor. In International Solid-State Circuits Conference, pages 98–99, February 2009. [19] H. Song, B. Kwon, and H. Yoon. Throttle and Preempt: A New Flow Control for Real-Time Communications in Wormhole Networks. In International Conference on Paral lel Processing, pages 198–202, 1997. [20] D. Stiliadis and A. Varma. Design and Analysis of Frame-Based Fair Queuing: A New Traﬃc Scheduling Algorithm for Packet Switched Networks. In SIGMETRICS, pages 104–115, 1996. [21] D. Wentzlaﬀ, P. Griﬃn, H. Hoﬀmann, L. Bao, B. Edwards, C. Ramey, M. Mattina, C.-C. Miao, J. F. B. III, and A. Agarwal. On-Chip Interconnection Architecture of the Tile Processor. IEEE Micro, 27(5):15–31, September/October 2007. [22] L. Zhang. Virtual Clock: A New Traﬃc Control Algorithm for Packet Switching Networks. In SIGCOMM, pages 19–29, 1990. In the 64-node network, PVC has 1.5 times less buﬀering than WFQ and 10 times less than GSF. In the larger network, PVC’s storage footprint is 3 times smaller than WFQ’s and 20 times smaller than GSF. Although the difference between WFQ and PVC may not appear signiﬁcant, WFQ’s scheduling and buﬀering overheads are in the critical path of each router node, which is undesirable in latency and energy sensitive on-chip interconnects. 6. CONCLUSION Future CMP and SOC substrates will integrate hundreds or thousands of compute and memory elements on a single die. These elements will be connected by an on-chip network, which will shoulder the responsibility of providing fair access to shared resources while meeting performance, area, and energy targets. Prior network QOS schemes suﬀer from high buﬀer overheads, complex scheduling functions or poor bandwidth utilization, motivating us to propose Preemptive Virtual Clock, a novel QOS scheme speciﬁcally designed for on-chip interconnects. By combining features of frame-based and rate-based approaches, PVC provides strong guarantees, enforces ﬂow isolation, and enables eﬃcient bandwidth utilization with modest hardware cost and complexity. PVC does not require per-ﬂow buﬀering, reducing router area and energy footprint. Priority inversion in a PVC network is averted through preemption of lowerpriority packets. To support preemption, PVC requires a dedicated low-bandwidth ACK network and a small window of outstanding transactions at each node. Finally, PVC enables ﬂexibility in network provisioning by allowing bandwidth to be allocated at any granularity from a single thread to an application to a user. An evaluation of PVC in a 64-node network shows that it can guarantee fairness and provide diﬀerentiated services with low latency and good throughput. PVC also delivers strong performance isolation, demonstrated in a denial-ofservice scenario against three PARSEC benchmarks. Results conﬁrm that the average latency of PARSEC packets increases by less than 22% with PVC over their execution in isolation. In comparison, a previously proposed NOC QOS scheme called GSF causes latency to increase by up to 500%. Acknowledgments This research is supported by NSF CISE Infrastructure grant EIA-0303609 and NSF grant CCF-0811056. 7. "
2009,Application Specific Routing Algorithms for Networks on Chip.,"In this paper we present a methodology to develop efficient and deadlock free routing algorithms for Network-on-Chip (NoC) platforms which are specialized for an application or a set of concurrent applications. The proposed methodology, called application specific routing algorithm (APSRA), exploits the application specific information regarding pairs of cores which communicate and other pairs which never communicate in the NoC platform to maximize communication adaptivity and performance. The methodology also exploits the known information regarding concurrency/non-concurrency of communication transactions among cores for the same purpose. We demonstrate, through analysis of adaptivity as well as simulation based evaluation of latency and throughput, that algorithms produced by the proposed methodology give significantly higher performance as compared to other deadlock free algorithms for both homogeneous as well as heterogeneous 2D mesh topology NoC systems. For example, for homogeneous mesh NoC, APSRA results in approximately 30% less average delay as compared to odd-even algorithm just below saturation load. Similarly the saturation load point for APSRA is significantly higher as compared to other adaptive routing algorithms for both homogeneous and non-homogeneous mesh networks.",
2008,Energy- and Performance-Aware Incremental Mapping for Networks on Chip With Multiple Voltage Levels.,"Achieving effective run-time mapping on multiprocessor systems-on-chip (MPSoCs) is a challenging task, particularly since the arrival order of the target applications is not known a priori. This paper targets real-time applications which are dynamically mapped onto embedded MPSoCs, where communication happens via the Network-on-Chip (NoC) approach, and resources connected to the NoC have multiple voltage levels. We address precisely the energy- and performance-aware incremental mapping problem for NoCs with multiple voltage levels and propose an efficient technique (consisting of region selection and node allocation) to solve it. Moreover, the proposed technique allows for new applications to be added to the system with minimal in- terprocessor communication overhead. Experimental results show that the proposed technique is very fast, and as much as 50% communication energy savings can be achieved compared to using an arbitrary allocation scheme.",
2009,A communication characterisation of Splash-2 and Parsec.,"Recent benchmark suite releases such as Parsec specifically utilise the tightly coupled cores available in chip-multiprocessors to allow the use of newer, high performance, models of parallelisation. However, these techniques introduce additional irregularity and complexity to data sharing and are entirely dependent on efficient communication performance between processors. This paper thoroughly examines the crucial communication and sharing behaviour of these future applications. The infrastructure used allows both accurate and comprehensive program analysis, employing a full Linux OS running on a simulated 32-core x86 machine. Experiments use full program runs, with communication classified at both core and thread granularities. Migratory, read-only and producer-consumer sharing patterns are observed and their behaviour characterised. The temporal and spatial characteristics of communication are presented for the full collection of Splash-2 and Parsec benchmarks. Our results aim to support the design of future communication systems for CMPs, encompassing coherence protocols, network-on-chip and thread mapping.",
2006,A Statistical Traffic Model for On-Chip Interconnection Networks.,"Network traffic modeling is a critical first step towards understanding and unraveling network power/performancerelated issues. Extensive prior research in the area of classic networks such as the Internet, Ethernet, and wireless LANs transporting TCP/IP, HTTP, and FTP traffic among others, has demonstrated how traffic models and model-based synthetic traffic generators can facilitate understanding of traffic characteristics and drive early-stage simulation to explore a large network design space. Though on-chip networks (a.k.a networks-on-chip (NoCs)) are becoming the de-facto scalable communication fabric in many-core systems-on-a-chip (SoCs) and chip multiprocessors (CMPs), no on-chip network traffic model that captures both spatial and temporal variations of traffic has been demonstrated yet. As available on-chip resources increase with technology scaling, enabling a myriad of new network architectures, NoCs need to be designed from the application’s perspective. In this paper we propose such an empirically-derived network on-chip traffic model for homogeneous NoCs. Our comprehensive model is based on three statistical parameters described with a 3-tuple, and captures the spatio-temporal characteristics of NoC traffic accurately with less than 5% error when compared to actual NoC application traces gathered from fullsystem simulations of three different chip platforms. We illustrate two potential uses of our traffic model: how it allows us to characterize and gain insights on NoC traffic patterns, and how it can be used to generate synthetic traffic traces that can drive NoC design-space exploration.",
2012,Globally Synchronized Frames for guaranteed quality-of-service in on-chip networks.,"Future chip multiprocessors (CMPs) may have hundreds to thousands of threads competing to access shared resources, and will require quality-of-service (QoS) support to improve system utilization. Although there has been significant work in QoS support within resources such as caches and memory controllers, there has been less attention paid to QoS support in the multi-hop on-chip networks that will form an important component in future systems. In this paper we introduce globally-synchronized frames (GSF), a framework for providing guaranteed QoS in on-chip networks in terms of minimum bandwidth and a maximum delay bound. The GSF framework can be easily integrated in a conventional virtual channel (VC) router without significantly increasing the hardware complexity. We rely on a fast barrier network, which is feasible in an on-chip environment, to efficiently implement GSF. Performance guarantees are verified by both analysis and simulation. According to our simulations, all concurrent flows receive their guaranteed minimum share of bandwidth in compliance with a given bandwidth allocation. The average throughput degradation of GSF on a 8times8 mesh network is within 10% compared to the conventional best-effort VC router in most cases.","International Symposium on Computer Architecture International Symposium on Computer Architecture Globally-Synchronized Frames for Guaranteed Quality-of-Service in On-Chip Networks Jae W. Lee, Man Cheuk Ng Krste Asanovi ´c Computer Science and Artiﬁcial Intelligence Laboratory Massachusetts Institute of Technology Cambridge, MA 02139 {leejw, mcn02}@csail.mit.edu Computer Science Division, EECS Department University of California at Berkeley Berkeley, CA 94720-1776 krste@eecs.berkeley.edu Abstract Future chip multiprocessors (CMPs) may have hundreds to thousands of threads competing to access shared resources, and will require quality-of-service (QoS) support to improve system utilization. Although there has been signiﬁcant work in QoS support within resources such as caches and memory controllers, there has been less attention paid to QoS support in the multi-hop on-chip networks that will form an important component in future systems. In this paper we introduce Globally-Synchronized Frames (GSF), a framework for providing guaranteed QoS in onchip networks in terms of minimum bandwidth and a maximum delay bound. The GSF framework can be easily integrated in a conventional virtual channel (VC) router without signiﬁcantly increasing the hardware complexity. We rely on a fast barrier network, which is feasible in an on-chip environment, to efﬁciently implement GSF. Performance guarantees are veriﬁed by both analysis and simulation. According to our simulations, all concurrent ﬂows receive their guaranteed minimum share of bandwidth in compliance with a given bandwidth allocation. The average throughput degradation of GSF on a 8×8 mesh network is within 10 % compared to the conventional best-effort VC router in most cases. 1 Introduction Advances in fabrication technology allow the integration of many processors on a chip to form a chip multiprocessor (CMP), possibly in the form of a complex system-on-a-chip (SoC) with custom application accelerators (Figure 1). These platforms will be required to support a variety of complex application workloads, with possibly hundreds to thousands of concurrent activities competing for shared platform resources. Without effective quality-of-service (QoS) support, the gap between best-case generalpurpose processor generalpurpose processor applicationspecific accelerator processors R R router R R R R highly-structured scalable on-chip network on-chip memory bank (cache) memory controller I/O interface shared on-chip  resources Figure 1: A complex system-on-a-chip containing a chip-scale multiprocessor and application accelerators communicating with memory and I/O resources over a multi-hop on-chip network. and worst-case throughput will continue to grow, requiring overprovisioning and hence poor utilization of platform resources [11, 12, 13, 18]. We believe future integrated platforms must implement robust QoS support for both performance isolation and differentiated services. Performance isolation is the property that a minimum level of performance is guaranteed regardless of other concurrent activities (e.g., preventing denialof-service attacks to DRAM channels [21]). Differentiated services is the ability to allocate each resource ﬂexibly among competing tasks. Robust QoS support is only possible if all shared resources are managed together, as an application’s guaranteed service level is determined by the weakest guarantee for any of its shared resources. For example, allocating a portion of off-chip memory bandwidth at a memory controller is ineffective if the on-chip network does not guarantee adequate bandwidth to transport memory requests and responses. Even in a case where the on-chip network is not a bandwidth bottleneck, tree saturation [27] can produce a tree of waiting packets that fan out from a hotspot resource, 1063-6897/08 $25.00 © 2008 IEEE 1063-6897/08 $25.00 © 2008 IEEE DOI 10.1109/ISCA.2008.31 DOI 10.1109/ISCA.2008.31 89 89 thereby penalizing remote nodes in delivering requests to the arbitration point for the hotspot resource. Figure 2 provides a motivational example, showing how poorly multihop on-chip networks perform with no QoS support. Although there has been signiﬁcant prior work in QoS support for other on-chip resources such as memory controllers (often combined with on-chip bus) [3, 15, 18, 22] and shared cache banks [13, 14, 23, 26], there has been less work on QoS support for multi-hop on-chip networks in programmable platforms. In this paper, we present a new scheme, GloballySynchronized Frames (GSF), to implement QoS for multihop on-chip networks. GSF provides guaranteed and differentiated bandwidth as well as bounded network delay without signiﬁcantly increasing the complexity of the on-chip routers. In a GSF system, time is coarsely quantized into “frames” and the system only tracks a few frames into the future to reduce time management costs. Each QoS packet from a source is tagged with a frame number indicating the desired time of future delivery to the destination. At any point in time, packets in the earliest extant frame are routed with highest priority but sources are prevented from inserting new packets into this frame. GSF exploits fast on-chip communication by using a global barrier network to determine when all packets in the earliest frame have been delivered, and then advances all sources and routers to the next frame. The next oldest frame now attains highest priority and does not admit any new packets, while resources from the previously oldest frame are recycled to form the new futuremost frame. Provided that the pattern of injected packets in each frame does not oversubscribe the capacity of any hardware link, the system can switch frames at a rate that sustains any desired set of differentiated bandwidth ﬂows with a bounded maximum latency. Note that bandwidth and latency are decoupled in this system, as multiple frames can be pipelined through the system giving a maximum latency of several frame switching times. The scheme does not maintain any per ﬂow information in the routers, which reduces router complexity and also avoids penalizing short-lived ﬂows with a long route conﬁguration step. The scheme supports bursty trafﬁc, and allows best-effort trafﬁc to be simultaneously supported with little loss of network utilization compared to a pure best-effort scheme. 2 Related Work We begin with a survey of related work which we divide into three parts. We ﬁrst examine schemes to manage resources with centralized arbitration, such as a memory controller or a shared bus, where providing QoS is relatively easy because there is a single gateway through which all requests pass. We next examine earlier work in distributed QoS systems, where QoS is more difﬁcult to provide as each request passes through multiple stages of arbitration. Finally, we examine other proposals for QoS in on-chip networks. 2.1 QoS Support for Resources with Centralized Arbitration Off-chip memory bandwidth is often a performance bottleneck and is a natural target for QoS support. For example, to target real-time applications, Philips’ TM-1 processor supports bandwidth and latency guarantees among one VLIW processor and four DMA engines [3]. More recently, Nesbit et al. have proposed a QoS memory system for CMPs based on a Fair Queueing (FQ) algorithm [22]. The FQ algorithm requires the memory controller to have per-ﬂow queues and maintain per-ﬂow statistics such as virtual start and ﬁnish times, which causes a scalability concern for future manycore processors. The resource allocation management unit of the Cell Broadband Engine supports QoS for system memory and I/O interfaces [15]. To reduce the overhead of per-ﬂow data structures, each requester is assigned to a resource allocation group (RAG) and the system allocates a percentage of the managed resources to each RAG. There are also proposals for QoS provision for shared on-chip caches. Suh et al. propose a non-uniform cache partitioning scheme to minimize the overall miss rate, but without consideration of guaranteed services to an individual thread [26]. Iyer’s cache controller in the CQoS framework enforces the priority of each thread to allocate cache lines appropriately [14]. Both schemes manage cache space but not access bandwidth. Virtual Private Caches (VPC) manage both shared cache bandwidth and storage [23]. The QoS-capable shared resources discussed in this section are important building blocks for guaranteed QoS systems, but QoS support from the on-chip network is also required to make system-level QoS guarantees possible. 2.2 QoS Support for Resources with Distributed Arbitration Distributed shared resources, most notably multi-hop onchip and off-chip networks, require multiple stages of arbitration, which make it more challenging to provide guaranteed service to a ﬂow. Several approaches have been developed to address this issue, either for the IP networks, or for multichip multiprocessor networks. (Weighted) Fair Queueing [7] and Virtual Clock [32] were developed for QoS in long-haul IP networks where large buffers are available. These achieve fairness and high network utilization, but each router is required to maintain per-ﬂow state and queues which would be impractical in an on-chip network. 9090 accepted throughput [flits/cycle/node] accepted throughput [flits/cycle/node] accepted throughput [flits/cycle/node] 0.06 0.04 0.02 0 0.06 0.04 0.02 0 0.06 0.04 0.02 0 12345678 nodeindex(Y) 12345678 ( X ) d e x i n d e n o (a) round-robin scheduling with dimension-ordered routing 12345678 nodeindex(Y) 12345678 ( X ) d e x i n d e n o (b) round-robin scheduling with minimal-adaptive routing 12345678 ( X ) d e x i n 12345678 nodeindex(Y) d e n o (c) GSF scheduling with dimension-ordered routing Figure 2: Motivation for QoS in on-chip networks. All nodes generate trafﬁc toward a hotspot shared resource located at (8,8) (indicated by arrow) with injection rate of 0.05 (ﬂits/cycle/node), and the bar graph shows accepted service rate per node by the hotspot resource. In (a), locally-fair round-robin (RR) scheduling leads to globally-unfair bandwidth usage, penalizing remote nodes. The minimal-adaptive routing in (b) eliminates the imbalance of trafﬁc between x and y directions in (a), and possibly helps mitigate the problem in a lightly-congested network, but does not fundamentally resolve the problem. Our proposed GSF scheme in (c) guarantees fair bandwidth allocation among all sharers. All three networks achieve comparable average throughput. See Section 6.1 for detailed simulation setup. In multi-rate channel switching [29], the source rate of a ﬂow is ﬁxed at an integer multiple of a basic rate before the source starts transmission and remains unchanged for the duration of the ﬂow. Because of the ﬁxed rate, it cannot claim unused bandwidth efﬁciently, which leads to low network utilization. Source throttling dynamically adjusts the trafﬁc injection rate at a source node primarily for congestion control [27]. This keeps the network from suffering overall throughput degradation beyond the saturation point, but does not provide QoS to individual ﬂows. Age-based arbitration is known to provide strong global fairness. Each packet (or ﬂit) carries information to indicate its age, either a counter updated at every hop [25], or a timestamp issued when the packet ﬁrst enters the network from which age can be calculated by subtracting from the current time [5]. The oldest packet wins in any arbitration step. This approach lacks ﬂexibility in bandwidth allocation because it does not allow for asymmetric resource allocation, and requires sophisticated logic to handle aging, arbitration and counter rollover. Rotating Combined Queueing (RCQ) is designed for a multiprocessor and provides predictable delay bounds and bandwidth guarantees without per-ﬂow queues at intermediate nodes (though it still maintains per-ﬂow statistics) [16]. The idea of rotating priorities in a set of queues is similar to GSF, but GSF further simpliﬁes the router using global information, which is only feasible in an on-chip environment. With RCQ, each packet is assigned a local frame number using per-ﬂow statistics upon arrival at every node on the path. In contrast, the frame number in the GSF is global, which eliminates expensive book-keeping logic and storage at each node. 2.3 QoS-Capable On-Chip Networks The on-chip environment has different opportunities and challenges compared to the off-chip environment, leading to different design tradeoffs. For example, on-chip networks are buffer (power) limited while multiprocessor networks are often pin-bandwidth limited. Network latencies differ by multiple orders of magnitude, which affects the cost of synchronization. The following brieﬂy introduces several proposals for QoS support in on-chip networks, representing the current state-of-the-art. Æthereal uses pipelined time-division-multiplexed (TDM) circuit switching to implement guaranteed performance services [10]. Each QoS ﬂow is required to explicitly set up a channel on the routing path before transmitting the ﬁrst payload packet, and a ﬂow cannot use more than its guaranteed bandwidth share even if the network is underutilized. To mitigate this problem, Æthereal adds a best-effort network using separate queues, but this introduces ordering issues between the QoS and best-effort ﬂows. SonicsMX supports guaranteed bandwidth QoS without explicit channel setup [30]. However, each node has to maintain per-thread queues, which make it only suitable for a small number of threads (or having multiple sources share a single queue). The Nostrum [20] Network-on-Chip (NoC) employs a variant of TDM using virtual circuits for allocating bandwidth. The virtual circuits are set up semi-statically across routes ﬁxed at design time and only the bandwidth is variable at runtime, which is only suitable for applicationspeciﬁc SoCs. The MANGO clockless NoC [2] partitions virtual channels (VCs) into two classes: Guaranteed Service (GS) and Best-Effort (BE). A ﬂow reserves a sequence of GS VCs along its path for its lifetime. Therefore, the 9191 number of concurrent GS ﬂows sharing a physical channel is limited by the number of GS VCs (e.g., 8 in [2]). Felicijan et al. propose a clockless NoC which provides differentiated services by prioritizing VCs. Though this approach delivers improved latency for certain ﬂows, no hard guarantees are provided [8]. 3 Globally-Synchronized Frames (GSF) In this section, we present the design of GSF starting from an idealized deadline-based arbitration scheme for bandwidth guarantees. We then transform this scheme stepby-step into an implementable GSF queueing and scheduling algorithm. 3.1 Global Deadline-Based Arbitration for Bandwidth Guarantees GSF was originally inspired by deadline-based arbitration, which is a generalization of age-based arbitration [1, 5, 6, 25]. In age-based arbitration, each packet carries a global timestamp, issued when the packet enters the network, and each arbiter (router) forwards the packet with the earliest timestamp ﬁrst. Instead of using the timestamp, we allow each source to assign a deadline other than the current time according to a deadline assignment policy. Our premise is that we can achieve a desired ﬂow property, including guaranteed minimum bandwidth, by controlling deadline assignment policy, at least in an idealized setup. Figure 3 shows a network from such an idealized setup, where each queue is a perfect priority queue with inﬁnite capacity, capable of instantly dequeuing the packet with the earliest deadline. Dotted rectangles are a network component which Cruz [4] introduced and named “MUX”. Since we assume zero-cycle delay for arbitration and queue bypassing, the entire network conceptually reduces to a single priority queue having four input ports and one output port, with a total ordering among all packets according to their deadlines. To provide bandwidth guarantees, we assign the deadline for the n-th packet of Flow i (dn i ) as follows: i (ρi ) = M AX [current time, dn−1 dn i ] + Ln i /(ρiC ) where ρi is the guaranteed minimum bandwidth of Flow i represented as a fraction of channel bandwidth C (0 ≤ ρi ≤ 1) and Ln i is the length of the n-th packet of Flow i. This formula directly follows from what is known as the virtual ﬁnish time in the Fair Queueing algorithm [7]. The deadline speciﬁes the time when a packet’s last bit arrives at the destination if the channel were inﬁnitely divisible and shared by multiple packets simultaneously transmitting according to their guaranteed shares (ρ’s), provided we ignore the network traversal delay, which is dependent upon a unit of payload data  with associated deadline tag bottleneck link (channel rate C) src1 src2 •• •• •• •• MUX1 arbiter 1 src3 src4 arbiter 2 MUX2 •• •• •• •• •• •• •• •• MUX3 arbiter 3 sink Figure 3: A three-node queueing network with perfect priority queues with inﬁnite capacity. Dotted rectangles are a network component called “MUX”, which merges two incoming ﬂows into a single outgoing one. Each packet carries an associated deadline and the priority queue can dequeue the packet having the earliest deadline. The arbiter and the priority queue are assumed to have zero-cycle delay, which implies a packet just generated at any source can be immediately forwarded to the sink at channel rate C through the combinational path if the packet wins all arbitrations on the path. each ﬂow’s distance from the destination. Figure 4 compares three arbitration schemes: round-robin, age-based and deadline-based with the deadline assignment policy presented above. Note that the deadline-based scheme provides bandwidth distribution to all ﬂows proportional to the ratio of ρ’s at all congested links. This result holds even if we have non-zero delay for arbitration and/or queue bypassing as long as the priority queue has an inﬁnite capacity. In such a case, two ﬂows sharing a congested link eventually enter into the steady state of proportional bandwidth sharing after a ﬁnite winning (losing) streak by the remote (local) node starting when the two ﬂows ﬁrst meet at the congested link. The length of the winning (losing) streak is determined by the relative difference of the distance to the congested link. Although deadline-based arbitration provides minimum bandwidth guarantees to ﬂows using the proposed policy in the idealized setup, there are several issues that make this scheme infeasible to implement. First, the scheme is based on perfect priority (sorting) queues and inﬁnite-sized buffers. Second, there is a large overhead for sending and storing the deadline along with the payload data. Therefore, we propose a practical implementation approximating the behavior of the ideal deadline-based arbitration, called baseline GSF. 3.2 Baseline GSF To make deadline-based arbitration practical, we adopt a frame-based approach [31]. The original deadline-based arbitration is a priority-based approach, where competing packets’ priorities are compared to determine which packet is allocated buffer space and switching bandwidth ﬁrst. In contrast, a frame-based approach groups a ﬁxed number of time slots into a frame and controls the bandwidth allocation by allocating a certain number of ﬂit injection slots per frame to each ﬂow. Figure 5 shows a step-by-step transformation towards 9292 accepted throughput @ sink [flits/cycle] accepted throughput @ sink [flits/cycle] 0.6 0.5 0.4 0.3 0.2 0.1 0 Flow 4 Flow 3 Flows 1, 2 0.6 0.5 0.4 0.3 0.2 0.1 0 Flows 1, 2, 3, 4 accepted throughput @ sink [flits/cycle] Flow 2 ((cid:587)2=0.50) Flow 1 ((cid:587)1=0.30) Flow 3 ((cid:587)3=0.15) Flow 4 ((cid:587)4=0.05) 0.6 0.5 0.4 0.3 0.2 0.1 0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 injection rate (flits/cycle/source) (a) round-robin (RR) arbitration 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 injection rate (flits/cycle/source) (b) age-based arbitration 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 injection rate (flits/cycle/source) (c) deadline-based arbitration Figure 4: Per-source accepted throughput at the sink with various arbitration schemes in the network shown in Figure 3. Dotted vertical lines indicate minimum injection rate causing congestion. In locally-fair round-robin arbitration in (a), which does not use the deadline ﬁeld, the throughput of a ﬂow decreases exponentially as the number of hops increases. Age-based arbitration in (b), where deadline is assigned as network injection time, gives fair bandwidth allocation among all ﬂows. With deadline-based arbitration with the policy for bandwidth guarantees in (c), we achieve bandwidth distribution proportional to the ratio of ρ’s (ρ1 : ρ2 : ρ3 : ρ4 = 0.30 : 0.50 : 0.15 : 0.05) in face of congestion. input:  (data flit, deadline) pair •• •• •• •• arbiter (a) ideal implementation of deadline-based arbitration (perfect priority queues  with infinite capacity) frame number [deadline range] 0 [1,F] 1 [F+1,2F] 1 frame FIFO = F flits •• •• k [kF+1,(k+1)F] • • • •• • • • (b) per-frame buffers (FIFOs) with infinite frame window 1 frame FIFO input # =B flits frame number k+(W-j) k+W-1 head k k+1 k+(W-j-1) •• • • •• •• •• • • •• 0 j-1 j j+1 W-1 (c) circular frame buffers with finite frame window (W) and smaller FIFO size (B<F) (head pointer indicating head frame) Figure 5: Step-by-step transformation towards a frame-based, approximate implementation of deadline-based arbitration. (a) shows the ideal MUX introduced in Section 3.1, which is associated with each physical link. In (b), we group all data entries having a range of deadlines (whose interval is F ) to form a frame. The frame number is used as a coarse-grain deadline, and we now drop the deadline (or frame number) ﬁeld because each frame has an associated frame buffer. Finally, we recycle frame buffers, with W active frames, as in (c) to give a ﬁnite total buffer size. a frame-based, approximate implementation of deadlinebased arbitration. Frame k is associated with packets whose deadline is in the range of [kF + 1, (k + 1)F ], where F is the number of ﬂit times per frame. The frame number k is used as a coarse-grain deadline. By introducing frames, we enforce an ordering across frames but not within a frame because the service order within a frame is simply FIFO. The baseline GSF arbitration is shown in Figure 5(c), where we have a ﬁnite active frame window having W frames (i.e., Frame k through (k + W − 1)) and each active frame has a dedicated frame buffer (FIFO) whose depth is B ﬂits. The head pointer indicates which frame buffer is currently bound to the earliest frame (frame buffer j in the ﬁgure), which we call the head frame. Note that the baseline GSF in Figure 5(c) is an asymptotic implementation of the ideal deadline-based arbitration in Figure 5(a) because the former reduces to the latter as W → ∞ and F → 1. Here is a brief sketch of how the GSF network operates. For each active frame, every ﬂow is allowed to inject a certain number of ﬂits, denoted by Ri for ﬂow i. Although our scheme is similar to conventional frame-based bandwidth allocation schemes, we allow W frames to overlap at any given time to accommodate bursty trafﬁc while preventing an aggressive ﬂow from injecting too much trafﬁc into the network. Once a packet is injected into the network, it traverses the network using only the frame buffers for its given frame number. Therefore, there is no possibility of priority inversion, where a lower-priority packet blocks a higher-priority packet. Combined with earliest-frame-ﬁrst scheduling for bandwidth allocation, the head frame is guaranteed to drain in a ﬁnite amount of time because only a ﬁnite sum of packets can be injected into a single frame by all ﬂows. The drained head frame buffers across the entire network are reclaimed and allocated to a newer frame synchronously, which is called an (active) frame window shift. We deﬁne an epoch as the period of time between adjacent frame window shifts, and the interval of the k-th epoch 9393 LM AX Variables epoch** ek 1 .. eM AX eM AX T epoch W HF F B C Range Description Global parameters and variables* 2 .. ∞ active frame window size 0 .. (W − 1) 1 .. ∞ current head frame 1 .. ∞ frame size in ﬂits frame buffer depth in ﬂits (0, 1] channel bandwidth in ﬂits/cycle 1 .. ∞ maximum packet length in ﬂits 0 .. ∞ current epoch number interval of k-th epoch 1 .. ∞ maximum epoch interval (= max∀k ek ) epoch timer Per-ﬂow variables a fraction of bandwidth allocated to Flow i (normalized to C ) ﬂit slots reserved for Flow i in a single frame current injection frame of Flow i available credit tokens for Flow i to inject ﬂits to I Fi * Global variable with a subscript i denotes a local copy of the variable maintained by Flow i. ** not implemented in hardware 0 .. F 0 .. (W − 1) -LM AX .. Ri 0 .. eM AX I Fi Ci 0 .. 1 ρi Ri Table 1: Variables and parameters used in GSF. (i.e., the period of time when frame k is the header frame) is denoted by ek . We also deﬁne eM AX ≡ max∀k ek . Table 1 summarizes variables and parameters used in the GSF algorithm. More detailed description of each network component’s operation follows. Packet injection process: Algorithm 1 describes a packet injection algorithm used by the baseline GSF network. Flow i can inject packets into the active frame pointed to by I Fi as long as it has a positive credit balance (Ci > 0) for the frame (Lines 2-4). The ﬂow can go overdrawn, which allows it to send a packet whose size is larger than Ri . To preserve bandwidth guarantees, a ﬂow with negative credit balance cannot inject a new packet until its balance becomes positive again. If the ﬂow has used up all reserved slots in Frame I Fi , it can use reserved slots further in the future by incrementing I Fi by one (mod W ) (Lines 5-13) until it hits the tail of the active frame window. Once the ﬂow uses up all reserved slots in the active frame window, it must stall waiting for a frame window shift to open a new future frame. Note that bucket ﬁlter [4] with (ρ, σ) = (Ri/eM AX , Ri ∗W ) assuming this injection process is effectively implementing a tokenthe active frame window shifts at every eM AX cycles. Switching bandwidth and buffer allocation: Frame buffer allocation is simple because every packet is assigned a frame at the source, which determines a sequence of frame buffers to be used by the packet along the path. There can be contention between packets within a frame but not across frames. In allocating switching bandwidth, we give the highest priority to the earliest frame in the window. Frame window shifting algorithm: Algorithm 2 shows an algorithm used to shift the active frame window. Source injection control combined with earliest-frame ﬁrst scheduling yields a ﬁnite drain time for the head frame, bounded Algorithm 1 GSF packet injection algorithm into source queue for Flow i (⊕W : modulo W addition) Initialize: epoch = 0, HFi = HF = 0 Initialize: Ri = Ci = (cid:1)ρi F (cid:2) Initialize: IFi = 1 1: AT EV E RY PACK E T G EN E RAT I ON EV EN T: Ci = Ci + Ri S ourceQueuei.enq(packet, IFi ) Ci = Ci − packet.size() 2: if Ci > 0 then 3: 5: else {used up all reserved slots in Frame IFi } 4: while (IFi ⊕W 1) (cid:4)= HFi and Ci < 0 do 6: 7: IFi = IFi ⊕W 1 8: 9: end while 10: if Ci > 0 then 11: 12: 13: end if 14: end if S ourceQueuei.enq(packet, IFi ) Ci = Ci − packet.size() i by eM AX . Therefore, we shift the active frame window at every eM AX cycles by default. Every ﬂow maintains a local copy (T epoch ) of the global epoch timer (T epoch) and decrements it at every clock tick (Lines 9-10). Once the timer reaches zero, all the ﬂows synchronously increment the head frame pointer H Fi (mod W ) to reclaim the frame buffer associated with the earliest frame. The frame window shifting algorithm does not allow a ﬂow to inject a new packet into the head frame (Lines 4-7). Otherwise, we would have a very loose bound on the worstcase drain time of the head frame (eM AX ), which would degrade network throughput. Algorithm 2 GSF frame window shifting algorithm (⊕W : modulo W addition) Initialize: Tepoch Initialize: HFi = HF = 0 = eM AX i 1: F O R A L L FLOW S , AT EV E RY C LO CK T I CK : i 2: if Tepoch == 0 then HFi = HFi ⊕W 1 3: 4: if HFi == IFi then IFi = IFi ⊕W 1 5: 6: 7: 8: 9: else 10: 11: end if = Tepoch i Tepoch i Tepoch i = eM AX end if − 1 Ci = M IN (Ri , Ci + Ri ) In effect, the GSF network implements W logical networks sharing physical channels, and each logical network is associated with one frame at any point in time. The W logical networks receive switching bandwidth according to priorities which rotate on every frame window shift. A logical network starts as the lowest-priority logical network when it is just assigned to a new frame, and is promoted throughout the lifetime of the frame to eventually become the highest-priority network, after which it ﬁnally gets re9494 claimed for the new futuremost frame. The baseline GSF network provides the following guaranteed bandwidth to ﬂow i if (1) none of the physical channels along the path are overbooked and (2) the source queue (S ourceQueuei) has sufﬁcient offered trafﬁc to sustain the reserved bandwidth: Guaranteed bandwidthi = Ri/eM AX The proof sketch is simple. Flow i can inject Ri ﬂits into each frame, and the network opens a new frame every eM AX cycles. Because the network does not drop any packets and has a ﬁnite buffer size, the guaranteed bandwidth holds. In addition, the worst-case network delay is bounded by W eM AX because a packet injected in k-th epoch must be ejected from the network by the beginning of (k + W )-th epoch. Although the baseline GSF scheme provides guaranteed services in terms of bandwidth and bounded network delay, there are several drawbacks to the scheme. First, frame buffers are underutilized, which degrades overall throughput for a given network cost. Second, it is difﬁcult to bound eM AX tightly, which directly impacts the guaranteed bandwidth. Even with a tight bound, it is too conservative to wait for eM AX cycles every epoch because the head frame usually drains much faster. To address these two issues without breaking QoS guarantees, we propose two optimization techniques: carpool lane sharing and early reclamation of empty head frames. 3.3 Carpool Lane Sharing of Frame Buﬀers: Improving Buﬀer Utilization One observation in the baseline GSF scheme is that guaranteed throughput does not really depend on the active frame window size, W . The multiple overlapping frames only help claim unused bandwidth to improve network utilization by supporting more bursty trafﬁc. As long as we provide a dedicated frame buffer for the head frame at each router to ensure a reasonable value of eM AX , we do not compromise the bandwidth guarantees. We propose carpool lane sharing to relax the overly restrictive mapping between frames and frame buffers. Now we reserve only one frame buffer to service the head frame (like a carpool lane), called the head frame buffer, but allow all active frames, including the head frame, to use all the other frame buffers. Each packet carries a frame number (mod W ) in its head ﬂit, whose length is (cid:7)log2 W (cid:8) bits, and the router services the earliest frame ﬁrst in bandwidth and buffer allocation. The frame window shifting mechanism does not change. Note that head-of-line blocking of the head frame never happens because we map frame buffers to virtual channels (allocated on a per-packet basis) and the head frame buffer at each router serves as an escape channel for packets that belong to the head frame. According to our evaluation, the carpool lane sharing scheme increases the overall throughput signiﬁcantly because more frame buffers are available to a packet at each node. That is, any packet can occupy any frame buffer, except that the head frame buffers are reserved only for packets in the head frame. To support best-effort trafﬁc, we can simply assign a special frame number (W , for example) which represents the lowest priority all the time. 3.4 Early Reclamation of Empty Frames: Increasing Frame Reclamation Rate One important factor affecting the overall throughput in the GSF network is the frame window shift rate. According to our analysis, only a small fraction of ek ’s ever come close to eM AX , which implies that the head frame buffer is often lying idle waiting for the timer to expire in each epoch. Therefore, we propose to use a global barrier network to reclaim the empty head frame as quickly as possible. Instead of waiting for eM AX cycles every epoch, we check whether there is any packet in the source or network buffers that belongs to the head frame. If not, we retire the head frame immediately and allocate its associated buffers to the new futuremost frame. Note early reclamation does not break the original bandwidth guarantees, because we always see a net increase, or at worst no change, in available ﬂit injection slots. Figure 6 shows that early reclamation provides over 30% improvement in network throughput in exchange for a small increase in area and power for the barrier network. The barrier network is only a small fraction of the cost of the primary data network, as it uses only a single wire communication tree and minimal logic. 4 Implementation The GSF frame structure ﬁts well into the architecture of a conventional virtual channel (VC) router, requiring only relatively minor modiﬁcations. This section discusses the GSF router architecture and the fast on-chip barrier network. 4.1 GSF Router Architecture Figure 7 shows a proposed GSF router architecture. This router implements both carpool lane buffer sharing and early frame reclamation on top of the baseline GSF. Starting from a baseline VC router, we describe various aspects and design issues in the GSF router. Baseline VC router We assume a three-stage pipelined VC router with lookahead routing [9] as our baseline. The 9595 frame number active frame window at T=20000  (W=6, 13th epoch) 24 21 18 15 12 9 6 3 0 0 active frame window at T=20000  (W=6, 21st epoch) slope = 1 / 959 (frame/cycles) 20000 40000 time (T) [cycles] (b) with early reclamation slope = 1 / 1500 (frame/cycles) 20000 40000 0 time (T) [cycles] (a) without early reclamation Figure 6: Frame life time analysis for comparison of frame reclamation rates with and without early reclamation. Although the estimated eM AX = 1500 is within 10% of the observed worstcase eM AX , the early reclamation increases the frame reclamation rate by >30%, which leads to corresponding improvement in the average throughput. See Section 6.1 for simulation setup. We use a hotspot trafﬁc pattern with injection rate of 0.05 ﬂits/cycle/node. three stages are next-hop routing computation (NRC) in parallel with virtual channel allocation (VA), switch allocation (SA) and switch traversal (ST). Added Blocks Each router node keeps a local copy of the global head frame (H F ) variable. This variable increments (mod W ) at every frame window shift triggered by the global barrier network. Each VC has a storage to maintain the frame number (mod W ) of the packet it is servicing. The frame number at each VC is compared against H F to detect any packet belonging to the head frame. Then the global barrier network gather information to determine when to shift the frame window appropriately. Next-Hop Routing Computation (NRC) In order to reduce the burden of the VA stage, which is likely to be the critical path of the router pipeline, we precalculate the tained by (f rame num−H F ) (mod W ). The lowest numpacket priority at this stage. The packet priority can be obber has the highest priority in VC and SW allocation. When calculating the routing request matrix, NRC logic is responsible for masking requests to VC0 from non-head frames, because VC0 is reserved for the head frame only. VC and SW allocation VC and SW allocators perform priority-based arbitration, which selects a request with the highest priority (the lowest number) precalculated in the previous NRC stage. The GSF router uses standard creditbased ﬂow control. 4.2 Global Synchronization Network The latency of the global synchronization network affects the overall network throughput because higher latencies leave VC0 (the carpool channel) idle for longer. Although our proposed router is generally tolerant to the latency of the barrier network if the frame size (F ) is reasonX _ e d o n _ t a _ y t p m e _ e m a r f _ d a e h • • • • • • • global barrier network increment_head_frame flit buffers • • • route computation frame_num VC0 VC1 VC2 VC3 2 x 1 0 • • VC0 VC1 VC2 VC3 2 0 3 2 (cid:760) (cid:760) (cid:760) (cid:760) (cid:760) (cid:760) (cid:760) (cid:760) head_frame=2 VC allocation SW allocation crossbar (5x5) to P to N to E to S to W Figure 7: A GSF router architecture for 2D mesh network. Newly added blocks are highlighted while existing blocks are shown in gray. ably large, the impact is more visible for a trafﬁc pattern having a high turnaround rate of frame buffers. One way to achieve barrier synchronization is to use a fully-pipelined dimension-wise aggregation network [27]. In this network, assuming a 2D mesh, the center node of each column ﬁrst collects the status of its peers in the same column. Then, it forwards the information to the center node of its row where the global decision is made. A broadcast network, which operates in reverse of the aggregation network, informs all nodes to rotate their head frame pointers (H F ). For k-ary n-cube (or mesh) network, the latency of the synchronization will be 2n(cid:7) k−1 2 (cid:8) cycles assuming one-cycle per-hop latency. Alternatively, we can implement a barrier network using combinational logic which might take multiple fast clock cycles to settle. This requires signiﬁcantly less area and power, and provides lower latency as cross-chip signal propagation is not delayed by intermediate pipeline registers. If propagation takes N fast clock cycles, we could sample each router’s state and read the barrier signal every N cycles to determine when to perform a frame window shift. For evaluation, we use a variable number of cycles up to 2 (cid:8) cycles. 2n(cid:7) k−1 5 System-Level Design Issues A QoS-capable on-chip network sits between processors running the software stack and shared platform resources. This section addresses issues in interacting with these two 9696 (cid:1) i∈Sc ends of the system to provide robust QoS support. Admission control: Admission control is a software process that should guarantee that no channel in the network is oversubscribed. That is, suppose Sc = {i1 , i2 , · · · , in} is a set of ﬂows that pass through Channel c. Then ∀ Channel Ri ≤ F should hold. To keep netc in the network, work utilization high, each ﬂow can be granted more than the minimum number of slots required where possible, as the maximum number of ﬂits in ﬂight from ﬂow i at any given time is upper bounded by W Ri . If a new ﬂow enters into a previously reserved channel, the software stack redistributes the excess injection slots according to its excess bandwidth sharing policy. Note that our GSF scheme does not require any explicit channel setup, and so only the Ri control register at each source must be changed. If there are multiple clock domains, possibly with dynamic voltagefrequency scaling (DVFS), any channel c should provide at least the sum of guaranteed bandwidths on the channel to preserve QoS guarantees. Specifying bandwidth requirements: To specify requested bandwidth, one can use either a relative measure (e.g., 10 % of available bandwidth) as in [24] or an absolute measure (e.g., 100 MB/s). If a relative measure ρi is (in ﬂits/cycle) is used, Ri can be set to be (BW ∗ eM AX ). given, Ri can be set to be ρiF . If an absolute measure BW eM AX is a function of trafﬁc pattern, bandwidth reservation, frame size, packet size, global synchronization latency, and so on, and it is generally difﬁcult to obtain a tight bound. (Currently, we rely on simulation to get a tight bound.) GSF-based integrated QoS framework: We can extend the domain of GSF arbitration into other QoS-capable shared resources, such as memory bandwidth at a shared memory controller. A single global deadline (frame number) assigned at the source could also be used to manage end-point bandwidth usage to create a GSF-based integrated QoS system. We leave development of this integrated QoS environment for future work. 6 Evaluation In this section, we evaluate the performance of our proposed GSF implementation in terms of QoS guarantees and average latency and throughput. We also discuss tradeoffs in the choice of network parameters. 6.1 Simulation Setup Table 2 summarizes default parameters for evaluation. We implemented a cycle-accurate network simulator based on the booksim simulator [28]. For each run, we simulate 0.5 million cycles unless the simulation output saturates early, with 50 thousand cycles spent in warming up. We use an 8×8 2D mesh with four trafﬁc patterns where the destination of each source at Node (i, j ) is determined 9797 8x8 2D mesh dimension-ordered VA/NRC - SA - ST (3 cycles) 2 cycles Simulation parameters Speciﬁcations Common parameters Topology Routing Router pipeline (per-hop latency) Credit pipeline delay (including credit traversal) Number of VCs per channel (V) Buffer depth (B) Channel capacity (C) VC/SW allocation scheme Packet size Trafﬁc pattern GSF parameters active frame window size (W) same as number of VCs frame size (F) 1000 ﬂits global barrier latency (S) 16 cycles 6 5 ﬂits / VC 1 ﬂit / cycle iSlip [19] (baseline) or GSF 1 or 9 ﬂits (50-50 chance) variable Table 2: Default simulation parameters as follows: hotspot (d(i,j) = (8, 8)), transpose (d(i,j) = (j, i)), nearest neighbor (d(i,j) = (i + 1, j + 1) (mod 8)) and uniform random (d(i,j) = (random(), random())). Hotspot and uniform random represent two extremes of network usage in terms of load balance for a given amount of trafﬁc. The other two model communication patterns found in real applications, e.g. FFT for transpose, and ﬂuid dynamics simulation for nearest neighbor. 6.2 Fair and Diﬀerentiated Services We ﬁrst evaluate the quality of guaranteed services in terms of bandwidth distribution. Figure 8 shows examples of fair and differentiated bandwidth allocation in accessing hotspot nodes. Figure 8 (a) and (b) illustrate QoS guarantees on a 8×8 mesh network and (c) on a 16×16 torus network. In both cases, the GSF network provides guaranteed QoS to each ﬂow. We are able to achieve this without signiﬁcantly increasing the complexity of the router partly because the complex task of prioritizing packets to provide guaranteed QoS is ofﬂoaded by the source injection process, which is globally orchestrated by a fast barrier network. We make the case for using a simple secondary network (barrier network) to control a primary high-bandwidth network to improve the efﬁciency of the primary network (i.e., to provide more sophisticated services in our case). For all the simulation runs we performed, we conﬁrmed that bandwidth is shared among all ﬂows in compliance with the given allocation. Therefore, for the rest of this section, we focus on non-QoS aspects such as average throughput and tradeoffs in parameter choice. 6.3 Cost of Guaranteed QoS and Tradeoﬀs in Parameter Choice The cost of guaranteed QoS with GSF is additional hardware including an on-chip barrier network and potential degradation of average latency and/or throughput. Unaccepted throughput [flits/cycle/node] accepted throughput [flits/cycle/node] 0.06 0.04 0.02 0 0.06 0.06 0.04 0.04 0.02 0.02 0 0 12345678 nodeindex(Y) 12345678 ( X ) i n d e e x d o n 12345678 nodeindex(Y) 12345678 ( X ) i n d d e x e o n (a) fair allocation: 8x8 (b) differentiated allocation: 8x8 accepted throughput [flits/cycle/node] 0.06 0.04 0.02 0 123456789ABCDEF0 nodeindex(Y) 123456789ABCDEF0 ( X ) i n n o d d e e x (c) differentiated allocation: 16x16 torus Figure 8: Fair and differentiated bandwidth allocation for hotspot trafﬁc. (a) shows fair allocation among all ﬂows sharing a hotspot resource located at (8,8). In (b), we partition a 8×8 CMP in mesh topology into 4 independent groups (e.g., running 4 copies of virtual machine) and provide differentiated services to them independent of their distance from the hotspot. In (c), we partition a 16×16 CMP in torus topology into 2×2 processor groups and allocate bandwidth to four hotspots in a checkerboard pattern. less a router has a priori knowledge of future packet arrivals, it must reserve a certain number of buffers for future high-priority packets although there are waiting packets with lower priorities. This resource reservation is essential for guaranteed QoS but causes resource underutilization, degrading average-case performance. Therefore, it is our primary design goal to provide robust average-case performance over a wide range of network conﬁgurations and workloads. Note that robust performance by the GSF framework entails setting QoS parameters appropriately for a given workload. Figure 9 shows the average latency versus offered load over three different trafﬁc patterns. For uniform random trafﬁc, we allocate (cid:10)F /64(cid:11) = 15 ﬂit injection slots per frame to each source (not to each source-destination pair), and these slots are shared by all packets from the same source. For the other trafﬁc patterns, each sourcedestination pair is regarded as a distinct ﬂow and allocated ﬂit slots considering the link sharing pattern. We ﬁrst observe that the GSF network does not increase the average latency in the uncongested region. The network saturation throughput, which is deﬁned as the point at which packet latency is three times the zero-load latency (as in [17]), is degraded by about 12% in the worst case. The performance impact of barrier synchronization overhead is (cid:1)N −1 k=0 ek )/N ). the most visible in uniform random trafﬁc because it has the lowest average epoch interval (eAV G ≡ ( Assuming 16-cycle barrier synchronization latency (S = 16), S/eAV G ratios are 0.32, 0.15 and 0.09 for uniform random, transpose and nearest neighbor, respectively. There are two main reasons for degradation of network saturation throughput: underutilization of the head frame VC (VC0) and ﬁnite frame window. Because VC0 at each node is reserved to drain packets in the head frame, only (V 1) VCs are available for packets in the other active frames. The ﬁnite frame window prevents a ﬂow from injecting more trafﬁc than its reserved ﬂit slots in the active frame window even when there are unclaimed network resources. Figure 10 explains the impact of these two factors on average accepted throughput. With a small number of virtual channels, e.g. V =2, the throughput gap between GSF and baseline is dominated by underutilization of VC0 and increasing the window size from V to 2V does not improve throughput much. As the number of VCs increases, the gap narrows, and the performance gain from a wider window becomes more signiﬁcant. To have enough overlap of frames to achieve over 90% of the throughput of the baseline VC router, the number of VCs should be at least four in this network conﬁguration. With 8 VCs, the GSF achieves a comparable network throughput at the cost of increased average latency. We choose the 6 × 5 (virtual channels × buffers) conﬁguration by default. In choosing the window size (W ), a larger window is desirable to overlap more frames, thereby increasing overall network throughput. However, the performance gain only comes with a cost for more complex priority calculation and arbitration logic. According to our simulation, increasing W to be larger than 2V gives only marginal throughput gain. Therefore, we choose the frame window size (W ) to be V by default as a reasonable design tradeoff. normalized average accepted throughput 1.2 1 0.8 0.6 0.4 0.2 0 100 500 frame size (F) [flits] 1000 2000 Hotspot/16 Hotspot/8 Hotspot/1 U-random /16 U-random /8 U-random /1 Figure 11: Throughput of GSF network normalized to that of the baseline VC router with variable F (frame window size). Two trafﬁc patterns (hotspot and uniform random) and three synchronization costs (1, 8 and 16 cycles) are considered. 9898 average delay [cycles] uniform random traffic 400 350 300 250 200 150 100 50 0 transpose traffic average delay [cycles] 400 350 300 250 200 150 100 50 0 average delay [cycles] nearest neighbor traffic 400 350 300 250 200 150 100 50 0 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 offered load [flits/cycle/node] 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 offered load [flits/cycle/node] iSlip GSF/1 GSF/8 GSF/16 iSlip GSF/1 GSF/8 GSF/16 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 offered load [flits/cycle/node] iSlip GSF/1 GSF/8 GSF/16 Figure 9: Average packet latency versus offered load with three trafﬁc patterns. For each trafﬁc pattern, we consider three different synchronization costs: 1 (GSF/1), 8 (GSF/8) and 16 cycles (GSF/16). Network saturation throughput is the cross point with dotted line (3Tzero−load line) as in [17]. With GSF/16, network saturation throughput is degraded by 12.1 % (0.33 vs. 0.29) for uniform random, 6.7 % (0.15 vs. 0.14) for transpose and 1.1 % (0.88 vs. 0.87) for nearest neighbor, compared to baseline VC router with iSlip VC/SW allocation. average accepted throughput [flits/cycle/node] 0.025 hotspot traffic 0.02 0.015 0.01 0.005 0 average accepted throughput [flits/cycle/node] 0.5 uniform random traffic (injection rate = 0.4) 0.4 0.3 0.2 0.1 0 4 x 2 2 x 4 8 x 2 4 x 4 2 x 8 6 1 x 2 8 x 4 4 x 8 2 x 6 1 2 3 x 2 6 1 x 4 8 x 8 4 x 6 1 8 16 buffer size per channel [flits] 32 64 GSF (W=V) GSF (W=2V) base line VC/iSlip 5 x 6 30 4 x 2 2 x 4 8 x 2 4 x 4 2 x 8 6 1 x 2 8 x 4 4 x 8 2 x 6 1 2 3 x 2 6 1 x 4 8 x 8 4 x 6 1 8 16 buffer size per channel [flits] 32 64 GSF (W=V) GSF (W=2V) base line VC/iSlip 5 x 6 30 Figure 10: Tradeoff in buffer organization with hotspot and uniform random trafﬁc patterns. VC buffer conﬁguration is given by V × B . The frame window size (W ) is assumed to be V or 2V. For both trafﬁc patterns, having V ≥ 4 achieves 90% or higher throughput compared to the baseline VC router. Generally, increasing VCs improves the throughput at the cost of increased average latency. 6 × 5, our default, is a sweet spot for the speciﬁc router architecture we use. the end-points. The end-points and network are globally orchestrated by a fast barrier network made possible by the on-chip implementation. Our preliminary evaluation of the GSF network shows promising results for robust QoS support in on-chip networks. 8 Acknowledgements We thank Christopher Batten and Heidi Pan at MIT, Rose Liu at the University of California, Berkeley, and Kyle Nesbit at the University of Wisconsin, Madison, as well as anonymous reviewers for their helpful comments. This work was partly funded by Nokia Inc. In Figure 11, we explore the choice of frame size (F ). A long frame (whose size is ≥ 1000 in this conﬁguration) amortizes the overhead of barrier synchronization and effectively increases the size of injection window to support more bursty trafﬁc, which is likely to improve the network throughput. The downside is larger source buffers and potential discrimination of remote nodes within a frame. The choice depends on workloads, synchronization overhead and system size. 7 Conclusion In this paper, we introduced Globally-Synchronized Frames (GSF) to provide guaranteed QoS from on-chip networks in terms of minimum bandwidth and maximum delay bound. We show that the GSF algorithm can be easily implemented in a conventional VC router without signiﬁcantly increasing its complexity. This is possible because the complex task of prioritizing packets to provide guaranteed QoS is pushed out to the source injection process at 9999 [23] K. J. Nesbit, J. Laudon, and J. E. Smith. Virtual private caches. In ISCA, 2007. [24] K. J. Nesbit, J. Laudon, and J. E. Smith. Virtual Private Machines: A resource abstraction for multicore computer systems. In University of Wisconsin - Madison, ECE TR 07-08, 2007. [25] R. S. Passint, G. M. Thorson, and T. Stremcha. United States Patent 6674720: Age-based network arbitration system and method, January 2004. [26] G. E. Suh, S. Devadas, and L. Rudolph. A new memory monitoring scheme for memory-aware scheduling and partitioning. In HPCA, 2002. [27] M. Thottethodi, A. R. Lebeck, and S. S. Mukherjee. Selftuned congestion control for multiprocessor networks. In HPCA, 2001. [28] B. Towles Booksim 1.0. and W. J. Dally. http://cva.stanford.edu/books/ppin/. [29] J. S. Turner. New directions in communications (or which way to the information age). IEEE Communications, 24(10):8–15, Oct. 1986. [30] W.-D. Weber, J. Chou, I. Swarbrick, and D. Wingard. A quality-of-service mechanism for interconnection networks in system-on-chips. In DATE, 2005. [31] H. Zhang and S. Keshav. Comparison of rate-based service disciplines. In SIGCOMM, 1991. [32] L. Zhang. Virtual Clock: a new trafﬁc control algorithm for packet switching networks. In SIGCOMM, 1990. "
2006,"Simulation and analysis of network on chip architectures - ring, spidergon and 2D mesh.","NoC architectures can be adopted to support general communications among multiple IPs over multi-processor systems on chip (SoCs). In this work we illustrate the modeling and simulation-based analysis of some recent architectures for network on chip (NoC). Specifically, the ring, spidergon and 2D mesh NoC topologies have been compared, both under uniform load and under more realistic load assumptions in the SoC domain. The main performance indexes considered are NoC throughput and latency, as a function of variable data-injection rates, source and destination distributions, and variable number of nodes. Results show that the spidergon topology is a good trade-off between performance, scalability of the most efficient architectures inherited from the parallel computing systems design, constraints about simple management, and small energy and area requirements for SoCs"," Simulation and Analysis of Network on Chip Architectures:   Ring, Spidergon and 2D Mesh    Luciano Bononi, Nicola Concer  Dipartimento di Scienze dell’Informazione, Università degli Studi di Bologna,   Mura Anteo Zamboni 7, 40126, Bologna, Italy  {bononi, concer}@cs.unibo.it  Abstract   NoC architectures can be adopted to support general  communications among multiple IPs over multi-processor  Systems on Chip (SoCs). In this work we illustrate the  modeling and simulation-based analysis of some recent  architectures for Network on Chip (NoC). Specifically,  the Ring, Spidergon and 2D Mesh NoC topologies have  been compared, both under uniform load and under more  realistic load assumptions in the SoC domain. The main  performance indexes considered are NoC throughput and  latency, as a function of variable data-injection rates,  source and destination distributions, variable number of  nodes. Results show that the Spidergon topology is a  good trade-off between performance, scalability of the  most efficient architectures inherited from the parallel  computing systems design, constraints about simple  management, small energy and area requirements for  SoCs.   1. Introduction  A new generation of communication infrastructures called  Networks on Chip (NoCs) [1-15] have been recently  considered as a novel alternative to existing On Chip  Communication Architectures (OCCAs) based on shared  communication medium  like on-chip buses (as an  example, ARM AMBA [16], Wishbone [17], STBus [20],  Core Connect [18],  Sonics Backplane [19]. The design of  Network on Chip solutions can be considered in between  the classical networking solutions (good for scalability  and flexibility  to adapt  to general communication  patterns) and the more specific communication and  switching architectures for high-performance parallel  computing (good for performances but less scalable and  less flexible under the dynamic configuration viewpoint).  A natural step has been the attempt to inherit the  This work was supported by MIUR and University of Bologna and  STMicroelectronics project funds “modeling and analysis of network  protocols for Spidergon-based networks on chip”.  consolidated solutions in these two domains into the SoC  world. This led to proposals for packet-switched micronetwork backbones based on appropriate protocol stacks.  Most recent NoC architectures have been implemented on  top of ring, 2D mesh or custom topologies: UPMC/LIP6’s  DSPIN [2], Nostrum (KTH) [15], Æthereal (Philips  Research Lab) [11], Raw network (MIT) [12], Eclipse  (VTT) [13],  Xpipes (University of Bologna) [14]. One of  the most recent architectures and topologies proposed is  the  novel Spidergon  (STMicroelectronics) NoC  architecture [9, 10], which will be sketched in section II.   Many research issues are still open and the complex  design space for NoCs requires a deep exploration, by  involving at least three identified fields: synthesis of  communication  infrastructure,  selection  of  communication paradigms and application-mapping  optimization [7]. This led to the definition of many,  correlated, open research problems, still requiring global  solutions, techniques and tools to assist designers at many  levels [7, 8]. The list includes: topology synthesis,  channel and buffer sizing, floorplanning, routing and  switching  techniques, flow control  techniques, data  scheduling, buffer and queues management, IP mapping  over the NoC architecture, performance evaluation and  resource planning, end-to-end services, Quality of  Service, packet and message format, deadlock avoidance  [7, 8].  Recent works have investigated and compared many NoC  architectures under general assumptions [6].   The main contributions of this paper are the following: i)  the modeling and simulation-based analysis of low degree  topologies (Ring, 2D Mesh and Spidergon) focusing the  on chip domain requirements and overcoming  the  classical parallel computing and networking results; to the  best of our knowledge, this is the first work considering  irregular mesh topologies, and this analysis is motivated  since regular meshes cannot be always assumed as  realistic topologies, ii) the first deep analysis of the novel  Spidergon NoC  is presented, resulting  in a good  compromise among the well-known topologies, and iii)  we propose the OMNeT++ framework [21] for a fast and  high level simulation environment for NoC topologies’  exploration.                                                                        The paper structure is the following: in section II we  sketch  the Ring, Mesh and Spidergon  topologies  considered in our study, by illustrating some results of the  analysis of their characteristics; in section III we illustrate  the modeling and simulation scenarios, and  the  performance results; in section IV we draw conclusions  and future work.  2. The considered NoC architectures   NoCs must have regular, scalable and simple network  topology, characterized by the space locality of modules  connected by short links, the high correlation of the link  traffic, the severe energy and latency constraints, and the  need of  low cost solutions. In packet-based NoC  communication each packet is split into data units called  flits. The buffer queues for channels are defined as  multiples of the flit data unit. The packet forwarding  among nodes is performed with a flit-by-flit (adaptive,  source, arithmetic or table-driven) routing and local  signal-based flow control. The most generally adopted  switching scheme is the wormhole scheme. In wormhole,  the head flit of a packet is actively routed towards the  destination by following the forwarding indications on  routers, while subsequent flits are passively switched by  pre-configured switching functions on the output queue  of the channel belonging to the path opened by the head  flit. When the channel buffer space is available on the  input queue of the channel towards the next switch in the  path the next flit of a packet is forwarded on. Flit-based  wormhole is an interesting solution compared to virtual  cut-through and packet-based circuit switching because  its pipelined nature facilitates flow control and end-to-end  performances, with  low packet-overheads and  low  buffering space. Wormhole realizes a tradeoff between  circuit-switching performances and packet-switching  flexibility and resources utilization. Due to the distributed  and partial capture of buffers and channel resources and  the possible circular waiting, deadlock and livelock  conditions are possible. The management of deadlock  solutions and the efficiency of link utilization often  introduced the virtual channels (VCs) management. VCs  are implemented by multiple output queues for each  physical link, and respective buffers. The IPs are  connected to a NoC switch by a Network Interface (NI)  incorporating the connection management and the data  fragmentation functions.        Some of the most common NoC architectures belong  to the classes of the Ring (figure 1.b) and m*n 2D Mesh  (figure 1.c). The Spidergon architecture with N (even)  nodes is similar to a ring enriched by across links between  opposite nodes (see figure 2.a). For a tagged node, a  clockwise, counterclockwise and across links are present.  Some of the most interesting characteristics of the  Spidergon scheme are: i) network with regular topology,  ii) vertex symmetry (same topology appears from any  node), iii) edge-transitivity, iv) constant node degree  (equal to 3) translating in simple router HW and  efficiency. High node degree reduces the average path  length but increases complexity. By assuming channels as  unidirectional pairs of links, the number of network links  in a N nodes’ network is 2N for Ring, 3N for Spidergon  and 2(m-1)n+2(n-1)m for a (m*n=N) 2D Mesh.   0 0 11 11 10 10 9 9 1 1 2 2 8 8 7 7 3 3 4 4 5 5 6 6 9 9 10 10 8 8 11 11 0 0 1 1 7 7 6 6 5 5 2 2 4 4 3 3 0 0 m m 1 1 m+1 m+1 2m 2m ... ... n-1 n-1 m m ... ... 2 2 ... ... ... ... ... ... m-1 m-1 ... ... ... ... nm nm -1 -1 Figure 1:  NoC topologies: IPs connected to numbered  nodes on a) Spidergon, b) Ring, c) (m*n) 2D Mesh         A significant worst case index, named the network  diameter ND is defined as the maximum shortest path  length between any pair of nodes in the topology. The  average network distance E[D] is defined as the average  path length of all different paths in the network. By  assuming a NoC of N nodes, in a Ring topology,  ND=floor(N/2) and E[D]=N/4, in (m*n) 2D Mesh  ND=(m+n-2)  and E[D]=(m+n)/3,  in Spidergon,  ND=ceiling(N/4) and E[D]=(2x2+4x+1)/N (if N=4x) and  E[D]=(2x2+2x-1)/N if (N=4x+2).        Under  the worst case analysis assumptions, the  network diameter of real  2D mesh topologies with N  nodes shows quite unpredictable fluctuations between the  ideal (√N*√N) mesh values and the Ring diameter values,  as shown in figure 2. The analysis shows that the  Spidergon NoC has lower ND than regular 2D meshes at  least up to 40-45 nodes (and after, depending on the value  of N, see figure 2). In figure 3, we show the analysis  results for the average network distance E[D] for ring,  ideal and real 2D meshes, and Spidergon. It results that  Spidergon outperforms Ring, and works on the middle of  the value range of the real mesh implementations. Ideal  mesh behavior is obtained by real meshes only under  specific N values (that is when N=m*n and m ≈ n). These  results are quite indicative of the difference that may exist  between theory results in ideal cases and real scenarios,  for mesh topologies. Results in figures 2 and 3 show that  Spidergon is expected to have competitive and linear  behavior, on the average and worst case scenarios, due to  node symmetry and regular topology with respect to real  ring and mesh topologies.        In the following we will investigate the NoC support  for communication under some optimal routing strategies  (that is, resulting in the lowest path length) for the  proposed topologies. Specifically, the Spidergon NoC            will adopt the Across-first routing scheme: first, if the  target node for a packet is at distance D > N/4 on the  external ring (that is, in the opposite half of the Spidergon  external ring) then the across link is traversed first, to  reach  the opposite node. Second, clockwise or  counterclockwise direction is taken and maintained,  depending on the target’s position. In Ring-based NoC  the routing strategy is straightforward: clockwise or  counterclockwise direction is taken from the source to the  target node, depending on the shortest path direction. In  2D Mesh NoC, Dimension order routing is adopted: flits  from the source node migrate along the X (horizontal  link) nodes up to the column of the target, then along the  Y (vertical link) nodes up to the target node.  Figure 2: Network Diameter ND vs.  number of nodes N  in Ring, ideal and real 2D Mesh and Spidergon NoCs.  Figure 3: Average Network Distance vs. number of  nodes in Ring, ideal and real 2D Mesh and Spidergon  NoCs.  3. Performance evaluation        The modeling and simulation of the NoC architectures  have been performed with the OMNeT++ simulation  framework [21]. OMNeT++ is a public source, generic  and flexible simulation environment with strong GUI  support that allows a fast and high-level simulation  environment for NoC exploration topologies.         The node model for the Spidergon NoC is shown in  figure 4. Each node has an external network interface to  connect the IP to the NoC. The external IP can act as a  packet source and/or as a packet destination (sink)  depending on the simulated scenario. Packet sources  adopt a Poisson interarrival distribution of constant size  packets (6 flits  in our simulations), with variable  parameter Lambda. The first (head) flit of a packet is sent  to  the routing mechanism of  the node, and  then  transferred on the output queue of the target channel (if  room). Once the head flit has been processed by the  routing element of a node, a switching mechanism is  defined to forward all immediately following packet-flits  to the buffers of outgoing links of the target path to the  destination node. Application packets are consumed from  the IP memory in a FIFO order.  0 0 11 11 10 10 9 9 1 1 2 2 8 8 7 7 3 3 4 4 5 5 6 6 Figure 4: a node model for Spidergon NoC  The scheme in figure 4 refers to Spidergon nodes. On the  other hand, Ring and Mesh nodes considered in this  analysis have been defined with  the same node  architecture, excepted the number of links, the cumulative  buffers sizes, and the routing policies. Specifically, Ring  nodes have clockwise and counterclockwise links only,  and mesh nodes may have from 2 up to 4 links, by  including N, S, W and E direction links. Incoming links  have a one-flit buffer, while outgoing links have a pair of  output buffers (used both for virtual channel management  and deadlock avoidance)  in Ring and Spidergon  topologies, and one single buffer in Mesh topologies. All  output buffers may contain up to three-flits.         Experiments have been performed by modifying the  overall buffer capacity of nodes and buffer symmetry  depending on the expected link usage. Results indicated  that small buffer tuning have some marginal impact on  the peak performances. These results have not been  presented in this work due to space limitations. Due to              system (that is, one single destination node for all  packets). Destination nodes have been taken in different  points on the Mesh topology (in symmetric Ring and  Spidergon this would not have difference). The result  from figure 6 is that the throughput index presents no  differences with respect to the implemented topology  when one single target destination is adopted for all  communications. The only difference is given by varying  the number of source nodes. When all the sources  homogeneously increase the injection rate, this translates  to linear absorption from the (single) destination node, up  to the destination node saturation is obtained. This means  that the most significant system bottleneck under hot-spot  traffic destination scenarios is the destination node, and  not the NoC architecture and the channel buffering  resources. This result  is quite different from  the  interpretation that can be obtained by assuming a uniform  load distribution among many sources and many  destinations. This does not mean  that  the NoC  architecture is irrelevant, because the NoC architecture  behaves better when parallel local communication is  present. On the other hand, in today’s common SoCs  scenarios, when the system memory is external, the  behavior obtained with different NoC topologies would  converge to the behavior shown in figure 6.   space limitations, in the following we will illustrate and  comment the results obtained in three basic scenarios: the  single and double hot-spot target scenario, and the  homogeneous sources and destinations scenario.   3.1 Simulation Results       The first set of data shown is related to the validation  of the simulation and analytical model. Figure 5 shows   Figure 5: analytical and simulation-based average network  distances (hops)  the analytically estimated average distance E[D] and the  simulation-based  value  obtained. Despite  some  differences in the data, due to stochastic variability, the  figure confirms  that Ring has  the worst average  performances, while Spidergon and 2D Mesh topologies  Figure 7: NoC latency, one hot-spot destination node  In other words, the scalable and symmetric architecture of  Spidergon would give the same advantages of more  complex solutions, like 2D Mesh, under the hot-spot  communication viewpoint. In addition, Spidergon can  outperform ring or a complex bus hierarchy when  multiprocessors are presents (these data have been  obtained and were not included in this paper due to space  limitations).    Moreover, Spidergon introduces a degree of scalability  and flexibility that would not be found in current bus  architectures. For this reason, Spidergon appears as the  good  trade-off  solution  for obtaining  the  same  Figure 6: NoC throughput, one hot-spot destination node  work close to each other in the range from 8 to 32 nodes.  3.1.1 Single hot-spot target scenario       Figure 6 shows the throughput index of the NoC  architecture as a function of the injection rate parameter  of the source nodes when hot-spot target is present in the                  performances of more complex architectures, under  common scenarios in current SoCs.        Figure 7 shows the average latency obtained by  Spidergon, 2D Mesh and Ring topologies under one  single hot-spot destination node, as a function of the  number of nodes N and the injection rate parameter of  multiple source nodes. Data show that the latency sharply  increases when the target node saturation is obtained,  with little differences due to the NoC topology adopted.  By assuming an homogeneous injection rate, the latency  increases early when the number of source nodes  increases, as expected.  3.1.2 Double hot-spot scenario      Simulations have been performed by considering a pair  of hot-spot target scenarios, and by allocating the targets  in different positions inside the NoC topologies.    For 2D Mesh, scenario A is with 2 targets on the  opposite corners (nodes 1 and N), scenario B is with one  target in the corner (node 1) and the second one in the  middle (node 5 with 2*4=8 mesh and node 14 with  4*6=24 mesh), and scenario 3 is with both targets in the  middle (nodes 5 and 6 with 2*4=8 mesh, and nodes 14  and 15 with 4*6=24 mesh). In Ring and Spidergon,  scenario A is with two targets in opposition (North-South  position) on the ring, and scenario B is with two targets in  North and West positions on the ring. The results (see  figures 8 and 9) basically confirm the system behavior  and conclusions discussed for one hot-spot target.   3.1.3 Homogeneous sources/destinations scenario       Figure 10 shows the throughput results with respect to  the NoC topology and the number of nodes, under  homogeneous scenarios with uniform distribution of  sources and destinations. Specifically, all the nodes  behave like sources and can be addressed as destination  for packets, with uniform probability distribution. When  all node sources increase the injection rate, this translates  to linear absorbtion from all the destination nodes, up to  the set of destination nodes and/or the network become  saturated. This performance  index  illustrates  that  Spidergon and 2D Mesh topologies outperform Ring, and  scale better when the number of nodes is low. Under this  scenario, 2D Mesh shows a better throughput than  Spidergon only with many nodes and when the local  injection rate of all source nodes is greater than 0.3  flits/cycle. On the other hand this scenario is hardly  obtained in real systems, and this does not constitutes a  good motivation to prefere the adoption of 2D Mesh in  favour of the Spidergon topology. As expected, the  bottleneck emerging in this scenario is basically given by  the communication infrastructure. This is confirmed also  by the worst performances obtained by the Ring topology.  Figure 8: NoC throughput, two hot-spot destination  nodes  Figure 9: NoC latency, two hot-spot destination nodes  Figure 10: NoC throughput, homogeneous system with  all nodes working as packet sources and destinations       Figure 11 illustrates the average latency obtained by  Spidergon, 2D Mesh and Ring  topologies under  homogeneous  source  and destination distribution  scenarios. All the nodes behave like sources and can be                    patterns originated by common applications, and analysis  of routing protocols and additional NoC topologies.  Acknowledgments  The authors wish to thank Marcello Coppola and  Riccardo Locatelli  (STMicroelectronics)  for  their  contributions and constructive discussions about the  topics and analysis presented in this paper.  "
2007,A GALS Infrastructure for a Massively Parallel Multiprocessor.,"This case study focuses on a massively parallel multiprocessor for real-time simulation of billions of neurons. Every node of the design comprises 20 ARM9 cores, a memory interface, a multicast router, and two NoC structures for communicating between internal cores and the environment. The NoCs are asynchronous; the cores and RAM interfaces are synchronous. This GALS approach decouples clocking concerns for different parts of the die, leading to greater power efficiency.",
2013,A clustered manycore processor architecture for embedded and accelerated applications.,"The Kalray MPPA-256 processor integrates 256 user cores and 32 system cores on a chip with 28nm CMOS technology. Each core implements a 32-bit 5-issue VLIW architecture. These cores are distributed across 16 compute clusters of 16+1 cores, and 4 quad-core I/O subsystems. Each compute cluster and I/O subsystem owns a private address space, while communication and synchronization between them is ensured by data and control Networks-On-Chip (NoC). The MPPA-256 processor is also fitted with a variety of I/O controllers, in particular DDR, PCI, Ethernet, Interlaken and GPIO. We demonstrate that the MPPA-256 processor clustered manycore architecture is effective on two different classes of applications: embedded computing, with the implementation of a professional H.264 video encoder that runs in real-time at low power; and high-performance computing, with the acceleration of a financial option pricing application. In the first case, a cyclostatic dataflow programming environment is utilized, that automates application distribution over the execution resources. In the second case, an explicit parallel programming model based on POSIX processes, threads, and NoC-specific IPC is used.",
2009,SCARAB - a single cycle adaptive routing and bufferless network.,"As technology scaling drives the number of processor cores upward, current on-chip routers consume substantial portions of chip area and power budgets. Since existing research has greatly reduced router latency overheads and capitalized on available on-chip bandwidth, power constraints dominate interconnection network design. Recently research has proposed bufferless routers as a means to alleviate these constraints, but to date all designs exhibit poor operational frequency, throughput, or latency. In this paper, we propose an efficient bufferless router which lowers average packet latency by 17.6% and dynamic energy by 18.3% over existing bufferless on-chip network designs. In order to maintain the energy and area benefit of bufferless routers while delivering ultra-low latencies, our router utilizes an opportunistic processor-side buffering technique and an energy-efficient circuit-switched network for delivering negative acknowledgments for dropped packets.","SCARAB: A Single Cycle Adaptive Routing and Bufferless Network Mitchell Hayenga University of Wisconsin-Madison hayenga@ece.wisc.edu Natalie Enright Jerger University of Toronto enright@eecg.toronto.edu Mikko Lipasti University of Wisconsin-Madison mikko@ece.wisc.edu ABSTRACT As technology scaling drives the number of processor cores upward, current on-chip routers consume substantial portions of chip area and power budgets. Since existing research has greatly reduced router latency overheads and capitalized on available on-chip bandwidth, power constraints dominate interconnection network design. Recently research has proposed buﬀerless routers as a means to alleviate these constraints, but to date all designs exhibit poor operational frequency, throughput, or latency. In this paper, we propose an eﬃcient buﬀerless router which lowers average packet latency by 17.6% and dynamic energy by 18.3% over existing buﬀerless on-chip network designs. In order to maintain the energy and area beneﬁt of buﬀerless routers while delivering ultra-low latencies, our router utilizes an opportunistic processor-side buﬀering technique and an energy-eﬃcient circuit-switched network for delivering negative acknowledgments for dropped packets. Categories and Subject Descriptors C.1.2 [Computer Systems Organization]: MultiprocessorsInterconnection architectures; C.1.4 [Parallel Architectures]: Distributed architectures General Terms Design, Performance Keywords Interconnection networks, multi-core, routing 1. INTRODUCTION Historically, switched networks have relied on in-router buﬀering to handle routing conﬂicts; when two outbound packets are destined for the same link, one must be buﬀered while the other is transmitted. These traditional buﬀered routing approaches were derived in an era when the source Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. MICRO’09, December 12–16, 2009, New York, NY, USA. Copyright 2009 ACM 978-1-60558-798-1/09/12 ...$10.00. and destination nodes were far apart, and retransmission due to conﬂicts was considered either unacceptable or something to be avoided at all costs. In contrast, in on-chip networks, the source and destination nodes are in close proximity of each other. Furthermore, advances in on-chip router microarchitecture have greatly decreased end-to-end latency and provided abundant inter-node bandwidth [11, 17, 22]. Both the low end-to-end latency provided by these microarchitectural improvements and the proximity provided onchip lessens the power and performance cost of retransmission making it a viable alternative to buﬀering. In addition to being less necessary for performance in comparison to their oﬀ-chip counterparts, network buﬀers add pressure to the area and power constraints for on-chip networks. Recent designs from Intel have shown on-chip interconnects consuming as much as 28% of total chip power, with 22% of router power being consumed by network buﬀering resources [7]. Removing in-network buﬀering and performing processor-side buﬀering through utilization of the miss status handling registers (MSHRs) that are already being held for outstanding requests, is attractive as their use can lead to fewer total required buﬀering resources. Fewer overall buﬀering resources will reduce the dynamic and leakage power of the on-chip network. In this paper we propose SCARAB, a single-cycle minimallyadaptive routing and buﬀerless router for on-chip interconnection networks. SCARAB is a processor-side buﬀered router which supports a dropping protocol for dealing with routing conﬂicts. It employs multiple novel mechanisms to reduce the likelihood of packet drops and retransmission costs. With these mechanisms, the SCARAB network architecture makes the following novel contributions: Optimized NACK network. A ﬁxed-delay, circuit-switched negative acknowledgement (NACK) network is utilized for energy-eﬃcient packet retransmissions. As packets progress through the SCARAB network, they reserve NACK wires on a NACK network to trigger retransmission from the packet source upon network contention. Signaling NACKs on a separate, pre-allocated network after routing data on a buﬀerless minimally-adaptive network results in deterministic latency, which enables successful packet transmissions to be implicitly acknowledged (ACKed). Additionally, time division multiplexing and other techniques are employed to lessen the NACK network overhead. 244 Opportunistic processor-side buffering. Although the routers within the network provide no buﬀering, SCARAB can utilize idle MSHRs at intermediate nodes to opportunistically buﬀer in-ﬂight packets, provided the ejection port is idle. Once opportunistically buﬀered, future retransmissions are initiated from the intermediate node rather than the original source, saving latency and power. We detail a heuristic for when to opportunistically buﬀer which depends upon the successful transmission rate observed from each router port and the number of local MSHRs available. High-performance minimally-adaptive allocator. To lessen network contention, while retaining high frequency operation, we detail the implementation of a novel high performance, minimally-adaptive switch allocator design. The short critical delay path through this allocator enables high-frequency single-cycle packet latency at intermediate nodes. We compare SCARAB to previously proposed buﬀerless on-chip routers and establish the advantages it oﬀers for performance and energy eﬃciency. For comparison purposes, we implement the router originally proposed in [26] and recently re-evaluated by Moscibroda et. al [15, 16]. This hotpotato (HP) router utilizes fully adaptive routing and a priority protocol to ensure packets reach their destinations in a timely fashion. We also implement a router similar to the Blind Packet Switched (BPS) router presented by Gomez et. al [6]. From synthesized RTL verilog and C-model performance simulations on real-world applications, we show the dynamic energy per active cycle across all evaluated routers is within 1%, but the SCARAB network demonstrates 12.2-17.6% less observed packet latency resulting in fewer active network cycles. Thus we ﬁnd that the SCARAB network, in addition to delivering better performance, is up to 18.3% more dynamic energy eﬃcient than previously proposed buﬀerless architectures. Due to their similar overall structure and comparable chip area, we do not expect there to be signiﬁcant diﬀerences in leakage power for these designs, so we only report detailed results for dynamic energy. Section 2 provides in-depth coverage of our baseline buﬀerless routers. Section 3 details the microarchitecture of the SCARAB router. Section 4 compares the area, frequency, and power of the router models. Section 5 contains the performance results evaluation and associated discussion. Section 6 details related work. Section 7 summarizes and concludes the paper. 2. BASELINE ARCHITECTURES This section details the selected baseline routers which were implemented and benchmarked against the SCARAB router. In deﬁning the baseline architectures, the design tradeoﬀs involved in each are highlighted and discussed. All routers are evaluated in the context of an on-chip 2D mesh. 2.1 Hot-Potato Architecture Deﬁnition. The HP router [15, 16, 26] is a recently proposed buﬀerless router for on-chip networks which is derived from the historic HEP’s network switch architecture [23]. These switches utilize hot-potato routing to enable both non-dropping and buﬀerless operation. Hot-potato routing enables buﬀerless and NACK-less operation by forcing all arriving ﬂits at a node to be routed out on the next cycle, even if a nonproductive route must be taken. The HP router consists of a two-stage pipeline; the ﬁrst stage is switch allocation (SA) and the second stage is switch traversal (ST). Packet headers contain a priority vector which records the number of router hops a packet has traversed. This priority ﬁeld is used to ensure older packets are more likely to obtain proﬁtable routing to their destinations. Each cycle, the switch allocator services input requests in order of decreasing priority. If a high-priority packet can select multiple proﬁtable outputs and any lower priority packets have one of these outputs as their only possible proﬁtable route, the high-priority packet will receive the less contested output. Implementation. Our implementation of the HP router is designed to be functionally equivalent to the router deﬁned in [15] although it diﬀers in some respects to the other versions of the architecture [16, 26]. The authors consider only single-ﬂit packets [15], while our adaptation to multiple-ﬂit packets highlights some resulting design complexities. If a multi-ﬂit packet has won arbitration for an output port it must be sent in its entirety before allowing the port to be reallocated. All ﬂits of a multi-ﬂit packet must be routed to the same output port in consecutive cycles since only the head ﬂit contains routing and destination information. This diﬀers from the multi-ﬂit implementations [16, 26] which replicate header information in each ﬂit, hence enabling packet fragmentation and switch reconﬁguration in response to output port contention. Also, our HP router must have enough additional injectorside buﬀering to hold a maximal length packet. This buﬀering is required because the hot-potato router must be able to temporarily misroute a packet out of the injector port. The injector-misroute case occurs when a multi-ﬂit packet from the injector has won allocation for an outward bound port on one cycle, and all other input ports register an incoming packet on the next clock cycle. All of the incoming packets could be maximum length packets and one of them will require temporary buﬀering on the local port. Disadvantages. The HP router suﬀers from a number of shortcomings fundamental to operation and the design choices necessary for its implementation. First, the HP allocator is intrinsically serial since it must support the case where packets on all input ports must be routed to all output ports. That is, given incoming packets on all ports, each must be serviced in order of decreasing priority as the output port selections of the higher priority packets determine which outputs are still available to lower priority packets. Prior work details the diﬃculty of achieving competitive clock frequencies with hot-potato routing [19, 20, 26]. The reported critical path has a depth of 50 gates [19, 20] and can only achieve a 500 MHz operation in 0.13 um technology [26]. Our own implementation, further detailed in Section 4 was only able to achieve operation at 857 MHz, a factor of two slower than our other allocators. No operating frequency analysis was done in [16] 245 or [15]. Note that allocation is an inherently atomic (singlecycle) operation, and cannot be pipelined without resorting to speculative techniques that can fail, and are inherently incompatible with the hot potato router’s guaranteed delivery of all injected packets. Second, [26] assumes multi-ﬂit packets can be fragmented in-ﬂight and reassembled at the destination node. This assumption drastically increases the destination buﬀering requirement as every node must be able to resequence packets from potentially every other node within the network. It should be noted that [16] demonstrates an observed doubling in required destination buﬀering from benchmark runs, but this is not the maximal bound which must be allocated to guarantee that the network will never drop packets. Finally, Moscibroda and Mutlu [15] note that their network is livelock free since they prioritize the oldest packets, guaranteeing a packet eventual delivery at its destination node. This statement makes the assumptions that 1) priorities can not saturate and 2) all packets are single ﬂits or packet fragmentation is supported. If priorities can saturate it is possible for multiple maximum priority packets to deﬂect each other, preventing any from reaching their ﬁnal destination. The HEP solved the saturating priority issue by forcing all packets to take a deterministic route once they reached a maximum priority [23]. Additionally, if not all packets are single ﬂits, livelock is still possible when outputs are allocated for multiple cycles. It is possible for a packet, regardless of its priority, to never get routed to a destination node since all productive outputs could have been allocated in a previous cycle. Once the packet is misrouted, nothing prevents it from facing this same situation again on all subsequent clock cycles. One of the advantages of buﬀerless routing, in addition to power, is being able to operate at higher clock frequencies due to removing buﬀer writes from the critical path [6]. Unfortunately, the strict allocator imposed by hot-potato routing and complexity in solving livelock issues may limit these performance gains. 2.2 BPS Architecture Deﬁnition. The BPS router is a NACK-based buﬀerless router which performs minimally adaptive routing to limit the number of possible collisions. In the event of a collision, a NACK packet is routed through the network back to the source node to trigger retransmission of the original data packet. Because NACKs cannot be dropped, small NACK buﬀers are present at every input port. The ACKs within the BPS network are implicit since the maximum time necessary to wait to receive a NACK is deterministic. This is because NACK buﬀers at each router are serviced in a deterministic order and NACKs carry a higher priority than regular data packets. Due to their higher priority, NACK packets can cause data packets to abort leading to higher drop rates. The BPS proposal also used Space Division Multiplexing (SDM), splitting large 256-bit links into four 64-bit links, in order to limit network contention for shared links. By reducing contention, SDM improves the packet drop rate at the expense of additional allocation and switch conﬁguration logic. Implementation. For our implementation we assume that NACK packets only assert a higher priority when NACK buﬀering at the local router is limited. This leads to lower packet drop rates and does not aﬀect overall network performance assuming additional MSHRs are appropriately provisioned to tolerate a longer, maximally-bounded, implicit ACK latency. Additionally, our BPS implementation more aggressively targets low latency than the original proposal. The initial proposal suggested using latch chains to temporarily buﬀer data while routing decisions were made. Instead, we use separate allocation and data networks similar to those in [11]. This enables our BPS baseline to operate as a singlecycle router, sending the allocation packet one cycle ahead of the data packet such that the data switch is fully set up when the data ﬂits arrive. For purposes of fair comparison, our implemented version of BPS does not use SDM as it is orthogonal to the overall router design and could likewise be applied to the other buﬀerless routers in order to reduce network contention. Disadvantages. Using a shared network for packet transmissions and NACKs hinders the BPS architecture as NACKs from previous routing conﬂicts further increase total network congestion. The negative impact of NACKs upon the network is likely to accelerate total network saturation under moderate workloads. Also, though implicit ACKs in BPS have deterministic latency, it is relatively high due to the presence of NACK buﬀering. This increases pressure on source-side MSHRs as they must remain allocated for longer to ensure successful packet delivery. 3. SCARAB ARCHITECTURE 3.1 Overview The SCARAB router is designed to eliminate in-network buﬀering, limit additional processor-side buﬀering, provide an eﬃcient NACK mechanism for packet retransmission, and scale to high frequencies with low end-to-end network delays. 3.2 Router Pipeline The SCARAB router implements a single-cycle latency pipeline similar to that in [11]. As illustrated in Figure 1, the packet header travels along a small (17-bit) allocation network one cycle ahead of the data. By optimizing the allocation network to operate with a single-cycle latency, trailing ﬂits on the data network also experience only a single cycle router delay per network hop. Figure 1 demonstrates how multiple data ﬂits can be streamed through multiple hops. Figure 2 shows that the router can be viewed as three inter-related but physically separate networks: one for allocation, one for data transfers, and one for NACKs. To successfully route a packet, an allocation packet must be sent one cycle before the ﬁrst data ﬂit is sent on the data network. The cycle before the ﬁrst data ﬂit arrives, the allocation packet performs switch allocation and traversal. Allocation is successful if a productive output is obtained and free NACK wires exist along this output path. On the subsequent clock cycle, the data ﬂit will immediately proceed to switch traversal, as the allocation packet has preconﬁgured the data crossbar switch. If allocation cannot be 246 2. Counts the number of possible requests per output. 3. Masks oﬀ an output port request from requesters with multiple proﬁtable output ports. If the number of requests per outputs are equal, a bit from an LFSR randomly selects one to mask. 4. Computes the maximum priority requesting each output. 5. Presents masked request vectors to a per output roundrobin arbiter if their priority is equal to the maximum. 6. Selects a winning request per output using the round robin arbiters. A packet’s allocation priority can be incremented on either a per-hop or retransmission basis. A per-hop basis would provide better fairness to older packets, but in our testing a per-retransmission priority was found to achieve the majority of the beneﬁt and require fewer priority bits. These vectors can also be minimally sized as SCARAB can be made to operate with saturating priority ﬁelds. Saturating priorities create potential livelock problems for HP, but do not in SCARAB as processors can implement randomized exponential backoﬀ in the event that a saturated priority MSHR has required multiple retransmissions. 3.4 NACK Network The NACK network in the SCARAB router operates as a small 5x5 mux-based switch. Every packet that traverses a router conﬁgures a 1-bit wire to be asserted from output to input if the packet fails at a future router. This NACK wire is connected along the packet’s entire path, such that the source MSHR can be triggered for retransmission in the event of a network collision. As no buﬀering is present in the system, the window of time which a packet could be NACKed after initial transmission is deterministically bounded. If the NACK wire to an MSHR is not triggered in L = 4 × (N + 1) cycles, where N is the number of hops between source and destination, the packet has been implicitly ACKed and the MSHR can be discarded. Each router in the network along the path between source and destination must also allocate these NACK wires for at least 4 × (N + 1) cycles before allowing reallocation. L cycles must elapse before reallocating NACK wires because it takes 2 cycles to enter the network from the injection port, 2 × N cycles to progress to the destination router at which the packet could fail arbitration for the local port, leading to an additional 2 × (N + 1) cycles for the NACK to arrive at the source injector. To highlight the need for an eﬃcient NACK network, we evaluate the storage overhead of a na¨ıve implementation. A na¨ıve implementation would allocate a counter per NACK wire. As derived in the previous paragraph, each counter would require log2 (4 × (max(N ) + 1)) bits. The entire router node would require a F counter ﬂip-ﬂops, F = P W log2 (4 × (max(N ) + 1)), where P is the number of router ports and W is the number of NACK-wires between nodes. Although this equation grows logarithmically with increasing network size, the linear growth with respect to NACK wires is unacceptable. Additionally, for scalable performance, the number of necessary NACK wires per router port does increase with network size as messages are transported through more intermediate nodes. Taking this into Figure 1: SCARAB single cycle pipeline processing. Allocation header performs allocation (SA) and switch traversal (ST) in a single cycle. Trailing data ﬂits follow pre-conﬁgured crossbar switch. All ﬂits observes a single cycle of link delay (LN) for intertile latency. Figure 2: SCARAB router showing the three networks 1) Allocation 2) Data 3) NACK and signaling between them. performed successfully, the data packet is dropped and on the successive cycle, the NACK wire corresponding to this packet is asserted to the previous node. This NACK signal will travel back across the network to the source to trigger the retransmission of the packet. The NACK network, acting as a pre-conﬁgured circuit-switched network, is also only a single router cycle delay from input NACK to output NACK. 3.3 Allocator Design The SCARAB router employs a minimally adaptive routing algorithm and only allows packets to be routed in productive directions. The input along the allocation network consists of a ﬁeld containing the following information: a 5bit one-hot vector encoding productive output ports at this current hop, the priority of the current packet (4 bits), the size in ﬂits of the corresponding data packet (2 bits, allowing 4 packet sizes), and the destination node number (6 bits for an 8x8 network). At 17 bits, the allocation port is reasonably small compared to the 128-bit data port for each input. At each cycle allocation is performed among incoming allocation packets. During this cycle the allocator: 1. Masks oﬀ unavailable outputs (due to previous allocation for a multi-ﬂit packet or lack of available NACK wires) from the incoming request vectors. 247 a longer duration due to the group management of epochs. Additionally, the need to scale much further beyond 16 logical NACK wires for larger networks is likely small as it is highly workload dependent and performant applications running on large scale networks would have a limited number of global references spanning the entire network. For example, server consolidation workloads are likely to exhibit a higher percentage of local requests compared to global requests. Using a 1-bit NACK network results in a very energy eﬃcient means of signaling retransmission in comparison to the BPS network which would need to send a full data packet to request retransmission. In addition to being very small, the NACK network experiences very little activity assuming network contention is kept at reasonable levels. Finally, separating the NACK network from the data network creates deterministic delays and a tighter bound on how long MSHRs must remain allocated for processor-side buﬀering. In the BPS network, this bound exists but is signiﬁcantly larger due to buﬀering delays that NACKs may face in-ﬂight to their source node. 3.5 Opportunistic Buffering To increase the scalability and performance of SCARAB, we further optimize the network with a novel processor-side buﬀering technique that comes at almost no hardware cost. Opportunistic buﬀering is the temporary borrowing of another node’s MSHR buﬀers such that retransmissions occur not from the packet’s source, but from an intermediate node in the network. Intermediate buﬀering leads to both lower energy consumption and lower latency per retransmission. This opportunistic buﬀering should not be confused with traditional in-network buﬀering as no additional buﬀer resources are necessary; opportunistic buﬀering puts otherwise idle buﬀers to use. Implementing opportunistic buﬀering requires only small router changes. First, opportunistic buﬀering only occurs when a packet is determined to beneﬁt from buﬀering, the local ejection port is idle, and suﬃcient free MSHRs exist. Signaling free MSHRs involves the addition of a single wire from the injection port to the local router. From experimentation on real application traces (see Section 5.2 for application descriptions), we have derived a heuristic for when to opportunistically buﬀer. To ensure a node is not starved of its own MSHRs we limit opportunistic buﬀering to only use up to one quarter of the total available MSHRs. Additionally, we do not signal the availability of buﬀers if the local node is using more than half of its MSHRs. This policy leaves suﬃcient free MSHRs for a local burst in traﬃc. To determine when it is potentially beneﬁcial to opportunistically buﬀer a packet, we have designed a novel heuristic to identify likely to fail packets. For each output direction we maintain a single counter which keeps the running average priority of all packets routed out of the output port. If a packet’s priority is less than or equal to this average priority, the packet is deemed at risk and should be opportunistically buﬀered if possible. Since multiple output directions may match this heuristic during a given cycle, we grant the MSHR to the requestor with the highest priority. The packet is then routed out both the output and local ports. The local port must check the incoming packet’s destination to determine if they are being opportunistically buﬀered or destined for this current node. To simplify logic, we only alFigure 3: Percentage of packets dropped due to lack of NACK wire availability for an 8x8 network versus the number of available logical NACK wires under a uniform random traﬃc workload. Drop rates are plotted until network saturation. account, the number of ﬂip-ﬂops required for scalable performance in a na¨ıve mesh network would scale almost quadratically with increasing network size. Our router takes advantage of serveral novel techniques to reduce the cost of the NACK network and scale logarithmically with increasing network size. First, NACK wires are managed in groups to reduce the number of cycle-counters required to determine when an individual NACK wire can be reallocated. NACKs for each port are managed in two allocation epochs. All NACKS within an epoch are allocated until no free NACKs exist. Each epoch maintains a counter equal to the maximum number of cycles for any NACK allocated within this epoch. This counter is decremented until it is equal to zero, at which point in time all NACKs wires within this epoch are considered allocatable. Secondly, our network takes advantage of time division multiplexing of the NACK wires to lessen the number of NACK wires needed between routers. Since it takes two cycles to reach the allocation phase of the next router, we implicitly know any packet we send out on an even clock cycle can only be NACKed on a later even cycle. This enables us to halve the number of inter-router NACK wires necessary to sustain network bandwidth. For better management of time-based multiplexing we have four total epoch counters per port, two for even clock cycles and two for odd clock cycles. Finally, our epoch-based allocation assigns NACK wires in an ordered fashion such that neighboring nodes implicitly know the next sequential NACK which will be allocated. This property eliminates the need for communicating a NACK wire identiﬁer in the allocation packet. To demonstrate the scalability of this NACK network design, Figure 3 shows the percentage of failed transmissions due to unvailable NACK wires on an 8x8 network with 4, 8, 12, and 16 logical NACK wires. The traﬃc workload was uniform random traﬃc and these tests were performed on a SCARAB network with priorities, but without the opportunistic buﬀering feature mentioned in the next section. For low injection rates, a small number of NACK wires is sufﬁcient to limit packet drops due to NACK wire contention. Also, with more NACK wires in a single epoch, NACK network performance scales despite wires being allocated for 248 low single-ﬂit packets to be opportunistically buﬀered; support for multi-ﬂit packets would require logic to truncate partially buﬀered packets and rollback alterations to the NACK network necessary for opportunistic buﬀering. With our application workloads, ∼70% of packets are single-ﬂit, so limiting processor-side buﬀering to only single-ﬂit packets will capture the ma jority of opportunity with low hardware cost. The NACK network protocol must be modiﬁed to support opportunistic buﬀering. Once a packet is selected for opportunistic buﬀering, instead of tying the NACK wire from the packet’s incoming port to its outgoing port, the protocol ties the input and output port NACK wires to the local port so that it can intelligently manage NACK actions from future nodes. Additionally, the source node for a packet must be notiﬁed not to treat the MSHR as retired. To do this we extend the pulse-based NACK protocol to include level-based signaling to leave NACK wires intact for 4 × (N + 1) + 2 cycles. If a pulse is received, a packet is interpreted as having been NACKed. If a level raise is received, it indicates a downstream node is opportunistically buﬀering the packet and intermediate nodes should not tear down their associated NACK wires or treat the source MSHR as retired. Once the opportunistically buﬀering node is implicitly ACKed indicating successful transmission, this NACK level is lowered signaling completion. An opportunistically buﬀering node can itself receive a level raise from a future node, at which point it leaves the NACK wires conﬁgured, but is allowed to free the intermediate MSHR as it is no longer necessary. This event implies that a packet has been again opportunistically buﬀered at a downstream node. For clarity, these steps are explained as a detailed graphical example in Figure 4. Opportunistic buﬀering allows our router to scale to higher saturation points, better deal with network congestion, and better scale to larger network sizes; opportunistic buﬀering is evaluated in Section 5. 4. PHYSICAL IMPLEMENTATION 4.1 Methodology To ensure accurate hardware modeling all compared routers were implemented in RTL Verilog. Results for area, power, and frequency are derived from synthesizing to the TSMC 65nm standard cell library using the Synopsys Design Compiler R(cid:13) with high optimization enabled. For dynamic power calculations, uniform switching activity was assumed on all router input ports and we report the clock-normalized dynamic energy per cycle. For all three routers, equal eﬀort was placed into optimizing the designs for cycle time. For synthesis, the conﬁguration parameters as speciﬁed in Table 2 in Section 5 were used, with the only deviation being that a ﬁxed 4-bit priority ﬁeld, rather than 64-bit priority used in the performance evaluation, was used in the synthesis of the HP router. 4.2 Implementation Results BPS and SCARAB. Due to the fact that both the BPS router and SCARAB router are dropping, minimally adaptive routers, a similar allocator structure was utilized for both, allowing each to 249 Figure 4: Example NACK operation in the SCARAB network. A) Packet awaits transmission from source node 0 to destination node 8. B) Packet has progressed to 3 and becomes opportunistically buﬀered. 3 raises the level of the associated NACK to signal that the MSHR cannot be deallocated and the NACK wire must remain intact. C) Packet progresses successfully onward to node 7 before failing. D) 7 pulses the NACK causing 3 to retransmit the packet E) The packet, retransmitted from 3 reaches 6 where it is again buﬀered. 6 raises the level of the associated NACK wire causing 3 to deallocate its MHSR. F) Packet successfully reaches destination node 8. G) The NACK wire at 6 implicitly times out, causing it to lower the NACK wire back to the source. H) Source sees the NACK level drop and deallocates the original MSHR. Table 1: Router Synthesis Results Router Area (um2 ) Energy (pJ) Frequency SCARAB 34.1K 24.32 1.9GHz BPS 33.7K 24.42 1.9GHz HP 31.2K 24.46 857MHz be a single-cycle router. This minimally adaptive allocator, when synthesized by itself, achieves a 2.5GHz frequency. The combined allocator and crossbar latency is the critical path for both the BPS and SCARAB routers, as was expected for such an aggressive design. As shown in Table 1 the combined allocator/crossbar of SCARAB and BPS routers limit their frequency to 1.9GHz, with the reduction in allocator frequency due to a combinational path necessary to signal the availability of NACK wires(SCARAB) or buﬀers(BPS) to neighboring nodes that is excluded from the standalone allocator module. The 1.9GHz frequency for each of these routers corresponds to a delay of 16.8FO4, given our library’s 31.3ps FO4 delay. A 16.8FO4 delay is competitive with aggressive router implementations which target 20FO4 [22] and 35FO4 [17]. The SCARAB network is slightly more expensive in terms of area because its NACK network consumes more area than the NACK buﬀers present in the BPS router. HP. As discussed in Section 2.1, the implementation of a hotpotato switch allocator presents diﬃculties in achieving an acceptable clock frequency. To lessen the serial nature of allocating outputs in the HP router, we have leveraged insight from high speed arithmetic circuits. Figure 5 details the general algorithm used for both the na¨ıve and more advanced allocator used in our HP implementation. In Figure 5a, the serial version simply performs a parallel sort of the incoming packets based upon priority and then allocates each output in descending order. Synthesis of this na¨ıve serial version results in a maximum allocator frequency of 670MHz. Figure 5b details a carry-select version of the allocator in which each lower priority packet calculates 5 possible port selections in parallel with the higher priority packet’s allocation stage. Once the higher priority packet’s output port is selected, the appropriate allocation for the lower priority packet is selected. This carry-select version increases the maximum realizable frequency of the HP allocator to 990MHz. If the sort of the incoming packets based upon priority is not performed within the same clock cycle as allocation, lengthening the router pipeline to 3 stages, the carry-select hot-potato allocator can synthesize at 1.3GHz. When all logic necessary to implement the HP allocator is synthesized, the maximum achieved frequency is 857MHz for the 2-stage design. Perhaps with further modiﬁcations to the allocation algorithm, the HP allocator could be made to operate at an aggressive clock frequency. Giving the HP router the beneﬁt of the doubt, all later performance evaluations within this paper assume that the HP router can operate at the same 1.9GHz frequency as the BPS and SCARAB routers. It should be noted that frequency resulting from a physical implementation was not speciﬁed in HP [15, 16]. 250 Figure 5: HP allocator alternatives. Power Analysis. Table 1 shows all three routers expend approximately (within 1%) the same amount of dynamic energy for an individual router node on a per-cycle basis assuming a constant and uniform load, irrespective of total network performance. As will be shown in Section 5.2, for real world application workloads the SCARAB network results in 17.6% less latency than HP and 12.2% less latency than BPS. As all three routers are buﬀerless, lower latency directly corresponds to fewer dropped or misrouted packets that lead to additional network events. Taking the absolute number of network events for the application traces in Section 5.2 and combining them with the given dynamic energy expended on a per-cycle basis we can derive the total dynamic energy necessary to execute the given traces. We ﬁnd SCARAB to be at least 18.3% more eﬃcient than HP and 12.6% more eﬃcient than BPS on a dynamic energy basis. 5. EVALUATION We evaluate the SCARAB router against BPS and HP with both synthetic traﬃc and with traces collected from real workloads. To perform these evaluations, a cycle accurate C++ model of each router was constructed. For SCARAB, two versions, one with opportunistic buﬀering with retransmission-based priorities and another with no opportunistic buﬀering or priorities, are used for comparison. If no version is speciﬁed, the SCARAB router used is the opportunistic buﬀering, priority-based version. Also, the evaluated BPS router assumes only a single link between nodes, rather than multiple, smaller links. All routers are assumed to be able to operate at the same 1.9GHz frequency, despite the fact that our verilog implementations indicate that the maximum implementable frequency of the HP router is much less than either the BPS or SCARAB routers. To highlight the fact that the HP router is operating at an idealized frequency, its results are shown as dotted lines and should be regarded as an upper bound on its potential performance. Table 2 speciﬁes all conﬁguration parameters used in the performance evaluation. Figure 6: Average packet latency for single-ﬂit uniform random traﬃc on 4x4, 6x6, and 8x8 networks. Pipeline Latency Packet Priority Routing Algorithm MSHRs NACK Wires Table 2: Network Conﬁguration Common Parameters Processor Frequency 3.8 GHz Router Frequency 1.9 GHz Flit Size 16 bytes (128 bits) Coherence Packet Size 1 ﬂit Data Packet Size 5 ﬂits Network Sizes 4x4, 6x6, 8x8 Mesh SCARAB Router 1-cycle 4-bits, Retransmission-based Minimally Adaptive 16 8 per port (16 logical) BPS Router 1-cycle 4-bits, Retransmission-based Minimally Adaptive 16 8 per port HP Router 2-cycle 64-bits, Hop-based Fully Adaptive Inﬁnite Pipeline Latency Packet Priority Routing Algorithm MSHRs NACK Buﬀers Pipeline Latency Packet Priority Routing Algorithm MSHRs 5.1 Synthetic Workload Evaluation To determine how the routers compare across multiple network sizes they were directly compared with networks of 16, 36, and 64 nodes using uniform random, tornado, and neighbor traﬃc traces. Single-ﬂit traﬃc should result in the highest total network utilization for all routers. For all synthetic traﬃc patterns we evaluated the performance of four router models. 1) SCARAB with priorities and opportunistic buﬀering 2) SCARAB without priorities or opportunistic buﬀering 3) HP and 4) BPS. MSHR modeling in the SCARAB and BPS routers greatly impacts the synthetic traﬃc workload performance in comparison to the HP router. As synthetic, single-ﬂit traces operate independently of coherence or consistency constraints, the HP router can free MSHRs as soon as packets are injected into the network. In a real system, MSHRs are held until the miss is satisﬁed (data is returned). This makes 251 MSHRs on HP for synthetic traﬃc eﬀectively unlimited. SCARAB and BPS can not free MSHRs upon injection due to their requirement to retransmit from MSHRs when network collisions occur. In the following traﬃc patterns, the SCARAB and BPS routers saturate in many cases once their MSHRs are fully occupied. It should be noted that for realistic network workloads, which guard against race conditions, this artiﬁcial advantage of HP does not apply. Uniform Random Trafﬁc. Figure 6 shows the average packet latency for each router model on uniform random traﬃc traces for networks of 4x4, 6x6, and 8x8. The simulations across all network sizes produce consistent results with the relative performance rankings of the routers unchanged. For all network sizes BPS has low zero-load latency, but quickly saturates at low injection rates. This phenomenon supports the hypothesis that transporting NACKs along the data network adds signiﬁcant network pressure, quickly leading to saturation. The HP router, as a 2-cycle router, has a signiﬁcantly higher zero-load latency but approaches saturation very gradually and demonstrates the best average packet latency at high network injection rates. This characteristic of the HP router suggests it is well suited to latency insensitive, high-bandwidth applications. For more typical injection rates of less than 15% [4, 5, 9], the SCARAB router demonstrates the best average packet latency. Additionally, the relative beneﬁt of opportunistic buﬀering and retransmission-based priorities are shown to increase as network size increases. Tornado Trafﬁc. To model potential worst-case performance, the tornado traﬃc pattern was evaluated against the router models on an 8x8 network. Figure 7 shows that the saturation point for all routers is signiﬁcantly less than their corresponding saturation point on uniform random traﬃc. This adversarial traﬃc pattern has no impact on the respective ordering of the routers’ performances. For this workload and network size, the BPS router performs very poorly and saturates just beyond a 3% injection rate. SCARAB and HP scale much better, achieving reasonable latencies with moderate traﬃc. Neighbor Trafﬁc. To approximate the best traﬃc pattern for buﬀerless routers, we use the neighbor traﬃc pattern on an 8x8 network. In this trace all nodes randomly transmit to their immediate neighbors. Figure 8 shows that all routers perform quite well; all are able to achieve a 30% injection rate prior to Table 3: Benchmark Descriptions SPECjbb Standard java server workload utilizing 24 warehouses, executing 200 requests SPECweb Zeus Web Server 3.37 servicing 300 HTTP requests TPC-W TPC’s Web e-commerce benchmark, DB Tier Browsing mix, 40 web transactions TPC-H TPC’s Decision Support System Benchmark, IBM DB2 v6.1 running query 12 w/ 512MB database, 1GB of memory 514x514 full end-to-end run (parallel phase only) -room -batch -ae 5000 -en .050 -bf .10 (parallel phase only) car input (parallel phase only) Radiosity Ocean Figure 7: Average packet latency for tornado traﬃc on an 8x8 network. Raytrace Figure 8: Average packet latency for immediate neighbor traﬃc on an 8x8 network. saturating. This ﬁgure exhibits two notable features. First, the single cycle routers realize a one cycle zero-load latency beneﬁt over the the 2-cycle HP router. This single cycle beneﬁt is obtained from the second crossbar traversal required to reach an immediate neighbor. Second, SCARAB scales similarly to the HP router until it quite suddenly saturates around 40%. This occurs because the average service time of a request causes the MSHRs at local nodes to be exhausted. As the HP router releases MSHRs upon injection, it does not experience this sudden saturation on the synthetic traﬃc trace. From this synthetic testing, it can be seen that all three buﬀerless routers could see use cases for certain applications and network sizes. Overall, SCARAB obtains lower packet latencies and saturates later than the tested version of the BPS router. BPS with multiple links per direction could improve its situation, but would not displace the SCARAB router since the same techniques could be applied to it. HP typically has higher latencies, but oﬀers higher saturation points making it competitive with the SCARAB router for very high injection rates. 5.2 Application Driven Evaluation To obtain a better view of how the diﬀerent router models aﬀect real-world application performance, this section Figure 9: Average packet drop rate on SPLASH-2 and Commercial benchmark traces on a 4x4 node network for the BPS and SCARAB routers. utilizes traces from simulated applications. The on-chip network traﬃc traces are collected from a full system simulator [3] for end-to-end runs of 8 workloads including 4 commercial workloads [24, 27] and 4 scientiﬁc workloads [30]. Workload details are presented in Table 3. These workloads are for a 4x4 CMP with a directory protocol modeled after the SGI Origin [13]. We simulate 32KB L1 I/D caches and private 256KB L2 caches. Addresses are distributed across 16 directories with one directory located at each processor tile. These traces contain a mix of packet sizes, coherence messages create single-ﬂit packets, while cache line transfers (64 bytes) create 5-ﬂit packets. Figure 10 shows the average packet latency of all routers across the collected application traces. From this graph, we infer that network utilization is quite low since the BPS router module delivers on-average better performance than the HP router. This low network utilization was veriﬁed and of the selected applications, Ocean had the highest injection rate of around 5%. The SCARAB routers deliver the best performance across all applications. The diﬀerence between the opportunistic buﬀering and non-buﬀering SCARAB router is very slight and this can partially be attributed to the small 4x4 network size used in these traces. On average, the opportunistic buﬀering SCARAB router is 12.2% faster than the BPS router and and 17.6% faster than the HP router on real-world applications. Since both packet dropping routers, BPS and SCARAB, perform the best on the application traces, their respec252 Figure 10: Average packet latency for SPLASH-2 and Industry benchmark traces on a 4x4 node network. tive drop rates correspond to how much power each router wasted. Figure 9 shows the percentage of packet retransmissions necessary to successfully complete the application traces. On average the SCARAB router has to perform retransmission for 4.88% of all packets. The BPS router scales more poorly, due to the fact it has to send NACKs along the same data network, and has to retransmit 18.15% of all packets. The presence of data-network NACKs in the BPS network degrades performance in times of congestion and bursty traﬃc, since the NACKs add congestion to the network. 6. RELATED WORK Bufferless routers. Circuit switching is another buﬀerless routing technique which has been evaluated in the context of on-chip networks. Enright Jerger et al. [5] evaluate traditional circuit switching and compare it to a hybrid combination of circuit switching and packet switching. Banerjee et al. [1] evaluate the area and power of an on-chip circuit-switched network in comparison to a wormhole router and the router from [17]. Circuit switching impacts low-load latency by requiring a circuit setup phase; SCARAB has the advantage of providing low latency at low and moderate loads by not requiring a distinct setup phase. Bouhraoua and Elrabaa [2] propose a buﬀerless on-chip network based upon a fat tree topology that targets throughput, rather than latency, as its primary ob jective. The Nostrum network on-chip [14] also proposes a deﬂection-based, buﬀerless router structurally similar to the HP router, but augmented it with a protocol to provide two classes of network transactions: guaranteed bandwidth and best-eﬀort. Buffer reduction. Many works have focused upon reducing, but not eliminating, the buﬀering requirements of on chip networks. Kodi et al. [10] advocate multipurposing repeater logic on internode links as storage elements in order to reduce the inrouter buﬀering requirement. Dynamically Allocated MultiQueue (DAMQ) [25] buﬀering reduces the total buﬀer requirement per router port by sharing buﬀer space across multiple virtual channels. ViChaR [18] works to improve buﬀering eﬃciency by dynamically adjusting the depth and number of virtual channels in response to network traﬃc. Also, application speciﬁc buﬀering approaches have been proposed in order to optimize their allocation [8]. Power optimized. Optimizing on-chip network parameters to lessen total power consumption has been widely studied in recent years [1, 21, 29]. Additionally, many microarchitectural techniques have been proposed to reduce dynamic power. Kumar et al. [12] avoids dynamic buﬀer activity in scenarios where buﬀer reads and writes can be avoided. Wang et al. [28] detail multiple microarchitectural techniques impacting crossbar design and write buﬀers. Buﬀerless networks such as SCARAB reduce both the dynamic power consumed by buﬀers as well as the leakage power. 7. CONCLUSION We propose SCARAB, a single-cycle buﬀerless router that relies on adaptive routing, a novel circuit-switched NACK network, priority-based arbitration, and opportunistic processor-side buﬀering to provide the lowest possible latency and reasonable saturation bandwidth relative to two previously-proposed buﬀerless networks: BPS [6] and HP [15,16,26]. Detailed design and evaluation shows that SCARAB is amenable to very high frequency implementation, provides the lowest end-to-end latency under low and moderate loads, and scales to higher utilization than the BPS router [6], due to its novel circuit-switched NACK network. In contrast, the HP router requires a complex arbiter that is likely to pose a cycle-time bottleneck and suﬀers from worse latency at low and moderate utilization, but does scale to higher saturation throughput. In summary, SCARAB appears most attractive for memory latency-bound commercial workloads which are an important target for future many-core architectures. In future work, we plan to explore a broader set of policies for opportunistic buﬀering in larger networks and diﬀerent topologies. Furthermore, we will evaluate these networks in a full-system, execution-driven simulator, and will investigate the impact of buﬀerless networks on coherence protocol implementation, processor core and buﬀer design, and memory consistency models. 253 page 20890, Washington, DC, USA, 2004. IEEE Computer Society. [15] T. Moscibroda and O. Mutlu. A case for buﬀerless routing in on-chip networks. Technical report, Microsoft Research, 2008. [16] T. Moscibroda and O. Mutlu. A case for buﬀerless routing in on-chip networks. In ISCA-36, Washington, DC, USA, 2009. IEEE Computer Society. [17] R. Mullins, A. West, and S. Moore. Low-latency virtual-channel routers for on-chip networks. In ISCA-31, page 188, Washington, DC, USA, 2004. IEEE Computer Society. [18] C. Nicopoulos, D. Park, J. Kim, V. Narayanan, M. S. Yousif, and C. Das. ViChaR: A dynamic virtual channel regulator for network-on-chip routers. In MICRO-39, pages 333–344, December 2006. [19] E. Nilsson. Design and Implementation of a hot-potato Switch in a Network on Chip. Master’s thesis, Royal Institute of Technology, IMIT/LECS 2002-11, Sweden, June 2002. [20] E. Nilsson and J. ¨Oberg. Reducing power and latency in 2-D mesh NoCs using globally pseudochronous locally synchronous clocking. In CODES+ISSS-2, pages 176–181, New York, NY, USA, 2004. ACM. [21] C. Patel, S. Chai, S. Yalamanchili, and D. Schimmel. Power constrained design of multiprocessor interconnection networks. In ICCD-16, pages 408–416, Oct 1997. [22] L.-S. Peh and W. J. Dally. A delay model and speculative architecture for pipelined routers. In HPCA-7, page 255, Washington, DC, USA, 2001. IEEE Computer Society. [23] B. J. Smith. Architecture and applications of the hep mulitprocessor computer system. In Readings in computer architecture, pages 342–349. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2000. [24] SPEC. SPEC benchmarks. http://www.spec.org. [25] Y. Tamir and G. Frazier. High-performance multiqueue buﬀers for VLSI communication switches. In ISCA-15, pages 343–354, May-2 Jun 1988. [26] S. Tota, M. R. Casu, and L. Macchiarulo. Implementation analysis of NoC: a MPSoC trace-driven approach. In GLSVLSI-16, pages 204–209, New York, NY, USA, 2006. ACM. [27] TPC. TPC benchmarks. http://www.tpc.org. [28] H. Wang, L.-S. Peh, and S. Malik. Power-driven design of router microarchitectures in on-chip networks. In MICRO-36, page 105, Washington, DC, USA, 2003. IEEE Computer Society. [29] H.-S. Wang, X. Zhu, L.-S. Peh, and S. Malik. Orion: a power-performance simulator for interconnection networks. In MICRO-35, pages 294–305, 2002. [30] S. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. The SPLASH-2 programs: Characterization and methodological considerations. In ISCA-22, June 1995. 8. ACKNOWLEDGEMENTS This research was supported in part by the National Science Foundation under grant CCF-0702272, an NSERC Discovery Grant, as well as grants and equipment donations from Hewlett-Packard, IBM, and Intel. 9. "
2009,Low-cost router microarchitecture for on-chip networks.,"On-chip networks are critical to the scaling of future multicore processors. The challenge for on-chip network is to reduce the cost including power consumption and area while providing high performance such as low latency and high bandwidth. Although much research in on-chip network have focused on improving the performance of on-chip networks, they have often relied on a router microarchitecture adopted from off-chip networks. As a result, the on-chip network architecture will not scale properly because of design complexity. In this paper, we propose a low-cost, on-chip network router microarchitecture which is different from the commonly assumed baseline router microarchitecture. We reduce the cost of on-chip networks by partitioning the crossbar, prioritizing packets in flight to simplify arbitration, and reducing the amount of buffers. We show that by introducing intermediate buffers to decouple the routing in the x and the y dimensions, high performance can be achieved with the proposed, low-cost router microarchitecture. By removing the complexity of a baseline router microarchitecture, the low-cost router microarchitecture can also approach the ideal latency in on-chip networks. However, the prioritized switch arbitration simplifies the router but creates starvation for some nodes. We show how delaying the rate credits are returned upstream can be used to implement a distributed, starvation avoidance mechanism to provide fairness. Our evaluations show that the proposed low-cost router can reduce the area by 37% and the power consumption by 45% compared with a baseline router microarchitecture that achieves a similar throughput.","Low-Cost Router Microarchitecture for On-Chip Networks John Kim KAIST Depar tment of Computer Science Daejeon, Korea jjk12@cs.kaist.ac.kr ABSTRACT Keywords On-chip networks are critical to the scaling of future multicore processors. The challenge for on-chip network is to reduce the cost including power consumption and area while providing high performance such as low latency and high bandwidth. Although much research in on-chip network have focused on improving the performance of on-chip networks, they have often relied on a router microarchitecture adopted from oﬀ-chip networks. As a result, the on-chip network architecture will not scale properly because of design complexity. In this paper, we propose a low-cost,on-chip network router microarchitecture which is diﬀerent from the commonly assumed baseline router microarchitecture. We reduce the cost of on-chip networks by partitioning the crossbar, prioritizing packets in ﬂight to simplify arbitration, and reducing the amount of buﬀers. We show that by introducing intermediate buﬀers to decouple the routing in the x and the y dimensions, high performance can be achieved with the proposed, low-cost router microarchitecture. By removing the complexity of a baseline router microarchitecture, the low-cost router microarchitecture can also approach the ideal latency in on-chip networks. However, the prioritized switch arbitration simpliﬁes the router but creates starvation for some nodes. We show how delaying the rate credits are returned upstream can be used to implement a distributed, starvation avoidance mechanism to provide fairness. Our evaluations show that the proposed low-cost router can reduce the area by 37% and the power consumption by 45% compared with a baseline router microarchitecture that achieves a similar throughput. Categories and Subject Descriptors C.1.2 [Computer Systems Organization]: Multiprocessors—Interconnection architectures General Terms Design, Performance Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. MICRO’09, December 12–16, 2009, New York, NY, USA. Copyright 2009 ACM 978-1-60558-798-1/09/12 ...$10.00. on-chip network, router microarchitecture, complexity 1. INTRODUCTION With the increasing number of transistors in modern VLSI technology, the number of cores on a single chip continues to increase in order to eﬃciently utilize the transistors. As a result, an eﬃcient on-chip network is required in these manycore architectures to connect the cores together. It is pro jected that the on-chip network will be the critical bottleneck of future manycore processors – both in terms of performance and power [35]. Recently, on-chip network or network-on-chip (NoC) research has focused on the various aspects of on-chip networks, including topology [2, 17, 12, 8], routing [39], ﬂow control [24], and router microarchitecture [1, 33, 22, 27]. These research eﬀorts have focused on providing high performance and achieving power-eﬃcient architectures. However, none of them have addressed the complexity 1 issue in designing an on-chip network. As on-chip network size increases, the design complexity can become the bottleneck that prevents the proper scaling of on-chip networks. This paper addresses the complexity issue in on-chip network by proposing a low-cost router microarchitecture that reduces router complexity and also provides high performance. Oﬀ-chip networks provide very diﬀerent constraints compared with on-chip networks, but many of oﬀ-chip network architectures have been adopted for the on-chip network. As a result, the use of the conventional oﬀ-chip network router microarchitecture results in a complex router design for on-chip networks. This increases not only the cost (area and power) of the network but also the pipeline cycle-time and design complexity. Many microarchitectural techniques have therefore been proposed to reduce on-chip network latency, but they have used the conventional oﬀ-chip router microarchitecture as the baseline, thereby involving additional complexity and cost. Because of the complexity of proposed packet-switched, NoC architectures, simpler approach to on-chip networks have been proposed such as the use of ring topologies [14, 9]. The ring topology has been used in the IBM Cell processor [36] and has been suggested for future Intel processors [15], including the Intel Larrabee processor [38]. Because of the simplicity of the ring topology, it does not have 1Complexity is deﬁned as design complexity. An increase in complexity results in an increase in area and veriﬁcaton complexity, and this can also lead to increase in power [3]. 255 the complexity of other architectures. However, as the network size increases, the ring topology becomes limited in its scalability. In this work, we propose to develop a router microarchitecture that approaches the simplicity of a ring topology while providing high performance. By reducing the complexity of the three main components of a router microarchitecture – input buﬀers, crossbar, and the arbitration – we present an alternative on-chip network design that attempts to simplify on-chip networks. Instead of assuming a baseline, input-queued router microarchitecture with a single crossbar switch, we propose using a dimension-sliced crossbar to partition the crossbar into an x crossbar and a y crossbar. The arbitration is simpliﬁed by providing priority to packets that are in ﬂight and that continue to travel in the same dimension in order to enable a single-cycle router. Additional router pipeline latency is src src src (a) (b) (c) dest dest dest Figure 2: (a) Ideal on-chip network with only wire delay, (b) wire delay pipelined with registers, and (c) muxes inserted to share the wire resources with other nodes. and cost, we propose to simplify the router microarchitecture and minimize the amount of buﬀers needed to create a lost-cost router microarchitecture. 2.2 Switch The area of a crossbar switch is often the dominant area component of an on-chip router as the area is proportional to O(p2w2 ), where p is the number of router ports and w is the datapath width. As compared to the datapath width (w), the number of ports (p) for on-chip routers is relatively small – e.g., p = 5 for a 2D mesh network and p = 10 for high-radix on-chip network routers [17] while w = 128 to w = 256 because of the abundant on-chip bandwidth. The wire dominated crossbar area can occupy up to 64% of the total router area [22]. As a result, to minimize the area impact of on-chip routers, the crossbar area must be minimized. We propose the use of dimension-sliced routers in on-chip networks to reduce crossbar switch area with minimal performance loss. 2.3 Arbitration The power consumption or the area from the arbitration logic has been shown to be very minimal [41]. However, poor arbitration can limit the throughput of the router and reduce the overall performance of on-chip networks. The latency of the arbitration logic also often determines the router cycle time. Separable allocators have been proposed for on-chip networks which separates the allocation into two stages – input and output arbitration. These allocators require an eﬃcient matching algorithm and novel switch allocation has been proposed to increase the matching eﬃciency for on-chip networks [22]. However, arbitration is still often in the critical path. Arbitration is needed since resources (such as channel bandwidth) are shared, but if they are reserved ahead of time, arbitration complexity can be reduced or removed completely. In this work, we present simplifying arbitration by giving priority to those packets already in the network that continue to travel in the same dimension – thus removing the switch arbitration from the critical path. 2.4 Motivation Using baseline router microarchitecture (Figure 1), a router bypass path can be created to reduce the per-hop router latency as packets that bypass the router can avoid the internal router pipeline. However, this requires additional complexity and cost on top of the baseline router microarchitecCost Design Metric category Metric Performance Latency Bandwidth Area Power Extensibility Partitionability Regularity Validation/Testing Fault Tolerance Scalable Architecture Table 1: Diﬀerent evaluation metric of on-chip networks with some proposed by Azimi et al. [28]. ture. Recently proposed architectures such as the concentrated mesh (CMESH) [2], ﬂattened butterﬂy (FBFLY) [17], and the express virtual channel (EVC) [24] bypass intermediate routers in order to provide good performance and attempt to achieve an ideal latency – i.e. the wire delay from the source to its destination. However, these architectures also add complexity to the design of the on-chip network. For example, EVC requires diﬀerent router designs for bypass nodes and source/sink nodes, and additional virtual channels are needed to support EVC. The CMESH and FBFLY topologies require non-uniform router designs and high-radix routers which can increase the design complexity. In addition to common evaluation metrics such as performance and cost, other metrics needs to be considered in the evaluation of on-chip network router microarchitecture as shown in Table 1. For example, the ﬂattened butterﬂy topology is a scalable topology, but it is not extensible since new router designs are required as the network size increases. In this work, we present a router microarchitecture that provides good performance on design metrics. An ideal on-chip network between two nodes is shown in Figure 2(a), which corresponds to the wire delay between two nodes. To improve the throughput and reduce the clock cycle, pipeline registers can be inserted (Figure 2(b)). However, key aspect of on-chip network is sharing on-chip bandwidth resource among multiple nodes and multiplexers can be inserted share the on-chip bandwidth (Figure 2(c)). In this work, instead of adopting Figure 1 as our baseline, we use the Figure 2(c) view of on-chip network as a starting point in the design of an on-chip network to reduce the cost and complexity. The proposed low-cost router microarchitecture builds on a 2D mesh topology to exploit its design regularity while attempting to provide high performance. 3. LOW-COST ROUTER MICROARCHITECTURE In this section, we describe the microarchitecture of our proposed, low-cost router microarchitecture for the 2D mesh network. We simplify the router microarchitecture by using prioritized switch allocation, partitioning the crossbar, and reducing the amount of buﬀers needed in the router. 3.1 Bufferless Router for Ring Topology The buﬀerless router microarchitecture has been proposed for ring topology, such as the router used in the Intel Larrabee ring network [38]. A block diagram of an 8-node ring topol257 R7 R6 R5 R4 N7 N6 N5 N4 R0 R1 R2 R3 N0 N1 N2 N3 IN0 IN1 OUT1 OUT0 injec tion por t ejec tion por t Figure 3: An 8-node ring topology with buﬀerless router microarchitecture. X Router (Rx) Y Router (Ry) Local In East Out East In West In West Out South Out South In North In North Out Local Out Figure 4: High-level block diagram of a dimensionsliced router in a 2D mesh network. ogy with a buﬀerless router is shown in Figure 3 with only pipeline registers. Once a packet is injected into the ring network, the packet is guaranteed to make progress towards its destination by prioritizing those packets that are in ﬂight [9]– thus, there are no contentions for network resources and input buﬀers are not needed. In this work, we use this buﬀerless router 2 microarchitecture, which is similar to the ﬁgure shown in Figure 2(c), as the starting point and extend this microarchitecture to a 2D mesh topology. 3.2 Switch The proposed router microarchitecture block diagram for the 2D mesh is shown in Figure 4. Instead of a 5-port router used in a conventional 2D mesh topology, the router is partitioned or sliced into two separate routers – one for each dimension of the network – to create a dimension-sliced router. The dimension-sliced router was used for the Cray T3D router [16] as the router was partitioned into three separate router chips – one for each dimension of the 3D torus networks. Technology constraints prevented the router from ﬁtting on a single chip, and it was necessary to partition the router across multiple chips. However, we leverage the same microarchitectural technique to reduce the cost of on-chip networks and simplify the router microarchitecture. The number of router ports is reduced from a single router with 5 ports to two routers with 3 ports. A dimension-sliced router partitions the crossbar switch into two smaller crossbar switches : the x router (Rx) and the y router (Ry ). Rx (Ry ) is used to route packets that continue to traverse in the x (y ) dimension, respectively. Since we assume dimension-ordered (X-Y) routing, a packet that needs to traverse both dimensions to reach its destination will need to change dimension once (i.e., switch routers 2A buﬀerless router [30] has been proposed for the 2D mesh NoC but requires deﬂection routing to remove the need for buﬀers in on-chip networks – which can increase the latency and reduce the eﬀective bandwidth. . . . . . . h u o S t O u t h u o S t I n N o t r h I n N o t r h O u t East Out East In Local In Local Out Rx Ry intermediate  buffer West In West Out . . . h u o S t O u t h u o S t I n N o t r h I n N o t r h O u t East Out East In Local In Local Out Rx Ry intermediate  buffer West In West Out (a) (b) Figure 5: Detailed logic diagram of the proposed router microarchitecture using (a) a shared, intermediate buﬀer and (b) a dedicated, separate intermediate buﬀer. R00 BW / RC SA/ VA ST LT BW/ RC SA/ VA ST LT BW / RC SA/ VA ST LT R01 R11 1 2 3 4 5 6 7 8 9 10 11 12 Cycle (a) R00 R01 R11 STx / LT STx/ BW ST y/ LT STy 1 2 3 4 Cycle (b) Figure 6: Pipeline diagram of a single-ﬂit packet in the (a) baseline, conventional router and the (b) proposed low-cost router in a 2D mesh network, routing from R00 to R11 in the network shown in Figure 7. STx is the switch traversal of Rx , and STy is the switch traversal Ry . from Rx to Ry once). However, even if the source and the destination share the same row or same column, the packet will still need to be routed from Rx to Ry because the local injection port is only connected to Rx , while the local ejection port is connected to Ry (Figure 5(a)). By using the dimension-sliced router, it enables creating overpass channels in on-chip network – similar to overpass in highways and roads, the dimension-sliced router does not require packets that travel in diﬀerent dimensions to stop at the current router. 3.3 Buffers With a single-cycle router, only two buﬀer entries are needed to cover the credit round-trip latency. The buﬀer management provides backpressure and avoids the need to drop packets or misroute them as in a buﬀerless router [30]. However, intermediate buﬀers are placed between Rx and Ry to decouple the ﬂow control and routing of Rx from Ry . If a packet traversing the x dimension switches to the y dimension, the packet is buﬀered in this intermediate buﬀer before traversing in the y dimension. Thus, a packet will encounter an additional cycle when switching from Rx to Ry . 258                 20 21 22 20 21 22 20 21 22 20 21 22 20 21 22 10 11 12 10 11 12 10 11 12 10 11 12 10 11 12 00 01 02 00 (a) 01 (b) 02 00 01 (c) 02 00 02 00 01 (d) 02 01 (e) Figure 7: Example ﬂow control in the low-cost, router microarchitecture when there is no contention (a,b) and when packets contend for the same resource (c,d,e) on a 3×3 mesh network. Diﬀerent color represents diﬀerent packet in the network Two diﬀerent organizations of intermediate buﬀer is shown in Figure 5. For the shared intermediate buﬀer organization (Figure 5(a)), switch arbitration (discussed in Section 3.4) is needed prior to being buﬀered in the intermediate buﬀer. Another organization requires having dedicated buﬀers for each router port at the intermediate buﬀer, as shown in Figure 5(b). For both organizations, the intermediate buﬀer buﬀers the packets and allows other packets in the x dimension to continue traversing the network. As the intermediate buﬀers are located locally, no complex buﬀer management ﬂow control is needed. The east/west input units need to share a credit for the shared buﬀer organization (Figure 5(a)), or separate credits are needed with a dedicated ﬂow buﬀer organization. If the intermediate buﬀer is full, the input buﬀers will hold the packets until a intermediate buﬀer slot becomes available. Simulations comparing the performance of the two diﬀerent organization of the intermediate buﬀers achieve similar performance if the total amount of storage is held constant – thus, we assume Figure 5(a) organization in the rest of the paper. 3.4 Arbitration To reduce the complexity of switch arbitration, simple priority arbitration is used where packets in ﬂight that continue to travel in the same direction have priority over other packets. For example, if a packet arriving from the West port in Rx needs to be routed through the East port, it is given priority over packets injected from the local port that needs to be routed through the East port. Similarily, a packet arriving from the North port in Ry that needs to be routed to the South port will have priority over packets being injected from the intermediate buﬀer. Thus, a packet continuing to travel in one dimension will encounter delay very similar to that in Figure 2(c) shown earlier, with additional delay e m i t trt e m i t R00 R01 R02 R03 R04 R05 R06 R07 r o l c o n t flit 0 flit 1 flit n c r c r c r flit R00 R01 R02 (a) R03 R04 R05 R06 R07 flit 0 flit 1 flit 2 (b)  0 c r flit flit 2 t0 t1 t2 t0 t2 Figure 9: Time diagram of using (a) explicit control signals to avoid starvation and (b) stalling credits to provide local starvation avoidance scheme for the traﬃc illustrated in Figure 8(b). arbitration is needed to access the shared intermediate buﬀer before traversing in the new dimension. The winner accesses the intermediate buﬀers, while the packet that does not have its access granted remains buﬀered in the input buﬀer. The contention of resource shown in Figure 7(c,d) is similar to that observed in a conventional microarchitecture; the only diﬀerence is how the contention is resolved. However, Figure 7(e) is a contention that is unique to our proposed architecture with a shared intermediate buﬀer. Two packets arrive at a router from the same dimension and want to turn to a diﬀerent direction of the new dimension. Because of the limited connections in a dimension-sliced crossbar, the intermediate buﬀer becomes a shared resource and creates a bottleneck. Thus, in the worst-case scenario, the throughput of the network can be degraded by 1/2 compared with a network using a conventional on-chip network router. 3.6 Fairness/Starvation By simplifying the arbitration in the proposed lightweight router microarchitecture, fairness can become an issue. Fairness is not an issue For uniform random traﬃc near zeroload, but as the load increases and approaches saturation, fairness will become a problem as the packets being injected from the edge of the network will always have priority. Nonuniform traﬃc patterns will also cause starvation. For example, with the traﬃc pattern shown in Figure 8(a), R01 can be starved indeﬁnitely if R00 continues to inject packets into the network. Similarly, R05 can be starved in Figure 8(b), as well as R01, R02, and R03 in Figure 8(c). To overcome this limitation, we can send an explicit control signal upstream to prevent starvation. For example, R01 in Figure 8(a) can wait n cycles and if it is still starved, it can send a control signal to R00 to halt its transmission of packets. Once R00 stops transmission and R01 does not see any more packets, it can inject its packet. A similar scheme has been proposed in the EVC ﬂow control [24] for starvation avoidance as express VCs can starve normal VCs. Thus, tokens were proposed in the EVC to prevent starvation. However, using control signals can be very complex and add latency and complexity. For the traﬃc pattern shown in Figure 8(a), control signals can be sent relatively quickly because the injecting node is only 1 hop away. However, in Figure 8(b), sending an explicit control signal or token can be very time consuming, as illustrated in a time diagram in Figure 9(a). If R05 decides to send an explicit control signal at t0 , in the worst-case scenario (when R00 continues to inject packets), R05 would not be able to inject packets into the network until t1 ; thus, the (t1 − t0 ) corresponds to the round-trip delay from R05 to R00. For traﬃc patterns such as the one shown in Figure 8(c) where R01, R02, and R03 are all starved from R00 traﬃc, each node sending a control signal (or tokens) will complicate the starvation avoidance scheme. To prevent starvation, we propose a simpliﬁed distributed approach where starvation is prevented by manipulating local router credits. A credit is decremented when a ﬂit is sent downstream. Once the ﬂit departs from the downstream node, a credit is sent back upstream and the appropriate credit count is incremented. However, by stalling the return of credits, an artiﬁcial backpressure can be created and prevent upstream nodes from injecting packets into the network, allowing the current node to inject packets into the network. In this scheme, each router maintains a starvation count n, and once it reaches the maximum value (nmax ), the router stops the transmission of credits upstream. By delaying the credit upstream, the backpressure ensures that upstream nodes do not inject any more packets into the network. Once the source router injects its packet, n is reset to 0. Each router needs to maintain four separate values of n: nE and nW for the east and the west port of Rx , respectively and nN and nS for the north and the south port of Ry , respectively. In each cycle, if the injection port of the router has a packet that it is trying to inject into the network, the appropriate n value is incremented each cycle if the packet is unable to inject the packet into the network. When n reaches nmax , it means that the nmax continuous stream of ﬂits has ﬂowed through the current router node in one particular direction while the router waited and thus, credits are not immediately returned. Figure 9(b) shows the time diagram of the starvation avoidance scheme. Assume R00 continues to inject packets into the network destined for R07 (Figure 8(b)), and for simplicity, assume that nmax = 1. Initially, nE = 0 at R05 and at t0 , R05 wants to inject a packet to R06. In t0 , ﬂit 0 also arrives from R04. Due to the prioritized allocation, ﬂit 0 is granted access to the output port and transmitted to R06 in the next cycle while nE is incremented to 1. Since there is a packet waiting at R05 to be injected into the network and nE = nmax , instead of immediately sending a credit back upstream at t0 , the credit return is stopped. As another packet can be in ﬂight, R05 will need to wait another cycle for ﬂit 1 to pass through. At this point, R04 does not have any credits and is thus required to stop sending packets to R05 – allowing R05 to inject ﬂits into the network at t2 and 260 0 20 40 60 80 100 0 0.1 0.2 0.3 Offered load 0.4 0.5 a L t n e y c ( e c y c l ) s b=2 b=4 b=8 b=16 b=32 b=64 0 20 40 60 80 100 0 0.1 0.2 0.3 Offered load 0.4 0.5 a L t n e y c ( e c y c l ) s b=2 b=4 b=8 b=16 b=32 b=64 (a) (b) 0 20 40 60 80 100 0 0.1 0.2 0.3 Offered load 0.4 0.5 a L t n e y c ( e c y c l ) s bi=2 bi=4 bi=8 bi=16 bi=32 bi=64 0 20 40 60 80 100 0 0.1 0.2 0.3 Offered load 0.4 0.5 a L t n e y c ( e c y c l ) s bi=2 bi=4 bi=8 bi=16 bi=32 bi=64 (c) (d) Figure 10: Latency vs. load comparison of (a,b) the conventional router microarchitecture and (c,d) the low-cost router for (a,c) UR and (b,d) TOR traﬃc as the amount of buﬀer is varied. 0 20 40 60 80 100 0 0.1 0.2 0.3 0.4 a L t n e y c ( c y c l e ) s Offered load baseline(b=4) baseline (b=8) LC( bi=4) 0 20 40 60 80 100 0 0.1 0.2 0.3 0.4 a L t n e y c ( e c y c l ) s Offered load baseline(b=4) baseline (b=8) LC( bi=4) (a) (b) Figure 11: Performance comparison of the baseline and LC router for (a) UR and (b) TOR traﬃc. also start returning credits back upstream. As long packets in the network require multiple ﬂits, we prevent the stalling of the credits until the tail ﬂit is received at the current node. This ensures that packets will not be interleaved at the ﬂit granularity and allows the body and tail ﬂits to follow the head ﬂit to its destination. 4. EVALUATION In this section, we evaluate the proposed, low-cost router microarchitecture against the conventional input-queued microarchitecture using a 64 node, 8×8 2D mesh network. We evaluate the proposed architecture using a cycle-accurate interconnection network simulator [7]. To evaluate the latencythroughput, the simulator is warmed up under load without taking measurements until steady-state is reached. Then, a sample of injected packets is labeled during a measurement interval. The simulation is run until all labeled packets exit the system. Synthetic traﬃc pattern results from uniform random and tornado traﬃc are presented. Simulations show that other permutation traﬃc such as bit complement and transpose follow a trend very similar to tornado traﬃc and are not included due to page constraint. In addition to comparing latency/throughput curves, synthetic workloads using closed-loop simulations are used for comparison as well. Synthetic workloads are used to model the memory coherence traﬃc of a shared memory with each node or processor generating 1K remote memory operations requests [2]. Once requests are received, responses are generated from the destination, and the total completion time for entire network is measured. We allow r outstanding requests per router node to mimic the eﬀect of MSHRs – thus, when r outstanding requests are injected into the network, new requests are blocked from entering the network until the response packets are received. We use r = 4 in the results presented in this paper. We also use network traces from a shared memory multiprocessor. Network traces have also been collected from a 64-processor directory-based Transactional Coherence and Consistency multiprocessor simulator [4] using SPLASH2 benchmarks [42] (methodology is described in [17]). The power and area model is based on the 65nm technology used in [2], and the conventional router has a 3 cycle router pipeline [22, 23]. We assume a datapath width of 128 bits. For short packets, we assume 1-ﬂit packets while for long packets such as cache line, we assume 4-ﬂit packets. For the latency-throughput analysis, we assume a bimodal distribution of packets with 50% of the packets being short, 1-ﬂit packets and the rest being long, 4-ﬂit packets. 4.1 Performance Comparison 4.1.1 Latency/Throughput Comparison The latency-throughput of the conventional, baseline router and the proposed low-cost (LC) router is shown in Figure 10 varying amounts of buﬀers for uniform random (UR) and tornado traﬃc (TOR) traﬃc patterns. For the baseline microarchitecture, we vary the number of entries in the input buﬀer (b), and for the LC router we keep only 2 buﬀer entries per router input port (b = 2) and vary the number of entries in the intermediate buﬀer (bi ). In general, deeper buﬀers improve network throughput by decoupling the behavior of neighboring routers. For the baseline router, with b = 2 or b = 4, there is a severe throughput degradation because of the insuﬃcient buﬀer entries to cover the credit round-trip latency 3 , resulting in up to 75% loss in throughput. However, beyond b = 16, there is little increase in throughput as the amount of buﬀer is increased further. For the LC router, continuing to increase the amount of intermediate buﬀers (bi ) results in a slight increase in throughput for both UR and TOR traﬃc. The increase in bi helps decouple the allocation of Rx and Ry . Thus larger amount of bi improves the overall network throuhgput. However, beyond bi = 64, there is minimal increase in throughput. In Figure 11, we compare the performance of the baseline with the LC router and show that the LC router reduces zero-load latency by up to 67% while providing an increase in throughput by up to 15%, compared with the baseline with b = 4. For the TOR traﬃc (Figure 11(b)), the LC router with bi = 4 is able to nearly match the throughput of the baseline router (b = 8), which has approximately 2.6× 3Based on Figure 6(a), the credit round-trip latency is 6 cycles. 261             0 10 20 30 40 50 0 0.1 0.2 Offered load 0.3 0.4 a L t n e y c ( e c y c l ) s baseline LC 0 10 20 30 40 50 0 0.1 0.2 Offered load 0.3 0.4 a L t n e y c ( e c y c l ) s baseline LC (a) (b) Figure 12: Impact of arbitration for (a) UR and (b) TOR traﬃc as the amount of buﬀers are varied. 0 20 40 60 80 100 0 0.1 0.2 0.3 a L t n e y c ( c y c l e s ) Offered load bi=4 bi=8 bi=16 bi=32 conventional (b=8) Figure 13: Adversarial traﬃc patttern evaluation. additional amount of storage. With a simpliﬁed pipeline and arbitration, the proposed architecture is able to achieve similar throughput and illustrate how simplifying router microarchitecture and pipeline improves the eﬃciency of the on-chip network. 4.1.2 Impact of Prioritized Arbitration In order to evaluate the impact of prioritized arbitration, we compare the performance of the baseline and LC router while holding the total amount of buﬀer constant and assuming the router delays to be constant as well. Thus, we assume b = 3 in the baseline and b = 2, bi = 4 in the LC router, and assume the baseline is also a single-cycle router including the link-traversal. The results are compared in Figure 12. The LC router has a slightly higher zero-load latency as we still assume the additional cycle delay to switch dimensions. The throughput of the two routers are very similar. On UR traﬃc, the baseline exceeds the LC router by approximately 9%, while on TOR traﬃc, the LC exceeds the baseline by approximately 11%. As a result, even with a simpliﬁed, prioritized arbitration, high throughput can be achieved with the LC router compared with the baseline router, which requires all packets to go through a centralized arbitration at each router. 4.1.3 Adversarial Trafﬁc Pattern As described earlier in Section 3.5, because of the limited bandwidth between Rx and Ry , the throughput of the LC router can be degraded. For the evaluated synthetic traﬃc patterns such as UR and TOR, this was not the case as we observed minimal loss in throughput. However, we also simulated an adversarial traﬃc pattern for the LC router and 0 5 10 15 20 25 30 0 0.1 0.2 Offered load 0.3 a L t n e y c ( e c y c l ) s 2 4 8 16 32 inf 18 16 14 12 10 8 6 4 2 0 4 8 16 32 inf a L t n e y c ( e c y c l ) s n_max value (a) (b) Figure 14: Performance impact of varying nmax on TOR traﬃc – (a) latency/throughput curve and (b) latency comparison near saturation. 01234567 y 140 120 100 80 60 40 20 0 0 1 2 3 4 5 6 7 a L t n e y c ( e c y c l ) s x 0 1234567 y 120 100 80 60 40 20 0 140 0 1 2 3 4 5 6 7 a L t n e y c ( e c y c l ) s x (a) (b) Figure 15: Latency distribution near saturation with (a) nmax = ∞ and (b) nmax = 4. its results are shown in Figure 13. The traﬃc pattern attempts to create packet contentions similar to the example shown in Figure 7(e). For example, with the router nodes represented as R(x, y ) in a 2D mesh, R(x1 , 0) sends its traﬃc to R(x2 , 1) where x1 ≥ x2 , and R(x3 , 2) sends its traﬃc to R(x4 , 1) where x3 ≤ x4 . As bi increases, unlike other trafﬁc patterns, the throughput does not increase accordingly with the limited bandwidth between Rx and Ry . Compared with the baseline architecture, the throughput degrades by approximately 30% for this particular traﬃc pattern. Thus, the simplicity of the switch architecture can result in performance degradation. However, for the other workloads evaluated, we saw this limitation to have a small impact on the overall performance. 4.1.4 Fairness and Impact of nmax With the simpliﬁed, prioritized arbitration in the LC router, some nodes can be continuously starved without any fairness support. To evaluate the impact of the proposed fairness mechanism described in Section 3.6, diﬀerent values of nmax are compared in Figure 14 for TOR traﬃc. For nmax > 2, the throughput of the network as nmax is increased is nearly identical to nmax = ∞, which corresponds to the LC router without any support for fairness. However, if we look into the details of the average latency near saturation (Figure 14(b)), having no support for fairness can result in an increase in average latency by approximately 17% because of the unfairness. The latency distribution of packets near the saturation throughput is shown in Figure 15. We plot the average latency of packets injected from the diﬀerent nodes in an 8x8 mesh. With nmax = ∞, the nodes in 262               0 0.2 0.4 0.6 0.8 1 b = 2 b = 4 b = 8 b = 16 N o r m a i l d e z r n u i t m e 0 0.2 0.4 0.6 0.8 1 b = 2 b = 4 b = 8 b = 16 N o r m a i l d e z r n u i t m e 0 0.2 0.4 0.6 0.8 1 b = 2 b = 4 b = 8 b = 16 N o r m a i l d e z r n u i t m e (a) (b) (b) Figure 16: Synthetic workload comparison using closed-loop simulation comparison using (a) uniform random, (b) bit complement, and (c) transpose traﬃc patterns. The results are normalized to the runtime of the proposed router microarchitecture with bi = 2. 0.5 0.6 0.7 0.8 0.9 1 barnes equake ocean tomcatv P e f r o r m e c n a ( o n r m a i l d e z t o n e v n o c i t a n o l a u r h c ) Figure 17: traces. Simulation results using SPLAHS2 the middle are continuously starved, resulting in very high latency as the packets need to wait for the outgoing channels to be idle before injecting their packets. By using nmax = 4, we can reduce the peak latency by over 50% while achieving lower overall, average latency. However, for nmax = 2, the throughput of the network degrades slightly as shown in Figure 14(a). By holding back credits, the eﬀective credit round-trip latency is increased – thus, with only 2 buﬀer entries, there are not enough buﬀers to cover the credit roundtrip latency. 4.1.5 Synthetic Workload and Trafﬁc Pattern Closed-loop simulations comparing the two microarchitectures are shown in Figure 16 for synthetic traﬃc patterns, and the SPLASH2 benchmark results are shown in Figure 17. When the amount of buﬀers are held constant (b = 2), the LC router provides up to 65% reduction in execution time and up to 22% when b = 16 using synthetic workloads and closed-loop simulations. For the diﬀerent SPLASH2 benchmarks, the LC router with bi = 2, also provides up to 20% reduction in execution time compared with the baseline with b = 8. Because of the reduction in zero-load latency, the LC router is able to achieve an improvement in overall performance. 4.2 Cost To evaluate the cost of the low-cost router microarchitecture, we compare the area and power of the baseline and the LC router as shown in Figure 18. For the baseline router microarchitecture, we assume an input buﬀer depth of 8 (b = 8) and for the LC router,b = 2 and the depth of the interme0 0.2 0.4 0.6 0.8 1 1.2 convent ional  lightweight o N r m a i l d e z a r a e allocator c rossbar buffer 0 0.2 0.4 0.6 0.8 1 1.2 convent ional  lightweight o N r m a i l d e z o p w e r u s n o c m p i t n o allocator c rossbar buffer (a) (b) Figure 18: (a) Area and (b) Power comparison of the conventional microarchitecture to the proposed lightweight router microarchitecture. diate buﬀer is assumed to be 4 (bi = 4) to approximately match the throughput of the two router microarchitecture. The area comparison of the two routers is shown in Figure 18(a). With only 2 buﬀers at the inputs in the LC router, the amount of storage bits required is reduced by approximately 2.6×, resulting in the router area consumed by the buﬀer to be reduced by approximately 40%. The area of the router is also dominated by the crossbar, as it is quadratically proportional to the number of router ports and channel width. By dimension slicing the router structure, the crossbar area is reduced by approximately 33%, and the reduction in the amount of buﬀer along with dimension-sliced crossbar results in an overall reduction of 37% area. The power consumption comparison shown in Figure 18(b) follows the same trend as the area comparison. The only signiﬁcant difference is that the area consumed by the allocator is nearly negligible, but it does consume some amount of power. However, with the LC router, the power consumption of the allocator is signiﬁcantly reduced as well. In addition, with the low-cost router, the critical path of the router changes. The critical path through the router is often the control signals (e.g., allocator outputs) that drive the datapath (e.g., mux select), resulting in a large delay due to the high fanout with a wide datapath. However, with the LC router, this critical path is removed as the packets in ﬂight have priority and thus, pre-determined allocation results. Our estimate shows that the LC router is able to achieve a cycle time of approximately 13 FO4 – with the critical path consisting of register read, FIFO mux (2-to1 mux as we only have two entries in the input buﬀers), 263                     Local In West In West Out X Router East Out East In Local In0 Local In1 Local In2 Local In3 West In West Out Local Router X Router Local Out0 Local Out1 Local Out2 Local Out3 East Out East In North In North Out Y Router South Out South In North In North Out Y Router South Out South In Local Out (a) (b) Figure 19: Alternative router microarchitecture to (a) support alternative routing algorithms and (b) support 4-way concentration. crossbar mux (3-to-1 mux with a dimension-sliced crossbar) and the channel link traversal of 1mm in 65nm technology and ﬁnally, the register write. Compared to the baseline router microarchitecture, we are able to achieve approximately 2.5× reduction in latency in the LC router if we assume that the baseline router is built as a single-cycle router and all the pipeline stages are serialized. 5. DISCUSSIONS In this section, we provide discussions on diﬀerent possible variations of the proposed architecture to support diﬀerent on-chip networks. 5.1 Adaptive Routing Algorithms In this work, we assumed the use of dimension-ordered routing (DOR) and compared our proposed architecture to a conventional microarchitecture that also implements DOR. However, for load-balancing adversarial traﬃc patterns, alternative routing algorithms such as randomized DOR (O1turn [39]) or adaptive routing can be used. The microarchitecture described in this work does not support other routing algorithms because of the dimension-sliced microarchitecture. However, if increased performance and load-balancing are required, other routing algorithms can be supported by adding additional complexity to the crossbar switch as shown in Figure 19(a), enabling the Y router to send packets to the X router. This allows the packets to make both X-Y turns as well as Y-X turns. In addition, by using a router microarchitecture with a very shallow buﬀer, stiﬀ backpressure can be provided such that it can possibly enable a better adaptive routing decision without the need for explicit global congestion notiﬁcation [10]. 5.2 Concentration Concentration in on-chip networks has been proposed [2, 17] to reduce the cost of the network. The proposed router architecture can be used with concentration to exploit local traﬃc and further reduce network cost. For example, the proposed router architecture with a concentration factor of 4 can be implemented as shown in Figure 19(b) by creating another slice and creating a local router for the local injection and ejection ports. This organization isolates the local traﬃc among the local nodes from any global traﬃc traversing the X or the Y router. However, the bandwidth between the local router and the X router can become the bottleneck, and additional internal speedup might be required to provide good performance. 6. RELATED WORK Many diﬀerent designs of single-cycle on-chip network routers have been proposed. Mullins et. al [33] proposed a single cycle router, which uses precomputation to remove the control logic from the critical path to create a single-cycle router. Although it was initially assumed to achieve a clock period of 12 FO4, because of the complexity of their microarchitecture, an implementation of their router resulted in a router pipeline with 35 FO4 [32]. The on-chip network router used in the TRIPS processor was built as a single-cycle router which included the link traversal delay [11]. The router pipeline serialized the diﬀerent pipeline stages, but a single cycle was achieved because of a non-aggressive cycle time (366Mhz using 130nm technology). Kumar et al. [22] proposed a single-cycle router that achieved 3.6GHz in 65nm technology. However, to achieve single-cycle, additional advanced bund le signals were required to set up the path of the packet in low load. In addition, the capability to bypass routers to achieve the ideal zero-load latency was proposed on top of a conventional router microarchitecture, thereby adding complexity to the router design. The complexity and tradeoﬀ of arbitration and scheduling have been previously studied [31, 22]. Mukherjee et. al [31] showed that a simpler, low-latency but sub-optimal arbiter design outperformed the traditional, complex arbiter in an Alpha 21364 router. They proposed the Rotary Rule which provides priority to those packets already in the network. However, the rotary rule was proposed for a network when it approaches saturation. In addition, there is still signiﬁcant complexity in the proposed arbiter as multiple priority rules are required, and like other iterative arbiters, it requires multiple steps to arbitrate between the inputs and the outputs. SPAROFLO [22] proposes using a separable allocator and gives priority to past requests over new requests in the network. However, SPAROFLO also requires three diﬀerent priority rules which complicate the allocation and it is a simpliﬁed matching algorithm. In comparison, the proposed low-cost microarchitecture does not require a separable allocator but relies on a simple arbiter to prioritize packets in ﬂight. Many crossbar switch designs have been proposed which partition the crossbar into a smaller crossbars such as using smaller, faster subcrossbars to exploit traﬃc characteristics [5], as well as using subswitches to scale the router to high-radix [37]. However, these architectures were focused on oﬀ-chip networks where the constraints are diﬀerent. Recently, partitioning on-chip router microarchitecture designs have been proposed. Lee et al. [26] proposed an router microarchitecture that partitioned the router into a left and a right router which are disjoint – the left router handles trafﬁc coming from the left (west) port, while the right router handles traﬃc coming from the right (east) port. However, this requires partitioning the north and south port bandwidth in half to accommodate the outputs of each of the disjoint router. Kim et al. [20] partitioned a router microarchitecture for a 2D mesh network into two 2×2 crossbar. Although the crossbar design was simpliﬁed, additional buﬀers and virtual channels were needed in front of the crossbars, which resulted in additional complexity. The on-chip network router for crossbar structure in a 3D architecture has 264 been proposed which was partitioned according to the dimensions [19]. This reduces the area occupied by the crossbar but adds wire and routing complexity in front of the dimension decomposed crossbar. Using buﬀers within channels has been proposed to modify repeaters and use them as a storage element [29, 21]. This approach reducess the amount of buﬀer needed at the routers and creates a more eﬃcient router. However, this does not reduce the need for buﬀers but only distributes them across the channels. Bypass channels were proposed to increase the performance of an on-chip ﬂattened butterﬂy network for non-minimal routing [17]. This work uses a similar approach of bypass channels as each router behaves similar to a bypass channel in each dimension but does not require the complexity of high-radix routers in on-chip networks. Credit round-trip latency was used in the dragonﬂy topology to stiﬀen backpressure and thus improve the performance of adaptive routing [18]. The fairness mechanism described in Section 3.6 is similar because the rate of credit return is modiﬁed; however, we do not rely on credit roundtrip latency but only on the local management of credits. The proposed fairness mechanism is not intended to provide global fairness such as other proposed schemes (i.e., GSF [25]) but only an attempt to provide local fairness – similar to a conventional router microarchitecture. The motivation described in Section 2.4 is similar to the motivation of using an operand network in the MIT RAW processor [40]. However, we extend this motivation to simplify the router microarchitecture for creating a scalable 2D mesh network. 7. CONCLUSION AND FUTURE WORK In this work, we present an alternative approach to designing on-chip network routers to achieve a low-cost and complexity-eﬀective router microarchitecture. By eliminating the amount of buﬀers, simplifying the switch arbitration, and using dimension-sliced router microarchitecture, a lowcost router microarchitecture is developed that can provide single-cycle router latency and approach ideal on-chip network latency. To support a scalable 2D mesh network, we introduce intermediate buﬀers internal to the router to decouple the two dimensions of the dimension-sliced router. By giving priority in switch arbitration to packets continuing to travel in the same dimension, the router pipeline delay is also minimized and reduces network contention to provide high throughput with limited amount of buﬀers. However, simpliﬁed switch arbitration causes starvation, and we show how delaying credits can provide a simple mechanism for starvation avoidance. Evaluations show that the proposed lightweight architecture can reduce the area by 37% and the power consumption by 45% compared with a conventional router microarchitecture that achieves the same throughput. Our low-cost router does not include the many functionalities that have been proposed for on-chip networks, including fault tolerance, QoS, support for diﬀerent traﬃc classes, and alternative routing algorithms. Our future work will focus on incorporating these functionalities into the proposed low-cost router without adding any signiﬁcant cost. We also assumed a conventional, credit-based ﬂow control but with only two buﬀer entries and the prioritized arbitration, other ﬂow controls may be more appropriate to minimize cost. In addition, improvement in the fairness mechanism is needed to provide better fairness while still attempting to minimize the complexity as the network size continues to increase. Acknowledgments We would like to thank the anonymous reviewers for their comments. This work was supported in part by the KAISTMicrosoft Research Collaboration Center (KMCC) at KAIST, Korea. 8. "
2007,Heuristics for Dynamic Task Mapping in NoC-based Heterogeneous MPSoCs.,"Multiprocessor Systems-on-Chip (MPSoCs) is a trend in VLSI design, since they minimize the ""design crisis "" (gap between silicon technology and actual SoC design capacity) and reduce the time to market. Important issues in MPSoC design are the communication infrastructure and task mapping. MPSoCs may employ NoCs to integrate multiple programmable processor cores, specialized memories, and other IPs in a scalable way. Applications running in MPSoCs execute a varying number of tasks simultaneously, and their number may exceed the available resources, requiring task mapping to be executed at runtime to meet real-time constraints. Most works in the literature present static MPSoC mapping solutions. Static mapping defines a fixed placement and scheduling, not appropriate for dynamic workloads. Task migration has also been proposed for use in MPSoCs, with the goal to relocate tasks when performance bottlenecks are identified. This work investigates the performance of mapping heuristics in NoC-based MPSoCs with dynamic workloads, targeting NoC congestion minimization, a key cost function to optimize the NoC performance. Here, tasks are mapped on the fly, according to communication requests and the load in the NoC links. Results show execution time and congestion reduction when congestion-aware mapping heuristics are employed.",
2004,Managing power consumption in networks on chips.,"Systems on a chip (SOCs) are rapidly evolving into larger networks on a chip (NOCs). This work presents a new methodology for managing power consumption for NOCs. Power management problem is formulated using closed-loop control concepts, with the estimator tracking changes in the system parameters and recalculating the new power management policy accordingly. Dynamic voltage scaling and local power management are formulated in the node-centric manner, where each core has its local power manager that determines unit power states, The local power manager's interaction with the other system cores regarding the power and the QoS needs enables network-centric power management. The new methodology for power management of NOCs is tested on a system consisting of four satellite units, each with the local power manager capable of both node and network centric power management. The results show large savings in power with good QoS.",
1992,Application of the ANNA neural network chip to high-speed character recognition.,"A neural network with 136000 connections for recognition of handwritten digits has been implemented using a mixed analog/digital neural network chip. The neural network chip is capable of processing 1000 characters/s. The recognition system has essentially the same rate (5%) as a simulation of the network with 32-b floating-point precision.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>",
2013,Design of an Energy-Efficient CMOS-Compatible NoC Architecture with Millimeter-Wave Wireless Interconnects.,"The Network-on-chip (NoC) is an enabling technology to integrate large numbers of embedded cores on a single die. The existing methods of implementing a NoC with planar metal interconnects are deficient due to high latency and significant power consumption arising out of multihop links used in data exchange. To address these problems, we propose design of a hierarchical small-world wireless NoC architecture where the multihop wire interconnects are replaced with high-bandwidth and single-hop long-range wireless shortcuts operating in the millimeter (mm)-wave frequency range. The proposed mm-wave wireless NoC (mWNoC) outperforms the corresponding conventional wireline counterpart in terms of achievable bandwidth and is significantly more energy efficient. The performance improvement is achieved through efficient data routing and optimum placement of wireless hubs. Multiple wireless shortcuts operating simultaneously further enhance the performance, and provide an energy-efficient solution for design of communication infrastructures for multicore chips.","2382 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 Design of an Energy-Efficient CMOS-Compatible NoC Architecture with Millimeter-Wave Wireless Interconnects Sujay Deb, Member, IEEE, Kev in Chang, Student Member, IEEE, Xinmin Yu, Student Member, IEEE, Suman Prasad Sah, Student Member, IEEE, M ira lem Cos ic, Am lan Gangu ly, Member, IEEE, Partha Prat im Pande, Sen ior Member, IEEE, Ben jam in Be lzer, Member, IEEE, and Deukhyoun Heo, Member, IEEE Abstract—The Network-on-chip (NoC) is an enabling technology to integrate large numbers of embedded cores on a single die. The existing methods of implementing a NoC with planar metal interconnects are deficient due to high latency and significant power consumption arising out of multihop links used in data exchange. To address these problems, we propose design of a hierarchical small-world wireless NoC architecture where the multihop wire interconnects are replaced with high-bandwidth and single-hop longrange wireless shortcuts operating in the millimeter (mm)-wave frequency range. The proposed mm-wave wireless NoC (mWNoC) outperforms the corresponding conventional wireline counterpart in terms of achievable bandwidth and is significantly more energy efficient. The performance improvement is achieved through efficient data routing and optimum placement of wireless hubs. Multiple wireless shortcuts operating simultaneously further enhance the performance, and provide an energy-efficient solution for design of communication infrastructures for multicore chips. Index Terms—Network-on-chip, millimeter-wave wireless, small world, optimization, performance evaluation Ç 1 INTRODUCTION THE Network-on-chip (NoC) has emerged as a revolutionary methodology to integrate numerous blocks in a single chip. An important performance limitation in traditional NoCs arises from planar metal interconnectbased multihop communications, wherein the data transfer between two far apart cores cause high latency and power consumption. This limitation of conventional NoCs can be addressed by drawing inspiration from the interconnection mechanism of natural complex networks. Many networks, such as networks of neurons in the brain, the Internet, and social networks share the small-world (SW) property [1]. Compared to a purely locally and regularly interconnected network (such as a mesh interconnect), small-world networks have a very short average distance between any pair of nodes. This makes them particularly interesting for efficient communication in modern multicore chips with increasing levels of integration. This small-world topology . S. Deb is with the Department of Electronics and Communication Engineering, Indraprastha Institute of Information Technology, Okhla, Phase-III, Delhi 110020, India. E-mail: sdeb@iiitd.ac.in. . K. Chang, X. Yu, S.P. Sah, M. Cosic, P.P. Pande, B. Belzer, and D. Heo are with School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA 99164. E-mail: {jchang, xyu, ssah, mcosic, pande, belzer, dheo}@eecs.wsu.edu. . A. Ganguly is with the Department of Computer Engineering, Rochester Institute of Technology, Room 09-3425, Rochester, NY 14623-5603. E-mail: amlan.ganguly@rit.edu. Manuscript received 30 Nov. 2011; revised 27 Aug. 2012; accepted 29 Aug. 2012; published online 11 Sept. 2012. Recommended for acceptance by R. Marculescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TC-2011-11-0923. Digital Object Identifier no. 10.1109/TC.2013.224. can be incorporated in NoCs by introducing long-range, high-bandwidth and low-power links between far apart cores. In this work, we propose a hybrid NoC architecture that uses on-chip millimeter (mm)-wave wireless links designed in traditional CMOS technology as long-range communication channels between widely separated cores, along with wired interconnects connecting adjacent cores. Recent investigations have established characteristics of the silicon integrated on-chip antenna operating in the mmwave range of a few tens to one hundred GHz and it is now a viable technology [2]. Coupled with significant advances in mm-wave transceiver des ign this opens up new opportunities for detailed investigations of mm-wave wireless NoCs (mWNoCs). In this paper, we propose a design methodology and establish associated tradeoffs for hierarchical NoCs with mm-wave wireless links in presence of various traffic patterns. We demonstrate that the proposed mWNoC outperforms its more traditional wireline counterparts in terms of sustainable data rate and energy dissipation. We also evaluate the performance of mWNoC with respect to two other small-world NoC architectures with emerging interconnect technologies. In one of these architectures , the long-range links are implemented with recently proposed RF interconnects (RFNoC) [3]. The other architecture is a hierarchical and small-world wireless NoC designed with carbon nano tube (CNT) enabled THz wireless links (THzNoC) [4]. We demonstrate the advantages and the limitations of each architecture and establish the relevant design tradeoffs. The main contributions of this paper are as follows: 1. We demonstrate that mm-wave wireless interconnectbased NoCs can be a viable CMOS compatible 0018-9340/13/$31.00 ß 2013 IEEE Published by the IEEE Computer Society DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2383 solution for future many core chips, and are capable of solving the performance limitations of traditional multihop wireline counterparts. The mWNoC can achieve performance comparable to that of other emerging and more technologically challenging onchip RF/wireless interconnect solutions. It is also shown that mWNoC can accommodate multiple simultaneously operating wireless channels resulting in further improvement of overall performance. 2. We present simulation resu lts to evaluate the performance of mWNoC against other emerging interconnect-based NoCs, viz., THzNoC and RFNoC, in both uniform and nonuniform traffic scenarios. The inherent broadcasting capability of mWNoC is also exploited to demonstrate its performance advantage. We also demonstrate that the hierarchical and small-world-based NoC architectures with emerging interconnects like wireless and RF provide significantly better performance than either conventional mesh-based NoCs or hierarchical architectures without any shortcuts. The area overheads associated with these novel NoC architectures are also quantified and it is shown that performance benefits clearly outweigh the overheads. 2 RELATED WORK T h e l im i t a t i o n s an d d e s i g n c h a l l e n g e s a s s o c i a t e d with existing NoC architectures are elaborated in [5]. Conventional NoCs use multihop packet switched communication. At each hop, the data packet goes through a complex router/switch, which contributes considerable power, throughput, and latency overhead. To improve performance, a methodology to automatically synthesize an architecture with a few application specific long-range links inserted in a regular mesh was proposed in [6]. Subsequently, performance advantages of NoCs by insertion of long-range wired links following principles of smallworld graphs was elaborated in [7]. The concept of express virtual channels is introduced in [8]. By using virtual express lanes to connect distant cores in the network, it is possible to avoid the router overhead at intermediate nodes, and thereby improve NoC performance in terms of power, latency, and throughput. Performance is further improved by incorporating ultralow-latency, multidrop on-chip global lines (G-lines) for flow control signals [9]. Despite significant performance gains, in the above schemes the longrange links are designed with conventional wires. It is already shown that beyond a certain length wireless links are more energy efficient than the conventional metal wires. Hence, the performance improvements by using long-range wireless links will be more than that using wired links [10]. The design principles of photonic NoCs are elaborated in various recent publications [11], [12], [13]. The components of a complete photonic NoC, for example, dense waveguides, switches, optical modulators, and detectors, are now viable for integration on a single silicon chip. It is estimated that a photonic NoC will dissipate an order of magnitude less power than an electronic NoC. Another alternative is NoCs with multiband RF interconnects (RF-I) [3]. Various implementation issues of this approach are discussed in [14]. In this particular NoC, instead of depending on the charging/discharging of wires for sending data, electromagnetic (EM) waves are guided along on-chip transmission lines created by multiple layers of metal and dielectric stack. As the EM waves travel at the effective speed of light, low latency and high-bandwidth communication can be achieved. This type of NoC is also predicted to dissipate an order of magnitude less power than the traditional planar NoC, with significantly reduced latency as well. Recently, the design of a wireless NoC based on CMOS ultra wideband (UWB) technology was proposed in [15] and [16]. The authors of [17] propose multichannel wireless NoC using UWB transceivers. As ultrashort pulses can be used with the UWB technology, the authors propose timehopping multiple access to improve the performance of the NoC. In this scheme, a transmitting RF node uses pseudorandom timing of its pulses within the UWB signal interval, which is unique for each receiver. This enables concurrent multiple channels between multiple transceiver pairs. The performance of silicon integrated on-chip antennas for intra- and interchip communication have been already demonstrated by the authors of [18]. They have primarily used metal zigzag antennas operating in the range of tens of GHz. The propagation mechanisms of radio waves over intrachip channels with integrated antennas were also investigated [19]. Depending on antenna configuration and substrate characteristics, achievable wireless channel frequencies can be in the range of 50-100 GHz. At these mmwave frequencies the effect of metal interference structures such as power grids, local clock trees, and data lines on onchip antenna characteristics like gain and phase are investigated in [20]. The demonstration of intrachip wireless interconnection in a 407-pin flip-chip package with a ball grid array (BGA) mounted on a PC board [21] has addressed the concerns related to influence of packaging on antenna characteristics. Design rules for increasing the predictability of on-chip antenna characteristics have been proposed in [20]. Using antennas with a differential or balanced feed structure can significantly reduce coupling of switching noise, which is mostly common mode in nature [22]. In [23], the feasibility of designing miniature antennas and simple transceivers that operate in the sub-THz frequency range for on-chip wireless communication has been demonstrated. In [24], a combination of Time and Frequency Division Multiplexing is used to transfer data over inter-router wireless express channels. However, the issues of interchannel interference due to multiple adjacent frequency channels remain unresolved in this work. Design of a small-world wireless NoC operating in the THz frequency range using CNT antennas is elaborated in [4]. Though this particular NoC is shown to exceed the performance of traditional wireline NoCs by orders of magnitude, integration and reliability of CNT devices need more investigation. This work aims to circumvent the performance limitations of traditional multihop NoCs by introducing a hierarchical small-world network with CMOS compatible mm-wave wireless links for multicore chips. 2384 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 3 MM-WAVE WIRELESS NoC ARCHITECTURE A generic wired NoC provides interconnection among embedded cores via switches and wired links. Communication between pairs of source and destination cores is generally via multihop links, resulting in high energy dissipation and latency. With increasing system size, the average hop count increases and consequently the problem of higher energy dissipation and latency becomes more profound. To alleviate this problem, we propose a hierarchical NoC architecture with wireless interfaces (WIs) strategically placed for optimum performance. In the following sections, we discuss the topology of the proposed hierarchical architecture and the adopted performance optimization methodology. 3.1 mWNoC Architecture Modern complex network theory provides powerful methods to analyze network topologies and their properties [25]. Networks with the small-world property have a very short average path length, which is commonly measured as the number of hops between any pair of nodes. The average path length of small-world graphs is bounded by a polynomial in log(N ), where N is the number of nodes, which makes them particularly interesting for efficient communication with minimal resources [26]. This feature of small-world graphs makes them attractive for constructing mWNoCs. A small-world topology can be constructed from a locally connected network by rewiring selected node connections randomly to other nodes, which creates shortcuts in the network [27]. These random long-range links between nodes can also be established following probability distributions depending on the distance separating the nodes [28]. It has been shown that such shortcuts in NoCs can significantly improve the performance compared to locally interconnected mesh-like networks [7], [27] with fewer resources than a fully connected system. Our goal here is to use the small-world approach to build a highly efficient NoC based on both wired and wireless links. This topology can be incorporated in NoCs by introducing long-range, high-bandwidth and low-power wireless links between distant cores. This will enable the design of hierarchical NoC architectures, where closely spaced cores will communicate through traditional metal wires, but long distance communications will be predominantly achieved through high-performance wireless links. Thus, for our purpose, we first divide the whole system into multiple small clusters of neighboring cores called subnets. As subnets are smaller networks, intrasubnet communication will have a shorter average path length than a single NoC spanning the whole system. These subnets have switches and links as in a standard NoC. The cores are connected to a centrally located hub through wired links, and the hubs from all subnets are connected in a second level network forming a hierarchical structure. This is achieved by interconnecting adjacent hubs with wireline links, and by introducing a few long-range mm-wave wireless links between distant hubs according to the placement scheme outlined in Section 3.2. The hubs connected through wireless links require WIs. Reducing long-distance multihop wired communication is essential to achieve the full benefit of on-chip wireless Fig. 1. A hierarchical 256-core network where hubs are connected by a small-world graph. networks for multicore systems. The number of WIs and their placement are optimized for performance using a simulated annealing (SA) [29]-based optimization algorithm. The SA approach allows network design to be scalable with increasing system size. The key to our approach is establishing optimal overall network topology under given resource constraints, i.e., a limited number of WIs. Fig. 1 shows a representative interconnection topology with 16 hubs and six wireless interfaces. In this paper, as an example, the hubs are considered to be connected in a mesh. Instead of the mesh, the hubs can be connected in any other possible interconnect topology depending on the exact performance requirement. The subnets considered here have the StarRing architecture, which consists of a ring with a central hub. We have already shown that this architecture provides the best performance-overhead tradeoff point for mWNoC architectures [10]. The size and number of subnets should be chosen such that neither the subnets nor the upper level of the hierarchy become too large. If either level of the hierarchy becomes too large, then it causes a performance bottleneck by limiting the data throughput in that level. Since the architecture of the two levels can be different causing their traffic characteristics to differ, the exact hierarchical division can be obtained by performing system-level simulations as discussed in Section 5.2. 3.2 Optimization of mWNoC Architecture In this section, we present the method used for determining the optimum mWNoC architecture. At first, we define the optimization metric, and then we discuss the SA-based optimization procedure for obtaining optimum number of WIs and their suitable placement. 3.2.1 Optimization Metric To determine the optimal number of WIs for a given network, we define two metrics, which account for the performance as well as the cost of the NoC. The first metric, which measures approximate network performance, is the average shortest path,  between all pairs of hubs. Let N be the number of hubs of the network. Let d be an N  N matrix, where element di;j is the distance (shortest path) between hub i and hub j measured in hops. A single hop in this work is defined as the path length between a source and destination pair that can be traversed in one clock cycle. The matrix d is populated using Dijkstra’s shortest path algorithm [30]. The distances are then weighted with the DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2385 normalized frequencies of communication between hub pairs. The metric, , can be calculated as hi;j  fi;j =½ðN 2   N Þ  F ; X  ¼ ð1Þ hi;j ¼ p  di;j with shortcut þ ð1   pÞ  di;j without shortcut; ð2Þ where hij is the distance (in hops) between the ith source and jth destination . The frequency fi;j of communication between the ith source and jth destination is the apriori frequency of the traffic interactions between the subnets determined by a particular traffic pattern that depends on the application mapped onto the NoC. F is then calculated as X F ¼ fi;j : ð3Þ The probability of getting access to the wireless channel for communication between any source-destination pair is designated by p, which is inversely proportional to the number of WIs (n) sharing the same frequency channel. With the assumption that all the WIs are equally likely to have access to the wireless channel, p can be computed as p ¼ 1=n: ð4Þ ð5Þ Here, equal importance is attached to interhub distance and frequency of communication. The second metric needed to complete the quantification of a network’s quality is the cost function: C ostð#ofW I Þ ¼ A þ P þ L; where, A, P, and L are normalized area, power, and wireless channel access delay overheads, respectively, arising from the WIs. A is determined by dividing the total wireless hub area by the area of the communication infrastructure. The power dissipated by all WIs is divided by the total power consumed by the communication infrastructure to determine P . L is determined by diving the token returning period (described in Section 4.3) by the average packet latency. The two metrics, average shortest path  and cost, are thus the two objectives to be optimized. Many methods exist for evaluating multiobjective optimization problems [31]. We describe the aggregate objective function (AOF), which combines both of the metrics, as follows: AOF ¼ a   þ ð1   aÞ  C ost; a ¼ 0 results in an analysis entirely dependent on cost, where a specifies the importance of the two metrics, i.e., a ¼ 1 results in an analysis entirely dependent on the network connectivity, while a ¼ 0:5 makes for a balance between the two metrics. The choice of a is a design decision and depends on the design requirements. For a chosen value of a, optimum number of WI (n) is selected that results in minimum value of AOF. The AOF defined above is then used in the optimization step outlined in the next section to determine the optimal NoC architecture. ð6Þ 3.2.2 Placement of WIs This process takes N and a as inputs and for all possible number of WIs perform SA-based placement optimization. WI placement is crucial for optimum performance gain as it Fig. 2. Flow diagram for the simulated annealing-based optimization of mWNoC architectures. establishes high-speed, low-energy interconnects on the network. It is shown in [4] that for placement of wireless links in a NoC, the SA algorithm converges to the optimal configuration much faster than the exhaustive search technique. Hence, we adopt a SA-based optimization technique for placement of the WIs to get maximum benefits of using the wireless shortcuts. Initially, the WIs are placed randomly with each hub having equal probability of getting a WI. The only constraint observed while deploying the WIs to the hubs is that a single hub could have a maximum of one WI. Once the network is initialized randomly, an SA-based optimization step is performed. Since the deployment of WIs is only on the hubs, the optimization is performed solely on the second level network of hubs. If there are N hubs in the network and n WIs to distribute, the size of the search space S is given by   Sj j ¼ N n : ð7Þ Thus, with increasing N , it becomes more computationally expensive to find the best solution by exhaustive search. SA is performed on the optimization metric AOF defined by (6). In each SA iteration, a new network is created by randomly reassigning a WI in the current network. The metric for the new network is calculated and compared to the current network’s metric. The new network is chosen as the current optimal solution if its metric is lower. However, even if the metric is higher we choose the new network probabilistically. This reduces the probability of getting stuck in a local optimum, which could happen if the SA process were to never choose a worse solution. In this work, we have used Cauchy annealing schedule [29] and it is preferred over the normal distribution because of its flatter tails, making it easier to escape from local minima. The convergence criterion chosen here is that the metric at the end of the current iteration differs by less than 0.1 percent from the metric of the previous iteration [4]. Fig. 2 shows the steps used to optimize the network. 2386 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 Fig. 3. Zigzag antenna structure details. An important point to note here is that similar results can also be obtained using other optimization techniques, like evolutionary algorithms (EAs) [32] and coevolutionary algorithms [33]. Although EAs are generally believed to give better results, SA reaches comparably good solutions much faster [34]. We have used SA in this work as an example. 4 OVERALL COMMUNICATION SCHEME In this section, we describe the various components of the WIs and the adopted data routing strategy. As mentioned in the previous section, the WIs are optimally placed in some of the hubs to provide them with the capability to communicate using the wireless channel. The two principal components of the WI are the antenna and the transceiver. Characteristics of these two components are outlined below. 4.1 On-Chip Antennas The on-chip antenna for the proposed mWNoC has to provide the best power gain for the smallest area overhead. A metal zigzag antenna [35] has been demonstrated to possess these characteristics. This antenna also has negligible effect of rotation (relative angle between transmitting and receiving antennas) on received signal strength, making it most suitable for mWNoC application [19]. The zigzag antenna is designed with 10-m trace width, 60-m arm length and 30 degree bend angle. The axial length depends on the operating frequency of the antenna which is determined in Section 5.4. The details of the antenna structure are shown in Fig. 3. 4.2 Wireless Transceiver Circuit To ensure the high throughput and energy efficiency of the mWNoC, the transceiver circuitry has to provide a very wide bandwidth as well as low-power consumption. In designing the on-chip mm-wave wireless transceiver, the low-power design considerations are taken into account at the architecture level. Noncoherent on-off keying (OOK) is chosen as the modulation method, as it allows relatively simple and low-power circuit implementation. As illustrated in Fig. 4, the transmitter (TX) circuitry consists of an up-conversion mixer and a power amplifier (PA). On the receiver (RX) side, direct-conversion topology is adopted, consisting of a low-noise amplifier (LNA), a down-conversion mixer, and a baseband amplifier. An injection-lock voltage-controlled oscillator (VCO) is reused for TX and RX. With both direct-conversion and injectionlock technology, a power-hungry phase-lock loop (PLL) is eliminated. Moreover, at the circuit level, body-enabled design techniques [36], including both forward body-bias (FBB) with DC voltages, as well as body-driven by AC signals [37], are implemented to further decrease power Fig. 4. OOK transceiver block diagram. consumption. High isolation to other circuits is guaranteed by using triple-well CMOS with deep N-well, which is now common in most of the scaled CMOS processes. Detailed design descriptions of the transceiver are presented in our previous works [10], [38]. 4.3 Adopted Data Transmission Strategy In the proposed hierarchical NoC, data are transferred via flit-based wormhole routing [39]. Intrasubnet data routing is done according to the topology of the subnets. For StarRing subnet topology, if the destination core is within two hops on the ring from the source, then the data are routed along the ring. If the destination core is more than two hops away, then the data routing takes place via the central hub. To avoid deadlock within the subnet, we follow the virtual channel management scheme adopted from the Red Rover algorithm [40], in which the ring is divided into two equal sets of contiguous nodes. Messages originated from each group of nodes use a particular set of dedicated virtual channels regardless of destination. Furthermore, messages injected on a particular virtual channel will continue their traversals on that channel until reaching destinations. Since a message is confined to a particular channel for its entire traversal and each of these channels contains no cycles, the scheme is deadlock free. Intersubnet data routing, however, requires the flits to use the upper level network consisting of the wired and wireless links. By using the wireless shortcuts between the hubs with the WIs, flits can be transferred in a single hop. If the source hub does not have a WI, the flits are routed to the nearest hub with a WI via the wired links and are transmitted through the wireless channel. Likewise, if the destination hub does not have a WI, then the hub nearest to it with a WI receives the data and routes it to the destination through wired links. Between a pair of source and destination hubs without WIs, the routing path involving a wireless link is chosen if it reduces the total path length compared to the wired path. This can potentially give rise to a hotspot situation in the WIs because many messages try to access wireless shortcuts simultaneously, thus overloading the WIs and resulting in higher latency. Token flow control [41] and distributed routing are used to alleviate this problem. Tokens are used to communicate the status of the input buffers of a particular WI to other nearby hubs, which need to use that WI for accessing wireless shortcuts. Every WI input port has a token and the token is turned on if the availability of the port’s buffer is greater than a fixed threshold and turned off otherwise. The routing adopted here is a combination of dimension order routing for the hubs without WIs and South-East routing algorithm for the DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2387 Fig. 6. Number of iterations required to reach optimal solution by the SA and exhaustive search methods. work, the boundary nodes are the hubs, which allow intersubnet communication. The hubs are safe nodes as there is no path from an internal output link to an internal input link. 5 EXPERIMENTAL RESULTS In this section, we discuss the experimental results that demonstrate performance of the proposed mWNoC. First, we present the justification behind using SA-based optimization followed by the characteristics of the on-chip wireless communication channel. Then, we present detailed network-level simulations with various system sizes and traffic patterns. We evaluate the performance of SA for WI placement by comparing the number of iterations required to achieve optimal network configuration through SA and exhaustive search for various system sizes. SA produces network configurations with average hop counts exactly equal to those generated by exhaustive search for the system configurations considered in this paper. Fig. 6 shows the number of iterations required to arrive at the optimal solution with SA and exhaustive search. The numbers of iterations with SA were measured as an average of 10 trials. Clearly , the SA algorithm converges to the optimal configuration much faster than the exhaustive search technique. This advantage will further increase for larger system sizes. 5.1 Simulation Setup An overview of the performance evaluation setup for the mWNoC is shown in Fig. 7. To obtain the gain and bandwidth of the antennas, we use the ADS momentum tool [44]. For our experiments, we consider three different system sizes, namely 128, 256, and 512 cores, and the die Fig. 7. Performance evaluation setup for mWNoC. Fig. 5. An algorithmic representation of the adopted data routing strategy. hubs with wireless shortcuts. This routing algorithm is proved to be deadlock free in [7]. If the WIs that the message encounters along the way are not available, the message follows dimension order routing and keeps looking for the shortest path using WIs at every hub until the destination hub is reached. Consequently, the distributed routing and token flow control prevents deadlocks and effectively improves performance by distributing traffic though alternative paths. All the wireless hubs are tuned to the same channel and can send or receive data from any other wireless hub on the chip. Under these conditions, an arbitration mechanism needs to be designed to grant access to the wireless medium to a particular hub at a given instant to avoid interference and contention. To avoid the need for a centralized control and synchronization mechanism, the arbitration policy adopted is a token passing protocol [42]. It should be noted that the use of the word token in this case differs from the usage in the above-mentioned token flow control. According to this scheme, the particular WI possessing the token can broadcast flits into the wireless medium. All other hubs will receive the flit as their antennas are tuned to the same frequency band. When the destination address matches the address of the receiving hub, then the flit is accepted for further routing. It is routed either to a core in the subnet of that hub or to an adjacent hub. The token is released to the next hub with a WI after all flits belonging to a single packet at the current token-holding hub are transmitted. Fig. 5 shows the flowchart of the adopted data routing strategy. According to [43], the mWNoC is deadlock free if both the subnets and the second level of the network are deadlock free and the boundary nodes are safe nodes. As explained above, the subnets and the second level of small-world network are deadlock free. Moreover, in this 2388 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 TABLE 1 Performance Parameters for Different NoC Components area is kept fixed at 20 mm  20 mm for all system sizes. The mm-wave wideband wireless transceiver is designed and simulated using Cadence tools with TSMC [45] 65-nm standard CMOS process to obtain its power and delay characteristics. The subnet switches and the digital components of the hubs are synthesized using Synopsys tools with 65-nm standard cell library from TSMC at a clock frequency of 2.5 GHz. Energy dissipation of all the wired links is obtained from Cadence layout assuming a 20 mm  20 mm die area. All the power and delay numbers of various components along with the optimum network configuration generated from the SA are then fed into the network simulator to obtain overall mWNoC performance. As an example, Table 1 shows all the performance parameters for different components that the NoC simulator uses for deriving network performance for a 256-core system divided into 16 subnets. The NoC switch architecture is adopted from [46]. The hubs and the NoC switches in the subnets all have four virtual channels per port and have a buffer depth of two flits. Each packet consists of 64 flits. The ports associated with the WIs have an increased buffer depth of eight flits, which ensures that all the messages trying to access wireless links are efficiently handled without compromising performance [10]. Increasing the buffer depth beyond this tradeoff point does not produce any further performance improvement for this particular packet size, but will give rise to additional area overhead. The wireless ports of the WIs are assumed to be equipped with antennas and wireless transceivers. A self-similar traffic injection process is assumed. We consider a Mesh-StarRing as the overall interconnection architecture for the mWNoC. The upper level of the hierarchy is a mesh with overlaid mm-wave wireless shortcuts and the subnets have StarRing architectures. The Mesh-StarRing network architecture is simulated using a cycle accurate simulator. The delays in flit traversals along all the wired interconnects that enable the proposed hybrid NoC architecture are considered while quantifying the performance. These delays include the intrasubnet core-tohub and the interhub wired links in the upper level of the network. The delays through the switches and interswitch wires of the subnets and also the delays through the hubs are taken into account. Fig. 8. Achievable bandwidth of a 256-core Mesh-StarRing NoC for various hierarchical configurations. NS ¼ number of subnets, SS ¼ subnet size. 5.2 Optimum Hierarchical Division To determine the optimum division of the proposed hierarchical architecture in terms of achievable bandwidth, we evaluate the performance of the mWNoC by dividing the whole system in various alternative ways. This analysis is performed without any shortcuts to highlight the effect on performance resulting from different ways of doing the hierarchical division. Fig. 8 shows the achievable bandwidth for a 256-core Mesh-StarRing divided into different numbers of subnets. As can be seen from the plot, the division of the whole system into 16 subnets with 16 cores in each performs the best. Similarly, the suitable hierarchical division that achieves the best performance is determined for the other system sizes. For system sizes of 128 and 512, the optimum number of subnets turns out to be 8 and 32, respectively. 5.3 Optimum Number of WIs The WIs introduce hardware overhead, and hence, we aim to limit the number of WIs without significantly compromising the overall performance. As this is related to the utilization of the wireless medium, only the second level of the network is considered. We undertook the network optimization analysis following the methodology elaborated in Section 3. The optimum number of WIs (n) obtained for different values of a for a 16 hub system with one wireless channel is shown in Fig. 9a. The weight parameter a determines how the cost versus the Fig. 9. Results obtained from (a) cost function analysis and (b) network simulation. DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2389 Fig. 10. Antenna transmission gain (S21) response. Fig. 11. Simulink block diagram of interconnect. the transceiver for wireless performance is weighted for the optimization fitness function. From this result, it can be observed that for a moderate weight value, a (varying from 0.30 to 0.7) the optimum number of WIs varies from 4 to 12. The error bars represent the overall variation of the optimum number of WIs for different execution of the optimization process. As expected at the weight boundary values, the cost function optimization ends with either zero or the maximum number of WIs. Thus, this analysis gives us a narrower window of possible optimum number of WIs for a particular system size. To exactly determine the optimum number of WIs, we carried out system-level simulations within this narrower window with the wireless token passing mechanism and the results are shown in Fig. 9b. The token is considered to be a single flit transmitted from the WI, which currently holds it to the next one. From Fig. 9b, it is seen that for a 256-core mWNoC (16 subnets with 16 cores in each subnet) bandwidth increases with number of WIs until reaching a maximum at six WIs and then it decreases. This is because although a higher number of WIs improves connectivity by reducing hop-count of the network, the shared wireless medium is distributed among the WIs, and as the number of WIs increases beyond a certain point, performance degrades due to the large token return ing per iod . Moreover , as the number of WIs increases, the overall energy dissipation from the WIs becomes higher, and it causes the packet energy to increase as well. Considering all these factors, we determine the optimum number of WIs for 256-core mWNoC as 6. Similarly, for system sizes of 128 and 512 (consisting of eight and 32 subnets, respectively) the optimum performance is achieved with four and 10 WIs, respectively. 5.4 Wireless Channel Characteristics The metal zigzag antennas described earlier are used to establish the on-chip wireless communication channels. High resistivity silicon substrate ( ¼ 5k    cm) is used for the simulation. To represent a typical intersubnet communication range the transmitter and receiver were separated by 20 mm. The forward transmission gain (S21) of the antenna obtained from the simulation is shown in Fig. 10. As shown in Fig. 10, we are able to obtain a 3-dB bandwidth of 16 GHz with a center frequency of 57.5 GHz. For optimum power efficiency, the quarter wave antenna needs an axial length of 0.38 mm in the silicon substrate. Since a flat channel and antenna frequency response over the entire signal bandwidth is not practical, a system-level simulation is performed to more accurately define the circuit design specifications. The simulations were carried out in Simulink, with the block diagram given in Fig. 11. We assume that the gain and noise figure (NF) of the LNA are both fixed at 10 dB, and the down-conversion mixer has a gain of 0 dB and a NF of 20 dB. Thus, the overall NF is   NFtotal ¼ 10 log 1 þ FLNA þ Fmixer GLNA ¼ 13 dB; ð8Þ where FLNA and Fmixer are the noise factors of the LNA and mixer, respectively, and GLNA is the gain of the LNA, all in linear scale. We assume that the temperature is at 323 K (50 C). As for the transmitter, assume that the PA output power varies from  10 to  4 dBm. Therefore, the SNR at the demodulator can be calculated as SNR ¼ Pt   Path Loss   Noise Floor; ð9Þ ð10Þ Noise Floor ¼ 10 log kTð Þ þ 10 log BWð Þ þ NFtotal ; in which Pt is the TX power, k is the Boltzmann constant, T is the absolute temperature, and BW is the bandwidth, which is set to be 32 GHz, considering the worst case noise for OOK modulation with 16-Gbps data rate. From Fig. 10, it is seen that the path-loss is 26.5 dB at the center frequency. Accordingly from (9), the SNR at the demodulator ranges from 19 to 25 dB. The BER performances were simulated within this range of SNR. Using these results, the required SNR was then extrapolated for the targeted BER of 10 15 , which is the BER of traditional wired links [23]. The resulting BER versus transmitted power curve is shown in Fig. 12. It can be seen that a PA transmit power of at least 2.5 dBm (equivalent to an SNR of 31.5 dB) is needed. In [47], simulations with root-raised cosine (RRC) pulse shaping filters in both TX and RX gave a 5-dB performance gain, which in principle would allow reduction of the PA transmit power by 5 dB. However, circuit implementation of a low power and sufficiently wideband RRC matched filter in the receiver working in the 60-GHz range remains a Fig. 12. Simulated BER versus TX power. 2390 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 Fig. 13. (a) Simulated gain, and (b) DSB NF of the receiver front end at different temperatures and process corners. challenging problem for the designed mWNoC. Hence, the present paper employs rectangular pulse shaping. According to the simulation results, it is now possible to redistribute the SNR budget to RF building blocks in the system. Specifically, for a low-power consumption of the TX, we decreased Pt min to  0:5 dBm, so that the corresponding N Ftotal needs to be 10 dB at the receiver, to maintain the target BER. Therefore, a gain of greater than 13 dB and an NF less than 7 dB are required at the LNA. The mixer would still need to achieve less than 20-dB NF. With the design target set by the system-level simulation, the wireless transceiver circuitry was designed and simulated using TSMC 65-nm standard CMOS process. The overall conversion gain and double-sideband (DSB) NF of the receiver at 27C with typical-typical (TT) process corner are illustrated in Fig. 13. As can be seen, the conversion gain is 20 dB at the center frequency, and rises up to 20.5 dB at the peak. Fig. 13a also shows that the overall 3-dB bandwidth of the receiver front end is 18 GHz. From Fig. 13b, it can be seen that the overall NF stays below 6 dB. Fig. 13 also demonstrates the process and temperature variation of the receiver performance. In the worst case of 85 C with TT process corner, both the conversion gain and the NF show around 2 dB of degradation, and the 3-dB bandwidth shrinks to 16.5 GHz. Moreover, at 27C with slow-slow (SS) process corner, approximately 1.5 dB of gain degradation is observed, and the NF increases by 1 dB. However, the 3-dB bandwidth remains 18 GHz. Therefore, even with process and temperature variations, the achieved bandwidth and NF of the receiver are still better than the design targets of 16 GHz and 10 dB, respectively. The conversion gain of the transmitter is illustrated in Fig. 14. The transmitter has a peak gain of 15 dB, and a 3-dB bandwidth of 18.1 GHz. Furthermore, circuit simulation also shows that the output 1-dB gain compression point (P1dB ) of the transmitter is 0 dBm. The achieved aggregate power consumption of the entire transceiver is 36.7 mW, 16 percent lower than the previous Fig. 14. TX conversion gain. Fig. 15. Ach ievab le bandw idth w ith sca l ing for d ifferent NoC architectures. design without using body-enabled techniques [48]. It is able to support a data rate of at least 16 Gbps, and a BER < 10 15 using an OOK modulation scheme [47] for a communication range of 20 mm. All the transceivers work in the same frequency range, making the overall design modular and scalable. Area overhead is minimized because only one antenna per transceiver is needed. As mentioned earlier, a token passing protocol is used to select which transceiver will use the wireless channel at any particular time, thereby removing the possibility of channel contention. The omnidirectionality of the zigzag antennas allows essentially equal antenna gains for all pairs of wireless transceivers on the chip. Thus, the combination of token passing protocol and zigzag antenna provides a great deal of flexibility in mWNoC design. 5.5 Achievable Bandwidth with Uniform Traffic In this section, we analyze the characteristics of the proposed mWNoC and study trends in its performance as the system size scales up. Fig. 15 shows the bandwidth of the proposed mWNoC for the three different system sizes considered under a uniform random spatial traffic distribution. For comparison, we also present the bandwidth of five alternative architectures of the same size: 1. 2. flat mesh, the same hierarchical architecture as the mWNoC, but without any long-range links, 3. hierarchical architecture as the mWNoC, but longrange links implemented with RF interconnects (RFNoC) [14], 4. hierarchical architecture as mWNoC, but long-range links implemented with CNT antenna-based THz wireless interconnects (THzNoC) [4], and 5. hierarchical architecture as the mWNoC, but with shortcuts implemented using buffered metal wires (BWNoC) instead of the wireless links. Due to the short range of communication, UWB-based onchip wireless interconnects proposed in [15] are not considered as another alternative to establish the shortcuts in the hierarchical small-world networks. We have also shown in our previous studies that UWB NoC dissipates significantly more energy compared to the THzNoC [4]. We designed a small-world RFNoC by replacing the wireless communication channel of the mWNoC by the RFI, maintaining the same hierarchical topology. As mentioned in [3], in 65-nm technology it is possible to have eight DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2391 Fig. 16. Packet energy for different NoC architectures. different frequency channels each operating with a data rate of 6 Gbps. Like the wireless channel, these RF links can be used as long-range shortcuts in the hierarchical NoC architecture. These shortcuts are optimally placed using the same SA-based optimization as used for placing the WIs in the mWNoC. We also designed THzNoC using nanoscale antennas based on CNTs operating in the THz/optical frequency range as long-range wireless shortcuts in mWNoC architecture. There can be 24 different wireless shortcuts each operating at 10-Gbps data rate [49]. These shortcuts are placed optimally using the same optimization method. In case of BWNoC, the numbers of wired shortcuts are kept equal to the number of WIs for different system sizes and they are also optimally placed using the same optimization as used for the placement of WIs (Section 3.2). Each wired shortcut is considered to be 32-bit wide. The wires are designed for minimum delay with an optimum number of uniformly placed and sized repeaters. The flat mesh architecture performs worst among all the alternatives due to its highest average hop count. The hierarchical architecture improves the performance by reducing hop count, but the best performance is obtained from the hierarchical architecture with shortcuts due to the small-world nature of the network. BWNoC, RFNoC, and THzNoC perform better than mWNoC because multiple shortcuts can work simultaneously in them, whereas in mWNoC (where the wireless channel is a shared medium) only one pair can communicate at a particular instant of time. But BWNoC suffers from significant energy dissipation overhead, which is quantified in Section 5.6. Though THzNoC shows better performance than mWNoC, it is not a CMOS compatible solution and the integration and reliability of CNT devices need more investigation. Similarly, the total long-range link area overhead and the layout challenges of the RFNoC are more significant compared to mWNoC. For example, for a 20 mm  20 mm die, an RF interconnect of approximately 100-mm length has to be allocated for RFNoC following the layout of [14]. This is significantly higher than the combined length of all the antennas used in the mWNoC, which is 3.8 mm for the highest system size (512 cores) considered in this paper. 5.6 Energy Dissipation for Uniform Traffic To quantify the energy dissipation characteristics of the proposed mWNoC architecture, we determine the packet energy dissipation, Epkt . The packet energy is the energy Fig. 17. (a) The variation of per bit energy dissipation with distance for a wired and a wireless link and (b) components of packet energy dissipation for mWNoC and flat mesh. dissipated on average by a packet from its injection at the source to delivery at the destination. This is calculated as Epkt ¼ NintrasubnetEsubnet:hophsubnet þ NintersubnetEs whs w Nintersubnet þ Nintersubnet ; ð11Þ where Nintrasubnet and Nintersubnet are the total number of packets routed within the subnet and between the subnets, respectively, Esubnet;hop is the energy dissipated by a packet traversing a single hop on the wired subnet including a wired link and a switch, and Es w is the energy dissipated by a packet traversing a single hop on the second level of the mWNoC network, which has the small-world property. The average number of hops per packet in the subnet and the upper level small-world network are denoted by hsubnet and hs w , respectively. Fig. 16 shows the packet energy dissipation for the considered architectures under uniform random traffic. The energy dissipation for RF-I and CNT based interconnect is obtained from [14] and [4], respectively. The flat mesh architecture dissipates highest packet energy among all the NoCs considered. A hierarchical network reduces the average hop count, and hence, the latency between the cores compared to a flat mesh. Packets get routed faster and, hence, occupy resources for less time and dissipate significantly less energy compared to flat mesh in the process. In Fig. 17a, we show the variation of per bit energy dissipation with distance for a single wired and a mm-wave wireless link. Fig. 17b highlights the contributions of the different components of the packet energy dissipation for 256-core mWNoC and flat mesh architecture. The contributions of the antenna and the transceiver, which constitute the wireless link energy, are shown separately from the wireline links of the upper level small-world network. The largest contribution to packet energy in mWNoC is from the wireless and wireline link traversals combined in the upper level small-world network. This is because on an 2392 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 Fig. 18. Achievable bandwidth with different traffic scenarios. average a large portion of the packets travels through the upper level of the mWNoC to reach other subnets. However, as this level has very small average path length due to its small-world nature and due to the low-power wireless channels, the absolute value of this energy dissipation is small. It can be observed that the energy dissipation of the hierarchical NoC with metal wire shortcuts (BWNoC) is significantly more compared to the other NoC architectures (mWNoC, RFNoC, and THzNoC). This is because the energy dissipation in wireless and RF-I transm iss ion is much less compared to long me ta l wire interconnects. From Fig. 16, it can be observed that a 512-core hierarchical NoC with buffered wire shortcuts burns 12.79 times more energy yet achieves only 1.46 times more bandwidth compared to mWNoC. All three smallworld NoC architectures with emerging interconnect technologies, viz., mWNoC, RFNoC, and THzNoC dissipate significantly less packet energy than the other three alternatives. The THzNoC has the lowest packet energy dissipation and the difference in packet energy values between RFNoC and mWNoC is small. But RFNoC and THzNoC have their implementation challenges compared to mWNoC as mentioned earlier. Due to the high-energy dissipation, flat mesh, hierarchical NoC without shortcuts, and hierarchical NoC with multiple metal wire shortcuts are not considered for the subsequent analysis. The Mesh-StarRing architecture along with the routing mechanism elaborated in Section 4.3 results in 14.6 percent bandwidth improvement and 48 percent savings in packet energy for a 256-core system with six WIs in comparison with the previously proposed NoC architecture with mmwave wireless links [48] for the same system size. 5.7 Performance Evaluation with Nonuniform Traffic To eva luate the performance of the proposed NoC architecture with nonuniform traffic patterns, we considered both synthetic and application-based traffic distributions. In the following analysis, the system size considered is 256 (with 16 subnets and 16 cores per subnet) with six WIs as a representative case. We considered two types of synthetic traffic to evaluate the performance of the proposed mWNoC architecture. First, a transpose traffic pattern [7] is considered, where a certain number of cores are considered to communicate more frequently with each other. We considered three such pairs and 50 percent of packets originated from one of these cores are targeted toward the other in the pair. The other synthetic traffic pattern considered is hotspot traffic [7], Fig. 19. Achievable bandwidth for different NoCs with broadcast traffic. where each core communicates with a certain number of cores more frequently than with the others. We considered three such hotspot locations to which all other cores send 50 percent of the packets that originate from them. In both of these situations, the communicating cores are considered to be in different subnets so that the second level of the network is used in the data exchange. As an applicationbased traffic, a 512-point Fast Fourier Transform (FFT) is considered and each core is assigned to perform a 2-point radix 2 FFT computation. The traffic pattern generated in performing multiplication of two 256  256 matrices was also used to evaluate the performance of the mWNoC. Fig. 18 shows the achievable bandwidth for the different NoC architectures in nonuniform traffic scenarios. From the results, it is evident that for all the traffic patterns considered here the Mesh-StarRing architectures with efficient shortcuts performs very close to each other. The difference between achievable bandwidth of the NoCs considered here is small and follows the same trend for nonuniform traffic scenarios as we have seen for uniform traffic. Due to the presence of higher number of simultaneously operating shortcuts in THzNoC, it performs best in all the different traffic scenarios considered here. The performance of THzNoC is closely followed by RFNoC and mWNoC for all the traffic scenarios considered in this paper. 5.8 Performance Evaluation with Broadcast Traffic Though traditional NoC supports many concurrent transactions, they do not directly support broadcast. There exists a variety of SoC applications that require broadcast, for example, passing global states, managing and configuring the network, implementing cache coherency protocols, and so on. Due to the broadcasting capability of the mm-wave wireless channels, mWNoC is capable of incorporating broadcasting efficiently. Broadcasting can be implemented in the proposed mWNoC by employing the wireless links in broadcast mode. Fig. 19 shows the achievable bandwidth of mWNoC, RFNoC and THzNoC in presence of broadcast traffic for a 256-core system. The number of broadcast source and destinations are kept identical for all the NoCs under consideration. The results show that mWNoC performs better than RFNoC and THzNoC. Due to the inherent broadcasting capability of mWNoC, all the WIs can receive the broadcast at 16-Gbps data rate. This gives mWNoC higher overall bandwidth than RFNoC’s RF-I-based point to point shortcuts (6 Gbps each) and THzNoC’s point to point wireless shortcuts (10 Gbps each). Since all the WIs can receive the broadcast traffic at higher bandwidth, the overall performance of mWNoC is better in case of broadcast traffic scenario. DEB ET AL.: DESIGN OF AN ENERGY-EFFICIENT CMOS-COMPATIBLE NOC ARCHITECTURE WITH MILLIMETER-WAVE WIRELESS... 2393 Fig. 20. Antenna transmission gain (S21) for three nonoverlapping channels. 5.9 A mWNoC with Multiple Simultaneously Operating Channels The performance of mWNoCs can be significantly improved by optimally placing and using multiple simultaneously operating wireless shortcuts. The works of [23] and [24] have already discussed the feasibility and advantages of multichannel wireless interconnects in the NoC environment. We extended our single channel mWNoC design to mWNoC with three simultaneously operating channels. The antenna’s forward transmission gains (S21) obtained via simulations are shown in Fig. 20. We are able to obtain three different nonoverlapping channels with 3-dB bandwidths of 16 GHz and center frequencies of 31, 57.5, and 120 GHz, respectively. For optimum power efficiency, the quarter wave antennas use axial lengths of 0.73, 0.38, and 0.18 mm, respectively, in the silicon substrate. The antenna design ensures that signals outside the communication bandwidth for each channel are sufficiently attenuated to avoid interchannel interference. The wireless transceiver circuitry is designed and simulated using TSMC 65-nm CMOS process. Multiple nonoverlapping wireless channels are distributed among the hubs and the WIs sharing the same channel form a cluster. Since each channel is shared between relatively smaller number of WIs, the optimum number of WIs increases from a single channel case. The technique for finding out optimum number of WIs and SA-based optimization algorithm discussed in Section 3.2 are used for optimally distributing the WIs belonging to three different clusters. The WI clusters are equal in size and a single WI with transceivers of all frequencies acts as gateway between different clusters for intercluster wireless communication. For a 256-core (16 subnets with 16 cores per subnet) and 512-core (32 subnets with 16 cores per subnet) mWNoC, with three nonoverlapping wireless channels, the optimum number of WIs is found to be 7 (three clusters of two WIs each and a gateway) and 13 (three clusters of four WIs each and a gateway), respectively. The achievable bandwidths for 256-core and 512-core system mWNoCs with three simultaneously operating wireless channels, RFNoC and THzNoC is shown in Fig. 21. Since the performance improvements are more prominent in larger systems, results for 128-core systems are not shown here. It can be observed that the performance difference decreases considerably among these NoCs as the number of simultaneously operating wireless channels increases for the mWNoC. The mWNoC (three channels) performs better than RFNoC and the performance difference between THzNoC and mWNoC (three channels) is smaller than that with mWNoC with single channel. The fact that mWNoC can establish communication channel between any WI pair unlike RFNoC and THzNoC where fixed point to point communication links are assigned, also helps in achieving improved performance. Therefore, it can be concluded that mm-wave based long-range interconnects can be a viable and efficient alternative interconnect in future many core NoCs. The technological challenges of making mWNoC practically feasible are significantly lower than the THzNoC with CNT-based wireless links. 6 AREA OVERHEAD In this section, we quantify the area overhead due to the wireless deployment in the mWNoC. The antenna used is a 0.38-mm -long and 58-m wide zigzag antenna. The area of the transceiver circuits required per WI is the total area required for the OOK modulator/demodulator, LNA, PA, and VCO. The total area overhead per wireless transceiver turns out to be 0:3 mm2 for the selected frequency range. The digital part for each WI, which is very similar to a traditional wireline NoC switch, has an area overhead of 0:40 mm2 . Therefore, the total area overhead per hub with a WI (inclusive of transceiver and antenna) is determined to be 0:72 mm2 . Since the number of WIs is kept limited, the overall silicon area overhead is dominated by the wireline NoC switches. For example, in case of a 256 core mWNoC, six wireless transceivers consume only 4.8 percent of total silicon area overhead. The transceiver area overhead for RFNoC and THzNoC is obtained from [14] and [4], respectively. Total silicon area overheads for flat mesh, mWNoC, RFNoC, THzNoC, and BWNoC for a 256-core system are shown in Fig. 22. The required silicon areas are dominated by the NoC intrasubnet switches. The area overheads of the hubs along with the required transceivers (mWNoC, RFNoC, THzNoC) and buffers (BWNoC) are shown separately. The transceiver area overhead for mWNoC is marginally higher than RFNoC, THzNoC, and BWNoC. Fig. 21. Achievable bandwidth for NoCs with different interconnects. 2394 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 12, DECEMBER 2013 not require any new technology. Therefore, it can be concluded that mWNoC achieves the best performanceenergy-area-technological challenge tradeoff among all of the emerging interconnects compared in this paper. As part of this on-going investigation, we intend to establish a detailed performance benchmark for the proposed mWNoC with respect to other emerging NoC architectures, such as 3D and photonic NoCs. ACKNOWLEDGMENTS This work was supported in part by the US National Science Foundation (NSF) CAREER Grants (CCF-0845504 and ECCS-0845849) and the CRI Grant (CNS-1059289). "
2008,Contention-aware application mapping for Network-on-Chip communication architectures.,"In this paper, we analyze the impact of network contention on the application mapping for tile-based network-on-chip (NoC) architectures. Our main theoretical contribution consists of an integer linear programming (ILP) formulation of the contention-aware application mapping problem which aims at minimizing the inter-tile network contention. To solve the scalability problem caused by ILP formulation, we propose a linear programming (LP) approach followed by an mapping heuristic. Taken together, they provide near-optimal solutions while reducing the runtime significantly. Experimental results show that, compared to other existing mapping approaches based on communication energy minimization, our contention-aware mapping technique achieves a significant decrease in packet latency (and implicitly, a throughput increase) with a negligible communication energy overhead.",
2005,Application-specific network-on-chip architecture customization via long-range link insertion.,"Networks-on-chip (NoCs) represent a promising solution to complex on-chip communication problems. The NoC communication architectures considered so far are based on either completely regular or fully customized topologies. In this paper, we present a methodology to automatically synthesize an architecture where a few application-specific long-range links are inserted on top of a regular mesh network. This way, we can better exploit the benefits of both complete regularity and partial customization. Indeed, our experimental results show that inserting application-specific long-range links significantly increases the critical traffic workload at which the network state transits from a free to a congested regime. This, in turn, results in a significant reduction in the average packet latency and a major improvement in the network achievable throughput.","Application-Specific Network-on-Chip Architecture  Customization via Long-Range Link Insertion Umit Y. Ogras Radu Marculescu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA e-mail: uogras@ece.cmu.edu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA e-mail: radum@ece.cmu.edu Abstract Networks-on-Chip (NoCs) represent a promising solution to complex on-chip communication problems. The NoC communication architectures considered so far are based on either completely regular or fully customized topologies. In this paper, we present a methodology to automatically synthesize an architecture where a few application-specific long-range links are inserted on top of a regular mesh network. This way, we can better exploit the benefits of both complete regularity and partial customization. Indeed, our experimental results show that inserting application-specific long-range links significantly increases the critical traffic workload at which the network state transits from a free to a congested regime. This, in turn, results in a significant reduction in the average packet latency and a major improvement in the network achievable throughput. I. INTRODUCTION Continuous scaling of CMOS technology makes it possible to put many heterogeneous devices on a single chip. Largescale integration of these blocks onto a single chip calls for truly scalable Networks-on-Chip (NoC) communication architectures [1,2,3]. Regular NoC architectures based on grid-like (or 2D lattice) topologies provide well-controlled electrical parameters and reduced power consumption across the links. However, due to the lack of fast paths between remotely situated nodes, such architectures may suffer from long packet latencies. Indeed, having many hops between different communicating nodes, not only increases the message latency, but also increases the message blocking probability thus making the end-to-end packet latency more unpredictable. Consequently, such generic platforms may become easily less attractive for application-specific designs that need to guarantee a given level of performance.  On the other hand, fully customized topologies [8-11] can improve the overall network performance, but they distort the regularity of the grid structure. This results in links with widely varying lengths, performance and power consumption. Consequently, better logical connectivity comes at the expense of a penalty in the structured nature of the wiring which is anyway one of the main advantages offered by the regular on-chip networks [1]. In the extreme case, fully customized solutions may end up resembling ASIC-style designs where individual modules communicate by packet switching. Hence, the usual problems of cross-talk, timing closure, global wires etc. may undermine the overall gain obtainable through customization.  0-7803-9254-X/05/$20.00 ©2005 IEEE. 246 Figure 1. Illustration of adding long-range links to a 4x4 standard mesh network. Fortunately, these two extreme points in the design space (i.e. designs based on purely regular or completely customized topologies) are not the only solutions possible for NoC architectures. In fact, it is interesting to note that many technological, biological, and social networks are neither completely regular, nor irregular [14,15]. One can view these networks as a superposition of clustered nodes with short links and a collection of random long-range links that produce “shortcuts” among different regions of the network. Regular lattice networks with a number of additional random long-range links, similar to the one shown in Figure 1, can be used to model such networks [15]. This paper explores precisely the potential of using standard mesh networks in conjunction with a few additional longrange links to improve the performance of regular NoCs.  Inserting long-range links to regular architectures clearly reduces the average distance between remote nodes. However, inserting long-range links cannot be done randomly for NoCs because adding extra links has a more pronounced, yet barely studied, impact on the dynamic properties of the network, which are characterized by traffic congestion. At low traffic loads, the average packet latency exhibits a weak dependence on the traffic injection rate. However, when the traffic injection rate exceeds a critical value, the packet delivery times rise abruptly and  the network  throughput starts collapsing (Figure 2). The state of the network before congestion (i.e. the region on left hand side of the critical value) is the free state, while the state beyond the critical value (right hand side) is said to be the congested state. Finally, the transition from the free state to the congested one is known as phase transition region.  As it turns out, the phase transition in regular networks can be significantly delayed by introducing additional long-range links (see Figure 2) [16]. Due to the exponential increase in the latency beyond the critical point, even a small right hand shift uniform traffic. The packets in the network consist of a single atomic entity containing address information only. Also, due to the infinite buffer assumption, the authors do not deal with deadlock states explicitly.  In contrast to this prior work, we do consider wormhole routing with arbitrary flit sizes and network routers with bounded input buffers. Most importantly, instead of uniform traffic, we assume application-specific traffic patterns and present an algorithm which inserts the long-range links in a smart manner rather than randomly. Due to the bounded input buffers, additional long-range links may cause deadlock states. For this reason, we also present a deadlock-free routing algorithm that exploits the long-range links to achieve the desired performance boost. III. LONG-RANGE LINK INSERTION ALGORITHM We start by formulating the long-range link inserting problem. After that, we present the details of the solution following a top-down approach. A.  System model and basic assumptions The system of interest consists of a set T of  m n×  tiles interconnected by a 2D mesh network1. The tiles of the network (referred to as PEs) are populated with processing and/or storage elements that communicate with each other via the network. We do not make any assumption about the distribution of the packet injection rate into the network, but only consider the frequencies at which the PEs communicate with each other. Due to limited on-chip buffer resources and low latency requirements, it makes sense to assume wormhole switching for the network; the results derived here, however, are also applicable to packet- and virtual cut-through switching networks. Further, we do not assume any particular routing algorithm for the mesh network; the only requirement is that the underlying routing algorithm has to be deadlock-free and minimal. Deadlockfree property is desirable for on-chip networks for two reasons: First, implementing deadlock detection and recovery mechanisms is expensive in terms of silicon resources. Second, such mechanisms can cause unpredictable delays, which need to be avoided for most embedded applications.  After inserting the long-range links as explained in Section C, the routers without extra links simply use the default routing strategy. Since this default strategy cannot route the packets across the newly added links, we define a deadlock-free routing strategy which enables the use of the newly added longrange links (Section E).  B.  Problem formulation The communication volume between the PE located at tile i T∈  and the PE located at tile  j T∈  is denoted by Vij. We compute the frequency of communication, fij, between PEs i and j by normalizing the inter-tile communication volume as follows:     1. The following discussion assumes a 2D mesh but the proposed technique is applicable to other topologies for which a distance definition as in equations 6 and 7 (in Section III) exists.  Figure 2. Shift in the critical traffic load after the insertion of longrange links to a 6x6 mesh network under hotspot traffic (Section V). in the critical traffic value may result in orders of magnitude reduction for latency. Similarly, the achievable throughput grows with the right shift of the critical traffic value. This phenomenon is at the very heart of our optimization technique.  The main objective of our optimization technique is to boost the network performance (i.e. reduce the average packet latency and increase the network throughput) by maximizing the value of the critical traffic load via smart insertion of application-specific long-range links. To this end, our contribution is twofold:   • First, for a given application, we propose an algorithm that determines the most beneficial long-range links to be inserted in a mesh network.   • Second, we present a deadlock-free decentralized routing algorithm that exploits the long-range links to achieve the desired performance level.  The paper is organized as follows. Section II reviews related work. The proposed approach for smart link insertion is explained in Section III. Practical considerations in implementing long-range links are discussed in Section IV, while the experimental results appear in Section V. Finally, Section VI concludes the paper by summarizing our main contribution.  II. RELATED WORK The use of NoCs as a scalable communication architecture is discussed in [1,2,3]. Design methodologies for applicationspecific NoCs are discussed in [4-11]. Studies in [6,7] consider regular network topologies and present algorithms for application mapping under different routing strategies. On the other hand, fully customized communication architecture synthesis for a given application is addressed in [8,9,10].  To the best of our knowledge, the idea of optimizing a generic grid-like network with application-specific long-range links is first addressed in this paper. Previous work on a similar idea comes from the networks theory side and uses very idealistic assumptions. For instance, the authors of [16] investigate the effect of adding random links to mesh and torus networks under 247 ∀ i j p q , , , ∈ T     f i j = -------------------------(1) V i j ∑ p ∑ q p≠ Vp q 1– The addition of long-range links introduces an overhead due to the additional wires and repeaters1 connecting the wire segments to ensure the latency-insensitive operation. Hence, we need to model the cost of long-range links to have a measure of this overhead.  Without losing the generality, we measure the size of longrange links,  s l( ) , in multiples of basic link units which are identical to the regular links used in the mesh network. This is reasonable, since the long-range links consist of a number of standard links connected by repeaters, as shown in Figure 8. The number of repeaters required by a long-range link is given by  s l( ) . Consequently, the maximum amount of permissible overhead can be expressed as a multiple of the standard link segments that make up the long-range link. For example, a resource constraint of S means that only long-range links consisting of at most S units of standard links, total, can be added.  We can now state the application-specific long-range link insertion problem as follows:  Given  • fij  i j  • Maximum number of links that can be added, S  • Routing strategy for the mesh network, R Determine  • The set of long-range links to be added on top of the mesh network,  LS  • A deadlock-free routing strategy that governs the use of the newly added long-range links,  RL such that  T∈,∀ m a x λ c( )   s u b j e c t t o    l s l( ) S< ∑ L S∈ (2) λ c λ c where   is the critical load at which the network enters the congested phase. To give some intuition, the long-range links are added to maximize the critical traffic,  , subject to the total amount of available resources; that is, the phase transition region is delayed beyond the value a standard mesh network (of exactly same size) can offer. Maximizing   increases the achievable throughput and reduces the latency compared to the original critical load, as shown later in the experiments. Note that, the objective of inserting long-range links is by no means limited to maximizing  . Indeed, other objective functions (e.g. increased fault-tolerance, guaranteed service, etc.), can replace or augment the objective of maximizing   in order to take the full advantage of the inserted links. λ c λ c λ c C.  Iterative link addition algorithm We propose an efficient iterative algorithm that inserts the most beneficial long-range links to the current configuration of the network, provided that the available resources are not used up yet. The link insertion algorithm is summarized in Figure 3.  1. In our terminology, the repeaters act primarily as storage elements (like FIFO buffers), as explained in Section IV in more detail. 248 Figure 3. The flow of the long-range link insertion algorithm. The evaluation step is detailed in Section D. ) ( The algorithm starts with a standard mesh network and takes the communication frequencies between the network tiles, the default routing algorithm and the amount of resources allowed to use as inputs. Then, the algorithm selects all possible pairs of tiles (i.e.  C T 2,  pairs where  T  is the number of nodes in the network) and inserts links between them. After inserting each long-range link, the resulting network is evaluated to find out the gain obtained over the previous configuration. Since our goal is to maximize  , we compare different configurations in terms of critical traffic load as detailed in Section D. After the most beneficial long-range link is found, the information about this link is stored and the amount of utilized resources updated. For example, if a long-range link consisting of four equivalent segments of standard links is added, the utilization is incremented by four.  The procedure described above repeats until all available resources are used up. Once this happens, an architecture configuration file is generated. Then, the routing strategy governing the use of long-range links is produced and written to a routing configuration file, as described in Section E. λ c D.  Evaluation of the critical traffic value While the impact of routing strategy, switching techniques and network topology on the critical point have been studied via simulation [18], no work has been done to maximize the traffic critical value subject to resource constraints. The major obstacle in optimizing the critical load comes from the difficulty in modelling the variation of critical point as a function of the design decisions. Several theoreticians [16,17] estimate the criticality point using mean field models. However, unlike our work, these studies assume uniform traffic, infinite buffers, and the estimates are valid only for regular grids without long-range connections. The key idea of our contribution is to reduce the estimation of critical point of the network to just one parameter that can be computed analytically, much faster than simulation. This is important since using very accurate estimates obtained through simulation would be simply too costly to use within an optimization loop. The optimization goal can still be achieved using the simple parameter, as long as the comparison between two network configurations matches the one with the critical load.   λ c In the following, we relate   to the free packet delay (τ0) in the network, which can be efficiently computed. Let the number of messages in the network (at time t) be  N t( )  and the aggregated packet injection rate be  , i.e.  λ i , λ i : t h e i n j e c t i on rate o f t i l e i T∈ λ λ ∑= i T∈ In the free state (i.e. when  ), the network is in the steady-state, so the packet injection rate equals the packet ejection rate. As a result, we can equate the injection and ejection rates to obtain the following approximation:     λ λ c< λ ≈ ----------N a v e τa v e (3) = Na v e <N t( ) > where τave is the average time each packet spends in the network, and   is the average number of packets in the network. The exact value of τave is a function of the traffic injection rate, as well as topology, routing strategy, etc. While no exact analytical model is available in the literature, we observe that τave shows a weak dependence on the traffic injection rate when the network is in the free state. Hence, τ0 can be used to approximate τave. If we denote the average number of N c packets in the network, at the onset of the criticality, by  , we can write the following relation:  N c ------------a v e a v e (4) λ c ≈ τ 0 ⁄ ) = = a v e λ c λ c λ c a v e τ 0⁄ τ a v e λ c( λ N a v e τ a v e τ 0 ≤ λ c N c This approximation is also an upper bound for the critical load  , since  . We note that   follows also Little’s law. Indeed, other theoretical studies proposed to approximate   using mean field [16] and distance models [17] under uniform traffic. Given that the number of messages in the network, at the onset of the criticality, is bounded by its capacity,  N c , the critical traffic load   and the average packet latency are inversely proportional to each other. Indeed, if the average packet latency decreases, the phase transition point is delayed, as demonstrated in Figure 2, where the reduction in the latency is obtained due to the long-range links. Our optimization technique uses the relationship between   and τave to maximize the critical load. More specifically, we minimize τ0 which can be efficiently computed in the optimization loop, as opposed to   for which there is no known analytical result to date. Experimental Verification of the Equations 3 and 4 For completeness, we verified experimentally both Equation 3 and Equation 4, as shown in Figure 4. The dotted line shows the actual packet injection rate (λ), for reference. The solid line with the square marker is obtained for a  network under the hotspot traffic, as the ratio between the average number of packets in the network and the average packet delay at that particular injection rate. From these plots, it can be clearly seen that there is a good agreement between the actual value obtained through simulation and the one predicted by Equation 3 before entering the criticality. Since the network is not in steady-state beyond the critical traffic value, the Equation 3 does not hold for higher injection rates. As mentioned before, the exact value of the average packet delay at a given load,  , can only be found by simulation. The dashed τ λ( 8× λ c 8 ) 8x8 Mesh Network λ Nave / τave  Nave / τ0 e l c y c / s t e k c a p λ (packets/cycle) Figure 4. Experimental verification of Equation 3 and Equation 4 for a 8x8 mesh network. i j ) ) i≠ τ 0 (5) ∑ ) tr ( ∑= T∈,∀ f i j d i j,( line with triangular markers in Figure 4 illustrates the upper bound given in Equation 4. We observe that this expression provides a good approximation at lower data rates and holds the upper bound property. Computation of τ0 For arbitrary traffic patterns characterized by the communication frequencies fij  i j , τ0 can be written as  + + ts tw ) m a x t s + tw+( L ----W where  d i j,(  is the distance from routers i to router j, and tr, ts, tw are the is architectural parameters representing time to make the routing decision, traverse the switch and the link, respectively. Finally, L is the length of the packet, while W is the width of the network channel. For the standard mesh network, the Manhattan distance (dM) is used to compute  d i j,( , i.e.  dM i j,( = i x iy where subscripts x and y denote the x-y coordinates, respectively. For the routers with long-range links, an extended distance definition is needed in order to take the long-range connections into account. Hence, we use the following generalized definition:  jx– j y– (6) + ) ) ( ) )   d i j,( =   dM i j,( )        if no long-range link is attached to i m i n dM i j,( ) 1 +, dM k j,( )  if l i k,( )  exists In this equation, l(i,k) means that node i is connected to node k via a long-range link. The applicability of the distance definition is illustrated in Figure 5. Note that the distance computation does not require any global knowledge thus making the routing decision algorithm decentralized. (7) Figure 5. Illustration of distance definition (see Eqn. 7). 249 Interestingly enough, Equation 4 also confirms that the average number of hops between the nodes, a common performance metric, has indeed a positive impact on the dynamic behavior of the network. as being illegal, as in Figure 7. Therefore, we check whether or not the long-range links cause any of these prohibited turns. If it is legal to use a long-range link, then the packet is forwarded to this link. Otherwise, the default routing algorithm is employed.  E.  Routing strategy for long-range links The routers without any extra link use the default routing strategy. Defining a strategy for the routers with long-range links is a necessity dictated by two factors:   • Without a customized mechanism in place, the newly added long-range links cannot be utilized at all by the default routing strategy;  • Introducing long-range links may result in cycling dependencies. Therefore, arbitrary use of these links may result in deadlock states. The routing strategy proposed in this section tries to produce minimal paths towards the destination by utilizing the long-range links effectively, as shown in Figure 6. To this end, we first check whether or not there exists a long-range connection to the current router. If there is one, the distance to the destination with and without the long-range link is computed using Equation 7. It is interesting to note that we can obtain global improvements in the network dynamics by using local information only.  If a newly added long-range link produces a shorter distance to the destination, we check whether or not using this link may cause deadlock before accepting it as a viable route. In order to guarantee that using the newly added link does not cause a deadlock state, some limitations on the use of long-range links are introduced. We achieve deadlock-free operation by extending the turnmodel [13] to long-range links. More precisely, in the original turn model, one out of four possible turns is prohibited to avoid cyclic dependencies (Figure 7). However, unlike standard links, the long-range links can extend in two directions, such as NE, NW, etc. For this reason, one has to consider the rotation from middle directions, NE, NW, SE, SW to the main directions N, S, E and W. In the extended model, we arbitrarily chose the Sto-E, S-to-W, SE-to-E, SE-to-W, SW-to-E, and SW-to-W turns Figure 6. The description of the routing strategy. 250 Figure 7. Possible routing directions, basic and extended turn models. A long-range link may become a traffic attractor and jam the network earlier than the regular short links. For this reason, if the routing algorithm is not adaptive (as it is our case), one more check point is needed before assigning a traffic stream to a new link. For instance, by assessing the amount of traffic assigned to a long-range link, further traffic can be routed over the link only if it is not likely to become a bottleneck. IV. PRACTICAL CONSIDERATIONS We analyze next the implications of customizing the regular network architecture with long-range links on the actual design implementation.  A.  Implementation of long-range links In order to preserve the advantages of structured wiring, the long-range links are segmented into regular, fixed-length, network links connected by repeaters. The use of repeaters with buffering capabilities guarantees latency-insensitive operation, as discussed in [19]. Repeaters can be thought as simplified routers consisting of only two ports that accept an incoming flit, stores it in a FIFO buffer, and finally forwards it to the output port, as illustrated in Figure 8. If the depth of buffers in the repeaters is at least 2 flits, then the packets can be effectively pipelined to take the full advantage of the long-range links [20].  The final consideration in terms of implementation is the increased size of the routers with extra links due to increased number of ports (Figure 8). To measure the area overhead, we implemented routers with 5 and 6 ports using Verilog and synthesized them for a 1M gate Xilinx Virtex2 FPGA. The router with 5 ports utilizes 387 slices (about 7% of total resources), while the one with 6 ports utilizes 471 slices of the target device. We also synthesized a pure   mesh network, and a  mesh network with 4 long-range links and observed that the extra links induce about 10% area overhead. This overhead has to be taken into account, while computing the maximum number of long-range links that can be added to the regular mesh network. While there is no theoretical limitation imposed by our approach on the number of additional links a router can have, a maximum of one long-range link per router is used in our experiments. This way the regularity is minimally altered, while still providing significant improvements over the standard mesh networks, as explained in Section V. 4 4× 4 4× < < 2 α 3 The worst-case complexity of the technique, that is link insertion and routing table generation, is  O SNα  where . The run-time of the algorithm for the examples analyzed ranges from 0.14sec for a   network to less than half hour for a   network on a Pentium III machine with 768MB memory under Linux OS. 4 4× 8× 8 ( ) A.  Experiments with synthetic traffic workloads We first demonstrate the effectiveness of adding long-range links to standard mesh networks by using synthetic traffic inputs. Table 1 compares the critical traffic load, average packet latency and throughput at the edge of criticality under hotspot traffic pattern for   and   networks. For the hotspot traffic three nodes are selected arbitrarily to act as hotspot nodes. Each node in the network sends packets to these hotspot nodes with a higher probability compared to the remaining nodes.   Critical load Latency at the critical load 6 6× 4 4× (packet/cycle) (cycles) hotspot 4x4 hotspot 6x6 λM c 0.41 0.62 λL c 0.50 0.75 LM λM c ( ) L L λM c ( ) 196.9 224.5 34.4 38.2 Table 1: Critical load (packet/cycle) and latency comparison (cycles) for regular mesh (M) and mesh with long links (L). As shown in Table 1, inserting 4 long-range links (consisting of 10 short link segments) to a   network makes the phase transition region shift from 0.41 packet/cycle to 0.50 packet/cycle (the resulting network appears in Figure 1). Similarly, the average packet latency at 0.41 packet/cycle injection rate drops from 196.9 to 34.4 cycles. We also show the variation of the network throughput and average packet latency as a function of traffic injection rate using a much denser scale in Figure 9. 4 4× Hotspot Benchmark (a) (b) Figure 8. Implementation of the repeaters. Routers 1 and 3 are both connected by Router 2 (a), the underlying mesh network, and the inserted long-range link (b). B.  Energy-related considerations One can measure the energy consumption using the Ebit metric [12], defined as the energy required to transmit one bit of information from the source to the destination. Ebit is given by  E (8) + = E b i t EB b i t + Sb i t EL b i t ES b i t EL b i t EB b i t where  ,   and   represent the energy consumed by the interconnect, buffering and switching in the router, respectively. Analyzing the energy consumption before and after the insertion of long-range links shows that the proposed approach does not induce a significant penalty in the total communication energy consumption of the network. Indeed, since the longrange links consist of several regular links with repeaters between them (instead of routers), the link energy consumption stays approximately the same whether the traffic flows over the long-range link or over the original path provided by the mesh network. On the other hand, the energy consumption due to the switch and routing logic is greatly simplified in the repeater design compared to the original routers. This results in a reduction in the switching energy consumption. Finally, the routers with extra links will have slightly increased energy consumption due to the larger crossbar switch. We compared the energy consumption obtained by simulation before and after the insertion of the long-range links, for the traffic patterns reported in Section 6. We observed that the link and buffer energy consumptions increase about 2% after the insertion of long-range links, while the switch energy consumption drops about 7%, on average. The results show that the overall energy consumption increases by only about 1%.  V. EXPERIMENTAL RESULTS We present next an extensive experimental study involving a set of benchmarks with synthetic and real traffic patterns. The NoCs under study are simulated using an in-house cycle accurate C++-based NoC simulator developed specifically for this project. The simulator models the long-range links precisely as explained in Section IV. The configuration files describing the additional long-range links and the routing strategy for a given traffic pattern are generated using the proposed technique and supplied to the simulator as an input.  Figure 9. Traffic injection rate vs. average packet latency and network  throughput  for hotspot  traffic  is  shown. The improvement in terms of critical point and latency values at criticality are indicated on the plots. 251 6 6× Similar results have been obtained for a   grid, as shown in Table 1. In this case, the phase transition region shifts from 0.62 packet/cycle to 0.75 packet/cycle. Likewise, with the addition of long-range links, the average packet latency at 0.62 packet/cycle injection rate drops from 224.5 to 38.2 cycles.  Comparison with the torus network We also compared the performance of the proposed approach against that achievable with a torus network, which provides wrap around links added in a systematic manner. Our simulations show that application-specific insertion of only 4 long-range links, with an overhead of 12 extra standard link segments, provides 4% improvement in the critical traffic load compared to a   torus under hotspot traffic. Furthermore, the average packet latency at the critical point of the torus network, 0.48 packet/cycle, drops from 77.0 to 34.4 cycles. This significant gain is obtained over the standard torus network by utilizing only half of the additional links, since the extra links are inserted in a smart way considering the underlying application rather than blindly adding wrap-around channels. Scalability Analysis To evaluate the scalability of the proposed technique, we also performed experiments involving networks of sizes ranging from   to  . Figure 10 shows that the proposed technique results in consistent improvements when the network size scales up. For example, by inserting only 6 long-range links, consisting of 32 regular links in total, the critical load of a  network under hotspot traffic shifts from 1.18 packet/ cycle to 1.40 packet/cycle giving a 18.7% improvement. This result is similar to the gain obtained for smaller networks. Figure 10(a) also reveals that the critical traffic load grows with the network size due to the increase in the total bandwidth. Likewise, we observe consistent reduction in the average packet latency across different network sizes, as shown  in Figure 10(b). 10 10× 10 10× 4 4× 4 4× B.  Experiments involving real applications In this section, we evaluate the performance of the link insertion algorithm using two applications with realistic traffic: A 4x4 auto industry benchmark and a 5x5 telecom benchmark retrieved from E3S benchmark suite [21]. The variation of average packet latency and network throughput as a function of traffic injection rates for auto industry benchmark is given in Figure 11. These plots show that the insertion of long-range links shifts the critical traffic load from 0.29 packet/cycle to 0.33 packet/cycle resulting in a 13.6% improvement. Similarly, as shown in Table 2, we observe that the average packet latency for the network with long-range links is consistently lower compared to that of a pure mesh network. For instance, at 0.29 packet/cycle injection rate, the latency drops from 98.0 cycles to 30.3 cycles giving about 69.0% reduction.    Similar improvements have been observed for the telecom benchmark as shown in Figure 12. Specifically, the critical traffic load is delayed from 0.44 packet/cycle to 0.60 packet/cycle showing a 36.3% improvement due to the addition of longrange links. Likewise, the latency at 0.44 packet/cycle traffic injection rate drops from 73.1 cycles to 28.2 cycles (Table 2).  252 Figure 10. Scalability results. Performance of the proposed technique for larger network sizes. Comparison with the mesh network with extra buffers Implementation of long-range links requires buffers in the repeaters. To demonstrate that the savings are the result of using the long-range links, we also added extra amount of buffers to the corresponding channels of the pure mesh network, equal to the amount of buffers utilized for the long-range links. Table 2 summarizes the results for standard mesh network (M), standard mesh network with extra buffers (MB) and the network with long-range links (L). We observe that insertion of buffers improves the critical load by 3.5% for the auto industry benchmark. On the other hand, the corresponding improvement due to long-range links is 13.6% over initial mesh network and 10% over the mesh network with additional buffers. Likewise, we note that with the insertion of long-range links, the average packet latency reduces by 69% compared to the original value and 57.0% compared to the mesh network with extra buffers. Consistent results have been obtained for the synthetic traffic workloads mentioned in the previous section and for the telecom benchmark. Due to the limited space, we report only the results for telecom benchmark (Table 2). The results show that, with the addition of extra buffers, the critical traffic point shifts only from 0.44 packet/cycle to 0.46 packet/cycle. Inserting long-range links, on the other hand, shifts the critical point to 0.60 packet/cycle which is a huge improvement in the network capability. Similarly, the average packet latency obtained by the proposed technique is almost 1/3 of the latency provided by standard mesh and about 1/2 of the latency provided by mesh with extra buffers.  Critical load (packet/cycle) Latency at critical load (cycles) auto-indust M auto-indust MB auto-indust L telecom M telecom MB telecom L λ c 0.29 0.30 0.33 0.44 0.46 0.60 L λM c ( ) 98.0 70.5 30.3 73.1 56.0 28.2 Table 2: Critical load (packet/cycle) and latency (cycles) comparison for pure mesh (M), mesh with extra buffers (MB) and mesh with long links (L).   Figure 11. Traffic rate vs. packet latency and network throughput for auto industry benchmark.  Figure 12. Traffic injection rate vs. average packet latency and network throughput for telecom benchmark. VI. CONCLUSION AND FUTURE WORK We have presented a design methodology to insert application-specific long-range links to standard grid-like networks. It is analytically and experimentally demonstrated that insertion of long-range links has an important impact on the dynamics, as well as static properties of the network. Specifically, additional long-range links increase the critical traffic workload. We have also demonstrated that this increase means significant reduction in the average packet latency in the network, as well as improvement in the achievable throughput.  Our current work employs oblivious routing to utilize the long-range links. We plan to extend this work to employ adaptive routing instead. Other possible extensions include inserting long-range links for different objective functions such as faulttolerance and QoS operation.  Acknowledgements : This research is supported by Marco GSRC , NSF CCR-00-93104, and SRC 2004-HJ-1189. VII.  "
2007,Photonic NoC for DMA Communications in Chip Multiprocessors.,"As multicore architectures prevail in modern high- performance processor chip design, the communications bottleneck has begun to penetrate on-chip interconnects. With vastly growing numbers of cores and on-chip computation, a high-bandwidth, low-latency, and, perhaps most importantly, low-power communication infrastructure is critically required for next generation chip multiprocessors. Recent remarkable advances in silicon photonics and the integration of photonic elements with standard CMOS processes suggest the use of  <b xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">photonic</b>   <b xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">networks-on-chip</b> . In this paper we review the previously proposed architecture of a hybrid electronic/photonic NoC. We improve the former internally blocking switches by designing a non-blocking photonic switch, and we estimate the optical loss budget and area requirements of a practical NoC implementation based on the new switches. Additionally, we tackle one of the key performance challenges: the latency associated with setting-up photonic paths. Simulations show that the technique suggested can substantially reduce the latency and increase the effective bandwidth. Finally, we consider the DMA communication model in the context of the photonic network and evaluate the optimal DMA block size.",
2004,Design space exploration for optimizing on-chip communication architectures.,"Rapid growth in the complexity of system-on-chips is being accompanied by increasing volume and diversity of on-chip communication traffic, which in turn, is driving the development of advanced system-level communication architectures. While these architectures have the potential to improve system performance, they pose significant new challenges to the system designer, owing to the complex design space defined by the availability of numerous network topologies, communication protocols, and mapping alternatives for system communications. In this paper, we address the problem of mapping a system's communication requirements to a given communication architecture template. We illustrate the nature of the communication architecture design space, and describe an exploration methodology that uses efficient algorithms to help automate the process of mapping the system communications to the selected template. In addition, we demonstrate the importance of simultaneously optimizing the on-chip communication protocols in order to maximize system performance. Experiments conducted on example systems, including a cell forwarding unit of an ATM switch, indicate that the proposed techniques aid in automatically constructing communication architectures that have high performance. For the systems we considered, the solutions generated using our methodology had 53% superior performance (on average), over those based on conventional architectures and mapping approaches. The algorithms used in the proposed methodology are computationally efficient, and scale well with increasing communication architecture complexity.",
2012,CONNECT - re-examining conventional wisdom for designing nocs in the context of FPGAs.,"An FPGA is a peculiar hardware realization substrate in terms of the relative speed and cost of logic vs. wires vs. memory. In this paper, we present a Network-on-Chip (NoC) design study from the mindset of NoC as a synthesizable infrastructural element to support emerging System-on-Chip (SoC) applications on FPGAs. To support our study, we developed CONNECT, an NoC generator that can produce synthesizable RTL designs of FPGA-tuned multi-node NoCs of arbitrary topology. The CONNECT NoC architecture embodies a set of FPGA-motivated design principles that uniquely influence key NoC design decisions, such as topology, link width, router pipeline depth, network buffer sizing, and flow control. We evaluate CONNECT against a high-quality publicly available synthesizable RTL-level NoC design intended for ASICs. Our evaluation shows a significant gain in specializing NoC design decisions to FPGAs' unique mapping and operating characteristics. For example, in the case of a 4x4 mesh configuration evaluated using a set of synthetic traffic patterns, we obtain comparable or better performance than the state-of-the-art NoC while reducing logic resource cost by 58%, or alternatively, achieve 3-4x better performance for approximately the same logic resource usage. Finally, to demonstrate CONNECT's flexibility and extensive design space coverage, we also report synthesis and network performance results for several router configurations and for entire CONNECT networks.",
2006,The design and implementation of a low-latency on-chip network.,"Many of the issues that will be faced by the designers of multi-billion transistor chips may be alleviated by the presence of a flexible global communication infrastructure. In the short term, such a network will provide scalable chip-wide communication and ease the complexity of handling multi-cycle communications. In the long term, the network will become a primary tool for optimising power and data transfers and for scheduling computations. This paper details the design and implementation of a low-latency on-chip network. The network's speculative routers are in the best case able to route flits in a single clock cycle, helping to minimise on-chip communication latencies and maximise the effectiveness of buffering resources. Results from our 180nm test chip demonstrate an inter-router data transfer rate in excess of 16Gbit/s for each link. In the best case each router hop adds just 1 clock cycle to the final communication latency.","The Design and Implementation of a Low-Latency On-Chip Network Robert Mullins, Andrew West and Simon Moore Computer Laboratory, University of Cambridge Robert.Mullins@cl.cam.ac.uk Abstract— Many of the issues that will be faced by the designers of multi-billion transistor chips may be alleviated by the presence of a ﬂexible global communication infrastructure. In the short term, such a network will provide scalable chip-wide communication and ease the complexity of handling multi-cycle communications. In the long term, the network will become a primary tool for optimising power and data transfers and for scheduling computations. This paper details the design and implementation of a low-latency on-chip network. The network’s speculative routers are in the best case able to route ﬂits in a single clock cycle, helping to minimise on-chip communication latencies and maximise the effectiveness of buffering resources. Results from our 180nm test chip demonstrate an inter-router data transfer rate in excess of 16Gbit/s for each link. In the best case each router hop adds just 1 clock cycle to the ﬁnal communication latency. I . IN TRODUC T ION Transistor switching speeds are continually improved through scaling. Unfortunately, the impact of scaling on long wires is a negative one. This forces an increase in communication latencies and the energy required to communicate each bit of information. The growing disparity between communication and switching times will soon make the provision of a chip-wide communication infrastructure a central problem in achieving performance and power dissipation goals. The resulting shift in design trade-offs will lead to an era of “communication-centric” system design. While constant length global wires fail to scale well, the distance reachable in a single clock cycle in multiples of λ does remain essentially constant [7]. This allows the performance of designs of ﬁxed complexity to scale when ported to the next technology node. This observation leads to the concept of a scalable architecture composed of a number of tiles or modules of ﬁxed complexity. The performance of each tile scales as expected and additional performance is possible by adding tiles as scaling permits. Inter-tile communication is handled by an on-chip network which consumes only a few percent of the total chip area. The way in which such a system could scale is illustrated in Table I. In this example the die size is assumed to be ﬁxed at 256mm2 . Each tile contains around 11M transistors and the clock period is set to 16 FO4 delays. The table shows how the frequency, size (width) and number of tiles scale. The interconnect delay along one edge of a tile remains constant at around one clock cycle. delay may be calculated as 500ps ∗ Lgate (where Lgate is the The calculation of cycle time in Table I assumes one FO4 physical gate length as speciﬁed in [13]). The channel delays were estimated using results from [1], [7]. In all cases it should Technology Node 90nm 65nm 45nm 32nm No. of Tiles Width of Tile 32 2.8mm 64 2mm 128 1.4mm 256 1mm Tile Frequency 3.4GHz 5.0GHz 7.0GHz 13.0GHz PR ED IC T ED SCA L ING O F A G EN ER IC T I L E -BA S ED SY S T EM TABLE I be possible to traverse the channel between two routers in less than one clock cycle. Of course, if a longer clock period is employed a smaller number of larger tiles may be used. Such tile-based systems may implement arrays of homogeneous processor/cache tiles [9], [10], ﬁner-grain computing fabrics [14] or networks of heterogeneous IP blocks. Such approaches provide highly reconﬁgurable platforms for a wide range of performance hungry applications. The provision of an efﬁcient chip-wide dynamic on-chip network is fundamental in achieving performance goals, ﬂexibility and mitigating complexity in such systems. Packet-switched networks employing Virtual Channel (VC) ﬂow control have recently been proposed as one approach to implementing a chip-wide interconnection network [3]. Figure 1 illustrates the major components of a generic virtual-channel router. Packets gain access to a physical channel by ﬁrst obtaining a virtual-channel (VC allocation). Each of these virtual-channels has its own private input FIFO at the destination router allowing ﬂits1 from different packets to be sent in an interleaved manner. Access to a physical channel is now allocated on a cycle-by-cycle basis (switch allocation) amongst waiting ﬂits from any of the buffered packets which have been assigned a VC. This scheme improves both throughput and latency when compared to a simple wormhole routed network by allowing blocked packets to be bypassed. Particular classes of trafﬁc may be restricted to a subset of the available virtual-channels in order to provide QoS enhancements or circumvent message-dependent deadlocks. I I . S P ECU LAT IV E ROU T ER ARCH I T EC TUR E S The description of virtual-channel ﬂow control in Section I implies that VC allocation and switch allocation are performed sequentially. Peh and Dally [12] describe how this dependency may be relaxed if we speculate that a waiting packet will be successful in acquiring a VC. In this way both VC and switch allocation may be performed in parallel. In order to avoid a negative impact on performance, the 1A packet is composed of a number of ﬂits (ﬂow-control digits) Input Channel credit out Input Channel credit out VC identifier Routing Logic VC Allocator credits in V Switch Allocator VC Buffer Output Channel Output Channel Crossbar (P x P) Input Port Fig. 1. A Virtual-Channel Router switch allocator must prioritise non-speculative requests over speculative ones. This is achieved by implementing two switch allocators: one handling non-speculative requests from packets which have been allocated a VC and one for requests from packets awaiting VC allocation. We will refer to these as the high and low priority switch allocators respectively from this point onwards. Speculative requests are only granted for a particular output when no regular requests are present. In the case that a speculative request is granted we must ensure that the VC has in fact been allocated and buffer space exists downstream. Fortunately, such checks may be performed in parallel with crossbar traversal. I I I . S ING L E -CYC L E ROU T ER S The introduction of further speculative optimisations to reduce the router pipeline depth to a single pipeline stage was proposed in [11]. These optimisations almost completely remove any control overhead from the critical path. Both VC and switch allocation are now performed concurrently with the transport of ﬂits across the datapath and physical channel. The ability to make such optimisations is based on the following observations: if we assume that the network is heavily loaded it should be possible to make scheduling decisions accurately one clock cycle in advance. This is because all the information necessary to make such a decision is present when many packets are buffered. At the other extreme, when the network is very lightly loaded, we may assume that contention for a VC or physical channel is low. In this case it is also possible to schedule one cycle in advance by speculating that any new request for a VC or physical channel may be granted immediately. Simulation results predicted that for all intermediate throughputs the router sacriﬁces only a few percent of performance over a perfect single-cycle sequential scheme [11]. Figure 2 provides an outline of the single-cycle router architecture. In this scheme VC and switch allocation is effectively performed one cycle in advance and concurrently with the transport of ﬂits. Each allocator’s output is a set of grant-enable signals which are registered and used on the succeeding clock cycle to generate VC and switch allocation grant signals. The presence of buffered ﬂits allow resources to be scheduled one cycle in advance, in this case the asserted grant-enable signals correspond to the subset of requests to be granted on the next clock cycle. If it is not possible to schedule a particular VC or output in advance, a prediction is made that there will be only one subsequent request for the resource. In this case multiple grant-enable signals are set. This allows any request on the next clock cycle, for the resource in question, to be successful. Cases where multiple requests are made on the following clock cycle are detected by the abort logic described in Section III-A. Datapath control signals are produced early in the clock cycle by the “fast” logic blocks, simply by combining the output port requests from each buffered (or newly arrived) ﬂit and the registered grant-enable signals. The output port required by each ﬂit is known without the need to ﬁrst evaluate a routing function by performing this task in the previous router (look-ahead routing [6]). A. Abort Detection One issue which must be considered carefully is the case when our prediction that requests on the next clock cycle will not contend is subsequently proven false. Fortunately, to detect these abort cases we only need consider newly arrived ﬂits. If ﬂits were buffered on the previous clock cycle, speculation would not have been necessary. The abort logic associated with both VC and switch allocation consists mainly of a comparison between each of the output ports required by each new ﬂit2 . If we assume there are P -input ports this requires P (P − 1)/2 comparisons. The abort logic detects cases where we are speculating and two or more ﬂits requiring the same output port resource (physical link or VC) have arrived simultaneously. In these cases the allocation of the resource is blocked incurring a one clock cycle penalty. The correct scheduling of the resource takes place during this time and non-speculative grant-enable signals are generated for use on the following clock cycle. In order to use the simple abort logic described above some additional logic is required to account for one remaining corner case. This is the scenario when a tail ﬂit leaves an input buffer and exposes a new packet (buffered head ﬂit). As this packet can now request any output port it is possible it will contend with another such packet or newly arrived ﬂit. The solution adopted for such cases is to always stall such head ﬂits for one cycle to ensure they are handled properly by the switch and VC allocation logic and need no further special treatment. This has a negligible impact on performance. B. Calculating the next set of requests To enable the VC and switch allocators to produce accurate grant-enable signals for the next clock cycle they may be fed a set of requests that we know will be present on the next clock cycle. These may be calculated by considering available 2At most one new ﬂit may be received at each input port per clock cycle Switch Allocation Output VC status (blocked?) switch grant enables Switch Fast Switch Next Current switch allocation requests (A simple implem. passes the current reqs.) Switch Allocator High Priority Switch Allocator Low Priority Switch Allocator Speculatively Allocate If Necessary Next Buffered Flit’s Output Port, VC Alloc. Abort Signals, Blocked VCs Virtual Channel Allocation VC grant enables VC Fast VC Next Current VC alloc. requests (masked by NextFreeVC) Virtual Channel Allocator Speculatively Allocate If Necessary Switch Control Output VC status (blocked?) Output Port Channel Level Flow Control FSM NextFreeVC Free VC FIFO Tail Flits Return VC ID to Free List Permit? channel flow control signals Output Channel Input Port valid VC ID Reg. VC Flit Buffer Newly Allocated VC IDs input channel channel flow control signals New Flit’s output port requests New Flit’s VC IDs Where is  speculation taking place? Crossbar FIFO Empty? Abort Detection Flit Kill Logic Output VC status (blocked?) Newly Allocated VC IDs Fig. 2. A single-cycle speculative virtual-channel router architecture. When necessary the router is able to speculate that ﬂits arriving on the next clock cycle may be routed without contention. During switch allocation the router is also able to speculate on the successful acquisition of VCs by new packets and on the availability of buffer space at the ﬂit’s destination. information such as the current requests and those granted on the current cycle. Information about the next buffered ﬂit in each VC buffer may also be exploited. To ensure that the abort logic is the only place where we need to handle mispredictions, it is important that the set of requests output by the next request logic contains at least the requests from those ﬂits already buffered. Presenting additional requests, e.g. those granted on the current cycle, may reduce performance but will not cause the router to malfunction. If requests that are to be made by buffered ﬂits are not considered, grant-enable signals may be set speculatively enabling multiple buffered ﬂits to gain access to the same output (or VC). As only newly arrived ﬂits are considered by the abort logic, this problem would go unchecked. In the ﬁnal router implementation we chose to accurately calculate VC next requests using all the information available. In the case of the switch scheduler we simply used the current set of requests to schedule the switch for the next cycle. This provided a signiﬁcant improvement in cycle time with a small architectural performance penalty (see comparison between spec-fast and spec-accurate in Section V). The simpliﬁcation is aided by the fact that those switch requests recently granted have a low arbitration priority. C. Pipelining the use of VC state The use of VC status information provides an example of how internal control paths may be pipelined with only minor changes to the architecture. In order to reduce cycle time it was advantageous to pipeline the VC status data used by the switch allocation logic. By adding a pipelining register, the information provided to the switch allocator about which VC is blocked becomes more out-of-date. In order to ensure the quality of the switch schedule does not suffer signiﬁcantly the availability of both high- and low-priority switch allocators is exploited. If a request is associated with a VC that appears to be blocked it is steered to the low-priority allocator. Actual VC blocked status is checked when the ﬂit is selected for transport (in parallel with its journey to its output port). This sort of modiﬁcation is simpliﬁed by the way in which the architecture decouples scheduling from the datapath. The allocator’s task is simply to provide the best schedule it can for the next clock cycle with the information available. Final checks on the validity of the schedule are delayed until the schedule is applied. If advantageous, further pipelining of the control logic internally could be exploited without compromising the best case single cycle routing latency. This could involve further pipelining of the allocators themselves. IV. IM P L EM EN TAT ION The Lochside test chip consists of 16 trafﬁc generating tiles interconnected by a 4x4 mesh network. The chip is implemented in UMC’s L180 logic process (1.8V core, 0.18µm) with all aluminium interconnect. Tiles and routers are interconnected as shown in Figure 3. Each router is connected to its neighbour using two unidirectional 80-bit channels (64-bits of data and 16-bits of control information). Each of the router’s input ports support 4 virtual-channels and may buffer 4 ﬂits on each virtual-channel. The implementation is fully testable via traditional scan chain techniques. An on-chip PLL may be used to provide a clock source and is distributed to each tile using a simple hand-crafted H-tree. Alternatively, a Distributed Clock Generator (DCG) [5] may be selected as the global clock source. In both cases, tile level clock distribution was achieved by running a standard-cell clock tree synthesis tool. The vast majority of the design is implemented in a standard cell style. Exceptions include the DCG nodes and latch-based virtual-channel buffers which beneﬁted from a full-custom implementation. The ﬁnal router design was generated from a highly parameterised network router model that allows a range of router designs to be synthesized. The performance of the design is limited by our current PGA package (due to both thermal and bond-wire IR drop issues). This limits the performance when running all trafﬁc generators to around 250MHz. If only two random packet sources are enabled the maximum clock rate may be increased to 300MHz. Once a ﬂit is received at a router’s input port it may be allocated a virtual-channel and access to an output port, traverse the crossbar and arrive at the destination router in a single clock cycle (best case latency is simply one cycle per hop). At 250MHz each router is able to transfer data at a maximum rate of 16Gbits/s on each input and output link. V. R E SU LT S Each tile’s trafﬁc generator is able to produce a wide range of trafﬁc patterns. Trafﬁc destinations may be selected randomly or deterministically with control over packet length. Error detecting code and ﬂit ordering checks are also performed at each tile. Each tile maintains statistics on the number of packets sent and received, together with the timing information necessary to calculate average latency and throughput. Each tile is able to inject trafﬁc at a controlled rate into a tile output queue. Packets injected into this queue when it is full may be counted. The conﬁguration system also provides the necessary control logic in order to synchronise the execution of commands at each tile, e.g. in order to start and stop all tiles simultaneously. Figure 5 shows the recorded average packet latency versus measured throughput for our 4x4 mesh network. For each experiment 16K packets were sent to uniformly distributed destinations from each tile. Curves are plotted for a range of ﬁxed packet lengths. Experiments which resulted in the tile output queue becoming full and generated packets being dropped are not plotted. A. Performance The router was synthesized to operate at 200MHz under worst case PVT operating conditions (around 35 FO4 including clocking overhead). If the speculative scheduling optimisations are removed but VC and switch allocation is still performed in parallel, the clock period is extended by a factor of 1.65. It may be noted that the optimised router does 64+16 bit Channel Traffic Generator Router Pull−Up DCG Node Pull−Down DCG Node Distributed Clock Generator (DCG) Network Fig. 3. Block Diagram of the Lochside Chip ’sequential’ ’spec-accurate’ ’spec-fast’  30  25  20  15  10  5 ) l s e c y c k c o c l t s a f c e p s n i ( y c n e t a L e g a r e v A  0  0  0.05  0.1  0.15  0.2  0.25  0.3 Throughput (flits/node/clock cycle)  0.35  0.4  0.45 Fig. 6. Latency/Throughput comparison for three router architectures. Latency is scaled to account for differences in each router’s cycle time. 256-bits (4 ﬂits). In our ﬁnal design the switch allocation critical path is composed of the following delays: input register, steering and buffering switch request to allocator, (53%) switch allocation, (15%) selecting speculative or non-speculative switch allocator result and speculatively setting grant-enables if necessary. The performance achieved by this implementation closely tracks that predicted by earlier router simulation models. (32%) B. Area A 4x4 mesh network is not really practical for the size of our test chip or its technology. The small tile size is dominated by the area of each router (more than two thirds of a tile’s area is taken by the network). However, if we move to the next technology node (130nm) and imagine a larger chip (4x4 array of 3mm x 3mm tiles) synthesis results have shown that the network area overhead is reduced to only 5 − 6%. This overhead would drop even further if the scaling in Table I was adopted. The area overhead of the speculative single-cycle architecture is small at around 8%. This compares the area of two single cycle routers one with our optimisations and one without. If the unoptimised case was pipelined, the difference in area would fall as registers would be required to buffer intermediate results. V I . R E LAT ED WORK Our implementation compares favourably to other on-chip network designs and implementations published to date. Comparable networks which have been implemented include the Philips Æthereal network-on-chip [4] and the RAW processor’s dynamic networks [14]. The Philips team report a similar peak link bandwidth of 16Gbit/s while operating at 500MHz in a 130nm process. Control decisions are actually taken at 166MHz. The router differs from ours in its ability to offer guaranteed services by reserving consecutive Fig. 4. Lochside Die Micrograph. Die size is 5mm x 5mm. The chip contains approximately 5 million transistors. ’8’ ’6’ ’4’ ’2’ ’1’ Packet Length  30  25  20  15  10  5 ) l s e c y c k c o c l ( y c n e t a L e g a r e v A  0  0  0.05  0.1  0.15  0.2  0.25 Throughput (flits/node/clock cycle)  0.3  0.35  0.4 Fig. 5. Latency versus throughput measured from test-chip for a range of packet lengths. not quite achieve a speedup equal to the reduction in clock cycle time. This is due to our router producing a slightly inferior routing and VC allocation schedule as a result of the approximations exploited to reduce cycle time. It is not, as may be expected, directly as a consequence of VC and switch aborts. The number of aborts is in fact consistently very low. Overall our speculative scheduling optimisations reduce average communication latency by a factor of 1.3 to 1.6. Figure 6 plots latency against throughput for three router architectures: (spec-fast) full speculation with no switch next request logic, (spec-accurate) full speculation with accurate switch next request logic and (sequential) concurrent switch and VC allocation followed by switch traversal in the same clock cycle. Each architecture was synthesized to calculate its minimum clock period and the latency ﬁgures scaled to account for these differences. The clock period results were, 30, 41 and 50 FO4 delays respectively (including 2 FO4 of clock uncertainty). The packet length in these experiments was                 routing slots in consecutive routers. Virtual-channels are not supported for improving the performance of best-effort trafﬁc. RAW’s dynamic networks operate at 225 MHz (worst-case PVT). In this case the whole network is duplicated in preference to exploiting virtual-channels. The RAW processor was implemented using IBM’s 180nm 6LM ASIC copper process Other research projects include Netchip [8] which aims to automatically generate application-speciﬁc on-chip networks. The authors emphasise the need to maintain a high switch operating frequency and adopt a deeply pipelined architecture (7-stage router). Unfortunately this signiﬁcantly increases buffering requirements by extending round-trip time. It also incurs a signiﬁcant overhead in terms of the additional pipelining registers required. Even if a very short clock period of less than 10 FO4 is possible, best case communication latencies would still be more than double that of our current single cycle design. A study of virtual-channel router implementations undertaken by Peh and Dally [12] suggests that an on-chip network typically requires 3 pipeline stages operating at a clock frequency of 20 FO4. While our actual switch and VC allocator implementations offer improvements over the published delay models, clocking and test overheads and internal buffering delays extend our clock period to around 35 FO4 in the ﬁnal implementation. Improvements to the input port logic to reduce this delay are ongoing. Even at 35 FO4 our network’s best case latency would be nearly half that of their reported pipelined design. A. Global Synchronisation The speculative techniques at the heart of our router exploit the presence of a global clock. Global synchronisation offers regular snapshots of state and ensures the system proceeds in a deterministic fasion. This simpliﬁes the implementation of the speculative scheduling mechanisms and ensures abort detection and handling mispredictions is relatively simple. The cost of providing a low-skew high-frequency global clock is in both its complexity and the power it consumes. In many designs this cost may be considered to be too high. This has prompted asynchronous on-chip interconnect techniques to be investigated [2], [15]. While such approaches are promising, it is also possible to make similar trade-offs while retaining a synchronous router implementation. The ﬁrst approach is to exploit known relationships between router clock signals while relaxing global synchronisation. Examples include source-synchronous communication and the use of clock predictive synchronisers. Global synchronisation may be relaxed further by generating clock pulses locally on demand or in a data-driven manner. This allows each router to operate at a rate dictated by the data it is transporting. This both reduces synchronisation overheads and provides a simple high-level approach to clock gating. Work in this area is ongoing. Techniques such as the DCG [5] may also be employed as previously discussed. V I I . CONC LU S ION This paper has detailed the design of an on-chip network which can provide an efﬁcient global communications infrastructure for future gigascale ICs. A speculative architecture is able to accurately produce datapath control signals one cycle in advance of their use. This enables both datapath and control logic to operate concurrently providing signiﬁcant latency improvements over previously published work. A number of trade-offs between cycle time and speculation accuracy have also been introduced and evaluated. The optimisations proposed are orthogonal to other well known techniques for boosting performance such as adaptive routing and are independent of the network topology selected. ACKNOW L EDG EM EN T S This work is supported by EPSRC (grant GR/L86326) and the Cambridge-MIT Institute. "
2010,A 201.4 GOPS 496 mW Real-Time Multi-Object Recognition Processor With Bio-Inspired Neural Perception Engine.,"A 201.4 GOPS real-time multi-object recognition processor is presented with a three-stage pipelined architecture. Visual perception based multi-object recognition algorithm is applied to give multiple attentions to multiple objects in the input image. For human-like multi-object perception, a neural perception engine is proposed with biologically inspired neural networks and fuzzy logic circuits. In the proposed hardware architecture, three recognition tasks (visual perception, descriptor generation, and object decision) are directly mapped to the neural perception engine, 16 SIMD processors including 128 processing elements, and decision processor, respectively, and executed in the pipeline to maximize throughput of the object recognition. For efficient task pipelining, proposed task/power manager balances the execution times of the three stages based on intelligent workload estimations. In addition, a 118.4 GB/s multi-casting network-on-chip is proposed for communication architecture with incorporating overall 21 IP blocks. For low-power object recognition, workload-aware dynamic power management is performed in chip-level. The 49 mm <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>  chip is fabricated in a 0.13 ¿m 8-metal CMOS process and contains 3.7 M gates and 396 KB on-chip SRAM. It achieves 60 frame/sec multi-object recognition up to 10 different objects for VGA (640 × 480) video input while dissipating 496 mW at 1.2 V. The obtained 8.2 mJ/frame energy efficiency is 3.2 times higher than the state-of-the-art recognition processor.",
2010,Dynamic Task Mapping for MPSoCs.,"Multiprocessor-system-on-a-chip (MPSoC) applications can consist of a varying number of simultaneous tasks and can change even after system design, enforcing a scenario that requires the use of dynamic task mapping. This article investigates dynamic task-mapping heuristics targeting reduction of network congestion in network-on-chip (NoC)-based MPSoCs. The proposed heuristics achieve up to 31% smaller channel load and up to 22% smaller packet latency than other heuristics.",
2015,"Noxim - An open, extensible and cycle-accurate network on chip simulator.","Emerging on-chip communication technologies like wireless Networks-on-Chip (WiNoCs) have been proposed as candidate solutions for addressing the scalability limitations of conventional multi-hop NoC architectures. In a WiNoC, a subset of network nodes are equipped with a wireless interface which allows them long-range communication in a single hop. This paper presents Noxim, an open, configurable, extendible, cycle-accurate NoC simulator developed in SystemC which allows to analyze the performance and power figures of both conventional wired NoC and emerging WiNoC architectures.",
2003,Bringing communication networks on a chip - test and verification implications.,"In this article we present test and verification challenges for system chips that utilize on-chip networks. These SOCs and networks on a chip are introduced, where the NOC is exemplified by Philips' AE THEREAL NOC architecture. We discuss existing test and verification methods for SOCs and NOCs, and show the particular advantages of using an NOC for both testing and verifying the network, and testing and verifying the other components of the SOC. This article is concluded with our experiences with NOCs and a description of ongoing work within Philips in this emerging field.",
2006,A Low-Cost Solution for Protecting IPs Against Scan-Based Side-Channel Attacks.,"Scan designs used for testing also provide an easily accessible port for hacking. In this paper, we present a new low-cost secure scan design that is effective against scan-based side-channel attacks. By integrating a test key into test vectors that are scanned into the chip, testing and accessing scan chains are guaranteed to be allowed only by an authorized user. Any attempt to use the scan chain without a verified test vector will result in a randomized output preventing potential side-channel attacks. The proposed technique has a negligible area overhead, has no negative impact on chip performance, and places several levels of security over the scan chain protecting it from potential attacks",
2005,Virtual channels in networks on chip - implementation and evaluation on hermes NoC.,"Networks on chip (NoCs) draw on concepts inherited from distributed systems and computer networks subject areas to interconnect IP cores in a structured and scalable way. Congestion in NoCs reduces the overall system performance. This effect is particularly strong in networks where a single buffer is associated with each input channel, which simplifies router design, but prevents packets from sharing a physical channel at any given instant of time. The goal of this work is to describe the implementation of a mechanism to reduce performance penalization due to packet concurrence for network resources in NoCs. One way to reduce congestion is to multiplex a physical channel using virtual channels (VCs). VCs reduce latency and increase network throughput. The insertion of VCs also enables to implement policies for allocating the physical channel bandwidth, which enables to support quality of service (QoS) in applications. This paper has two main contributions. The first is the detailed implementation of a NoC router with a parameterizable number of VCs. The second is the evaluation of latency and throughput in reasonably sized instances of the Hermes NoC (8x8 mesh), with and without VCs. Additionally, the paper compares the features of the proposed router with others employing VCs. Results show that NoCs with VCs accept higher injections rates w.r.t. NoCs without VCs, with a small standard deviation in the latency values, guaranteeing precise packet latency estimation.",
2009,A Low-power Low-cost Optical Router for Optical Networks-on-Chip in Multiprocessor Systems-on-Chip.,"Networks-on-chip (NoCs) can improve the communication bandwidth and power efficiency of multiprocessor systems-on-chip (MPSoC). However, traditional metallic interconnects consume significant amount of power to deliver even higher communication bandwidth required in the near future. Optical NoCs are based on optical interconnects and optical routers, and have significant bandwidth and power advantages. This paper proposed a high-performance low-power low-cost optical router, Cygnus, for optical NoCs. Cygnus is non-blocking and based on silicon microresonators. We compared Cygnus with other microresonator-based routers, and analyzed their power consumption, optical power insertion loss, and the number of microresonators used in detail. The results show that Cygnus has the lowest power consumption and losses, and requires the lowest number of microresonators. For example, Cygnus has 50% less power consumption, 51% less optical power insertion loss, and 20% less microresonators than the optimized traditional optical crossbar router. Comparing to a high-performance 45nm electronic router, Cygnus consumes 96% less power. Moreover, the passive routing feature of Cygnus guarantees that, while using dimension order routing algorithm, the maximum power consumption to route a packet through a network is a small constant number, regardless of the network size. For example, the maximum power consumption is 4.80fJ/bit under current technologies. We simulated and analyzed an 8 times 8 2D mesh NoC built from Cygnus and showed the end-to-end delay and network throughput under different offered loads and packet sizes.",
2005,An automated technique for topology and route generation of application specific on-chip interconnection networks.,"Network-on-chip (NoC) has been proposed as a solution to the communication challenges of system-on-chip (SoC) design in nanoscale technologies. Application specific SoC design offers the opportunity for incorporating custom NoC architectures that are more suitable for a particular application, and do not necessarily conform to regular topologies. Custom NoC design in nanoscale technologies must address performance requirements, power consumption and physical layout considerations. This paper presents a novel three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisfies the performance and architectural constraints. We present an analysis of the quality of the results of the proposed technique by experimentation with realistic benchmarks.","An Automated Technique for Topology and Route Generation of Application Speciﬁc On-Chip Interconnection Networks Krishnan Srinivasan, Karam S. Chatha, and Goran Konjevod Department of CSE, PO BOX 875406, Arizona State University, Tempe, AZ 85287-5406 Email: (cid:0)ksrinivasan,kchatha,goran(cid:1)@asu.edu Abstract— Network-on-chip (NoC)) has been proposed as a solution to the communication challenges of System-on-chip (SoC) design in nanoscale technologies. Application speciﬁc SoC design offers the opportunity for incorporating custom NoC architectures that are more suitable for a particular application, and do not necessarily conform to regular topologies. Custom NoC design in nanoscale technologies must address performance requirements, power consumption and physical layout considerations. This paper presents a novel three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisﬁes the performance and architectural constraints. We present an analysis of the quality of the results of the proposed technique by experimentation with realistic benchmarks. I . INTRODUCT ION On-chip interconnection networks or Networks-on-Chip (NoC) have been proposed as a solution for addressing the global communication challenges in System-on-Chip architectures that are implemented in nanoscale technologies [1] [2]. An example of the NoC architecture is shown in the right hand side of Figure 1. The ﬁgure depicts a physical layout of an example SoC architecture. The various square blocks with labels (P1, P2, and so on) denote processing or storage cores. The black ﬁlled boxes denote routers that are connected by physical links. Application speciﬁc SoC design offers the opportunity for incorporating custom NoC architectures that are optimized for the target problem domain, and do not necessarily conform to regular topologies. Regular topologies are suitable for general purpose architectures such as the MIT RAW [3] that include homogeneous cores. Application speciﬁc SoC architectures consist of heterogeneous cores and memory elements which have vastly different sizes. For such architectures, the custom NoC architecture has been demonstrated to be superior to regular architecture in terms of power, area and performance by Jalabert et. al. [4]. This paper concentrates on the design of custom NoC topologies that are optimized for the target application. The design of custom NoC architectures poses several challenges to the designer. The interconnection architecture must provide sufﬁcient bandwidth for low latency congestion free P2 P5 P7 P3 {B, L] P1 P4 P6 [H, W] P1 P4 P2 P5 P3 P6 P7 Fig. 1. Application Speciﬁc NoC Design Problem communication between the various units in the architecture. Power reduction has emerged as a ﬁrst order design goal in nanoscale technologies. Hence, the designer must aim to minimize the power consumption for on-chip communication in the interconnection architecture. Due to technology scaling, the physical links consume upwards of 30 % of the total communication power. The power consumption in the physical links is linearly dependent on their length. Therefore, custom NoC design must include physical layout information. The custom NoC design problem is depicted in Figure 1. The input to the problem is the system-level speciﬁcation described by a directed communication trace graph in which the nodes represent various computation and storage elements, and edges denote communication between two units. The nodes include physical dimension information (height and width, H and W in the ﬁgure) about the processing and storage elements, and edges are annotated with bandwidth and latency requirements (B and L in the ﬁgure). The output of the custom NoC design stage (shown in the right side of the ﬁgure) is a physical layout aware topology and a unique route for every edge in the system-level speciﬁcation that satisﬁes the performance requirements, and minimizes the power (primary goal) and area (secondary goal) of the interconnection architecture. This paper presents an automated technique for solving the custom NoC design problem. Automated design of custom NoC architectures requires a characterized library of interconnection network building blocks. We characterized the power consumption of the unit router in 100 nm technology with the help of a cycle accurate power and performance evaluator [5]. In the interest of space, we have omitted the complete details of the experiments. The variation of power consumption with injection rate for the input and output ports of a router are shown in Figures 2 0-7803-9254-X/05/$20.00 ©2005 IEEE. 231 0.00E+00 2.00E-01 4.00E-01 6.00E-01 8.00E-01 1.00E+00 1.20E+00 1.40E+00 1.60E+00 1.80E+00 0 0.01 0.02 0.03 0.04 Injection Rate (packets/cycle) 0.05 0.06 I u p n t o P t r o P w e r ( W m ) Fig. 2. Input port power consumption 0.00E+00 5.00E-02 1.00E-01 1.50E-01 2.00E-01 2.50E-01 3.00E-01 3.50E-01 4.00E-01 0 0.01 0.02 0.03 0.04 0.05 Cumulative Injection Rate (packets/cycle) 0.06 0.07 O u t u p t o P t r o P w e r ( W m ) Fig. 3. Output port power consumption 0.00E+00 2.00E-01 4.00E-01 6.00E-01 8.00E-01 1.00E+00 1.20E+00 0 0.01 0.02 0.03 0.04 0.05 Cumulative Injection Rate (packets/cycle) 0.06 0.07 o P k n L i w e r ( W m ) Link Length = 2500 um Fig. 4. Link power versus injection rate 3.00E-01 1.00E+03 4.00E-01 5.00E-01 6.00E-01 7.00E-01 8.00E-01 1.50E+03 2.00E+03 2.50E+03 Link Length (um) 3.00E+03 3.50E+03 o P k n L i w e r ( W ) Injection Rate = 0.0089 Fig. 5. Link power versus length 0 200 400 600 800 1000 1200 1400 1600 0 0.01 0.02 0.03 0.04 Injection rate (packets/cycle) 0.05 0.06 0.07 a L t y c n e ( s e c y c l ) Latency Fig. 6. Latency for 2 routers 0 200 400 600 800 1000 1200 1400 0 0.01 0.02 0.03 0.04 0.05 Injection rate (packets/cycle/node) 0.06 0.07 a L t y c n e ( s e c y c l ) Latency Fig. 7. Latency for 4x4 mesh and 3, respectively. The power consumption of the input and output ports vary linearly with the injection rates, respectively. Quantitatively, we estimated the power consumption of the input port as (cid:0)(cid:1)(cid:2)(cid:1)(cid:2) (cid:4), and (cid:3)(cid:4)(cid:7)(cid:4)(cid:1)(cid:2) (cid:4) for the output port. We studied the variation of link power with respect to the bandwidth ﬂowing on the link, and its length. Figure 4 plots the variation of link power with the supported bandwidth. Figure 5 plots the variation of link power with its length. The power consumption of the physical links varies linearly with both the supported bandwidth, and the length of the link. We estimated the power consumption of the links to be equal to (cid:5)(cid:6)(cid:7)(cid:6)(cid:1)(cid:2) (cid:4)(cid:2). The variation of average latency for data packets that travel over two router hops with respect to injection rate is shown in Figure 6. The average latency remains almost constant in the un-congested mode, and onset of congestion is marked by a sharp increase in latency. As shown in Figure 7, a similar trend is observed for average latencies of packets in a 4x4 mesh. Our technique prevents network congestion by static routing of the communication traces subject to the peak bandwidth constraint on the router ports. Since the network is always operated in the un-congested mode, we can represent the network latency constraint in terms of router hops (such as 1 or 2) instead of an absolute number (such as 100 cycles). In the following section we deﬁne the NoC design problem. A. Problem Deﬁnition Given: (cid:0) A directed communication trace graph (cid:9)(cid:10) (cid:11) (cid:12) , where each (cid:13)(cid:0) (cid:0) (cid:10) denotes either a processing element or a memory unit (henceforth called a node), and the directed edge (cid:14)(cid:1) (cid:9) (cid:1)(cid:13)(cid:0) (cid:11) (cid:13)(cid:2) (cid:2) (cid:0) (cid:12) denotes a communication trace from (cid:13)(cid:0) to (cid:13)(cid:2) . For every (cid:13)(cid:0) (cid:0) (cid:10) , the height and width of the core is denoted by  (cid:0) and (cid:4)(cid:0) , respectively. (cid:0) For every (cid:14)(cid:1) (cid:9) (cid:1)(cid:13)(cid:0) (cid:11) (cid:13)(cid:2) (cid:2) (cid:0) (cid:12) , (cid:15)(cid:14)(cid:1)  denotes the bandwidth requirement in bits per cycle, and (cid:16)(cid:14)(cid:1)  denotes the latency constraint in hops. (cid:0) A router architecture, where (cid:10) denotes the peak input and output bandwidth that the router can support on any one port. Thus, each port of a router can support equal bandwidth in input and output modes. Since a node (cid:13) (cid:0) (cid:10) is attached to a port of a router, the bandwidth to any node from a router, and from any node to a router is less than (cid:10). Two quantities 	(cid:0) and 	 that denote the power consumed per  (cid:4) of trafﬁc bandwidth ﬂowing in the input and output direction, respectively for any port of the router. (cid:0) A physical link power model denoted by 	  per  (cid:4) per . Let (cid:5) denote the set of routers utilized in the synthesized architecture, (cid:12) represent the set of links between two routers, and (cid:12)(cid:6) represent the set of links between routers and nodes. The objective of the NoC design problem is to generate a system-level ﬂoorplan, and a network topology (cid:17) (cid:5)(cid:11) (cid:10) (cid:11) (cid:12) (cid:11) (cid:12)(cid:6) , such that: (cid:0) for every (cid:14)(cid:1) (cid:9) (cid:13)(cid:0) (cid:11) (cid:13)(cid:2)  (cid:0) (cid:12) ,  (cid:9)(cid:1)(cid:13)(cid:0) (cid:11) (cid:0) (cid:11) (cid:0) (cid:11) (cid:2) (cid:11) (cid:7) (cid:7) (cid:7) (cid:1) (cid:11) (cid:13)(cid:2) (cid:2) in (cid:17) that satisﬁes (cid:15)(cid:14)(cid:1) , and (cid:16)(cid:14)(cid:1) , there exists a route (cid:0) the bandwidth constraints on the ports of the routers are satisﬁed, and (cid:0) the total system-level power consumption for inter-core communication is minimized (primary goal), and number of router resources is minimized (secondary goal). In the above problem formulation we assume that the maximum physical link length that permits single clock cycle data transfer between neighboring routers is denoted by the 232                         maximum dimension (  (cid:13) or (cid:1) (cid:13)) of a node in the systemlevel speciﬁcation. This assumption is based on the fact that it is possible to perform intra-core single clock cycle data transfer from one corner of node to the any of the neighboring corners. We also consider that the dimensions of the routers are much lower than the sizes of the cores. This assumption is supported by the observation of Dally et al. [1] that the entire NoC places an area overhead of 6.6% on the SoC architecture. Therefore, we assume that the routers that are possibly utilized in the layout are located at corners of the cores. If (cid:20) (cid:13)(cid:11) (cid:21) (cid:13) denotes the lower left hand side corner of the node, the core is mapped to one of the routers located at (cid:20) (cid:13)(cid:11) (cid:21) (cid:13), (cid:20) (cid:13)  (cid:4)(cid:6) (cid:11) (cid:21) (cid:13), (cid:20) (cid:13)(cid:11) (cid:21) (cid:13)   (cid:6)  or (cid:20) (cid:13)  (cid:4)(cid:6) (cid:11) (cid:21) (cid:13)   (cid:6) . The power consumption of the NoC can be minimized by minimizing the cumulative trafﬁc ﬂowing through the ports of all routers. Trafﬁc ﬂowing in a network can be reduced by placing communicating cores close to each other. However, the close location of the communicating cores must be traded-off with the latency constraints. The latency constraints imposed by the trafﬁc traces specify the maximum number of hops allowed for the trace. Bandwidth requirements and latency constraints of communication traces can be viewed as mutually independent. A trace such as a signalling event or a cache miss is not expected to have high bandwidth requirement, but is bound by tight latency constraints. On the other hand, many non-critical multimedia streams have high bandwidth requirement, and their latency is bound only by the period constraint of the application [6]. A NoC design framework has to perform a trade-off between placing communicating cores with high bandwidth, and those with tight latency close to each other to minimize power, and to satisfy the performance constraints, respectively. The NoC synthesis problem as described above is a variation of the generalized steiner forest problem that is known to be NP hard [7]. We present a three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisﬁes the performance and architectural constraints. The paper is organized as follows: in Section II we discuss previous work, in Section III we present our technique, in Section IV we discuss our experimental results, and ﬁnally in Section V we conclude the paper. I I . PREV IOU S WORK Many researchers [8] [9] [10] [11] have presented core mapping and routing techniques for mesh based NoC architectures. Recently, researchers have begun to address the problem of automated design of application speciﬁc NoC architectures. Pinto et al. [12] presented a technique for constraint driven communication architecture synthesis of point to point links by utilizing deterministic heuristic based k-way merging. Their technique results in network topologies that have only two routers between each source and sink. Hence, their problem formulation does not address routing. In [6], Murali et al. C1 B C2 A C5 C C4 D C3 E C6 (A) C7 C8 F V H H V V V V A B C D E F Fig. 8. CTG Fig. 9. Slicing Tree A D A D A B E X B Y E C F C F B C Y D E F B (A) (B) (C) Fig. 10. Initial Floorplanner D F A C E (D) presented a technique that integrates physical planning with quality of service. However, they do not address synthesis of custom NoC topologies. We on the other hand, synthesize an application speciﬁc custom topology optimized for the target application. Further, they propose a computationally complex solution for the problem, where they iteratively invoke an MILP based placement technique in a tabu search framework. In contrast, we present polynomial time algorithms for integrated ﬂoorplanning, and topology synthesis of application speciﬁc custom NoC architectures. I I I . SYNTHE S I S O F CU S TOM NOC ARCH IT ECTURE S In this section, we present our application speciﬁc onchip interconnection architecture synthesis technique. Our technique operates in three phases. In the ﬁrst phase, it invokes a performance aware slicing tree based ﬂoorplanner to obtain an initial physical layout of the nodes constituting the SoC. In the second phase, the technique invokes a linear programming (LP) based algorithm that maps the processing cores to different routers such that the power utilized for communication is minimized. Finally, in the third phase, it executes a LP based routing algorithm that generates routes for the traces such that the total number of routers utilized in the topology are minimized. In the following sections, we will discuss each phase in detail. A. Initial Floorplanner We utilize a slicing tree based initial ﬂoorplanner (IF) described in [13]. In this paper, we present an overview of the technique, and refer the reader to [13] for further details. Unlike [13], we do not add extra nodes. Figures 8, 9, and 10 give examples of an input CTG, slicing tree, and various stages of the algorithm execution, respectively. The slicing tree is formed by recursively dividing the layout area into vertical and horizontal sections. In Figure 9, the letter (cid:10) denotes that the plane is divided into a left and right sub-plane by a vertical cut, and the letter   denotes that the plane is divided into top and bottom sub-planes by a horizontal cut. IF invokes a graph equicut algorithm proposed by Fiduccia and Mattheyses (FM) [14] to generate the partitions. The partitioning technique assigns nodes to one of the sub-planes such that the total weight of the edges across the cut is minimized. IF assigns a weight to each edge as follows. Bandwidth constraints on the ports of routers can be satisﬁed 233 (cid:9)(cid:8)(cid:0) (cid:1) (cid:6) (cid:7)(cid:8)(cid:2)  (cid:7)(cid:8)(cid:0)  by ﬁnding alternative (sometimes longer) route for the trace. Latency constraints on the other hand cannot be adhered to by ﬁnding alternative paths. Therefore, IF gives higher priority to latency compared to bandwidth. Let (cid:14)(cid:0) be a trace with the highest bandwidth requirement among all traces in the graph. Let (cid:14)(cid:2) be the trace with tightest (lowest) latency constraint among all traces in the graph. IF determines an integer (cid:22) such that it is the minimum value required to ensure that (cid:9)(cid:8)(cid:2) (cid:1) . Once (cid:22) is determined, IF assigns an edge weight to each edge given by (cid:7)(cid:14) (cid:0) (cid:12) (cid:11) (cid:23)(cid:14) (cid:9) (cid:7)(cid:8) (cid:9)(cid:8)(cid:1) . For two edges with the same edge weight, the one with tighter latency has higher priority. This heuristic ensures that traces with low bandwidth requirements, but with tight latency constraints are given priority over those with high bandwidth requirement and relaxed latency constraints. After the ﬂoorplan is generated, our technique invokes a compaction algorithm that takes the actual sizes of the processing cores into account and generates a ﬁnal layout. The compaction stage is required as we utilize a slicing tree based ﬂoorplanning algorithm. The slicing tree based heuristic assigns the nodes to bounding boxes at rectangular grid locations. As the size of the bounding box is typically larger than the size of the node, we require a compaction stage. The compaction algorithm ﬁrst moves all nodes toward the center of the layout in the X direction, and then moves all nodes in the Y direction, again toward the center of the layout. The movement in X and Y directions is repeated until no further compaction is possible. B. Core to router mapping technique In this section, we present a linear programming based technique called CMT that maps each processing or storage core to one router that is located at the corners of the core. We present a lower bound on the optimal solution, and utilize a randomized rounding algorithm to arrive at the optimal (or near optimal) solution. For node (cid:24), let (cid:25)(cid:0) denote the set of routers to which (cid:24) can be mapped. Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) (cid:0) (cid:25)(cid:0) , else 0. Each node is mapped to one of the routers located at its four corners. Therefore, there are (cid:13)  (cid:9)(cid:10) (cid:9) variables of this type. For each edge (cid:24)(cid:11) (cid:22) let (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  denote the communication cost when node (cid:24) is assigned to router (cid:26) and node (cid:22) is assigned to router  . The cost denotes the power consumed to perform this communication. Therefore, (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:15)(cid:0)(cid:10)(cid:1)  (cid:29)(cid:24)(cid:2)(cid:10)  where (cid:15)(cid:0)(cid:10)(cid:1) is the bandwidth requirement of the edge (cid:24)(cid:11) (cid:22), and (cid:29)(cid:24)(cid:2)(cid:10)  is the Manhattan distance between routers (cid:26) and  . Let vector (cid:20) (cid:14)(cid:13)  (cid:9)(cid:10) (cid:9) (cid:15) (cid:16)(cid:17) denote the possible assignments of nodes to different routers, and matrix (cid:31)(cid:14)(cid:13)  (cid:9)(cid:10) (cid:9)  (cid:13)  (cid:9)(cid:10) (cid:9)(cid:17) (with elements (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0) (cid:31)) denote the costs of the various mappings. The problem is to obtain an assignment of the nodes such that the total communication cost is minimized. The problem is a special case of the quadratic assignment problem (QP) and can be expressed mathematically as follows. (cid:24)(cid:24)(cid:24) (cid:14) (cid:20) (cid:11) (cid:31)(cid:20) ! 	(cid:4)(cid:26) (cid:14)#  (cid:7)(cid:24) (cid:0) (cid:10) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:2)(cid:1)(cid:12)(cid:0) where (cid:25)(cid:0) denotes the set of routers that node (cid:24) can be mapped to. The constraints enforce the requirement that each node is mapped to exactly one router. QP is among the hardest problems to solve in combinatorics. It is well known that the formulation presented above cannot be solved in polynomial time unless the matrix (cid:31) is positive semi-deﬁnite. In other words, in order for the QP to be polynomial time solvable, all determinants of the principal submatrices of (cid:31) should be nonnegative [15]. In matrix (cid:31), the diagonal elements indicate the communication cost from a node to itself, and therefore, are zero. Hence, (cid:31) is not positive semi-deﬁnite. One way to make the QP polynomial time solvable is to increase the cost of the diagonal elements of (cid:31) by some value % to make the matrix positive semi-deﬁnite, solving the QP, and ﬁnally subtracting % obtain the ﬁnal solution. But this can result in sub-optimal solutions for the QP [15]. The objective function of QP with constant % added to the diagonal elements is of the form (cid:0) (cid:0)(cid:10)(cid:2) (cid:1)(cid:13) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:20)(cid:1)(cid:10)   (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)   %  (cid:0) (cid:0)(cid:1)(cid:14) (cid:0) (cid:20) (cid:2) (cid:0)(cid:10)(cid:2) (cid:2) (cid:2)(cid:12)(cid:0) (cid:2) ((cid:9) (cid:3) (cid:3) If % is large, the square terms dominate the objective function, and therefore, the minimizer would tend to assign values close to (cid:4) for the stated problem) to the variables (cid:20)(cid:0)(cid:10)(cid:2) . Hence, a randomized rounding scheme that assigns a variable (cid:20)(cid:0)(cid:10)(cid:2) to 1 with probability (cid:20)(cid:0)(cid:10)(cid:2) , will assign node (cid:24) to any of the four routers with almost the same probability, and may not perform well. We are interested in the integer solution of the QP. Since even the continuous version (where variables can take fractional values) is hard to solve, we formulate the integer version as an integer linear program (ILP). An ILP in general is not polynomial time solvable unless  (cid:9)   . Therefore, we relax the integer constraints on the ILP, and solve the problem as an LP. An optimal solution to any linear program can be generated in time polynomial in the number of variables and constraints [16]. Noting that the integer versions of the QP and LP solve the same problem, we apply a randomized rounding technique on the QP by rounding a variable to 1 with a probability given by the value assigned to the variable by the LP. 1) ILP Formulation: In this section, we present our ILP formulation for the quadratic assignment problem. We give a unique number to each node. For each node (cid:24), let (cid:25)(cid:0) (cid:9) (cid:1)(cid:0)(cid:5) (cid:11) (cid:0)(cid:3) (cid:11) (cid:0)(cid:2) (cid:11) (cid:0)(cid:6) (cid:2) denote the set of routers to which (cid:24) can be mapped. Variables We deﬁne the following variables. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) (cid:0) (cid:25)(cid:0) , else 0. There are (cid:13)  (cid:9)(cid:10) (cid:9) variables of this type in the formulation. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) , and node (cid:22) is mapped to router  , else 0. We deﬁne these variables only when 234 (cid:24)(cid:11) (cid:22) (cid:0) (cid:12) or (cid:22) (cid:11) (cid:24) (cid:0) (cid:12) . Hence, there are (cid:16)(cid:3)  (cid:9)(cid:12) (cid:9) The overall expected cost of the solutions is given by variables of this type. Objective Function The objective is to minimize the total communication cost. It can be expressed as follows.  (cid:24)(cid:24)(cid:24) (cid:14) ( (cid:9) (cid:0) (cid:0) (cid:0) (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)   (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)(cid:1)(cid:12)(cid:0)  (cid:1)(cid:12)(cid:1) where (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  is the product of the bandwidth of the trafﬁc for edge (cid:24)(cid:11) (cid:22), and the Manhattan distance between routers (cid:26) and  . We can represent (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  as (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:15)(cid:0)(cid:10)(cid:1)  (cid:29)(cid:24)(cid:2)(cid:10)  where (cid:15)(cid:0)(cid:10)(cid:1) is the bandwidth requirement of the edge (cid:24)(cid:11) (cid:22), and (cid:29)(cid:24)(cid:2)(cid:10)  is the Manhattan distance between routers (cid:26) and  . Note that the objective function is deﬁned only for node pairs that have an edge between them. Constraints (cid:0) Each node should be mapped to exactly one router. This constraint can be modeled as follows. (cid:7)(cid:24) (cid:0) (cid:10) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:2)(cid:1)(cid:12)(cid:0) (cid:0) The variable (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  represents node (cid:24) mapped to router (cid:26) , and node (cid:22) mapped to router  . Therefore, if node (cid:24) is mapped to router (cid:26) , all communication should take place through that router. This condition is represented by the following two equations. (cid:7)(cid:24)(cid:11) (cid:22) (cid:0) (cid:12) (cid:11) (cid:7)(cid:26) (cid:0) (cid:25)(cid:0) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:1)(cid:12)(cid:1) (cid:7)(cid:24)(cid:11) (cid:22) (cid:0) (cid:12) (cid:11) (cid:7)  (cid:0) (cid:25)(cid:1) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:20)(cid:1)(cid:10)  (cid:2)(cid:1)(cid:12)(cid:0) C. Discussion We show with the help of lemmas that a randomized rounding technique can be successfully applied to obtain near optimal solutions. Lemma 1: The optimal solutions of the integer versions LP and QP have the same cost. Proof: Let us denote the integer versions of the problems as ILP and IQP, respectively. We note that the ILP and IQP solve the same problem, and therefore, the cost of their optimal solutions will be the same. Lemma 2: The expectation of the integer solution generated by randomized rounding of the variables of the QP with probability equal to the value of the variable in the solution is equal to the cost of solution generated by QP. Proof: Let the cost of the solution of QP be denoted as (	 , and the cost of the integer version of QP be denoted as (	 . Consider an experiment of picking one router (cid:26) among the four routers placed in the corners of node (cid:13)(cid:0) , with a probability (cid:20)(cid:0)(cid:10)(cid:2) . For an edge (cid:24)(cid:11) (cid:26)  (cid:0) (cid:12) , the cost of mapping nodes (cid:24) and (cid:26) is given by (cid:12) (cid:14)( (cid:0)(cid:10)(cid:2) 	 (cid:17) (cid:9) (cid:0) (cid:0)  (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:1)  (cid:20)(cid:1)  (cid:9) (cid:16)  (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:2)   (cid:12) (cid:14)(	 (cid:17) (cid:9) (cid:0) (cid:0) (cid:0)  (cid:20)(cid:0)(cid:2) (cid:9) (cid:16) (cid:1)  (cid:20)(cid:1)  (cid:9) (cid:16)  (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)   Noting that the probabilities are independent and (cid:20)(cid:0)(cid:10)(cid:2) is set to 1 with probability (cid:20)(cid:0)(cid:10)(cid:2) , we get (cid:12) (cid:14)(	 (cid:17) (cid:9) (cid:0) (cid:0) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:20)(cid:1)(cid:10)   (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (	 (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)   The lemma proves that there is some feasible assignment of the nodes to routers such that the cost of the solution and that of the infeasible optimal solution obtained by relaxing the integer constraints is the same. Let this optimal feasible solution be represented by (  	 . Let the cost of the LP be denoted as ( , and the cost of the ILP be denoted as (  . From the above argument, it follows that ( (cid:6) (	 (cid:9) (  	 (cid:9) (    Lemma 3: Let ((cid:19)	 represent the cost of the solution obtained by adding a constant % to the diagonals of matrix (cid:31) to make it positive semi-deﬁnite. Then, (	 (cid:12) ((cid:19)	  (cid:9)(cid:10) (cid:9)% . Proof: From Lemma 2, We also know that (  	 (cid:9) (	 (   (cid:19)	 (cid:12) ((cid:19)	 In the optimal integer solution, one and only one (cid:20)(cid:0)(cid:10)(cid:2) per node (cid:24) is set to one. The remaining variables are set to zero. Therefore, ( (cid:19)	 is minimized only when the ﬁrst part of the sum in the objective function is minimized. But the ﬁrst part represents (	 . Therefore, (   (cid:19)	 (cid:9) (  	  %  (cid:9)(cid:10) (cid:9) Now, since (   (cid:19)	 (cid:12) ((cid:19)	 , and (  	 (cid:9) (	 , (	 (cid:12) ((cid:19)	   (cid:9)(cid:10) (cid:9)  % . Therefore, we can solve for ((cid:19)	 in polynomial time, and obtain a lower bound on (	 . From Lemma 2, this gives us a lower bound on the expected value of the integer solution. To obtain an integer solution with a cost given by the lower bound, we utilize the randomized rounding technique. 1) Randomized rounding: Based on the LP formulation, we present a randomized rounding algorithm using (	 as a lower bound. The algorithm iteratively assigns routers to nodes with probability given by the value of the corresponding variable ((cid:20)(cid:0)(cid:10)(cid:2) ), until the number of iterations is maximum, or an optimal solution is found. Once the exit criterion is satisﬁed, the algorithm returns the best solution found thus far. 235 2) Merging routers: At the end of the ﬂoorplanning and mapping phases, the architecture may have routers that are placed very close to each other. In order to eliminate redundant routers and also to reduce the complexity of the routing stage, we merge pairs of routers that are less than a certain distance apart. The distance is speciﬁed by the designer, and can be set to the maximum permitted link length for single clock cycle data transfer. Our merging algorithm checks all pairs of available routers and merges two routers if (cid:0) the distance between them is less than the maximum allowable distance under single clock cycle data transfer, and (cid:0) merging the two routers does not cause a violation of the single clock cycle data transfer for any other router. D. Routing Technique In this section, we present RT, a linear programming based algorithm for routing communication traces such that the total number of routers utilized in the topology is minimized. The problem is a variation of the rectilinear steiner arborescence problem which is known to be NP-Complete [17]. Our heuristic models the problem as an LP formulation, and employs a randomized rounding technique to arrive at the ﬁnal solution. In the following paragraphs, we discuss our technique in detail. Variables: We deﬁne the following variables. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0 1) variable that is set to 1 if the router at location (cid:24)(cid:11) (cid:26)  is selected for routing. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1) denote a (0 1) variable that is set to 1 if edge (cid:22) utilizes router at location (cid:24)(cid:11) (cid:26)  for routing. The number of variables of this type is equal to the product of the number of edges and the number of (cid:20)(cid:0)(cid:10)(cid:2) variables. Objective: The objective is to minimize the number of routers. The objective can be expressed as  (cid:24)(cid:24)(cid:24) (cid:14) ( (cid:9) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) Constraints: For each edge in the CTG, consider a bounding box on the layout deﬁned by the location of the source and sink nodes. The bounding box for the communication trace speciﬁes the routers that can be utilized for routing with the shortest Manhattan path length. For edge (cid:14), let the bounding box be denoted as )(cid:8) . (cid:0) An edge in CTG always passes through the source and sink routers. For edge (cid:14), let  denote the source node, and  denote the sink node. Let the location of the router that connects to  be ((cid:24)(cid:11) (cid:26) ), and the location of the router that connects with  be ((cid:22) (cid:11)  ). The following two equalities must hold. (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:8) (cid:9) (cid:16)(cid:11) (cid:20)(cid:1)(cid:10) (cid:10)(cid:8) (cid:9) (cid:16) (cid:0) If a router at location (cid:24)(cid:11) (cid:26)  is utilized to route an edge (cid:14), at least one of its adjacent routers that is closer to the sink node, should also be utilized in the route. Assuming that router (cid:20)(cid:0)(cid:10)(cid:2) is considered, and locations that take the router close to sink are (cid:20)(cid:0)(cid:10)(cid:2)(cid:3)(cid:10)(cid:8) , and (cid:20)(cid:0)(cid:3)(cid:10)(cid:2)(cid:10)(cid:8) , we need the following inequality. (cid:7)(cid:24)(cid:11) (cid:26) (cid:0) )(cid:8) (cid:11) (cid:20)(cid:0)(cid:10)(cid:2)(cid:3)(cid:10)(cid:8)  (cid:20)(cid:0)(cid:3)(cid:10)(cid:2)(cid:10)(cid:8)   (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:8) (cid:12) (cid:18) SPR (tbd trace list) for t (cid:1) tbd trace list for e (cid:1)  /* For all physical links in  */ if ((cid:7)(cid:8)  (cid:7) (cid:21) (cid:8)) /* BW violation */ edge weight(e) = (cid:4) else edge weight(e) = 1 end if end for shortest path((cid:10)  (cid:10) (cid:5)) end for end Fig. 11. Shortest path router Benchmark Nodes Edges dsp 263 encoder mp3 encoder mpeg4 mwd vopd mp3 enc mp3 dec 263 dec mp3 dec 263 enc mp3 enc 263 enc 263 dec 6 7 8 12 12 12 13 14 15 16 5 7 8 13 13 13 12 12 17 17 Power ((cid:3)(cid:4) ) 1686 172.6 6.48 7392.18 993.6 2611.1 9.15 11.98 181.6 159.5 Routers 2 2 3 5 3 5 4 5 4 5 TABLE I R E S U LT S (cid:0) If a router is utilized to route an edge, it should be present in the ﬁnal solution. Therefore, (cid:7)(cid:22) (cid:11) (cid:20)(cid:0)(cid:10)(cid:2) (cid:12) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1) The objective function makes sure that if a router is not utilized in routing any edge, the corresponding (cid:20)(cid:0)(cid:10)(cid:2) will be set to zero. 1) Randomized rounding technique: The randomized rounding technique operates as follows. Initially, we solve the LP, and ﬁx all (cid:20)(cid:0)(cid:10)(cid:2) variables that are assigned a value 1. Among the variables that have fractional values, we randomly pick a variable, and assign it to 1 with a probability given by the fractional value of the variable. The LP is solved again and the randomized rounding step is repeated until all variables are either set to 0 or 1. At the end of the routing phase, there might be links that violate bandwidth constraints. We un-map the traces with minimum bandwidth requirement from these links, and reroute them by invoking Dijkstra’s shortest path algorithm. The re-routing technique is described in the following paragraph. 2) Shortest path router: The shortest path router (SPR) is called for each trafﬁc trace that is unmapped at the end of RT phase. SPR attempts to ﬁnd alternate routes for these traces. For each trace in (cid:4)(cid:29) (cid:27)#(cid:14)  (cid:24), SPR sweeps all possible links  of the physical layout grid. It assigns an edge weight of (cid:14) to all links that would see a bandwidth violation on the ports constituting the links, if the trace was routed through that link. These links are not utilized to generate the route for the trace. This step is followed by calling Dijkstra’s shortest path algorithm to ﬁnd a route for the trace on the mesh. IV. RE SULT S We present and analyze the experimental results obtained by execution of our technique on representative multimedia applications. We ﬁrst discuss the benchmark applications, the 236 vu 0.5 190 au 60 600 mem 1 910 mem2 32 670 upsp 0.5 dsp cpu 600 rast 40 mem 3 193 bab idct 250 500 risc Fig. 12. MPEG 4 decoder CTG risc dct mem 3 dsp bab au rast upsp cpu mem 1 vu mem 2 Fig. 13. Floorplan and NoC architecture experimental setup, and ﬁnally, we present and discuss the results. A. Benchmark applications We generated custom NoC architectures for six combinations of four multimedia benchmarks namely, mp3 audio encoder, mp3 audio decoder, H.263 video encoder, and H.263 video decoder. The applications were obtained from the work presented by Hu et al. [11]. In addition, we obtained results for four other benchmarks namely, mpeg4 decoder, video object plane decoder (vopd), multi-window display (mwd), and DSP ﬁlter application (dsp). The mpeg4 decoder, vopd, and mwd applications were obtained from [4], and the dsp application was obtained from [9]. B. Experimental setup We estimated the power consumption for the input and output trafﬁc of a port in 100  technology to be (cid:0)(cid:1)(cid:2)(cid:1)(cid:2) (cid:4) and (cid:3)(cid:4)(cid:7)(cid:4)(cid:1)(cid:2) (cid:4), respectively. We estimated the link power consumption to be equal to (cid:5)(cid:6)(cid:7)(cid:6)(cid:1)(cid:2) (cid:4)(cid:2). All results were obtained on a 950 MHz dual sparc processor. We utilized the XPRESS-MP solver [18] to generate our LP solutions. C. Results and discussion The LP formulations of CMT technique generated integer solutions for all benchmarks. Since the solution generated by LP is less than or equal to the that generated by the integer version, we conclude that the integer solutions generated by our CMT formulations are optimal. The solutions of the RT formulation required at most 3 iterations of rounding to generate the ﬁnal design. The results are presented in Table I. In the table, the ﬁrst column describes the benchmark application, the second and third columns present the size of the benchmark in terms of nodes and edges respectively, the fourth column presents the power consumption of the NoC, and the ﬁfth column presents the number of routers in the solution. An LP formulation can be solved in polynomial time, and in all our test cases, the LP generated results in fraction of a second. The communication trace graph for MPEG4 decoder is shown in Figure 12. In the graph, the nodes denote processing cores, and the edges are annotated by bandwidth requirement in Mbps. Figure 13 shows the physical layout and NoC architecture for the MPEG4 decoder application. V. CONCLU S ION In this paper, we proposed a novel three phase automated ﬂoorplanning and synthesis technique for generation of application speciﬁc custom on-chip interconnection architectures. Our technique utilizes a low complexity slicing tree based ﬂoorplanner, and linear programming based techniques for core to router mapping and routing of communication traces. Our linear programming based techniques are able to generate optimal results for node to router mapping stage. We demonstrated that the complexity of our techniques is low, and as stated in the results section, the techniques are able to generate solutions in less than a second. ACKNOWL EDGEMENT The research presented in this paper was supported in part by a grant from the National Science Foundation (IIS0308268) and Consortium of Embedded Systems "
2010,Throughput-Effective On-Chip Networks for Manycore Accelerators.,"As the number of cores and threads in manycore compute accelerators such as Graphics Processing Units (GPU) increases, so does the importance of on-chip interconnection network design. This paper explores throughput-effective network-on-chips (NoC) for future manycore accelerators that employ bulk-synchronous parallel (BSP) programming models such as CUDA and OpenCL. A hardware optimization is ""throughput-effective"" if it improves parallel application level performance per unit chip area. We evaluate performance of future looking workloads using detailed closed-loop simulations modeling compute nodes, NoC and the DRAM memory system. We start from a mesh design with bisection bandwidth balanced with off-chip demand. Accelerator workloads tend to demand high off-chip memory bandwidth which results in a many-to-few traffic pattern when coupled with expected technology constraints of slow growth in pins-per-chip. Leveraging these observations we reduce NoC area by proposing a ""checkerboard"" NoC which alternates between conventional full-routers and half-routers with limited connectivity. Checkerboard employs a new oblivious routing algorithm that maintains a minimum hop-count for architectures that place L2 cache banks at the half-router nodes. Next, we show that increasing network injection bandwidth for the large amount of read reply traffic at the nodes connected to DRAM controllers alleviates a significant fraction of the remaining imbalance resulting from the many-to-few traffic pattern. The combined effect of the above optimizations with an improved placement of memory controllers in the mesh and channel slicing improves application throughput per unit area by 25.4%.","2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture Throughput-Effective On-Chip Networks for Manycore Accelerators Ali Bakhoda ECE Department University of British Columbia Vancouver, Canada Email: bakhoda@ece.ubc.ca John Kim CS Department KAIST Daejeon, Korea Email: jjk12@kaist.edu Tor M. Aamodt ECE Department University of British Columbia Vancouver, Canada Email: aamodt@ece.ubc.ca Abstract—As the number of cores and threads in manycore compute accelerators such as Graphics Processing Units (GPU) increases, so does the importance of on-chip interconnection network design. This paper explores throughput-effective network-on-chips (NoC) for future manycore accelerators that employ bulk-synchronous parallel (BSP) programming models such as CUDA and OpenCL. A hardware optimization is “throughput-effective” if it improves parallel application level performance per unit chip area. We evaluate performance of future looking workloads using detailed closed-loop simulations modeling compute nodes, NoC and the DRAM memory system. We start from a mesh design with bisection bandwidth balanced with off-chip demand. Accelerator workloads tend to demand high off-chip memory bandwidth which results in a manyto-few trafﬁc pattern when coupled with expected technology constraints of slow growth in pins-per-chip. Leveraging these observations we reduce NoC area by proposing a “checkerboard” NoC which alternates between conventional full-routers and half -routers with limited connectivity. Checkerboard employs a new oblivious routing algorithm that maintains a minimum hop-count for architectures that place L2 cache banks at the half -router nodes. Next, we show that increasing network injection bandwidth for the large amount of read reply trafﬁc at the nodes connected to DRAM controllers alleviates a signiﬁcant fraction of the remaining imbalance resulting from the many-to-few trafﬁc pattern. The combined effect of the above optimizations with an improved placement of memory controllers in the mesh and channel slicing improves application throughput per unit area by 25.4%. Keywords-NoC; Compute accelerator; GPGPU I . IN TRODUC T ION The bulk-synchronous parallel (BSP) programming model [44] is attractive for manycore compute accelerators since it provides relatively simple software scalability as the number of cores increases with Moore’s Law. Languages such as CUDA [35], [38], OpenCL [19], and recently proposed programming models for future accelerator architectures [16] embody the BSP model. In this paper, we explore the on-chip network design space for compute accelerators. Our goal is to ﬁnd NoC designs for future manycore accelerator architectures employing BSP-like programming models that provide the best performance per unit area cost—those that are throughput-effective. Highly multi-threaded applications running on multi-core microprocessors have coherence trafﬁc and data sharing 1072-4451/10 $26.00 © 2010 IEEE DOI 10.1109/MICRO.2010.50 421 Figure 1. Many-to-Few-to-Many On-Chip Trafﬁc. C nodes are the compute cores and the M C nodes are the memory controllers/memory. Figure 2. Throughput-Effective Design Space. “Balanced Mesh”: bisection bandwidth balanced to off-chip DRAM bandwidth (Section III); “Thr. Eff.”: mesh network optimized for many-to-few-to-many trafﬁc (Section IV); “2x BW”: mesh with double channel width. resulting in signiﬁcant core-to-core communication. In contrast, accelerator applications written in a BSP style [7], [16] tend to organize communication to be local to a group of threads that can execute on hardware units that are located close together and have less communication between threads in different groups even when coherence is supported [16], [17]. Consequently, as the number of pins on a chip is growing only 10% per year [14], the net effect of increases in transistor density on accelerator architectures is an increasingly many-to-few trafﬁc pattern [2] with many compute cores sending trafﬁc to a few memory controller (MC) nodes. Using detailed closed-loop simulation, we identify how the many-to-few-to-many trafﬁc causes another performance bottleneck. A high level diagram of this communication pattern is illustrated in Figure 1. An implication of this is the following. Starting from a baseline mesh topology with bisection bandwidth balanced to effective off-chip memory bandwidth (labeled “Balanced Mesh” in Figure 2) application throughput can be increased while maintaining a regular interconnect topology by naively increasing channel bandwidth. The “2x BW” data point in Figure 2 shows the impact this has on throughputeffectiveness (IPC/mm2 ). This ﬁgure decomposes throughput per unit chip area as the product of application level throughput (measured in scalar instructions per cycle– IPC) on the x-axis and inverse area (1/mm2 ) on the y axis1 . Curves in this ﬁgure represent constant throughputeffectiveness (IPC/mm2 ) and design points closer to the top right near “Ideal NoC” are better where an ideal NoC has inﬁnite bandwidth, zero latency, and zero interconnect area. In contrast, the point “Thr. Eff.” results from modifying the baseline NoC to take advantage of the many-to-few-tomany trafﬁc—resulting in a design closer to the throughputeffectiveness of an ideal NoC than alternative designs. The contributions of this paper are: • We present a limit study on the impact of on-chip networks across a wide range of compute accelerator applications—identifying the impact of on-chip communication on overall performance. Based on our analysis, we show how conventional network improvements (such as reducing router latency) do not signiﬁcantly improve overall performance while simply increasing channel width results in signiﬁcant performance gains but with a large area increase. Consequently, we propose simultaneously considering the effect of the interconnect on parallel application level performance and chip area to ﬁnd interconnects which are throughputeffective. • We identify that the many-to-few-to-many trafﬁc pattern of manycore accelerators (more compute nodes than MCs) creates a trafﬁc imbalance and show how the overall system performance is directly correlated with the injection rate of the few MC nodes. • Based on the above observations, we propose a throughput-effective design that includes a novel checkerboard network organization using half -routers with limited connectivity to reduce the on-chip network area while having minimal impact on performance. The throughput-effective design also includes a multiport router structure to provide additional terminal bandwidth on the few routers connected to the MCs that improves system performance at minimal area cost. The rest of this paper is organized as follows: Section II summarizes background information, Section III identiﬁes important insights into NoC behavior of manycore accelerator architectures, Section IV describes our proposed NoC, Section V describes experimental results, Section VI summarizes related work and we conclude in Section VII. 1Average throughputs are for benchmarks in Table I, described in Section II, using conﬁgurations described in Section V. The area estimates are from Section V-F assuming 486mm2 is used for compute nodes. I I . BA SE L IN E ARCH I T EC TUR E In this section we describe our baseline manycore accelerator architecture and on-chip interconnect. Manycore accelerators can be classiﬁed along several dimensions: SIMT2 versus SIMD, degree of multithreading per core, support for caching and coherence, and the granularity at which heterogeneity is introduced. We study a generic architecture with some similarities to NVIDIA’s Fermi [36] and GeForce GTX 280, but our baseline is not meant to be identical to any speciﬁc GPU. We believe our conclusions are applicable to other architectures. We employ benchmarks written in CUDA [35], [38], which is similar to the open standard OpenCL [19]. Many of the benchmarks we use (see Table I) are “dwarves” [4] from Rodinia [7]. Our baseline architecture is illustrated in Figures 3, 4, and 5. Figure 3 illustrates the overall chip layout showing the placement of compute nodes and memory controller nodes. In this work, we assume a 2D mesh topology with the memory controllers (MCs) placed on the top and the bottom rows, similar to the topology and layout used in Intel’s 80core design [46] and Tilera TILE64 [47] processors. Current GPUs often use a crossbar with concentration (to share a single port among several cores) as the number of ports is small. As the number of cores increases, scalability of this approach will be limited. In addition, prior work [5], which included a crossbar comparison, showed that for the workloads we consider performance is relatively insensitive to topology. Thus, we chose a 2D mesh topology since it provides a very regular, simple and scalable network [6]. Each compute node is illustrated in Figure 4. We assume 8-wide SIMD pipelines that execute “warps” (NVIDIA terminology; similar to “wavefronts” in AMD’s terminology) consisting of 32 scalar threads executed over four clock cycles. Each compute core maintains a dispatch queue holding up to 32 ready warps (representing up to 1024 scalar threads). In a hardware implementation the large register ﬁles would be implemented with banks and bank conﬂicts might be mitigated using hardware that reorders operand accesses [31] (labeled OC in Figure 4). Memory operations (loads and stores) to global memory (visible to all threads on all cores) go through a memory divergence detection stage (DD) that attempts to “coalesce” memory accesses from different scalar threads within a warp that access a single L1 cache line so that only one request is made per cache block miss. In line with recent manycore architectures such as Sun Niagara [24] we place shared L2 cache banks adjacent to the MCs. The L1 data caches are writeback writeallocate and dirty L1 cache lines are ﬂushed to the L2 under software control (e.g., software managed coherence [16], [36]). Applications also employ a software managed “shared 2 Single-instruction multiple thread (SIMT): groups of scalar threads execute on a SIMD pipeline using stack-based mechanisms to selectively enable or disable processing elements without need for compiler generated predication [8], [30]. 422 Figure 3. Compute accelerator showing layout of compute node routers and MC node routers in baseline mesh. Shaded routers on top and bottom are connected to MCs. Figure 6. Limit study showing bisection bandwidth of a mesh with 16B channel size can achieve 93% application level throughput (IPC) of a network with inﬁnite bandwidth while maximizing application level throughput per unit estimated area cost. memory” (S). Addresses are low-order interleaved among MCs every 256 bytes [13] to reduce hot-spots [40]. I I I . CHARAC TER I ZAT ION In this section we analyze characteristics of BSP applications written in CUDA on the baseline architecture described in Section II using closed-loop execution driven simulations (see Section V-A for conﬁguration details). We start by identifying the bisection bandwidth required to achieve a balanced NoC design when considering the heavy offchip demands of accelerator workloads. Then, we classify our applications by the intensity of on-chip trafﬁc they generate and their application level throughput sensitivity to interconnect optimizations. A. Balanced Design We ﬁrst size the bisection bandwidth of our network with the aim of ﬁnding a balanced design. Bisection bandwidth is a key parameter limiting network throughput. It is deﬁned as the minimum bandwidth over all cuts that partition the network with equal number of nodes in each half [10]. Starting from a system with bisection bandwidth that is “too low” may signiﬁcantly limit application throughput for memory bound applications (which should instead be limited by off-chip bandwidth) while a system with bisection bandwidth that is “too high” may waste area. Figure 6 plots two curves: One curve (square markers) is the harmonic mean throughput (IPC) of our benchmarks 423 Figure 4. Compute Node Figure 5. Memory Controller Node assuming realistic timing models for compute nodes and memory nodes, but a zero latency network with limited aggregate bandwidth. This network has zero latency once a ﬂit is accepted, but it limits the number of ﬂits accepted per cycle by enforcing the bandwidth limit speciﬁed on the x-axis. Here, bandwidth is total ﬂits transmitted across the network, expressed as a fraction of peak DRAM bandwidth. A packet is accepted provided the bandwidth limit has not been exceeded. Multiple sources can transmit to a destination in one cycle and a source can send multiple ﬂits in one cycle. Application level throughput is normalized to that obtained with an inﬁnite bandwidth zero latency network. The slight improvements beyond the point where bisection bandwidth is equal to DRAM bandwidth (1.0 on x-axis) is due to the presence of L2 caches. The other curve (diamond markers) shows this throughput divided by an estimated chip area. Chip area here includes compute node area and NoC area. NoC area is estimated to be proportional to the square of the channel bandwidth [6]. Although higher network bandwidth continues to increase performance, when normalized to cost, an optimal design from a performance per area perspective occurs at around bisection bandwidth ratio of 0.7-0.8. In addition, since performance is generally limited by off-chip bandwidth due to a lack of locality in the workloads and considering the activate/precharge overheads of switching DRAM pages, network bandwidth with 70-80% of peak off-chip DRAM bandwidth also provides a balanced network design. Based on this bisection bandwidth ratio, we determine that this ratio approximately corresponds to a 2D mesh network with 16-byte channels3 . 3 In Figure 6, the interconnect transfers at most N ﬂits/cycle at interconnect clock frequency (iclk). The x-axis in Figure 6 is x = N [ﬂits/iclk] ·16 [B/ﬂit] ·602 [MHz (iclk)] 1107 [MHz (mclk)] ·8 [# MC] ·16 [B/mclk] where mclk is the DRAM clock frequency. At the marked location (x = 0.816), N is 12 ﬂits/iclk. Hence, link size is 12 (N ) times ﬂit size (16 B) divided by 12 (bisection of a 36-node mesh has 12 links) equals 16B per channel. Clock frequencies are from Table II. Table I B ENCHMARK S Name AES Cryptography [5] Binomial Option Pricing [37] HotSpot [7] Neural Network Digit Recognition [5] Needleman-Wunsch [7] Heart Wall Tracking [7] Leukocyte [7] 64-bin Histogram [37] LU Decomposition [7] Scan of Large Arrays [37] Back Propagation [7] Abbr. AES BIN HSP NE NDL HW LE HIS LU SLA BP Name Separable Convolution [37] Nearest Neighbor [7] Black-Scholes Option Pricing [37] Matrix Multiplication [41] 3D Laplace Solver [5] Ray Tracing [5] gpuDG [5] Similarity Score [7] Matrix Transpose [37] Speckle Reducing Anisotropic Diffusion [7] Weather Prediction [5] Abbr. CON NNC BLK MM LPS RAY DG SS TRA SR WP Name MUMmerGPU [5], [7] LIBOR Monte Carlo [5] Fast Walsh Transform [37] Scalar Product [37] Streamcluster [7] Kmeans [7] CFD Solver [7] BFS Graph Traversal [7] Parallel Reduction [37] Abbr. MUM LIB FWT SCP STC KM CFD BFS RD LL LH HH Figure 7. Speedup of a perfect interconnection network over baseline. LL, LH, HH: First character denotes low or high speedup with perfect NoC; second character denotes low or high memory demand. B. Network Limit Study Next we perform a limit study to measure the performance beneﬁts of a perfect interconnect (zero latency and inﬁnite bandwidth) versus our baseline mesh with 16B channel size. Figure 7 shows the speedup of a perfect network over the mesh with 16B channel bandwidth and a 4-stage router pipeline and a 1-cycle channel delay (5-cycle per hop delay) with the parameters in Table III. We divide applications into three groups using a two letter classiﬁcation scheme. The ﬁrst letter (H or L) denotes high or low (greater or less than 30%) speedup with a perfect network. The second letter (H or L) denotes whether the application sends a heavy or light amount of trafﬁc with a perfect network: accepted trafﬁc, averaged across all nodes, is greater than or less than 1Byte/cycle. All of our applications fall into one of three groups: LL, LH, and HH. Applications in LL place little demand upon the network. Studying the source code of these applications and their detailed simulation statistics we ﬁnd they have been heavily optimized to group related threads together on a compute node and make good use of the software managed scratchpad memory and/or achieve high L1 hit rates. There is no HL group since applications with low memory access are not likely to get a speedup with a better network. Despite the mesh having sufﬁcient bisection bandwidth (Figure 6) the speedup of a perfect network versus our realistic baseline mesh is 36% across all benchmarks, 87% across HH benchmarks and 42% across the Rodinia [7] benchmarks. We explore the reasons for this below. The LL and HH applications behave as expected: applications that make low use of memory are expected to have low sensitivity to network performance and conversely for those with heavy trafﬁc one would expect to see high speedups. The LH group has a relative high memory usage but its Figure 8. Perfect network speedup versus memory node injection rate performance does not increase much with a perfect network. Detailed analysis shows these benchmarks achieve close to the peak performance indicating that the interconnect is not the bottleneck with the exception of NNC, which has an insufﬁcient number of threads to fully occupy the ﬁne-grain multithreaded pipeline or saturate the memory system. Figure 8 plots perfect network speedup versus average memory controller node injection rate. Speedups are correlated to the memory controller injection rate (or the MC output bandwidth shown in Figure 1) suggesting the presence of a bottleneck on the read response path. We address this bottleneck in Section IV-D. C. Router Latency and Bisection Bandwidth In this section we show that aggressive router latency optimizations [26], [28], [33], [39] do not provide signiﬁcant performance beneﬁts for our workloads. Figure 9 shows that replacing the 4-cycle baseline routers with aggressive 1cycle routers results in fairly modest speedups ranging from no speedup to at most 7% (harmonic mean speedup is 2.3% for all benchmarks). Figure 10 compares the network latency of these two conﬁgurations; y-axis is the network latency reduction of using 1-cycle routers over 4-cycle baseline routers. These ﬁgures show that an aggressive router can decrease network latency but this improvement in network performance does not necessarily translate into overall performance beneﬁts for these workloads. For example, the 424 LL LH HH Figure 9. Impact of scaling network bandwidth versus latency. Solid bars: channel size 32 versus 16, Hashed bars: 1-cycle versus 4-cycle router latency. Figure 10. Interconnection latency reduction of using 1-cycle routers over baseline 4-cycle routers network latency of HIS is reduced by approximately 2× with an aggressive router but this only results in a 3% performance improvement. In contrast, network bandwidth is an important metric as it impacts the overall throughput of the network. By increasing the network channel bandwidth by a factor of 2× (from 16B to 32B), a 27% speedup is achieved over the baseline with 16B channels as shown in Figure 9. However, high-bandwidth NoC designs are very costly in terms of area as we show in Section V-F. Given the baseline mesh was designed to have a bisection bandwidth within 7% of that required to achieve the performance of perfect a network, the data in Figure 9 is again strongly suggestive of an imbalance in the network. Next, we show that one of the reasons is the trafﬁc pattern. D. Many-to-Few-to-Many Trafﬁc Pattern The compute accelerator architectures we study presents the network with a many-to-few-to-many trafﬁc—with many compute nodes communicating with a few MCs. As shown earlier in Figure 1, the MC bottleneck is not only caused by the ratio of many cores to few MCs (28/8 in our simulations), but also caused by the difference in packet sizes. As a result, by simulating a closed-loop system with all components modeled, we also identify how the many-tofew-to-many trafﬁc pattern causes a bottleneck in addition to the bottleneck caused by the many-to-few pattern. The trafﬁc sent from compute cores to MCs consists of either read requests (small 8-Byte packets) or, less frequently, write requests (large 64-Byte packets) while the trafﬁc from MCs to compute cores only consists of read-replies (large 64-Byte packets). This creates an imbalance in injection rates—on average the injection rate (bytes/cycle) of an MC is 6.9× higher than a compute core. The higher injection rates of memory response data returning from the MCs creates bottlenecks in the reply network that can stall the MCs. This problem is shown in Figure 11 which shows the fraction of the time MCs are stalled (i.e. cannot process requests) because the reply network cannot accept packets from MCs—resulting in MCs being stalled up to 70% of the time for some of the HH benchmarks. IV. THROUGH PU T-E FFEC T IV E N E TWORK D E S IGN In this section we leverage the insights from the analysis in Section III to design throughput-effective NoCs for manycore accelerators. We describe the checkerboard network organization which uses half -routers to reduce network cost while exploiting the many-to-few trafﬁc pattern characteristics. In addition, it also enables a staggered MC placement to avoid creating hotspots. To address the many-to-few trafﬁc imbalance, we describe a simple yet effective router microarchitectural extension to the checkerboard network with multi-port routers at the few nodes that increases the terminal bandwidth of these nodes. We also extend the checkerboard network with channel slicing to create two parallel networks and further reduce cost. A. Checkerboard Network Organization Although the many-to-few trafﬁc pattern creates challenges, it also provides opportunities for optimization—for example, there is no all-to-all communication among all nodes in the system. Based on this observation, we propose a checkerboard NoC to exploit this trafﬁc pattern and reduce the area of the NoC. Figure 12 shows a 6×6 conﬁguration of the checkerboard network where routers alternate between full-routers shown with solid shaded squares and half routers drawn with hatching. A full-router provides full connectivity between all ﬁve ports in a 2D mesh while a halfrouter (shown in detail in Figure 13) limits the connectivity as packets can not change dimensions within the router. The router microarchitecture is similar to a dimension-sliced microarchitecture [18] but in a dimension-sliced router, packets can change dimensions while we limit this capability to further reduce the complexity of the router. While the injection port and the ejection port of a half-router are connected to all ports, the East port only has a connection to the West port and similarly, the North port is connected only to the South port. By taking advantage of half-routers, the router area can be signiﬁcantly reduced. For example, in a full-router, the crossbar requires a 5×5 crossbar 4 while 4 Since a packet arriving on a given port can not depart through the same port, the crossbar will actually be a 4×5 crossbar. 425 Figure 11. Fraction of time injection port at MCs are blocked preventing data read out of DRAM from returning to compute nodes. (a) General restrictions (b) Case 1: YX routing (c) Case 2: Checkerboard routing Figure 12. Checkerboard Mesh On-chip Network routing examples. Dashed lines are examples of XY routes prevented by half-routers (hatched); alternate feasible routes are solid. Dark shaded nodes are MC routers. level on-chip caches, if the cache banks are restricted to halfrouters they can be accessed by all compute nodes. Miss trafﬁc at these banks can reach MC nodes from the cache banks provided both cache banks and MC are also placed at half-router nodes since half routers can route to other halfrouters (as described below). However, if cache banks are placed on the same tiles as the compute cores, the checkerboard organization will restrict cache-to-cache communication as full-routers cannot communicate with all other full-routers. In this case packets would need to be routed to an intermediate half-router (either minimally or nonminimally) and be ejected or removed from the network—before being reinjected into the network and being routed to their destination, thus doubling the network load5 . However, prior work has shown that for accelerator applications written in BSP style languages supporting coherence, cache-to-cache communication is relatively infrequent [16], and hence we expect the impact of this routing on overall performance to be minimal. B. Checkerboard Routing Algorithm and Flow Control We assume a baseline dimension-ordered routing (DOR) using XY-routing in the proposed checkerboard network. However, because of the limited connections of the halfrouters, XY-routing cannot route a packet for the following two trafﬁc patterns: Case 1: Routing from a full-router to a half-router which is an odd number of columns away and not in the same row. Case 2: Routing from a half-router to a half-router which is an even number of columns away and not in the same row. 5 This is different from randomized routing algorithms such as Valiant [45] routing where packets are routed to an intermediate node but packets do not need to be removed from the network at the intermediate node. Figure 13. Half-router connectivity the half-router only requires four 2×1 muxes (two for each dimension) and one 4×1 mux for the ejection port, resulting in approximately 50% reduction in area (detailed analysis shown in Section V-F). The checkerboard layout does present some limitations in terms of communication (and routing) because of the limited connectivity of the half-routers. Regardless of the routing algorithm (minimal, adaptive, or non-minimal), a packet with a full-router source and a full-router destination that are an odd number of columns or rows away cannot be routed, as illustrated in Figure 12(a), since the packet cannot turn at a half-router. However, by exploiting the many-to-few trafﬁc pattern, the communication between full-routers can be removed by placing the MC nodes at half-routers. Thus, all full-routers represent a compute node and this routing limitation of the checkerboard layout does not become a problem for these manycore accelerator architectures. In addition, as the data in Section III-D suggests, an injection rate imbalance between MCs and compute cores creates hotspots in the baseline network in which the MCs are placed in neighboring locations on top and bottom of the chip. Thus, the checkerboard network can also exploit a staggered MC placement [2], [5]. Similarly, in architectures with large last 426 Figure 14. Layout example. Normal (left): F=full-router; Checkerboard (right): H=half-router, F=full-router. Area savings of 10% with two tile layouts assuming (for illustration only) a 75% reduction in half-router and full-routers are 25% of a normal tile. If YX routing is used as the baseline routing algorithm, similar routing restrictions exist as well. For Case 1, since a packet cannot “turn” or change dimensions at a half-router, YX routing can be used instead of XY routing and thus, the packet turns at a full-router as shown in Figure 12(b). For Case 2, neither XY nor YX routing can be used to route packets because of the limitations of half-routers (Figure 12(c)). As a result, an additional turn is needed to route the packet from the source to its destination by ﬁrst routing to an intermediate, full-router node and then, routing to the destination. A random, intermediate full-router is selected within the minimum quadrant containing the source and destination that does not share the same row as the source and is not an odd number of columns away from the source. Thus, checkerboard routing (CR), occurs in two phases—in the ﬁrst phase, YX routing is used to route to the intermediate node and in the second phase, XY routing is used to route minimally to the destination. The CR routing is similar to a 2-phase ROMM routing [34] discussed in Section VI but differs as the random intermediate node is restricted to a full router and each phase needs to be done with a different DOR routing. We implement this routing algorithm with a single extra bit in the header which is set upon injection and tells all the routers on the way that this packets must be YX routed. To avoid circular dependencies and routing deadlock, two virtual channels are needed in the checkerboard routing, similar to O1Turn routing algorithm [42]. The YX routing is done using one VC while XY routing uses another VC. Additional VCs to avoid protocol deadlock are still needed. Although the checkerboard network requires additional VCs, the reduction in router area is substantial as shown in Section V-F. Reducing overall chip area with this design may require layout modiﬁcations like those illustrated in Figure 14. This ﬁgure assumes for illustration and clarity purposes, a 75% reduction in the area of a half-router and a full-router that is initially 25% of a tile leading to a 10% area reduction in chip area. (a) Normal router (b) With 2 injection/ejection ports Figure 15. Router connections width with each channel having a bandwidth b, our baseline uses a single physical network. However, since router area is proportional to O(b2 ), it can be reduced by taking advantage of channel slicing [10]: creating a double network6 , each with a channel bandwidth of b/2. Our channel slicing technique increases the serialization latency of large packets (write requests and read replies) but as we showed earlier these accelerator architectures are not sensitive to a slight increase in latency. The trafﬁc in the double network can be load-balanced with a dedicated double network where each network is used for a different class of trafﬁc – one network carries request packets and the other network carries reply packets. With a dedicated double network, no extra virtual channel (VC) is needed to avoid protocol deadlock while with a single network, VCs are needed for protocol deadlock avoidance. D. Multi-port Routers for Memory Controller Nodes To help reduce the bottleneck at the few nodes with many-to-few-to-many trafﬁc pattern (shown in Figure 1), we propose a simple change to the routers attached to the few MC nodes: adding additional injection/ejection ports from/to the MC and creating a multi-port router microarchitecture. These additional ports do not increase the network bisection bandwidth or any network channel bandwidth but instead, increase the terminal bandwidth by providing more injection/ejection bandwidth from/to the MC nodes. Figure 15(a) shows connection of a conventional router in a 2D mesh network and Figure 15(b) shows the proposed multi-port router microarchitecture with additional injection/ejection ports. Selection of the ports at multi-port routers can be done in a simple round-robin fashion. Note that only the routers connected to the MC nodes change. When adding extra ejection ports, we leverage the fact that an MC is servicing requests from many compute cores; as packets destined to different compute cores get in the MC router, they will start traveling in different directions towards their destination. This technique would not improve performance if the MC had to service a single compute core for a long time since we are not increasing the bandwidth of the links between routers. V. EX PER IM EN TA L R E SU LT S In this section we present experimental results for our throughput-effective interconnect optimizations. We start by C. Double Network—Channel Sliced Network The area footprint of NoC can be further reduced using channel slicing. For a network with a given bisection band6Balfour and Dally [6] proposed MeshX2 topology which creates two parallel networks which increases cost. Our approach differs slightly as we partition the network – thus, comparing networks with same bisection bandwidth. 427 Table II S IMU LAT ION PARAM E TER S BA SE L IN E IN TERCONNEC T CON FIGURAT ION Table III Parameter Number of Compute(Shader) Cores Number of Memory Channels MSHRs / Core Warp Size SIMD Pipeline Width Number of Threads / Core Number of CTAs / Core Number of Registers / Core Shared Memory / Core Constant Cache Size / Core Texture Cache Size / Core L1 Cache Size / Core L2 Cache Size / MC Compute Core Clock Interconnect & L2 Clock Memory Clock GDDR3 Memory Timing DRAM request queue capacity Memory Controller (MC) Branch Divergence Method Warp Scheduling Policy Value 28 8 64 32 8 1024 8 16384 16KB 8KB 8KB 16KB 128KB 1296 MHz 602 MHz 1107 MHz tCL =9, tRP =13, tRC =34 tRAS =21, tRCD =12, tRRD =8 32 out of order (FR-FCFS) Immediate Post Dominator [11] Round Robin among ready warps describing our simulation setup, then explore the impact of MC placement, the impact of checkerboard router design, the impact of separate physical networks, and ﬁnally the impact of multi-port routers at the MC nodes. A. Methodology We use a modiﬁed version of GPGPU-Sim [5], a detailed cycle level simulator modeling a contemporary GPU running compute accelerator workloads. The modiﬁcations we made include adding support for a limited number of MSHRs per core, proper modeling of memory coalescing according to the CUDA manual [38], using Booksim 2.0 [1] instead of Booksim 1.0, and adding support for some undocumented (by NVIDIA) barrier synchronization behavior required by LE and SS benchmarks (barriers synchronize at the level of warps rather than scalar threads in NVIDIA GPUs [48]). Table II and III show our hardware parameters. Conﬁguration abbreviations are listed in Table V. We modeled half routers with a 3-stage pipeline, though we found the performance impact of one less stage was negligible. While we are interested in future designs, we chose parameters similar to GeForce GTX 280 except for the addition of caches which more closely represent per thread resources on Fermi. We do this to aid in estimating area overheads of compute portions of the overall accelerator. We use ORION 2.0 [15] for network area estimation; Table IV shows the corresponding conﬁguration options. The benchmarks used in simulation are listed in Table I. We simulate all benchmarks to completion to capture distinct phases of the benchmarks. B. Checkerboard Placement (CP) Figure 16 shows the performance impact of moving the MC nodes from the top-bottom conﬁguration in Figure 3 to the staggered locations shown in Figure 12, but still maintaining full routers and DOR routing. This placement of the MCs beneﬁts from less contention [2] and by itself 428 Topology Routing Mechanism Routing Latency (number of router pipeline stages) Channel Latency Flow Control Virtual Channels Buffers per Virtual Channel Allocator Input Speedup Channel width (Flit size) Mesh DOR 4 1 Virtual Channel based on Wormhole 2 8 iSLIP 1 16 bytes Table IV OR ION 2 .0 CON FIGURAT ION Table V ABBR EV IAT ION S Technology Crossbar type Buffer Type Wire Layer Wire Spacing 65nm Matrix SRAM Intermediate Single DOR CP CR TB 2P BW Dimension Order Routing Checkerboard Placement Checkerboard Routing Baseline Top-Bottom Placement 2 injection port MCs Bandwidth results in an average speedup of 13.2% compared to baseline top-bottom placement. We chose this particular placement by picking the best performing placement after simulating several valid checkerboard placements (but did not exhaustively simulate all valid placements). For applications with low injection rates at the MC nodes (such as LL and LH applications), the MC placement has little or no impact on overall performance since the contention in the return network is not high. Note that WP’s loss of performance (6%) is due to global fairness issues that slow down a few of the compute cores. There are studies [29] that tackle the global fairness in NoCs which are orthogonal to the techniques we introduce in this paper. C. Checkerboard Routing (CR) Figure 17 shows the relative performance of DOR with 4 VCs (solid bars) and checkerboard routing with 4 VCs (hashed bars) compared to the DOR routing with 2VCs. Simulations show that using checkerboard network, with half of the routers being half -routers, results in minimal loss in performance (on average 1.1% reduction), compared to the 2VC DOR network which requires all full-routers while signiﬁcantly reducing the network area. Although a different routing algorithm is required in the checkerboard network, it is still minimal routing (minimal hop count between source and destination). Checkerboard network has minimal impact on average network latency as it makes balanced use of the virtual channels in each direction. For example, RD uses the VC dedicated to YX routing for 60.1% of the total packets it injects to the network. Thus, checkerboard network reduces router area with minimal performance loss on average. D. Double Network—Channel Sliced Network As described earlier in Section IV, the trafﬁc with a double network is load-balanced with a dedicated double network where each network is used for a different class of LL LH HH Figure 16. Overall speedup of using checkerboard placement of routers compared to baseline top-bottom placement (both conﬁguration have 2 VCs). Figure 17. Relative performance (IPC) of DOR with 4 VCs (solid bars) and checkerboard routing with 4 VCs (hashed bars) compared to DOR routing with 2 VCs; all with checkerboard placement(CP). Higher bars mean better performance. Figure 18. IPC speedup of using two physical networks with channel width 8B (each network has 2VCs) compared to a single network with channel width 16B with 4VCs (both have checkerboard routing and checkerboard placement and 8 buffers per VC). trafﬁc—one network dedicated to read/write requests and the other network dedicated to replies. Conventionally, channel slicing is beneﬁcial if combined with the reduction of the network diameter [10], [22]; however we utilize channel slicing without reducing network diameter to reduce network area (Section V-F). In addition to the area savings in the router crossbar (taking advantage of quadratic dependency of crossbar area on channel bandwidth) we also save buffer area by keeping the number of VCs constant as we move from single network to double network. The number of VC buffers in the network remains constant but the amount of storage of each VC buffer is reduced to half since the channel width is also halved. Figure 18 shows the speedups of the double over the single network. On average there is no change in performance (around 1% speedup) while providing area savings as we show in Section V-F. One drawback of channel slicing is increased serialization latency for large packets with narrower channels. This increase in latency only impacts read reply and write request packets since the small read request packets still ﬁt in a single ﬂit. However, as shown earlier in Section III-C, the additional latency has minimal impact on these workloads and are tolerated by the compute cores. E. Multi-port routers Figure 19 shows the speedups of increasing terminal bandwidth of MC routers by adding an extra injection port (left bars), an extra ejection port (middle bars) and combination of these changes (right bars) – as described in Section IV and Figure 15(b). It can be seen that the speedups gained by extra injection and ejection ports are orthogonal and add up when combined. The highest speedups are gained by HH benchmarks. The extra injection ports at MC routers reduces the average fraction of execution time the injection ports at MCs are blocked by 38.5% which provides additional performance beneﬁts. Adding extra ejection ports to MC routers only helps a few benchmarks such as TRA and FWT that are sensitive to the delivery timing of requests to the FR-FCFS input sorting queue in the MC. Their speedup is due to an increase in DRAM row locality for these benchmarks which translates into higher DRAM efﬁciency7—e.g. FWT’s DRAM efﬁciency goes from 57% to 65% with the addition of the extra ejection port. We will not keep the extra ejection port as part of our throughput-effective design since the speedups it provides are limited to a few benchmarks. Combining the optimizations introduced above (checkerboard placement, checkerboard routing, double network and 2 injection ports at MC routers) results in a 17% speedup versus our baseline introduced in Section II as shown in Figure 20. Compared with 36% speedup of a perfect network, our throughput-effective network achieves roughly half of the performance possible with a perfect network while signiﬁcantly reducing area. Figure 21 plots open-loop latency versus offered load for the combinations of checkerboard and multiple injection ports evaluated earlier using closed-loop simulation for both uniform many-to-few and hotspot trafﬁc. For hot-spot trafﬁc 20% of requests go to one MC as opposed to of 12.5% (1/8) for uniform random. These open-loop simulations use a single network with two logical networks for request and 7Deﬁned as the percentage of time a DRAM chip is transferring data over its data pins divided by the time when pending memory requests exist. 429 Figure 19. IPC speedup of adding multi-port MC routers versus double network checkerboard. Figure 20. with DOR. IPC speedup of combining checkerboard placement and routing with double network and two injection port MCs versus baseline top-bottom (a) Uniform Random Many-to-Few-to-Many (b) Hotspot Many-to-Few-to-Many Figure 21. Latency versus network throughput for different architectures. The few nodes (8 MC nodes) inject 4-ﬂit packets while the compute nodes inject 1-ﬂit packets i.e., only read trafﬁc is simulated. The overall network throughput is limited because of the many-to-few-to-many bottleneck. reply trafﬁc. These ﬁgures show that combining checkerboard placement (CP), checkerboard routing (CR) and two injection ports at the MC (2P) improves performance by increasing saturation throughput versus the baseline topbottom placement (TB). The double bandwidth counterpart of baseline (2x-TB) is also shown for reference. The largest contributors to performance for uniform random trafﬁc are the placement of MCs and increasing injection ports at the MCs (note read response packets are larger than read request packets). For the hot-spot trafﬁc the improvements of MC placement are more moderate while adding the extra injection ports at MCs improves performance signiﬁcantly by alleviating the bottlenecks created by hot-spot trafﬁc. Although addresses are low-order interleaved among MCs every 256 bytes [13] to reduce hot-spots we have observed that temporary hot-spots happen in closed-loop simulations. F. Area Analysis We use ORION 2.0 [15] to estimate area of various router architectures and network topologies. As shown earlier, aggressive investments to reduce router latency do not result in substantial overall performance improvements. Table VI provides the area estimates for the designs we evaluated. We use the GTX280’s area, 576mm2 in 65nm, as our baseline. Then we estimated the area of “compute” parts by subtracting the total estimated area of our baseline mesh network from the GTX280’s area (486mm2 ). Assuming the compute area does not change, we estimate the total chip area for other network conﬁgurations (last column of table). The ﬁrst row shows the area of baseline mesh with channel width of 16 bytes and the second row a mesh with channel width of 32 bytes. As expected, a quadratic increase in the router area happens by doubling the channel width. The high area overhead of the mesh with channel width 32 bytes, which is 53% of GTX280’s area, makes it impractical to build. By exploiting half-routers, which occupy only 56% of the area of a full-router, the checkerboard network results in a signiﬁcant reduction in total router area of 14.2% (comparing sum of router area numbers which are 59.2mm2 in 65nm for checkerboard and 69mm2 for baseline router). By further taking advantage of the quadratic dependency, the double network reduces the area further by 37%. Table VI’s last row shows the area of the conﬁguration with 2 injection ports at MC nodes; it increases the router area overhead only by 1%. In this design, the eight half-routers connected to MCs have 2 injection ports instead of 1. Overall, considering both the increase in throughput and reduction in area, we improve throughput-effectiveness (IPC/mm2 ) by 25.4% when comparing the checkerboard network with checkerboard placement, 2 injection ports, and double network versus our balanced baseline mesh. V I . R ELAT ED WORK A. Accelerator Architectures Rigel [16] is an accelerator that is fundamentally similar to our architecture but provides a more ﬂexible programming model compared to CUDA and chooses a MIMD model rather than SIMT. The Cell [23] architecture’s NoC design is an example of making tradeoffs between network’s area and latency. The Cell designers chose a ring over a crossbar 430 AR EA E ST IMAT ION S (mm2 ) . OV ERH EAD S AR E BA SED ON GTX280 ’ S AREA . A “ / ” S E PARAT E S D I FFER EN T ROU T ER TY PE S FOR CON FIGURAT ION S THAT HAV E MOR E THAN ONE ROUT ER TY PE . Table VI Area of 1 link 0.175 0.349 0.175 0.087 0.087 Crossbar Area 1.73 6.95 0.83/ 1.73 0.43/ 0.20 0.43/ 0.20/ 0.28 Buffer Area 0.17 0.34 0.34/ 0.34 0.087/ 0.087 0.087/ 0.087/ 0.10 Allocator Area 0.004 0.004 0.004/ 0.015 0.004/ 0.015 0.004/ 0.015/ 0.015 Area of 1 Router 1.916 7.305 1.18 / 2.10 0.522/ 0.30 0.522/ 0.30/ 0.38 Baseline 2x-BW CP-CR Double CP-CR Double CP-CR 2P Link Router Area Sum Area Sum 21.015 69.00 41.963 263.0 21.015 59.20 % of NoC overhead 15.63% 52.95% 13.9 % Total Chip Area 576 790.948 566.2 21.015 21.015 29.74 30.44 8.7 % 8.93% 536.74 537.44 to meet their area and power constraints [25]. The choice of centralized arbiters can limit scalability. UltraSPARC T2 [43] microprocessor is a multithreading, multi-core CPU that uses a crossbar interconnect. GPUs and Cell are related to stream computing [3], [9]. B. Interconnection Networks Increasing number of cores on a single chip has increased the importance of networks-on-chip (NoC). However, much of the research in NoC have focused on reducing network latency by improving different aspects of NoC such as lower latency router microarchitectures [26], [33], lower-diameter topologies [6], [12], [21], or better ﬂow control [27], [28]. However, as we showed in Section III, reducing latency does not help to improve overall performance in compute accelerator applications but they are more sensitive to bandwidth. Bufferless routing [32] was proposed to reduce network cost by removing buffers but for applications with high trafﬁc, network throughput can be degraded. On-chip networks for GPUs have been explored by Bakhoda et al. [5] where impact of different network parameters are evaluated. This work builds upon their work, providing more in-depth analysis and proposing a cost-efﬁcient on-chip network architecture for accelerator architectures. Yuan et al. [49] proposed a complexity-effective DRAM access scheduling technique for manycore accelerators that relies on modiﬁcation to arbitration scheme in request path of NoC. Abts et al. [2] studied alternative MC placements for core-memory trafﬁc; however, they did not show overall performance beneﬁts on applications but focused on latency metrics and synthetic trafﬁc patterns. The MC placement that we use in this work leverages this prior work by staggering the MC placement and shows how overall performance can be signiﬁcantly improved. Checkerboard routing is similar to ROMM [34]. In 2-phase ROMM, a random node is selected within the minimal quadrant and DOR routing is used to route the packet to a random node in the ﬁrst phase before routing to the destination in the second phase. Increasing the radix of the routers in on-chip networks have been proposed [6], [21] to reduce the network diameter and increase network performance, mainly through lower latency. The multi-port approach differs as we only increase radix across a few routers to minimize the impact on complexity. The proposed half-router shares some similarity to the low-cost router microarchitecture [20]. However, unlike the low-cost router microarchitecture which provides full connectivity for XY routing, the routing is restricted in the halfrouter to further reduce complexity. V I I . CONC LU S ION In this paper, we analyze the impact of communication and on-chip network across a wide range of applications in manycore compute accelerators. We describe how these applications are not sensitive to latency but to bandwidth and how the trafﬁc pattern (mostly many-to-few-to-many) creates a bottleneck in the on-chip network. To improve the performance, we focus on throughput-effective on-chip network where we optimize for higher application throughput per area. To achieve a throughput-effective on-chip network, we propose a checkerboard organization where we exploit half -routers to reduce network cost with minimal loss in performance. We further extend the checkerboard network with multi-port routers to address the many-to-fewto-many bottleneck and provide a throughput-effective microarchitectural technique to improve network performance by increasing the terminal bandwidth of the network. ACKNOW LEDG EM EN T S We thank Wilson W. L. Fung, Andrew Turner, Johnny Kuan, Arun Ramamurthy, Minoo Jalali, and the anonymous reviewers for their valuable feedback on this work. This work was partially supported by the Natural Sciences and Engineering Research Council of Canada. "
2007,Fully Adaptive Fault-Tolerant Routing Algorithm for Network-on-Chip Architectures.,"In this paper, we present a novel fully adaptive and fault-tolerant routing algorithm for Network-on-Chips (NoCs) called Force-Directed Wormhole Routing (FDWR). The proposed routing algorithm is implemented in the switches of a TLM (Transaction Level Model) packet switching NoC using SystemC. Based on these switches, mesh, torus, and hypercube topologies for NoCs can be automatically generated. We show how the proposed algorithm distributes the traffic uniformly across the entire network to avoid overloaded links. Simulation results depict that the proposed routing algorithm is able to route packets even in the case of faulty links or switches in the NoC. Furthermore, it is shown that in the case of faulty switches the area around that switches is not overloaded and that the traffic is uniformly distributed across the entire network.",
2010,SunFloor 3D - A Tool for Networks on Chip Topology Synthesis for 3-D Systems on Chips.,"Three-dimensional integrated circuits (3D-ICs) are a promising approach to address the integration challenges faced by current systems on chips (SoCs). Designing an efficient network on chip (NoC) interconnect for a 3-D SoC that meets not only the application performance constraints but also the constraints imposed by the 3-D technology is a significant challenge. In this paper, we present a design tool, SunFloor 3D, to synthesize application-specific 3-D NoCs. The proposed tool determines the best NoC topology for the application, finds paths for the communication flows, assigns the network components to the 3-D layers, and places them in each layer. We perform experiments on several SoC benchmarks and present a comparative study between 3-D and 2-D NoC designs. Our studies show large improvements in interconnect power consumption (average of 38%) and delay (average of 13%) for the 3-D NoC when compared to the corresponding 2-D implementation. Our studies also show that the synthesized topologies result in large power (average of 54%) and delay savings (average of 21%) when compared to standard topologies.","SunFloor 3D: A Tool for Networks on Chip Topology Synthesis for 3D Systems on Chips Ciprian Seiculescu(cid:2) , Srinivasan Murali§ (cid:2) , Luca Benini‡ , Giovanni De Micheli(cid:2) (cid:2) LSI, EPFL, Lausanne, Switzerland,{ciprian.seiculescu, giovanni.demicheli}@epﬂ.ch § iNoCs, Lausanne, Switzerland, murali@inocs.com ‡ DEIS, Univerity of Bologna, Bologna, Italy, lbenini@deis.unibo.it ABSTRACT Three-dimensional integrated circuits are a promising approach to address the integration challenges faced by current Systems on Chips (SoCs). Designing an efﬁcient Network on Chip (NoC) interconnect for a 3D SoC that not only meets the application performance constraints, but also the constraints imposed by the 3D technology, is a signiﬁcant challenge. In this work we present a design tool, SunFloor 3D, to synthesize application-speciﬁc 3D NoCs. The proposed tool determines the best NoC topology for the application, ﬁnds paths for the communication ﬂows, assigns the network components on to the 3D layers and performs a placement of them in each layer. We perform experiments on several SoC benchmarks and present a comparative study between 3D and 2D NoC designs. Our studies show large improvements in interconnect power consumption (average of 38%) and delay (average of 13%) for the 3D NoC when compared to the corresponding 2D implementation. Our studies also show that the synthesized topologies result in large power (average of 54%) and delay savings (average of 21%) when compared to standard topologies. Keywords 3D ICs, Networks on chip (NoC), synthesis, topology, placement 1. INTRODUCTION To continue the growth of the number of transistors on a chip, the 3D IC technology, where multiple silicon layers are stacked vertically, is emerging as a promising solution. The 3D ICs have a smaller footprint than a comparative 2D implementation. The long horizontal wires in a 2D design can be replaced by shorter and more efﬁcient vertical wires, leading to lower interconnect delay and power consumption. Wafer-to-wafer bonding technology, where the vertical interconnects are implemented using Through Silicon Vias (TSVs), is one of the popular choices for 3D integration [36]. The interconnects for 3D have evolved from simple vertical links connecting buses in different 3D layers to a more scalable Network on Chip (NoC) solution [1]-[3]. NoCs consists of switches and links and use circuit or packet switching to transfer data through the system. NoCs are a necessity for 3D chips, as they are modular, provide conﬁgurable parallelism and can control the number of TSVs required across layers. Most Systems on Chips (SoCs) are composed of heterogeneous cores and target a speciﬁc application domain. To obtain a powerperformance efﬁcient implementation, it is important to build a NoC topology that is tailored to match the application communication characteristics, such as bandwidth and latency constraints 978-3-9810801-5-5/DATE09 © 2009 EDAA  of data ﬂows. Recently, researchers have addressed the issue of NoC topology synthesis for 2D SoCs [11]-[18], including our earlier work on developing a synthesis ﬂow for 2D SoCs [18]. However, topology synthesis for a 3D SoC introduces several new and signiﬁcant challenges: (i) the number of TSVs that can be allowed across any two layers strongly depends on the underlying 3D fabrication technology. For technologies where a large number of TSVs are available, cores across different 3D layers can share the same switches, as more vertical links can be established. On the other hand, with a tight TSV constraint, a core on a layer may need to connect to a switch in the same layer. Thus, depending on the TSV constraint, the topology synthesized can be very different and the synthesis procedure should be able to handle this, (ii) the assignment of switches to different layers needs to be performed, and (iii) TSV macros need to be introduced in each layer for a vertical link and placement of switches and TSV macros need to be performed. Building a custom application-speciﬁc NoC topology will be instrumental in pushing 3D NoC technology in industrial designs. In this paper, we make two major contributions: ﬁrst, we present, SunFloor 3D, a tool for synthesizing application speciﬁc NoCs for 3D SoCs. Second, we consider several realistic SoC benchmarks and perform a comparative study of the NoCs designed for a 3D and a 2D implementation of the benchmarks. The study shows the advantages of using 3D technology for reducing interconnect power consumption and zero-lead latency (in the rest of the paper, this referred to as just latency) on realistic SoC designs. The application communication characteristics and, optionally, a ﬂoorplan of the SoC (with the positions of each core) before instantiating the NoC are taken as inputs to the design process. The tool synthesizes the NoC topology that optimizes the design objectives (such as minimizing power consumption or latency), performs layer assignment of switches and placement of switches and TSV macros. The placement is performed such that the resulting ﬂoorplan is minimally perturbed from the input ﬂoorplan and the NoC wire lengths are minimized. From the ﬂoorplan, the tool can obtain the length of the NoC links, and hence account for wire delay and power consumption accurately during the synthesis process. Several works have addressed the problems of assigning cores to the different layers and performing 3D ﬂoorplanning, considering thermal issues [22]-[25]. Also, in many designs, the layer assignment of cores is dictated by technology constraints (such as having logic and memory dies on different layers). Thus, in this work, we take the ﬂoorplan of the cores as an input to our ﬂow. Our work is complementary to the works on 3D ﬂoorplanning [22]-[25], as we only place the network components on the given input ﬂoorplan, minimally perturbing it. We perform experiments on several SoC benchmarks that show large power (54% on average) and latency (21% on average) im    provement for the synthesized topologies when compared to standard topologies. For comparative purposes, we also apply a 2D synthesis ﬂow developed earlier by us [18] for a corresponding 2D implementation of the benchmarks. Our results show that a 3D design can signiﬁcantly reduce the interconnect power consumption (38% on average) and latency (13% on average). 2. RELATED WORK An introduction to the issues in NoC architecture design and synthesis has been presented in [3]. Methods for synthesizing pointto-point links and bus-based systems are presented in [4]-[6]. In [7]-[9], the authors present approaches to map cores on to regular NoC topologies. Synthesis of custom NoC topologies for 2D SoCs has been presented in [11]-[18]. In [18], we presented a method to synthesize the most power-performance efﬁcient NoC topologies for 2D SoCs. Several works have been investigating the 3D manufacturing processes [20], [21], [36]. Methods for 3D ﬂoorplanning and placement of cores, taking into account the thermal issues has been presented in [22]-[25]. Manufacturing of 3D interconnects has been addressed by [26] and [27]. Multi-dimensional regular topologies (like k-ary n-cubes, hypercubes) have been explored by researchers as viable interconnect solutions for chip-to-chip networks [19]. However, such standard topologies are not suitable for application speciﬁc SoCs, which are heterogeneous in nature. Synthesis of NoCs for 3D SoCs is a relatively new topic. New switch architectures for 3D have been presented in [33] and [35]. In [34], the authors present the use of NoCs as interconnects for 3D multi-processors. The electrical characteristics of vertical interconnects are analyzed in [36] and the authors also present a back-end design ﬂow to implement 3D NoCs. An analytical cost metric for 3D NoCs is presented in [30]. Design of standard topologies for 3D is analyzed in [31] and mapping of cores on to NoC topologies is presented in [32]. Power-delay analysis of 3D interconnects is presented in [28]. However, none of these works address the issue of synthesizing custom NoCs topologies for 3D SoCs. Moreover, the works do not present a comparison of the NoC power and latency for 2D and 3D NoC implementations. In [38], we presented a synthesis algorithm, which is based on a direct extension of the 2D NoC synthesis procedure. In the work, the NoC was designed for each layer separately, and the connectivity of the switches across the layers was then determined. The method forces cores in a layer to be connected to switches in the same layer and allows vertical interconnects only across adjacent layers. Thus, the inter-layer ﬂows incur large power and latency penalty (shown in Sub-section 4.2). In this paper, we propose a more general approach for topology synthesis, where the cores across layers can share switches, depending on the TSV constraints. Also, the work in [38] does not address additional issues, such as assigning switches to layers, placement of TSV macros and placement of network components with minimum perturbation of the input ﬂoorplan. 3. TOPOLOGY SYNTHESIS The core names, their communication requirements and the ﬂoorplan (core sizes, locations) are obtained as inputs to the tool. The maximum number of TSVs across any two layers is also obtained as an input. The NoC architectural parameters (such as NoC operating frequency and data width) can either be given as inputs, or can be varied in steps in a user-deﬁned range. For a given link width, the constraint on the maximum TSVs can be translated to a constraint on the maximum number of inter-layer links (referred as switch Core TSV macro Layer 2 horizontal link Layer 1 vertical link TSV macro switch Core Layer 0 Figure 1: Example vertical link max ill) allowed. To estimate the power, timing and area for the generated topology, models of the NoC components (switches and links) are obtained as inputs. In Figure 1, we show an example vertical link connecting two switches that are in the bottom-most and top-most layers. From the bottom layer, the link is ﬁrst routed horizontally on the metal layer and then vertically. In the second layer, an intermediate TSV macro is needed to allow the link to cut through the silicon. Then, the link is routed again on the metal layers in the second layer, and when aligned with the switch on the top layer, the link is fed vertically. The switch in the top layer has a TSV macro embedded for the port that is connected to this link. The area of the TSV macros for a particular link width is taken as input. For the synthesized topologies, our tool automatically places the TSV macros in the intermediate layers and on the corresponding switch ports. As topology synthesis is NP-Hard [10], we present efﬁcient heuristics for solving the problem. Varying the number of switches in a design has a great impact on the power consumption and latency. Increasing the number of switches may lead to smaller switch sizes, but also an increase in power consumption, as the packets have to traverse more switches. On the other hand, with more switches, the link power consumption may be reduced, as the links get shorter. The total power consumption is given by the combined effect of both these factors and is very hard to predict beforehand. In our method, topologies with different switch counts are synthesized and the most power-performance efﬁcient design is chosen. In the synthesis procedure, we perform the following steps: ﬁrst, we establish core to switch connectivity (Sub-section 3.1). Then, we obtain deadlock-free paths for trafﬁc ﬂows (Sub-section 3.2). Then, placement of switches and TSVs on the input ﬂoorplan are obtained (Sub-section 3.3). 3.1 Establishing Core to Switch Connectivity In this sub-section, we present methods for establishing connectivity between the cores and switches. D E FIN I T ION 1. Let n be the number of cores in the design. The 3D layer to which a core i is assigned is represented by layeri . The communication characteristics of the application are obtained and represented by a graph [7], deﬁned as follows: G(V , E ) with each vertex vi ∈ V representing a core and the diD E FIN I T ION 2. The communication graph is a directed graph, rected edge (vi , vj ) representing the communication between the Figure 2: LPG and the min-cut partitions Figure 3: PG and the min-cut partitions Figure 4: SPG and the min-cut partitions cores vi and vj . The bandwidth of trafﬁc ﬂow from cores vi to vj is represented by bwi,j and the latency constraint for the ﬂow is represented by lati,j . bandwidth requirements or tight latency constraints are assigned to the same partition and traverse a single hop in the network. We deﬁne a Partitioning Graph (PG) as follows: D E FIN I T ION 3. The partitioning graph is a directed graph, P G(U, H , α), that has the same set of vertices and edges as the communication graph. The weight of the edge (ui , uj ), deﬁned by hi,j . In this paper, hi,j is set to a combination of the bandwidth and the latency constraints of the trafﬁc ﬂow from core ui to uj : hi,j = α×bwi,j /max bw + (1−α)× min lat/lati,j , where max bw is the maximum bandwidth value over all ﬂows, min lat is the tightest latency constraint over all ﬂows and α is a weight parameter. The parameter α can be set by the designer based on the application characteristics or swept by the tool over a range of values, in order to meet the latency constraints. 2: U nmet = φ. Algorithm 1 Core-to- switch connectivity 1: Build partitioning graph PG(U,H,α) 3: {Vary number of direct switches in a range} 4: for i = 1 to |U | do 5: Perform i min-cut partitions of PG. Let the set P artitionj be set of vertices in j th partition, ∀j ∈ 1 · · · i. {Compute layer assignment for each switch:} 6: P ∀k∈partitionj layer k |partitionj | layer swj = 11: θ = θmin 7: 8: Compute paths for inter-switch ﬂows 9: If path computation failed, add i to set U nmet. 10: end for 12: while ((U nmet! = φ) & (θ ≤ θmax )) do for Each i ∈ U nmet do 13: 14: Build scaled partitioning graph, SPG(W,L,θ) 15: PG = SPG 16: Repeat steps 5 to 8 If valid paths found, remove i from set U nmet. 17: 18: end for 19: 20: end while θ = θ + θscale In the ﬁrst step of Algorithm 1, the partitioning graph is built. Then (in Step 3), the number of switches in the design is varied from 1 to the number of cores in the design. In the next step (step 5), for the current switch count, that many min-cut partitions of PG are obtained. All the cores in a partition are connected to the same switch and the partitioning is done such that each partition has about equal number of cores. Thus, those trafﬁc ﬂows with large E XAM P L E 1. For the communication graph from Figure 2, an example partitioning graph is shown in Figure 3. The cores are assigned to the two layers such that highly communicating cores are placed one above the other, which is an input to our synthesis algorithm. Here, we assume α = 1 and the bandwidth of the trafﬁc ﬂowing between cores with in a layer is lower than the trafﬁc between the cores across the layers. In the ﬁgure, we also show an example of 3 min-cut partitions of the graph. The partitioning leads to cores in different layers being assigned to the same partition. Then (in step 7), the layer assignment of each switch is computed as an average of the layers of the cores to which the switch is connected. Alternatively, the switch could also be assigned to the layer containing the most number of cores connected to it. At this point, the intra-partition trafﬁc ﬂows are taken care of and we need to establish connectivity across the switches for the inter-switch trafﬁc ﬂows. This step is explained in the next section. Then (in step 9), the resulting designs are evaluated to see whether they meet the max ill constraint and the switch counts that do not meet the constraint are stored in the set unmet. In order to facilitate meeting the max ill constraint for the design points in the set unmet, we use the Scaled Partitioning Graph, deﬁned as follows: D E FIN I T ION 4. A scaled partitioning graph with a scaling parameter θ , SPG(W , L, θ), is a directed graph that has the same set of vertices as PG. A directed edge li,j exists between vertices i and j , if ∃(ui , uj ) ∈ P or layeri = layerj . That is, in the SPG, along with the edges in PG, we deﬁne new edges between all cores in the same layer of 3D. We also reduce the edge weights of inter-layer ﬂows, depending on the scaling parameter θ . If this scaled graph is used for partitioning, then more cores in the same layer will be in a partition, thereby reducing the inter-layer links, at the expense of increasing the power consumption and latency of inter-layer ﬂows. To obtain designs with lower inter-layer links, the parameter θ is varied from θmin to θmax in steps of θscale in the algorithm (steps 12 to 19), until the max ill constraint is met. After several experimental runs, we determined that varying θ from 1 to 15 in steps of 3 gives good results. In order to cluster cores in a layer that actually communicate, we also need to ensure that the newly added edges have a lower edge weight than the original intra-layer edges. Please note that if the new edges are not added, the partitioner may still cluster cores across layers, which will not lead to a reduction in the inter-layer links. We denote the maximum edge weight in PG by max wt. We formally deﬁne the edge weights in SPG as follows: 5 10 15 Switch count 20 25 0 20 40 60 80 100 120 o P w e r n o c s u m p i t n o ( m W ) Switch power Core−to−switch link power Switch−to−switch link power Total power Figure 5: Power consumption in 2D 5 10 15 Switch count 20 25 0 10 20 30 40 50 60 70 80 90 o P w e r n o c s u m p i t n o ( m W ) Switch power Core−to−switch link power Switch−to−switch link power Total power Figure 6: Power consumption in 3D 0 − 1 1 − 2 2 − 3 3 − 4 4 − 5 5 − 6 6 − 7 7 − 8 8 − 9 9 −10 Wire length 0 2 4 6 8 10 12 14 16 18 N u m e b r o f w r i s e 2D 3D Figure 7: Wire length distributions li,j = 8>>>< >>>: hi,j , if (ui , uj ) ∈ P G & layeri = layerj θ×|layeri−layerj | , if (ui , uj ) ∈ P G & layeri (cid:6)= layerj , if (ui , uj ) /∈ P G & layeri = layerj hi,j θ×max wt 10×θmax 0 , otherwise (1) From the deﬁnition, we can see that the newly added edges have at most one-tenth the maximum edge weight of any edge in PG, which was obtained experimentally after trying several values. E XAM P L E 2. The SPG for θ = 10 for the PG from Example 1 is presented in Figure 4. In the SPG, the inter-layer links have lower weights and new edges are added between cores with in the same layer. The 3 min-cut partitions are now different, with more cores in the same layer belonging to the same partition. 3.2 Path Computation When establishing links across switches, we need to consider the max ill constraint. In this paper, we do not show the entire path computation algorithm (including the removal of deadlocks), as it is similar to the 2D case presented in earlier works, such as [15] and [18]. We only show how the max ill constraint is handled. During path computation, a high cost (SOF T I N F ) is assigned for establishing links between switches that would lead to increasing the number of vertical links across any layer above sof t max ill value. The sof t max ill is set to be few links less than the max ill value. The use of this softer constraint ﬁrst, facilitates the procedure to obtain more valid paths, when compared to directly using the hard max ill constraint. From experiments, we set the cost SOF T I N F to be ten times the maximum cost of any ﬂow and the value of sof t max ill to be 2 or 3 links less than max ill. We show the use of this softer constraint in Algorithm 2, for evaluating the cost of establishing a physical link across two switches i and j. Algorithm 2 Check Constraints (i,j) 1: Deﬁne sof t max ill and SOF T I N F 2: Estimate power consumption increase in opening and using link from i to j. 3: If establishing link increases vertical link count across any layer above sof t max ill, assign cost of SOFT INF for using switch i to j 4: If establishing link increases vertical link count across any layer above max ill, assign cost of INF for using switch i to j 3.3 Placement of NoC Components The ideal position of the switches and TSVs can be computed based on the positions of the cores and the connectivity between the switches and cores. For example, a switch position can be computed to be equidistant from all the cores to which it is connected. However, placing the components at the ideal positions may lead to overlap with the already placed cores. To remove such overlaps, we consider one switch or TSV macro at a time. We try to ﬁnd a free space near its ideal location to place it. If no space is available, we displace the already placed blocks from their positions in the x or y direction by the size of the component, creating space. As more components are placed, they can re-use the gap created by the earlier components. For lack of space, we do not present the detailed algorithm for placement in this paper. 4. EXPERIMENTS AND CASE STUDIES For the experiments, the NoC component library from [37] is used. The power and latency values of the switches and links of the library are determined from post-layout simulations, based on 65nm low power libraries. The vertical interconnects using TSVs are implemented based on the models from [36]. In [36], the authors show that the vertical links have much lower resistance and capacitance (an order of magnitude reduction) when compared to horizontal links. 4.1 Multimedia SoC case study We consider a benchmark of a realistic multimedia and wireless communication SoC for case-study (referred to as D 26 media). The benchmark contains 26 cores with irregular sizes, and performs based-band and multi-media processing. The system includes ARM, DSP cores, multiple memory banks, DMA engine and several peripheral devices. The cores are manually mapped on to three layers in 3D. For comparisons, we also consider a 2D implementation of the benchmark. The ﬂoorplans of the cores in each layer of the 3D and for the 2D design are obtained using existing tools [39]. For fair comparisons, we use the same objectives of minimizing area and wire-length when obtaining the ﬂoorplan for both the cases. To synthesize the topologies for the 2D case, We use our synthesis ﬂow developed earlier [38]. In Figures 5 and 6, we present the power consumption of the NoC topologies (power consumption on switches and links) synthesized by our tools for different switch counts for both cases. In all the experiments, we set the data width of the NoC links to 32 bits, to match the core data widths and the NoC operating frequency to the minimum point at which valid topologies are obtained (computed to be 400 MHz for this benchmark). We use a max ill constraint of 25 links for this and the experiments in the next sub-section. In Sub-section 4.3, we study the impact of varying this constraint. When very few switches are used in the design, they need to have more input/output ports, as they need to connect to more cores. A large switch can only support a low operating frequency, as the crit                              Figure 8: Most power-efﬁcient topology Benchmark D 36 4 D 36 6 D 36 8 D 35 bot D 65 pipe D 38 tvopd Table 1: 2D vs 3D NoC Comparison Power (mW) Switch power 2D 3D 65 70.5 76.5 82 105 104.5 48 43.3 63 58 37 38.11 Total power 2D 3D 215 112 230 125.5 320 160 116 79.5 169 162 89.5 60.78 Link power 2D 3D 150 41.5 154.5 43.5 215 55.5 68 36.2 106 104 52.5 22.67 Figure 9: Resulting 3D ﬂoorplan with switches 3D Application specific 3D Layer by layer 2.5 2 1.5 1 0.5 n o i t p m u s n o c r e w o p e v i t a l e R 0           D_36_4    D_36_6    D_36_8    D_35_bot  D_65_pipe D_38_tvopd Figure 10: Comparison with layer-by-layer Latency (cyc) 2D 3.28 3.57 4.37 6.04 2.53 4 3D 3.14 3.5 3.65 4.2 2.57 3.6 ical path inside the switch increases with its size. In order to meet the 400 MHz requirement, we could only obtain valid topologies with 4 or more switches, thus the plots starts at 4 switches. In the plots, we show the switch, switch-to-switch link and core-to-switch link power consumption values as well. For this benchmark we can observe a power savings of 25% for the 3D relative to the 2D case. This is due to the fact that the long horizontal wires in a 2D design are replaced by shorter vertical wires. In Figure 7, we show the wire-length distribution of the links in 2D and 3D cases. From the ﬁgure, as expected, the 2D design has many long wires. In Figures 8 and 9, we present an example topology synthesized by our tool and the ﬂoorplan of the cores and network components for the 3D case. 4.2 2D vs. 3D Comparison We applied our synthesis procedure on varied set of benchmarks to validate the gains under different application scenarios. We consider three distributed benchmarks with 36 cores (18 processors and 18 memories): D 36 4, D 36 6 and D 36 8, where each processor has 4, 6 and 8 trafﬁc ﬂows going to the memories. The total bandwidth is the same in the three benchmarks. We consider a benchmark, D 35 bot that models bottleneck communication, with 16 processors, 16 private memories (one processor is connected to one private memory) and 3 shared memories to which all the processors communicate. We also consider two benchmarks where all the cores communicate in a pipeline fashion: 65 core (D 65 pipe) and 38 core designs (D tvopd). In the last two benchmarks, each core communicates only to one or few other cores. The power consumption for the least power design points for 2D and 3D, as well as the average latency are presented in Table 1. Most of the power savings obtained in 3D are due to shorter wires. For this reason, we can observe large power savings for the distributed benchmarks, where there are trafﬁc ﬂows to many different cores. We can also notice reasonable power savings for the bottleneck design, because the wires going to shared memories are long, though the trafﬁc to the shared memories is smaller than to the private memories. For the pipelined benchmarks, lower savings are obtained. For the different benchmarks, on average, a 38% power reduction and 13% latency reduction are obtained in the 3D case when compared to a 2D implementation. In Figure 10, we show the power consumption of the topologies synthesized by the approach presented in [38], with respect to the proposed approach for the different benchmarks. The method in [38] connects cores in a layer to switches in the same layer. Thus, the inter-layer trafﬁc needs to traverse more switches to reach the destination, leading to an increase in power consumption and latency. As seen from Figure 10, the method presented in this work results in 40% reduction in NoC power consumption, when compared to the earlier work. 4.3 Impact of Inter-layer Link Constraint and Comparisons with Mesh Imposing a stricter constraint on max ill results in topologies having more switches. When there are more switches, more cores in a layer are connected to a switch in the same layer, reducing the number of inter-layer links. However, the inter-layer trafﬁc ﬂows would need to traverse more switches, there by leading to higher power consumption and latency. We perform topology synthesis for the D 26 media design with different max ill constraint values, and the power, latency values for the different points are presented in Figures 11 and 12. With a tighter TSV constraint, the power consumption and latency increases signiﬁcantly, as more switches are needed in the design. For completeness, we compare power consumption of the topologies generated by our procedure to a standard topology. We generate best mapping (optimizing for power, meeting the latency constraints) of the cores on to a mesh topology, and remove any unused switch-to-switch links. Compared to this optimized mesh topology, we obtain a large power reduction for the custom topologies (an average of 51%), shown in Figure 13. Our experiments also showed that we obtain 21% reduction in latency when compared to the optimized mesh.         190 180 170 160 150 140 130 120 ) W m ( n o i t p m u s n o c r e w o p m u m i n i M 110 0 4 3.5 3 2.5 2 1.5 1 0.5 ) s e l c y c ( y c n e t a l m u m i n i M 3D Application specific 3D Opt−mesh 450 400 350 300 250 200 150 100 50 ) W m ( n o i t p m u s n o c r e w o P 5 10 15 20 Maximum number of inter−layer links (max_ill) 25 0 0 5 10 15 20 Maximum number of inter−layer links (max_ill) 25 0           D_36_4    D_36_6    D_36_8    D_35_bot  D_65_pipe D_38_tvopd Figure 11: Impact of max ill on power Figure 12: Impact of max ill on latency Figure 13: Comparisons with mesh Even though the algorithm explores a large space of solutions, due to the use of efﬁcient heuristics presented, all the experiments could be performed in few hours (on a system operating at 2 GHz). Also, it is important to note that the synthesis algorithm has to be performed only once at design time for a system and the timing overhead is negligible. 5. CONCLUSIONS Networks on Chips (NoCs) are necessary to achieve a scalable communication infrastructure in 3D chips. The use of NoCs in 3D ICs introduces several new and challenging problems. Building a custom NoC topology that meets the application communication requirements, as well as the 3D technological constraints, is a critical problem that needs to be addressed. In this work, we presented SunFloor 3D, a tool for NoC topology synthesis for 3D ICs. The tool also performs path computation, assignment and placement of network components in the 3D layers. Our experiments on several realistic benchmarks show that the tool produces topologies that result in large NoC power and latency savings (54% and 21%, respectively) when compared to standard topologies. We also presented a comparative analysis of NoCs in 2D and 3D, which shows that 3D integration can produce large interconnect power and latency reduction (38% and 13%, respectively). In future, we plan to address the design of NoCs for Globally Asynchronous Locally Synchronous (GALS) paradigm for 3D ICs. 6. ACKNOWLEDGMENT We would like to acknowledge the ﬁnancial contribution of the European Union under Project ICT-ARTIST-DESIGN. 7. "
2009,An Asynchronous Power Aware and Adaptive NoC Based Circuit.,A fully power aware globally asynchronous locally synchronous network-on-chip circuit is presented in this paper. The circuit is arranged around an asynchronous network-on-chip providing a 17 Gbits/s throughput and automatically reducing its power consumption by activity detection. Both dynamic and static power consumptions are globally reduced using adaptive design techniques applied locally for each NoC units. The dynamic power consumption can be reduced up to a factor of 8 while the static power consumption is reduced by 2 decades in stand-by mode.,
2005,An Asynchronous Router for Multiple Service Levels Networks on Chip.,"Networks on chip that can guarantee quality of service (QNoC) are based on special routers that can support multiple service levels. GALS SoCs call for asynchronous NoC implementations, to eliminate the need for synchronization when crossing clock domains. An asynchronous multi-service level QNoC router is investigated. It comprises multiple interconnected input and output ports, and arbitration mechanisms that resolve any output port and service level conflicts. Buffering and credit based transport are enabled, enhancing throughput. A synchronous and an asynchronous router have been designed, and their performance is compared. The asynchronous router requires less area and enables a higher data rate.",
2003,A fault model notation and error-control scheme for switch-to-switch buses in a network-on-chip.,"The reliability of a network-on-chip will be significantly influenced by the reliability of the switch-to-switch connections. Faults on these buses may cause disturbances on multiple adjacent wires, so that errors on these wires can no longer be considered as statistically independent from one another, as it is expected due to deep submicron effects. A new fault model notation for buses is proposed which can represent multiple-wire, multiple-cycle faults. An estimation method based on this notation is presented which can accurately predict error probabilities. This method is used to examine bus encoding schemes. Finally, an encoding scheme for four quality-of-service classes is proposed which can be dynamically selected for each packet.","A Fault Model Notation and Error-Control Scheme for Switch-to-Switch Buses in a Network-on-Chip Heiko Zimmer Darmstadt University of Technology Darmstadt, Germany heiko@mes.tu-darmstadt.de Axel Jantsch Royal Institute of Technology (KTH) Stockholm, Sweden axel@imit.kth.se ABSTRACT The reliability of a Network-on-Chip will be signiﬁcantly inﬂuenced by the reliability of the switch-to-switch connections. Faults on these buses may cause disturbances on multiple adjacent wires, so that errors on these wires can no longer be considered as statistically independent from one another, as it is expected due to deep submicron eﬀects. A new fault model notation for buses is proposed which can represent multiple-wire, multiple-cycle faults. An estimation method based on this notation is presented which can accurately predict error probabilities. This method is used to examine bus encoding schemes. Finally, an encoding scheme for four Quality-of-Service classes is proposed which can be dynamically selected for each packet. Categories and Subject Descriptors B.4.3 [Input/Output and Data Communications]: Interconnections (Subsystems); B.8.1 [Performance and Reliability]: Reliability, Testing, and Fault-Tolerance General Terms Design, Reliability Keywords Network-on-Chip, Fault Tolerance, Bus Encoding 1. INTRODUCTION To eﬃciently use the billions of transistors that will soon be available on a single chip, new design methods will be necessary. While the reuse of components in building Systemson-Chip (SoC) will continue, their interconnection becomes a ma jor concern. Currently used shared buses and dedicated wires exhibit limited scalability. A new approach to overcome these limitations is to implement a Network-on-Chip (NoC) to handle the on-chip Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro£t or commercial advantage and that copies bear this notice and the full citation on the £rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci£c permission and/or a fee. CODES+ISSS’03, October 1–3, 2003, Newport Beach, California, USA. Copyright 2003 ACM 1-58113-742-7/03/0010 ...$5.00. communication [2, 7, 8]. In such an architecture, communication can be decoupled from computation: The computational blocks called resources (which can be anything from processors or DSPs over FPGA, mixed signal or ASIC blocks to any kind of memory) are connected to an inter-resource communication network. ing in a n × m mesh of switches. Adjacent switches are conWe assume a NoC-architecture that employs packet switchnected by wide buses so that a complete packet can be transmitted in parallel. By a network interface, one resource is connected to every switch. These switches must be as small and eﬃcient as possible [10] in order to limit the overhead (in terms of area, power and delay) introduced by the NoC. s s s R R R s s s R R R s s s R R R s s s R R R Bus Switch Network Interface Resource Figure 1: Complete NoC and detailed view of one resource/switch block QoS Levels The Network-on-Chip becomes the communication backbone to handle all data transmitted between components of a SoC. Due to the varying requirements of communication streams, it must implement transmission at multiple Quality-of-Service (QoS) levels (classiﬁed by parameters like bandwidth, reliability, latency etc.) [7]. The transport of multimedia data may require maximum bandwidth whereas data integrity must be guaranteed for transfers from and to memories. We propose four QoS levels oﬀering diﬀerent characteristics to applications: Maximum Bandwidth: Since the amount of wires available for routing the inter-switch buses is limited, the redundancy introduced by bus encoding will directly inﬂuence the application payload that can be transported with every packet. Consequently, maximum bandwidth is available to the application when no encoding is applied. Guaranteed Integrity: To ensure data integrity as far as possible, error detection methods can be used. Data correction is not attempted since it might result in miscorrection. If erroneous data is detected, a ﬂag can be set, a retransmission can be initiated or the whole packet can be dropped. Minimum Latency: To achieve minimum latency, packets are always forwarded. Error correction is performed, the underlying assumption is that all errors can be corrected by the code used. This mode is well suited for applications that can tolerate rare errors (due to miscorrection) but depend on receiving data at a constant rate. High Reliability: Using codes capable of correcting errors and detecting uncorrectable errors at the same time combines the characteristics of the two previously described modes at the expense of lower bandwidth and higher latency. Faults on DSM buses During the next decade, deep submicron (DSM) technology will have to cope with more transient faults than ever before. The number of single-event-upsets (SEU) due to various reasons (charge injection by neutrons or α-particles, process variations, electro-magnetic interference) will increase along with crosstalk, mainly aﬀecting long interconnects [1]. Technology scaling also gives rise to new error sources: For instance can the eﬀects of neutrons (which have formerly only been a concern with memories) now cause upsets in logic elements and low power/low capacitance buses as well [9]. However, the main source for errors on buses will be crosstalk, which can lead to increased delay or cause voltage glitches on wires [4]. Furthermore, crosstalk can inherently multiple wires, causing both 0 → 1 and 1 → 0 errors). cause multi-bit and bidirectional errors [6] (i.e., disturbing Since faults on the massively parallel buses between adjacent switches will mainly be transient and not necessarily conﬁned to one wire, conventional fault models are not sufﬁcient to accurately describe them. We have developed a new fault model notation for faults on on-chip buses. It is capable of describing a wide range of faults and as a significant feature, it supports the modeling of faults that aﬀect multiple wires and last multiple bus cycles. Furthermore, arbitrary eﬀects of faults can be represented. We show that accurate prediction of error probabilities can be achieved by an estimation method based on this notation which includes structural information (eﬀect, duration and aﬀected wires) about the faults. Evaluating various bus encoding schemes, we derive some general design guidelines to achieve higher reliability of transmissions over on-chip buses in the presence of multiple-wire faults. Eventually, a case study combines all aspects of this work and shows how to select encoding schemes for a fault-tolerant NoC supporting network traﬃc with non-uniform QoS requirements. System-wide energy management is not considered. When a NoC is operated in diﬀerent power-saving modes, we expect diﬀerent fault scenarios. Our approach is compatible and complementary to power-saving techniques such as [12]. 2. RELATED WORK The importance of crosstalk faults for bus reliability has lead to the development of a crosstalk fault model which can be used to generate test vectors [4]. To evaluate the dependability of interconnects, a hardware-software co-design methodology has been used to compare bus encodings [9]. Also, a combination of error detection and retransmission was identiﬁed as very energy eﬃcient [3]. This was extended to an adaptive low-power transmission scheme for NoCs [12]. All these approaches lack a comprehensive fault model notation that is complete or can at least represent all expected fault types. Such a model must explicitly support faults spanning multiple wires and it must not be limited to one fault type. In the presence of crosstalk eﬀects, statistical independence of errors on adjacent bus lines cannot be assumed. However, the eﬀect of this on bus encoding schemes has not been discussed previously. The main contribution of this paper is a high-level fault model notation for buses which can represent multiple-wire, multiple-cycle faults on single- or multi-layer on-chip bus architectures. Furthermore, we present an approach to adaptive encoding of on-chip buses with QoS-support. 3. MODELING FAULTS ON NOC-INTERCONNECTS On a bus, arbitrary faults may occur. Of these, all faults that are caused by the same physical eﬀect belong to one fault type fi . For instance, crosstalk faults and faults caused by neutrons form two fault types. Faults of diﬀerent types are statistically independent. 3.1 Fault Model Notation The fault model FM(fi ) describes faults of type fi in a given bus architecture. It is based on the faults’ probability of occurrence (αi ), their characteristics (expressed in the matrix P i ) and a distance metric DMi inﬂuenced by the physical bus layout. FM : fi → (αi , P i , DM i ) Probability of Occurrence We deﬁne αi as the probability of occurrence of a fault of type fi per wire and cycle. Thus, αi = 1 128 leads to one fault of type fi occurring on a 128 bit wide bus every cycle or every 8 cycles on a 16 bit bus. Fault Characteristics When a fault of type fi occurs, it has a probability pi (w, d, e) to aﬀect w wires for a duration of d time units (typically clock or transfer cycles) with the eﬀect e. The eﬀect of a fault is selected from a list of all possible eﬀects. See table 1 for an incomplete list including symbolic names. Eﬀect e Inv Set0 Set1 Description logic value on wires inverted wires forced to logic 0 wires forced to logic 1 SetRand wires forced to random logic value wire wi forced to value of wire wi−1 delay: wire set to previous value . . . Bridge Del . . . 1 2 3 4 5 6 7 Table 1: (Numerical) representation of faults’ eﬀects All possible combinations of pi (w, d, e) are represented in the normalized matrix P i of the dimensions wmaxi × (dmaxi + 1) × emax . wmaxi and dmaxi are the maximum values for the number of wires aﬀected and the fault’s duration respectively. These maximum values can be diﬀerent for every fault type fi . While dmaxi can take any positive value, wmaxi must not exceed the bus width wmax of the interconnects between the switches: wmaxi ≤ wmax . emax is the number of diﬀerent eﬀects which can be described. E.g., when setting emax = 1 and thus restricting the model to the eﬀect Inv, the normalized matrix P i is written as   P i = pi (1, 0, Inv) pi (2, 0, Inv) ... · · · · · · pi (1, dmaxi , Inv) pi (2, dmaxi , Inv) . . . ... pi (wmaxi , 0, Inv) · · · −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→ pi (wmaxi , dmaxi , Inv) f ault duration   n o . o f − − − − − − − − → r e s w i A fault generally lasts at least one clock cycle (d ≥ 1). The elements of P i with the index d = 0 are used to indicate the probability of permanent faults. Since the matrix elements describe the probabilities of diﬀerent characteristics of one fault occurrence, their values must satisfy the following condition: wmaxi(cid:7) dmaxi(cid:7) emax(cid:7) pi (a, b, c) = 1 a=1 b=0 c=1 The manifestation of a fault of type fi aﬀecting w wires for d cycles with eﬀect e is determined by the probability of occurrence and the normalized value pi (w, d, e) to a probability of αi · pi (w, d, e). Example 1 (fault type f1 ). The characteristics of a single-event-upset that is always conﬁned to one wire, lasts only one cycle and has the eﬀect Inv are represented by matrix element p1 (1, 1, Inv) = 1. Since for this fault type dmax1 = wmax1 = 1, the resulting matrix is P 1 = p1 (1, 0, Inv) p1 (1, 1, Inv) 0 1 (cid:8) (cid:9) (cid:8) (cid:9) = meaning that if a fault of type f1 occurs, it wil l always have the characteristics w = 1, d = 1 and e = Inv. The probability that a fault of this type occurs is determined by its occurrence probability α1 . Example 2 (fault type f2 ). P 2 characterizes a fault that can aﬀect multiple wires (e = Inv) for multiple cycles. (cid:10) (cid:11) P 2 = 0 0.65 0 0.2 0.1 0.05 meaning that a fault of type f2 wil l be conﬁned to one wire and one clock (or transfer) cycle in 65% of al l occurrences. Another 20% of these faults wil l disturb two wires for one clock cycle. Only in 15% can the eﬀects be noted for two cycles (on one (10%) or two wires (5%) respectively). Note that in both examples the elements of the ﬁrst column are zero, indicating that faults of type f1 or f2 wil l never lead to permanent errors. Example 3 (permanent fault). A fault that causes a permanent defect on one wire whenever it occurs, can be described by a P -matrix whose only non-zero elements are: ppermanent (1, 0, Set0) = 0.5 ppermanent (1, 0, Set1) = 0.5 meaning that faults of this type wil l cause a permanent error on one wire; stuck-at-0 and stuck-at-1 are equal ly probable. Distance Metric One parameter of the fault characteristics is the number of wires that are aﬀected by a fault. This does not include the information which wires these are. Without loss of generality, we say that a fault aﬀects w adjacent wires and describe the relative distance between wires in a distance metric DMi . This distance metric may be diﬀerent for every fault type and bus layout. We use a weighted, directed acyclic graph (DAG), examples are given in ﬁgure 2. The w wires aﬀected by a fault will be those with the lowest distance from the wire where the fault occurs. If multiple wires have the same distance, the choice among them is random. a) 1 1         2 2 b) 3 3 2 2 1 3         1 1 Figure 2: Example for distance relation between wires of a bus running on one or two layers 3.2 Fault Scenario For a complete representation of all faults that occur in a given environment, a set of fault models is necessary. This set is referred to as a fault scenario and is deﬁned as: FM(f1 ), FM(f2 ), . . . , FM(fn ) S = (cid:12) (cid:13) When using a fault scenario in simulation, at every time step it will be checked for each wire if one or multiple faults have occurred (based on the probability of occurrence). If a fault of type fi has occurred, P i and DM i are evaluated to determine the fault’s duration, eﬀect and the aﬀected wires. Used Fault Scenario The fault scenario used throughout this paper is a set of three fault models: FM(f1 ), FM(f2 ), FM(f3 ) S = (cid:13) (cid:12) (cid:12) (cid:13) = (α1 , P 1 , DM1 ) , (α2 , P 2 , DM2 ) , (α3 , P 3 , DM3 ) All three fault models were assigned the same probability of −9 and a distance metric occurrence α1 = α2 = α3 = α = 10 equivalent to that from ﬁgure 2a was used. While the ﬁrst two fault models are those from examples 1 and 2, the third one was extracted from a more detailed experiment: Since the inter-wire capacitance CI between adjacent wires of a bus has a signiﬁcant inﬂuence on the total capacity which has to be charged during a bus transition, the signal delay depends strongly on the bus transition pattern. Type 4C 3C v1 v1 v1 −→ v1 v1 v1 Transitions v1 v1 v2 −→ v1 v1 v2 v2 v1 v1 −→ v2 v1 v1 Type 2C 1C v1 v2 v3 −→ v1 v2 v3 Transitions v1 v2 v2 −→ v1 v2 v2 v2 v2 v1 −→ v2 v2 v1 Table 2: Classiﬁcation of crosstalk sequences Considering three adjacent wires, transition patterns can be classiﬁed in 1C. . . 4C sequences (table 2) depending on how much they slow down the transition of the middle signal [5]. Out of a large number of random data, we identiﬁed all 4C sequences (causing maximum signal delay) and marked the middle wire as fault location. Translating the resulting error patterns into our fault model using e = Inv, we derived   P 3 = 0 0.6768 0.0836 0.0102 0.0013 0 0.1521 0.0195 0.0028 0.0003 0 0.0353 0.0047 0.0007 0 0 0.0090 0.0009 0.0002 0 0 0.0019 0.0002 0 0 0 0.0003 0.0001 0 0 0 0.0001 0 0 0   . Due to the lack of a more realistic fault scenario for future DSM technology, all further discussion and results are based on the described fault scenario. I.e., transmission over a planar bus in presence of the three fault types is considered. 4. ERROR-CONTROL CODING FOR NOC COMMUNICATION BUSES In this section, possibilities are explored how error-control coding can be used on the switch-to-switch buses of a NoC to implement a network supporting diﬀerent QoS levels. Knowing that errors on adjacent wires of these buses are not always statistically independent, coding techniques to enhance the bus reliability are discussed. In a NoC running with gigahertz clock frequency, consisting of 100 switches and about 20.000 switch-to-switch wires, we have to take −20 (one every 107 sec.) into faults with a probability of 10 account to assess reliability over four months. Since simulation cannot be used and to eﬃciently compare diﬀerent coding schemes, a method for the estimation of error probabilities is presented. This method is ﬁnally used to compare coding schemes providing diﬀerent QoS-characteristics. 4.1 Coding Techniques for NoC-Buses A code protecting data on the switch-to-switch buses must allow for fast decoding because decoding has to be completed before the switch can make a routing decision. Additionally, area constraints motivate a switch design with as little buﬀers as possible. We assume a NoC architecture that requires very low area overhead and high performance from the switches. Thus, we consider only codes that can process 100-200 bit wide buses in a single clock cycle and that can be implemented in a few gates of hardware for each bit. The requirement of fast decoding can be fulﬁlled by combinatorial logic circuits of low logic depth. Therefore, parity-based codes (e.g., Hamming or Hsiao codes [11]) are considered. These can be employed at various coding schemes: A singleerror correcting (SEC) code can correct all single errors. All other errors lead to miscorrection. A double-error detecting (DED) code, on the other hand, detects all single and double errors. In fact, a DED code detects even more errors: If there are 2k valid codewords of length n, 2n − 2k error patterns are detected. The properties of these two operating modes are combined in SEC-DED codes which require one more bit of redundancy to encode the same amount of information. Using codes with the ability to detect/correct more than two random errors usually makes decoding slower because arithmetic decoding is necessary [11]. Therefore, we focus on SEC, DED and SEC-DED codes and propose methods that help to enhance the capabilities of these codes in the presence of multiple-bit errors. One possibility is to divide the network packet into several smaller blocks encoded separately. This paral lel coding increases the redundancy, but enhances the overall error detection/correction capabilities and reduces the length of the critical path in the decoder. This approach also enables using diﬀerent codes for diﬀerent parts of the packet. If the data is split into multiple blocks encoded separately, the n bits of a data block can be assigned to n adjacent wires of the bus or they can be interleaved, so that they will be assigned to the wires x, x + δ, x + 2δ, . . . , x + (n − 1)δ . The distance δ between two wires that belong to the same block is called interleaving degree. To compare the capabilities of diﬀerent coding schemes, we use the probability of uncorrected and undetected errors in a packet, Perr,U C and Perr,U D respectively. It can be seen from ﬁgure 5 that in the presence of multibit errors, interleaving can lead to the reduction of those probabilities by several orders of magnitude. At small interleaving degrees, multi-wire faults may easily aﬀect multiple bits of one block. With increasing interleaving degree, the probability that a fault aﬀects multiple wires of one block decreases. In the fault scenario used, faults can aﬀect up to 7 adjacent wires. This is why in ﬁgure 5, Perr,U C and Perr,U D constantly decrease with increasing interleaving degree. For interleaving degrees greater than 7, no further improvement can be achieved for the fault scenario used. 4.2 Estimation of Error Probabilities To assess coding schemes, simulation is not feasible for −20 . faults with occurrence probabilities as low as 10 We have therefore developed an estimation method to predict error probabilities which is based on the proposed fault model notation. Thereby, errors spanning multiple adjacent wires are taken into account. In order to be able to assess block codes, we compute error probabilities for each block. For instance, a single error in a block of 4 wires of a bus occurs if exactly one wire is erroneous. Single errors are caused by faults aﬀecting only one of the wires within the block or if a wire at the block’s border is aﬀected by multiple-bit errors. Thus, the probability that a single error is caused by an erroneous value of a border wire is higher compared to a wire in the middle of the block. Figure 3 shows errors due to two diﬀerent faults, both leading to a single error within the considered block. a) b) 4 bit block Figure 3: Faults aﬀecting one and two adjacent wires, both leading to single errors in the 4 bit block Figure 4 shows the probability of single and double errors when transferring data words of diﬀerent width over a bus on adjacent wires or with interleaving. In these ﬁgures, estimations derived by the method proposed below are compared with simulation results and a second estimation based only on the fault occurrence probability. The simulation results were generated using a SystemC model for a bus which introduced errors according to the fault scenario from section 3.2. While results for a fault occurrence probability −4 are shown, other magnitudes of α yielded compaα = 10 rable accuracy for both interleaved and adjacent alignment. The algorithm to estimate the probability of x-bit errors for blocks of n bits with an interleaving degree of δ is: 0 10 20 30 40 50 n wires of a 120bit wide bus (interleaved, interleaving degree d=120/n) 60 10−7 10− 6 10− 5 10− 4 10− 3 10− 2 10− 1 e r r o r p r b a b o t i l i y estimation of single and double error probability simulation results                                estimation based on fault model                   simple estimation based on occurrence probability single errors  double errors  4 5 6 7 8 bus with n adjacent wires 9 10 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 x 10− 4 e b u o d l e r r o r p r b a b o t i l i y estimation of double error probability simulation results              estimation based on fault model simple estimation based on      occurrence probability          Figure 4: Estimation and simulation results 1. Compute the average probability that a wire is not aﬀected by any fault: Pok 2. Compute the probabilities Pb1 , . . . , Pbx that 1 . . . x adjacent bits on the border of the considered block are erroneous due to one fault. Combinations of diﬀerent faults leading to erroneous bits are not counted. 3. In a similar way, compute the probabilities that 1 . . . x adjacent bits in the middle of the considered block are erroneous. (Pm1 , . . . , Pmx ) 4. From all possible error combinations leading to a xor one double error and x − 1 single errors), the overbit error in the considered block (e.g., x single errors all probability of x-bit errors is computed using Pok , Pb1 , . . . , Pbx and Pm1 , . . . , Pmx . Using this approach, the probability Pde of double errors in a block of n bits is for instance computed as · (2 · Pb2 + P 2 b1 + 2 · Pb1 · Pm1 · (n − 2) + (n − 2 − 1) · Pm2 + P 2 ) The inﬂuence of the interleaving degree δ is contained in the values computed in the steps 1.–3. Pde = P (n−2) ok m1 · (cid:8) n−2 2 (cid:9) The current implementation accurately predicts error probabilities for faults on a planar bus whose eﬀect is to invert the logic value. It seems feasible to extend it to incorporate faults with diﬀerent eﬀects and other bus layouts. 4.3 Multiple QoS-levels in a NoC The NoC must provide reliable communication services to resources. To guarantee packet delivery, the header (including destination address) of a packet must be particularly strong protected. On the other hand, the protection level of the payload should be tunable by the application. Given a ﬁxed number of physical wires, we propose to select the encoding scheme for the header ﬁrst, so that the minimum reliability constraint is met. The number of wires required for header encoding limits those remaining for payload transmission. Payload encoding schemes for the desired service levels have to be selected so that the remaining wires are used eﬃciently. The selection is guided by trading oﬀ reliability versus bandwidth. We show this approach in the following example where we assume that 128 wires are available and that a 16 bits wide header is used. Header Protection Since the header protection should correct as many errors as possible while at the same time leaving as little errors as 1 2 3 4 5 6 interleaving degree 7 8 9 10 10− 25 10− 20 10− 15 10− 10 10− 5 e r r o r p r b a b o i t i l i s e 4x4 SEC− DED (32 wires)  2x8 SEC− DED (26 wires)  1x16 SEC− DED (22 wires) uncorrected errors  undetected  errors  Figure 5: Reduction of error probabilities by interleaving blocks on a 128 bit bus The header (16 bits) can be encoded as one block (1 × 16 possible undetected, the obvious choice is a SEC-DED code. SEC-DED), or as 2 blocks of 8 bits each (2 × 8 SEC-DED) or as 4 blocks (4 × 4 SEC-DED). The notation b × k means b blocks with k useful information bits each. code selection estimation results check bits coding scheme (cid:14) FM(f1 ), . . . , FM(fn ) fault scenario S = information bits to be protected, buswidth (cid:15) , Figure 6: Code quality assessment The estimation method we presented above was used to compare the properties of diﬀerent encoding schemes. Figure 6 illustrates how this method was used to derive table 3 which shows the amount of wires required for the diﬀerMax. Crit. interl. path 5 9 9 8 16 6 Code Wires 1x16 22 2x8 26 4x4 32 Perr,U C −11 −15 −16 Perr,U D −18 −23 −23 1.47 · 10 1.21 · 10 4.33 · 10 2.37 · 10 4.63 · 10 1.32 · 10 Table 3: Comparison of header protection with different SEC-DED codes ent encoding schemes along with information about the expected decoder logic depth and the probabilities of uncorrected and undetected errors (Perr,U C and Perr,U D ). As a without encoding, the error probability is 5.33 · 10 comparison: When transmitting 16 bits over adjacent wires −8 . Based on the information from table 3 and complementing experiments, the 2 × 8 SEC-DED code was chosen as header encoding scheme for this example. It is a reasonable tradeoﬀ between error probability and decoder speed, leaving 102 of the 128 wires to transmit the payload. Payload Protection Regarding the services discussed at the beginning of this paper, the Maximum Bandwidth (MB) mode is inherent in         every implementation. In this example, the bandwidth of this mode is 102 bits/packet and the probability of an erroneous transfer is 3.36 · 10 −7 . Both the Guaranteed Integrity (GI) and Minimum Latency (ML) modes can be implemented with one code, using the property that every SEC code can also work as DED code: The same codewords are used for transmission, the encoder is identical and the DED code just uses the ﬁrst part of the decoder block. Thus, these two services oﬀer the same bandwidth to the application, but diﬀerent protection characteristics. The possibility of this eﬃcient implementation has inﬂuenced the selection of examined codes. The selection of an appropriate coding scheme is guided by reliability and bandwidth constraints. Parameters are the number of parallel encoded blocks and their interleaving degree. This trade-oﬀ is shown in table 4. Out of these coding schemes, the appropriate one can be chosen. Code 1x95 2x45 3x28 Max. interl. 1 2 3 Avail. bandw. 95 90 84 Perr,U C Perr,U D used as SEC used as DED 5.68 · 10 6.13 · 10 3.77 · 10 1.71 · 10 5.88 · 10 3.20 · 10 −9 −10 −12 −8 −9 −10 Table 4: Error probabilities for diﬀerent operation modes of SEC (or DED) codes, 102 physical wires Since the High Reliability (HR) mode is based on a SECDED code, it will require diﬀerent encoder/decoder logic in parallel to that used for the other modes. Note that SECDED codes oﬀer one information bit less per block compared to SEC codes occupying the same amount of wires. For the 128 bit bus of our example, we have selected the coding schemes from table 5. The selection of services and Mode Header protect. Payload protect. Payload MB 2x8 SEC-DED none 102 GI 2x8 SEC-DED 2x45 DED 90 ML 2x8 SEC-DED 2x45 SEC 90 HR 2x8 SEC-DED 3x27 SEC-DED 81 Table 5: Selected coding schemes coding schemes a NoC supports is a design-time decision which depends on the intended application and environment, whereas each packet can be encoded with one of these codes during run-time. Since subsequent packets can be encoded diﬀerently, the information about the payload encoding scheme is transmitted as part of the header information. 5. CONCLUSIONS We have presented a fault model notation for faults occurring on on-chip buses that can represent a wide range of faults due to deep submicron eﬀects, among them multiplewire faults. We showed that error probabilities can be accurately predicted by this model in situations where the statistical independence of errors on bus lines cannot be assumed. This is important because crosstalk faults in future technology generations will most likely aﬀect multiple wires. Based on simulation and estimation results, we derived design guidelines for bus encoding schemes, namely splitting the data into multiple, separately encoded blocks and interleaving them. Using these simple methods, the probability of erroneous transfers can be reduced signiﬁcantly. The tradeoﬀ between required reliability and the necessary overhead to achieve it was explored for diﬀerent application requirements, leading to a proposal of a NoC that supports network traﬃc at four QoS levels. From these, each application can dynamically select the most appropriate one for its communication. An application can even adapt its policy during run-time when too many errors are encountered. The speciﬁc constraints assumed for NoC-switches inﬂuenced the selection of considered codes which we belive is a good compromise when the critical path in the decoder should be kept as short as possible. With diﬀerent requirements or when pipelining is possible, alternatives should be considered. 6. "
2009,Design and Management of Voltage-Frequency Island Partitioned Networks-on-Chip.,"The design of many core systems-on-chip (SoCs) has become increasingly challenging due to high levels of integration, excessive energy consumption and clock distribution problems. To deal with these issues, we consider network-on-chip (NoC) architectures partitioned into several voltage-frequency islands (VFIs) and propose a design methodology for runtime energy management. The proposed approach minimizes the energy consumption subject to performance constraints. Then, we present efficient techniques for on-the-fly workload monitoring and management to ensure that the system can cope with variability in the workload and various technology-related parameters. Simulation results demonstrate the effectiveness of our approach in reducing the overall system energy consumption for a real video application. Finally, the results and functional correctness are validated using an field-programmable gate-array (FPGA) prototype for an NoC with multiple VFIs.",
2009,HeMPS - a Framework for NoC-based MPSoC Generation.,"Multi-processor systems-on-chip (MPSoCs) are increasingly popular in embedded systems. Due to their complexity and huge design space to explore for such systems, CAD tools and frameworks to customize MPSoCs are mandatory. Some academic and industrial frameworks are available to support bus-based MPSoCs, but few works target NoCs as underlying communication architecture. A framework targeting MPSoC customization must provide abstract models to enable fast design space exploration, flexible application mapping strategies, all coupled to features to evaluate the performance of running applications. This paper proposes a framework to customize NoC-based MPSoCs with support to static and dynamic task mapping and C/SystemC simulation models for processors and memories. A simple, specifically designed microkernel executes in each processor, enabling multitasking at the processor level. Graphical tools enable debug and system verification, individualizing data for each task. Practical results highlight the benefit of using dynamic mapping strategies (total execution time reduction) and abstract models (total simulation time reduction without losing accuracy).",
2005,"Design and analysis of an NoC architecture from performance, reliability and energy perspective.","Network-on-chip (NoC) architectures employing packet-based communication are being increasingly adopted in system-on-chip (SoC) designs. In addition to providing high performance, the fault-tolerance and reliability of these networks is becoming a critical issue due to several artifacts of deep sub-micron technologies. Consequently, it is important for a designer to have access to fast methods for evaluating the performance, reliability, and energy-efficiency of an on-chip network. Towards this end, first, we propose a novel path-sensitive router architecture for low-latency applications. Next, we present a queuing-theory-based model for evaluating the performance and energy behavior of on-chip networks. Then the model is used to demonstrate the effectiveness of our proposed router. The performance (average latency) and energy consumption results from the analytical model are validated with those obtained from a cycle-accurate simulator. Finally, we explore error detection and correction mechanisms that provide different energy-reliability-performance tradeoffs and extend our model to evaluate the on-chip network in the presence of these error protection schemes. Our reliability exploration culminates with the introduction of an array of transient fault protection techniques, both architectural and algorithmic, to tackle reliability issues within the router's individual hardware components. We propose a complete solution safeguarding against both the traditional link faults and internal router upsets, without incurring any significant latency, area and power overhead.",
2004,Power-aware communication optimization for networks-on-chips with voltage scalable links.,"Networks-on-chip (NoC) is emerging as a practical development platform for future systems-on-chip products. We propose an energy-efficient static algorithm which optimizes the energy consumption of task communications in NoCs with voltage scalable links. In order to find optimal link speeds, the proposed algorithm (based on a genetic formulation) globally explores the design space of NoC-based systems, including task assignment, tile mapping, routing path allocation, task scheduling and link speed assignment. Experimental results show that the proposed design technique can reduce energy consumption by 28% on average compared with existing techniques.","Power-Aware Communication Optimization for Networks-on-Chips with Voltage Scalable Links∗ Dongkun Shin School of Computer Science and Engineering Seoul National University Jihong Kim School of Computer Science and Engineering Seoul National University sdk@davinci.snu.ac.kr jihong@davinci.snu.ac.kr ABSTRACT Networks-on-Chip (NoC) is emerging as a practical development platform for future systems-on-chip products. We propose an energyefﬁcient static algorithm which optimizes the energy consumption of task communications in NoCs with voltage scalable links. In order to ﬁnd optimal link speeds, the proposed algorithm (based on a genetic formulation) globally explores the design space of NoCbased systems, including task assignment, tile mapping, routing path allocation, task scheduling and link speed assignment. Experimental results show that the proposed design technique can reduce energy consumption by 28% on average compared with existing techniques. Categories and Subject Descriptors: C.3 [Special-purpose and application-based systems]: Real-time and embedded systems General Terms: Algorithms, Design Keywords: Network-on-chip, Real-time systems, Low-power design 1. INTRODUCTION Networks-on-Chip (NoC) have recently been proposed as a practical development platform for systems-on-chip (SoC) products [1, 3]. NoCs are especially useful in overcoming complex on-chip communication problems by providing a more structured and modular network interface. Since networks are structured and wired beforehand, their electrical parameters can be well controlled and optimized, which makes it possible to use aggressive signaling circuits thus signiﬁcantly reducing power dissipation and propagation delay. And a standard interface between modules facilitates reusability and interoperability. As shown in Figure 1(a), an NoC-based system is typically divided into regular tiles, where each tile might be a programmable microprocessor, an ASIC, or an FPGA. Instead of being connected by dedicated wires, each of these tiles is connected to an interconnection network that routes packets between tiles. As shown in Figure 1(b), the router in NoCs consists of input and output links, buffers and a crossbar switch. This research was supported by University IT Research Center Project. ∗ Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’04, September 8–10, 2004, Stockholm, Sweden. Copyright 2004 ACM 1-58113-937-3/04/0009 ...$5.00. In NoC-based systems, on-chip networks take up a substantial portion of system power budget, e.g. the MIT Raw on-chip network in which the communication between 16 tiles containing processing elements consumes 36% of the total chip power [14]. And on the Alpha 21364 processor, 20% of the total chip power is consumed by the router and links [11]. One promising low-power technique for energy-efﬁcient NoCs is to scale the speeds of the communication links with the corresponding voltage level [6]. There are two kinds of speed scaling techniques. One is an on-line scheme, which adjusts the communication speed dynamically, based on variations in the run-time communication trafﬁc. The other is an off-line scheme which assigns an appropriate ﬁxed communication speed to each link, based on the communication patterns of target applications. The off-line scheme is better suited to real-time applications since system designers are able to predict communication delays at the design time. In this paper, we propose an off-line link speed assignment algorithm for energy-efﬁcient NoCs with voltage scalable links. Given the task graph of a periodic real-time application, our proposed algorithm assigns an appropriate communication speed to each link, which minimizes the energy consumption of the NoC while guaranteeing the timing constraints of the real-time application. In addition, the proposed algorithm turns off links statically when no communications are scheduled because the leakage power of an interconnection network is not negligible (for example, 21% of the total (leakage+switching) power consumption in 0.07µ m technology [2]). As with other multiprocessor-based systems, the design ﬂow of NoC-based systems involves several (interacting) steps, of which link speed assignment is the last step. In a typical multiprocessor system, the design ﬂow includes two key steps, task assignment and task scheduling. Given a task graph with design constraints (e.g. the execution time and the power consumption) and processing elements (PEs), we ﬁrst assign each task to an appropriate PE ( task assignment). Then, each task is scheduled for execution within the PE (task scheduling). However, in NoC-based systems, two additional steps are necessary, tile mapping and routing path allocation. The tile mapping step maps a PE to one of the tiles in an NoC. The routing path allocation step determines communication paths between tiles. For example, if an NoC has sixteen PEs, as shown in Figure 1(a), then we need to decide on which tile each PE will be located. If data has to be transferred from the tile t1 to the tile t16 , then we must determine which switches among s1 , · · · , s16 will forward the data. (In this paper, we use the term network assignment to refer to both the tile mapping and routing path allocation steps.) In an NoC-based system, design decisions made in the network assignment step, as well as the task assignment and the task scheduling steps, can signiﬁcantly affect the communication speed of each link, because communication trafﬁc patterns vary according to the result of the design steps. Therefore, in order to make an NoCs1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 s13 s14 s15 s16 t1 t2 t3 t4 t5 t6 t7 t8 t9 t10 t11 t12 t13 t14 t15 t16 (a) An NoC with 16 tiles Crossbar Switch buffer buffer u b r e f f u b r e f f b u ff e r west switch east switch north switch south switch processor (b) Structure of a router Figure 1: An architectural overview of an NoC-based system. based system energy-efﬁ cient, each step should be taken with an awareness of its implication for energy consumption in links. For example, consider the task graph g shown in Figure 2(a), where the tasks τ 1 , τ 2 , τ 3 and τ 4 are assigned to the PEs p1 , p2 , p3 and p4 , respectively. A tile mapping algorithm might generate the network assignment shown in Figure 2(b), where a, b, c and d indicate the corresponding communication costs for the links. Assuming that the routing paths are allocated by the XY-routing algorithm [4], packets are ﬁ rst routed along the X-axis. Once a packet reaches the column under which the destination tile is located, it is then routed along the Y-axis. But if we change the tile mapping to the network assignment NA2 (as shown in Figure 2(c)), we get a different energy consumption. If b < c, the network assignment NA2 consumes less energy than the network assignment NA1 , because the energy consumed in the communication links are given as (a + b + 2c + d ) and (a + 2b + c + d ) for NA1 and NA2 , respectively. Therefore, we can say that the network assignment NA2 is better than NA1 . Now let us consider how to assign the communication speed of each link in the network assignment NA2 . If the task τ 3 has a hard deadline, then the link from t il e1 to t il e2 should have a high speed because the link is on the critical path and it has to transfer the data between τ 2 and τ 4 as well as τ 2 and τ 3 . This suggests that the network assignment NA2 could be improved so that the critical path does not share links with non-critical paths. Therefore, the routing path allocation should be performed with an awareness of its effect on link speed scaling. If we change the routing path of the edge (τ 2 , τ 3 ) in NA2 from t il e1 → t il e2 → t il e4 to t il e1 → t il e3 → t il e4 , we get the network assignment NA3 , shown in Figure 2(d). Although the network schedule NA3 has the same amount of communication trafﬁ c as the network assignment NA2 , we can now assign a lower speed to the link from t il e1 to t il e2 . b a d c c a d c b b a b c d a d b,c b τ 1 H = 400 τ 1 τ 1 τ 1 τ 2 τ 2 τ 2 τ 2 τ 3 τ 3 τ 3 τ 3 τ 4 τ 4 τ 4 τ 4 p1 p1 p1 p1 p2 p2 p2 p2 p3 p3 p3 p3 p4 p4 p4 p4 t il e1 t il e1 t il e1 t il e2 t il e2 t il e2 t il e3 t il e3 t il e3 t il e4 t il e4 t il e4 d ead l ine3 = 100 (b) network assignment NA1 (c) network assignment NA2 (d) network assignment NA3 (a) an example task graph Figure 2: A motivational example. In this paper, we show that the existing design algorithm for NoCs is inappropriate for NoCs with voltage scalable links, and we go on to propose a novel optimization algorithm (based on a genetic formulation) which explores the overall design space efﬁ ciently. Experimental results show that the proposed design algorithm can reduce the energy consumption by 28% on average compared with the existing algorithm. The rest of the paper is organized as follows. In Section 2, we brieﬂ y review the related works on NoC design techniques. The overall design ﬂ ow and problem formulation are presented in Section 3. The detailed design techniques are described in Section 4. We present experimental results in Section 5. Section 6 concludes with a summary and directions for future work. 2. RELATED WORKS Several research groups have investigated design techniques for minimizing the energy consumption in NoC-based systems. For example, Simunic and Boyd [12] proposed a power management technique for NoCs. Based on a network-centric power management scheme, their technique makes better predictions of future workload than techniques based on a node-centric power management approach. While that work focused on PEs, other techniques [6, 11, 13, 15, 5] have been developed with the aim of reducing the energy consumption of communication links in NoCs, because they are such a signiﬁ cant energy consumer [11]. Kim and Horowitz [6] proposed variable-frequency links, which can track and adjust their voltage level to the minimum supply voltage as the link frequency is changed, thus reducing the power dissipation. Based on the variable-frequency links proposed by Kim et al. [6], Sang et al. [11] developed a history-based dynamic voltage scaling (DVS) policy which adjusts the operating voltage and clock frequency of a link according to the utilization of the link and the input buffer. Soterious et al. [13] proposed a simple dynamic power management technique for communication links based on the communication trafﬁ c variance to reduce the leakage power consumption. Worm et al. [15] proposed an adaptive low-power transmission scheme for on-chip networks. They minimized the energy required for reliable communications, while satisfying a QoS constraint by dynamically, varying the voltage on the links. Unlike these existing techniques, that are all on-line schemes, our proposed technique is an off-line technique which assigns the appropriate constant speeds to each link. We exploit the information on communication patterns from a task graph. Hu and Marculescu [5] tackled a similar problem. Their algorithm determines a network assignment which is designed to minimize the dynamic power consumption by reducing the communication trafﬁ c. However, they did not address the issue of link speed scaling, but only the network assignment problem, assuming task assignment and task scheduling had been completed. Lei and Kumar [7] has also used the communication patterns of a task graph in tile mapping. But the objective of their algorithm is to ﬁ nd a tile mapping that minimizes the overall execution time of the task graph. 3. OVERALL DESIGN FLOW FOR NOCS 3.1 Speciﬁcation and Architectural Model We represent a periodic real-time application by a task graph (TG) G =< V, E >, which is a directed acyclic graph, where V is the set of tasks and E is the set of directed edges between tasks. In a TG, each directed edge e(τ i , τ j ) represents a precedence relation between τ i and τ j . That is, e(τ j ) means that the task τ i must complete its execution before the task τ j starts its execution. (For descriptive purposes, we will denote e(τ i , τ j ) by ei, j .) The TG has a period H . A task τ i in TG may have a deadline di , which must i , τ be met to ensure correct functionality of the application. Each edge ei, j is associated with a value w(ei, j ) which indicates the amount of communication data required between τ i and τ j , in the case that τ i and τ j are allocated in different PEs. Figure 2(a) shows an example of a task graph. Each edge e has a value of w(e), and the task τ 3 has a deadline. We denote an NoC-based system N with m × m tiles as a tuple < T , L >, where T = {t1 , · · · , tm , · · · , tm2 } is the set of tiles and L = {(cid:5)1 , · · · , (cid:5)4m(m−1) } is the set of links between tiles. All tiles are assumed to have the same area A . We will denote the link between ti and t j by (cid:5)i→ j . We also use the notation src((cid:5)i→ j ) and d st ((cid:5)i→ j ) to represent the source and destination of (cid:5)i→ j respectively. For a link (cid:5)i , W ((cid:5)i ) indicates the total amount of data which is transferred across the link. We denote the set of PEs as R = {r1 , · · · , rn }, where number of tiles are the same, i.e., |R| = |T |. Each tile has associated ri indicates the i-th PE. We assume that the number of PEs and the coordinate values, ti .x and ti .y which specify row and column. (In this paper, we set ti .x and ti .y to be the quotient and the remainder of (i − 1)/m respectively.) Since the task assignment may change the total computation energy consumption on PEs due to the heterogeneous architecture, we should consider both the computation energy of PEs and the communication energy of links. However, in this paper, we consider only the communication energy assuming the homogeneous PEs to concentrate on the network assignment problem. 4. ENERGY-EFFICIENT NOC DESIGN Figure 3 shows the design ﬂ ow for NoC-based systems, which consists of ﬁ ve optimization steps. Unfortunately, this design problem has a very large solution space, as the search space increases factorially with the number of tiles in an NoC [5]. Moreover, since all the design steps are closely related to the link speed assignment step, it is unlikely that a good speed assignment will be found by optimizing each step independently. We use three nested genetic algorithms (GAs) to explore the design space efﬁ ciently. There are a GA-based task assignment algorithm (GA-TA), a GA-based tile mapping algorithm (GA-TM) and a GA-based routing path allocation algorithm (GA-RPA). 3.2 Problem Formulation For a given task graph G =< V, E >, an initial step assigns each task in G into one of the available PEs. We use the function Φ : V → R to represent this task assignment step. Task assignment affects the total communication load because only the tasks assigned into different PEs generate communication loads. Each PE is then : R → T is used assigned to one of tiles in the NoC. The function Ψ to represent this tile mapping step. The mapping also affects the total communication load because the distances between tiles are changed. The routing path between tiles is then allocated, and the : E → P is used to denote this routing path allocation function Ω step, where P is the set of link sequences. After the routing path allocation, we set W ((cid:5)i ) for all (cid:5)i in L to be ∑ ∀e j ,(cid:5)i ∈ Ω (e j ) w(e j ). In this paper, we only consider a static minimal-path routing algorithm, because that is more suitable for an on-chip network and generates less communication trafﬁ c than non-minimal routing paths. The routing path allocation step does not affect the total communication load because we consider only the minimal routing path. However, since the allocation affects the communication load of each link W ((cid:5)), it also affects the speed of the links. The task scheduling step determines the execution order of tasks assigned to the same PE. Since the task scheduling step converts the task graph G to G by inserting additional edges, we describe it with the function O : G → G. Because we need to know the communication delay between tasks for task scheduling, the tile mapping and the routing path allocation steps are executed ﬁ rst. The link speed assignment step decides the clock speed of each link to reslack time. We use function S : L → C to denote the link speed asduce the energy consumption by utilizing what would otherwise be signment step, where C is the set of possible clock speeds for the links. We can deﬁ ne the link energy optimization problem for energyefﬁ cient NoCs as follows: (cid:11) Link Energy Optimization Problem Given G =< V, E >, R and N =< T , L >, ﬁnd the functions Φ , O and S such that (CL · W ((cid:5)i ) · f ((cid:5)i )2 + H · Pl eakage ((cid:5)i )) is minimized subject to ∀ τ i ∈ V, i ) ≤ di . E = ∑ (cid:5)i ∈L θ ( τ , Ψ , Ω CL is the average switching capacitance of the links. f ((cid:5)i ) and Pl eakage ((cid:5)i ) are the clock speed and the leakage power of a link (cid:5)i . For a link (cid:5)i with W ((cid:5)i ) = 0, Pl eakage ((cid:5)i ) is 0, because we can turn off an inactive link. θ (τ i ) is the end time of τ i . NoC Architecture Description Task Graph Description Task Assignment Tile Mapping Routing Path Allocation Task Scheduling Link Speed Assigment A P R A G A T A G M T A G Evaluation Evaluation Evaluation Optimized Link Speeds Figure 3: An overall design ﬂ ow for NoCs. Genetic algorithms imitate the principles of natural evolution to solve search and optimization problems, and are a promising technique for system-level design which has a large solution space. GA is especially suitable for multiple-objective optimization. Figure 4 shows a typical structure of a genetic algorithm. Starting with an initial population, a genetic algorithm evolves a population using the crossover and mutation operations. Since the performance of a genetic algorithm depends on the encoding, the crossover and the mutation schemes, we need to select these schemes carefully. Genetic Algorithm (CTG G) 1: initialize a population with n individuals; 2: ranking each individual according to its ﬁ 3: repeat { 4: select two individuals, p1 and p2 ; 5: child = crossover( p1 , p2 ); 6: child = mutation(child ); 7: 8: } until (there is no improvement during m-iterations). replace the lowest ranked individual with child ; tness; Figure 4: A typical structure of a genetic algorithm. 4.1 GA-based Task Assignment The more tasks that are assigned to a PE, the larger its area becomes, because it requires more memory or gates. Since each tile has the same size, the area constraint may be expressed as AΦ (ri ) ≤ A , where AΦ (ri ) means the area of a PE ri under the task assignment function Φ . If there is an edge e between two tasks assigned to the same PE, its value w(e) is changed to 0. This task assignment step affects the total communication load. We will represent a task assignment solution as an array of integers. For example, in Figure 5(a), the task τ 1 is mapped to r8 in the individual p1 . Our crossover operation is the two-point crossover, which is widely used in GAs. Both parent individuals p1 and p2 are divided at the same two points and the child individual c1 is generated from the ﬁ rst part of p1 , the second part of p2 and the third part of p1 . Our mutation operation changes the values of randomly selected genes into new values, which make up a new individual. 4.2 GA-based Tile Mapping We encode a tile mapping solution as an array of integers. For example, in Figure 5(b), the PE r1 is mapped to t8 in the individual p1 . To achieve GA-based tile mapping, we need to be careful in designing the crossover operation. If we were to use a two-point crossover for tile mapping, we would obtain illegal solutions because different PEs might be allocated into the same tile. Therefore, we use the cycle crossover [8], which is appropriate when the encoding represents a sequence. Figures 5(b)-(d) show how to make child individuals using the cycle crossover. In the mutation operation in the mapping, two randomly selected genes are exchanged to make a new individual. For each individual, we perform routing path allocation, task scheduling and link speed assignment steps to evaluate the ﬁ tness value. To reduce the computation time, we check whether one individual is topologically identical to another individual, and omit the evaluation step if an identical individual has already been evaluated. To achieve this operation, we ﬁ rst transform each individual into an ordered form and compare the ordered forms of indithe PE Ψ −1 (t1 ) has a smaller index than the indices of Ψ −1 (tm ), viduals. The ordered form has the following two properties: (1) Ψ −1 (tm2−m+1 ) and Ψ −1 (tm2 ), where t1 , tm , tm2−m+1 and tm2 are four corner tiles; (2) the PE Ψ −1 (tm ) has a smaller index than the index of Ψ −1 (tm2−m+1 ). We can transform a tile mapping into the ordered form by rotating or mirroring the tile mapping structure. τ 1 τ 2 τ 3 8  7  1 τ 4 τ 5 τ 6 9  6  3 τ 7 τ 8 τ 9 4  5  2 p1 individual gene p2 9  2  4 3  1  5 6  8  7 8  7  1 3  1  5 4  5  2 9  2  4 9  6  3 6  8  7 r1 r2 r3 r4 r5 r6 r7 r8 r9 8  7  1  9  6  3  4  5  2 9  2  4  3  1  5  6  8  7 8  2  4  9  1  3  6  5  7 9  2  4  3  1  5  6  8  7 p1 p2 c1 c2 c1 c2 p1 p2 c1 c2 (a) two-point crossover (b) 1st step of cycle crossover 8  7  1  9  6  3  4  5  2 9  2  4  3  1  5  6  8  7 8  2  4  9  1  3  6  5  7 9  7  4  3  1  5  6  8  2 p1 p2 c1 c2 8  7  1  9  6  3  4  5  2 9  2  4  3  1  5  6  8  7 8  2  1  9  6  3  4  5  7 9  7  4  3  1  5  6  8  2 (c) 2nd step of cycle crossover (d) 3rd step of cycle crossover Figure 5: Crossover operations in GA-TA and GA-TM. After tile mapping, we compose the set of communication loads, CL. For each edge ei, j for which w(ei, j ) > 0, we make a communication load υ which has three properties: υ src = Ψ i )), υ d st = j )), and υ d at a = w(ei, j ). (Φ (τ (Φ (τ 4.3 GA-based Routing Path Allocation In routing path allocation, we assume that the source tile sends the data packet with the routing information represented by a binary number. Each bit of the binary number represents routing direction, i.e. bits 1 and 0 correspond to moves along the X-direction and Ydirection respectively. (Although there are two output links in each direction, there is no ambiguity in practice, because we assume a minimal path routing.) The intermediate routers between the source tile and the destination tile determine the forward direction from the most signiﬁ cant bit of routing information and forwards the routing information after shifting it by one bit. The routing path allocation step determines n directions, where the Manhattan distance between two tiles is n. The individuals in the GA-based routing path are represented by represents the routing path for a communication load υ ∈ CL. For one-dimensional arrays of binary numbers. Each binary number example, Figure 6 shows two different routing paths for the communication load υ where υ src = t1 and υ d st = t16 . The routing paths p1 and p2 can be represented as follows: p1 = {(cid:5)1→2 , (cid:5)2→3 , (cid:5)3→7 , (cid:5)7→11 , (cid:5)11→15 , (cid:5)15→16 } p2 = {(cid:5)1→2 , (cid:5)2→6 , (cid:5)6→7 , (cid:5)7→11 , (cid:5)11→12 , (cid:5)12→16 }. p1 1  1  0  0  0  1 p2 1  0  1  0  1  0 1 5 9 13 2 6 10 14 3 7 11 15 4 8 12 16 1 5 9 13 2 6 10 14 3 7 11 15 4 8 12 16 Figure 6: Routing path encoding. By representing the routing path in this way, we can use an effective crossover and mutation operation as well as reducing the memory required for a population. When the X-distance and the Y-distance of a communication load are n and m respectively, the initial population is generated using random binary numbers which has n-number of 1s and m-number of 0s1 . Routing path allocation also requires a special crossover operation. As we can see in Figure 7(a), if we were to use one-point crossover for the path routing, we might get illegal solutions. The crossover operation should guarantee that it generates only legal solutions while passing on properties from parent individuals to child individuals. In order to satisfy these requirements, we have invented a special crossover, called the coordinate crossover, for path routing. Figure 7(b) shows the coordinate crossover operation. First, we ﬁ nd the meeting points from two parent individuals, where two different routing paths represented by the parents meet at the meeting points. For example, in Figure 6, two routing paths represented by p1 and p2 meets at the tiles t1 , t7 and t16 . The meeting points can be easily found by calculating the partial sum si (k) from the ﬁ rst bit to the kth bit in the parent individual pi . If two partial sums s1 (k) and s2 (k) of p1 and p2 are equal but s1 (k − 1) and s2 (k − 1) are different, the location k is a meeting point as shown in Figure 7(b). (The source and destination tiles are always meeting points.) Second, both parent individuals are divided at the meeting points and child individuals are created by mixing parts from two parents like the multi-point crossover operation. The coordinate crossover only generates legal child individuals because children have the same number of 1s as their parents. The child individuals are also guaranteed to inherit the links which both parents share. The turn model which prevents a deadlock can be sustained with the coordinate crossover. For the mutation operation, we exchange the locations of two bits where one bit is 1 and another is 0. Using these specially designed crossover and mutation operations, we are sure to explore only the legal solution space. 1To prevent a deadlock in the routing path, we can use a turn model such as west-ﬁ rst, north-last and negative- ﬁ rst [4]. A routing path can be represented so that it follows a speciﬁ c turn model. Ψ meeting points meeting points p1 1  1 0  0  0  1 p1 1  1  0 0  0  1 p3 1  1  0  0 0  1 p2 1  0 1  0  1  0 partial sum 0   1    2    2    2   2   3 0   1   2    2   2    2   3 p2 1  0  1 0  1  0 p4 0  0  1  1 1  0 0   1    1    2    2   3   3 0   0   0    1   2    3   3 c1 1  1 1  0  1  0 deformed child c2 1  0 0  0  0  1 deformed child c1 1  1  0 0  1  0 normal child c2 1  0  1 0  0  1 normal child c3 c4 1  1  0  0 1  0 normal child 0  0  1  1 0  1 normal child (a) one-point crossover (b) coordinate crossover Figure 7: Crossover operation for routing. 4.4 Task Scheduling For task scheduling, we adopted a list scheduling algorithm which uses the mobility of each task to determine its priority. The mobility of a task is deﬁ ned as the difference between the ASAP start time and the ALAP end time. To get these times, we need to know the communication delay of an edge. However, we cannot know its exact value due to the asynchronous communication protocol of an NoC. Moreover, the communication delay at a link is dependent on how many communication loads share the link. So, we use the worst-case communication delay of each edge to satisfy the hard real-time constraint. To estimate the worst-case communication delay, we assumed that the worst-case delay at each link is the time required to transfer all communication loads assigned the link2 . We can now calculate the worst-case communication delay of an edge ei as follows: δ (ei ) = ∑ (cid:5) j ∈ Ω (ei ) W ((cid:5) j ) f ((cid:5) j ) · B , where B is the bandwidth of the communication links (in bits/sec). The clock speed f ((cid:5) j ) is set to maximum but a lower speed can be obtained by the following link speed assignment step. 4.5 Link Speed Assignment For the link speed assignment, we have used a similar idea to the voltage and clock speed selection algorithm proposed by Schmitz and Al-Hashimi [10]. Their algorithm ﬁ rst estimates the slack time of each task considering the deadline and precedence constraint. It then calculates ∆ E (τ i ) for a task τ i which has slack time. ∆ E (τ i ) is the energy gain when the time slot for τ i is increased by ∆ t (with a lower clock speed). After increasing the time slot for the task τ i with the largest ∆ E (τ i ), by a time increment ∆ t , it repeats the same sequence of steps until there is no task with slack time. While this algorithm determines the operating speed of each task assigned on the DVS-enabled PE, our link speed assignment algorithm determines an operating speed for each link which does not change dynamically at run time. To estimate the slack time for each link, we need to consider the edges whose communication loads share that link. The slack time of a link is the minimum value among the slack times of the edges, i.e., ξ ((cid:5)i ) = min(cid:5)i∈ Ω (e j ) (ξ (e j )), where ξ ((cid:5)i ) and ξ (e j ) are the slack times of (cid:5)i and e j respectively. 5. EXPERIMENTAL RESULTS We started by estimating the efﬁ ciency of each optimization technique at the task assignment, tile mapping, routing path allocation 2 Although there are special on-chip network architectures for hard realtime systems [9], we have assumed no special architecture and have used an aggressive communication delay model. However, such a network architecture could be combined with our design technique by modifying the communication delay model. and link speed assignment steps. For our experiments, we generated random task graphs g1 to g16. Figure 8 shows the energy consumptions of the communication links under various optimization conﬁ gurations. The results were normalized against the energy consumption obtained by a design technique which uses random task assignment, random tile mapping, XY-routing and no link speed scaling. The ﬁ rst bar for each task graph represents the result when we applied only the link speed scaling technique (o ptLS ). The second bar represents the result when we used the GA-RPA algorithm for routing path allocation, as well as link speed scaling (o ptLS+R ). The third bar shows the result when the GA-TM algorithm for tile mapping is also applied (o ptLS+R+T M ). The fourth bar shows the energy efﬁ ciency when all optimization algorithms are used (o ptLS+R+T M+T A ). The energy consumption is reduced by 8%, 17%, 27% and 43% on average by the o ptLS , o ptLS+R , o ptLS+R+T M and o ptLS+R+T M+T A techniques, respectively. These reduction ratios are dependent on the characteristics of the task graph (e.g., slack time and communication load) and the performance of the random conﬁ gurations. For example, the link speed scaling (o ptLS ) showed small energy reductions because the random task assignment, the random tile mapping and the XY-routing generate little slack time. From these results, we realize that all design steps have large effects on communication energy, and it is necessary to optimize the energy consumption at all design steps. (We did not compare the task scheduling step with other techniques because the list scheduling is universally popular.) o ptLS o ptLS+R o ptLS+R+T M o ptLS+R+T M+T A 1.2 1.0 0.8 0.6 0.4 0.2 0.0 n o i t p m u s n o C y g r e n E d e z i l a m r o N g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 Task graph Figure 8: Effects of the nested optimization techniques. We also compared our GA-based NoC design technique with previous techniques. Hu and Marculescu proposed a tile mapping technique that uses a branch-and-bound (B&B) algorithm and a routing path allocation algorithm that balances the communication workload across the links [5]. We expanded their algorithm by integrating it with our task assignment, task scheduling and link speed assignment algorithms. We denote the integrated algorithm as BB in this paper. In BB, the cost of a solution is estimated from the amount of trafﬁ c, which is proportional to the dynamic power consumption of the communication links. We improved the BB algorithm by assuming that we can turn off a link which has no communication trafﬁ c. We call this technique as BB+ to distinguish it from BB. The BB+ technique takes into account the leakage power in estimating the cost of a solution. The heuristic for routing path allocation is also improved in BB+ , which gives priority to the links with non-zero trafﬁ c. Using this algorithm, the number of links without trafﬁ c can be increased. In [5], the authors showed that their algorithm can ﬁ nd an optimal solution within a short time. However, if we consider task scheduling and link speed assignment, BB and BB+ cannot ﬁ nd an optimal solution because the exact cost of an internal node3 cannot be estimated before task scheduling and link speed assignment. 3 In the branch-and-bound technique, the bound step compares U BC, the     Figure 9 shows experimental results that compare our GA-based algorithm with BB and BB+ . To compare only the network assignment step, all the algorithms were executed with the same predetermined task assignment. The results were normalized againt the energy consumption of the random tile mapping and XY-routing technique. As we can see from the results, BB reduces the energy consumption by 16% on average but sometimes generates worse results than the random mapping (e.g., the task graph g15). This is because BB does not consider leakage power or link speed assignment. The BB+ technique and the GA-based technique reduced the energy consumption by 22% and 39% on average, compared with the random mapping and XY-routing technique. The GAbased technique reduced the energy consumption by 28% on average, compared with the BB technique. We also experimented with the task graph of the real application (a multimedia system with an H.263 encoder/decoder and an MP3 encoder/decoder) introduced previously [5]. Since each task is assigned to a processing element in the task graph, we only evaluated the tile mapping and routing path allocation steps. Our GA-based algorithm reduced the energy consumption by 35% compared with the random tile mapping and XY-routing technique. BB BB+ GA n o i t p m u s i l a m r o N n o c y g r e n e d e z 1.2 1.0 0.8 0.6 0.4 0.2 0.0 g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 AVE Task graph Figure 9: Performance comparison between the B&B and GA techniques. Table 1 shows the features of the task graphs and the execution times of the o ptLS+R+T M algorithm running on a Pentium-III 500 MHz Linux machine. The execution time of the genetic algorithm depends on various design factors, such as the population size, the mutation probability and the termination condition. We initialized the population sizes as |T |2 /2 and |T | in GA-TM and GA-RPA respectively. For our experiments, the number of tiles, |T |, was 9 (3 × 3) or 16 (4 × 4). From Table 1, we see that the GA-based algorithm takes a long time when a task graph has a large number of edges, i.e., there are many communication loads. Exceptions such as the task graphs g3 and g14 are due to the nature of the link speed assignment algorithm. The link speed assignment algorithm iterates, increasing the delay time of a link by ∆ t until there is no slack time. So it takes longer as a task graph has long slack times. So we can improve the speed of the algorithm with a fast link speed assignment module. The BB and BB+ performed well when |T | = 9, but become very slow when |T | = 16. Without spewhen |T | = 16. But our GA-based algorithm take under a minute, cial speedup techniques, BB takes over 1 hour for the graph g2 even for quite complex task graphs, which makes it acceptable for a design methodology. 6. CONCLUSIONS In this paper, we have proposed an energy-efﬁ cient algorithm to optimize the communication energy consumption in NoC-based best cost of leaf nodes generated up to the current time, with LBC, the lowerbound cost of the leaf nodes which are still to be generated from the current internal node. Nnod e /Nedge 3 × 3 4 × 4 TG g1 26/43 5.2 8.4 g2 40/77 9.3 35.5 g3 20/33 9.6 38.8 g4 40/77 11.6 38.6 g5 20/26 5.7 20.1 g6 20/27 3.6 13.8 g7 18/26 5.1 15.8 g8 16/15 3.2 12.2 * Nnod e = # of nodes and Nedge = # of edges TG g9 g10 g11 g12 g13 g14 g15 g16 Nnod e /Nedge 30/29 36/50 37/36 24/33 31/56 29/56 12/15 14/19 time (sec) 3 × 3 4 × 4 6.5 43.9 12.5 57.9 9.0 26.3 5.0 9.6 9.9 58.6 6.2 19.3 3.2 9.4 2.8 4.2 Table 1: Execution times of o ptLS+R+T M algorithm. systems with voltage scalable links. The proposed algorithm optimizes communication energy at the various design steps, i.e., task assignment, tile mapping, routing path allocation and link speed assignment. We used genetic algorithms to explore the large design space of energy-efﬁ cient NoCs effectively. Our algorithm reduced the energy consumption of on-chip network by 39% on average compared with an algorithm which uses random tile mapping and XY-routing. Our work can be extended in several directions. Due to the asynchronous communication protocol, we estimated the worstcase communication delay pessimistically. However, by considering the precedence dependency in the task graph, we could obtain a tighter bound on the communication delay. In particular, we can ﬁ nd communication loads that never overlap by analyzing the task graph. Another issue is the buffer size of each router. Since the required buffer size changes depending on the tile mapping and the routing path allocation, it is necessary to design NoC-based systems under a buffer size constraint. 7. "
2008,Token flow control.,"As companies move towards many-core chips, an efficient on-chip communication fabric to connect these cores assumes critical importance. To address limitations to wire delay scalability and increasing bandwidth demands, state-of-the-art on-chip networks use a modular packet-switched design with routers at every hop which allow sharing of network channels over multiple packet flows. This, however, leads to packets going through a complex router pipeline at every hop, resulting in the overall communication energy/delay being dominated by the router overhead, as opposed to just wire energy/delay.","Token Flow Control Amit Kumar, Li-Shiuan Peh and Niraj K. Jha Department of Electrical Engineering Princeton University, Princeton, NJ 08544 Email: {amitk, peh, jha}@princeton.edu Abstract As companies move towards many-core chips, an efﬁcient onchip communication fabric to connect these cores assumes critical importance. To address limitations to wire delay scalability and increasing bandwidth demands, state-of-the-art on-chip networks use a modular packet-switched design with routers at every hop which allow sharing of network channels over multiple packet ﬂows. This, however, leads to packets going through a complex router pipeline at every hop, resulting in the overall communication energy/delay being dominated by the router overhead, as opposed to just wire energy/delay. In this work, we propose token ﬂow control (TFC), a ﬂow control mechanism in which nodes in the network send out tokens in their local neighborhood to communicate information about their available resources. These tokens are then used in both routing and ﬂow control: to choose less congested paths in the network and to bypass the router pipeline along those paths. These bypass paths are formed dynamically, can be arbitrarily long and, are highly ﬂexible with the ability to match to a packet’s exact route. Hence, this allows packets to potentially skip all routers along their path from source to destination, approaching the communication energy-delaythroughput of dedicated wires. Our detailed implementation analysis shows TFC to be highly scalable and realizable at an aggressive target clock cycle delay of 21FO4 for large networks while requiring low hardware complexity. Evaluations of TFC using both synthetic trafﬁc and traces from the SPLASH-2 benchmark suite show reduction in packet latency by up to 77.1% with upto 39.6% reduction in average router energy consumption as compared to a state-of-theart baseline packet-switched design. For the same saturation throughput as the baseline network, TFC is able to reduce the amount of buffering by 65% leading to a 48.8% reduction in leakage energy and a 55.4% lower total router energy. 1. Introduction The current trend in utilizing the growing number of transistors provided by each technology generation is to use a modular design with several computation cores on the same chip. As the number of such on-chip cores increases, a scalable and high-bandwidth communication fabric to connect them becomes critically important. As a result, packet-switched onchip networks are fast replacing buses and crossbars to emerge as the pervasive communication fabric in both general-purpose chip multi-processor (CMP) [1]–[3] as well as applicationspeciﬁc system-on-a-chip (SoC) [4] domains. Apart from providing scalable and high-bandwidth communication, on-chip networks are required to provide ultra-low latency with an extremely constrained power envelope and a low area budget. Most state-of-the-art packet-switched designs use a complex router at every node to orchestrate communication, and packets travel only a short distance on the link wires before having to go through a complete router pipeline at every intermediate hop along their path. As a result, communication energy/delay in such networks is dominated by the router overhead, in contrast to an ideal network where packet latency and energy are solely due to the wires between the source and destination. For instance, routers consume around 61% of the average network power in the MIT Raw chip as opposed to 39% consumed by the links [5]. Similarly, the Intel 80-core teraﬂops chip has router power taking 83% of network power versus 17% consumed by the links [3]. The large energy-delay-throughput gap between the state-of-the-art packet-switched network and the ideal interconnect of dedicated point-to-point wires was pointed out in [6]. In this work, we propose TFC, a ﬂow-control mechanism which aims to deliver the energy-delay-throughput of dedicated wires through the use of tokens. Tokens are indications of resource availability in the network. Each node in the network sends out tokens in its ﬁxed local neighborhood of dmax hops to disseminate information about availability of resources, such as buffers and virtual channels (VCs) at its input ports. Individual packets then use these tokens during both routing – to ﬁnd less congested routes in chunks of up to dmax hops, and ﬂow control – to bypass the router pipeline at intermediate nodes along these dmax -hop routes. When one such dmax -hop token route ends, another token route can be chained to it seamlessly without any additional energy-delay overhead. Thus, packets can use an arbitrary number of tokens to bypass all intermediate routers between their source to destination, like that in an ideal network. In the rest of this paper, Section 2 provides background for this work by looking at router energy/delay overhead in state-ofthe-art packet-switched designs. This is followed by the working of TFC in Section 3 and its implementation details in Section 4. Evaluation results are presented in Section 5. Section 6 presents related work while Section 7 concludes the paper. 2. Background 2.1. Baseline state-of-the-art router Fig. 1(a) shows the microarchitecture of a state-of-the-art baseline VC router used for comparison in all our experiments. We assume a two-dimensional mesh topology for simplicity. Flit-level buffering and on/off VC ﬂow control [7] are used to minimize the amount of buffering per router and hence its area footprint. This design incorporates several features which are critical to on-chip networks – low pipeline delay using lookahead routing [8], speculation [11], [12], no-load bypassing Route  Computation VC  Allocator Switch  Allocator VC 1 VC 2 Input 0 VC n Shared input  buffer pool VC 1 VC 2 VC n Shared input  buffer pool Input 4 Output 0 Head  flit Setup BW RC Body/ tail     flit SA VA Setup BW ST SA LT ST LT Output 4 (b) Speculative pipeline Setup BW RC Router 1 Router 2 SA VA ST LT LA LT Control  setup ST LT LA LT (c) No-load bypass pipeline – lookahead pipeline stages are shaded in dark (LA LT: Lookahead link traversal) Crossbar switch (a) Router microarchitecture Figure 1. State-of-the-ar t packet-switched router and lookaheads [9], [13], [21], high throughput using dynamic buffer management [10], high clock frequency using pipelining, simpliﬁed VC allocation [9] and separable switch allocation [7] and low router energy using no-load bypassing [9], [13], [21] and power-optimized straight-through buffers and cut-through crossbar [5]. Fig. 1(b) presents the router pipeline with the different stages being setup (in which ﬂits send arbitration requests for their desired output port), buffer write (BW), route computation (RC), switch allocation (SA), VC allocation (VA), switch traversal (ST) and link traversal (LT). Fig. 1(c) presents the no-load bypass pipeline applicable under very low loads (when router ports are mostly empty) where lookaheads, which travel one cycle ahead of data ﬂits on separate narrow channels1 , are used to do control setup to allow data ﬂits to directly go through ST upon arrival. Control setup involves checking for input/output port conﬂicts (with local ﬂits and other lookaheads) and free resources (buffer/VC) at the next hop. This no-load bypassing is only effective under very low loads since the router ports will be mostly busy as network load increases, leading to the lookaheads failing to do control setup most of the time. We refer the readers to [6], [9] for further details on the baseline. 2.2. Beneﬁts of bypassing Router energy/delay overhead: Out of all router pipestages described above, ST and LT are the only stages where a packet actually covers the physical distance towards its destination with all other stages contributing to the delay overhead which packets incur at every hop. In terms of energy consumption, apart from the energy spent in traversing the physical links, packets consume additional energy at each router while being written to the buffer, going through VC arbitration and switch arbitration, being read out of the buffer and ﬁnally while traversing the crossbar. In contrast to this, if packets are allowed to bypass the router pipeline at all levels of network load by skipping through buffer read/write and allocation operations and only going through ST and LT, it would lead to a signiﬁcantly shorter pipeline delay per hop, savings in router energy as well as a higher throughput due to lower contention for resources. Moreover, since a ﬂit does not use up any buffers when bypassing a router, this allows other ﬂits to have more free 1. This lookahead, which uses a signiﬁcantly narrower channel as compared to the data, also needs to traverse a correspondingly short distance of the crossbar switch (since its path can be laid out along the inner side of the wider normal data path) before traversing the link which takes place in parallel with reading of the data flit out of its buffer. buffers available to them which helps push performance at high loads. When looked at in another way, bypassing helps to cut down the total buffering needed to achieve a target performance, resulting in signiﬁcant buffer leakage and dynamic energy as well as area savings. This helps approach the energy/delay of an ideal network in which packets would incur only wire energy/delay and no router overhead along their path. 3. Token ﬂow control (TFC) In this section we describe the working of TFC. Tokens can have two ﬂavors, normal tokens and guaranteed tokens, as explained next by answering the following questions. 3.1. Normal tokens What are normal tokens? A normal token is a hint for buffer and VC availability at an input port of a router. How are tokens turned on and off? A router turns on a normal token for a particular input port if there are greater than a ﬁxed threshold of bthr buffers and vthr VCs available at that port. These thresholds act as a proxy for congestion at that router port. Similarly, a router turns of f a normal token for an input port if either the number of free buffers becomes ≤ bthr or the number of free VCs becomes ≤ vthr at that port. It should be noted that the use of the word token here differs from the traditional usage – a token is not turned off if a packet grabs it. It is turned off explicitly by its source router based on the number of buffers and VCs at that input port. How are tokens forwarded? While in state-of-the-art networks, availability of buffers and VCs is communicated only across adjacent nodes2 , tokens are used to communicate this information across all nodes in a dmax -hop neighborhood (where dmax is the maximum token route length). Fig. 2 demonstrates token forwarding for a particular input port (West input) at node 34. When there are greater than bthr buffers and vthr VCs available at the West input port of node 34, it turns on an Eon token for that input port to its West neighbor node 33, signaling to node 33 that its East output direction (hence the token Eon ) is not congested. Node 33 then forwards this Eon token by broadcasting it to its neighbors (except in the East direction, assuming routes with U-turns are not allowed) by appending the received token with its own tokens (based on resource availability at its corresponding input ports). Hence, before forwarding a token along a particular port, the node 2. This is done using credit, on/off or ack/nack signaling in conventional networks [7]. 51 41 31 21 52 53 54 42 EonSonEon 43 SonSonEon 44 WonSonEon SonEon 32 22 33 EonEon Eon NonEon 23 34 24 Figure 2. Token forwarding in a network with dmax = 3 43 33 SonEon 32 LAF2 Conflict LAF1 34 EonEon Eon Figure 3. Example token conﬂict 43 33 LAF2  killed 32 LAF2 LAF1  successful LAF1 34 Local priority setting at node 33: North  input has priority to use East output Figure 4. Token conflict resolution checks to see if there are sufﬁcient resources (greater than bthr buffers and vthr VCs) at that corresponding input port. For instance, node 33 is allowed to forward the Eon token to its North neighbor (node 43) using an appended SonEon token, only if there are sufﬁcient resources at its North input port (South output port of node 43). All nodes which receive tokens from node 33 do a similar forwarding to their neighbors by appending their own tokens, as shown in Fig. 2. This token forwarding takes place for up to dmax hops in the network, thus allowing each node to gather knowledge about resource availability at all other nodes within its dmax -hop vicinity. Propagation of tokens between adjacent nodes uses separate point-to-point wires which are much narrower than the data channels. Hence, in a way, TFC makes use of tokens traveling on separate narrow channels between nodes to optimize communication energy/delay on the wider data channels. How are tokens used? Tokens provide knowledge of congestion levels in ad max -hop neighborhood. Packets at these nodes thus use these tokens during RC to form a token route – partial route of the packet computed for up to the next dmax hops at once along less congested sections of the network. Thus, for instance, the EonSonEon token at node 42 in Fig. 2 can be used by a packet at that node to travel to node 34 (assuming partial route (assuming dmax ≥ 3) through the East output to node 34 is closer to the packet’s destination) along a three-hop reach node 43, followed by a South hop to node 33 and then an East hop to node 34 (route shown in bold), thus making use of the EonSonEon token to route through a path along which sufﬁcient resources are available. Once these token routes are known, lookaheads are sent (on separate channels) ahead of the data ﬂits along these routes to do control setup at intermediate nodes one cycle prior to data arrival, thereby allowing the data ﬂit to bypass the router pipeline and right away traverse the crossbar when it arrives at these intermediate nodes. In contrast to the baseline, which allows lookaheads to succeed only under very low loads when router ports are empty, lookaheads here hold tokens. When such a lookahead arrives at an intermediate router, it is prioritized to use its desired switch port over any locally-buffered ﬂits at that router and hence succeeds in control setup even at high loads. Moreover, the likelihood of conﬂicts with other lookaheads is low along token routes as tokens are forwarded only along less congested sections in the network. Hence, in the example of Fig. 2, a packet using the EonSonEon token at node 42 can bypass intermediate nodes 43 and 33 on its way to node 34. Are tokens used on a per-flit basis? Yes, tokens are used by individual ﬂits of a packet. A header ﬂit starting at a node is free to use any of the available tokens during route computation. Body/tail ﬂits, on the other hand, do not go through route computation and need to follow this same route and use tokens to bypass intermediate routers along that route if such tokens are available or else they traverse that route without tokens. Similar to the baseline VC ﬂow control design which uses a VC control table at each router to store information about each traversing packet [7], a packet’s route in the token scheme is stored in a control table at each intermediate router as its header ﬂit traverses it, which allows the subsequent body/tail ﬂits to follow the same route as the header. How are conflicts between multiple ﬂits using tokens resolved? As discussed above, tokens are forwarded by broadcasting them in the network. However, since broadcasting involves forwarding the same token along multiple directions, it can lead to conﬂicts when multiple lookaheads (corresponding to different ﬂits) arrive at a router from different input directions holding the token for the same output port to bypass that router. Fig. 3 shows an example of such a conﬂict where two lookaheads for ﬂit F1 (using token SonEon ) and ﬂit F2 (using token EonEon ) arrive simultaneously at router 33 at its North and West input ports, respectively, holding the token to go out at the East output. To resolve such conﬂicts, each router maintains a local switch port priority vector which has one entry for each output port which denotes the particular input port which has priority to use that output port. If an incoming lookahead matches the priority setting for its desired output port at that router, it is deemed to have won the switch. For instance, as shown in Fig. 4, the current priority setting at node 33 denotes the North input having priority to use the East output. Hence, the lookahead for F1 (which matches this priority setting) is allowed to succeed while the lookahead for F2 is killed. This priority vector is varied dynamically to balance the request queues at each input based on the observed trafﬁc, as explained in Section 4.4. What happens when a lookahead carrying a token gets killed? Normal tokens only act as hints of resource (buffers/VCs) availability in the network. They do not need to guarantee resources at the endpoint node of a ﬂit’s token route. Hence, a check for a free buffer/VC is done at each intermediate node along the token route and a lookahead carrying a token is killed at an intermediate node if there are no free buffers or VCs available at the next hop along the token route. A lookahead might also be killed due to conﬂicts with other lookaheads (as described above in the answer to the previous question). When a ﬂit’s lookahead gets killed at an intermediate node, its corresponding data ﬂit cannot bypass that node and needs to get buffered there while going through the normal pipeline. The key thing to note here is that since a check for a free Route of a packet  P1 trying to go to  node 34 but stuck  at node 42 due to  lack of resources  at node 32 51 41 31 21 52 42 32 22 53 43 33 23 Congested  section in the  network Packet P1 uses  guaranteed token  Eon_g to route from  node 42 to node 34  bypassing congested  nodes 32 and 33 West input  port at node  34 is not  congested Eon_g token unicast  along the current switch  port priority setting at  node 32 – North input  has priority to use East  output 54 44 34 24 51 41 31 21 Eon_g 52 42 32 22 53 43 33 Eon_g Eon_g 23 54 44 34 24 Congested  section in the  network Guaranteed token  turned on by its  generating source  node 34 for its East  neighbor node 33 Eon_g token unicast along the  current switch port priority  setting at node 33 – West input  has priority to use East output (a) An example of network congestion (bold links denote congestion at (b) Using guaranteed token to bypass a congested network section (priority settings at intermediate endpoints) nodes are shown using solid bold arrows) Figure 5. Guaranteed tokens their buffer/VC is done on a hop-by-hop basis, it is completely safe to stop a ﬂit mid-way if its lookahead gets killed. Continuing with the example shown in Fig. 2, consider the case when a packet P1 at node 42 is using the EonSonEon to travel to node 34 and buffers at the North input of node 33 become full by the time ﬂits of P1 reach node 43. In this case, the in-ﬂight lookaheads of these ﬂits are killed at node 43 and the ﬂits are stopped and buffered at that node. Thus, even though individual token routes can span up to dmax hops, buffer/VC management is still done on a hop-by-hop basis. This makes token routes highly scalable by allowing them to extend over long distances without the need to ensure a large amount of buffering to cover a correspondingly longer round-trip of all in-ﬂight ﬂits between the endpoints of that route. Hence, the beneﬁts of longer token routes can be achieved with the buffering overhead of only single-hop routes. It should be noted that since normal tokens are forwarded only along paths where each port along that path has free resources, the probability of lookaheads getting killed due to lack of resources at intermediate nodes is small. What happens at the end of a dmax -hop token route? A single token route with a lookahead carrying a token going ahead of the data ﬂit can extend up to dmax hops, provided the lookahead is successful and does not get killed at every intermediate node along that route. To allow seamless transition from using one token route to another, we do RC in the lookahead pipeline. Speciﬁcally, one hop before the current token route is about to complete (i.e., at the (dmax − 1)th hop from the starting node of the token route), a new token route is computed for up to the next dmax hops in the lookahead pipeline (explained further in Section 4.1). This allows chaining of multiple token routes: allowing the intermediate router between successive token routes to be bypassed as well. Thus, in cases where the lookahead does not get killed in between, a ﬂit has the opportunity to bypass all routers along its path from the source to destination by chaining several token routes in succession. 3.2. Guaranteed tokens What are guaranteed tokens? A guaranteed token is a guarantee for buffer and VC availability at an input port of a router. Similar to dmax for normal tokens, guaranteed tokens are forwarded in a gmax -hop neighborhood (where gmax is the maximum guaranteed path length). Unlike a normal token, which only acts as a hint of resource availability at its source node from where the token was generated, a guaranteed token guarantees the presence of free buffers and VCs at its generating source node. Moreover, while lookaheads carrying normal tokens can get killed at intermediate nodes along the token route due to conﬂicts with other lookaheads, the mechanism using which guaranteed tokens are propagated in the network ensures that such conﬂicts never happen and lookaheads carrying guaranteed tokens never get killed at intermediate nodes. Thus, ﬂits using these tokens are guaranteed to bypass intermediate nodes along the token route. Similar to normal tokens, these tokens should not be viewed as being turned off if a packet uses them. They are turned off explicitly by their source routers. Why do we need guaranteed tokens? Consider a packet starting at a node which is in a congested section of the network. In this case, there will likely be no normal tokens for bypassing neighboring nodes in that congested neighborhood due to lack of buffers/VCs at neighbors. Thus, the packet will be forced to be buffered and wait for VCs/buffers by going through the router pipeline at each hop which will most likely further exacerbate contention for these resources in that congested section, hence leading to an increase in queuing delay. The key intuition behind guaranteed tokens is the observation that if a packet’s destination does not lie in a congested section of the network, then ideally it should not care about the availability of resources at intermediate nodes in that section and should be able to jump out of it by zooming through neighboring routers. Fig. 5(a) depicts such a scenario where a packet going from node 42 to destination node 34 is not able to bypass nodes in a congested network section due to lack of normal tokens from neighboring nodes even though its destination node lies outside that congested section and has enough free buffers/VCs. In such cases, having guaranteed tokens which allow ﬂits to skip through the congested routers, from 42 directly to 34, will help improve energy-delay-throughput. What needs to be ensured by a gmax -hop guaranteed token? A gmax -hop guaranteed token provides a guarantee (to a ﬂit using it) for resource availability at the endpoint node of that token route (i.e., at the source node from where that token was generated), but not at any of the intermediate nodes along that route. Hence, such a token needs to ensure three things: (cid:129) There is at least one free buffer so the ﬂit is ensured of a buffer at the endpoint node of the guaranteed token route. (cid:129) There is at least one free VC so the ﬂit is ensured of ﬁnding a free VC at that endpoint node. (cid:129) A lookahead carrying a guaranteed token is not killed at any intermediate node along that token route due to conﬂicts with other lookaheads. Since a ﬂit starting out at a node using a guaranteed token is not guaranteed resources at intermediate hops along its token route, it is not safe to kill its lookahead in between at a node which may have no free buffers/VCs. Hence, a guaranteed token route needs to be conﬂict-free. How are these conditions ensured when turning on/off and forwarding a guaranteed token? Turning on: In order to ensure the ﬁrst two conditions of at least one free buffer and VC, a source router of a guaranteed token turns on a guaranteed token for an input port only if there are greater than bgthr buffers and vgthr VCs available at that port. These threshold values are higher than the corresponding ones for normal tokens (bthr buffers and vthr VCs) in order to cover a longer gmax -hop round-trip delay so that all already-inﬂight ﬂits are ensured of buffers/VCs during the time it takes to turn off the guaranteed token. An example is shown in Fig. 5(b), where node 34 sends out a guaranteed token Eon g to its West neighbor when its West input port has greater than bgthr free buffers and vgthr free VCs. Forwarding: The third condition of no lookahead conﬂicts is ensured by the mechanism used to forward guaranteed tokens. When a node receives a guaranteed token, it forwards the token by unicasting the token along the direction given by the switch port priority vector entry for that output port. This is unlike normal tokens which are forwarded by broadcasting to neighboring nodes. This unicasting ensures that a lookahead arriving at a node carrying guaranteed token will always have priority to use its desired output port and hence will never be killed due to conﬂicts with other lookaheads. Thus, as shown in Fig. 5(b), node 33 on receiving the Eon g guaranteed token from the token’s source node 34, unicasts it to its West neighbor, assuming in the current priority setting at node 33, the West input has priority to use the East output. This forwarding of the guaranteed token is done similarly at other nodes and continues for gmax hops in the network. Assuming a gmax = 3, the Eon g token ends at node 42. It should be noted that, unlike normal tokens, a node does not need to check for buffers/VCs at its own input ports before forwarding guaranteed tokens. Turning of f : A guaranteed token for an input port is turned of f by its source router if either the number of free buffers at that port becomes ≤ bgthr or the number of free VCs at that port becomes ≤ vgthr . On the other hand, at routers which are not the source of a guaranteed token but are involved in forwarding of that token, whenever there is a change in their local switch port priority vector setting, any guaranteed tokens forwarded along the previous priority direction are turned off and instead now forwarded along the new priority direction. Handling of already in-transit ﬂits using the old guaranteed tokens is explained later in Section 4.4. How are guaranteed tokens used? If a packet is not able to get a normal token for the next hop along its route (due to lack of buffers/VCs), it looks for any available guaranteed tokens which match its already-computed route. If such a guaranteed token is available, the packet is allowed to make progress by sending out a lookahead (similar to lookaheads for normal tokens) even if there are no VCs/buffers available at the next hop. As described above, since guaranteed tokens are only unicast along switch allocator priority setting paths at each router, a lookahead arriving at an intermediate router holding a guaranteed token is ensured of having priority to use its desired switch port at that router. Moreover, now there is no need to check for VCs/buffers at the intermediate hops because of the guarantee to get a VC/buffer at the endpoint node of the guaranteed token route. Hence, such a lookahead is allowed to directly make progress to the next hop with its corresponding data ﬂit directly traversing the switch upon arrival in the next cycle. Continuing with the example in Fig. 5(b), even though there may be no buffers/VCs available at the North input port of node 32, a ﬂit starting at node 42 and going to node 34 (which may be its destination node or a node closer to its destination) can use the Eon g guaranteed token to bypass nodes 32 and 33 along the way without checking for buffers and VCs at those nodes. The ﬂit only needs to allocate a free VC for the endpoint node of its guaranteed token route (node 34) which is done by the lookahead at the previous node 33. Moreover, several guaranteed tokens can be chained together in the lookahead pipeline, just like chaining of normal tokens, thus enabling arbitrarily long guaranteed paths. 4. Implementation details 4.1. Router pipeline and microarchitecture Fig. 6(a) shows the typical pipeline of the head ﬂit of a packet traveling over multiple hops using a token. Normal tokens are used during RC to compute a packet’s token route for up to the next dmax hops in one go. This is done one hop in advance, just as in the baseline router. At node R1, from where the packet’s token route starts, the head ﬂit ﬁrst goes through the complete router pipeline starting with the setup stage where it sends an output port request to the switch allocator based on its immediately next output port given by its route. In parallel, it is written to the payload buffer. In the next cycle, SA and VA are done using using a scheme similar to the one used in the baseline router (Section 2). After successfully winning the switch port, the ﬂit traverses the crossbar during the ST stage. A lookahead pipeline operates in parallel with the data ﬂit pipeline, where a lookahead, which encodes the ﬂit’s token route and its remaining hops to the destination, is sent out on a separate dedicated narrow channel during the lookahead link traversal (LA LT) stage to travel to the next node R2. During the time that the data ﬂit goes through LT in the next cycle, a lookahead conﬂict check (LA CC) takes place at the next node (R2) for the subsequent output port encoded in the token route carried by the lookahead. During LA CC, the lookahead succeeds in winning its desired switch port if there are no conﬂicts, i.e., if it is the only lookahead asking for that output port in that cycle. However, if more than one lookaheads arrive simultaneously at R2 asking for the same output port, the local switch port priority vector maintained by R2 is used to break conﬂicts (as explained earlier in Fig 4), with a lookahead succeeding if it arrived at the input Head  flit Setup BW SA VA ST LT Time Router n  (R1) Router n+1  (R2) Router n+2 (R3)  (dmax-1)th hop Router n+3  (R4) LA LT LA CC ST LT LA LT LA CC LA RC ST LT LA LT LA CC ST LT LA LT Route  Computation VC  Allocator Switch  Allocator Input 0 Shared input  buffer pool VC 1 VC 2 VC n VC 1 VC 2 Input 4 VC n Shared input  buffer pool Output 0 Output 4 Crossbar switch (b) Router microarchitecture (a) Router pipeline assuming dmax = 3 (lookahead pipeline stages are shaded) Figure 6. Token flow control router pipeline and microarchitecture port which has priority to use its desired output port. Thus, the complexity of LA CC is minimal as compared to a fullblown switch arbitration scheme and it only involves checking if a lookahead matches the priority vector setting for its desired port. There is never a need to do full-blown arbitration. For instance, if two lookaheads conﬂict and none of them matches the priority vector setting then both are killed. Hence, LA CC only uses a one-hot detect logic to check if there is a conﬂict (similar to the baseline), along with a simple priority match to break conﬂicts. In parallel with LA CC, a free VC for the next hop is picked from a pool of free VCs along with checking for a free buffer, just as in the baseline. However, in this case, if there are no buffers/VCs available at the next hop, the lookahead is still allowed to succeed if a guaranteed token which matches either the entire or a part of the packet’s remaining token route is available3 . Thus, while normal tokens are used to form a packet’s token route for up to dmax hops during RC, a guaranteed token can be selected for this alreadycomputed route at any node along the route during LA CC if there are no resources available at the next hop. As mentioned in Section 3.1, lookaheads, in this case, are prioritized over any locally-buffered ﬂits at that router waiting to exit the same output port. Thus, if the lookahead succeeds in LA CC, the local SA result at R2 for that output port is nulliﬁed. The data ﬂit corresponding to that successful lookahead is able to bypass the router pipeline at R2 and directly traverses the crossbar during ST when it arrives in the next cycle, with the lookahead continuing to travel to the next hop along the token route. However, if the lookahead fails, it is killed and its corresponding data ﬂit goes through the complete pipeline. Another token route can be chained one hop before the end of the current token route (at router R3, assuming the current token route extends up to dmax = 3 hops, i.e., up to router R4) by doing RC in the lookahead pipeline (LA RC), thus avoiding any delay overhead to the data pipeline due to this chaining from one token route to another. There is a similar data and lookahead pipeline for each body/tail ﬂit of the packet except that they do not go through RC and VA stages, instead inheriting the route and VC used by the header ﬂit. Fig. 6(b) shows the microarchitecture of a router in a network using TFC. The modiﬁcations to the different units, as compared 3. This check for guaranteed tokens is done in parallel with LA CC to allow chaining from one token route to another without overhead. to the baseline microarchitecture of Fig. 1(a), are minimal and are highlighted using shaded regions. The RC unit is modiﬁed to incorporate available normal tokens while calculating packet routes. The switch allocator now maintains a switch port priority vector for resolving clashes among lookaheads during LA CC. Moreover, SA for locally-buffered ﬂits is nulliﬁed if a lookahead is using a particular output port. The VC allocator now also checks for guaranteed tokens which match the packet’s route if there are no VCs available for the next hop. Note that these modiﬁcations are mainly to the control logic and arbiters which are only a small portion of the router complexity. For instance, these units consume only 7% of the router power in the Intel teraﬂops router [3]. 4.2. Buffer and VC thresholds for sending tokens As mentioned in Section 2, the baseline design uses dynamic buffer management with on/off ﬂow control to signal buffer availability across adjacent nodes. As the number of free buffers at an input port of a node becomes equal to or falls below a threshold bthr , it sends an of f signal to its adjacent node, signaling to it to stop sending further ﬂits. The threshold value bthr needs to be enough to ensure that all ﬂits which are already inﬂight are ensured of free buffers during the time the of f signal is transmitted and processed. Hence, bthr is calculated based on the round-trip delay between adjacent nodes. Assuming the off signal takes one cycle each for transmission to the adjacent node, one cycle for being processed and there can be at most two ﬂits already in-ﬂight which need to be ensured of free buffers, gives a value of bthr = 4. Similarly, an on signal is sent out if the number of free buffers exceeds bthr . In TFC, even though a token route using a normal token can extend up to dmax hops, ﬂits traveling along normal token routes need to check for buffers at every intermediate node along their route and, hence, normal tokens require buffers to be managed on a hop-by-hop basis similar to the baseline. Therefore, a normal token for an input port is turned off if the number of free buffers at that port becomes less than or equal to bthr and vice versa. On the other hand, the corresponding buffer threshold value, bgthr , for turning on/off guaranteed tokens, needs to cover a longer up to gmax -hop round-trip to ensure buffer availability across the gmax hops. bgthr is given by: bgthr = gmax + 1 + 2gmax = 3gmax + 1 (1) where the off signaling is assumed to take gmax cycles to travel back gmax hops to the farthest away node which may be using the guaranteed token, it takes one cycle for processing the off signal and there can be at most 2gmax ﬂits already in-ﬂight at the intermediate nodes which may be using this guaranteed token and which need to be ensured of free buffers. The value of 2gmax in-ﬂight ﬂits stems from the bypassing data pipeline in TFC which has two stages (ST and LT) per hop (Fig 6(a)). In case of VCs, the threshold for the number of free VCs, vthr , to turn on/off a normal token, is a parameter which is used as a proxy to communicate the level of congestion. Hence, a normal token is turned off for a port having less than or equal to vthr VCs and vice versa. On the other hand, the threshold value to turn on/off a guaranteed token, vgthr , needs to be such that a packet using a guaranteed token is ensured to ﬁnd a free VC when it reaches the endpoint of that guaranteed token route (which may be up to gmax hops away from where the packet starts using that token). In our design, vgthr is set to be equal to bgthr to cover a gmax -hop round-trip. 4.3. Route computation Routing algorithm: As explained in Section 3.1, packets use normal tokens to form up to dmax -hop long token routes along less congested sections of the network. This assumes the routing algorithm to be adaptive. In this work, we use minimal westﬁrst routing [14] for both the baseline and TFC. In this routing scheme, packets are restricted to cover all their hops in the West direction (if any) before turning to a different dimension, while routes can be adaptive if a packet has hops remaining in both East and North directions or both East and South directions (in which case it chooses the direction which is more proﬁtable, i.e., has more buffers [15], [16]). Minimal west-ﬁrst routing is easy to implement and provides inherent deadlock freedom by prohibiting turns which lead to cyclic dependencies while using only minimal paths by not allowing misroutes which can adversely affect packet energy/delay. It should be noted that even though we choose minimal west-ﬁrst routing, TFC can be used along with any adaptive routing algorithm. Moreover, even if the routing algorithm is non-adaptive, packets can still bypass nodes using tokens along a deterministic route although fewer token route choices will be available. We evaluate this aspect in Section 5.7. RC using longest match: RC is done by ﬁnding the longest feasible token route (which can be up to dmax hops long) based on the routes permitted by the adaptive routing scheme and the available tokens. Since packet routes are computed for up to dmax hops in one go, the hardware complexity of RC (which is done in the lookahead pipeline, as shown in Fig. 6(a)) is proportional to dmax . The lookahead corresponding to the head ﬂit of a packet carries the magnitude of the remaining hops to the packet’s destination node in each dimension (x and y ), with two sign bits indicating the corresponding direction to be taken in each dimension (sx and sy ). Since minimal west-ﬁrst routing allows adaptivity only if there is distance to be covered in both East (x >0 and sx = 0) and North (y > 0 and sy = 0) directions or in both East (x >0 and sx = 0) and South (y > 0 and sy = 1) directions, ﬁnding less-congested routes using tokens can be done only in these cases. Consider the case when the packet has hops left in the East (E) and North (N) directions. In this case, the possible values for x either lie in the range 1 to dmax − 1 or x ≥ dmax , and similarly for y , thus leading to a total of dmax × dmax possible (x, y ) tuples. Based on the available tokens at a given instant of time, each router maintains a corresponding dmax × dmax vector of the longest match (LM) token route for each corresponding (x, y ) tuple. For instance, in a network with dmax = 3, if a packet has hops left in the E and N directions with x = 2 and y = 1, it can take up to two E hops and up to one N hop in any order leading to the following eight possible route combinations: EEN, ENE, NEE, EE, EN, NE, E and N. The LM vector entry corresponding to the (x = 2, y = 1) tuple then contains the longest possible consecutive sequence of available tokens out of the above eight possibilities. Hence, if there is an Eon token available at a node from its immediate East neighbor, an Eon token available from the node which lies two hops to the East, and an Non token available from the node two hops East and then one hop North, the LM vector entry for (x = 2, y = 1) would contain EEN. Among two or more token sequences of the same length, the one in which there are more proﬁtable hops (hops along directions with more buffers than the other alternative direction) is chosen as the LM entry4 . All LM vector entries can be precalculated based on the available tokens before a lookahead arrives. Hence, LM vector calculation does not fall on the RC critical path. Route padding: The LM vector entries, for which the longest imum hops possible for that (x, y ) tuple (which is ≤ dmax ), sequence of available normal tokens is smaller than the maxare padded assuming X-Y routing to ﬁll in the remaining hops even though there may be no tokens available for the padded portion of the route. Hence, considering the above example when the longest token route for the tuple (x = 2, y = 1) is EE, the corresponding LM vector entry contains the padded route EEN (assuming dmax = 3). Route padding helps packets to bypass routers when there are no normal tokens available or when there is no adaptivity possible along their route due to constraints imposed by the routing algorithm5 . In such cases, adaptive token routes cannot be created and padding is used instead to compute the packet’s route for up to dmax hops. Lookaheads, which do not carry tokens, are then sent out ahead of the data ﬂits along this padded route. These lookaheads go through a similar pipeline as the lookaheads carrying tokens (Fig. 6(a)) and are prioritized over local ﬂits at intermediate nodes, thereby allowing packets to bypass these intermediate nodes. However, the chances of successfully bypassing a node is lower for lookaheads which do not carry a token than when bypassing using a token since routes formed using tokens are ensured to be along less congested paths in the network and, hence, have relatively less chances of conﬂicts. As mentioned in Section 4.1, packets are allowed to use guaranteed tokens to jump out of congested pockets only along their already-computed route. Hence, using padding to compute 4. If the number of profitable hops is the same, the one, in which the packet covers its remaining hops in the x-dimension first, is chosen. 5. For minimal west-first routing, there is no adaptivity possible if the packet needs to travel west or has hops left only in either the east or the Y-dimension. Table 1. Route computation critical path delay Delay (FO4) 3.59 5.09 5.96 dmax 1 2 3 longer routes (up to dmax hops) when there are no normal tokens available also enables packets to use any available guaranteed tokens to bypass nodes when there are no buffers/VCs available at the next node. RC logic complexity: We analyzed the critical path delay of the RC logic circuit in terms of fanout-of-four (FO4) delays using the theory of logical effort with the methodology used in [12]. This delay T in FO4 units is given by: T = log4 (3 · d3 max ) + 2.8 (2) The values of T for different values of dmax are presented in Table 1. As can be seen, this delay grows with larger values of dmax . However, since RC is done in the lookahead pipeline one hop before it is required (as shown in Fig. 6(a)), it does not have to be serialized before doing LA CC and can be done in parallel. Using circuit-level analysis data from [9] (which targets a clock period of 18FO4), the only stage where we extend the critical path in comparison is LA CC (due to the extra RC logic which dominates the LA CC logic in delay). We estimate this RC logic of up tod max = 3 to require an additional delay of 3 FO4 on top of using the already available wire delay slack of 3 FO4 in the lookahead pipeline, as shown in [9] (which is due to a relatively short switch path which these narrow bit-width lookaheads need to traverse as compared to the data ﬂit). This gives a total clock delay of 21 FO4 for our design. 4.4. Switch port priority vector As mentioned in Section 3, each router maintains a switch port priority vector with an entry for each output port denoting which input port has priority to use that output. This vector is used for both – breaking conﬂicts between multiple lookaheads carrying normal tokens and ﬁguring out the unicast direction along which the router forwards the guaranteed tokens it receives from its neighbors. We vary this priority vector entry at each router dynamically to favor different input-output combinations based on the observed trafﬁc with the intuition being to balance the output port request queues at each input. Speciﬁcally, each router keeps a count of the number of waiting requests for each output port at each input queue. After every e clock cycles (where e is a parameter deﬁned as the epoch period), these counters are examined, and the input port i with the highest number of requests for a particular output port o is assigned priority to use that output. This assumes that the past trafﬁc seen in the previous epoch is a predictor of the future trafﬁc to be seen in the next epoch. The forwarding of normal tokens is unaffected by local changes in priority settings at each router. On the other hand, any guaranteed tokens, which were forwarded earlier by unicasting along the direction given by the old priority setting, need to be turned off while now being forwarded along the direction given by the new priority setting. Hence, for instance, if the West input had priority over the East output at a router in the old setting and the North input has that priority in the new setting, any guaranteed tokens received at the East input by that router and forwarded along the West neighboring node earlier are turned off and now forwarded along the North neighboring node. However, there may already be in-transit ﬂits using the old guaranteed tokens corresponding to the old priority setting. In order to ensure such ﬂits do not get stalled due to lookahead conﬂicts, even though the old guaranteed tokens are turned off they are not forwarded along their new direction and the new priority setting is not applied locally at that router immediately at the end of the epoch e. Rather, each router maintains a transition window equal to 2.gmax to cover all potential head ﬂits which may have started up to gmax hops away using the old guaranteed token while tracking any outstanding body/tail ﬂits (which are yet to arrive) corresponding to these header ﬂits. When this window is complete and there are no outstanding ﬂits, it is ensured that there will be no more ﬂits arriving at that router using the old guaranteed tokens. It is then safe to apply the new priority settings which are applied and guaranteed tokens are forwarded along the new priority direction. 4.5. Wiring overhead TFC uses additional wiring to communicate tokens and lookaheads between nodes. Assuming minimal west-ﬁrst routing using number of free buffers to indicate the more proﬁtable direction and lookahead routing, the wiring required for a token design with dmax = 1 is the same as that of the baseline design. This overhead, however, increases with dmax . Normal tokens: Indicating greater than a threshold value of free buffers/VCs using normal tokens requires a single-bit wire per port. With minimal west-ﬁrst routing, a node needs to receive normal tokens only from router ports which lie in either its NE or SE quadrant (along which adaptivity is possible) extending up to dmax -hops. One extra wire for every reachable node in the NE quadrant is needed to indicate which one of the N and E ports is more proﬁtable (has more buffers) and similarly for nodes in the SE quadrant. In addition, extra wires proportional to dmax are needed to make tokens visible to neighboring nodes in order to enable lookahead routing. Since neighboring nodes in only NE and SE quadrants need to be considered, the total additional wiring overhead of normal tokens is not symmetric across all directions and the per-port overhead at a router, Wnormal , is given by: (3 · (d2 max ) + 8 · dmax − 11)/4 (cid:3) Wnormal = (3) Guaranteed tokens: In contrast to normal tokens, a node receives guaranteed tokens from all nodes in its gmax -hop neighborhood with the associated wiring being proportional to the total number of ports reachable in this neighborhood. This overhead when divided across each port at the router, Wguaranteed , is given by: (cid:2) Wguaranteed = g2 max (4) Lookahead signals: Lookaheads for each ﬂit in the baseline design encode the remaining hops in each dimension and the immediate next hop output port of that ﬂit. In addition to this information, lookaheads in TFC need to encode the ﬂit’s route for an additional dmax − 1 hops. Hence, using three bits to dmax (= gmax ) Wnormal Wguarantee Wlookahead Table 2. Additional wiring overhead over the baseline design Total 12 25 5 10 4 9 3 6 2 3 encode each output port in this route leads to an additional perport wiring overhead, Wlookahead , given by: Wlookahead = 3 · (dmax − 1) (5) Table 2 presents the total wiring overhead in addition to the baseline design for different values of dmax > 1 (assuming gmax = dmax ), with the wiring for dmax = 1 being the same as that of the baseline. As can be seen, this additional overhead is small as compared to the data channel width (which we assume to be 128 bits in this work) for up to reasonable values of dmax , and grows as dmax increases. However, it should be noted that TFC enables arbitrarily long bypass paths even with a small dmax , since multiple small token routes can be chained together without any delay overhead. 4.6. Starvation avoidance In TFC, since lookaheads carrying tokens are given priority in using their desired switch port over any locally-buffered ﬂits at a router, this can lead to starvation of locally-buffered ﬂits. To avoid such scenarios, each node keeps track of the number of consecutive ﬂits bypassed using tokens for each output port. When this number for a particular output port o at a router r exceeds a pre-deﬁned threshold, strof f , and if there are locally-buffered ﬂits at that router which are waiting to use output o, a starvation avoidance mechanism is triggered. Further lookaheads carrying normal tokens, which arrive at r asking for port o, are killed and the corresponding ﬂit is forced to get buffered and go through the normal pipeline at r . However, similar lookaheads carrying guaranteed tokens cannot be killed in between. To prevent starvation due to ﬂits using guaranteed tokens, any guaranteed tokens forwarded by r , along input i which has priority to use output o, are turned off, thereby preventing any new lookaheads carrying guaranteed tokens along the starved route. This is done for strcycles after which forwarding of the turned off guaranteed tokens is resumed. strof f and strcycles are pre-deﬁned system parameters. 5. Evaluation 5.1. Comparison with express virtual channels (EVCs) In addition to comparing TFC against the state-of-the-art baseline design (presented in Section 2), we also compare it against EVCs [6], a recently proposed technique which allow packets to virtually bypass nodes along their path similar to bypassing of nodes in TFC. EVCs allow bypassing using predeﬁned virtual lanes in the network which connect distant nodes along a straight line. However, EVC paths have certain limitations. They have ﬁxed endpoints and, in the general case, can only run straight without turning. The maximum length, lmax , of an EVC is limited by the amount of buffering available at router ports. In addition, resources such as VCs in an EVC design are partitioned among normal VCs and EVCs of varying lengths which prohibits efﬁciently sharing them across different paths based on the actual trafﬁc. While both TFC and EVCs share a common goal of bypassing routers, they are inherently different in their working. The use Table 3. Network and technology parameters Technology 65 nm 1.1 V 0.17 V Vdd Vthreshold Link length Wire pitch Flit size/channel width Frequency Topology Routing algorithm Number of message classes VCs per message class Buffers per port Token dmax Token gmax 1 mm 0.45µm 128 bits 3 GH z 7-ary 2-mesh Minimal West-First 3 8 48 (dynamically shared) 3 3 20 3 40 3 strof f strcycles Epoch e vthr of per-hop tokens in TFC helps improve on EVCs by removing all the above limitations. Bypass paths can be dynamically formed using tokens from one node of the network to any other node allowing them to adapt to a packet’s exact route. Packets can chain a succession of tokens without additional overhead, making token routes highly scalable with arbitrary lengths and including an arbitrary number of turns without being limited by the amount of buffering in the network. Moreover, resources, such as VCs, in TFC are not statically partitioned and can be shared across different token routes on a hop-by-hop basis. 5.2. Simulation setup We use a detailed cycle-accurate microarchitecture simulator to model network performance. All major components of the router microarchitecture, including RC, buffer management, VA, SA, token generation and forwarding, on/off ﬂow control, etc., are modeled in detail while tracking the different operations a ﬂit and its corresponding lookahead go through every cycle as they traverse the data and lookahead pipeline stages, respectively. Contention for resources, such as buffers, VCs, crossbar input and output ports, etc., are accurately modeled with the delay of each pipestage derived from detailed circuit-level schematics, similar to the approach in [9]. To evaluate network energy, we use Orion [17], an architecture-level network energy model, which is integrated in our performance model to keep track of both dynamic and leakage energy of all major microarchitectural components, including buffers, crossbar, allocation logic and network links. All designs incorporate power-optimized straightthrough buffer and cut-through crossbar designs [5]. Table 3 lists the default network and technology parameters used in this study. These parameters were chosen for the best baseline as well as EVC performance and unless otherwise mentioned, all experiments use these parameters. The comparison with EVCs uses a dynamic EVC design (in which every node is a source/sink of variable-length EVCs) using the nonaggressive express pipeline since the design with an aggressive express pipeline incurs additional area overhead in the form of extra straight-through links around the crossbar in order to allow ﬂits to skip ST as well when bypassing a router [6]. It should be noted, however, that using an aggressive design with extra straight-through link bandwidth will beneﬁt TFC as well. The maximum EVC length lmax was chosen to be three and the design incorporates the routing ﬂexibility feature proposed 80 60 40 20 ) s e l c y c ( y c n e t a L 0 0.04 0.16 0.28 0.4 0.52 0.64 0.76 Injected traffic (% of capacity) Baseline EVC Token Figure 7. Uniform random traffic in [6] which allows packets to switch between EVCs of varying lengths to reduce VC contention. All runs using synthetic trafﬁc are 1 million cycles long with a 100k cycles warm-up period and use a mix of single-ﬂit short packets and ﬁve-ﬂit long packets spread across three protocol message classes. In all results, we deﬁne network saturation to be the point where ﬂit latency becomes three times the no-load latency. Network capacity is calculated based on the channel load of the most heavily utilized links in the network based on the trafﬁc pattern. 5.3. Uniform random trafﬁc Fig. 7 presents network performance using uniform random trafﬁc by plotting ﬂit latencies as a function of injected load using the default parameters presented in Table 3. When the network load is low, the baseline latency is close to that of EVCs and TFC because of the use of lookaheads for no-load bypassing when router ports are mostly empty. However, at higher values of network load, TFC signiﬁcantly outperforms both the baseline and EVC designs in terms of latency while simultaneously improving throughput. As compared to the baseline, TFC leads to 51.7% reduction in latency near the baseline saturation point. When compared to EVCs, TFC reduces latency by 38.2% near the EVC saturation point. This is mainly attributable to the ﬂexible nature of TFC which allows packets to choose tokens that exactly match their route and bypass routers along them. Moreover, unlike EVCs, packets are able to bypass routers even while turning from one dimension to another. At very high load, when there are few normal tokens available due to lack of sufﬁcient resources, TFC continues to show lower latency and higher throughput because of route padding which is used to still compute up to dmax -hop long routes using XY routing (Section 4.3) and, lookaheads, which may not be carrying tokens, are sent along these routes to bypass routers. In terms of energy, while EVCs lead to a 26.5% reduction in router energy over the baseline near the baseline saturation point, this reduction is 37.3% using tokens. This again is mainly due to packets bypassing more nodes without having to get buffered. Speciﬁcally, while EVCs are able to reduce buffer energy by 45.1% as compared to the baseline, this reduction is a signiﬁcant 68% using tokens. Both EVCs and TFC allow packets to bypass nodes nonspeculatively even under medium/high loads and, hence, lead to latency and throughput improvements. But while EVCs allow bypassing only along restricted straight line paths, tokens allow packets to choose less congested routes in the network and then bypass nodes along them including along turns. When compared to the ideal packet-switched design, where packets can bypass all intermediate nodes along their route, tokens allow packets to bypass 87.1% of all intermediate nodes near baseline saturation. 5.4. Effect of fewer resources The signiﬁcantly higher throughput achieved by TFC, as compared to the baseline, allows for an energy-performance trade-off where the same throughput as that of the baseline can be attained with signiﬁcantly smaller amount of buffering in the network. Here, we study this effect by starting with a leaner router design with 4 VCs per message class and 40 buffers per port 6 , and gradually reducing the buffers per port in both the token and EVC designs, until their throughput became equal to that of the baseline. We found that while the EVC design achieved the same baseline throughput with a signiﬁcantly lower 25 buffers per port (leading to a 53.1% reduction in dynamic buffer energy and a 28.4% reduction in leakage energy as compared to the baseline), the token design achieved the same baseline throughput with an even lower 14 buffers per port (leading to a dynamic buffer energy reduction of 79.4% and a leakage energy reduction of 48.8% as compared to the baseline). This translated to a total router energy reduction (as compared to the baseline) of 35.6% using EVCs while the corresponding reduction using tokens was 55.4%. Naturally, this reduces the area footprint as well. 5.5. Non-uniform trafﬁc Fig. 8 shows network performance for bit-complement trafﬁc. While EVCs lead to a 18.4% latency reduction (24.9% lower router energy) over the baseline near saturation, tokens lead to a higher latency reduction by 56.9% (39.6% lower router energy) as well as push throughput. For this trafﬁc, this is mainly because EVCs only allow straight bypass paths in the network, thus leading to a higher queuing imbalance at certain nodes where the fraction of turning trafﬁc is high. In contrast, token bypass paths can turn and exhibit better queuing behavior by using dynamic switch port priority settings at each router which are changed based on the observed trafﬁc, thereby balancing the queue lengths at different input ports in each router. For transpose trafﬁc (Fig. 9), the ability of tokens to allow packets to take less congested routes in the network in addition to bypassing routers along those routes leads to a higher latency reduction of 20.6% over the baseline near saturation with the corresponding reduction in router energy being 29.3% (as compared to 19.9% lower energy using EVCs). Tornado trafﬁc which involves packets going half-way around the mesh in a straight line represents the best-case for EVCs and as shown in Fig. 10, they lead to signiﬁcant latency (48.7%) and router energy reduction (25.4%) over the baseline near saturation. While tokens also lead to a signiﬁcant corresponding latency (48%) and router energy reduction (33.4%), their saturation throughput is slightly lower than EVCs. Analyzing this further, we found that while seamless chaining of successive token routes allows packets to bypass a higher fraction of the total nodes along their route (75.3%) as compared to 43% nodes bypassed in EVCs (also leading to a correspondingly lower dynamic router energy), bypassing more nodes does not always 6. This number was chosen to minimize buffer contention in the baseline since we saw the baseline performance degrading significantly below 40 buffers.   60 50 40 30 20 10 ) s e l c y c ( y c n e t a L 0 0.0233 40 30 20 10 ) s e l c y c ( y c n e t a L 80 60 40 20 ) s e l c y c ( y c n e t a L 0.05825 0.0932 0.12815 0.1631 0.19805 0.233 0.26795 Injected traffic (flits/node/cycle) baseline EVC Token Figure 8. Bit-complement traffic 0 0.0233 0.040775 0.05825 0.075725 0.0932 0.110675 0.12815 0.145625 0.1631 0 0.0233 Injected traffic (flits/node/cycle) Baseline EVC Token Figure 9. Transpose traffic 0.1165 0.1864 0.2563 0.3262 Injected traffic (flits/node/cycle) baseline EVC Token Figure 10. Tornado traffic improve latency for this trafﬁc at high loads. This is because nodes at the center of each row in the network see a lot of bypassing trafﬁc causing their local ﬂits to wait longer for using the switch leading to more occurrences of starvation. This effect can be alleviated through a more dynamic starvation-avoidance policy based on the observed queuing at nodes instead of using ﬁxed thresholds to signal starvation and is left for future work. 5.6. Effect of varying dmax As mentioned in Section 3.2, packets use guaranteed tokens only along their already computed dmax -hop route (with gmax being equal to dmax in our design). Hence, a larger dmax has two effects: it not only allows more adaptive routes by providing packets with normal tokens from a larger neighborhood of nodes but also provides packets the opportunity to use longerhop guaranteed tokens to skip over more number of nodes in trying to get out of congested network sections at high loads. It should be noted that a smaller dmax does not necessarily mean bypassing of a smaller number of nodes because even in a token design with dmax = 1, packets can bypass more than one node in one go by chaining successive tokens at every hop without any delay overhead. Fig. 11 highlights this effect by presenting network performance for increasing values of dmax using tornado trafﬁc. The performance at low and medium loads is similar and not affected due to smaller dmax values. This is because packets are still able to bypass a high fraction of the total nodes along their path by chaining several tokens (72.6% of the total nodes bypassed for dmax = 1, 74.2% for dmax = 2 and 75.3% for dmax = 3). However, as network load increases, a higher dmax (= gmax ) leads to a higher saturation throughput. Since the tornado trafﬁc pattern has packets traveling only along straight line, there is no adaptivity possible in packet routes when using minimal routing and hence the performance improvement at high loads is not due to increased adaptivity using normal tokens but solely due to the ability to use longerhop guaranteed tokens to bypass several congested nodes in a guaranteed fashion. Hence, this depicts a scenario where guaranteed tokens beneﬁt performance in a design with higher dmax (= gmax ). In terms of energy consumption, since the number of nodes bypassed remains almost the same, there is almost no impact on dynamic router energy due to smaller dmax . 5.7. Flow control vs. routing The beneﬁts of TFC consist of both its adaptive routing aspect of choosing better routes using tokens and its ﬂow control aspect of bypassing routers along the token routes. To study the impact of the ﬂow control aspect, we use a token design, token no bypassing , which allows packets to compute up to dmax -hop routes adaptively using tokens similar to the default TFC. But unlike the default TFC token no bypassing disables bypassing of routers along the token routes. Fig. 12 presents network performance for uniform trafﬁc comparing token no bypassing with the default TFC (with dmax = 3). The ﬁgure shows the default TFC signiﬁcantly outperforming token no bypassing (44.7% latency reduction near saturation), thereby implying that bypassing routers along token routes is a major contributor towards overall performance. To study the adaptive routing aspect, we compared a design using dimension-ordered routing (DOR) when computing dmax hop token routes versus the default scheme which uses adaptive minimal west-ﬁrst routing. Fig. 13 plots this effect for both the baseline and TFC (with dmax = 3) using the transpose trafﬁc pattern which beneﬁts from adaptive routing. As seen, the performance using adaptive routing is better than DOR for both the baseline (18.9% lower latency near saturation), as well as for TFC (20.4% lower latency near saturation). 5.8. SPLASH benchmark results TFC leads to signiﬁcant improvements in energy/delay as compared to the baseline across a range of SPLASH-2 benchmarks (gathered using the methodology described in [6]). The reduction in latency is largest for the water-spatial benchmark (77.1%) mainly due to high trafﬁc load at which the baseline exhibits large queuing delays while TFC continues to show lower latency by allowing packets to bypass nodes along token routes which match their path. Similarly, water-nsquared also exhibits relatively high trafﬁc with the latency reduction using TFC being 69.6%. On the other extreme is raytrace which has very low trafﬁc load at which no-load bypassing in the baseline is effective and hence the latency reduction due to TFC is only 2%. The other benchmarks – lu, ocean, radix, barnes and fft represent medium-load scenarios with TFC reducing latencies by 25.5%, 26.2%, 39.2%, 24% and 22%, respectively. TFC is also able to signiﬁcantly reduce average router energy with the reductions being 24.5%, 21.6%, 22.9%, 25.1%, 20.6%, 23.5% and 15.4% for lu, ocean, radix, barnes, water-nsquared, waterspatial and fft, respectively. This is mainly due to lower buffer energy by eliminating the need for ﬂits to get buffered when they are bypassing routers along token routes. For raytrace, the energy reduction is only 2.3%, again due to low trafﬁc in this benchmark at which baseline’s no-load bypassing is effective. 6. Related work Flow control: Circuit switching [7] uses pre-reservation of physical channels from the source to destination before the actual data transfer begins. This can approach link energy/delay once data transfer starts but incurs a large delay overhead in       60 40 20 ) s e l c y c ( y c n e t a L 0 0.1631 0.19805 0.233 0.26795 0.3029 Injected traffic (flits/node/cycle) dmax=1 dmax=2 dmax=3 Figure 11. Effect of varying dmax 100 80 60 40 20 ) s e l c y c ( y c n e t a L 0 0.04 40 ) s e l 30 c y c ( 20 y c n e t a L 10 0.16 0.28 0.4 0.52 0.64 0.76 Injected traffic (% of capacity) Token_no_bypass Token Figure 12. Effect of flow control 0 0.0233 0.040775 0.05825 0.075725 0.0932 0.110675 0.12815 0.145625 0.1631 Baseline_DOR Injected traffic (flits/node/cycle) Baseline_Adaptive Token_DOR Token_Adaptive Figure 13. Effect of routing setting up and tearing down circuits while inefﬁciently sharing available bandwidth by dedicating channels to particular packet ﬂows. Variants of this such as pipelined circuit switching [18] and hybrid circuit switching [19] have been proposed which allow bandwidth sharing across multiple circuits. Unlike circuit switching and its variants, TFC allows packets to bypass routers along their path without any setup/tear-down delay while allowing complete sharing of link bandwidth across different ﬂows. Topology: TFC is completely orthogonal to network topology. Even though a mesh topology was chosen in this work because of its simplicity and ubiquity [1]–[3], tokens can signiﬁcantly reduce per-hop router overhead (which dominates link overhead in on-chip networks) by allowing packets to bypass a bulk of the intermediate routers along their path irrespective of topology and can complement topologies which target lower hop counts such as high-radix [20] and butterﬂy [7] designs. Techniques targeting router delay: Techniques such as speculation [11], [12], bypassing [21], lookahead pipelines [9], [13], simpliﬁed VA [9] and lookahead routing [8] which improve router delay are already incorporated in both the baseline and token designs. While these techniques drive towards ultra-low router latency, they only succeed in bypassing the router pipeline at low loads, performing poorly when network contention is high. TFC, however, allows router bypassing at all trafﬁc loads. Adaptive routing: A recent work by Gratz et al. [16] proposes adaptive routing using global status information aggregated across multiple hops. While this work has similarities with TFC in its propagation of status information and use in adaptive routing, the key distinction is that [16] is solely a routing algorithm; it does not allow packets to bypass the router pipeline. In contrast, like other ﬂow control techniques, e.g., credit-based, TFC manages allocation of resources such as buffers, switch and link bandwidth. Speciﬁcally, router bypassing using tokens allows packets to skip buffering and get priority in winning the switch/link. TFC, in general, can work with any routing scheme. 7. Conclusion Communication overhead in state-of-the-art packet-switched on-chip networks is dominated by the energy/delay incurred in traversing complex router pipelines at every hop. In this work, we proposed TFC which allows packets to use tokens, which are indications of resource availability at neighboring routers, to ﬁnd routes along which intermediate nodes can be bypassed. The high ﬂexibility and seamless chaining of token routes enables packets to bypass all nodes between their source and destination in the best case. We presented a detailed implementation of TFC along with a detailed evaluation showing tokens providing signiﬁcant energy-delay-throughput gains over existing designs. Acknowledgments The authors would like to thank Partha Kundu of Intel Corp. for useful feedback and assistance with the simulation infrastructure. This work was supported in part by NSF (grant CCF-0702110), MARCO Gigascale Systems Research Center, MARCO Interconnect Focus Center, SRC (contract 2008HJ1793) and an Intel PhD Fellowship. "
2016,Cycle-Accurate Network on Chip Simulation with Noxim.,"The on-chip communication in current Chip-MultiProcessors (CMP) and MultiProcessor-SoC (MPSoC) is mainly based on the Network-on-Chip (NoC) design paradigm. Unfortunately, it is foreseen that conventional NoC architectures cannot sustain the performance, power, and reliability requirements demanded by the next generation of manycore architectures. Recently, emerging on-chip communication technologies, like wireless Networks-on-Chip (WiNoCs), have been proposed as candidate solutions for addressing the scalability limitations of conventional multi-hop NoC architectures. In a WiNoC, a subset of network nodes are equipped with a wireless interface which allows them long-range communication in a single hop. Assessing the performance and power figures of NoC and WiNoC architectures requires the availability of simulation tools that are often limited on modeling specific network configurations. This article presents Noxim, an open, configurable, extendible, cycle-accurate NoC simulator developed in SystemC, which allows to analyze the performance and power figures of both conventional wired NoC and emerging WiNoC architectures.",
2009,Godson-3 - A Scalable Multicore RISC Processor with x86 Emulation.,"The Godson-3 microprocessor aims at high-throughput server applications, high-performance scientific computing, and high-end embedded applications. It offers a scalable network on chip, hardware support for x86 emulation, and a reconfigurable architecture. The four-core Godson-3 chip is fabricated with 65-nm CMOS technology. Eight- and 16-core Godson-3 chips are in development.",
2005,A scalable test strategy for network-on-chip routers.,"Network-on-chip has recently emerged as alternative communication architecture for complex system chip and different aspects regarding NoC design have been studied in the literature. However, the test of the NoC itself for manufacturing faults has been marginally tackled. This paper proposes a scalable test strategy for the routers in a NoC, based on partial scan and on an IEEE 1500-compliant test wrapper. The proposed test strategy takes advantage of the regular design of the NoC to reduce both test area overhead and test time. Experimental results show that a good tradeoff of area overhead, fault coverage, test data volume, and test time is achieved by the proposed technique. Furthermore, the method can be applied for large NoC sizes and it does not depend on the network routing and control algorithms, which makes the method suitable to test a large class of network models",
2009,A case for dynamic frequency tuning in on-chip networks.,"Performance and power are the first order design metrics for network-on-chips (NoCs) that have become the de-facto standard in providing scalable communication backbones for multicores/CMPs. However, NoCs can be plagued by higher power consumption and degraded throughput if the network and router are not designed properly. Towards this end, this paper proposes a novel router architecture, where we tune the frequency of a router in response to network load to manage both performance and power. We propose three dynamic frequency tuning techniques, FreqBoost, FreqThrtl and FreqTune, targeted at congestion and power management in NoCs. As enablers for these techniques, we exploit Dynamic Voltage and Frequency Scaling (DVFS) and the imbalance in a generic router pipeline through time stealing. Experiments using synthetic workloads on a 8x8 wormhole-switched mesh interconnect show that FreqBoost is a better choice for reducing average latency (maximum 40%) while, FreqThrtl provides the maximum benefits in terms of power saving and energy delay product (EDP). The FreqTune scheme is a better candidate for optimizing both performance and power, achieving on an average 36% reduction in latency, 13% savings in power (up to 24% at high load), and 40% savings (up to 70% at high load) in EDP. With application benchmarks, we observe IPC improvement up to 23% using our design. The performance and power benefits also scale for larger NoCs.","A Case for Dynamic Frequency Tuning in On-Chip Networks Asit K. Mishra† Ravi Iyer§ Reetuparna Das† N. Vijaykrishnan† †Depar tment of Computer Science and Engineering The Pennsylvania State University University Park, PA-16801, USA Soumya Eachempati† Chita R. Das† § Integrated Platforms Lab Intel Corporation Hillsboro, OR 97124, USA {amishra,rdas,eachempa,vijay,das}@cse.psu.edu ravishankar.iyer@intel.com Abstract Performance and power are the ﬁrst order design metrics for Network-on-Chips (NoCs) that have become the de-facto standard in providing scalable communication backbones for multicores/CMPs. However, NoCs can be plagued by higher power consumption and degraded throughput if the network and router are not designed properly. Towards this end, this paper proposes a novel router architecture, where we tune the frequency of a router in response to network load to manage both performance and power. We propose three dynamic frequency tuning techniques, FreqBoost, FreqThrtl and FreqTune, targeted at congestion and power management in NoCs. As enablers for these techniques, we exploit Dynamic Voltage and Frequency Scaling (DVFS) and the imbalance in a generic router pipeline through time stealing. Experiments using synthetic workloads on a 8x8 wormhole-switched mesh interconnect show that FreqBoost is a better choice for reducing average latency (maximum 40%) while, FreqThrtl provides the maximum beneﬁts in terms of power saving and energy delay product (EDP). The FreqTune scheme is a better candidate for optimizing both performance and power, achieving on an average 36% reduction in latency, 13% savings in power (up to 24% at high load), and 40% savings (up to 70% at high load) in EDP. With application benchmarks, we observe IPC improvement up to 23% using our design. The performance and power beneﬁts also scale for larger NoCs. Categories and Subject Descriptors C.1.2 [Multiprocessors]: Interconnection architectures. C.1.4 [Parallel Architectures]: Distributed architectures. General Terms Design, Experimentation, Performance. 1. INTRODUCTION On-chip interconnects or Network-on-Chip (NoC) architectures have become an important research focus in recent years for designing multicores/Chip Multi-Processors (CMPs) and System-on-Chip (SoC) architectures that can scale to hundreds of cores in the future. This is because an on-chip network plays a critical role in determining the performance and power behavior of a multicore/SoC architecture. While the performance implications of the underlying communication architecture is well understood in designing multiproPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. MICRO’09, December 12–16, 2009, New York, NY, USA. Copyright 2009 ACM 978-1-60558-798-1/09/12 ...$10.00. cessors over the years, power consumption has become a ﬁrst order design metric speciﬁcally in the nanometer regime. It is predicted that NoC power can be a signiﬁcant part of the entire chip power and can account for up to 40 to 60 watts [3] with technology scaling for a mesh based network with 128 nodes. A few commercial designs also support this trend, where up to 28% of the entire chip power is devoted to the interconnect [11]. Thus, on-chip interconnects that can optimize both performance and power pose intriguing research challenges. This is evident from the large body of literature covering multiple facets of NoC design [16, 13, 25, 8, 22, 28]. Router frequency is one of the critical design parameter that directly aﬀects both performance and power, albeit in a contradictory fashion. With a sophisticated design of a router pipeline, it is possible to increase the operating frequency [18, 23], but higher router frequency leads to higher power consumption. On the other hand, a mismatch between processor and router/network frequency can result in significant performance penalties [6]. Thus, a prudent control of the router frequency can help in optimizing both performance and power. We motivate the ﬁne balance that exists between power and performance in an on-chip network with a relative powerperformance trade-oﬀ analysis with respect to oﬀered network load. Figure 1 shows the relative growth of network power versus network latency for an 8x8 mesh with a synthetic traﬃc mixture of Uniform Random, Transpose, NearestNeighbor and Self Similar traﬃc (detail network conﬁguration is mentioned later in Table 3(a)). The bars indicate network latency/power normalized with respect to the network latency/ power at no load (idle network). At low load, the network power consumption is less. However, the rate of growth of network power is much higher as compared to the rate of growth of network latency. For example, as shown in Figure 1, the network power grows to 30x as the injection rate varies from 1% to 40%, whereas the network latency grows only 7x. We leverage our insights from these trends to optimize the network at low load for performance and at high load for power. An activity based power-management technique, which was recently implemented in the Intel 80core routers [11, 33], shares a similar view of optimizing the network power based on activity, albeit in a diﬀerent fashion by clock-gating the idle ports. Since performance and power are directly proportional to frequency, we dynamically modulate the router frequency in response to network load to facilitate these optimizations, and demonstrate the advantages at system level. Speciﬁcally, at low load we operate the routers at peak frequency. At high load, we dynamically determine the operating frequency of individual routers in the network. The dynamic schemes that determine the operating frequencies of the routers are designed to a) reduce power consumption and b) manage 292 Normalized Power Normilized Latency e s a e r c n I r e w o P f o o i t a R 35 30 25 20 15 10 5 0 e s a e r c n I y c n e t a L f o o i t a R 7 6 5 4 3 2 1 0 0.01 0.04 0.08 0.16 0.24 0.28 0.32 0.34 0.36 0.38 0.39 0.4 Injection Ratio (flits/node/cycle) Figure 1: Average network latency and power behavior of an 8x8 mesh network. congestion in the network, by selectively stepping up and down the frequency of a subset of routers in the congested regions of a network. We propose a two-prong approach to vary the baseline router frequency: clock scaling and timestealing. We employ Dynamic Voltage and Frequency Scaling (DVFS) [29, 35] to scale up and down the router clock frequency below the nominal frequency by switching the operating voltage levels. The time stealing technique is employed to boost the baseline router frequency by exploiting the timing imbalance between router pipeline stages, such that a router can operate at the average cycle time of all the pipeline stages in contrast to the delay of the worst case pipeline stage. We explore three techniques for dynamic frequency tuning to simultaneously address power-performance trade-oﬀs. The ﬁrst technique, called FreqBoost, initially employs timestealing to operate all routers at a boosted frequency. This helps in enhancing the performance at low load conditions, while slightly increasing the power consumption. However, as the network gets congested, power consumption becomes a key challenge. Hence, it throttles the frequency/voltage of selected routers using DVFS. The second mechanism, called FreqThrtl, initially operates all routers at the baseline frequency and selectively employs time-stealing and DVFS to either increase or decrease the frequency at the onset of congestion. This scheme, unlike FreqBoost, can modulate frequency of routers bi-directionally (higher or lower) and consequently can help reduce power and manage congestion at high load more eﬀectively. Using this technique, the frequency of a congested router is boosted at the onset of congestion and the frequency of a router adjacent to this congested router is throttled. FreqTune is a hybrid of the above two schemes that dynamically switches between FreqBoost and FreqThrtl as the network load varies from low to high. We evaluate the performance and power implications of the proposed techniques using a wormhole-switched mesh interconnect with synthetic and application benchmarks and compare them with respect to a baseline router/network. To further emphasize the eﬃcacy of our approach, we compare our results with adaptive routing and with a baseline design that employs time-stealing but no congestion management. The primary contributions of this paper are the following: • We propose novel frequency tuning algorithms to reduce latency and power consumption in NoC by distributed throttling and boosting of router frequencies depending upon network load. To the best of our knowledge, this is the ﬁrst work to propose a distributed congestion management scheme that is based on operating individual routers at different frequency levels. Our proposal leads to 36% reduction in latency at high load, 13.5% savings in power (up to 24% at high load) and average 40.5% reduction in energy delay product (EDP) (maximum 70% at high load). With application benchmarks, we achieve IPC improvements up to 23.1% using our schemes. Moreover, the power-performance beneﬁts increase when these techniques are applied to large networks. No Change In  Frequency B CONGESTED HIGH Flit Empty Buffer  Slot A CONGESTED HIGH W N D CONGESTED HIGH E S E CONGESTED HIGH Throttles C Throttles (a) B CONGESTED LOW A W N D S E CONGESTED LOW C BACK TO  NORMAL  FREQUENCY (b) E Throttles Figure 2: An example showing actions taken by a congested router. • Our analysis corroborates the pipeline stage imbalance found in other routers proposed in [18, 6, 23]. While this imbalance can be removed using power optimizations such as variable voltage (supply/threshold) and gate sizing optimizations, we focus on time-stealing techniques to boost performance. Time-stealing in NoC routers can lead to 25% reduction in zero load latency. In addition, we use the well-known DVFS technique at the granularity of an individual router to tune the router frequency and power based on its load. We believe, this is the ﬁrst paper to apply time-stealing and DVFS techniques for performance and power management in on-chip routers. • We demonstrate that the proposed techniques are not only much more eﬀective in delivering better performance and reducing power consumption compared to the monolithic, single frequency design, but also can outperform other pure performance enhancement techniques such as using adaptive routing and simply increasing the operating frequency without any congestion management. Moreover, we also show how coarse-grain frequency tuning can help in reducing the overheads involved in these techniques. All these results make a strong case for implementing variable frequency routers in on-chip interconnects. The rest of this paper is organized as follows: the three performance and power management techniques are presented in section 2. In section 3, we elaborate on clock scaling and time stealing techniques for deploying these schemes, and the required hardware support. Section 4 discusses the experimental platform and results. Prior work is discussed in section 5, followed by the concluding remarks in section 6. 2. FREQUENCY TUNING RATIONALE We use a congestion metric (buﬀer utilization) per port in a router to decide whether this port of the router is likely to get congested in the next few cycles, and if so, it signals the upstream router to throttle. The intuition behind such an approach comes from the fact that if a router is getting congested, it is due to the pressure from its neighboring routers. The congested router is unable to arbitrate and push out its ﬂits fast enough compared to the rate of ﬂit injection into its buﬀers. To handle this mismatch and reduce the contention in the congested router, we throttle the upstream router by lowering its frequency. This decrease in frequency of the upstream router leads to a lower rate of arrival of the ﬂits into the congested router, giving the congested router some leverage to push out its ﬂits, and hence, reduce the overall blocking latency in the network. To better understand our proposed techniques, we present an example using Figure 2. Figure 2(a) shows the central (D) router’s North (N),South (S) and East (E) port buﬀers are at the onset of congestion. Thus, router D signals congested port’s corresponding upstream routers B,C and E to throt293             Table 1: (a) Settings for F reqB oost and F reqT hrtl (b) T hresholdthrottled Settings for FreqBoost, FreqThrtl and FreqTune. The table shows throttling frequency that a neighboring router uses based on its buﬀer utilization(BU) after receiving a congested high signal. Fbase 2.20 GHz Fboost 2.75 GHz T hresholdcongestion T hresholdlow 0.60 0.40 (a) BU > 0.60 0.50 < BU < 0.60 F reqBoost F reqT hrtl F reqT une Fboost Fbase Fboost 0.9*Fboost 0.9*Fbase 0.85*Fboost (b) 0.40 < BU < 0.50 BU < 0.40 0.85*Fboost 0.8*Fboost 0.85Fbase 0.8*Fbase 0.8*Fboost Fbase tle. Due to similar reasons, router B’s East port signals its upstream router to throttle. The upstream routers in turn, depending on their own congestion status, decide whether to throttle themselves or operate at the normal frequency. In the example shown, router B does not throttle itself since it is at the verge of congestion, while routers C and E throttle themselves. A few cycles later, when buﬀer availability in East and South ports of router D increases, it signals the throttled routers to boost their frequency back to the normal level. This is shown in Figure 2(b). Based on these premises, we design three techniques, FreqBoost, FreqThrtl and FreqTune. 2.1 FreqBoost Technique In the FreqBoost technique, we operate the network at a higher frequency, Fboost (2.75 GHz), compared to the nominal operating frequency, Fbase (2.2GHz), right from the beginning using time-stealing technique and apply DVFS to throttle a router for congestion management. This technique and all other techniques proposed later in this paper use two thresholds, T hresholdcongestion and T hresholdlow (shown in Table 1(a)), for triggering the proposed schemes. T hresholdcongestion is used to decide pro-actively whether a particular port is likely to get congested in the next few cycles. Upon detection of such an onset of congestion, this port signals a congested high to the upstream router. We assume that it takes one cycle for this signal to reach the upstream router similar to the credit-ﬂow information. Upon receipt of the congested high signal, the upstream router compares its overal l buﬀer utilization with the T hresholdthrottled settings, shown in Table 1(b), and depending on its overall buﬀer utilization, the upstream router decides its operating frequency. Table 1(b) shows the diﬀerent frequency settings for each level of buﬀer utilization in the router. If the total buﬀer utilization in the router that received the congested high signal is high, then it will not throttle itself by a big margin, whereas, if the buﬀer utilization is low, then it would throttle itself aggressively. The reason behind using overall buﬀer utilization as a metric in choosing the throttled frequency settings and not a port’s buﬀer utilization, is to handle asymmetric traﬃc, where buﬀers across some ports are heavily utilized compared to other ports. This scenario arises in X-Y routing, where buﬀers in the X-direction are heavily utilized compared to buﬀers in the Y-direction. The T hresholdthrottled settings ensure that the buﬀer utilization of a router to be throttled is not close to the congestion threshold, and thereby, the slowed-down router can sustain throttling, without itself getting congested. When a congested router’s buﬀer utilization goes below T hresholdlow , it signals congested low to its upstream router. After receiving a congested low signal, the throttled router increases its frequency back to Fboost . 2.2 FreqThrtl Technique With F reqT hrtl, we increase the frequency of a congested router to Fboost only at the onset of congestion and throttle the upstream router to manage congestion, otherwise the base frequency,Fbase (2.2GHz), is not enhanced during normal operation. Increasing the frequency of the congested router helps in servicing the ﬂits faster through higher rate of arbitration and ﬂit traversal. Additionally, slowing down upstream routers helps to reduce the pressure of injections and helps to ease out the traﬃc in the congested router. Note that, we do not change the routing algorithm during congestion, thus, the algorithm does not have to deal with any deadlock situations. Also, monitoring the buﬀer utilization per port and throttling the corresponding upstream router helps us to manage congestion across traﬃc ﬂows, i.e. at the onset of congestion in a router, the scheme selectively throttles only those neighboring routers which can lead to congestion in the current router. Additionally, our schemes work on top of the credit-based ﬂow control. With the creditbased ﬂow control, a ﬂit’s traversal into the downstream router would pause when there are no available credits. However, with our approach, we pro-actively detect whether the downstream router port is likely to get congested (before all buﬀer slots get ﬁlled up) and slow down the rate of injection into this downstream router, making it diﬀerent from the credit-based approach, where ﬂit traversal is paused till credit availability. This approach leads to reduction in blocking and queuing latency per ﬂit since each ﬂit now sees reduced contention upon arrival at each input port. Figure 3 shows the load-latency and power consumption/ savings in an 8x8 network for Uniform Random (UR) trafﬁc. BaseC ase, in the ﬁgures depicts a network, where no time-stealing or DVFS techniques are applied. For comparison purposes, we have also plotted latency curves with a minimally-adaptive routing algorithm (shown as Adaptive in the ﬁgure) and a case where time-stealing alone (no DVFS) is employed on top of the base case to boost the performance of the network (shown as BaseC ase + T S ). As can be seen, F reqB oost and F reqT hrtl increase the throughput of the network at higher injection rates when BaseC ase starts saturating. F reqB oost always gives the best performance compared to all of the schemes. With F reqB oost, we operate the network at a 25% higher frequency due to time-stealing, and hence, consumes 25% more power at lowinjection rates. However, at low injection rates, absolute power consumption in the network is low (less than 7W till 12% injection rate) and F reqB oost does not, therefore, increase the absolute power envelope signiﬁcantly. At higher injection rates, F reqB oost starts throttling routers to manage congestion and thus, power consumption in the network decreases. The power curves for FreqBoost lie in between BaseC ase+T S and BaseC ase. Comparison of performance and power curves for BaseC ase+T S and F reqB oost shows that simply increasing the frequency of a router does not lead to signiﬁcant performance beneﬁts. Since F reqB oost employs intelligent throttling of routers along with frequency boosting, the performance diﬀerence between F reqB oost and BaseC ase+T S can solely be attributed to our congestion management scheme, where we tune the frequency of individual routers depending on load conditions. With F reqT hrtl, we always save power (Figure 3(b)), which 294 BaseCase Adaptive FreqThrtl FreqBoost BaseCase+TS ) s d n o c e s o n a N n i ( y c n e t a L 40 30 20 10 0 BaseCase Adaptive FreqBoost FreqThrtl BaseCase+TS ) s t t a W n i ( n o i t p m u s n o C r e w o P 40 35 30 25 20 15 10 5 0 s g n v a i S e g a t n e c r e P 40 30 20 10 0 -10 -20 -30 FreqThrtl FreqBoost BaseCase+TS 0 0.1 0.2 0.3 Injection Ratio (flits/node/cyle) 0.4 0 0.05 0.1 0.15 0.2 0.25 Injection Ratio(flits/node/cycle) 0.3 0.35 0.01 0.04 0.08 0.12 0.16 0.2 0.24 0.28 0.32 Injection Ratio(flits/node/cycle) (a) Load-Latency Graph (b) Power Consumption (c) Savings in Power w.r.t. BaseCase 3.1 Frequency Scaling Figure 3: Performance and network power analysis of F reqB oost and F reqT hrtl with UR traﬃc. comes mostly when few routers under high network load opniques, their hardware implementation and the corresponderate at lower than nominal voltage and frequency. However, ing overheads. when compared with F reqB oost, F reqT hrtl saturates earlier. Therefore, while F reqB oost helps in performance enhancement and consumes more power, F reqT hrtl helps in reducing power consumption while providing smaller performance enhancement margins. Since F reqT hrtl at low load behaves similar to BaseC ase until congestion thresholds are reached, initial power savings with F reqT hrtl are negligible until the load increases to about 4% injection rate. On an average, we ﬁnd about 4.5-5.5 nanoseconds (10-12 cycles) reduction in zero and light load latency and about 40% increase in the throughput of the network with F reqB oost. With F reqT hrtl, there is about 12% increase in network throughput. Average power saving with F reqT hrtl is 23%, while F reqB oost consumes on an average 14% more power compared with BaseC ase. Figure 3(c) depicts that simply boosting the network frequency by 25% (BaseC ase+T S ) leads to a consistent 25% more power consumption. The ﬁgures also show that both F reqB oost and F reqT hrtl outperform adaptive routing in average latency and F reqT hrtl provides much better power savings due to congestion management in the network. Our simulations show a similar power and performance trend with other non-uniform traﬃc patterns as well. Hence, in subsequent sections, we do not present any evaluation results comparing adaptive routing to our techniques to preserve clarity. Our approach extends the concept of per-core on-chip DVFS [17] to per-router DVFS in NoCs for congestion and power management. In order to minimize the overhead of supporting multiple power domains in the network, we also experiment with one regulator being shared among a group of routers. We adopt the two-step voltage regulator conﬁguration as proposed by Kim et al. [17]. An oﬀ-chip regulator performs the initial step down from the Li-ion battery (3.7V) to 1.8V followed by multiple on-chip voltage regulators, where each of them steps down voltage from 1.8V to 1V. The 2-level approach amortizes the degradation in conversion eﬃciency of employing only oﬀ-chip regulators. A multi-phase buck converter that can provide three voltage and frequency levels and a programmable voltage controlled ring oscillator [10] are used. The programmable ring oscillator is required for diﬀerent frequencies at the same voltage to support the timestealing technique described next. The on-chip regulators operate at 125MHz switching frequency and provide voltage transitions between 1V to 0.8V. The routers can operate at the lower frequency during frequency step-down by speedily ramping down the frequency before the voltage steps down. For stepping-up the frequency using DVFS, we ﬁrst step-up the voltage before ramping up the router frequency. Thus, the overhead in every transition is primarily the voltage settling time which is 13ns for every 100mV change [17]. Hence, due to higher than required voltage during step-down (and lower frequency during step-up), the power consumed by the router during a transition lies between the values before and after the scaling. All our evaluations take this overhead into account. The power consumption (at activity factor of 0.5) for our regulator with conversion eﬃciencies similar to that in [17] is given in Table 2(a). The area overhead in an 8x8 mesh for 64 on-chip regulators is 4mm2 which is about 25% of the area. The average power overhead is around 8% (at 1V) of all routers in the network. This is based on our router area of 0.245 mm2 and power of 0.35W at 65nm node based on our synthesized design (see Section 3.3.2). This area and power overhead reduces by 4x when we use per-column regulators (described later in Section 4.3). 2.3 FreqTune Technique Leveraging our insights from the above results, we propose an adaptive technique that utilizes F reqB oost and F reqT hrtl. It uses F reqB oost at low load for performance enhancement and switches to F reqT hrtl at high load to save power and manage congestion. The EDP results shown in later sections reinforce this choice. We call this hybrid technique F reqT une, since using this technique, the network dynamically tunes to the traﬃc conditions. With FreqTune, each router selects its operating mode using information from its neighbors. This leads to distributed throttling of routers in the network with a mix of schemes, wherein some regions operate in the nominal frequency mode, some in FreqBoost mode and others operate in FreqThrtl mode. Thus, with F reqT une, a router transitions from using high-frequency, Fboost , at low load to using nominal frequency, Fbase , at medium load and again to high frequency at high load if it gets congested. This distributed dynamic frequency transition, based on network load, manages congestion as well as saves power in the network. 3. ROUTER AND NETWORK ARCHITECTURE In this section, we discuss the enablers for our proposed techniques: on-chip DVFS in routers and time-stealing. We then describe the architectural modiﬁcations to the router design for supporting frequency scaling and time stealing tech3.2 Time Stealing in Router Pipeline A generic on-chip router pipeline stage delays are quite imbalanced unlike the processor pipeline [6, 26, 24]. In order to boost the router frequency from the nominal frequency, we apply time stealing techniques, where a slower stage in the router gains evaluation time by stealing it from successive or previous router pipeline stages. In order to steal slack from a previous pipeline stage, an early clock signal needs to be available and this may be limited by the earliest time a clock signal can be obtained from the clocking system. A cycle may steal time from subsequent stages by delaying the triggering 295             RC 290ps 454ps VA 454ps SA 440ps 363ps ST 326ps LT 309ps (a) Base case router pipeline Frequency  = 1/454ps  = 2.20GHZ Frequency  = 1/363ps  = 2.75GHZ Latch delay L 2 RC VA1 SA1 L 1 RC VA2 SA2 L 2 ST L 1 ST L 2 LT L 1 LT L 2 Cycle time Phase 1 Phase 2 C1 C2 Original  C1 C1 C2 RC 290ps VA 454ps SA 440ps SA 326ps LT 309ps Resulting Stage 1 Clock domain Resulting ST Clock  domain Resulting LT Clock  domain Original falling edges Delayed falling edges Time stolen from ST (> what  ST can give) ST steals time from  LT (b) Time stealing in router pipeline (c) Time stealing with a 2-phase clocked pipeline 91ps 54ps 46ps 27ps Output voltage 1V 0.9V 0.85V 0.8V Power overhead 52.3mW 41.5mW 37.9mW 34.1mW (a) Skew Stage @ Freq VA @ 2.75GHz ST @ 2.75GHz VA @ 2.47GHz VA @ 2.34GHz Skew Inverter Size 4.75 2.41 1.9 2.41 Figure 4: Time stealing in a generic router pipeline with a 2-phase clock. edge of the clock to all the subsequent latches. We use the Table 2: (a) On chip regulator power consumption later method for our router design. and (b) Inverter sizes for introducing clock skew. Our baseline router is a 2-stage speculative router in which the ﬁrst stage performs the routing computation (RC), the virtual channel allocation (VA) and the switch allocation (SA) in parallel and the second stage is the switch transfer (ST) as shown in the Figure 4(a). The link traversal (LT) stage takes an additional cycle. The router stage delays (shown in Figure 4(a)) are obtained after synthesis using the Synopsys Design Compiler, and the LT stage delay is obtained using wire models from PTM [1]. A nonoverlapping symmetric two-phase clock is used for boosting the router frequency (shown as C1 and C2 in 4(c)). In our 2-stage router, since the VA stage (454ps) is the bottleneck, it steals time from the ST stage. Since the time required by the VA stage is greater than the slack available in the ST stage, ST stage will need to steal time from LT as shown in Figure 4(b). Consequently, we delay the active clock edge of C1 and C2 for both ﬁrst and second stages (shown in Figure 4(c)). Let the new enhanced clock time after time ). The active clock edge for the VA stage is delayed by S1 = TV A − Tc . This is the extra time that is required by VA (stolen from ST and LT put together). The slack time ST can provide is S2 = Tc − TST . The remaining time of S1 − S2 is stolen from the LT stage by the ST stage. Thus, the clock edge to the ST stage is delayed Figure 5: Impact of #VCs on time-stealing. stealing be Tc (= TV A+TST +TLT -15% BaseCase +15% Sensitivity To Arbitration Delay 45 40 35 30 25 20 15 10 5 0 t n e m e v o y c n e u q e r F (b) +25% r p m I % l e c y C n i VC=3 VC=4 -25% VC=2 VC=5 VC=6 3 by TV A + TST − 2 ∗ Tc . The extra time required to delay the falling edge is introduced using tunable delay buﬀers comprising of inverter chains [32]. We assume a hierarchical network consisting of an H-tree at the top level and local mesh grids at the lower level for distributing the clock on the chip similar to the Itanium [31] clock-distribution design. A local grid typically constitutes about 1250 ﬂip-ﬂops [9], which is about the size of a single stage of our router. Thus, the clock signal to the router stages are supplied by the distinct local clock grids. Hence, accommodating for time stealing technique will involve introducing the extra delay buﬀer for the clock grid supplying a router stage. Assuming a two-stage inverter chain for the buﬀer, the size of the second inverter required for introducing the clock skew in the clock distribution network is shown in Table 2(b). For a delay of 27ps, a single inverter sized to 2.4 times the minimum sized inverter is suﬃcient. These values were obtained from HSPICE simulations at 65nm, and we ﬁnd that the power and the area overheads for introducing these extra buﬀers are minimal. To study the eﬀectiveness of the time-stealing approach across more diverse VA stage designs and implementation choices, the frequency improvement was evaluated by varying the VA stage delay by ±25% from our design. Further, the number of virtual channels (VCs) is also varied to analyze the percentage beneﬁts with time-stealing due to variation in both VA stage latency as well the number of VCs. Such delay variations are done to mimic changes due to diﬀerent arbiter designs or circuit optimizations. Figure 5 shows the percentage improvement in cycle frequency using time-stealing technique as the number of VCs vary and as the cycle-time of the VA stage varies from the BaseCase design. There is a 25% frequency improvement using time stealing over the base router frequency (2.2 GHz at 1V and 4VCs). If the delay of the VA stage is reduced by 25%, it no longer becomes the bottleneck stage in the router and the ST stage becomes the delay dominant stage. Under such scenarios, the ST stage steals time from the LT stage. On an average, there is 32% improvement in cycle-time across ±25% variations in VA stage time as the number of VCs change. 3.3 Architectural Support for Frequency Adaptation and Hardware Implementation 3.3.1 Asynchronous Communication In order for the network routers to operate at diﬀerent frequencies, they should be able to communicate asynchronously with each other. The router control logic, switching logic and arbitration logic remain unaﬀected. This architecture essentially mimics a Globally Asynchronous Locally Synchronous (GALS) design within the network. To support the communication between routers operating at diﬀerent frequencies, we utilize the dual clock I/O buﬀer design from [12] for our router buﬀers. In this design, the buﬀers use independent read and write clock signals along with control to prevent synchronization problems when read and write pointers approach each other. In our design, the write clock of a buﬀer is controlled by the clock of the feeding upstream router and the 296         read clock is from the current router. When two neighboring routers operate at the same frequency and the read and the write pointers are in separate locations in the buﬀer, the read and write operations are independent. Two operational situations that could cause problems are when the two address pointers approach each other in the buﬀer. These situations correspond to buﬀer emptying and buﬀer full. Prevention of synchronization problems is handled separately for each of these cases without introducing any delay penalty using additional circuitry as proposed in [12]. Note that, with our proposed distributed frequency tuning schemes, the entire network does not become asynchronous, only neighboring routers that are operating at diﬀerent frequencies communicate asynchronously. The feasibility of such asynchronous clocking styles has been demonstrated recently. For example, the 80-core prototype chip from Intel [33] uses mesochronous clocking, where there is no control over the clock phase reaching a particular module and data signal is transmitted along with a strobe signal, which is translated by the receiver as an incoming clock. Our proposed distributed frequency tuning techniques would beneﬁt with these kinds of clocking styles for on-chip networks. 3.3.2 Hardware Implementation All of our proposed techniques require only buﬀer utilization (BU) as the input. This information is already gathered in conventional on-chip networks for the credit-based ﬂow control. Buﬀer utilization is a good indicator of network congestion since it is sensitive to network traﬃc and adapts well to the changes in traﬃc pattern. Also, to ﬁlter out short-term ﬂuctuations in the network traﬃc and adapt our techniques to handle long-term traﬃc characteristics, we use exponential weighted average utilization of buﬀers by combining the current buﬀer utilization with past buﬀer utilization to decide the operating points. The threshold values for triggering the techniques are stored in registers and the comparison operations can be implemented using simple combinational logic. For signaling congestion status to neighbors, we use a 1-bit line that does not add any signiﬁcant overhead to the already existing backwiring for credit-ﬂow information. All the overheads for voltage and frequency management discussed in Section 3.1 are included in our evaluations. In addition, the overheads for implementing the buﬀer utilization tracking and control signal generation are obtained through synthesis using the Synopsys Design Compiler. This shows an additional 550 logic gates per router port with a negligible 6 mW power consumption increase in the router. None of these logic gates lie in the critical path of the router pipeline, and hence, the router frequency is not aﬀected. 4. PERFORMANCE EVALUATION 4.1 Experimental Platform We use a 64-node network as our experimental platform with the network laid out as a 8x8 2D-mesh. We also vary the network size from 8x8 to 16x32 for conducting scalability analysis. We use a cycle-accurate NoC simulator for our simulations and model a state-of-the art two stage router pipeline based on [26]. The base case router has 5 physical channels (PCs) including the local PE-to-router port and 4 virtual channels (VCs) multiplexed on to each PC. A message (packet) consists of six 128-bit ﬂits and we use a buﬀer depth of 4 ﬂits per VC. We simulate a wormhole-switched network with the deterministic X-Y routing and credit-based ﬂow control. The router along with the proposed modiﬁcations, described in Section 3, was implemented in structural RTL Verilog and synthesized using Synopsys Design Compiler using TSMC 90 nm cell library and then scaled down the parameters to 65 nm based on rules given in [4]. The resulting design operates at a clock voltage of 1V and 2.20 GHz (2.75 GHz using time-stealing). The dynamic and leakage power numbers were extracted using Orion [34] and incorporated in our simulator for detailed power analysis of the network. The network is initially warmed up with 1000 packets and the statistics are collected for 100,000 packets. We measure average ﬂit latency, average power consumption and energy delay product (EDP) across various injection rates for synthetic traﬃc. The injection rates are with respect to the base frequency and are unbiased to frequency scaling. For synthetic workload, we use Uniform Random (UR), Transpose (TP), Bit-Compliment (BC), Nearest Neighbor (NN) and Self-similar (SS) traﬃc patterns. For application workloads, we use four commercial workloads and six benchmarks from the PARSEC suite [2] and measure reduction in latency, power savings and IPC improvements when our techniques are applied. 4.2 Results with Synthetic Workload We compare the latency and power consumption characteristics of the three techniques with the ﬁve synthetic trafﬁc patterns. BaseC ase in our discussion corresponds to the standard design without any frequency tuning and congestion management. Base C ase+T S represents the case, where time-stealing is used on top of BaseC ase to boost the frequency of the network, but no congestion management techniques are used. Figures 6(a)-(e) show the loadlatency curves with diﬀerent traﬃc patterns. We measure the saturation bandwidth when the average latency per ﬂit is three times the zero-load latency [8]. All three of our proposed techniques outperform the BaseCase as well as the BaseCase+TS network, and as expected, FreqTune’s performance envelope lies between F reqT hrtl and F reqB oost. At low load, F reqT une’s performance is similar to that of F reqB oost, and at high load, F reqT une’s performance gets close to F reqT hrtl. On an average, we ﬁnd 24% (up to 31%) increase in throughput using F reqT une when compared to the BaseC ase, and up to 21% increase in throughput when compared to the BaseC ase+T S . For NN traﬃc in Figure 6(d), the reduction in latency is mostly due to the frequency boosting technique. The congestion management techniques do not play a signiﬁcant part in latency reduction because of the very nature of the NN traﬃc, where a particular node sends packets only to its neighboring nodes. Therefore, throttling a neighbor node actually hurts latency since the throttled node will eject ﬂits to the local PE at a reduced rate. As the network load increases leading to an onset of congestion, FreqTune switches to the FreqThrtl mode, where the frequency of a congested router is boosted and the neighboring routers are throttled. The congested router can thus service its ﬂits at a faster rate compared to the rate at which it is receiving ﬂits from neighbors. At high injection rates, while some of the routers are congested, some routers are still un-congested. Thus, using F reqT une, the congested regions use F reqB oost and the un-congested regions use F reqT hrtl. Figure 6(f ) shows a contour plot of a snapshot with UR traﬃc depicting relative operating frequencies of the routers compared to BaseC ase at high load (0.36 injection rate). The 297 0 10 20 30 40 0 0.1 0.2 0.3 Injection Ratio(flits/node/cycle) 0.4 a L t y c n e ( i n N s d n o c e s o n a ) BaseCase FreqThrtl FreqBoost FreqTune BaseCase+TS 0 10 20 30 40 0 0.05 0.1 0.15 0.2 Injection Ratio(flits/node/cycle) 0.25 a L t y c n e ( i n N s d n o c e s o n a ) BaseCase FreqThrtl FreqBoost FreqTune BaseCase+TS 0 10 20 30 40 0 0.1 0.2 0.3 Injection Ratio(flits/node/cycle) 0.4 a L t y c n e ( i n N s d n o c e s o n a ) BaseCase FreqThrtl FreqBoost FreqTune BaseCase+TS (a) Uniform Random (b) Transpose Traﬃc (c) Bit-Complement Traﬃc 0 2 4 6 8 10 0 0.1 0.2 0.3 Injection Ratio(flits/node/cycle) 0.4 a L t y c n e ( i n N s d n o c e s o n a ) BaseCase FreqThrtl FreqBoost FreqTune BaseCase+TS 0 10 20 30 40 0 0.1 0.2 0.3 0.4 Injection Ratio(flits/node/cycle) 0.5 a L t y c n e i ( n N o n a s c e d n o ) s BaseCase FreqThrtl FreqBoost FreqTune BaseCase+TS                         -30 -10 10 30 50 70 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 0 . 2 0 . 4 2 0 . 8 2 0 . 2 3 P e r n e c t e g a Injection Ratio (flits/node/cycle) Injection Ratio (flits/node/cycle) FreqThrtl Power FreqTune Power FreqThrtl EDP FreqTune EDP FreqBoost Power Overhead FreqBoost EDP (a) Uniform Random Traﬃc -30 -15 0 15 30 45 60 75 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 e P r n e c t e g a Injection Ratio (flits/node/cycle) Power Overhead EDP -30 -15 0 15 30 45 60 75 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 0 . 2 0 . 4 2 0 . 8 2 0 . 2 3 0 . 6 3 0 . 4 e P r n e c t e g a Injection Ratio(flits/node/cycle) Power Overhead EDP (b) Transpose Traﬃc (c) Bit-Complement Traﬃc -30 -15 0 15 30 45 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 0 . 2 0 . 4 2 0 . 8 2 0 . 2 3 0 . 6 3 0 . 4 0 . 4 4 e P r n e c t e g a Injection Ratio(flits/node/cycle) Power Overhead EDP -30 -15 0 15 30 45 60 75 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 0 . 2 0 . 4 2 0 . 8 2 0 . 2 3 0 . 6 3 e P r n e c t e g a Injection Ratio(flits/node/cycle) Power Overhead EDP (d) Nearest-Neighbor Traﬃc (e) Self-Similar Traﬃc Figure 8: Power and EDP reduction with synthetic traﬃc for FreqTune and controller power overheads. 0 10 20 30 40 50 0 0.1 0.2 Injection Ratio 0.3 0.4 a L t y c n e i ( o n a n n s c e d n o ) s BaseCase FreqThrtl FreqBoost FreqTune 0 10 20 30 40 50 0 0.1 0.2 0.3 Injection Ratio(flits/node/cycle) 0.4 a L t y c n e i ( n N o n a s c e d n o ) s BaseCase FreqTune-Columnwise FreqTune-perRouter -30 -15 0 15 30 45 0 . 1 0 0 . 4 0 0 . 8 0 0 . 2 1 0 . 6 1 0 . 2 0 . 4 2 0 . 8 2 0 . 2 3 P e r n e c t e g a Injection Ratio Power Overhead EDP (a)UR Performance with Column-wise Freqtune (b) Comparison of per-router DVFS vs Column-wise DVFS (c) UR Power with Column-wise FreqTune Figure 9: UR traﬃc performance using Column-wise controllers. patterns, we ﬁnd the average power savings in the network to not aﬀected as much because of using high-frequency routers be 13.5% (up to 24% at high load) with F reqT une compared and thus, F reqT une’s latency curve is still better than the to the BaseC ase. Average reduction in EDP using FreqTune BaseC ase. Figure 9(b) shows how latency of F reqT une is 40.5% (up to 70% at high load). Overall, F reqT une is is aﬀected when using column-wise controllers compared to able to satisfy the two requirements we discussed earlier F reqT une with per-router controller. Figure 9(c) shows the reduce latency at low load and conserve power at high load. percentage reduction in power and EDP with F reqT une usHowever, depending on the speciﬁc requirements of a sysing column-wise controllers over the BaseC ase. With columntem, a designer can choose to implement any of the other wise controllers, there is on an average 12% reduction in latwo techniques if only performance enhancement or power tency, 13% savings in network power and 27% reduction in conservation is a concern. EDP with FreqTune. Hence, although congestion management with column-wise controllers now happens at a much coarser granularity, we still save in power and EDP without sacriﬁcing performance. 4.3 Results with Column-wise Controllers To further reduce the area and power overheads in having a per-router DVFS controller, we investigate the performance and power behavior by reducing number of DVFS controllers. We chose a column-wise scheme since our evaluations show that such a scheme is quite agnostic toward many routing algorithms (e.g. adaptive, X-Y,Y-X routing). A network designer can choose many other schemes, e.g. having one controller for the routers in the center of a mesh network that have similar utilization with X-Y traﬃc (as is evident from the contour plot in Figure 6(f )) or have one controller for routers around a hot-spot region (e.g. around a memory controller), etc. In this work, we reduce the number of controllers from one per router to one controller per half-column, i.e. we divide a column in the network into two halves and assign a controller to each half. A controller in a particular half now modulates the frequency of all the routers in half of the column. This reduces the performance gains compared to the ﬁne-grained frequency modulation. We experiment with the 8x8 mesh with 16 controllers (2 controller per column), reducing the area and power overheads by 4x compared to the per-router schemes. Figure 9(a) shows that F reqT hrtl performs worse than the BaseCase with column-wise controllers. This is because of the coarser granularity of frequency adjustments and adaptivity. However, we ﬁnd that F reqB oost’s performance is 4.4 Sensitivity Analysis 4.4.1 Network Scaling Analysis Figures 10(a)-(c) show the behavior of our techniques as the network size scales from 64 (8x8) to 512 (16x32) nodes. As the network size increases, all the three techniques get greater ﬂexibility in terms of the number of routers that can be modulated when adapting to load in the network. This leads to even higher percentage reduction in latency, power and EDP with network size. For F reqT une, the latency savings increase from 30% to 38% and power savings increase from 13.5% to 18.2% as the network scales to 512 nodes. Even with the column-wise DVFS scheme, the percentage reductions in three metrics increases as network size scales. 4.4.2 Sensitivity to Threshold Next, the sensitivity of our techniques to speciﬁed thresholds is analyzed. Sensitivity results are shown only for the F reqT une scheme with UR traﬃc for brevity. The congestion thresholds depend on buﬀer utilization, and hence, are sensitive to the number of virtual channels and buﬀer depth. Figure 11(a) shows the load-latency curves and 11(b) shows the percentages in power savings compared to the it BaseCase for the it FreqTune scheme, where the threshold to trigger the technique varies across the plots. With a 299         0 10 20 30 40 50 FreqThrtl FreqBoost FreqTune % u d e R i t c n o 8x8 8x16 16x16 16x32 -20 -10 0 10 20 30 % u d e R i t c n o 8x8 8x16 16x16 16x32 FreqThrtl FreqBoost FreqTune 0 10 20 30 40 50 8x8 8x16 16x16 16x32 % u d e R t c i n o %Power %Latency %EDP (a) Latency (per router controller) (b) Power (per router controller) (c) Column-wise Figure 10: Network scaling results for FreqTune with UR traﬃc. 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 Injection Ratio(flits/node/cycle) a L t y c n e ( i s d n o c e s o n a n n ) Thresholdcongested=0.40 Thresholdcongested=0.50 Thresholdcongested=0.60 Thresholdcongested=0.70 -30 -20 -10 % 0 10 20 30 0 . 1 0 0 . 2 0 0 . 4 0 0 . 6 0 0 . 8 0 0 . 1 0 . 2 1 0 . 4 1 0 . 6 1 0 . 8 1 0 . 2 0 . 2 2 0 . 4 2 0 . 6 2 0 . 8 2 0 . 3 0 . 2 3 0 . 4 3 R c u d e i t n o Injection Ratio(flits/node/cycle) Thresholdcongested=0.40 Thresholdcongested=0.50 Thresholdcongested=0.60 Thresholdcongested=0.70 0% 10% 20% 30% 40% 50% 60% Throughput Power EDP e P r c n e t e g a FreqThrtl(DVFS) FreqThrtl(TS+DVFS) (a) Load-Latency graph with UR traﬃc (b) Savings in power with UR traﬃc (c) FreqThrtl using DVFS only Figure 11: Sensitivity of FreqTune to thresholds and results with DVFS only. Table 3: CPU, Cache, Network and Workloads Conﬁguration. CPU and network conﬁguration Processor Pipeline: 64 x86 based 2.2 GHz (nominal) processors, two-way out of order, 64-entry instruction window L1 Caches: 16 KB per-core(private), 4-way set associative, 128B block size, 2-cycle latency, split I/D caches L2 Caches: 1MB banks (per-core),shared, 16-way set associative, 128B block size, 6cycles latency, 32 MSHRs Main Memory: 4GB DRAM,up to 16 outstanding requests for each processor, 400 cycle access, 4 memory controllers Network and Router: 8x8 mesh network(each tile consists of 64 CPUs and 64 L2 banks), 2-stage wormhole switched router, XY routing, 4 VCs per port, buﬀer depth=5, 1024 maximum packet size(8 ﬂits/packet), 2.2 GHz base frequency, 2.75 GHz boosted frequency Commercial workloads App. Benchmark(sap): SAP stands for Standard Application Benchmark and represents a sales and distribution workload. ServerWorkload(specjbb): SPECjbb2000 is a Java based benchmark that models a 3-tier system. We simulated 64 warehouses on 64 processors and start measurements 30 seconds after ramp-up time. Transaction Processing(tpcc): TPC-C is an OLTP benchmark.TPC-C simulates a complete computing environment where a population of users executes transactions against a database. SPEC Java App. Server(sjas): SJAS is a multitier benchmark for measuring the performance of J2EE technology-based application servers. The traces for TPC-C, SAP and SJAS benchmark were collected from a CMP server conﬁgurations at Intel Corporation and we use 64 threads from each benchmark. PARSEC PARSEC suite includes emerging RMS applications as well as large scale multi-threaded programs for CMPs. From this suite we choose three application benchmarks, ferret (frrt), facesim (fsim) and vips, and three kernel benchmarks, canneal (canl), dedup (ddup) and streamcluster (sclst), and ran them with simlarge input sets. Traces were collected on a CMP platform(see conﬁg. in (a)) using Simics for 64 threads of each benchmark for 20 million L2 references and then simulated in our cycle-accurate processorcache-network simulator. (c) (a) (b) more aggressive threshold of T hresholdcongested = 0.4 and T hresholdlow = 0.25, performance takes a hit. Correspondingly, percentage savings in power is also reduced. This is because, with a lower threshold, the technique is triggered earlier and starts throttling the routers even before there is a likelihood of congestion. Hence, latency of the ﬂits is increased and ﬂits spend more time in the network leading to increased power consumption. With a more relaxed threshold of T hresholdcongested = 0.7 and T hresholdlow = 0.4, performance again takes a hit, since in this case, the triggering of the congestion management schemes is delayed and this leads to network saturation. The optimal threshold values for our experiments are shown in Table 1. 4.4.3 FreqThrtl Using DVFS Only We also analyze the case when a router cannot support time-stealing to boost its frequency (to 2.75GHz). Such a scenario might arise if the pipeline stages in a router are balanced using circuit optimizations, and hence, there is no further scope for time-stealing. In this case, we can still use F reqT hrtl and can use DVFS knobs to scale the voltage and thereby the frequency of the upstream routers. Figure 11(c) shows the improvement in throughput, reduction in power and EDP when using F reqT hrtl with DVFS only compared to the BaseC ase (1V, 2.2GHz) for UR traﬃc averaged over L 2  Bank CPU L1 N I C Router Links From N From S From E From W Memory Controller Local Port 8x8 Mesh  Network Figure 12: CMP layout. injection rates. We also show the results for the original F reqT hrtl scheme that uses both DVFS and time-stealing. For F reqT hrtl with DVFS only, we use the highest voltage/frequency knob (1V, 2.2GHz) for nominal operation and during congestion, throttle the neighboring routers to the second highest voltage/ frequency setting (1V, 1.98GHz). Even with these constraints, on an average, there is 8% increase in throughput, 28% savings in power and 33.2% reduction in EDP. All these beneﬁts are purely due to congestion management in the network, which reinforces the advantages of frequency modulation. 300           16% 20% 24% 28% 32% 36% 40% sap sjbb tpcc sjas frrt fsim sclst canl ddup vips Avg.  Comm. Avg.  PARSEC e P c r n e t e g a BaseCase+TS FreqTune 9% 12% 15% 18% 21% 24% sap sjbb tpcc sjas frrt fsim sclst canl ddup vips Avg.  Comm. Avg.  PARSEC e P c r n e t e g a BaseCase+TS FreqTune (a)Percentage reduction in latency (b) Improvement in IPC 0% 4% 8% 12% 16% 20% sap sjbb tpcc sjas frrt fsim sclst canl ddup vips Avg.  Comm. Avg.  PARSEC e P n e c r t e g a FreqTune Overhead 0% 3% 6% 9% 12% 15% 18% sap sjbb tpcc sjas frrt fsim sclst canl ddup vips Avg.  Comm. Avg.  PARSEC e P n e c r t e g a IPC Improvement Latency Reduction Power Reduction Overhead (c) Controller overheads and percentage reduction in power (d)Application performance for Column-wise scheme with FreqTune Figure 13: Results with commercial and PARSEC benchmarks. 4.5 Results with Application Benchmarks We examine the impact of our frequency tuning schemes on application performance for a 64-tile CMP. Each tile in the CMP consists of a core with a private write-back L1 cache and a L2 cache bank. The memory hierarchy uses a two-level directory-based MESI cache coherence protocol and the network connects the cores, L2 cache banks, and memory controllers. All requests and responses are faithfully modeled by the network. The CPU, network conﬁgurations and workload details are given in Table 3 along with the CMP layout in Figure 12. We collected traces using Simics [21] and then used our cycle accurate network simulator with a x86based processor model as described in Table 3(a) for system level analysis. For our experiments, we chose four commercial benchmarks and six workloads from the PARSEC suite [2]. Figures 13(a)-(d) show the results with the application suite. Having a faster network with congestion management, reduces the average load/store latency and directly impacts system performance in terms of instructions per cycle (IPC). On an average, there is 35.7% (up to 37.16% with facesim ) reduction in latency (shown in Figure 13(a)), which translates to 21.2% (up to 23.1% for sjas ) improvement in IPC (Figure 13(b)) across all benchmarks. Correspondingly, there is on an average 15.17% (up to 19.57% for sap ) reduction in network power (Figure 13(c)) for these applications. We ﬁnd the IPC improvements to be greater for commercial benchmarks (21.70%) compared to PARSEC benchmarks (20.50%) because of the bursty characteristic and network-latency critical nature of the commercial workloads. Figure 13(a), also, shows the reduction in network latency when using a brute force frequency boosting approach (BaseC ase+T S ). The diﬀerence in beneﬁts with F reqT une and BaseC ase+T S scheme is solely due to congestion management oﬀered by our scheme. On an average, 10.8% latency diﬀerence between F reqT une and BaseC ase+T S schemes is due to the congestion management technique employed in the former. Figure 13(c) shows the overhead due to the controllers we deploy in the network for the F reqT une scheme.BaseC ase +T S is omitted in this plot since it always consumes 25% more power, and thus, incurs higher network power. We ﬁnd that with a modest 2.4% increase in power overhead, we get up to 23.1% increase in IPC. Further, the overheads in power     to 110nm. On an average, F reqT une reduces the latency by 38.5% compared to PowerHerd with UR traﬃc and also stays within the global power constraint. In addition, we did a quantitative comparison of our network congestion management scheme, F reqT une, with a recently proposed congestion management scheme, RCA [8], where the congestion information is propagated across the network to improve the ability of adaptive routers to spread network load. For comparisons with RCA, we used a simulation setting similar to the one used in RCA, i.e. 8 VCs with 5 ﬂits per VC, 16 ﬂits/packet. Although the comparison results with RCA are not included here due to space limitations, our scheme provides better performance (13.6% less latency) than RCA in addition to managing power since RCA is only aimed at congestion management and our proposed techniques simultaneously manage performance and power. 5. RELATED WORK We summarize the prior work in two sub-sections: on-chip networks and frequency scaling techniques. 5.1 On-Chip Networks Network-on-Chip is widely viewed as a de-facto solution to wire-delay problems with future technology scaling. However, due to the resource constrained nature of an NoC substrate, most researches have focused on two ma jor themes; improving the performance and reducing power consumption. For improving performance, researches have proposed the use of virtual channels and path speculation [26], look-ahead routing [7], smart pipelines [23] and dynamic traﬃc distribution [8, 15, 14] to reduce contention, improve throughput and provide fault-tolerance. Our approach is diﬀerent from all these works since, we use dynamic frequency modulation of routers to manage congestion and improve throughput. Recently, Moscibroda et.al. show that a buﬀerless routing approach [22] leads to lower power consumption without signiﬁcantly sacriﬁcing performance in on-chip networks. However, their proposed buﬀerless routing schemes delivers reasonable performance only when the injection rate into the network is low. On the other hand, our proposed techniques adapts to the load in the network to maximize performance and minimize power at low as well as high injection rates. Hence, our scheme is applicable to a more general purpose on-chip environment. An activity based power management scheme was recently implemented in the routers of the Intel 80-core chip [11]. For this chip, power reduction was achieved by de-activating ports in the on-chip router and putting individual queues in the ports to sleep or clock-gating them based on activity inside the router. Ours approach is orthogonal to this idea and can be implemented on top of this design for performance and power management as well. 5.2 DVFS and Time-Stealing Techniques Several works have proposed DVFS in processors [5, 35, 27] for power management. Recently, work done by Kim et.al [17], has shown the possibility of on-chip voltage regulators. Prior works have proposed DVFS for links [29, 12] to manage power in oﬀ-chip networks. In PowerHerd [28], throttling a ﬂit traversal in a router has been shown as a means to manage peak power constraints in oﬀ-chip networks. Also, in ThermalHerd [30], a collaborative run-time thermal management scheme is proposed for on-chip networks that uses distributed throttling and thermal correlation based routing to tackle thermal emergencies. Time-stealing is a technique that has been widely used in many works to handle Process Variation [20, 32, 19]. Our, work on the other hand, extends the concept of time-stealing to exploit the imbalance in router pipeline stages to overclock the router at frequencies above the nominal frequency. Our proposed schemes are quite diﬀerent from all related works discussed here in the sense that we propose an adaptive frequency router which adapts to load around its vicinity. We do distributed throttling of routers by frequency tuning in onchip networks to manage power and optimize performance. Moreover, our proposed schemes manage congestion in the network, and thereby, give additional throughput gain. To the best of our knowledge, no prior research has proposed any technique to tune a router’s frequency dynamically and adapt to the load conditions. 6. CONCLUSIONS Since both high performance and low power consumption are essential in designing on-chip interconnects for CMP/SoC architectures, in this paper, we propose a variable frequency router architecture for dynamically controlling the performance and power behavior of on-chip interconnects by eﬀective congestion management. Towards this end, we propose three dynamic congestion management techniques, called FreqBoost, FreqThrtl and FreqTune, show their implementation details, and conduct a comprehensive experimental evaluation using synthetic as well as application benchmarks to show the eﬃcacy of our proposal. FreqBoost gives the highest performance throughout but consumes more power at low load. FreqThrtl gives the best power behavior across all injection rates. FreqTune is a hybrid technique that uses FreqBoost at low load to enhance performance and FreqThrtl during high load to minimize network congestion and power consumption. The frequency tuning techniques are enabled by clock scaling through DVFS and frequency boosting through time stealing. The novelty of these schemes are that they can be applied independently for optimizing either performance (through FreqBoost) or power (through FreqThrtl) or both. In the absence of any time-stealing approach due to balanced router pipeline design, one can still use DVFS for congestion management and get beneﬁts both in performance and power. Furthermore, these techniques are more eﬀective than using adaptive routing, simple router frequency scaling for performance enhancement, and peak power reduction techniques. We believe all these results make a strong case for using variable frequency routers for future on-chip networks. 7. ACKNOWLEDGEMENTS We would like to thank the anonymous reviewers for their reviews and comments in improving this paper. This work is supported in part by National Science Foundation (NSF) grants CCF-0702617, CNS-0916887 and CCF-0903432. 8. "
2013,Graphene-enabled wireless communication for massive multicore architectures.,"Current trends in microprocessor architecture design are leading towards a dramatic increase of core-level parallelization, wherein a given number of independent processors or cores are interconnected. Since the main bottleneck is foreseen to migrate from computation to communication, efficient and scalable means of inter-core communication are crucial for guaranteeing steady performance improvements in many-core processors. As the number of cores grows, it remains unclear whether initial proposals, such as the Network-on-Chip (NoC) paradigm, will meet the stringent requirements of this scenario. This position paper presents a new research area where massive multicore architectures have wireless communication capabilities at the core level. This goal is feasible by using graphene-based planar antennas, which can radiate signals at the Terahertz band while utilizing lower chip area than its metallic counterparts. To the best of our knowledge, this is the first work that discusses the utilization of graphene-enabled wireless communication for massive multicore processors. Such wireless systems enable broadcasting, multicasting, all-to-all communication, as well as significantly reduce many of the issues present in massively multicore environments, such as data coherency, consistency, synchronization and communication problems. Several open research challenges are pointed out related to implementation, communications and multicore architectures, which pave the way for future research in this multidisciplinary area.",
2011,Photonic network-on-chip architectures using multilayer deposited silicon materials for high-performance chip multiprocessors.,"Integrated photonics has been slated as a revolutionary technology with the potential to mitigate the many challenges associated with on- and off-chip electrical interconnection networks. To date, all proposed chip-scale photonic interconnects have been based on the crystalline silicon platform for CMOS-compatible fabrication. However, maintaining CMOS compatibility does not preclude the use of other CMOS-compatible silicon materials such as silicon nitride and polycrystalline silicon. In this work, we investigate utilizing devices based on these deposited materials to design photonic networks with multiple layers of photonic devices. We apply rigorous device optimization and insertion loss analysis on various network architectures, demonstrating that multilayer photonic networks can exhibit dramatically lower total insertion loss, enabling unprecedented bandwidth scalability. We show that significant improvements in waveguide propagation and waveguide crossing insertion losses resulting from using these materials enables the realization of topologies that were previously not feasible using only the single-layer crystalline silicon approaches.",
2009,Interconnect-Based Design Methodologies for Three-Dimensional Integrated Circuits.,"Design techniques for three-dimensional (3-D) ICs considerably lag the significant strides achieved in 3-D manufacturing technologies. Advanced design methodologies for two-dimensional circuits are not sufficient to manage the added complexity caused by the third dimension. Consequently, design methodologies that efficiently handle the added complexity and inherent heterogeneity of 3-D circuits are necessary. These 3-D design methodologies should support robust and reliable 3-D circuits while considering different forms of vertical integration, such as system-in-package and 3-D ICs with fine grain vertical interconnections. Global signaling issues, such as clock and power distribution networks, are further exacerbated in vertical integration due to the limited number of package pins, the distance of these pins from other planes within the 3-D system, and the impedance characteristics of the through silicon vias (TSVs). In addition to these dedicated networks, global signaling techniques that incorporate the diverse traits of complex 3-D systems are required. One possible approach, potentially significantly reducing the complexity of interconnect issues in 3-D circuits, is 3-D networks-on-chip (NoC). Design methodologies that exploit the diversity of 3-D structures to further enhance the performance of multiplane integrated systems are necessary. The longest interconnects within a 3-D circuit are those interconnects comprising several TSVs and traversing multiple physical planes. Consequently, minimizing the delay of the interplane nets is of great importance. By considering the nonuniform impedance characteristics of the interplane interconnects while placing the TSVs, the delay of these nets is decreased. In addition, the difference in electrical behavior between the horizontal and vertical interconnects suggests that asymmetric structures can be useful candidates for distributing the clock signal within a 3-D circuit. A 3-D test circuit fabricated with a 180 nm silicon-on-insulator (SOI) technology, manufactured by MIT Lincoln Laboratories, exploring several clock distribution topologies is described. Correct operation at 1 GHz has been demonstrated. Several 3-D NoC topologies incorporating dissimilar 3-D interconnect structures are reviewed as a promising solution for communication limited systems-on-chip (SoC). Appropriate performance models are described to evaluate these topologies. Several forms of vertical integration, such as system-in-package and different candidate technologies for 3-D circuits, such as SOI, are considered. The techniques described in this paper address fundamental interconnect structures in the 3-D design process. Several interesting research problems in the design of 3-D circuits are also discussed.",
2007,On-Chip Interconnection Networks of the TRIPS Chip.,"The TRIPS chip prototypes two networks on chip to demonstrate the viability of a routed interconnection fabric for memory and operand traffic. In a 170-million-transistor custom ASIC chip, these NoCs provide system performance within 28 percent of ideal noncontended networks at a cost of 20 percent of the die area. our experience shows that NoCs are area- and complexity-efficient means of providing high-bandwidth, low-latency on-chip communication.",
2010,Netrace - dependency-driven trace-based network-on-chip simulation.,"Chip multiprocessors (CMPs) and systems-on-chip (SOCs) are expected to grow in core count from, a few today to hundreds or more. Since efficient on-chip communication is a primary factor in the performance of large core-count systems, the research community has directed substantial attention to networks-on-chip (NOCs). Current NOC evaluation methodologies include analytical modeling, network simulation, and full-system simulation. However, as core count and system complexity grow, the deficiencies of each of these methods will limit their ability to meet the demands of developers and researchers. Developing efficient NOCs requires high-fidelity, low-overhead NOC evaluation techniques and metrics. To address these challenges, this paper describes a new trace-based network simulation methodology that captures dependencies between network messages observed in full-system simulation of multithreaded applications. We also introduce Netrace, a library of tools and traces that enables targeted NOC simulators to track and replay network messages and their dependencies.","Netrace: Dependency-Driven Trace-Based Network-on-Chip Simulation Joel Hestness∗ hestness@cs.utexas.edu Boris Grot∗ bgrot@cs.utexas.edu Stephen W. Keckler∗ † skeckler@nvidia.com ∗Depar tment of Computer Science, The University of Texas at Austin †Architecture Research Group, NVIDIA Approach Analytical modeling Simulation: synthetic traﬃc Simulation: Full-system Fidelity Low Low Runtime Cite Zero [4, 18] Short [1, 15, 16] Abstract Chip multiprocessors (CMPs) and systems-on-chip (SOCs) are expected to grow in core count from a few today to hundreds or more. Since eﬃcient on-chip communication is a primary factor in the performance of large core-count systems, the research community has directed substantial attention to networks-on-chip (NOCs). Current NOC evaluation methodologies include analytical modeling, network simulation, and ful l-system simulation. However, as core count and system complexity grow, the deﬁciencies of each of these methods wil l limit their ability to meet the demands of developers and researchers. Developing eﬃcient NOCs requires high-ﬁdelity, low-overhead NOC evaluation techniques and metrics. To address these chal lenges, this paper describes a new trace-based network simulation methodology that captures dependencies between network messages observed in ful l-system simulation of multithreaded applications. We also introduce Netrace, a library of tools and traces that enables targeted NOC simulators to track and replay network messages and their dependencies. 1. INTRODUCTION As chip multiprocessors (CMPs) scale toward hundreds of processing cores, experimentation becomes evermore complex. Diversiﬁcation of cores in heterogeneous systems will require added eﬀort in building and debugging CMP simulators. Further, simulation time will increase as CMPs scale and integrate more components onto a single chip. Researchers must ﬁnd novel methods of testing emerging systems in ways that provide quick performance estimates without sacriﬁcing (too much) ﬁdelity or conﬁdence. Networks-on-chip (NOCs) promise eﬃcient communication between cores, caches, and memory controllers of future CMPs. Current NOC research assumes that hundreds of processing cores will be available on a chip, and indeed, Tilera has already produced such a design. Existing NOC research covers traditional topics, such as topologies and routing algorithms, as well as more complex ones, like incorporation of emerging manufacturing technologies, quality of service, and interactions of cache architecture, protocols, and network. In this paper, we survey existing NOC evaluation methodologies and observe that today’s approaches have ma jor drawPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. NoCArc ’10, December 4, 2010, Atlanta, Georgia, USA Copyright c(cid:13)2010 ACM 978-1-4503-0397-2 ...$10.00. Figure 1: Throttling by Timestamp traﬃc within a system running real applications. As such, they fail to oﬀer the designer application-level performance insights, such as memory access time or end-to-end runtime. A related approach is to develop synthetic traﬃc generators that mimic actual application-level behavior as in an SOC [15, 17]. These methods require statistical analysis of network traﬃc traces to tune multiple diﬀerent generators for appropriate injection rates, causal dependencies between messages, and application phase changes. Such tuning requires substantial eﬀort and is often speciﬁc to a particular class of architectures or applications. Full System Simulation: Full-system simulation provides the highest evaluation ﬁdelity by explicitly modeling the interaction of application and architecture. The insights gained through full-system simulation can reveal NOC bottlenecks with respect to actual applications and the impact of network-level optimizations on application performance. Despite the considerable beneﬁts, the approach suﬀers from two important drawbacks. First, the simulation time of a complete system running an operating system and benchmark applications can be on the order of many weeks to months, depending on the level of detail and system size of the simulation, and the duration of the application region of interest. Slow simulation hinders the ability of the designer to get quick feedback and to test a large design space. Second, even with deterministic full-system simulation, the issue of variability arises between simulations spanning a design space. For instance, comparing performance of even small modiﬁcations to the NOC can result in large diﬀerences in thread-to-core assignment, synchronization contention and operating system eﬀects due to slight timing diﬀerences and diﬀerent execution paths [3]. Such non-determinism makes exploration of the architectural design space of NOCs diﬃcult. Trace-driven NOC Simulation: As an alternative to full-system simulations, researchers have proposed driving an NOC simulator with traces of network traﬃc that have been collected from execution of an application. The motivation behind these trace-based approaches is to capture the network-level behavior of real applications while beneﬁtting from the speed of isolated network simulation. Speedups of up to 50x have been reported for trace-driven NOC evaluation over full-system simulation [16]. While application traﬃc tends to be more realistic than synthetic workloads, trace-driven methodologies have largely ignored the dependencies between network messages. Ignoring dependencies allows interleavings of messages that would not occur in full-system simulation and can cause misleading injection rates due to a lack of dependency-based throttling. As an example, Figure 1 shows multiple requesters issuing consecutive memory requests to the L2 bank on the right. In a trace-driven conﬁguration, the rate at which the requests enter the network is controlled by the trace packet timestamps that reﬂect the cycle in which the corresponding memory accesses occurred in full-system simulation. If the packet latency in the simulated NOC is greater than that modeled in full-system mode, the rate at which the packets enter the network can exceed the NOC’s ability to deliver them, causing pockets of congestion. Congestion tends to increase network latency and diminish throughput, distorting these metrics and compromising simulation ﬁdelity. This behavior is an artifact of incorrectly throttled packet injection that ignores transaction ordering and dependencies among messages. As a result of such distortions, existing trace-driven methodologies do not provide meaningful application-level performance metrics [10]. Without such feedback, designers are not able to evaluate the impact of NOC optimizations on application performance. Dependency-driven NOC Simulation: We propose a new evaluation methodology for trace-based NOC simulation that captures and obeys the dependencies between messages. Our approach is to construct a directed acyclic graph (DAG) between network messages based on the ordering and dependencies among memory transactions recorded during full-system simulation. The dependency information is stored along with packet data in the network trace. By enforcing the ordering constraints in a network simulator, the proposed technique can greatly increase the ﬁdelity of tracedriven evaluation with little impact on simulation speed. Dependency-tracking trace-driven simulation provides several beneﬁts. First, enforcing dependencies ensures a proper interleaving of network messages, which increases the ﬁdelity of the simulation by eliminating network hotspots that are a result of artiﬁcial network contention. Analysis of the remaining hotspots that arise while enforcing dependencies can oﬀer valuable insight into the network bottlenecks that are due to either the network architecture or the communication patterns of the application. Second, since the traces are collected from a single execution of a benchmark, the same application execution paths are enforced regardless of the NOC organization being tested. This strategy makes it easier to assess the impact of diﬀerent network designs on application-level performance characteristics as compared to full-system simulation, which is plagued by variability in execution paths. Third, the time to run an NOC simulation that obeys dependencies is only slightly longer than NOC simulation without dependencies, oﬀering substantial speedup over full-system simulation. Finally, we anticipate that the rich content of the traces will enable researchers to test the interplay of numerous design points, including cache coherence and cache-to-network protocols, physical placement of cache and memory controllers on a die, and cache line owner/home mappings. We hope that this methodology can be used as a standard for network evaluation as the size and complexity of NOC designs grow. Trace-based methods, including the one proposed here, are not without drawbacks. Trace ﬁle sizes can be large (a gigabyte or more) making distribution diﬃcult. Because each trace is matched to the architecture of the simulated system, testing a diﬀerent cache organization or processor core will require full-system simulation run to collect new traces. Despite these limitations, we anticipate that the beneﬁts of ﬁdelity and speed will motivate many NOC researchers to use these dependency-based traces and tools. 3. DEPENDENCIES Abstractly, a network message j is dependent on network message i if either of the following holds: (1) receipt of message i must occur before (or triggers) the sending of message j , or (2) message j is dependent on message k , and k is Cores L1 cache L2 cache Memory 64 on-chip, in-order, Alpha ISA, 2GHz 32KB instruction/32KB data, 4-way associative, 64B lines, 3 cycle access time, MESI coherence 64 bank fully shared S-NUCA, 16MB, 64B lines, 8-way associative, 8 cycle bank access time 150 cycle access time, 8 on-chip memory controllers Table 2: Target System Figure 2: Abstraction in Target System dependent on message i. The second condition is transitivity, stipulating that a message is dependent on another if there exists a chain of dependencies linking them. Analogous to a data-ﬂow graph, the set of packets and dependencies in a trace makes up a directed-acyclic graph where the nodes are packets and the edges are dependencies between packets. One of the simplest examples of a chain of dependencies is a memory access. Figure 3 depicts a memory access from an L1 instruction cache for instruction memory that is not currently on-chip. The request triggers a chain of packets and dependencies that goes to memory to get the data and returns it to the L1-I. More complex memory accesses involve the cache coherence protocol and result in longer or wider chains of packets and dependencies. We use the term “memory access” to denote the set of network messages and dependencies that result due to a single core issuing a single memory request. The concept of a memory access is a useful abstraction when trying to understand what a network traﬃc trace with dependencies looks like. For the target system in this study, a network traﬃc trace is made up of a set of memory accesses that are linked end-to-end through dependencies at the processor core. Since the packets and dependencies represent a directed, acyclic graph, a partial order can be deﬁned. The longest chain of dependencies in the graph, along with associated latencies, represents the network critical path for the application from which the traces were collected. This observation indicates the link between network performance and end-to-end runtime of an application, and it is our motivation for tracking dependencies. 3.1 Dependency Classes Dependencies between network messages arise as a result of three distinct causes: architectural, microarchitectural, and programmatic. We classify network message dependencies based on these causes and describe them in the context of a target system below. For a thorough discussion of these dependency classes in the context of microprocessor design, we refer the reader to Fields [8]. 3.2 Target System To make the message dependency discussion concrete, we walk through a case study of dependencies for a particular target system in the next subsection. Table 2 summarizes the design parameters for this target system, which is comFigure 3: Example Memory Access prised of in-order cores with private L1 instruction and data caches, a shared, banked L2 cache, and eight on-die memory controllers. This target system corresponds to a speciﬁc instance of the abstract architecture shown in Figure 2. The cache coherence protocol is MESI for the L1s. An L2 bank acts as the owner of shared lines and as the backing store for writebacks from the L1s. 3.3 Message Dependency Classes Architectural dependencies arise as a result of architectural component interaction, such as messages between cores, caches, and memory controllers. For our target system, there are 3 types of architectural dependencies: requestrequest, request-response and response-response. Each of these diﬀerent types is depicted in Figure 3. For instance, request-request dependencies occur when a request for data causes a miss in the L2 and thus, a subsequent request to the memory controller for the data. Analogously, when the response comes back on-chip, it ﬁrst returns to the L2 before being forwarded to the requesting L1. Request-response dependencies occur when an architectural component can service a request, so after it receives the request, it can send the response data. In this target system, the L2 and memory controllers can service requests. Microarchitectural dependencies are due to microarchitectural implementation details, including buﬀer capacities, protocols and others. In general, tracking microarchitectural dependencies can be diﬃcult as they must be considered on a per-architectural-component basis. For the target system, microarchitectural dependencies are caused by cache implementations and the cache coherence protocol. For instance, the L2 cache line size, associativity, replacement policy and capacity aﬀect when and which cache lines are evicted. When the L2 receives a packet i containing new data, it may trigger a writeback of the old data via a message to a memory controller. The writeback packet depends on the receipt of i, causing the eviction. The coherence protocol is also a source of many dependencies. For instance, if a cache line is shared between multiple L1 data caches, and one of the L1s issues an upgrade request for that cache line, the receipt of that upgrade request at the L2 will trigger the release of invalidation requests to all other sharers of that line. A similar situation occurs when read requests cause a downgrade request to the owner. Program behavior dependencies are a result of both data- and control-ﬂow dependencies within an application, and they are realized by the microarchitecture of the processor core. An example is when a branch or jump instruction in the control-ﬂow graph causes a new region of instruction memory to be loaded into the L1-I cache. The instruction load is dependent on executing an instruction that was loaded previously. Data-ﬂow dependencies, such as read-after-read (RAR) and write-after-read (WAR), cause similar network message dependencies between a load and other loads/stores. In practice, program behavior dependencies are diﬃcult to track without inspection of machine code of an application. For the purpose of investigating the eﬃcacy of dependency tracking, our initial target system uses in-order cores, which allow us to make the assumption that memory requests from a core must proceed serially. We have started investigating dependencies in the context of an out-of-order core, and we plan to complete a full analysis in future work. 4. TRACE COLLECTION We use a two step process for collecting network trafﬁc traces. First, we use full-system simulation to collect memory request traces, which we refer to as the “simulation traces.” Then we post-process these simulation traces to extract network messages and detect dependencies between them. This data is output to an encoded network traﬃc trace. While we describe the process in the context of a particular target system, our methodology can be extended and applied to a variety of system conﬁgurations. 4.1 Simulated System For full-system simulation, we use the M5 simulator [6] running a modiﬁed version of Linux 2.6.27 that supports up to 64 cores. We choose to simulate a system that is, in a couple ways, more abstract than the target system described in Section 3. First, the simulated system models a uniﬁed L2 cache and a single memory controller. This allows us to concentrate the L2 and memory traﬃc through a single point, simplifying trace post-processing and eliminating variable access time to physically distinct components. Second, the simulated system models a ﬁxed-latency bus between the L1 and L2 caches, and another between the L2 and memory controller. Packets are not artiﬁcially spaced through time due to contention for communication resources. The combination of these two abstractions avoids assuming any physical layout of the chip by giving the illusion that each core is the same “distance” from the L2 or memory. This approach ensures that the varying latencies that are realized in dependency-enforcing network simulation are not a result of artiﬁcial timing eﬀects from the full-system simulation. While future systems may feature non-uniform cache access latencies, the actual latencies of these components would be highly dependent on ﬂoorplanning and layout, so we ﬁx the access latency to a given cache. Another aspect of modeling component latency is deciding how to model network latency. Actual network latencies are dependent on the amount of contention in the network at a given time, as well as the network implementation, such as the number of routers between source and destination of a message. Due to the high variability in network latency, we again assume a ﬁxed latency for message communication. To decide this latency, we used an analytical model to calculate the average number of hops, and thus average packet latency, across a chip with a mesh-like network topology using manhattan distance and assuming no contention. The assumption of contentionfree network traﬃc reﬂects communication behavior of highperformance applications, which are typically optimized for local communication in an actual system. Format: <inject_cycle>: <bus>: src <port_id> dst <port_id> <type> <addr> A 36: sys.tol2bus: src 96 dst -1 ReadReq 0xd040 B 50: sys.tol2bus: src 46 dst -1 ReadReq 0xdb40 C 60: sys.tol2bus: src 16 dst 96 ReadResp 0xd040 D 74: sys.tol2bus: src 16 dst 46 ReadResp 0xdb40 Figure 4: Example Simulation Trace Records Figure 5: Example Packet 4.2 Post-processing Simulation Traces After collecting simulation traces from the simulated system, we post-process them to generate network traﬃc traces. Our post-processing application ﬁrst syntactically parses the simulation trace to build network packets that include the injection cycle, source and destination node, and others. The second phase inspects a window of packets from the previous 1,000,000 trace cycles to detect and track dependencies between them. The window depth was chosen empirically to contain at least 95% of each dependency type that we track. To make the post-processing step more concrete, consider the example records from a simulation trace as shown in Figure 4. The syntactic parsing of record A builds a packet data structure similar to the one shown in Figure 5. The packet injection cycle is read directly from the record. The source and destination ports are translated using the mapping deﬁned within simulation, which in this case maps port 96 to the L1 data cache at node 47. A destination port of -1 indicates that a packet is broadcast on the bus. Record C shows the response to record A, which originates at port 16, the L2 cache. The L2 home node of the cache line is calculated on an address-interleaved basis. Packet A is added to the packet window to be inspected later to detect dependencies. When record C is parsed, our application searches through the window of previously parsed records to ﬁnd packets on which C depends. Here, C depends on A, so the number of dependencies for packet A is incremented, and C is added to A’s list of downward dependencies. Similarly, packet D depends on B, so a dependency is established between them. 4.3 Benchmarks Our ﬁrst set of on-chip network traﬃc traces with dependencies was collected from M5 simulation of the PARSEC v2.1 benchmark suite [5] [9]. The PARSEC suite contains multiple input sets for each benchmark, and we collect traces for simulation with the simsmall, simmedium and simlarge input sets for all the benchmarks that work with simulation up to 64 cores. 5. NETRACE Netrace is a C/C++ library that includes functionality to read a standardized network traﬃc trace ﬁle and track the dependencies between network messages. This library can be easily incorporated into existing and new network simulators as a means of driving the simulation. A network simulator can employ the API calls of the Netrace system to read packets from a trace and to detect and enforce dependencies. This section outlines the Netrace API as shown in Table 3, and we describe the ﬂexibility of the traces. Netrace API: After a Netrace ﬁle has been opened, the nt_read_packet function will return the next packet in the ﬁle. A packet, i contains a list of downstream dependent packets that should not be injected into the network until i has been ejected. Netrace adds these dependencies to its internal data structures to power the next two functions. The nt_dependencies_cleared method queries the Netrace data structures to check if, for a packet j , all of its upstream dependent packets have been ejected from the network. If so, the method returns TRUE to indicate that j can be injected into the network, otherwise, it returns FALSE. The network simulator must clear these upward dependencies by calling the nt_clear_dependencies_free_packet method on all packets as they are ejected from the network. A call to nt_clear_dependencies_free_packet removes the downward dependencies of a packet and frees the packet memory. For packet, i, which is being ejected from the network, if i is the last upward dependency for packet j , then after the call nt_clear_dependencies_free_packet(i), subsequent calls to nt_dependencies_cleared(j ) will return TRUE indicating that all dependencies have been cleared. Netrace Flexibility: Figure 2 shows the abstraction of the target system as we discussed in Section 4. Thanks to this abstraction, an NOC simulator can be used to evaluate a wide range of network conﬁgurations within this target system using traces with message dependencies. First, Netrace is designed to support comparisons between traditional NOC design points, such as topologies and routing algorithms. At a detailed level, it can provide applicationlevel insight into bottlenecks caused by the NOC, similar to what we describe in Section 6. Second, the expressiveness of Netrace traces also supports emerging research directions. For instance, it allows for evaluations of on-chip ﬂoorplanning and layout in future systems that may incorporate numerous cores or new manufacturing technologies such as die-stacking. It can be used to evaluate diﬀerent cache and memory controller counts and locality simply by remapping the sources and destinations of packets aimed at particular components. Finally, Netrace provides the ﬂexibility to test the interplay of multiple design decisions in a system hierarchy. For example, the traces we distribute assume a particular coherence protocol that can easily be replaced with other protocols as long as the NOC simulator tracks coherence state for live cache lines. This allows for testing the interaction of different network designs and cache coherence protocols, which will be critical as the focus of NOC research comes to include broadcast/multicast support and power concerns. 6. EVALUATION Methodology: To evaluate the eﬀectiveness of enforcing message dependencies, we compare application-level performance metrics between M5 full-system simulation and tracebased NOC simulation. To assess the aﬀect of varying average packet latency on application-level performance characteristics, we ﬁrst run full-system simulations with a variety of ﬁxed network latencies. The full-system that we model is the same as our simulated system, which models an ideal network, namely, the communication latency from any node to any other node is the same. We then use a custom NOC simulator to test three network topologies that represent a Benchmark blackscholes canneal x264 Input Cycles Packets simlarge 894M 89.5M simmedium 300M 74.2M simsmall 1.48B 31.3M Table 4: Full-system simulation ROI data range of diﬀerent latency and throughput characteristics: a mesh, a mesh with concentration factor of four (Cmesh) [4], and a multidrop express channel topology (MECS) [11]. Discussion: Figure 6 plots the region of interest (ROI) runtime, normalized to full-system simulation with an 8cycle ﬁxed network latency for three diﬀerent PARSEC benchmarks. The benchmarks, listed in Table 4, were chosen as examples of the range of application performance characteristics that Netrace can capture. Three diﬀerent simulation conﬁgurations are shown in the ﬁgure – full-system, conventional trace-based NOC simulation without dependency tracking (Trace), and dependency-driven NOC simulation (Netrace). For both trace-based conﬁgurations, individual points correspond to the three modeled topologies – MECS, concentrated mesh, and mesh, respectively, going from left (lower latency) to right (higher latency) in the ﬁgure. For full-system simulations, the topology is unchanged but different ﬁxed network latencies are modeled. As expected, in full-system simulation, longer network latencies increase the runtime of the application by delaying the completion of cache and memory accesses. In contrast, the runtime of network simulation without dependencies remains unchanged across the diﬀerent topologies and is always equal to the runtime of the full-system conﬁguration under which the traces were collected. This is because simulation without dependencies fails to provide feedback to throttle packet injection and elongate runtime. Netrace correctly tracks network dependencies and faithfully serializes transactions, reﬂecting the relative elongation in application runtime experienced by full-system simulations with longer network delays (i.e. the slope of the fullsystem and Netrace lines in the ﬁgure are quite similar). For instance, for canneal, Netrace reveals that a MECS topology yields an 11% speed-up relative to a mesh network while reducing the average packet latency by over 66%, from 26.8 cycles to 11.9 cycles. The relative speedup precisely matches that observed in full-system simulation with equivalent network latencies. We can also see the eﬀect of communication locality on ROI runtime. As an example, x264-smal l can only utilize 8 cores during the ROI, and the Linux thread scheduler does a good job of placing threads for locality. The end result is that data communication between threads is mostly local, so network topology has a minor eﬀect on ROI runtime. On the other hand, blackscholes spreads the work among all of the cores with little communication aﬃnity. As a result, packets travel larger distances across the NOC, exposing the latency-reducing beneﬁts of low-diameter networks. In this case, Netrace shows that the low-diameter MECS topology improves application performance by 5% compared to the mesh network, which requires a large number of hops between source and destination. In general, the relative performance of diﬀerent topologies under Netrace correlates well with full-system measurements. However, the absolute performance as indicated by ROI runtime is quite diﬀerent for the two approaches. The reason for this phenomenon is that full-system simulation uses an idealized ﬁxed-latency NOC model, which ignores Method Description Read a packet from the Netrace ﬁle Check if upward dependencies have been cleared nt_clear_dependencies_free_packet( packet ) Clear downward dependencies and free the passed packet nt_read_packet( ) nt_dependencies_cleared( packet ) 1.1 ) d e z 1.08 Full-system Trace Netrace mesh  i l a m r o n ( e m i t n u r I O R 1.06 1.04 1.02 1 0 Cmesh  MECS  MECS  Cmesh  mesh  10 20 30 40 Average network latency (cycles)  Table 3: Netrace API Methods 1.6 1.5 1.4 1.3 1.2 1.1 1 0 Full-system Trace Netrace mesh  MECS  Cmesh  1.5 1.4 1.3 1.2 1.1 MECS  Cmesh  mesh  10 20 30 Average network latency (cycles)  40 1 0 Full-system Trace Netrace MECS  Cmesh  mesh  MECS  Cmesh  mesh  10 20 30 Average network latency (cycles)  40 (a) blackscholes-large (b) canneal-medium (c) x264-small Figure 6: Comparison of diﬀerent methodologies. the eﬀects of variable communication latency of a realistic multi-hop network. One of these eﬀects is the divergence in the execution rates of the diﬀerent threads based on their observed memory latency, which causes some threads to ﬁnish ahead of others. In parallel systems, workload completion time is always determined by the slowest thread – an eﬀect not fully captured in simulations with ﬁxed network latency. In contrast, Netrace faithfully captures both network eﬀects and application dependencies, and is likely a more accurate indicator of NOC’s impact on application performance than the full-system results here. 7. CONCLUSIONS AND FUTURE WORK This paper introduces Netrace, a trace-based network simulation platform that encodes dependencies between network messages. Netrace includes a set of NOC traﬃc traces and trace ﬁle reader library that can be incorporated into new and existing network simulators with little eﬀort. We will provide more detail about the Netrace tools and traces in our technical report [14]. Enforcing dependencies between network messages during trace-driven NOC simulation ensures that the network handles a proper interleaving of packets. This strategy increases the ﬁdelity of NOC simulation when compared to other trace-based NOC simulation methodologies by eliminating hotspots due to artiﬁcial network contention and focusing bottleneck detection. Compared to full-system simulation, trace-driven NOC simulation with dependencies can be orders of magnitude faster and can avoid the problem of variability of execution path by collecting a trace of a single execution of a benchmark. Finally, Netrace enables the analysis of the interaction of numerous design decisions and application-level evaluation metrics, most importantly, application runtime. In the future, we plan to extend Netrace to support systems with out-of-order cores. We will also be considering new on-chip system conﬁgurations, possibly with diﬀerent numbers of network terminal nodes and cache hierarchies. "
2011,A NoC Traffic Suite Based on Real Applications.,"As benchmark programs for microprocessor architectures, network-on-chip (NoC) traffic patterns are essential tools for NoC performance assessments and architecture explorations. The fidelity of NoC traffic patterns has profound influence on NoC studies. For the first time, this paper presents a realistic traffic benchmark suite, called MCSL, and the methodology used to generate it. The publicly released MCSL benchmark suite includes a set of realistic traffic patterns for 8 real applications and covers popular NoC architectures. It captures not only the communication behaviors in NoCs but also the temporal dependencies among them. MCSL benchmark suite can be easily incorporated into existing NoC simulators and significantly improve NoC simulation accuracy. We developed a systematic traffic generation methodology to create MCSL based on real applications. The methodology uses formal computational models to capture both communication and computation requirements of applications. It optimizes application mapping and scheduling to faithfully maximize overall system performance and utilization before extracting realistic traffic patterns through cycle-accurate simulations. Experiment results show that MCSL benchmark suite can be used to study NoC characteristics more accurately than traditional random traffic patterns.",
2009,Synthesis of networks on chips for 3D systems on chips.,"Three-dimensional stacking of silicon layers is emerging as a promising solution to handle the design complexity and heterogeneity of Systems on Chips (SoCs). Networks on Chips (NoCs) are necessary to efficiently handle the 3D interconnect complexity. Designing power efficient NoCs for 3D SoCs that satisfy the application performance requirements, while satisfying the 3D technology constraints is a big challenge. In this work, we address this problem and present a synthesis approach for designing power-performance efficient 3D NoCs. We present methods to determine the best topology, compute paths and perform placement of the NoC components in each 3D layer. We perform experiments on varied, realistic SoC benchmarks to validate the methods and also perform a comparative study of the resulting 3D NoC designs with 3D optimized mesh topologies. The NoCs designed by our synthesis method results in large interconnect power reduction (average of 38%) and latency reduction (average of 25%) when compared to traditional NoC designs.","3A-2 Synthesis of Networks on Chips for 3D Systems on Chips Srinivasan Murali(cid:2) , Ciprian Seiculescu(cid:2) , Luca Benini‡ , Giovanni De Micheli(cid:2) (cid:2) LSI, EPFL, Lausanne, Switzerland, {srinivasan.murali, ciprian.seiculescu, giovanni.demicheli}@epﬂ.ch ‡ DEIS, Univerity of Bologna, Bologna, Italy, lbenini@deis.unibo.it ABSTRACT Three-dimensional stacking of silicon layers is emerging as a promising solution to handle the design complexity and heterogeneity of Systems on Chips (SoCs). Networks on Chips (NoCs) are necessary to efﬁciently handle the 3D interconnect complexity. Designing power efﬁcient NoCs for 3D SoCs that satisfy the application performance requirements, while satisfying the 3D technology constraints is a big challenge. In this work, we address this problem and present a synthesis approach for designing power-performance efﬁcient 3D NoCs. We present methods to determine the best topology, compute paths and perform placement of the NoC components in each 3D layer. We perform experiments on varied, realistic SoC benchmarks to validate the methods and also perform a comparative study of the resulting 3D NoC designs with 3D optimized mesh topologies. The NoCs designed by our synthesis method results in large interconnect power reduction (average of 38%) and latency reduction (average of 25%) when compared to traditional NoC designs. Keywords 3D, networks on chip, topology synthesis, application-speciﬁc 1. INTRODUCTION The 2D chip fabrication technology is facing lot of challenges in utilizing the exponentially growing number of transistors on a chip. The wire delay and power consumption is increasing dramatically and achieving interconnect design closure is becoming a challenge. Designing the clock-tree network for a large chip is becoming very challenging and its power consumption is a signiﬁcant fraction of total chip power consumption. Moreover, diverse components that are digital, analog, MEMS and RF are being integrated on the same chip, resulting in large complexity for the 2D manufacturing process [19]. Vertical stacking of multiple silicon layers, referred to as 3D stacking, is emerging as an attractive solution to continue the pace of growth of Systems on Chips (SoCs) [19]-[24]. The 3D technology results in smaller footprint in each layer and shorter vertical wires that are implemented using Through Silicon Vias (TSVs) across the layers. Heterogeneous systems can be built easily, with each layer supporting a diverse technology [19]. The 3D technology has been maturing over the years in addressing thermal issues and achieving high yield [20]. To tackle the on-chip communication problem, a scalable communication paradigm, Networks on Chips (NoCs) has recently evolved [1]-[3]. NoCs are composed of switches and links and use circuit or packet switching technology to transfer data inside a chip. They provide better structure, modularity and scalability when compared to traditional interconnect solutions. NoCs are a necessity for 3D chips: they provide arbitrary scalability of the interconnects across additional layers, efﬁciently parallelize communication in each layer and help controlling the number of vertical wires (and hence TSVs) needed for inter-layer communication. The combined use of 3D integration technologies and NoCs introduces new opportunities and challenges for designers. Building power-efﬁcient NoCs for 3D systems that satisfy the performance requirements of applications, while satisfying the technology constraints is an important problem. To address this issue, new architectures and design methods are needed. While the issue of designing NoC architectures for 3D has received some attention [30]-[33], there has been little work on design methods for 3D NoCs. The design methods for 2D NoCs do not consider important 3D information, such as the technology constraints on the number of TSVs that can be supported, constraints on communication between adjacent layers, determining layer assignment for switches and placement of switches in 3D. In this work, we address this important problem and present a synthesis approach for designing the most power efﬁcient 3D NoC that meets application performance and technology constraints. We present a synthesis approach to determine the most power efﬁcient topology for the application and for ﬁnding paths for the trafﬁc ﬂows that meet the TSV constraints. Our methods account for power and delay of both switches and links. The assignment of cores to different 3D layers and the ﬂoorplan of the cores in each layer are taken as inputs to the synthesis process. To accurately model the link delay and power consumption, for the given core positions, we present a method to determine the optimal positions of switches in the ﬂoorplan in each layer. We then place the switches on each layer, removing any overlap with the cores. Please note that the assignment of cores to the different layers and the ﬂoorplan of each layer needs to consider several performance and technological constraints, such as thermal issues. There are several works that address these issues [21]-[24] and our work is complementary to them. Here, we only address the issue of designing the NoC topology and determining the placement of the NoC switches. As in our output ﬂoorplan (after placing the switches), the core positions are almost the same as the input ﬂoorplan, we minimally affect these (such as the thermal) issues. We perform experiments on varied, realistic SoC benchmarks to validate the methods. Our results show that the topologies synthesized by our method results in large interconnect power reduction (an average of 38%) and latency reduction (25% on average), when compared to optimized standard NoC topologies. 978-1-4244-2749-9/09/$25.00 ©2009 IEEE 242 3A-2 cores to the different layers in 3D is also obtained as an input. In the communication speciﬁcation ﬁle, the communication characteristics of the application are speciﬁed. This includes the bandwidth of communication across different cores, latency constraints and message type (request/response) of the different trafﬁc ﬂows. To achieve high yield, the number of TSVs that can be established across two layers may need to be restricted below a threshold [25]. In the rest of the paper, we model the maximum TSV constraint by using a constraint on the number of NoC links that can cross two adjacent layers, denoted max ill (for maximum number of inter-layer links). For a particular link width, the maximum number of links can be directly determined from the TSV constraints. For the synthesis procedure, the power, area and timing models of the NoC switches and links are also taken as inputs. We also take the power consumption and latency values of the vertical interconnects as inputs. The output of the topology synthesis procedure is a set of Pareto design points of topologies that meet the constraints, with different values of power, latency and design area. From the resulting points, the designer can choose the optimal point for the application. The synthesis procedure also produces a placement of the switches in the 3D layers and the positions of the switches. The TSV macros needed for establishing vertical links are directly integrated in the switch input/output ports, as done in [33]. As the topology synthesis and mapping problem is NP-Hard [10], we present efﬁcient heuristics to synthesize the best topology for the design. For achieving high yield, it is important to restrict the number of vertical links used and to allow vertical connections only across adjacent layers on the 3D chip [25]. Thus, in our procedure, we connect cores in a layer only to switches in the same layer, and ensure that switches of a layer are directly connected only to switches in adjacent layers. A NoC having fewer switches leads to longer core to switch links and hence, higher link power consumption. On the other hand, when many smaller switches are used, the ﬂows have to traverse more switches, leading to larger switch power consumption. Thus, we need to explore designs with several different switches to obtain the best solution, starting from one where all the cores are connected to a single switch in a layer to a design point where each core is connected to a separate switch. For each switch count, we determine the core to switch connectivity, as explained in Section 4. Then, we determine connectivity across the different switches (Section 5). Then, we determine the optimal positions of the switches on the ﬂoorplan (Section 6) and determine the wire lengths and link power consumption. 4. ESTABLISHING NUMBER OF SWITCHES In this section, we present methods for establishing connectivity between the cores and switches. From the core speciﬁcation ﬁle, we obtain the core speciﬁcations: D E FIN I T ION 1. Let n be the number of cores in the design. The yci respectively, ∀i ∈ 1 · · · n. The 3D layer to which the core i is x and y co-ordinate positions of a core i are represented by xci and assigned is represented by layeri . From the communication speciﬁcation ﬁle, the communication characteristics of the application are obtained and represented by a graph [6], [9], deﬁned as follows: G(V , E ) with each vertex vi ∈ V representing a core and the diD E FIN I T ION 2. The communication graph is a directed graph, rected edge (vi , vj ) representing the communication between the cores vi and vj . The bandwidth of trafﬁc ﬂow from cores vi to vj Figure 1: Proposed 3D NoC design approach 2. RELATED WORK The use of NoCs to replace bus-based designs has been presented in [1]-[2]. Several different NoC architectures and design methods [4]-[5] have been developed over the past few years. A detailed description of the important design issues and the current state-ofthe-art in NoC architectures and design methods is presented in [3]. Synthesis of bus and NoC architectures has been addressed by several researchers for 2D systems. Mapping and placement of cores onto standard NoC topologies has been explored in [6]-[9]. Synthesis of application speciﬁc NoC topologies has been addressed in [10]-[17]. In [17], we presented a NoC synthesis method for 2D SoCs and performed detailed comparisons with standard topologies and other mapping tools. In this paper, we use the basic principles from the 2D method to address the important issues in 3D NoC design. Several works have been presented on the 3D manufacturing processes and interconnects [19], [20], [33]. A performance and cost trade-off analysis of 3D integration is presented in [26]. Several works have explored 3D ﬂoorplanning, placement and temperature issues of cores [21]-[24]. These works do not consider the interconnect synthesis problem. Multi-dimensional topologies (such as k-ary n-cubes, hypercubes) have been extensively explored in the chip-to-chip interconnection ﬁeld [18]. However, such works only consider standard topologies suitable for homogeneous designs. Most SoCs, especially in 3D, are heterogeneous in nature and require application-speciﬁc interconnect architecture to optimize power and performance. Moreover, such works do not address the optimization of topologies based on trafﬁc patterns. Analysis and synthesis of NoCs for 3D technology is a relatively new topic. Novel NoC switch architectures for 3D are presented in [30] and [32]. In [31], the authors present the use of NoCs in 3D multi-processors. In [33], the authors analyze the electrical characteristics of vertical interconnects and show a back-end design ﬂow to implement 3D NoCs. In [27], the authors present an analytical model for cost metrics of 3D NoCs and compare them with 2D NoCs. In [28], design of standard NoC topologies (such as mesh) for 3D is analyzed. Mapping and placement of cores with thermal constraints on to NoC topologies is presented in [29]. However, none of these works address the issue of synthesizing applicationspeciﬁc 3D NoC topologies. 3. DESIGN APPROACH The approach used for topology synthesis is presented in Figure 1. In the core speciﬁcation ﬁle, the name of the different cores, the sizes and positions are obtained as inputs. The assignment of the 243 3A-2 Figure 2: Communication graph example Figure 3: LPGs for the two layers Figure 4: Two min-cut partitions of LPGs is represented by bwi,j and the latency constraint for the ﬂow is represented by lati,j . We deﬁne the Local Partitioning Graph for each layer: D E FIN I T ION 3. A local partitioning graph, LPG(Z , M , ly ), is a directed graph, with the set of vertices represented by Z and edges by M . Each vertex represents a core in the layer ly . An edge connecting two vertices is similar to the edge connecting the corresponding cores in the communication graph. The weight of the edge (mi , mj ), deﬁned by hi,j , is set to a combination of the bandwidth and the latency constraints of the trafﬁc ﬂow from core mi to mj : hi,j = α × bwi,j /max bw + (1 − α) × min lat/lati,j , where max bw is the maximum bandwidth value over all ﬂows, min lat is the tightest latency constraint over all ﬂows and α is a weight parameter. For cores that do not communicate with any other core in the same layer, edges with low weight (close to 0) are added between the corresponding vertices to all other vertices in the layer. This will allow the partitioning process to still consider such isolated vertices. The LPGs for the two layers of the communication graph from Figure 2 are shown in Figure 3. Since the LPGs are built layer by layer, the graphs for the two layers are independent of one another. Extra edges with low weights are added (dotted edges in the ﬁgure) from the vertices that have no connections to the other vertices of the LPG. The algorithm for establishing core to switch connectivity is presented in Algorithm 1. As the number of input/output ports of a switch increases, the maximum frequency of operation that can be supported by it reduces, as the combinational path inside the crossbar and arbiter increases with size. In the ﬁrst step of the algorithm, for the required operating frequency of the NoC, the maximum size of the switch (denoted by max sw size) that can support that frequency is obtained as an input. Based on this and the number of cores in each layer, in the next steps (2-4), we determine the minimum number of switches needed in each layer. Then the local partitioning graph for each layer is built. Then, the number of switches in each layer is incremented (starting from the initial count calculated in steps 2-4) every iteration, until it equals the number of cores in the layer. The term |LP G(Z, M , j )| represents the number of cores in layer j . For each switch count, that many min-cut partitions of the LPG of the layer are obtained (step 13). The cores in the same partition are connected to the same switch. Two min-cut partitions of the LPGs of Figure 3 are shown in Figure 4. Once the partitions for all the layers are obtained, the cores in a partition are attached to the same switch and hence the core to switch connectivity is obtained. The next step is to determine switch to switch connectivity, by ﬁnding paths for the inter switch trafﬁc ﬂows. This is explained further in the next section. 244 Algorithm 1 Core-to-switch connectivity 1: Obtain maximum switch size max sw size for current fre2: for each layer j ∈ 1 · · · lr do quency 3: 4: end for 5: Build LP G(Z, M , j ) for each layer j . for each layer j ∈ 1 · · · lr do nij = (cid:4) number of cores in layerj /max sw size(cid:5) 6: for i = 0 to max∀j∈1···lr {|LP G(Z, M , j )| − nij } do if nij + i ≤ |LP G(Z, M , j )| then np = nij + i np = |LP G(Z, M , j )| 7: 8: 9: 10: 11: 12: end if 13: Obtain np min-cut partitions of LPG(Z,M,j) end for 14: 15: Compute paths for inter-switch ﬂows (Section 5). 16: If valid paths found, save the current design point 17: end for else 5. PATH COMPUTATION The procedure to establish physical links and paths for trafﬁc ﬂows is based on the power consumption increase and latency in using the link. This cost computation in the 3D case is similar to the 2D case, such as those presented in [14], [17], but it needs to account for the max ill and max switch size constraints. Here, we do not show the entire path computation algorithm, but only present the steps needed to meet these constraints. In [14], [17], the authors present methods to remove both routing and messagedependent deadlocks when computing the paths. We also use the methods to obtain paths that are free of deadlocks. D E FIN I T ION 4. Let nsw be the total number of switches used across all the layers and let layeri be the layer in which switch i is present. Let ill(i, j ) be the number of vertical links established between layers i and j . Let the switch size inpi and switch size outi be the number of input and output ports of switch i. Let costi,j be the cost of establishing a physical link between switches i and j . In Algorithm 2, we show the use of hard and soft thresholds when evaluating the cost of establishing a physical link between switches i and j. In steps 3, 4, we assign a cost of INF for establishing a link across switches in non adjacent layers and for switches in layers that have reached the maximum vertical link (max ill) threshold. To ensure meeting the maximum link constraint, we assign a very high cost (denoted by SOF T IN F ) for establishing links between switches that are in layers having vertical links close to the max ill value, denoted by sof t max ill (steps 5, 6). From experiments, we found that a reasonable value for SOF T IN F to be 10 times the maximum cost of any ﬂow and sof t max switch ill to be few (2 to 3) links less than max ill value. We use a similar technique to meet the maximum switch size constraints (steps 10-12). By using these softer constraints ﬁrst, we facilitate the path computation procedure to determine valid paths when compared only using the hard constraints. weighted by their bandwidth values, so that higher bandwidth links are shorter than lower bandwidth ones. Formulating the objective function mathematically, we get: P P P P obj = + ∀i ∀i ∀k coredisti,k ∗ bw sw2corei,k ∀j swdisti,j ∗ bw sw2swi,j 3A-2 (3) (4) Algorithm 2 CHECK CONSTRAINTS(i,j) 1: for i = 1 to nsw do 2: for j = 1 to nsw do 3: if |layeri − layerj | ≥ 2 or ill(layeri , layerj ) ≥ max ill then else if |layeri − layerj | = 1 and ill(layeri , layerj ) ≥ costi,j = IN F sof t max ill then costij = SOF T IN F else if switch size inpi + 1 ≥ max switch size or switch size outj + 1 ≥ max switch size then costi,j = IN F else if switch size inpi + 1 ≥ sof t max switch size or switch size outj + 1 ≥ sof t max switch size 4: 5: 6: 7: 8: 9: costi,j = SOF T IN F then 10: 11: end if 12: end for 13: end for When paths are computed, if it is not feasible to meet the max switch size constraints, we introduce new switches in the topology that are used to connect the other switches together. These indirect switches help in reducing the number of ports needed in the direct switches. Due to space limitations, in this paper, we do not explain the details of how the indirect switches are established. 6. SWITCH POSITION COMPUTATION Once a topology for a particular switch count is obtained, the next step is to ﬁnd the latency and power consumption on the wires. In order to do this, based on the input positions of the cores, the optimal position of the switches needs to be determined. For this, we model the problem as a Linear Program (LP) [34]. Let us consider a topology with nsw switches. We denote the co-ordinates of a switch i by (xsi , ysi ), ∀i ∈ 1 · · · nsw . The goal of the LP is to determine the values of xsi and ysi , for all switches in the particular topology. The sum of the Manhattan distances between a switch i and a core k is given by: coredisti,k = |xsi − xck | + |ysi − yck | 0 , if switchi connected to corek , otherwise (1) The sum of the Manhattan distances between a switch i and switch j to which it is connected to is given by: |xsi − xsj | + |ysi − ysj | swdisti,j = , if switchi connected to switchj , otherwise 8< : 8< : 0 (2) The above equations can be easily represented as a set of linear equations [34]. Let bw sw2corei,k and bw sw2swi,j be the total bandwidth of trafﬁc ﬂows between switch i and core k and switches i and j , respectively. To minimize the total power consumption of the links, we need to minimize the length of the links 245 The LP for optimization is written as follows: minimize obj subject to E quations 1 − 3 xsi , ysi ≥ 0, ∀i ∈ 1 · · · nsw We use the lp solve package [35] to obtain the optimum solution for the switch co-ordinates. Even for big applications (65 cores, tens of switches), the optimal solution is obtained in few seconds. However, the optimal positions can result in overlap of switches among themselves or with the cores. To remove the overlaps, we use the ﬂoorplanner, Parquet [36], layer by layer. We feed the core and switch positions as an input solution to the ﬂoorplanner. We allow it to move the switches around the cores, maintaining the relative positions of the cores and minimizing the movement of the switches from the optimal positions computed by the LP. We also pipeline long links to support full throughput on the NoC and add Network Interfaces (NIs) to connect the cores to the network. The resulting design is a valid ﬂoorplan of the NoC. 7. EXPERIMENTS AND CASE STUDIES For our experiments, we use the switch and link libraries from [5]. The power consumption and latency numbers of the components of the library are obtained after post-layout analysis. We use 65nm low power technology libraries for the layout studies. For the electrical characteristics of vertical interconnects, we use the models from [33]. To obtain the electrical characteristics, a waferto-wafer bonding technique is used as the underlying 3D integration technology. The vertical links are shown to have an order of magnitude lower resistance and capacitance than a horizontal link of the same dimension. This translates to a traversal delay of less than 10% of clock cycle for 1 GHz operation and negligible power consumption on the vertical links. 7.1 Multimedia SoC case study For experimental case study, we consider a multi-media SoC, Triple Video Object Plane Decoder, that has 38 cores (D 38 tvopd). The communication graph of the benchmark is presented in Figure 5, where each vertex represents a core and the weight on the edge represents the bandwidth between the cores expressed in MB/s. The application is highly heterogeneous in nature, having three independent decoders working in parallel to improve performance. Each decoder has 12 cores organized in a pipeline fashion. There are two extra memories that are shared between the pipelines that serve as input and output buffers. We consider the design implemented on to 3 layers in 3D. The assignment of cores to the different layers and the ﬂoorplan of each layer were done manually, such that the performance and manufacturing constraints (such as thermal issues) are met. The processing cores are placed on the top and bottom layers, so that they are close to the heat sink. The large memory cores are all placed on the middle layer because they produce less heat and because this allows the manufacturer to use an efﬁcient integration process for implementing the memories. The ﬂoorplan of the design (along with the network components synthesized by our procedure) is presented in Figure 7. The data width of the NoC links is ﬁxed to 32 bits, to match the data width of the cores in the design. We allowed the synthesis method to sweep the NoC frequency and obtain NoC design points 3A-2 Figure 5: Communication graph for the D 38 tvopd benchmark Figure 7: Resulting 3D ﬂoorplan with switches for different frequencies. From the resulting design points, we found that the lowest operating frequency (of 500 MHz) resulted in least power consumption for this design. The power consumption of NoC designs synthesized by our procedure for different switch counts, at 500 MHz operation, is presented in Figure 8. In the ﬁgure, we show the core-to-switch link power, the switch-to-switch link power, the switch power and the total power consumption. The plot starts with 5 switches (on x-axis), as the maximum size of a switch to support 500 MHz operation was 11x11 and the top and bottom layers needed 2 switches each (topology shown in Figure 6), as they have more than 10 cores each. Because the number of cores and the communication demand on each layer is different, we obtain different number of switches on each layer. Since the area of each 3D layer is small (approximately 20 mm2 ), the links are short and switch power has higher impact on the total power consumption. With increasing switch count, the switch power increases signiﬁcantly, leading to higher power consumption. For this design, the NoC with 5 switches is most power optimal and the resulting ﬂoorplan is shown in Figure 7. Figure 6: Most power-efﬁcient topology ) W m ( n o i t p m u s n o c r e w o P 120 100 80 60 40 20 0 5 Switch power Core−to−switch link power Switch−to−switch link power Total power 10 15 20 Switch count 25 30 35 Figure 8: Power consumption 7.1 and ﬁve other benchmarks that model different trafﬁc scenarios. We consider 3 benchmarks: D 36 4, D 36 6 and D 36 8 with 36 cores, each core communicating to 4, 6 and 8 other cores, respectively, modeling designs with multiple local memories. We also consider a benchmark with shared memory bottleneck communication (D 35 bot). For a larger design, we performed tests on the D 65 pipe which has 65 processing elements distributed on three layers and organized in a pipeline fashion. All of the benchmarks are mapped on to 3 layers in 3D. We compared the custom topologies generated for the bench marks against an optimized mesh topology. For the optimized mesh each core is connected to a switch and only the necessary links among switches are opened. The results of the comparison between the best custom topology and the optimized mesh are presented in Figure 9. As can be seen from results, the topology synthesized by our method results in large power savings (38% on average) when compared to the optimized mesh topologies. The synthesized topologies also resulted in 24.5% reduction in average zero-load latency, when compared the optimized mesh based NoC. 7.2 Comparisons with mesh Custom topologies that match the application characteristics can result in large power-performance improvement when compared to the standard topologies, such as mesh and torus [17]. For this comparison we used the D 38 tvopd benchmark presented in Section 7.3 Impact on inter-layer link constraint Limiting the number of inter-layer links has a great impact on power consumption and average latency. Reducing the number of TSVs is desirable for improving the yield of a 3D design. However, a very tight constraint on the number of inter-layer links can 246     ) W m ( n o i t p m u s n o c r e w o P 400 350 300 250 200 150 100 50 0 3D Application specific 3D Opt−mesh D_36_4 D_36_6 D_36_8 D_35_bot D_65_pipeD_38_tvopd 240 230 220 210 200 190 180 ) W m ( n o i t p m u s n o c r e w o p m u m i n i M 170 10 3A-2 3.7 3.65 3.6 3.55 3.5 ) s e l c y c ( y c n e t a l m u m i n i M 11 12 13 14 15 16 Maximum number of inter−layer links (max_ill) 17 18 3.45 10 11 12 13 14 15 16 Maximum number of inter−layer links (max_ill) 17 18 Figure 9: Comparisons with mesh Figure 10: Impact of max ill on power Figure 11: Impact of max ill on latency lead to a signiﬁcant increase in power consumption. To see the impact of the constraint, we varied the value of max ill constraint and performed topology synthesis for each value, for one of the benchmarks (D 36 4). The power and latency values for the different max ill design points are shown in Figures 10 and 11. The dotted line in the ﬁgures represent points where the max ill constraint was too tight to produce any feasible topologies. When there is a tight constraint on the inter-layer links, more ﬂows are routed through existing inter-layer links instead of opening new ones. This leads to traversing more intermediate switches and higher switch activities, leading to higher latency and power consumption. Please note that our synthesis algorithm also allows the designers to perform such power, latency trade-offs for yield, early in the design cycle. The synthesis algorithm explores a large solution space. However, thanks to the efﬁcient heuristic methods presented, the entire topology design process completed in few hours for all the experiments, when run on a 2 GHz Linux workstation. Please note that the synthesis process is performed once at design time and this computational time incurred is negligible. 8. ACKNOWLEDGEMENTS This work is supported by the Swiss National Science Foundation (FNS, Grant 20021-109450/1). 9. CONCLUSIONS The use of Networks on Chips (NoCs) for communication in 3D chips has posed new opportunities and challenges for designers. One of the most important problems is to design the most powerperformance efﬁcient NoC topology that satisﬁes the application characteristics and 3D technology requirements. In this work, we presented a synthesis approach to solve this problem. We also presented methods to place switches optimally on the 3D ﬂoorplan, so that accurate power and delay numbers are obtained for the wires. Our detailed comparisons with regular 3D optimized mesh show that the custom 3D topologies lead to a large reduction in interconnect power consumption. In future, we plan to explore tuning the link data widths to meet the TSV constraints and to improve the yield of the 3D NoCs. 10. "
2006,Design of On-chip and Off-chip Interfaces for a GALS NoC Architecture.,"In this paper, we propose the design of on-chip and off-chip interfaces adapted to a globally asynchronous locally synchronous (GALS) network-on-chip (NoC) architecture. The proposed on-chip interface not only handles the resynchronization between the synchronous and asynchronous NoC domains, but also implements NoC communication priorities. This design is based on existing multi-clock synchronization fifos based on Gray code, and is adapted to standard implementation tools. Concerning Off-chip communications, a new concept of mixed synchronous/asynchronous dual mode NoC port is proposed as an efficient off-chip NoC interface for NoC-based open-platform prototyping. These interfaces have been successfully implemented in a 0.13mum CMOS technology",
2013,Elevator-First - A Deadlock-Free Distributed Routing Algorithm for Vertically Partially Connected 3D-NoCs.,"In this paper, we propose a distributed routing algorithm for vertically partially connected regular 2D topologies of different shapes and sizes (e.g., 2D mesh, torus, ring). The topologies that are the target of this algorithm are of practical interest in the 3D integration of heterogeneous dies using Through-Silicon-Vias (TSVs). Indeed, TSV-based 3D integration allows to envision the stacking of dies with different functions and technologies, using as an interconnect backbone a 3D-NoC. Intrinsically, 3D topologies have better performances, but yield and active area (and thus the cost) are function of the number of TSVs; therefore, the designs tend to use only a subset of available TSVs between two dies. The definition of blockage free and low implementation cost distributed deterministic routing on this kind of topology is thus of theoretical and practical interests. We formally prove that independently of the shape and dimensions of the planar topologies and of the number and placement of the TSVs, the proposed routing algorithm using two virtual channels in the plane is deadlock and livelock free. We also experimentally show that the performance of this algorithm is still acceptable when the number of vertical connections decreases.","IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 609 Elevator-First: A Deadlock-Free Distributed Routing Algorithm for Vertically Partially Connected 3D-NoCs F lorent ine Dubo is , Abbas She ibanyrad, Fre´ de´ r ic Pe´ tro t, and Maryam Bahman i Abstract—In this paper, we propose a distributed routing algorithm for vertically partially connected regular 2D topologies of different shapes and sizes (e.g., 2D mesh, torus, ring). The topologies that are the target of this algorithm are of practical interest in the 3D integration of heterogeneous dies using ThroughSilicon-Vias (TSVs). Indeed, TSV-based 3D integration allows to envision the stacking of dies with different functions and technologies, using as an interconnect backbone a 3D-NoC. Intrinsically, 3D topologies have better performances, but yield and active area (and thus the cost) are function of the number of TSVs; therefore, the designs tend to use only a subset of available TSVs between two dies. The definition of blockage free and low implementation cost distributed deterministic routing on this kind of topology is thus of theoretical and practical interests. We formally prove that independently of the shape and dimensions of the planar topologies and of the number and placement of the TSVs, the proposed routing algorithm using two virtual channels in the plane is deadlock and livelock free. We also experimentally show that the performance of this algorithm is still acceptable when the number of vertical connections decreases. Keywords—3D Integration, network-on-chip (NoC), routing algorithm, deadlock freedom 1 INTRODUCTION Ç THREE-DIMENSIONAL integration leads to a drastic increase in transistor density by vertically stacking multiple dies with a dense and high-speed die-to-die interconnection [1]. It results in a considerable reduction in the length and the number of long global wires which are the dominant factors on delays and power consumption, and allows stacking dies of different technologies (e.g., DRAM, CMOS, MEMS, RF) in a single package. ThroughSilicon-Via (TSV) is the most promising among the vertical interconnect technologies as it has the potential to offer the greatest vertical interconnect density and features an extremely small interwafer distance. The incorporation of the third dimension in the design of the integrated systems allows the use of 3D Networks-on-Chip (3DNoCs) [2]; thus, the exploitation of 3D topologies [3] which result in a ma jor improvement in the network performance [4] . Supposing a NoC with a complete 3D-Mesh topology, the number of vertical channels is equal to 2ðN   3 Þ, where N is the N 2 number of network nodes. As generally each channel of a NoC consists of tens and even in some architectures hundreds of physical wire links, such a network with a large number of nodes requires a huge number of physical vertical interconnections. Even though 3D Integration introduces a whole new set of application possibilities, the use of TSVs also introduces two new architecture level design issues. First, the TSV interconnect pitch (mainly due to its pads) imposes a larger area overhead than the p ﬃﬃﬃﬃﬃﬃﬃ . The authors are with the TIMA Laboratory, CNRS/Grenoble-INP/UJF, SLS team, 46, avenue Fe´lix Viallet, GRENOBLE Cedex 38031, France. E-mail: {florentine.dubois, abbas.sheibanyrad, frederic.petrot, maryam.bahmani}@imag.fr. corresponding horizontal wires and a TSV consumes all layers in the upper die in addition to the top layer in the lower die. Second, fabricating a 3D integrated circuit using TSV technology involves several extra and costly manufacturing steps, and each extra step adds a risk for defects, resulting in potential yield reduction. The yield is an exponential function of defect frequency and the number of TSVs, and thus, exponentially decreases when the number of TSVs goes beyond a certain value. As the approach can be cost effective only for very high yields, looking for cost efficiency introduces a significant tradeoff between the great benefit of exploiting high-speed, short-length, vertical TSV interconnects, and a serious limitation on the number of them that should (could) be fabricated. Another problem may be the topology heterogeneity of different tiers of a 3D chip. As said, 3D Integration enables the integration of differently fabricated dies with different technologies. Keeping a homogeneous topology (the same size and shape) for all tiers of such chips and using a regular 3D network topology (e.g., fully connected cube) is extremely hard and probably often impossible. In order to support the network topology heterogeneity of tiers and reduce the number of vertical links (TSVs) used by the network, we focus here on a vertically partially connected 3D-NoC in which the usual planar topologies (normally regular and fully connected) are partially connected together by only some vertical links and each tier could have its own planar topology independent from other tiers. We thus consider two types of routers: 2D routers with the switch degree required by their corresponding planar topology (e.g., 5 in 2D meshes) and 3D routers with a maximum of two additional degrees (connected to the coplanar neighbors, plus other neighbor routers placed in the upper and/or lower stages). The goal is not to determine some fixed places for 3D-Routers to construct a fixed 3D Topology, but to give the system designer flexibility in arranging 2D and 3D routers in any order and any combination as he decides. This flexibility gives the system designer the opportunity to find the best convenient technology and topology for each tier and to find the most appropriate places for vertical links. In other words, the aim is to have no hypothesis and no constraint on the location and connection of vertical links: any node of a tier can be connected to any node of the upper or lower stage. See Fig. 1. In such irregular 3D topologies, the main problem is to define the packet routing strategy (i.e., selecting a path in the network between a source and a destination), as the usual simple algorithmic routings are not applicable. Routing strategies have to provide different guarantees, mainly the freedom from blockage. Deadlock, the situation in which two or more packets are each waiting permanently for another to release a shared channel in a circular dependency, is the most critical blockage. While developing a deadlock-free routing algorithm in regular topologies is well understood, proposing a distributed deadlock-free routing strategy parameterized by the topology and applicable in irregular topologies is a difficult research topic. We propose here a general solution to this issue for the previously detailed topologies. After elaborating on related works in Section 2, in Section 3 we present our deadlock-free distributed routing algorithm (called “elevator-first”) and in Section 4 we prove deadlock and livelock freedoms of the proposed routing strategy when using two virtual channels. We study a specific case and provide some experimental results in Section 5 before concluding in Section 6. 2 RELATED WORKS Manuscript received 13 May 2011; revised 19 Oct. 2011; accepted 29 Nov. 2011; published online 14 Dec. 2011. Recommended for acceptance by R. Marculescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TC-2011-05-0320. Digital Object Identifier no. 10.1109/TC.2011.239. Irregular 2D or 3D NoCs and their associated routing scheme is a widely studied research field, as it offers the possibility to increase system performance and reliability. The majority of the works focus on mesh-based topologies; however, articles dealing with other topologies can be found in the literature [5], [6]. 0018-9340/13/$31.00 ß 2013 IEEE Published by the IEEE Computer Society 610 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 worked on a fault-tolerant adaptive distributed algorithm which creates f-rings composed of fault-free links and routers to bypass convex faulty regions. F-rings are created with only local information and this work has been extended by Kim and Han [20] to handle every region disposition. However, it is proven to be deadlock free in meshes networks with four additional virtual channels when our proposition works with only two. The LogicBased Distributed Routing (LBDR) algorithm [21] is a distributed and implementation-efficient scheme adapted to irregular networks. Routing decisions are taken based on the relative position of current node to the destination and some bits registered locally which define routing possibilities (i.e., possible direction changes). This algorithm is proven to be deadlock free, does not need additional virtual channel and has been extended in [22] to become fault tolerant. However, adapting this strategy to complex arbitrary topologies increases its complexity and inefficiencies may appear in large networks. Flexible Dimension-Order Routing (FDOR) [23] is a distributed routing scheme in irregular mesh-based 2D or 3D topologies. It relies on the alternation of dimension-order routing algorithms (XYZ, ZYX. . . ); this strategy requires very little additional hardware, but is not applicable to arbitrary topologies and the network is assumed to be vertically fully connected. Mejia et al. [24], [25] propose to split the network into several fault-free small regions where a local deadlock-free routing is defined. Their solution uses no additional virtual channel and handles any topology but some optimization algorithms based on the topology are required at segment creation as this technique may greatly affect performance with random segments and routing restrictions. Others examples of distributed routing schemes adapted to irregular topologies can be found in [26], [27], [28]. To complement these works, we propose in this paper a distributed routing algorithm adapted to heterogeneous partially vertically connected 3D mesh. It is suitable independently of vertical link locations and with very little additional hardware. The main contribution of this paper is the formal proof that this algorithm is deadlock and livelock free with two virtual channels. 3 ROUTING IN VERTICALLY PARTIALLY CONNECTED TOPOLOGIES Although our distributed routing algorithm is generic enough to be used in any topology for which it exists a deadlock-free routing algorithm in 2D, among which the stacked mesh topology [31] that is one of the early 3D based proposal, it specifically focuses on the topologies presented in the introduction that we call vertically partially connected 3D-NoCs. Fig. 1 is an example of such networks. As said above, our algorithm is independent of the vertical link locations and connections, and does not require homogeneous network tiers (where all planar networks in all tiers have the same size and the same shape). In the following, for the ease of explanation, we will use the example of 2D meshes and the usual representation ðx; y; zÞ of nodes in such topologies. When the network is heterogeneous, x and y are defined in the local basis of their 2D mesh: we have 0  x < n and 0  y < m, and n and m of each level are independent of n and m of other levels. See Fig. 1. However, every principle that will be presented can be easily adapted to any regular planar topology. Moreover, the routing algorithm is distributed, so, any routing decision is taken locally along the path, only according to the location of the destination (available in the packet header) and the current node which is making the decision. There are two possibilities for routing a packet toward its destination. The first possibility applies to packets for which the source and the destination are on the same tier. The issue is thus reduced to routing in a full regular 2D topology and any deterministic and deadlock-free conventional 2D routing algorithm can be used here. In the following, we will use, along with the example of 2D meshes , the we ll-known deadlock-free Fig. 1. An example of vertically partially connected 3D-NoC. Bartzas et al. directly address the issue of reducing the number of vertical links in 3D-mesh topologies [7]. This work is also one of the most relevant to our work, although it focuses more on the 3D topology aspect than on the routing one. Their idea is to benefit from the advantages of 3D topologies (higher performance and smaller energy consumption) while reducing the area dedicated to vertical links. Several models of vertically partially connected topology are proposed to adapt vertical link locations to the application flows. The authors also propose a routing algorithm based on the utilization of temporary destinations in intermediate layers. However, this work is limited to homogeneous 3D-mesh networks (layers have all the same dimensions) and the vertical link locations are supposed to follow a regular scheme. Thus, our work complements their works as we propose a more general distributed routing scheme which works independently of vertical links location and in heterogeneous topologies. Moreover, we formally prove its deadlock and livelock freedom. Topology-agnostic and fault-tolerant routing schemes are both adaptable to irregular networks (missing links can be assimilated to faulty links). An overview of the issues related to routing in such irregular networks can be found in [8]. The up*/down* routing [9] is a deadlock-free algorithm adapted to arbitrary topologies and which does not require any virtual channel. This strategy relies on the definition of node relative positions according to some predefined routing directions (up/down) and deadlock are avoided as messages use the up direction only before using the down direction. Puente et al. [10] propose an adaptive routing scheme which uses escape virtual channels to break the underlying cycle in deadlock situations. However, both those strategies require lookup tables; this kind of solution is not adapted to large networks as the table size grows as the square of the number of routers. The cost of such tables (in terms of silicon area and power consumption) is not negligible. Moreover, maintaining correct routing paths in the whole network becomes very difficult. Wu and Sheng [11] propose to overcome this issue by reducing routing table sizes with an extension of the up*/down* routing based on a smart node labeling; Borkar et al. also aim to reduce lookup tables by grouping some steps of the routing path in a single information [12]. However, even though those strategies limit table overhead, they still require heavy computation. Silla and Duato [13], Kim [14], Lysne et al. [15] and Fick and Boppana [19] also chose to use lookup tables to route messages in irregular networks. To avoid costly routing tables, a solution is to use distributed routing. In this context, Glass and Ni proposed the turn model in [17], [18]; in this model, deadlocks are prevented by disallowing some turns (i.e., direction changes) and remaining possibilities are used to perform partial adaptivity. This routing scheme is distributed and does not require any virtual channel. However, adaptivity is direction dependent. Chasalani and Boppana [19] IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 611 Fig. 2. Example of Elevator-First routing path in 2D meshes (coordinates next to channels represent the current packet destination). deterministic X-first routing algorithm (by which packets are routed along one dimension at a time) [17], [29]. The second possibility applies to messages whose source and target are on two different tiers. In this case, the usual routing algorithms are not applicable anymore for a vertically partially connected topology, as Z dimension contains few links and the topology is not vertically fully connected. An adapted solution is to bring the situation back to the totally solved first case described above. To perform this, every router statically knows the location of at least two vertical links in its level (one ascending and one descending). This information is assumed to be registered during network configuration in two local registers, so that the routing remains distributed. This strategy may resemble an everyday life example, where we change floors in a building. Normally, there is no stairway between each two vertically adjacent rooms of different stages. Instead, in each floor, there exist some elevators. One who wants to ascend or descend must know the location of the elevator and must go toward the elevator-first, even if the destination is exactly on the top of its room. This analogy inspired us to call our routing algorithm “Elevator-First.” 3.1 Routing Algorithm The routing mechanism is as follows: if a router issues a packet whose destination is on a different tier, it adds a new header to it. This new flit is added before the packet head to hide the original header. It contains two pieces of information: the coordinates of a vertical link (an elevator) in the current tier and a flag (one bit) to point out that the elevator location is not the effective packet target and the present header is not the original header. The location of the vertical link is directly read from a local register. With this new header, the problem becomes identical to planar routing in a fully connected regular 2D topology and no level change is required. Thus, the corresponding conventional planar routing algorithm (e.g., X-First in 2D meshes) can be used to bring the packet to the elevator (the target vertical link). The elevator flag is eventually tested when a router recognizes itself to be the destination. If it is set, the reached node is only a bridge to another level and not the packet final target. The first flit (the elevator header) is then deleted, and the packet is sent through the ascending or descending local vertical link with its original header. Finally, if the elevator flag is not set, the current router is the destination, and thus the packet is consumed. An example of routing from S (1, 2, 0) to D (3, 1, 2) is given in Fig. 2. S first adds a temporary header to the packet targeting an ascending vertical link in level 0. In this example, the elevator location registered in S’s registers is (1, 0, 0). The packet is then routed to this last node using the X-first routing algorithm, and Fig. 3. A deadlock case. sent to the upper tier after the intermediate header is removed. When node (3, 0, 1) in the next level receives the packet, it adds a new elevator header with destination (2, 1, 1) and so the packet is routed toward this vertical link. The Packet eventually arrives at (1, 0, 2), where no intermediate header is used as the destination is in the current tier. Hence, the message is simply sent to its destination. One can notice here that in the second tier it is not the nearest vertical link which is used as the elevator. In effect, the path length is not the only variable to take into account for network performances, and, for example, traffic distribution is also an important factor to choose the corresponding vertical links of each node to ascend or descend. The choice of the association of a router with a vertical link is out of scope of this paper, as it is an optimization problem that depends on many factors which are application and/or technology specific. Our main aim here is to formally prove that our algorithm works and is blockage free. The optimality of vertical channel assignment will not be developed anymore here and is left as a future work. 3.2 Virtual Channels The proposed algorithm is not deadlock free in this form: an example of deadlock is shown in Fig. 3, for 2D-mesh topologies associated with X-First routing (similar examples with any others topologies or routing schemes can be easily found). Here, S1(1, 2, 0) sends a message to D1(3, 1, 1) through the ascending vertical link at (1, 0, 0) and S2(3, 0, 1) sends a message to D2(1, 1, 0) through the descending vertical link at (3, 2, 1). We can notice that links from S1 to D2 and from S2 to D1 are shared by both the routing paths and thus, assuming that router buffers are not infinite and can be full, a deadlock occurs. To provide deadlock freedom, we introduce two virtual channels per physical link in x and y dimensions. No additional virtual channel is used in z dimension. Fig. 4 shows virtual channel locations in the example of vertically partially connected 3D-mesh network. The virtual channel choice is made in the source router and is definitive; a packet never changes the assigned virtual channel during its routing (even if the packet is on the destination tier). Packets are distributed as follows: the first virtual channels on x and y links and ascending vertical links are used by ascending Fig. 4. Zþ and Z  virtual channels distribution in a vertically partially connected 3D-mesh network. 612 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 packets (i.e., packets whose source tier is strictly lower than the destination tier). This virtual network will be called Zþ; it is the one used in the example given in Fig. 2. The second virtual channels on x and y links and descending vertical links are used by descending packets (i.e., packets whose source tier is strictly higher than the destination tier). This virtual network, called Z , is totally independent of Zþ as packets never pass from one virtual channel to the other. The other packets, which have their source and destination in the same level, can choose either Zþ or Z . Algorithm 1 details the Elevator-First routing algorithm when using two virtual channels Zþ and Z . This deterministic algorithm is distributed and needs little additional hardware of only two registers to locate ascending and descending vertical link locations. Moreover, the use of one additional channel (as the second virtual channel) in x and y dimensions is more cost efficient than the use of routing tables, particularly when the network is large. Algorithm 1. Elevator-First Routing using two Virtual Channels @c: current router address @s: source router address @d: destination router address if (@s ¼¼ @c) then // The current router is the source if (the destination is on a lower tier) then - Assign the packet to the virtual network (channel) Z  else if (the destination is on an upper tier) then - Assign the packet to the virtual network (channel) Zþ else // The destination is on the current tier - Randomly assign the packet to either the virtual network (channel) Z  or Zþ end if end if if (@d ¼¼ @c) then if (the elevator flag is set) then // The current router is an elevator node - Remove the packet header - Get the original header (the next flit) Send the packet to the ascending (if the assigned virtual channel is Zþ) or descending (if the assigned virtual channel is Z ) vertical link else // The current router is the final destination - Consume the packet end if else if (The packet destination is in the current tier) then Send the packet to the port determined by the given planar routing algorithm (e.g., X-First in 2D-meshes) else // The packet destination is not in the current tier - Add a new header with the elevator flag set and an address of a vertical link (i.e., elevator) on the current tier (given from local registers) as an intermediate destination Send the packet to the port determined by the given planar routing algorithm (e.g., X-First in 2D-meshes) toward the intermediate destination (i.e., the elevator) end if end if 4 DEADLOCK AND LIVELOCK FREEDOM PROOFS This part gives two theorems and their proofs which show that Elevator-First routing using two virtual channels is deadlock and livelock free. One can also notice that this routing algorithm is connected (i.e., each node is reachable) if all planar routing used in the different layers are connected and if there is at least one vertical channel per tier. The proof is not presented here as it is straightforward. 4.1 Deadlock Freedom Theorem 1. The elevator-first routing algorithm using two virtual channels Zþ and Z  is deadlock free in any vertically partially connected 3D-mesh topology associated with a set of deadlock free and deterministic 2D routing schemes. Proof. This proof is similar to the one used by Glass and Ni in [17] to prove that the turn model is deadlock free; it is based on the work of Dally and Seitz who have shown that an algorithm is deadlock free if the channels in the network can be numbered such as every routing path uses strictly increasing (decreasing) channels [29]. The proof’s main idea is thus to define a function which numbers vertically partially connected 3D-mesh channels such that every possible elevator-first routing path is along strictly increasing numbers, independently of the deterministic and deadlock-free planar routing algorithms used in the different levels. Such a function would prove that the channel dependency graph of the elevator-first algorithm is acyclic and thus that the elevator-first algorithm is deadlock free [29]. As the two virtual networks Zþ and Z  are virtually totally separate and independent, only the proof for deadlock freedom of Zþ is presented with no loss of generality. Let rz be the deterministic deadlock-free planar routing scheme used in level Z. As rz is deterministic and deadlock free, its channel dependency graph contains no cycle [29]. Thus, channels contained in level Z can be numbered such that every possible planar routing path (i.e., given by rz ) is along strictly increasing channels. Let fz be such a numbering function; we suppose that fz is strictly positive without loss of generality. We thus have a set of functions fz which number all planar routing paths in strictly increasing order; this set is then used to define a more general function, which numbers all channels in the network (i.e., including vertical ones). This last function is constructed iteratively, according to the following method: . . At level 0 (at the bottom of the 3D structure), planar channels are directly numbered with the corresponding f0 function. Vertical channels (ascending channels whose source is in level 0) are associated with a (e.g., maxðf0 Þ þ 1). More formally, number strictly greater than all numbers in the plane if c is a channel (planar or vertical) contained in level 0, let g0 be: g0 ðcÞ f0 ðcÞ if c is planar maxðf0 Þ þ 1 if c is vertical: At level z > 0, planar channels are numbered with the corresponding fz function augmented by a constant that we know greater than any number found in lower levels. Vertical channels are associated to a number strictly greater than all the channels in the current tier. Formally, if c is a channel (planar or vertical) contained in level z, let gz be: gz ðcÞ fz ðcÞ þ maxðgz 1 Þ if c is planar maxðfz Þ þ maxðgz 1 Þ þ 1 if c is vertical:         IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 613 Fig. 5. g function construction method, with c0 ; c1 ; c2 ; c3 ; c4 ; c5 an elevator-first routing path. The function g defined by the association of the gz numbers all channels in Zþ; the method used to construct g is illustrated in Fig. 5. We are going to prove in two steps that this function is strictly increasing for every routing path generated by the elevator-first routing algorithm. We will then be able to conclude. First case, Packet’s source and destination are in the same level z: Let c0 ; c1 ; . . . ; ck be a routing path provided by rz . We have: gðciþ1 Þ   gðci Þ ¼ gz ðciþ1 Þ   gz ðci Þ ¼ fz ðciþ1 Þ   fz ðci Þ > 0 by def inition: Any routing path included in a single level increasing. is strictly Second case, Packet’s source and destination are in different levels: We have already proven that paths included in a single layer are strictly increasing; we thus consider here the level change only. Let cz ; v; czþ1 , respectively, be the last planar channel before a level change, the ascending vertical channel and the first planar channel after a level change inside a general routing path. We have: gðvÞ   gðcz Þ ¼ gz ðvÞ   gz ðcz Þ ¼ maxðfz Þ   fz ðcz Þ þ 1 > 0 and gðczþ1 Þ   gðvÞ ¼ gzþ1 ðczþ1 Þ   gz ðvÞ ¼ fzþ1 ðczþ1 Þ þ maxðgz Þ   gz ðvÞ > 0 consequently: gðcz Þ < gðvÞ < gðczþ1 Þ: Those two last steps prove that g numbers channels such that every elevator-first routing path is along strictly increasing channels . We can eventually conclude that the routing algorithm is deadlock free. It is important to notice that this proof does not hold any assumption on vertical link locations and connections, so the algorithm is deadlock free in any vertically partially connected 3D topology. Moreover, one can also notice that this proof does not neither hold any condition on the 2D topologies, and is thus valid for any planar topology associated with a deadlock free and deterministic routing scheme. tu Fig. 6. Number attributed to 2D-mesh channels in function of the node location. 4.2 Livelock Freedom Theorem 2. The elevator-first routing algorithm using two virtual channels Zþ and Z  is livelock free in any vertically partially connected topology. Proof. The proof of Theorem 1 has shown that the output channels of a router have always a higher assigned number than its input channels, and so, every routing path uses strictly increasing numbers. On the other hand, the numbers assigned to the network channels have finite values (produced by function g) as the network dimensions are finite. Consequently, it is sure that the packet will traverse the routers in a finite time and so will get to its destination in a finite number of hops. Consequently, the presented routing algorithm is livelock free. tu 5 APPLICATION TO MESHES We study in this section the application of the elevator-first algorithm to vertically partially connected 3D meshes composed of the popular 2D mesh associated with the X-first routing algorithm. 5.1 Numbering Function This section presents an example of the numbering functions fz and g used in the deadlock-freedom proof for 2D meshes and X-first routing. The network is assumed to be of dimensions n  m  l, where all nodes are represented by a triplet of coordinates (x; y; z) with: 0  x < n; 0  y < m; 0  z < l; For heterogeneous networks (i.e., the 2D meshes do not have the same size), n and m are the size of the corresponding a two-digit number in base b, where b ¼ maxðn; mÞ > 1 (the dimension in the current tier. We assign to every planar channel number in base 10 assigned to the couple ðx; yÞb is x þ yb). We also define two functions: Xb : x ! ðx; 0Þb ¼ x Yb : y ! ð0; yÞb ¼ yb: fz is finally defined as, with (x, y, z) the current node coordinates Xb ðn   xÞ if c ¼ W est Yb ðy þ 1Þ if c ¼ N orth Xb ðx þ 1Þ if c ¼ East Yb ðm   yÞ if c ¼ South: fz ðcÞ ! Fig. 6 illustrates the chosen configuration for assigning these functions to router channels. In any case, the output channel has always a higher number than the input channel for the X-first routing (where routing is first performed along x dimension before going in y dimension), as obviously we have: 8ðx; y; zÞ; Xb ðxÞ < Xb ðx þ 1Þ < Yb ðyÞ < Yb ðy þ 1Þ:         614 IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 Fig. 9. Average latency using localized traffic distribution. but it uses two virtual channels of Zþ and Z , and the elevator of and descending packets into two independent Zþ and Z  networks each node is itself. As it can be observed, separating the ascending has a positive influence on the network performance, as the traffic and consequently the contention probability is divided by 2. To make the comparison a little bit fairer, we have also simulated the ordinary network with larger FIFOs to have the same overall amount of resource as “Uni0” with two VCs. The curve “UniNormLF” presents this case and as can be seen the network performance is better than the case of “UniNorm,” but there exists yet a gap between the performance of “Uni0” and “UniNormLF” even if the buffering resources for the two cases are the same. The curves “Uni5,” “Uni10,” “Uni25,” and “Uni50” are the results when 5, 10, 25, and 50 percent of vertical links are removed, respectively. We have chosen the vertical channels to be removed uniformly (randomly), and in order to have a more uniform distribution of missing vertical connections we have repeated the simulations 20 times. The results shown in the figure are the averages of these 20 simulations. Note that we did not impose any constraints in the selection of vertical links to be removed and in the modeled topologies there might be routers without ascending link, descending link, or both of them. The only point that we have to take into consideration is that in each plane there must be at least one ascending and one descending channels in order to keep the network connected. For nodes with removed link(s), one(two) elevator(s) is(are) selected randomly between the nearest routers in which the corresponding vertical link is not removed. Fig. 9 demonstrates the same simulation results as shown in Fig. 8, but this time for localized traffic distribution [30]. In the localized traffic distribution, the probability of sending packet to a destination decreases exponentially with the destination distance. In other words, with a localized traffic distribution, Fig. 7. Example of number assignation for Zþ (numbers are given in base 10). The function g constructed from the fz defined above is illustrated in Fig. 7 in an example of heterogeneous network. As expected, all elevator-first paths are strictly increasing when the planar routing is X-first. 5.2 Experimental Results In order to study the performance of the Elevator-First routing algorithm, we have developed Cycle-Accurate Bit-Accurate (CABA) SystemC model of routers. Fig. 8 shows the average latencies of a 5  5  5 network versus the flit injection rate (offered load of cores, as the percentage of the maximum possible load, i.e., the number of flits produced by each core in every hundred cycles) in different situations when using uniform traffic distribution (in which each core sends packets uniformly to all other cores with a same probability and a same rate). For these simulations, we used routers with 16-flit deep FIFOs and 16-flit packet size. The curve “UniNorm” presents the average latency of a fully connected 3D-Mesh network when using the ordinary XYZ routing algorithm. The curve “Uni0” presents the average latency using the Elevator-First routing algorithm when 0 percent of vertical channels are removed. It means the network is a fully connected 3D Mesh, Fig. 8. Average latency using uniform traffic distribution. 25 percent randomly chosen missing vertical links. Fig. 10. Average latency using localized traffic distribution for 20 different IEEE TRANSACTIONS ON COMPUTERS, VOL. 62, NO. 3, MARCH 2013 615 [11] [21] Self-Configuring Local Area Network Using Point-to-Point Links,” IEEE J. Selected Areas in Comm., vol. 9, no. 8, pp. 1318-1335, Oct. 1991. [10] V. Puente, J.A. Gregorio, F. Vallejo, R. Beivide, C. Izu, “High-Performance Adaptive Routing for Networks with Arbitrary Topology,” J. Systems Architecture, vol. 52, no. 6, pp. 345-358, June 2006. J. Wu and L. Sheng, “Deadlock-Free Routing in Irregular Networks Using Prefix Routing,” Proc. Int’l Conf. Parallel and Distributed Computing Systems, pp. 424-430, 1999. [12] S. Borkar, R. Cohn, G. Cox, S. Gleason, T. Gross, H.T. Kung, M. Lam, B. Moore, C. Peterson, J. Pieper, L. Rankin, P.S. Tseng, J. Sutton, J. Urbanski, and J. Webb, “iWarp: An Integrated Solution to High-Speed Parallel Computing,” Proc. ACM/IEEE Conf. Supercomputing (Supercomputing ’88), vol. 1, pp. 330-339, Nov. 1988. [13] F. Silla and J. Duato, “High-Performance Routing in Networks of Workstations with Irregular Topology,” IEEE Trans. Parallel and Distributed Systems, vol. 11, no. 7, pp. 699-719, July 2000. [14] Y.B. Kim, “Fault Tolerant Source Routing for Network-on-chip,” Proc. IEEE Int’l Symp. Defect and Fault-Tolerance in VLSI Systems (DFT ’07), pp. 12-20, 2007. [15] O. Lysne, T. Skeie, S.-A. Reinemo, and I. Theiss, “Layered Routing in Irregular Networks,” IEEE Trans. Parallel and Distributed Systems, vol. 17, no. 1, pp. 51-65, Jan. 2006. [16] D. Fick, A. DeOrio, G. Chen, V. Bertacco, D. Sylvester, and D. Blaauw, “A Highly Resilient Routing Algorithm for Fault-Tolerant NoCs,” Proc. Conf. Design, Automation and Test in Europe (DATE), pp. 21-26, 2009. [17] C.J. Glass and L.M. Ni, “The Turn Model for Adaptive Routing,” SIGARCH Computer Architecture News, vol. 20, pp. 278-287, 1992. [18] C.J. Glass and L.M. Ni, “Fault-Tolerant Wormhole Routing in Meshes,” Proc. 23rd Ann. Int’l Symp. Fault-Tolerant Computing, pp. 240-249, 1993. [19] S. Chalasani and R.V. Boppana, “Fault-Tolerant Wormhole Routing Algorithms for Mesh Networks,” IEEE Trans. Computers, vol. 44, no. 7, pp. 848-864, July 1995. [20] S.P. Kim and T. Han, “Fault-Tolerant Wormhole Routing in Mesh with Overlapped Solid Fault Regions,” Parallel Computing, vol. 23, pp. 1937-1962, 1997. J. Flich, S. Rodrigo, and J. Duato, “An Efficient Implementation of Distributed Routing Algorithms for NoCs,” Proc. Second ACM/IEEE Int’l Symp. Networks-on-Chip (NoCS ’08), pp. 87-96, Apr. 2008. [22] S. Rodrigo, J. Flich, A. Roca, S. Medardoni, D. Bertozzi, J. Camacho, F. Silla, and J. Duato, “Addressing Manufacturing Challenges with Cost-Efficient Fault Tolerant Routing,” Proc. Fourth ACM/IEEE Int’l Symp. Networks-onChip (NOCS), pp. 25-32, May 2010. [23] T. Skeie, F.O. Sem-Jacobsen, S. Rodrigo, J. Flich, D. Bertozzi, and S. Medardoni, “Flexible DOR Routing for Virtualization of Multicore Chips,” Proc. Int’l Symp. System-on-Chip (SOC ’09), pp. 073-076, Oct. 2009. [24] A. Mejia, J. Flich, J. Duato, S.A. Reinemo, and T. Skeie, “Segment-Based Routing: An Efficient Fault-Tolerant Routing Algorithm for Meshes and Tori,” Proc. Int’l Parallel and Distributed Processing Symp. (IPDPS), p. 10, 2006. [25] A. Mejia, J. Flich, J. Duato, S.A. Reinemo, and T. Skeie, “Boosting Ethernet Performance by Segment-Based Routing,” Proc. EUROMICRO Int’l Conf. Parallel, Distributed and Network-Based Processing (PDP ’07), pp. 55-62, 2007. [26] M.E. Gomez, N.A. Nordbotten, J. Flich, P. Lopez, A. Robles, J. Duato, T. Skeie, and O. Lysne, “A Routing Methodology for Achieving Fault Tolerance in Direct Networks,” IEEE Trans. Computers, vol. 55, no. 4, pp. 400-415, Apr. 2006. [27] A.A. Chien and J.H. Kim, “Planar-Adaptive Routing: Low-Cost Adaptive Networks for Multiprocessors,” J. ACM, vol. 42, pp. 91-123, 1995. [28] D. Xiang, Y. Zhang, and Y. Pan, “Practical Deadlock-Free Fault-Tolerant Routing in Meshes Based on the Planar Network Fault Model,” IEEE Trans. Computers, vol. 58, no. 5, pp. 620-633, May 2009. [29] W.J. Dally and C.L. Seitz, “Deadlock-Free Message Routing in Multiprocessor Interconnection Networks,” IEEE Trans. Computers, vol. 36, no. 5, pp. 547-553, May 1987. [30] A.Y. Weldezion, M. Grange, D. Pamunuwa, Z. Lu, A. Jantsch, R. Weerasekera, and H. Tenhunen, “Scalability of Network-on-Chip Communication Architecture for 3-D Meshes,” Proc. Int’l Symp. Networks-on-Chip (NoCs), 2009. [31] F. Li, C. Nicopoulos, T. Richardson, Y. Xie, V. Narayanan, and K. Mahmut, “Design and Management of 3D Chip Multiprocessors Using Network-inMemory,” Proc. Ann. Int’l Symp. Computer Architecture (ISCA), 2006. . For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib. cores send more packets to nearer nodes and less to farther ones. As we can see in the figure, even when 10 percent of vertical links are removed the network performance is approximately the same as that of a fully connected 3D-Mesh network using the usual XYZ routing algorithm (i.e., “LocNorm”). Fig. 10 shows the results obtained by the 20 simulations for the case of 25 percent randomly removed vertical links. As it can be seen the variance of the results is significant. This variation reveals the fact that the (x, y, z) coordinates of the unavailable channels can considerably impact the network saturation threshold. Moreover, the choice of elevators for each node, that depends on some parameters among which the traffic distribution, is also very important and can have a great influence on the network performance. We believe that the elevator-first routing algorithm opens appealing questions both in terms of elevator assignment to optimize the traffic metrics, power dissipation, etc., and in terms of microarchitecture implementation for which area, timing, and power tradeoffs are still to be analyzed. 6 CONCLUSION In this paper, we have elaborated on the actual exploitation of two key technologies: 3D Integration and Network-on-Chip. A 3D-NoC needs a huge number of vertical links, while 3D Integration has a major limitation on the number of vertical interconnects (TSVs) to be exploited. Additionally, 3D Integration enables the integration of differently fabricated dies with different technologies, but constructing a homogeneous and regular network topology for such a heterogeneous system is very challenging. In order to reduce the number of vertical links and to propose a network topology suited to the heterogeneity of tiers, we focus on nonregular 3D topologies in which the usual planar topologies are partially connected together by only some vertical links. To route packets in such an irregular network (without any hypothesis or constraint on location and connection of the vertical links), we have introduced the “Elevator-First” distributed routing algorithm, that for the case of deterministic and deadlock-free planar routing schemes we have formally proven to be deadlock and livelock free by using two virtual channels (one for ascending and the other for descending packets). We have also experimentally shown that the network performance is still acceptable when the number of vertical connections decreases, and, for example, for the case of localized traffic distribution with 10 percent missing vertical links the network performance is almost the same as that of a fully connected 3D mesh using usual dimension-ordered routing. "
2009,Crosstalk-Aware Channel Coding Schemes for Energy Efficient and Reliable NOC Interconnects.,"Network-on-chip (NOC) is emerging as a revolutionary methodology to integrate numerous intellectual property blocks in a single die. It is the packet switching-based communications backbone that interconnects the components on multicore system-on-chip (SoC). A major challenge that NOC design is expected to face is related to the intrinsic unreliability of the interconnect infrastructure under technology limitations. By incorporating error control coding schemes along the interconnects, NOC architectures are able to provide correct functionality in the presence of different sources of transient noise and yet have lower overall energy dissipation. In this paper, designs of novel joint crosstalk avoidance and triple-error-correction/quadruple-error-detection codes are proposed, and their performance is evaluated in different NOC fabrics. It is demonstrated that the proposed codes outperform other existing coding schemes in making NOC fabrics reliable and energy efficient, with lower latency.",
2012,HNOCS - Modular open-source simulator for Heterogeneous NoCs.,"We present HNOCS (Heterogeneous Network-on-Chip Simulator), an open-source NoC simulator based on OMNeT++. To the best of our knowledge, HNOCS is the first simulator to support modeling of heterogeneous NoCs with variable link capacities and number of VCs per unidirectional port. The HNOCS simulation platform provides an open-source, modular, scalable, extendible and fully parameterizable framework for modeling NoCs. It includes three types of NoC routers: synchronous, synchronous virtual output queue (VoQ) and asynchronous. HNOCS provides a rich set of statistical measurements at the flit and packet levels: end-to-end latencies, throughput, VC acquisition latencies, transfer latencies, etc. We describe the architecture, structure, available models and the features that make HNOCS suitable for advanced NoC exploration. We also evaluate several case studies which cannot be evaluated with any other exiting NoC simulator.",
2004,Cost considerations in network on chip.,"Systems on Chip (SoCs) require efficient inter-module interconnection providing for the required communications at a low cost. We analyze the generic cost in area and power of Networks on Chip (NoCs) and alternative interconnect architectures: a shared bus, a segmented bus and a point-to-point interconnect. For each architecture we derive analytical expressions for area, power dissipation and operating frequency as well as asymptotic limits of these functions. The analysis quantifies the intuitive NoC scalability advantages.Next we turn to NoC cost optimization. We explore cost tradeoffs between the number of buffers and the link speed. We use a reference architecture, termed QNoC (Quality-of-Service NoC), which is based on a grid of wormhole switches, shortest path routing and multiple QoS classes. Two traffic scenarios are considered, one dominated by short packets sensitive to queuing delays and the other dominated by large block-transfers. Our simulations show that network cost can be minimized while maintaining quality of service, by trading off buffers with links in the first scenario but not in the second.",
2005,Guest Editors' Introduction - The Network-on-Chip Paradigm in Practice and Research.,"The network-on-chip paradigm is an emerging paradigm that effectively addresses and presumably can overcome the many on-chip interconnection and communication challenges that already exist in today's chips or will likely occur in future chips. Effective on-chip implementation of network-based interconnect paradigms requires developing and deploying a whole new set of infrastructure IPs and supporting tools and methodologies. This special issue illustrates how, to date, engineers have successfully deployed NoCs to meet certain very-aggressive specifications. At the same time, the articles reveal many issues and challenges that require solutions if the NoC paradigm will indeed become a panacea or quasi-panacea for tomorrow’s SoCs.",
2005,Fault tolerance overhead in network-on-chip flow control schemes.,"Flow control mechanisms in network-on-chip (NoC) architectures are critical for fast packet propagation across the network and for low idling of network resources. Buffer management and allocation are fundamental tasks of each flow control scheme. Buffered flow control is the focus of this work. We consider alternative schemes (STALL/GO, T-Error, ACK/NACK) for buffer and channel bandwidth allocation in presence of pipelined switch-to-switch links. These protocols provide varying degrees of fault tolerance support, resulting in different area and power tradeoffs. Our analysis is aimed at determining the overhead of such support when running in error-free environments, which are the typical operating mode. Implementation in the timespipes NoC architecture and functional simulation by means of a virtual platform allowed us to capture application perceived performance, thus providing guidelines for NoC designers",
2011,Physical-Layer Modeling and System-Level Design of Chip-Scale Photonic Interconnection Networks.,"Photonic technology is becoming an increasingly attractive solution to the problems facing today's electronic chip-scale interconnection networks. Recent progress in silicon photonics research has enabled the demonstration of all the necessary optical building blocks for creating extremely high-bandwidth density and energy-efficient links for on-chip and off-chip communications. From the feasibility and architecture perspective however, photonics represents a dramatic paradigm shift from traditional electronic network designs due to fundamental differences in how electronics and photonics function and behave. As a result of these differences, new modeling and analysis methods must be employed in order to properly realize a functional photonic chip-scale interconnect design. In this paper, we present a methodology for characterizing and modeling fundamental photonic building blocks which can subsequently be combined to form full photonic network architectures. We also describe a set of tools which can be utilized to assess the physical-layer and system-level performance properties of a photonic network. The models and tools are integrated in a novel open-source design and simulation environment. We present a case study of two different photonic networks-on-chip to demonstrate how our improved understanding and modeling of the physical-layer details of photonic communications can be used to better understand the system-level performance impact.",
2008,Cluster-based Simulated Annealing for Mapping Cores onto 2D Mesh Networks on Chip.,"In network-on-chip (NoC) application design, core-to-node mapping is an important but intractable optimization problem. In the paper, we use simulated annealing to tackle the mapping problem in 2D mesh NoCs. In particular, we combine a clustering technique with the simulated annealing to speed up the convergence to near-optimal solutions. The clustering exploits the connectivity and distance relation in the network architecture as well as the locality and bandwidth requirements in the core communication graph. The annealing is cluster-aware and may be dynamically constrained within clusters. Our experiments suggest that simulated annealing can be effectively used to solve the mapping problem with a scalable size, and the combined strategy improves over the simulated annealing in execution time by up to 30% without compromising the quality of solutions.",
2003,Task-level timing models for guaranteed performance in multiprocessor networks-on-chip.,"We consider a dynamic application running on a multiprocessor network-on-chip as a set of independent jobs, each job possibly running on multiple processors. To provide guaranteed quality and performance, the scheduling of jobs, jobs themselves and the hardware must be amenable to timing analysis. For a certain class of applications and multiprocessor architectures, we propose exact timing models that effectively co-model both the computation and communication of a job. The models are based on interprocessor communication (IPC) graphs [4]. Our main contribution is a precise model of network-on-chip communication, including buffer models. We use a JPEG-decoder job as an example to demonstrate that our models can be used in practice to derive upper bounds on the job execution time and to reason about optimal buffer sizes.",
2004,An asynchronous on-chip network router with quality-of-service (QoS) support.,This paper presents an asynchronous on-chip network router with quality-of-service (QoS) support. The router uses a virtual channel architecture with a priority-based scheduler to differentiate between multiple connections with various QoS requirements sharing the same physical channel. A gate-level prototype of the router has been built and its functionality and performance evaluated. The simulations show that the router is capable of offering a high-level of QoS within the capacity limitations of the network.,
2011,CoQoS - Coordinating QoS-aware shared resources in NoC-based SoCs.,"Contention in performance-critical shared resources affects performance and quality-of-service (QoS) significantly. While this issue has been studied recently in CMP architectures, the same problem exists in SoC architectures where the challenge is even more severe due to the contention of shared resources between programmable cores and fixed-function IP blocks. In the SoC environment, efficient resource sharing and a guarantee of a certain level of QoS are highly desirable. Researchers have proposed different techniques to support QoS, but most existing works focus on only one individual resource. Coordinated management of multiple QoS-aware shared resources remains an open problem. In this paper, we propose a class-of-service based QoS architecture (CoQoS), which can jointly manage three performance-critical resources (cache, NoC, and memory) in a NoC-based SoC platform. We evaluate the interaction between the QoS-aware allocation of shared resources in a trace-driven platform simulator consisting of detailed NoC and cache/memory models. Our simulations show that the class-of-service based approach provides a low-cost flexible solution for SoCs. We show that assigning the same class-of-service to multiple resources is not as effective as tuning the class-of-service of each resource while observing the joint interactions. This demonstrates the importance of overall QoS support and the coordination of QoS-aware shared resources.",
2010,An Analytical Approach for Network-on-Chip Performance Analysis.,"Networks-on-chip (NoCs) have recently emerged as a scalable alternative to classical bus and point-to-point architectures. To date, performance evaluation of NoC designs is largely based on simulation which, besides being extremely slow, provides little insight on how different design parameters affect the actual network performance. Therefore, it is practically impossible to use simulation for optimization purposes. In this paper, we present a mathematical model for on-chip routers and utilize this new model for NoC performance analysis. The proposed model can be used not only to obtain fast and accurate performance estimates, but also to guide the NoC design process within an optimization loop. The accuracy of our approach and its practical use is illustrated through extensive simulation results.",
2007,Applying CDMA Technique to Network-on-Chip.,"The issues of applying the code-division multiple access (CDMA) technique to an on-chip packet switched communication network are discussed in this paper. A packet switched network-on-chip (NoC) that applies the CDMA technique is realized in register-transfer level (RTL) using VHDL. The realized CDMA NoC supports the globally-asynchronous locally-synchronous (GALS) communication scheme by applying both synchronous and asynchronous designs. In a packet switched NoC, which applies a point-to-point connection scheme, e.g., a ring topology NoC, data transfer latency varies largely if the packets are transferred to different destinations or to the same destination through different routes in the network. The CDMA NoC can eliminate the data transfer latency variations by sharing the data communication media among multiple users concurrently. A six-node GALS CDMA on-chip network is modeled and simulated. The characteristics of the CDMA NoC are examined by comparing them with the characteristics of an on-chip bidirectional ring topology network. The simulation results reveal that the data transfer latency in the CDMA NoC is a constant value for a certain length of packet and is equivalent to the best case data transfer latency in the bidirectional ring network when data path width is set to 32 bits.",
2007,A Unified Approach to Mapping and Routing on a Network-on-Chip for Both Best-Effort and Guaranteed Service Traffic.,,
2010,Fault Tolerant Network on Chip Switching With Graceful Performance Degradation.,"The structural redundancy inherent to on-chip interconnection networks [networks on chip (NoC)] can be exploited by adaptive routing algorithms in order to provide connectivity even if network components are out of service due to faults, which will appear at an increasing rate with future chip technology nodes. This paper is based on a new, fine-grained functional fault model and a corresponding distributed fault diagnosis method that facilitate determining the fault status of individual NoC switches and their adjacent communication links. Whereas previous work on network fault-tolerance assume switches to be either available or fully out of service, we present a novel adaptive routing algorithm that employs the remaining functionality of partly defective switches. Using diagnostic information, transient faults are handled with a retransmission scheme that avoids the latency penalty of end-to-end repeat requests. Thereby, graceful degradation of NoC communication performance can be achieved even under high failure rates.",
2006,Improving routing efficiency for network-on-chip through contention-aware input selection.,"The performance of network-on-chip (NoC) largely depends on the underlying routing techniques, which have two constituencies: output selection and input selection. Previous research on routing techniques for NoC has focused on the improvement of output selection. This paper investigates the impact of input selection, and presents a novel contention-aware input selection (CAIS) technique for NoC that improves the routing efficiency. When there are contentions of multiple input channels competing for the same output channel, CAIS decides which input channel obtains the access depending on the contention level of the upstream switches, which in turn removes possible network congestion. Simulation results with different synthetic and real-life traffic patterns show that, when combined with either deterministic or adaptive output selection, CAIS achieves significant better performance than the traditional first-come-first-served (FCFS) input selection, with low hardware overhead (<3%)","Improving Routing Efficiency for Network-on-Chip through  Contention-Aware Input Selection  Dong Wu, Bashir M. Al-Hashimi, Marcus T. Schmitz  School of Electronics and Computer Science  University of Southampton  Southampton, SO17 1BJ, UK  e-mail: {dw, bmah, ms4}@ecs.soton.ac.uk channels may request simultaneously the access of the same  output channel, e.g., packets p0 of input_0 and p1 of input_1  can request output_0 at the same time. The input selection  chooses one of the multiple input channels to get the access.  Whilst the impact of the output selection on routing  efficiency has been investigated [5-7], no explicit work has  been reported on the impact of the input selection, which is  the aim of this paper. The main contribution of this paper is  a novel contention-aware input selection (CAIS), as part of  the routing techniques implemented in switches. With CAIS,  each output channel within a switch observes the contention  level (i.e., the number of request from the input channels,  Section III), and transmits this contention level to the input  channel of the downstream switch. During the input  selection within the downstream switch, CAIS chooses an  input channel depending on the contention levels. Input  channels with higher contention levels get higher priority.  CAIS tries to remove possible network congestion by  keeping the traffic flowing even in the paths with heavy  traffic load, which in turn improves routing efficiency.  Experimental results with synthetic and real-life examples  show that CAIS can be combined with either deterministic  or adaptive output selection, and it is capable of decreasing  Abstract - The performance of Network-on-Chip (NoC) largely  depends on the underlying routing techniques, which have two  constituencies: output selection and input selection. Previous  research on routing techniques for NoC has focused on the  improvement of output selection. This paper investigates the  impact of input selection, and presents a novel contention-aware  input selection (CAIS) technique for NoC that improves the  routing efficiency. When there are contentions of multiple input  channels competing for the same output channel, CAIS decides  which input channel obtains the access depending on the  contention level of the upstream switches, which in turn  removes possible network congestion. Simulation results with  different synthetic and real-life traffic patterns show that, when  combined with either deterministic or adaptive output selection,  CAIS achieves significant better performance than the  traditional first-come-first-served (FCFS) input selection, with  low hardware overhead (<3%).  I Introduction As technology scales and chip integrity grows, on-chip  communication is playing an increasingly dominant role in  System-on-Chip (SoC) design. To meet the performance and  design productivity requirements, Network-on-Chip (NoC)  [1-4] has been proposed as a solution to provide better  modularity, scalability, reliability and higher bandwidth  compared to bus-based communication infrastructures. Fig.  1(a) shows a mesh-based NoC, which consists of a grid of  16 cores. Each core is connected to a switch by a network  interface. Cores communicate with each other by sending  packets via a path consisting of a series of switches and  inter-switch links. For each packet, there are several possible  paths, which directly influence the time needed for delivery.  Therefore, the performance of NoC largely depends on the  underlying routing technique, which chooses a path for a  packet and decides the routing behaviour of the switches.  Fig. 1(b) shows a block diagram of a switch with n+1  input channels and output channels interconnected by a  crossbar. In order to route packets through the network, the  switch needs to implement a routing technique. A routing  technique has two constituencies: output selection and input  selection. A packet coming from an input channel may have  a choice of multiple output channels, e.g., a packet p0 of  input_0 can be forwarded via output_0, output_1 and so on.  The output selection chooses one of the multiple output  channels to deliver the packet. Similarly, multiple input  * This work is supported in part by the EPSRC, UK, under  grant EP/C512804, GR/S95770.  Fig. 1. Block diagram of NoC and switch                                                          packet latency significantly compared to the traditional  first-come-first-served (FCFS) input selection. Furthermore,  the synthesis of prototype switches with CAIS shows low  hardware overhead compared to FCFS.  The rest of paper is organised as follows. Related work is  reviewed in Section II. Section III describes the proposed  contention-aware input selection (CAIS) in detail. The  experiment results and switch implementation are presented  in Section IV. Finally Section V gives the conclusion.  II. Related Work  The idea of NoC is derived from large-scale computer  networks and distributed computing [8, 9]. However, the  routing techniques for NoC have some unique design  considerations besides low latency and high throughput. Due  to tight constraints on memory and computing resources, the  routing techniques for NoC should be reasonably simple [7].  Several switch architectures have been developed for NoC  [10-12], employing XY output selection and wormhole  routing (Section III). In [6], a deflective routing technique is  proposed to avoid network congestion by spreading the  traffic over a larger area. It performs output selection based  on the number of packets being handled in the neighbouring  switches. Packets are forwarded to switches with less traffic  load. The routing technique proposed in [7] is similar to [6]  in terms of acquiring information from the neighbouring  switches to avoid network congestion, but uses the buffer  levels of the downstream switches to perform the output  selection. A routing scheme which combines deterministic  and adaptive routing is proposed in [5], where the switch  works in deterministic mode when the network is not  congested, and switches to adaptive mode when the network  becomes congested. All the routing techniques [5-7] focused  on the output selection. The motivation of this paper is to  investigate the impact of input selection and develop a  simple yet effective input selection, aiming to improve the  routing efficiency with low hardware cost.  III. Proposed Technique  Two  input selections have been used  in NoC,  first-come-first-served (FCFS)  input selection [5] and  round-robin input selection [10, 11]. In FCFS, the priority of  accessing the output channel is granted to the input channel  which requested the earliest. Round-robin assigns priority to  each input channel in equal portions on a rotating basis.  FCFS and round-robin are fair to all channels but do not  consider the actual traffic condition. This section presents a  contention-aware input selection (CAIS) as part of the  routing techniques implemented in switches. CAIS performs  more intelligent input selection by considering the actual  traffic condition, leading to higher routing efficiency.  A. Preliminaries  In this paper we consider NoCs with 2D mesh topology  (Fig. 1(a)). Wormhole switching [9, 13] is employed because  of its low latency and low buffer requirement. In wormhole  switching, a packet is divided into flits for transmission. The  header flit contains the routing information, which is used by  the switches to establish the routing path. The remaining flits  simply follow the path in a pipeline fashion. A flit is passed  to the next switch as soon as enough buffer space is  available to store it, even though there is not enough space to  store the whole packet. If the header flit encounters a  channel already in use, the subsequent flits have to wait at  their current locations and are spread over multiple switches,  thus blocking the intermediate links.  The proposed contention-aware input selection (CAIS,  Section III.B) has been combined with an output selection,  either deterministic or adaptive [5], to complete the routing  function. In this paper, the XY routing [9] is used as a  representative of deterministic output selection for its  simplicity and popularity in NoC. In the XY output selection,  packets are sent first along the X dimension then along the Y  dimension. For example, considering the NoC of Fig. 1(a), a  packet from (0, 3) to (2, 2) will take a path as follows: (0, 3)  (cid:968) (1, 3) (cid:968) (2, 3) (cid:968) (2, 2). The wormhole switching is  sensitive to deadlock [9, 13]. To avoid deadlock, the  minimal odd-even  (OE)  routing  [8]  is used as a  representative of adaptive output selection. In the OE output  selection, a packet chooses a path from multiple alternatives,  but paths with certain turns are prohibited to avoid deadlock.  Considering the previous example again, a packet from (0,  3) to (2, 2) has two alternative paths: (0, 3) (cid:968) (0, 2) (cid:968) (1,  2) (cid:968) (2, 2) and (0, 3) (cid:968) (1, 3) (cid:968) (1, 2) (cid:968) (2, 2). Note  the path (0, 3) (cid:968) (1, 3) (cid:968) (2, 3) (cid:968) (2, 2) is invalid  because an east-south turn is not allowed in the switch  positioned at (2, 3) to avoid deadlock.  B. Contention-Aware Input Selection  To show the influence of input selection and output  selection on the routing efficiency, consider the example of  Fig. 2, which shows a network of switches (cores are  ignored for simplicity). Note the grey scale of the switches  indicates the number of packets waiting at the switches. The  white colour switches have low number of waiting packets,  whilst the grey colour switches have higher number of  waiting packets, and the black colour switche at (2, 2) has  the highest number of waiting packets. To demonstrate the  influence of output selection, consider a packet p0 traveling  from (3, 0) to (0, 2), which has a choice of multiple paths. A  good path would be to avoid the congested area (i.e., the  grey and black switches), as indicated by the dashed line.  This shows a suitable output selection can avoid network  Fig. 2. Motivation of CAIS  congestion. Now consider the input selection. Packets p1 at  (3, 2) and p2 at (4, 3) both want to travel through (3, 3). In  this case, a good choice would be let p1 take the priority to  access (3, 3), because the switch at (3, 2) has more waiting  packets than the switch at (4, 3). Such an input selection  helps reduce the number of waiting packets in congested  areas. This removes possible network congestions and leads  to better NoC performance. Based on this observation, a  contention-aware input selection (CAIS) is developed.  The basic idea of CAIS is to give the input channels  different priorities of accessing the output channels. The  priorities are decided dynamically at run-time, based on the  actual traffic condition of the upstream switches. More  precisely, each output channel within a switch observes the  contention level (the number of requests from the input  channels) and sends this contention level to the input  channel of the downstream switch, where the contention  level is then used in the input selection. When multiple input  channels request the same output channel, the access is  granted to the input channel which has the highest  contention level acquired from the upstream switch. This  input selection removes possible network congestion by  keeping the traffic flowing even in the paths with heavy  traffic load, which in turn improves routing performance.  Fig. 3 illustrates the detailed architecture of a switch with  CAIS. As can be seen, besides wires for data transmission,  CAIS requires additional wires to transmit contention levels  (CLs) between neighbouring switches. The switch has n+1  input channels and output channels. Input channels contain a  buffer to store the incoming flits temporarily before  forwarding them to one of the output channels. The output  selection (OS) module examines the header flit and decides  to which output channel the packet should be passed. The  OS sends an access request to the corresponding output  channel. In an output channel, once it becomes available, the  CAIS module examines the access requests, and sends a  selection signal to the MUX module which accordingly  connects one of the input data signals to the output data  signal. If there is only one access request, the request is  granted. If there are multiple access requests, a selection of  which input channel gets the access has to be made. This  selection mechanism is explained next.  CAIS performs input selection based on the contention  level (CL). The contention level of an output channel is the  number of access request received at a certain time. The CL  of an input channel is acquired from the output channel of  the upstream switch through signal wires. Fig. 4 shows the  algorithm of CAIS, which consists of two processes working  in parallel. Process observe_cl is activated when the status of  req_0..n changes. It observes the number of request to this  output channel (i.e., CL) and puts the CL value at out_cl_i. Then the CL is transmitted to the input channel of the  downstream switch, where the CL will be used to perform  the input selection. For example, considering the switch of  Fig. 3, if input channels 0 and 1 are requesting output  channel 0, then the CL of output channel 0 (out_cl_0) is 2,  and the CL of the input channel of the downstream switch is  also 2. Note that, to avoid high complexity and hardware  cost, CL is only sent to the immediate downstream switches  and is not spread any further. For example, considering the  previous example again, if the CLs of the input channels 0  and 1 (in_cl_0 and in_cl_1) are 3 and 4 respectively, the CL  of output channel 0 is NOT 3+4, but 2. Process select_input is activated when the output channel is available and there  are requests. It examines all requests and the CLs of the  corresponding input channels, and grants the request with  the highest CL.  For the input channels connected to the cores, there are no  upstream switches transmitting CL to them. The CL value is  set to 0 for these input channels. Therefore, the packets  already in the network have higher priority than the packets  waiting to be injected into the network.  Fig. 3. Switch architecture with CAIS  Fig. 4. Pseudo VHDL code of the CAIS algorithm  IV. Experimental Results  Experiments are conducted to evaluate the performance of  the contention-aware input selection (CAIS) and give a  comparison between CAIS and traditional input selections.  Two traditional input selections have been used in NoC,  first-come-first-served (FCFS)  input selection [5] and  round-robin  input  selection  [10, 11]. Due  to  the  advancement of FCFS over round-robin, FCFS is selected to  compare with CAIS. Both CAIS and FCFS are combined  with a deterministic output selection (XY routing [9]) and an  adaptive output selection (OE routing [8]). Four switch  models are developed using VHDL to implement the four  routing schemes: XY+FCFS, XY+CAIS, OE+FCFS and  OE+CAIS. Simulations are carried out on a 6×6 mesh NoC  using these four switch models. As in previous work [5, 8,  14], the performance of the routing scheme is evaluated  through latency-throughput curves. For a given packet  injection rate (i.e., the number of packets injected to the  network per cycle), a simulation is conducted to evaluate the  average packet latency. It is assumed that the packet latency  is the duration from the time when the first flit is created at  the source core, to the time when the last flit is delivered to  the destination core. For each simulation, the packet  latencies are averaged over 50,000 packets. Latencies are not  collected for the first 5,000 cycles to allow the network to  stabilise. It is assumed that the packets have a fixed length of  5 flits and the buffer size of input channels is 5 flits. Since  the network performance is greatly influenced by the traffic  pattern, we applied four different traffic patterns, including  three synthetic traffic patterns (uniform, transpose and hot  spot) and a real-life traffic pattern (GSM voice CODEC).  A. Synthetic Traffic  In the first set of experiments we consider three synthetic  traffic patterns: uniform, transpose, and hot spot [8]. In the  uniform traffic pattern, a core sends a packet to any other  cores with equal probability. In the transpose traffic pattern,  a core at (i, j) only send packets to the core at (5-j, 5-i). In  the hot spot traffic pattern, the core at (3, 3) is designated as  the hot spot, which receives 10% more traffic in addition to  the regular uniform traffic.  Fig. 5 shows the performance of the four routing schemes  under uniform traffic. The X-axis represents the packet  injection rate per node (the packet injection rate for the  whole NoC is 36 times higher), and the Y-axis represents the  average packet latency. As can be seen from the figure, the  four schemes have almost the same performance at low  traffic load (<0.038 packets/cycle). As the traffic load  increases, the packet latency rises dramatically due to the  network congestion. Comparing the curves of OE+FCFS  and OE+CAIS, it can be seen that, using the OE output  selection, CAIS performs significantly better than FCFS.  Similarly, the curves of XY+FCFS and XY+CAIS show that  CAIS also outperforms FCFS when using XY output  selection. As reported in [5, 8], the XY output selection has  better performance than the OE output selection. This is  because  the XY output selection  incorporates global,  long-term information about the uniform traffic, leading to  even distribution of traffic. On the other hand, the OE  routing is based on local, short-term information, which only  benefits the immediate future packets while loses the  evenness of uniform traffic in the long run.  Fig. 6 shows the performance of the four routing schemes  under transpose traffic. It can be seen that FCFS and CAIS  have the same performance when using the XY output  Fig. 5. Routing performance under uniform traffic  Fig. 6. Routing performance under transpose traffic  Fig. 7. Routing performance under hot spot traffic  selection; FCFS works slightly better than CAIS when using  the OE output selection. This is because with transpose  traffic, it is rarely the case that more than one input channels  compete for the same output channel. Therefore, the input  selection policy has little impact on the routing performance.  Fig. 7 shows the routing performance under hot-spot  traffic. Once again, it can be seen that CAIS significantly  outperforms FCFS, either using XY or OE output selection.  Furthermore, although the OE output selection performs  worse than the XY output selection when using the FCFS  input selection, it achieves similar performance as XY when  using the CAIS input selection.  B. Voice CODEC Traffic  To evaluate the performance of CAIS under more realistic  traffic loads, we have conducted simulations using a GSM  voice CODEC [15]. The GSM voice CODEC is partitioned  into 9 cores. The communication trace between the cores is  recorded for an input voice stream of 500 frames (10  seconds of voice). The cores are mapped manually to a 6×6  mesh NoC. Fig. 8 shows the partition and communication  trace of the GSM voice CODEC. As can be seen, the  encoder and decoder are partitioned into core_0 – core_4  and core_5 – core_8 respectively. The directed edges  between the cores represent communications. For example,  the edge between core_0 and core_1 means there is a  communication from core_0 to core_1, the communication  has a size of 320 bytes and occurs at cycle 0. Due to the  space limitation, only communications in the first 1000  cycles are shown. Fig. 8 also shows the mapping of the cores  to the NoC using the dashed lines. The CODEC cores  generate packets according to the recorded communication  trace. The other cores in the NoC generate uniform traffic,  with the same average packet injection rate as the CODEC  cores. The packet injection rate is increased incrementally to  get the latency-throughput curve, which is shown in Fig. 9.  As can be seen, in both cases of using XY and OE output  selection, CAIS achieves better performance than FCFS.  Furthermore, although XY has worse performance than OE  when using FAFS, it achieves similar performance as OE  when the CAIS input selection is used. This observation and  the one obtained from Fig. 7 show that the employment of  CAIS can help the otherwise less effective output selection  when using FCFS catch up with the more effective output  selection. This demonstrates further the importance of input  selection in routing efficiency and the effectiveness of CAIS.  One consideration of CAIS is that some packets may  experience  indefinite waiting. Although  theoretically  possible, it does not happen in the experiments. To give an  insight, Fig. 10 shows the maximum packet latency of the  routing schemes under the GSM voice CODEC traffic. Note  the curves in Fig. 10 are NOT average latency, but the  maximum latency experienced by the packets, thus the  curves show some dips and jumps. As can be seen, when the  network load is low, CAIS has similar maximum packet  latency as FCFS; when the network load is high, CAIS has  shorter maximum packet latency than FCFS. CAIS does not  cause indefinite waiting. The reason is that, due to the  latency introduced by the processing of the header flit, there  is a gap between the access requests of two consecutive  packets. During this gap, one of the packets waiting in input  channels with low contention levels can get the access to the  output channel, thus indefinite waiting is avoided.  Overall, the experiments of Sections IV.A and IV.B have  demonstrated the importance of input selection, which is in  line with that obtained in [14] when applied in distributed  computing. The experiments have also shown that CAIS  Fig. 9. Routing performance under voice CODEC traffic  Fig. 8. Partition, communication trace and core mapping  of a GSM voice CODEC  Fig. 10. Maximum packet latency under CODEC traffic  effectively improves the routing efficiency for NoCs.  C. Implementation of Prototype Switch  To evaluate the area overhead of CAIS and show the  performance/area trade-off, switches with four different  routing schemes have been implemented. The first scheme is  XY+FCFS, i.e., XY output selection and FCFS input  selection. The other  three schemes are XY+CAIS,  OE+FCFS and OE+CAIS. The switches were coded in  VHDL and synthesized with Synplify ASIC using an ST  Microelectronics 0.12 µm standard cell library. For all  switches, the data width is set to 32 bits, and each input  channel has a buffer size of 5 flits. Fig. 11 shows the area  cost of  the four switches. As expected, using  the  deterministic XY output selection and the simple FCFS  input selection, XY+FCFS has the lowest area cost of  0.109725mm2. Due to the relative complexity of the  adaptive OE output selection and the CAIS input selection,  XY+CAIS and OE+FCFS have slightly higher area costs of  0.111480mm2  and  0.110355mm2  respectively,  and  OE+CAIS has the highest area cost of 0.113580mm2. Comparing the area costs of XY+FCFS and XY+CAIS,  CAIS introduces 1.6% additional overhead than FCFS.  Similarly, when comparing OE+FCFS and OE+CAIS, CAIS  introduces 2.9% additional overhead than FCFS.  CAIS requires additional wires to transmit the contention  levels (CLs). In the case of 2D mesh NoC, each switch have  at most 5 input channels, receiving packets from the core  and the 4 neighbouring switches. Thus at most 3 ((cid:203)log25(cid:219)) wires are needed to transmit a CL. This is acceptable  because NoC have abundant wiring resources [3, 4].  Note although this paper has considered mesh-based NoC,  CAIS is flexible enough to support other NoC topologies  including irregular topologies. This can be easily done by  configuring the value of n (Fig. 3 and Fig. 4), and the  number of wires for CL transmission accordingly.  V. Conclusion  This paper has shown the importance of input selection in  routing efficiency, and presented a simple yet effective  contention-aware input selection (CAIS) as part of the  routing techniques implemented in switches. CAIS performs  the input selection considering the contention level of the  upstream switches. By granting busier input channel higher  priority to access the output channel, CAIS keeps the traffic  in busy paths flowing, therefore removes possible  Fig. 11. Area cost of the switches  network congestion. Simulation has been carried out with a  number of different traffic patters, including synthetic traffic  and realistic voice CODEC traffic. The results shows that,  no matter which output selection is used (deterministic XY  routing or adaptive odd-even routing), the proposed CAIS  achieved  better  performance  than  the  traditional  first-come-first-served (FCFS) input selection for most  traffic patters except the transpose traffic, where CAIS has  similar performance as FCFS. Furthermore, the employment  of CAIS can make the XY routing (low complexity and  hardware cost) to achieve similar or even better performance  than the higher complexity and hardware cost odd-even  routing for some traffic patters, i.e., area saving. The  prototype switch with CAIS has been implemented and  shows that CAIS has slight hardware overhead compared to  FCFS (< 3%). As explained in Section IV.B, although not  shown in the experiments, there is a starvation possibility in  CAIS, which remains to be addressed in future work.  "
2005,Dynamic Interconnection of Reconfigurable Modules on Reconfigurable Devices.,"This article presents two approaches to solving the problem of communication between components dynamically placed at runtime on a reconfigurable device. The first is a circuit-routing approach designed for existing FPGAs. This approach uses the reconfigurable multiple bus (RMB). The second, network-based approach targets devices with unlimited reconfiguration capability such as coarse-grained reconfigurable devices. We introduce the dynamic network on chip (DyNoC) as a viable communication infrastructure for communication on dynamically reconfigurable devices. For prototyping the DyNoC on FPGAs, we design and implement an unrestricted communication model for a columnwise-reconfigurable chip. For the DyNoC, as well as for the RMB on chip (RMBoC), we provide algorithms and implementation results from real-life problems.",
2009,The Chip Is the Network - Toward a Science of Network-on-Chip Design.,,
2008,Programming the Intel 80-core network-on-a-chip terascale processor.,"Intel's 80-core terascale processor was the first generally programmable microprocessor to break the Teraflops barrier. The primary goal for the chip was to study power management and on-die communication technologies. When announced in 2007, it received a great deal of attention for running a stencil kernel at 1.0 single precision TFLOPS while using only 97 Watts. The literature about the chip, however, focused on the hardware, saying little about the software environment or the kernels used to evaluate the chip. This paper completes the literature on the 80-core terascale processor by fully defining the chip's software environment. We describe the instruction set, the programming environment, the kernels written for the chip, and our experiences programming this microprocessor. We close by discussing the lessons learned from this project and what it implies for future message passing, network-on-a-chip processors.",
2000,Connecting the Home With a Phone Line Network Chip Set.,"In addition to shared Internet access for PCs, the home network will connect to every consumer electronic device. To make this possible, we must consider robust system requirements, home phone line standards, costs, and implementation of a supporting iline10 chip set.",
2006,Mapping and configuration methods for multi-use-case networks on chips.,"To provide a scalable communication infrastructure for systems on chips (SoCs), networks on chips (NoCs), a communication centric design paradigm is needed. To be cost effective, SoCs are often programmable and integrate several different applications or use-cases on to the same chip. For the SoC platform to support the different use-cases, the NoC architecture should satisfy the performance constraints of each individual use-case. In this work we motivate the need to consider multiple use-cases during the NoC design process. We present a method to efficiently map the applications on to the NoC architecture, satisfying the design constraints of each individual use-case. We also present novel ways to dynamically reconfigure the network across the different use-cases and explore the possibility of integrating dynamic voltage and frequency scaling (DVS/DFS) techniques with the use-case centric NoC design methodology. We validate the performance of the design methodology on several SoC applications. The dynamic reconfiguration of the NoC integrated with DVS/DFS schemes results in large power savings for the resulting NoC systems","Mapping and Conﬁguration Methods for Multi-Use-Case Networks on Chips Srinivasan Murali CSL, Stanford University Stanford, USA smurali@stanford.edu Martijn Coenen, Andrei Radulescu, Kees Goossens Philips Research Laboratories The Netherlands {martijn.coenen,andrei.radulescu,kees.goossens}@philips.com Giovanni De Micheli LSI, EPFL Switzerland giovanni.demicheli@epﬂ.ch To provide a scalable communication infrastructure for SysAB STRACT tems on Chips (SoCs), Networks on Chips (NoCs), a communication centric design paradigm is needed. To be cost effective, SoCs are often programmable and integrate several different applications or use-cases on to the same chip. For the SoC platform to support the different use-cases, the NoC architecture should satisfy the performance constraints of each individual use-case. In this work we motivate the need to consider multiple use-cases during the NoC design process. We present a method to efﬁciently map the applications on to the NoC architecture, satisfying the design constraints of each individual use-case. We also present novel ways to dynamically reconﬁgure the network across the different use-cases and explore the possibility of integrating Dynamic Voltage and Frequency Scaling (DVS/DFS) techniques with the use-case centric NoC design methodology. We validate the performance of the design methodology on several SoC applications. The dynamic reconﬁguration of the NoC integrated with DVS/DFS schemes results in large power savings for the resulting NoC systems. Keywords: Systems on Chips, Networks on chips, UseCases, Multiple application platforms, Dynamic, Reconﬁguration, Voltage Scaling, Frequency Scaling, Guaranteed Throughput, Best Effort. I . INTRODUCT ION As the number of transistors on a chip increases with every technological generation, the number of processor, memory and hardware cores available on the chip also increases. Thus, functionalities that were carried out by several different chips are being integrated on to a single chip, forming a Systems on Chip (SoC). This, coupled together with the increase in the operating speed of the transistors has created the availability of large computational power for such systems. The challenges facing the SoC designer are to efﬁciently tap the available computational power under tight power budgets and meet the tight time-to-market constraints. As the computational loads on the SoC increases, so does the load on the communication architecture. To support the high communication needs of multi-application SoC platforms, scalable on-chip interconnection networks are needed. A communication centric design paradigm, Networks on Chips (NoCs), has been presented to address the interconnect issues 100 MB/s mem1 mem2 100 MB/s 50 MB/s 50 MB/s filter 1 input 50 MB/s filter 2 150 MB/s filter 3 200 MB/s output 50 MB/s mem1 mem2 100 MB/s 50 MB/s 50 MB/s 50 MB/s filter 1 input 50 MB/s filter 2 150 MB/s filter 3 200 MB/s output (a) Use-case 1 (b) Use-case 2 Fig. 1. A fragment of communication for two different use-cases of a set-top box SoC of SoCs [2]-[6]. NoCs provide a scalable communication infrastructure with structured and modular wiring between the components. NoCs also help meet the tight time-to-market constraints, as the scalable architecture can be re-used across multiple platforms. To be cost effective, SoCs are often programmable and integrate several different applications or use-cases on to the same chip. As an example, a SoC for a set-top box has multiple resolution video processing capabilities (like high deﬁnition, standard deﬁnition), multiple picture modes (like split-screen, picture-in-picture), video recording features, high speed internet access and ﬁle transfer services, etc. [9]. Such convergence of multiple use-cases on to the same device is being observed in other electronic devices as well, such as the cell-phone or the personal digital assistant. The different use-cases run on the SoC, although share many of the hardware components, could have very different performance requirements and design constraints for the communication architecture. As an example, we consider a simpliﬁed version of a SoC used in television set-top boxes [9], with support for four different use-cases. The communication bandwidth requirements for some of the connections between the components of the SoC for two of the use-cases are shown in Figure 1. Although we want the NoC to support all the usecases, a NoC that is designed to run exactly one use-case does not necessarily meet the design constraints of the other user cases. In many of the existing NoC design methods, the NoC is designed and optimized for a single use-case or for a single application-trace of the design [10]-[15]. Such a trace based approach captures the characteristics and constraints of a single use-case very well, but fails to capture the multiple usecase scenario. Such a method averages out the communication effects across all the use-cases, which may result in a design that is unacceptable for many use-cases. As an example, when such a method is applied to perform NoC mapping for the settop box SoC, the resulting NoC violates the design constraints of all the four use-cases. Today’s high-end SoCs support several hundred use-cases and manually checking whether the design constraints of the individual use-cases are satisﬁed by the NoC is a tedious process. Moreover, if the NoC design for the use-cases is carried out individually, it is difﬁcult to converge to a single NoC design that satisﬁes the design constraints of all the use cases. In this work we motivate the need to consider the design constraints of the individual use-cases during the NoC design process. We present a design method for mapping of cores on to the NoC, considering the NoC conﬁguration (i.e. path selection and resource reservation in the NoC) as sub-problems during the mapping phase, such that the resulting design satisﬁes the constraints of all the use-cases of the SoC. We then present methods to decrease the required network resources by dynamically reconﬁguring the network across different usecases. We also explore the effect of DVS/DFS techniques for reducing the power consumption of the network across the different use-cases. The methods are validated by performing experiments on several SoC designs. I I . PREV IOU S WORK Several researchers have proposed different architectures and design methodologies for the switches, links and Network Interfaces (NI), which are the major components of a NoC [18, 7, 20, 8]. Design ﬂows that automate many of the steps of the design process have been presented in [17, 19]. In [8], the Æthereal architecture that supports Quality-of-Service (QoS) for applications by using Guaranteed Throughput (GT) connections for trafﬁc streams that has bandwidth/latency constraints and by using Best Effort (BE) connections for the remaining trafﬁc streams is presented. The topology selection process and mapping of applications on to NoC architectures have been explored by many researchers. In [10, 11], branch-and-bound algorithms to map cores on to a mesh NoC topology for different routing functions are presented. In [12, 13], design methods and tools for mapping applications on to regular NoC topologies and automating the topology selection process has been presented. In [16], the methods are extended to consider the QoS constraints during the mapping phase. Building application speciﬁc buses and NoC topologies has been presented in [21, 14]. In [15], a tool that automates the combined mapping and NoC conﬁguration steps for the Æthereal is presented. In all these NoC design works, the design methods assume a single set of communication constraints, which is obtained either for a single application or is obtained from a single trace for multiple applications. In the RAW chip-multiprocessor, the interconnection network connectivity is reconﬁgured with the assistance of the compiler [23]. In the FLEXBUS architecture [22], the authors present methods to dynamically remove the overhead of bridges in multi-bus communication and provide methods Multiple Use cases (design constraints,communication patterns) UC1 UC2 UC3 ... UCn Topology Generation Mapping Path Selection Slot Table Allocation NoC Configuration Traffic Generation RTL Synthesis & Back End NoC Performance Verification SystemC & RTL VHDL NoC Simulation Fig. 2. Design Flow for NoCs Fig. 3. Example input ﬁle with design constraints for an MPEG application where a core can be connected to different buses dynamically. I I I . TH E U S E -CA S E CENTR IC D E S IGN FLOW In this section we present the NoC design ﬂow with the support for multiple use-cases integrated in to the ﬂow (Figure 2). The NoC design ﬂow and the mapping algorithms for the NoC for a single use-case were presented in [15, 17]. In this work, we extend the tool chain to support the multiple use-case scenario that is commonly encountered in SoCs. The communication design constraints for the different use-cases of the SoC are input to the design ﬂow in the excel and xml ﬁle formats. The communication design constraints for each use-case includes the required bandwidth for various connections between the cores in the use-case, the maximum latency allowed for the connection, the QoS level required for the connection (like GT or BE), etc. An example fragment of the input ﬁle is presented in Figure 3. With the different use-cases as input, in the ﬁrst two phases of the design ﬂow, the topology exploration and mapping of the use-cases on to the NoC are performed. The NoC conﬁguration phase in which path selection and TDMA slot-table allocation (required for the GT trafﬁc) are performed, is integrated with the mapping phase. The RTL level VHDL and SystemC models for the resulting NoC conﬁguration are then automatically generated, which can then be simulated. The performance of the NoC can also be veriﬁed in parallel by the automatic performance veriﬁer, which analytically checks whether the design constraints are met. The extension of the tool chain to support multiple use-cases is performed in a modular fashion without affecting most of the existing ﬂow. As the multi-usecase NoC design methods are integrated with the tool chain, performance validations of the methods can be easily carried out to analyze the efﬁciency of the design methods. IV. TH E MA P P ING ALGOR ITHM In this section, we ﬁrst present the mapping algorithm for a single use-case and then present methods to extend the algorithm for multiple use-cases. A.MappingAlgorithmforsingleuse-case The mapping algorithm for a single use-case is presented in detail in [15]. In this sub-section, we only present a brief version of the algorithm highlighting the major phases. As in general, graph mapping is a NP-Hard problem [10, 13], a heuristic algorithm is used to perform the mapping. The selection of paths for the different trafﬁc ﬂows and the reservation of TDMA slot-table entries for the GT trafﬁc ﬂows are uniﬁed with the mapping process. The mapping algorithm is presented in Algorithm 1. At the outermost level of the algorithm, a NoC topology is generated. In the outer loop, the size of the topology is increased until a feasible mapping is obtained in the subsequent phases. Initially, all the cores of the SoC are unmapped. In the ﬁrst step of the mapping algorithm, the trafﬁc ﬂows between the communicating cores are sorted in a non-increasing order. Then for each ﬂow in the order, the source and destination cores of the ﬂow, if they are not already mapped, are mapped on to the NoC. When performing the mapping of these cores, the path with the least cost that satisﬁes the bandwidth and latency constraints for the ﬂow is chosen and the cores are mapped to the NIs in the path. A path is assumed to originate from a NI, traverse one or more switches and terminate in a NI. The cost of the path is a combined metric that considers an afﬁne combination of the latency and bandwidth requirements for the ﬂow. The slot-table reservation for the ﬂow is also carried out in this step. The procedure is repeated for all the ﬂows in the SoC. The approach also takes in to account the possibility of multiple cores sharing a single NI for communication. Note that once the initial mapping step is performed, the solution space can be explored by considering swapping of vertices using simulated annealing or tabu search, as performed in [16]. Algorithm 1 Mapping Algorithm for a single use-case OUTERLOOP: Generate a NoC topology. 1. Sort the trafﬁc ﬂows between the cores in a nonincreasing order of the bandwidth requirements. 2. For each ﬂow in order: a. Choose a least-cost path for the ﬂow that satisﬁes the bandwidth, latency constraints. b. If the source or destination cores of the ﬂow are not yet mapped, map them on to the NIs in the path. c. Reserve the required bandwidth across the ports and reserve the slot-table entries for the ﬂow. If the resulting mapping violates design constraints, increase the size/resources of the topology and go to OUTERLOOP. We refer the interested reader to [15] for the time complexity of the algorithm, details of path selection, other optimizations carried out and for the performance evaluation of the algorithm for several SoC designs. B.MappingDesignApproachforMultipleUse-cases When the SoC has multiple use-cases, we assume that all of the use-cases utilize the same mapping of cores on to the NoC components. This is because, if each individual use-case has a different mapping, then each core potentially needs to be connected to several different NIs, which may not be feasible because of physical layout restrictions and wiring complexity. A direct extension of the single use-case mapping algorithm to support multiple use-cases would be to perform the mapping for the most communication intensive use-case and reuse the mapping for the other use-cases. However, as the design constraints of the use-cases can be very different, such a method may result in a mapping that does not satisfy the performance constraints of many of the use-cases. As an example, when such an approach is applied to the SoC considered in section I, the resulting NoC design satisﬁes only 2 of the 4 use-cases. We use the following design method to extend the mapping design procedure for multiple use-cases (Figure 4(a)). In order to obtain a mapping that satisﬁes all the use-cases, we construct a synthetic Worst-Case (WC) use-case from the given set of input use-cases. For the communication ﬂow between every pair of cores, the maximum required bandwidth values and the minimum required latency values for the ﬂow across all the use-cases are selected and used in the WC use-case. A small example is presented in Figure 4(b). Thus the design constraints of all the individual use-cases are subsumed in the WC use-case and any NoC design that satisﬁes the constraints in the WC use-case will satisfy the constraints of each individual use-case. The WC use-case is then used for the mapping process. Due to the manner in which the WC use-case is constructed, the selected paths and slot-table allocations from the mapping process will satisfy the design constraints of each individual use-case. Once the mapping is obtained from the WC use-case, we perform an optimization step, where we ﬁx the mapping that is obtained from the WC use-case, but re-run the path selection and slot-table reservation phases individually for each usecase. We perform this for two reasons. First, the WC use-case had the worst case constraints from each use-case and by rerunning the path selection and slot-table reservation steps and choosing the maximum values from the individual use-cases we can reduce the NoC resources, while still satisfying the constraints of all the use-cases (experimental evidence presented in Section VI A). Second, when the conﬁguration time between the use-cases is large, the frequency and voltage of operation of the NoC can be scaled to match each individual use-case, which can result in signiﬁcant power savings for the system. In general, when the paths and slot-tables used by the different use-cases are different, we need mechanisms to store them in memory and load them on to the network dynamically or compute them on the ﬂy for the use-case. This is explored in the next section. V. DYNAM IC RECON FIGURAT ION O F TH E NOC For most SoC designs, when the system switches between use-cases, some conﬁguration time is needed for loading the Multiple Use cases UC1 UC2 UC3 ... UCn Generate the worst case (WC) use case Topology generation and Mapping Path Slot Table Selection Allocation Opimize path selection,  slot table allocation for  each use case Integrate DVS/DFS techniques NoC generation <160 MB/s, 2900 cycles> Core 1 UC1 core 3 < 1 5 0 M Core 2 B /s, 3 0 0 0 c y cles > <170 MB/s, 3000 cycles> Core 1 B /s, 2 8 0 0 c y cles > UC2 Core 2 core 3 < 1 6 0 M <170 MB/s, 2900 cycles> Core 1 WC12 Core 2 B /s, 2 8 0 0 c y cles > core 3 < 1 6 0 M (a) Multi use-case mapping design ﬂow (b) Example of WC use-case constraints generation Fig. 4. Multi use-case mapping ﬂow and WC use-case generation new use-case. This is mostly attributed for loading the use-case data and code, sending control signals to different parts of the design and for gracefully shutting down the already running use-case. In many designs, this use-case switching time is of the order of few milli-seconds. This conﬁguration time can be utilized by the NoC for switching to a different path and slot-table allocation for the mapping. This time delay can also be utilized to vary the clock frequency/voltage of the NoC to match the use-case performance level. In the Æthereal architecture [8], a static path routing scheme is used, where the paths are selected at the source NI of the trafﬁc ﬂow. Thus, the NIs maintain the path and slot-tables for the various connections. When the paths and slot-tables used by the NIs vary across different use-cases, the tables need to be stored in memory. As the on-chip memory available is mostly limited and as the use-case switching time is large, we use the off-chip memory to store the paths for the different use-cases. We investigated the overhead for the reconﬁguration mechanism for the set-top box SoC. The amount of data required to store the path and slot-table information for each use-case is around 560 Bytes. With 4 use-cases, the memory requirement for the reconﬁguration mechanism is 2.24 KB. The time required to load the data from the memory and spread it around the NoC for an use-case is of the order of micro-seconds and the energy dissipation is of the order of micro-Joules. Using traditional mechanisms to scale the frequency and voltage of the system may require few milliseconds for conﬁguration. Thus we can envision three different ways of NoC operation. First, when the use-cases that run on the SoC switch very frequently or when the initial conﬁguration times are not acceptable (as in real-time use-cases), the different use-cases can use the WC use-case conﬁguration. In this conﬁguration, all the use-cases will use the same set of paths and slot-table allocations, thereby not requiring the NoC to be re-conﬁgured when the use-cases switch, resulting in seamless switching between the use-cases. However, this leads to an over-design of the network when compared to the scenario where the NoC is reconﬁgured to suit the individual use-cases. Second, when the use-case switching is not that frequent, the NoC conﬁguration (path and slot-tables) can be changed dynamically across usecases, leading to a smaller NoC design (in terms of network components or frequency of operation). Third, when the usecases are expected to run for a long time, the voltage or frequency of operation of the NoC can be varied to match the use-cases, resulting in large power savings for the system. The simulation results for these cases are presented in the next section. V I . S IMU LAT ION RE SULT S We present simulation results on applying the multi-usecase design procedure on to 4 different SoC designs: P1 (with 2 use-cases), P2 (2 use-cases), P3 (4 use-cases) and P4 (8 usecases). The designs P1-P3 are simpliﬁed versions of set-top box SoCs [9] and the design P4 is a video processing SoC used in TVs. Each use-case has a large number of (50 to 150) communicating pairs of components. A fragment of two of the use-cases used in the P3 design was presented earlier in Figure 1. The set-top box SoCs and the TV processor have different functionalities and communication patterns. The designs P1P3 use an external memory for storing and retrieving data and the amount of data communicated to the memory is very large when compared to the rest of the design. The P4 design uses a streaming architecture with local memories on the chip, there by distributing the communication load across several components. We apply our design method to these SoCs with different architectures to validate the generality of the methods. A.EffectofMappingontheNoCFrequency To evaluate the mapped designs, we ﬁxed the topology and the maximum slot-table size for each design and we found the WC12 UC1 UC2 0 50 100 150 200 250 300 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (a) Design P1 WC12 UC1 UC2 0 100 200 300 400 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (b) Design P2 WC1234UC1 UC2 UC3 UC4 0 100 200 300 400 500 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (c) Design P3 WC UC1 UC2 UC3 UC4 UC5 UC6 UC7 UC8 0 50 100 150 200 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (d) Design P4 Fig. 5. The NoC operating frequencies required to support the different use-cases for the various designs. The WC use-case values are obtained when the path selection and the slot-table reservation are based on the WC use-case. The other values show the effect of re-applying the path selection and slot-table reservation for each use-case with the mapping obtained from the WC use-case. WC1234UC1 UC2 UC3 UC4 0 20 40 60 80 100 120 Use Cases S l o t e b a T l S i e z (a) Slot Table Size WC1234UC1 UC2 UC3 UC4 0 0.2 0.4 0.6 0.8 1 Use Cases N o r m a i l d e z N o A C r a e (b) NoC Area UC1 UC2 UC3 UC4 0 100 200 300 400 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (c) P3 individual mappings UC1 UC2 UC3 UC4 UC5 UC6 UC7 UC8 0 50 100 150 Use Cases R u q e i r F d e r y c n e u q e ( i n M H z ) (d) P4 individual mappings Fig. 6. (a)-(b) The effect of the mapping design procedure on the slot-table size and NoC area, (c)-(d) NoC frequency requirements for individual mapping of use-cases in designs P3 and P4. minimum frequency of operation required by the NoC to support the different use-cases. The results of the mapping procedure for the 4 SoC designs are presented in Figure 5. The frequency of operation required for the WC use-case is obtained from applying the NoC conﬁguration (i.e. the path selection and the slot-table reservation) procedure on the WC use-case. The frequency of operation of the NoC after reapplying the conﬁguration procedure for each of the use-cases, ﬁxing the mapping from the WC use-case is also presented in the ﬁgures. When DVS/DFS techniques are not used and a single frequency of operation is used for all the use-cases, we need to take the maximum of the frequencies of each of the individual use-cases as the operating frequency of each design. In this case, re-applying the NoC conﬁguration step results in 9% to 38% reduction in the required NoC operating frequency across the different designs. A lower operating frequency implies lower power consumption and smaller impact of noise sources. In the above analysis, we assumed that the slot-table size is ﬁxed and the NoC frequency is varied to support the use-cases. We also explored the effect of ﬁxing the NoC frequency (at 500 MHz) and varying the slot-table size. As similar results were observed for all the designs, we only present the results for the P3 design (Figure 6(a)). We obtain 58% reduction in the slot-table size for the design by re-applying the NoC conﬁguration step. A smaller slot-table size usually corresponds to a lower area for the NoC and lower packet latencies (as the trafﬁc streams wait lesser to get the slots). The NoC area reduction due to the slot-table reduction (Figure 6(b)) is 10% for this design (the NoC area includes the area of the switches and the network interfaces). Trade-offs involving the frequency savings and area savings can also be explored. B.Comparisonswiththeindividualuse-casemappings To evaluate the optimality of the NoC design produced by the above method, we performed individual mappings for each of the use-cases in the P3 and P4 designs. The required NoC frequencies for the use-cases in the resulting designs are presented in Figures 6(c) and 6(d). These frequency values are the minimum possible values for the use-cases, as we have done the mappings individually and they provide a lower bound on the quality of solutions that can be obtained when all the usecases share the same mapping1. When the results from Figures 6(c) and 6(d) are compared with the results from Figures 5(c) 1Note that the heuristic nature of the mapping algorithm can sometimes invalidate this general statement.                                             WC UC1 UC2 0 0.2 0.4 0.6 0.8 1 Use Cases N o r m a i l d e z P o w e r C u s n o m p i t n o (a) Design P1 WC UC1 UC2 0 0.2 0.4 0.6 0.8 1 Use Cases N o r m a i l d e z P o w e r C u s n o m p i t n o (b) Design P2 WC UC1 UC2 UC3 UC4 0 0.2 0.4 0.6 0.8 1 Use Cases N o r m d e z a l i P o w e r C u s n o m p i t n o (c) Design P3 WC UC1 UC2 UC3 UC4 UC5 UC6 UC7 UC8 0 0.2 0.4 0.6 0.8 1 Use Cases N o r m a i l d e z P o w e r C u s n o m p i t n o (d) Design P4 Fig. 7. Effects of DVS/DFS. and 5(d), we ﬁnd that the multi-use-case mapping design procedure results in mappings that require operating frequencies that are with in 10% of the minimum possible operating frequencies. We also performed experiments ﬁxing the frequency of operation for the multi-use-case mappings to be the same as the individually mapped designs and varied the network resources needed to support all the use-cases in the designs. The multi-use-case mappings required slightly more resources (1%-10% increase in the NoC area) to support the same frequency of operation as the individual mappings. C.EffectofDVS/DFS When the frequency of the NoC is scaled to match the frequencies required for the individual use-cases, large power savings can be achieved. As the frequency of the network is scaled, the supply voltage required for operation can also be scaled to match the frequency. We use a conservative model for voltage scaling, where we assume that the square of the voltage scales linearly with the frequency [24]. The power savings achieved by the DVS/DFS techniques for the entire SoC platform depends on the amount of time each use-case is expected to run. Thus, in this experiment, we present the power savings achieved for each use-case of the platform separately. The power consumption of each of the use-cases, normalized with respect to the power consumption of the WC use-case is presented in Figure 7. On average, we obtain 59.21% power savings by using the DVS/DFS techniques across the different use-cases for the designs. V I I . CONCLU S ION S As the number of applications or use-cases integrated on to a single SoC increases, the designer is faced with the challenge of building an interconnect structure that supports the design constraints of all the use-cases. In this paper we motivated the importance of the problem and presented use-case centric design methods to map applications on to NoC architectures. We also presented a way to dynamically conﬁgure the interconnect to support multiple use-cases and integrated Dynamic Voltage and Frequency (DVS/DFS) techniques with the reconﬁguration mechanism. In future, we plan to extend the algorithms for supporting concurrent operation of use-cases and apply the use-case models for addressing other NoC design issues such as the application speciﬁc topology design. "
2012,Performance evaluation and design trade-offs for wireless network-on-chip architectures.,"Massive levels of integration are making modern multicore chips all pervasive in several domains. High performance, robustness, and energy-efficiency are crucial for the widespread adoption of such platforms. Networks-on-Chip (NoCs) have emerged as communication backbones to enable a high degree of integration in multicore Systems-on-Chip (SoCs). Despite their advantages, an important performance limitation in traditional NoCs arises from planar metal interconnect-based multihop links with high latency and power consumption. This limitation can be addressed by drawing inspiration from the evolution of natural complex networks, which offer great performance-cost trade-offs. Analogous with many natural complex systems, future multicore chips are expected to be hierarchical and heterogeneous in nature as well. In this article we undertake a detailed performance evaluation for hierarchical small-world NoC architectures where the long-range communications links are established through the millimeter-wave wireless communication channels. Through architecture-space exploration in conjunction with novel power-efficient on-chip wireless link design, we demonstrate that it is possible to improve performance of conventional NoC architectures significantly without incurring high area overhead.",
2004,Optical solutions for system-level interconnect.,"Throughput, power consumption, signal integrity, pin count and routing complexity are all increasingly important interconnect issues that the system designer must deal with. Recent advances in integrated optical devices may deliver alternative interconnect solutions enabling drastically enhanced performance. This paper begins by outlining some of the more pressing issues in interconnect design, and goes on to describe system-level optical interconnect for inter- and intra-chip applications. Inter-chip optical interconnect, now a relatively mature technology, can enable greater connectivity for parallel computing for example through the use of optical I/O pads and wavelength division multiplexing. Intra-chip optical interconnect, technologically challenging and requiring new design methods, is presented through a proposal for heterogeneous integration of a photonic ""above-IC"" layer followed by a design methodology for on-chip optical links. Design technology issues are highlighted and the paper concludes with examples of the use of optical links in clock distribution (with quantitative comparisons of dissipated power between electrical and optical clock distribution networks) and for novel network on chip architectures.",
2006,BIST for Network-on-Chip Interconnect Infrastructures.,"In this paper, we present a novel built-in self-test methodology for testing the inter-switch links of network-on-chip (NoC) based chips. This methodology uses a high-level fault model that accounts for crosstalk effects due to inter-wire coupling. The novelty of our approach lies in the progressive reuse of the NoC infrastructure to transport test data to its own components under test in a bootstrap manner, and in extensively exploiting the inherent parallelism of the data transport mechanism to reduce the test time and implicitly the test cost",
2003,Power-aware NoC Reuse on the Testing of Core-based Systems.,,
2005,Handling Different Computational Granularity by a Reconfigurable IC Featuring Embedded FPGAs and a Network-on-Chip.,"A system-on-chip integrating a microprocessor, three embedded FPGA (eFPGA) and an eight port network-on-chip (NoC) is implemented in a 90nm CMOS technology. The system has been designed to execute complex multimedia applications by the use of hardware accelerators mapped to a reconfigurable platform based on a message-passing architecture. Computational kernels are mapped as hardware autonomous processes inside the eFPGAs or locally accelerated by the usage of dedicated microprocessor coprocessors. Each eFPGA on the system can be independently programmed and share logic with the others eFPGAs by intra-communication channels. The architecture is highly scalable since the eFPGA number can be controlled and the reconfigurable platform communication channels are based on a configurable NoC. The silicon area required by the system is 26mm2 in a 90 nm CMOS process. 10x speed ups have been measured on a MP3 playler mapping example.",
2005,Thermal-aware mapping and placement for 3-D NoC designs.,"Networks on chip (NoC) and 3D integrated circuits have been proposed as solutions to the ever-growing interconnect woes surrounding systems-on-chip. 3D designs however suffer from hotspot creation, due to the increase in the power density of parts of the chip. In this paper, we propose the use of a genetic algorithm for a thermal and communication aware mapping and placement of application tasks on 3D NoC environment. Our results show a significant reduction in system temperature when compared to a random mapping and placement, and provide an encouraging situation for migration to the 3D design space",
2011,ARIADNE - Agnostic Reconfiguration in a Disconnected Network Environment.,"Extreme transistor technology scaling is causing increasing concerns in device reliability: the expected lifetime of individual transistors in complex chips is quickly decreasing, and the problem is expected to worsen at future technology nodes. With complex designs increasingly relying on Networks-on-Chip (NoCs) for on-chip data transfers, a NoC must continue to operate even in the face of many transistor failures. Specifically, it must be able to reconfigure and reroute packets around faults to enable continued operation, i.e., generate new routing paths to replace the old ones upon a failure. In addition to these reliability requirements, NoCs must maintain low latency and high throughput at very low area budget. In this work, we propose a distributed reconfiguration solution named Ariadne, targeting large, aggressively scaled, unreliable NoCs. Ariadne utilizes up*/down* for fast routing at high bandwidth, and upon any number of concurrent network failures in any location, it reconfigures to discover new resilient paths to connect the surviving nodes. Experimental results show that Ariadne provides a 40%-140% latency improvement (when subject to 50 faults in a 64-node NoC) over other on-chip state-of-the-art fault tolerant solutions, while meeting the low area budget of on-chip routers with an overhead of just 1.97%.",
2011,Application-Aware Topology Reconfiguration for On-Chip Networks.,"In this paper, we present a reconfigurable architecture for networks-on-chip (NoC) on which arbitrary application-specific topologies can be implemented. When a new application starts, the proposed NoC tailors its topology to the application traffic pattern by changing the inter-router connections to some predefined configuration corresponding to the application. It addresses one of the main drawbacks of the existing application-specific NoC optimization methods, i.e., optimization of NoCs based on the traffic pattern of a single application. Supporting multiple applications is a critical feature of an NoC when several different applications are integrated into a single modern and complex multicore system-on-chip or chip multiprocessor. The proposed reconfigurable NoC architecture supports multiple applications by appropriately configuring itself to a topology that matches the traffic pattern of the currently running application. This paper first introduces the proposed reconfigurable topology and then addresses the problems of core to network mapping and topology exploration. Further on, we evaluate the impact of different architectural attributes on the performance of the proposed NoC. Evaluations consider network latency, power consumption, and area complexity.",
2008,Run-time power gating of on-chip routers using look-ahead routing.,"Since on-chip routers in network-on-chips play a key role in on-chip communication between cores, they should be always preparing for packet injections even if a part of cores are in standby mode, resulting in a larger standby power of routers compared with cores. The run-time power gating of individual channels in a router is one of attractive solutions to reduce the standby power of chip without affecting the on-chip communication. However, a state transition between sleep and active mode incurs the performance penalty, and turning a power switch on or off dissipates the overhead energy, which means a short-term sleep adversely increases the power consumption. In this paper, we propose a sleep control method based on look-ahead routing that detects the arrival of packets two hops ahead, so as to hide the wake-up delay and reduce the short-term sleeps of channels. Simulation results using real application traces show that the proposed method conceals the wake-up delay of less than five cycles, and more leakage power can be saved compared with the original naive method.","Run-Time Power Gating of On-Chip Routers Using Look-Ahead Routing ∗ 1B-4 Hiroki Matsutani† Michihiro Koibuchi‡ Hideharu Amano† †Keio University, 3-14-1, Hiyoshi, Kohoku-ku, Yokohama, 223-8522, JAPAN ‡National Institute of Informatics, 2-1-2, Hitotsubashi, Chiyoda-ku, Tokyo, 101-8430, JAPAN E-mail: matutani@am.ics.keio.ac.jp Daihan Wang† Abstract— Since on-chip routers in Network-on-Chips play a key role in on-chip communication between cores, they should be always preparing for packet injections even if a part of cores are in standby mode, resulting in a larger standby power of routers compared with cores. The run-time power gating of individual channels in a router is one of attractive solutions to reduce the standby power of chip without affecting the on-chip communication. However, a state transition between sleep and active mode incurs the performance penalty, and turning a power switch on or off dissipates the overhead energy, which means a short-term sleep adversely increases the power consumption. In this paper, we propose a sleep control method based on look-ahead routing that detects the arrival of packets two hops ahead, so as to hide the wake-up delay and reduce the short-term sleeps of channels. Simulation results using real application traces show that the proposed method conceals the wake-up delay of less than ﬁve cycles, and more leakage power can be saved compared with the original naive method. I. Introduction Network-on-Chips (NoCs) have emerged as a promising approach to connect a number of processing cores on a single chip, by introducing a network structure similar to that in parallel computers[4]. They have been utilized not only for highperformance microarchitectures but also for cost-effective embedded devices mostly used in consumer equipment such as set-top boxes or mobile wireless devices. Power consumption is one of the major concerns in such applications, since it affects their battery life or packaging costs for heat dissipation. It is divided into dynamic switching power and static leakage power, and various saving techniques have been used, such as clock gating and operand isolation for switching power, and multi-threshold voltages and power gating for leakage reduction. Leakage power has already become a major component of power consumption in recent process technologies, and it will further increase while switching power becomes smaller when the technology is scaled down. Leakage reduction techniques have been widely researched for application processors used in mobile phones, and their standby power is very small (e.g., the leakage current is only 11μA in ultra standby mode [8]). In other words, the more leakage reduction such processor cores achieve, the more impact the leakage power of on-chip routers will give; therefore leakage reduction techniques are essential for on-chip routers as well as processing cores in order to reduce the standby power of the chip. The run-time power gating of individual channels in a router is one of attractive solutions to reduce the standby power of chip if it does not affect the on-chip communication. However, a state transition between sleep and active mode incurs the performance penalty, and turning a power switch on or off dissipates the overhead energy, which means a short-term sleep ∗ A part of this work was supported by Toshiba Semiconductor Company, NII, and JST CREST. The authors thank to VLSI Design and Education Center (VDEC) and Kyoto University for the design ﬂow of ASPLA/STARC 90nm CMOS process. INPUT OUTPUT p0 p1 p2 p3 p4 STATE FIFO ARB STATE FIFO XBAR   SW p0 p1 p2 p3 p4 Routers’ parameters Process  Voltage Speed  ASPLA 90nm 1.0V 200 MHz, 500 MHz Flit size 64-bit # of ports 3, 4, 5, 6 # of VCs 2 Buf size 4-flit for each VC Packet len 4-flit data + 1-flit header Fig. 1. Wormhole router architecture used HEAD RC SA ST RC SA ST RC SA ST DATA_0 DATA_1 DATA_2 ST ST ST ST ST ST ST ST ST 1 2 3 4 5 6 7 8 9 10 11 12 ELAPSED TIME [CYCLE] ROUTER A ROUTER B ROUTER C Fig. 2. Router pipeline (a packet is transferred from router A to C) adversely increases the power consumption. In this paper, especially for simple on-chip wormhole routers, we propose a sleep control method based on the look-ahead routing that detects the arrival of packets two hops ahead, so as to hide the wake-up delay and reduce the occasion of short-term sleeps which adversely increase the power consumption. The rest of this paper is organized as follows. Section II analyzes power consumption of an on-chip router, and discusses the need for run-time power gating of individual channels in the router. Section III surveys run-time power gating techniques on microprocessors. The sleep control method based on lookahead routing is proposed in Section IV and is evaluated in Section V. Conclusions are derived in Section VII. II. Power Analysis of On-Chip Router A. On-Chip Router Architecture Prior to discussing low power techniques for on-chip routers, we analyzed power consumption of a typical on-chip router used in [9]. Fig.1 shows the wormhole router architecture used in this analysis. This router consists of a crossbar switch (XBAR), an arbitration unit (ARB), and input physical channels (or ports). Each physical channel has two virtual channels[6], each of which has a FIFO buffer for storing four 64-bit ﬂits. This is a typical input buffered router, which has buffers only at its input channels, not output channels. In this design, the FIFO buffers were implemented with small registers, and up to 75% of the total router area was used for them. The router architecture was fully pipelined, and it transferred a header ﬂit through three pipeline stages that consisted of routing computation (RC), virtual channel and switch allocation (SA), and switch traversal (ST). Fig.2 shows the router pipeline, in which a packet consisting of a single header ﬂit and three data ﬂits is transferred from router A to router C. 978-1-4244-1922-7/08/$25.00 ©2008 IEEE 55 1B-4 ] W m [ n o i t p m u s n o c r e w o P  4.5  4  3.5  3  2.5  2  1.5  1  0.5  0 3-port router 4-port router 5-port router 6-port router Standby power (leakage >= 80%) 6543210543210432103210 Number of streams Fig. 3. Router power at ﬁxed throughputs (200MHz) Table I Breakdown of standby power on the 5-port router (200MHz, 500MHz) Crossbar & others Channels (FIFOs) Total 200MHz 500MHz dynamic leakage dynamic leakage 13μW 207μW 33μW 207μW 146μW 476μW 365μW 476μW 842μW 1,081μW B. Power Analysis To estimate the power consumption of the router mentioned previously, the following steps were performed: 1) synthesis by Synopsys Design Compiler, 2) place and route with buffer insertions at CTS using Synopsys Astro, 3) post place-and-route simulation by Cadence Verilog-XL to obtain switching activity information of the router, 4) power analysis based on the switching activity using Synopsys Power Compiler. A 90nm CMOS process with a core voltage of 1.0V was selected in this analysis. Clock gating and operand isolation were fully applied to the router to minimize its switching activity. In the step 3), the router was simulated at 200MHz and 500MHz with various ﬁxed workloads (throughputs), in the same manner as [3]. A packet stream is deﬁned as intermittent injections of packets, which utilize about 30% of the maximum link bandwidth of a single router link. Each header ﬂit contains a ﬁxed destination address, while data ﬂits contain a random payload. The number of packet streams injecting into the router was changed so as to generate various workloads. In this experiment, up to n streams were applied for a router that has n physical channels (i.e., an n-port router), and power consumption at each workload level was analyzed, where 3 ≤ n ≤ 6. Fig.3 shows the results at 200MHz. As we expected, the router consumes more power as it processes more packet streams. Notice the router consumes a certain standby power even with no trafﬁc (i.e., 0-stream). Table I shows the breakdown of standby power on the 5-port router. Leakage power consumes a substantial portion of the standby power (e.g., 81.1% of the standby power at 200MHz). Particularly, the leakage power consumed by input channels is the largest. The remaining power is dynamic power consumed by latches inserted for clock gating; so further reduction of dynamic power would be difﬁcult. Processor cores can be stopped if they are not used, though it takes millisecond order time to wake-up. However, on-chip routers must be always preparing for packet injections even if a part of cores are in standby mode, since they play a key role for enabling on-chip communication between cores; thus the runtime power gating of individual channels in a router is one of attractive solutions to reduce the standby power of chip without affecting the on-chip communication. Run-time power gating techniques are surveyed in the next section. III. Run-Time Power Gating Power gating technique shuts off the power supply of idle blocks by turning off (or on) power switches inserted between Vdd line and the blocks or between GND line and the blocks. This concept has been applied to circuit blocks with various 56 5-CYCLE HEAD NRC SA ST NRC SA ST NRC SA ST DATA_0 DATA_1 DATA_2 ST ST ST ST ST ST ST ST ST 1 2 3 4 5 6 7 8 9 10 11 12 ELAPSED TIME [CYCLE] ROUTER A ROUTER B ROUTER C Fig. 4. Pipelined router with look-ahead routing granularities, such as processor cores[8], execution units in a processor[7][1], and primitive gates[11]. In this paper, we focus on the execution unit level, since its granularity is close to our router channels. We need to understand both negative and positive impacts of power gating when we use it. Actually, a state transition between sleep and active mode incurs the performance penalty, and turning a power switch on or off dissipates the overhead energy, which means a short-term sleep increases the power consumption. [7] provides an analytical model of run-time power gating of execution units in a microprocessor. The following three parameters quoted from [7] affect performance and energy. • Twakeup : Number of cycles required to charge up the local voltage of a sleeping block. Delay for turning on its power switch is also lumped into Twakeup value. • Tidledetect : Number of cycles required to detect an idle duration at an active block and decide to shut off the block. Delay for turning off its power switch is also lumped into Tidledetect value. • Tbreakeven : Number of sleep cycles at least required to compensate the overhead energy for turning the power switch on and off. Twakeup value affects the performance (e.g., trafﬁc throughput on routers), since a pipeline stall will be caused if a new request suddenly comes to a sleeping block. Also, Tidledetect shortens the sleep duration of blocks, since an idle block must stay in the active state for Tidledetect cycles before it decides to go to the sleep mode. A short-term sleep of less than Tbreakeven cycles cannot compensate the energy overhead of driving a power switch, and power consumption will be increased; thus we need to avoid such short-term sleeps. Although Tbreakeven value depends on various parameters, [7] provides Tbreakeven ≈ 10 based on typical pasuch as sizes of a power switch and a decoupling capacitance, rameters on a typical microprocessor. In the same manner as [7], we also estimate Tbreakeven value on our on-chip router mentioned previously (see Section V.D). IV. Sleep Control Using Look-Ahead Routing In this section, we propose a sleep control method based on look-ahead routing that detects the arrival of packets two hops ahead, so as to mitigate the negative impacts of Twakeup and short-term sleeps of less than Tbreakeven cycles. We ﬁrst explain the general look-ahead routing, and then we propose our method for deterministic routing. Extensions for adaptive routing are also shown in this section. A. Look-Ahead Routing Look-ahead routing has been used for several purposes, such as reducing pipeline stages for low latency communication[6]. Here we just explain the differences between a look-ahead router and a normal router without look-ahead from the viewpoint of their router pipeline structure.     In the case of normal routers, an output channel at i-th hop router is selected by the RC stage of the same router (i.e., i-th hop router), as shown in Fig.2. an output channel at i-th hop router is selected by (i− 1)-th hop In the case of one-hop look-ahead routers, on the other hand, router. That is, each router performs a routing computation for the next hop (denoted as NRC), as shown in Fig.4. B. Basic Sleep Control We apply the look-ahead routing for early detections of both idle and busy periods on each router channel. Basic sleep control without look-ahead routing is preliminarily shown here. Each input channel monitors a “request” signal, which indicates that new packets (or requests) are approaching the input channel, and it is used for making a decision to go to the active mode. That is, if the request signal for a sleeping channel is asserted, then the channel starts the wake-up procedure to receive new packets. The request signal is also used for making a decision to go to the sleep mode. Each input channel checks the request signal after forwarding a packet in the channel, and if the request signal is de-asserted, the channel will go to the sleep mode. Obviously, performance penalty due to the wake-up delay depends on how early the new requests can be detected. C. Look-Ahead Sleep Control on Deterministic Routing Routing algorithms are categorized as deterministic and adaptive. All routing paths are statically ﬁxed in deterministic routing, while they are dynamically changed in adaptive routing in response to network conditions. Since a simple deterministic routing such as dimension-order routing (DOR) [6] has been widely used in NoCs, we mainly explain our sleep control method focusing on deterministic routing. Extensions for adaptive routing are summarized in Section IV.D. is determined at the NRC stage of (i − 1)-th hop router, in As we stated previously, the output channel at i-th hop router the case of look-ahead routers with deterministic routing. This means that, at the same time, we can also ﬁnd which input channel at (i + 1)-th hop router is going to be used, because the output channel of i-th hop router is directly connected to the input channel of (i + 1)-th hop router. For example, during cycle 1 in Fig.4, the NRC stage of router A detects which input channel of router C should be power-gated or waked-up from now. There is a ﬁve-cycle margin between the NRC stage at router A and the packet arrival at router C; so our proposed sleep control method can reduce the performance penalty, or remove that when Twakeup ≤ 5. However, the proposed method requires the following two modiﬁcations on look-ahead routers; 1) every input channel needs to assert (or de-assert) the request signals to all input channels which are located in two hops far from the channel; 2) every input channel needs to receive all request signals from input channels which are located in two hops far from the channel. Additional hardware amount required for these modiﬁcations is modest, since they can be implemented with simple combinational logic, which is much smaller than the buffers. 1 Fig.5 illustrates the sleep control signals for the South channel of router 1. Let us call the South channel of router 1 a “target”. The target channel monitors the request signals from input channels in router 3, 5, and 7 to make a decision to sleep or wake-up. Notice that the target channel does not need to monitor several input channels, since “U-turn” paths that introduce livelocks are usually prohibited even with heavy trafﬁc. That is, the target channel has only to monitor the input channels colored in Fig.5(a). 1Although we omitted such considerations from the evaluation section due to the page limitations, we implemented the look-ahead based sleep controller on the router, and estimated the hardware overhead (in gates) is only 1.08% of original. Notice this estimation does not include power switches, which will further increase the total area. 57 1B-4 R-0 R-1 R-2 R-0 R-1 R-2 REQUEST R-3 R-4 R-5 R-6 R-7 R-8 R-6 R-8 (a) Input channels in the NoC (b) Request network using OR-gates Fig. 5. Request signal for the South channel of router 1 (R denotes a router) The colored input channels assert their request signal for the target channel when they detect a packet destined for router 1, in order to notify that the packet will be arriving at the target at least ﬁve cycles later (Fig.5(b)). As shown, these request signals cover the twice longer length than normal links between routers cover. Although the critical path of the target router is not related to the sleep controllers (it is related to the arbitration logic of output ports), the wire delay of these request signals will be increased as the distance between routers increases. On the other hand, these request signals can be pipelined and be transferred in two cycles in order to mitigate the wire delay. In such cases, each channel can still detect the packet arrivals four cycles ahead. D. Extensions for Adaptive Routing In the case of adaptive routing, the RC stage provides several candidates of output channels, and one of them is selected based on an output selection function (OSF); thus look-ahead mechanism cannot detect the arrival of packets two hops ahead. Here, in order to save leakage power of routers’ channels even with adaptive routing, we proposed to change the OSF dynamically in response to the network load, as follows: • At heavy load: Randomly selects a channel every time • At light load: Continuously selects the same channel Clearly, the former OSF improves the network throughput compared with the latter one, but the arrival of packets can be correctly detected in the case of the latter OSF. At light network load, the network throughput is limited by the amount of packet injections, not OSFs; thus performance penalty of the latter OSF is negligible, and look-ahead sleep control with the latter OSF can save leakage power. At heavy load, on the other hand, there are few opportunities for power gating in most cases due to the frequent packet arrivals, so the former OSF without power gating would be reasonable. V. Evaluations The following three sleep control methods (including the look-ahead based one) were evaluated in terms of performance impact of wake-up delay and leakage power saving. • ideal: Power gating with no overhead (equivalent to the ideal case where Twakeup = 0 and Tidledetect = 0) • lookahead: Power gating with look-ahead based sleep control, which detects the packet arrivals ﬁve cycles ahead • naive (original): Power gating with naive sleep control, which detects the packet arrivals zero cycle ahead A. Performance Impact of Wake-Up Delay To show the impact of the wake-up delay on the performance, we evaluated the network throughput when power gating with naive method was applied for various Twakeup values. A ﬂit-level network simulator written in C++ was used for this experiment. A simple model corresponding to the wormhole router mentioned in Section II.A was used as a switching  0  0.05  500  1000  1500  2000  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]   0.3 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (a) uniform trafﬁc (16-core)  0  0.05  500  1000  1500  2000  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]   0.3 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (b) BT trafﬁc (16-core)  0  0.05  500  1000  1500  2000  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]   0.3 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (c) SP trafﬁc (16-core)  0  500  1000  1500  2000  0.06 0.08  0.1  0.12 0.14 0.16 0.18 Accepted traffic [flit/cycle/core]   0.2 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (d) CG trafﬁc (16-core)  0  0.05  500  1000  1500  2000  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]   0.3 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (e) MG trafﬁc (16-core) Fig. 6. Performance of naive method (Twakeup = 0, 1, 2, 3)  0  0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 Accepted traffic [flit/cycle/core]   500  1000  1500  2000 a L t y c n e [ e c y c l ] Twakeup=0 Twakeup=1 Twakeup=2 Twakeup=3 (f) IS trafﬁc (16-core) fabric in the simulator. That is, each router had three pipeline stages, and each packet consisted of ﬁve ﬂits including one ﬂit header (see Fig.1). Network topology and routing algorithm used in this simulation were 4 × 4 2-D Mesh and DOR[6]. As for the trafﬁc patterns, we used ﬁve application traces and uniform random trafﬁc. These application traces were captured from NAS Parallel Benchmark (NPB)[2] programs, because they would enable us to evaluate with various patterns of real application trafﬁc. We selected ﬁve matrix computation programs from NPB: Block Tridiagonal solver (BT), Scalar Pentadiagonal solver (SP), Conjugate Gradient (CG), Multi-Grid solver (MG), and large Integer Sort (IS). The class of problem was set to “W”, and the numbers of tasks was 16. In addition to these real applications, we used uniform trafﬁc as a baseline for comparison. Fig.6 shows the throughput (accepted trafﬁc) versus the latency with naive method in the cases where Twakeup = In the case of naive method, a pipeline stall of Twakeup cycles always occurs when a new packet arrives at a sleeping channel; thus its throughput is reduced as Twakeup value is increased. Notice that the throughput of ideal method is equivalent to the case where Twakeup = 0. As for the lookahead method, since it can detect the arrivals of packets ﬁve cycles ahead as we stated in Section IV, its throughput is also equivalent to the ideal if Twakeup ≤ 5. As a result, lookahead method successfully mitigates the performance penalty of wake-up delay. 0, 1, 2, 3. B. Break-Even Point of Power Gating Tbreakeven value determines the beneﬁts of power gating. In this section, we ﬁrst estimated energy parameters of a channel in our router. Then we calculated Tbreakeven value of the router channel based on these energy parameters in the same manner proposed in [7], because the circuit block size of the channel would be close to that of an execution unit in a microprocessor. The router was simulated at 200MHz and 500MHz. Table II shows the energy parameters of the router channel, such as dynamic power, leakage power, and switching activity. As reported in [7], the total energy saved over N cycles (denoted as EN saved ) is calculated as follows: EN saved = Eleak DIBL mVt N 2 2 αLVdd 2( 1 2 + CD CS ) , (1) where DIBL is the drain-induced barrier lowering, which is typically close to the value of 0.1, Vt = kT /q ≈ 25mV is the thermal voltage, and m ≈ 1.3 [7]. Also, WH is the ratio of the total area of the power switch to the area of the target block (i.e., the router channel), CS is the total switching capacitance of the block, and CD is the total capacitance at the local power supply including the power switch. Typically, WH is 0.1 and CD /CS is 0.5 as reported in [7]. Parameters of the router channel for energy calculation († Energy values are Table II expressed in Watts to show the differences between 200MHz and 500MHz) 200MHz 500MHz 1.0V 1.0V 0.095mW 0.095mW 0.105mW 0.261mW 0.91 0.36 0.10 0.10 Vdd Eleak Esw supply voltage static energy † dynamic energy † leakage factor (= Eleak /Esw ) switching factor L α As reported in [7], the dynamic energy overhead to turn the power switch (denoted as Eoverhead ) is calculated as follows: Eoverhead ≈ 2 WH α Eleak . (2) Based on Equation 1 and 2, we calculated the average leakage power consumed in an N -cycle sleep, in the cases of 200MHz and 500MHz. Note that the average leakage power consumption in this experiment includes the dynamic energy overhead to turn the power switch. Since the impact of the overhead energy is increased as the sleep duration is shortened, the average leakage power of a power-gated channel would be larger than that without power gating if the sleep duration is very short. The results are shown in Fig.7. “NoPG” stands for the leakage power of the router channel without power gating, while “PG(200MHz)” and “PG(500MHz)” are the results of the power-gated channel operating at 200MHz and 500MHz, respectively. As shown in the graph, the average leakage 1B-4 58              0.35  0.3  0.25  0.2  0.15  0.1  0.05 ] W m [ n o i t p m u s n o c r e w o P  0  0 NoPG PG(200MHz) PG(500MHz) Tbreakeven=5.60 Tbreakeven=14.00  5  10  15  20 Sleep duration (N) [cycle]  25  30 Fig. 7. Leakage power consumption vs. sleep duration power of PG(200MHz) and PG(500MHz) are decreased as the sleep duration N becomes long. Since the leakage power of NoPG is 0.095mW, we can estimate that Tbreakeven ≈ 6 for PG(200MHz) and Tbreakeven = 14 for PG(500MHz). C. Compensated Sleep Cycles Although a long-term compensated sleep (≥ Tbreakeven ) can save the leakage power consumption, a short-term uncompensated sleep (< Tbreakeven ) adversely increases the power. In this section, we show ratio of the compensated sleep cycles. The total execution time of each input channel in the NoC can be divided into the following three states: • Ncsc : Compensated sleep state (duration ≥ Tbreakeven ) • Nusc : Uncompensated sleep (duration < Tbreakeven ) • Nactive : Active state (neither Ncsc nor Nusc ) To calculate the ratio of Ncsc over the total execution time, we performed the network simulations in the same manner as Section V.A. We assumed 200MHz and 500MHz cases again. Tbreakeven was set to 6 for the 200MHz simulation, while it was set to 14 for the 500MHz, as estimated in the previous section. To see the differences of these Tbreakeven values, Twakeup was ﬁxed to 2 and Tidledetect was ﬁxed to 4, in both cases. Fig.8 shows the results in the case where Tbreakeven = 6. As we expected, the ratio of Ncsc is reduced as the network load (accepted trafﬁc) increases. Especially naive method cannot conceal the wake-up delay, and pipeline stalls are caused more frequently than the other methods. The stalled packets stay long at channel buffers, and the sleep opportunities are reduced. Thus, the ratio of Ncsc in lookahead method is higher than that in naive method, and it is comparable to ideal method. Fig.9 shows the results in the case where Tbreakeven = 14. Compared with Fig.8, the ratio of Ncsc is decreased in all methods. Particularly the sleep opportunities are much reduced in uniform trafﬁc, which is the worst case for the run-time power gating because all channels are evenly used at short intervals. D. Leakage Power Saving In the previous section, we focused on the ratio of the compensated sleep cycles, but we did not take account of the energy overhead induced by the uncompensated sleeps. In this section, we estimated the leakage power saving which includes the overhead energy for driving the power switches. To estimate the leakage power consumption, we obtained the length (i.e., number of cycles) of every sleep in every channel during the total execution time. Then we calculated the average power consumption for each sleep according to its length, based on the “power consumption vs. sleep duration” graph shown in Fig.7. That is, a sleep longer than Tbreakeven contributes to reduce the average power consumption, while a sleep shorter than Tbreakeven adversely eats additional power. Fig.8 and 9 also show the average leakage power consumption over all channels in the NoC. As shown in these graphs, more leakage power can be saved as Ncsc increases. In other words, the leakage power saving depends on the network load. 59 1B-4 Since the router channel consumes 0.095mW when power gating is not applied, our proposed lookahead based power gating can save 13.1% to 71.1% of leakage power, even at the maximum (peak) throughput. Furthermore, we can see the leakage power saving of lookahead method is larger than that in naive method. Actually, the results of lookahead are close to ideal. In this paper, we studied the run-time power gating of router channels to reduce the standby power of on-chip routers, because the leakage power of channels consumes more than half of the standby power (Table I). Although the leakage power is still small compared with the switching power at the peak throughput (Fig. 3), the impact of leakage power will further increase while switching power becomes smaller as the technology is scaled down. VI. Related Works Various low power techniques have been studied for onchip and off-chip routers. [5] proposes power-aware router buffers based on Drowsy and Gated Vdd SRAMs to regulate their leakage power. [10] provides a thorough discussion about power-aware networks whose links can be turned on and off, in terms of connectivity, routing, wake-up and sleep decisions, and router pipeline architecture. These related works are intended not only for off-chip interconnects but also for on-chip interconnects, and they assume to use relatively large buffers in their routers, compared with simple onchip wormhole routers used in [3] and [9]. In [5], router buffers are constructed with SRAMs and each input port has a 256-ﬂit buffer in the experiment. As a sleep control policy of the buffer, a certain portion (i.e., window size) of the buffer is waked up before it is accessed. By tuning the window size, input ports can always provide enough buffer space when packets arrive, and network performance will never be affected[5]. On the other hand, our light-weight wormhole router uses a small 4-ﬂit buffer for each channel[9], unlike routers that use SRAMs for their input and output buffers. Since the buffer depth is shorter than the window size in the low-cost router, the wake-up delay of buffers directly affects the network performance if links or channels are dynamically turned on and off. Our look-ahead based sleep control method can remove the negative impact of wake up delay on the light-weight onchip routers by detecting the arrival of packets two hops ahead. VII. Conclusions The run-time power gating of individual channels in a router is an attractive solution to reduce the standby power of chip without affecting the performance of the on-chip communication. In order to mitigate the performance penalty of Twakeup and increase the compensable sleep opportunities, we proposed a sleep control method based on the look-ahead routing. Simulation results using real application traces showed that lookahead method conceals Twakeup of less than ﬁve cycles, and more leakage power can be saved compared with the original naive method. Although the technique proposed here is simple, it is essential to mitigate the performance and energy overheads of the run-time power gating on simple on-chip routers. Based on the results provided here, we are planning to explore the power-gating aware router architecture and network topology. We will apply the proposed method to various network topologies such as fat trees that have multiple trees, each of which can be individually power-gated according to the trafﬁc load. In addition, we are developing an on-chip router that has ﬁve virtual channels, each of which can be individually power-gated. The virtual-channel mechanism has been considered to increase the leakage power due to its large buffer size while it can provide good performance. The virtual-channel level power gating would overcome such negative impacts. As a result, we can beneﬁt from the high peak performance of virtual channels without increasing the standby power of the chip.      0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (a) uniform trafﬁc (16-core)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (b) BT trafﬁc (16-core)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (c) SP trafﬁc (16-core)  0  0.02  0.04  0.06  0.08  0.1  0.06 0.08  0.1  0.12 0.14 0.16 0.18 Accepted traffic [flit/cycle/core]  0  0.2  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (d) CG trafﬁc (16-core) (e) MG trafﬁc (16-core) (f) IS trafﬁc (16-core) Fig. 8. Ncsc and leakage power consumption with ideal, lookahead, and naive methods (Twakeup = 2, Tidledetect = 4, Tbreakeven = 6)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc)  0  0  0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 Accepted traffic [flit/cycle/core]  0.02  0.04  0.06  0.08  0.1  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (a) uniform trafﬁc (16-core)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (b) BT trafﬁc (16-core)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (c) SP trafﬁc (16-core)  0  0.02  0.04  0.06  0.08  0.1  0.06 0.08  0.1  0.12 0.14 0.16 0.18 Accepted traffic [flit/cycle/core]  0  0.2  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) (d) CG trafﬁc (16-core) (e) MG trafﬁc (16-core) (f) IS trafﬁc (16-core) Fig. 9. Ncsc and leakage power consumption with ideal, lookahead, and naive methods (Twakeup = 2, Tidledetect = 4, Tbreakeven = 14)  0  0.05  0.02  0.04  0.06  0.08  0.1  0.1  0.15  0.2  0.25 Accepted traffic [flit/cycle/core]  0  0.3  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc)  0  0  0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 Accepted traffic [flit/cycle/core]  0.02  0.04  0.06  0.08  0.1  20  40  60  80  100 P o w e r u s n o c m p i t n o [ m W ] C o m e c y c p e e s d e a s n e p t l l ( N c s c ) [ % ] No PG (0.095 [mW]) ideal(Powr) ahead(Powr) naive(Powr) ideal(Ncsc) ahead(Ncsc) naive(Ncsc) "
2011,On the design and analysis of fault tolerant NoC architecture using spare routers.,"The aggressive advent in VLSI manufacturing technology has made dramatic impacts on the dependability of devices and interconnects. In the modern manycore system, mesh based Networks-on-Chip (NoC) is widely adopted as on chip communication infrastructure. It is critical to provide an effective fault tolerance scheme on mesh based NoC. A faulty router or broken link isolates a well functional processing element (PE). Also, a set of faulty routers form faulty regions which may break down the whole design. To address these issues, we propose an innovative router-level fault tolerance scheme with spare routers which is different from the traditional microarchitecture-level approach. The spare routers not only provide redundancies but also diversify connection paths between adjacent routers. To exploit these valuable resources on fault tolerant capabilities, two configuration algorithms are demonstrated. One is shift-and-replace-allocation (SARA) and the other is defect-awareness-path-allocation (DAPA) that takes advantage of path diversity in our architecture. The proposed design is transparent to any routing algorithm since the output topology is consistent to the original mesh. Experimental results show that our scheme has remarkable improvements on fault tolerant metrics including reliability, mean time to failure (MTTF), and yield. In addition, the performance of spare router increases with the growth of NoC size but the relative connection cost decreases at the same time. This rare and valuable characteristic makes our solution suitable for large scale NoC design.","5B-1 On the Design and Analysis of Fault Tolerant NoC Architecture Using  Spare Routers Yung-Chang Chang  Ching-Te Chiu  Shih-Yin Lin, Chung-Kai Liu  Information & Communications Research Lab.  Industrial Technology Research Institute  Hsinchu, Taiwan, R.O.C.  ycchangs@itri.org.tw Dept. of Computer Science  National Tsing Hua University  Hsinchu, Taiwan, R.O.C.  ctchiu@cs.nthu.edu.tw  Information & Communications Research Lab.  Industrial Technology Research Institute  Hsinchu, Taiwan, R.O.C.  {bryan.lin, ckliu}@itri.org.tw Abstract - The aggressive advent in VLSI manufacturing  technology has made dramatic impacts on the dependability of  devices and interconnects. In the modern manycore system, mesh  based Networks-on-Chip (NoC) is widely adopted as on chip  communication infrastructure. It is critical to provide an  effective fault tolerance scheme on mesh based NoC. A faulty  router or broken link isolates a well functional processing  element (PE). Also, a set of faulty routers form faulty regions  which may break down the whole design. To address these issues,  we propose an innovative router-level fault tolerance scheme with  spare routers which  is different  from  the  traditional  microarchitecture-level approach. The spare routers not only  provide redundancies but also diversify connection paths  between adjacent routers. To exploit these valuable resources on  fault tolerant capabilities, two configuration algorithms are  demonstrated. One is shift-and-replace-allocation (SARA) and  the other is defect-awareness-path-allocation (DAPA) that takes  advantage of path diversity in our architecture. The proposed  design is transparent to any routing algorithm since the output  topology is consistent to the original mesh. Experimental results  show that our scheme has remarkable improvements on fault  tolerant metrics including reliability, mean time to failure  (MTTF), and yield. In addition, the performance of spare router  increases with the growth of NoC size but the relative connection  cost decreases at the same time. This rare and valuable  characteristic makes our solution suitable for large scale NoC  design.  I. Introduction  As semiconductor technology advances into deep submicron  (DSM) regime, the increasing transistor budget and chip density have  enabled the integration of ten to hundreds of pre-designed IPs. This  shrinking of feature size and intensive combinations of homogeneous  and heterogeneous modules have revealed the significance of on-chip  networks (OCNs) design [1]. Traditional bus-based OCN architecture  suffers from the issues of scalability, performance, and power.  Therefore, packet based Network-on-Chip (NoC) has evolved as a  new paradigm to overcome these design challenges [2], [3]. Recently,  many NoC architectures have been proposed [4]. Among these  candidates, 2D-mesh is considered as the most attractive one since it  provides regularity  in both physical structures and electrical  properties [5]. As depicted in fig. 1(a), a homogeneous manycore  system with 4x4 2D-mesh NoC consists of 4 routers in each rows and  columns, and each router is a switching element with 5 ports  connecting its four neighboring routers and a local processing  element (PE).  However,  this aggressive  integration of computation and  communication elements has worsened the dependability issues in  DSM. Manufacturing defects introduce permanent faults on nodes  and links. It relies on the built-in self-test (BIST) circuit to capture  and mask these faulty elements in the testing procedure [6]. To  sustain the reliability, the system should provide a mechanism to  bypass and replace  these faulty elements. Recently, several  researches have been made on the fault tolerance routing algorithm,  in which faulty routers/paths are detoured [7], [8]. However, they are  not capable of solving a series of problems caused by faulty routers.  For example, fig. 1(b) shows four well functional PEs which are  isolated by faulty routers and broken links. This leads to a great  waste of hardware resource since the cost of a PE is much higher  than that of a router or links. A more elaborate example is illustrated  in fig. 1(c). A set of faulty routers may shape faulty regions which  break down the whole design. Existing fault tolerance routing  algorithms fail because there are no detouring paths between these  faulty regions. Although faulty regions can operate individually, this  deteriorates the performance in the manycore architecture in which  applications are highly parallelized and intensively cooperated. To  recover from a permanent fault, hardware redundancy is mandatory.  Microarchitecture level redundancy has been proposed in NoC design.  However, as the size of mesh increases and the cost of a single router  becomes relatively inexpensive when comparing to the entire NoC  (e.g., a 128 routers), microarchitecture  level redundancy  is  considered inefficiency [9]. As the result, it is reasonable to provide  redundancies in the router level.  In this work, we proposed a novel router level redundancy scheme  that  ingeniously  solves  the  problems mentioned  above  simultaneously. In addition, our design does not need any support  from the routing algorithm. This transparency to the upper layer  routing algorithms convinces our architecture a viable solution in the modern complex hierarchical hardware/software system designs. In  summary, our contributions are threefold:  1. Resolve the problem of isolated PE  2. Resolve the problem of faulty regions  3. The proposed architecture is routing algorithm transparency  We evaluate our design with fault tolerance metrics including  system reliability, mean time to failure (MTTF), and yield. Also,  while the underlying physical configuration is changed, applications  can be remapped to optimize the performance. This mapping problem  belongs to the class of NP-hard. We apply a heuristic algorithm to  reveal the potential of performance improvement.     The rest of this paper is organized as following: Section II  provides reviews of previous researches on fault tolerance NoC  designs. Section III describes the proposed fault tolerance NoC  architecture. In section IV, evaluation methodology and experimental  results are provided. Section V shows a case study to illustrate the  potential of performance improvement using application remapping.  Section VI concludes this paper. II. Related Works  978-1-4244-7516-2/11/$26.00 ©2011 IEEE 431 5B-1 (a) (b)  (c) Fig. 1. Problems of isolated PE and faulty regions. (a) A conventional faulty free 4x4 2D mesh. (b) Isolated PE caused by faulty routers and  broken links. (c) Faulty regions caused by faulty routers  Fault tolerance design in VLSI has been an active research topic.  As the raise of NoC for complex nanometer SoC design solutions,  several error control mechanisms have been proposed to address chip  level network failures on channels and routers. VLSI circuit faults  can be classified into three categories: transient, intermittent, and  permanent failures [12].   Transient faults are introduced by power supply noise, ground bounce, energetic particles, and interconnection noise such as  crosstalk and electromagnetic interference, etc. These faults occur  randomly and do not cause physical damages on circuits. Encoding  techniques are pervasively used to tackle these errors. For example,  Srinivas et al. presented an encoding framework to combat coupling  noise and transitions on bus wires [18]. On the other hand, devices  experience intermittent failures by marginal designs which are too  sensitive to the disturbances of outside environment conditions.  Intermittent faults may appear with locality in time and/or space.  Permanent  faults  are  induced by manufacturing defects,  electromigration, and wearout failures. In order to maintain the  system operations, spare hardware is usually used to replace  intermittently or permanently faulty units. Error control mechanisms  can be applied at different hierarchies spanning from the link layer to  the highest thread layer [14], [15], [19]. In our work, we address  these faults using spare units on both links and routers.  More specifically, we focus on faults that can be caught by add-on  mechanisms such as BIST or periodical run-time testing circuits.  Teijo et al. use spare wires as vehicle for in-line testing and erroneous  path detouring [16]. Opens and shorts occurred on adjacent switch  channels are tested periodically with error control code (ECC).  However, only the channel failures are addressed. Michihiro et al.  propose a mechanism in which faulty router is bypassed using default  backup paths (DBPs) [17]. Unfortunately, both the underlying  physical topology and the logical topology exposed to upper layer  applications are changed. New routing algorithm must be added to  support the proposed design. In our work, we adopt the idea of spare  links and combine them with spare routers. This innovative approach  does not impose any interference on routing algorithms.  Several fault tolerant routing algorithms have been proposed to  tackle defect on NoC. In [7], [13], randomized and stochastic  algorithms are presented in which packets are sent to a set of  destinations. Traditional fault tolerant routing algorithms introduce  congestion around faulty nodes. In [10], a traffic-balanced fault  tolerant routing algorithm is proposed to distribute this heavy traffic  load. However, routing level fault tolerance does not address the  problems of isolated PE and faulty regions mentioned above.  Traditionally, microarchitectural redundancy is widely adopted for  improving dependability in processor designs [20]. Recently, the state  of the art researches have shown that microarchitecture level  redundancy has the drawback of scalability [9]. As the number of  cores increases, microarchitectural redundancy within cores has  higher cost than that of core level redundancy. Motivated by this idea,  we propose a new scalable fault tolerance scheme for NoC at the  router level.  In contrast to previous researches, our design is innovative since  router-level redundancy on NoC is not seen before. We tackle defects  in both NoC routers and interconnection channels. We also consider  the mapping problem to minimize the cost parasitizing from  reconfiguring the NoC interconnections.  III. Designing Fault Tolerant Mesh Based On Chip  Networks Using Spare Routers In this section, we first formalize the fault tolerant mesh based  interconnection into graph embedding problem. After that, the  proposed spare router architecture is described. We also present two  path allocation algorithms. The first one utilizes spare routers is  shift-and-replace-allocation  (SARA). The  second one  takes  advantage  of  path  diversity  in  our  architecture  is  defect-awareness-path-allocation (DAPA).   A. Problem Definition  A fault tolerant interconnection system can be modeled using  graph theory. A graph G* = (V, E) where V is the vertex set  representing switching nodes, and E is the edge set representing  interconnection channels. G* is said to be fault tolerant with respect  to G if after removing the faulty nodes/channels in G*, G* contains  G. There are a lot of variants of G*. A G* is said to be k-optimal node  free fault tolerant if any k nodes can be removed and G* has the  minimum edges. In practice, it is unfeasible to design an optimal G* for any k. In our design, for an N x N mesh with N spare router, each  column can have one faulty router. As the result, there are at most N faulty routers simultaneously.  B. 2D Mesh with Spare Router Redundancy  To address the problems mentioned above, we propose a novel  router level redundancy scheme as shown in fig. 2(a). The original  2D mesh is partitioned into groups of column set. Every router within  a column set collectively shares a common spare router (SR) setting  on the top row. We duplicate the connection path from the PE to a  pair of adjacent routers. As the result, every PE has a chance to  detour the attached faulty router or broken links. This dual link/router  scheme relieves the symptoms of isolated PE. The connection path is  configured by the ROM through add-on circuits like BIST. Fig. 2(b)  shows an example of three faulty routers and the connection patterns  between PEs and routers. To support the idea of spare router  architecture, the underlying interconnection structure is depicted in  fig. 3(a). For clarity, PEs are not shown in this figure. In the vertical  direction, every input port is attached with a 2-to-1 mux (except the  boundary routers). In the horizontal direction, every input port is  432            (a)                        (b)   Fig. 2. Spare router architecture. (a) 2D mesh NoC with spare  router. (b) Isolated PE path recovery attached with a 3-to-1 mux except the boundary routers (which are  attached with 2-to-1 mux). If a router is failed, for example, marked  R5 in fig. 3(b), the vertical interconnections are reconfigured to  detour the faulty router using 2-to-1 muxs. The original faulty router  is replaced by its upper adjacent router. For this reason, every router  above the faulty one is shifted up cascaded by one position.  Comparing fig. 3(a) with fig. 3(b), it is noted that the original R6 is  replaced by R5 and SR7 is replaced by R6. On the other hand, the  horizontal paths between adjacent columns are configured to  maintain the mesh topology.   We address the path allocation problem in the next two  subsections. Fig. 3(b) also demonstrates the faulty region problem in  which faulty routers (marked R2, R5, and R10) cut the design into  upper (R2, R5, R6, and R10) and lower (R0, R1, R4, R8, and R9)  half separated regions. As you can see, faulty routers/regions are  hardware bypassed. The resulting topology is still connected in the  2D mesh manner as shown  in fig. 3(c). In addition,  this  interconnection structure also inherently provides path diversities  5B-1 between adjacent router columns. With our defect awareness  configuration approach, as the experimental results show, this scheme  dramatically improves the system yield.  C. Shift-And-Replace-Allocation (SARA)  We first provide a simple and fast path configuration algorithm  called shift-and-replace-allocation (SARA). Routers with various  complex hardware failure modes are modeled by a survival matrix.  For example, fig. 3(b) has three faulty routers R2, R5, and R10. Fig.  3(d) is the corresponding survival matrix. The vertical path  configuration is straightforward since there exists only one way to  detour faulty router vertically. The horizontal paths are configured  through two iterations steps. The first step is to pick up the first  non-marked survival router. This step is performed column by  column. For example, R0, R4, R8 are selected and marked in the first  step. In the second step, muxs are configured to set up paths  connecting those candidate routers. In the second iteration, R1, R5,  R9 are picked up, and so on. The detail of SARA is listed in  algorithm 1. We assume that all routers are initially connected to their  neighboring routers. SARA is a linear time algorithm.  Algorithm 1. SARA (Ms, Mc) Input: Ms: survival matrix  Output: Mc: configured spared mesh.  1: initialize Rs = (cid:1486) 2: for r = 1 to RowSize(Ms)-1             //horizontal connection  3: for c = 0 to ColumnSize(Ms)-1  4:     p = first non-marked “1” in column c of Ms 5:     Rs = Rs(cid:1046)p 6:     Mark(p) 7: end for  8:   Connect(Rs , Mc) 9: Rs = (cid:1486) 10: end for 11: for c = 0 to ColumnSize(Ms)-1          // vertical connection  12: z = find “0” in column c of Ms 13: if z (cid:1035) (cid:1486) and is not in the boundary  14:     Connect(z-1,z+1)  15: end if 16: end for Return Mc 17: D. Defect-Awareness-Path-Allocation (DAPA)  Although SARA provides a convenient way to configure paths, it  only takes advantages of spare routers and does not exploit the full  potential of our architecture. As the complexity of SoC increases,  link reliability plays a critical role in the chip yield. The proposed  architecture inherently provides path diversities between adjacent  router columns. According to the faulty patterns, there are three cases  between two adjacent router columns. In the first case, as shown in  fig. 4(a), two adjacent routers are all faulty free (column 0 and 1). In  the second case, only one column has a faulty router (column 1 and  2). In the final case, both columns have a faulty router (column 2 and  3). For a column with N routers, in case one, there exists C(N,N-1)* C(N,N-1) connection patterns. In case two, there exists C(N,N-1)  connection patterns. In the final case, there exists only one possible  connection pattern. Fig. 4(b) is a 4-router column example.  Connection patterns between column 1 and 2 are demonstrated in fig.  4(c). Since there are a variety of possible connections in case 1 and 2,  to  take  advantage  of  this  facility, we  propose  a  defect-awareness-path-allocation  (DAPA)  algorithm which  dramatically improves the chip yield. The horizontal path allocation  of DAPA is listed in algorithm 2. In the iteration, DAPA examines  every possible match between two adjacent columns until a defect  free one is found.  Fig. 3. (a) Underlying interconnections of spared mesh. (b) Path  configurations to detour faulty regions/routers. (c) Resulting  topology is consistent with 2D mesh. (d) Survival matrix. 433 Fig. 4. (a) Faulty patterns between router columns. The left column  is column 0. (b) Connection pattern numbers of a 4-router column.  (c) All connection patterns between column 1 and 2. Algorithm 2. DAPA (Mo, Mc) Input: Mo: original spared mesh  Output: Mc: configured spared mesh.   1: initialize Cs = ColumnSize(Mo) 2: for c = 0 to Cs 3: tc = column c of Mo without faulty router  4: tc+1 = column c+1 of Mo without faulty router  5: Tc = Combinations(tc , Cs) 6: Tc+1 = Combinations(tc+1 , Cs) 7: for all vector vc (cid:1488) Tc , vc+1 (cid:1488) Tc+1 8:    Sort vc , vc+1 with router index order 9:    z = FindMatch(vc , vc+1) 10:    if PathTest(z) is pass 11:     Connect(z, Mc) 12:     Break 13:    end if  14: end for 15: end for Return Mc 16: IV. Evaluation Methodology and Experimental Results  To evaluate our design, we perform three most important fault  tolerance metrics: reliability, mean time to failure, and yield.  A. Reliability Analysis  The reliability of an NoC router Rr(t) is the probability that a  router performs its functionalities correctly from time 0 to time t. It is  decided by the failure rate, (cid:1267)(t) , which is measured by the number  of failures per time unit. After the router has passed the infant  mortality period, we can express Rr(t) using exponential failure law  [11]:  The analytical model for the traditional NxN mesh and (N+1)xN spared mesh are given in equation (2) and (3). In this paper, we  assume n = N in all equations. It is obvious in equation (2) that all  routers in an NxN mesh have to be operational to ensure the system’s  operations. As the result, the system reliability is the product of all  routers’ reliability. On the other hand, we split a spared mesh into N columns. To ensure the system’s operation, every column must be  operational. As shown in equation (3), the reliability of a system is  the product of columns’ reliability Rc. A column is operational if all  the routers within the column are operational or if only N of the N+1 routers are operational.  R We can now perform the quantitative reliability analysis with  equations (1) ~ (3). We assume the failure rate(cid:691) of a router is (cid:1267)= 0.00315(times/year) [14]. The reliability of different mesh size over 1  to 10 years is shown in fig. 5. As you can see, the spared mesh (SM)  architecture successfully outperforms the traditional one. As the mesh  size increases, the reliability curve of traditional 10*10 meshes drops  sharply from 0.74 to less than 0.1 over 1 to 10 years. However, the  spared one still maintains a considerable reliability in 10th year. To  highlight the effectiveness of our design, the reliability gain is shown  in fig.6. As the mesh size increases, the relative cost of spare router  decreases. However, as you can see, the reliability gain increases  proportionally to the mesh size and time. This result is valuable in the  architectural design.  B. Mean Time to Failure Analysis  The mean time to failure (MTTF) is the average time before a  system fails which can be expressed as the area under the reliability  curve:  We substitute equation (2) into (4), the MTTF for an NxN mesh  can be derived as the following:  (4) Fig. 6. Reliability gain of various size of (spared) mesh from  1~10 years 14 12 10 8 6 4 2 0 1 2 3 4 5 6 7 8 9 10 R e i l b a t i l i y G n a i Years Mesh vs. SM 10x10 vs.  11x10 8x8 vs. 9x8 6x6 vs. 7x6 4x4 vs. 5x4 Fig. 5. Reliability of various size of (spared) mesh from 1~10  years  1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 1 2 3 4 5 6 7 Years 8 9 10 R e i l b a t i l i y 5x4 SM 7x6 9x8 11x10 4x4  Mesh 6x6 8x8 10x10 (2)  (3)  (cid:540)t r −= e (t)R  (1)  nn × r mesh sys R = ) ( _ n nn r r n n n r c spared sys RR )( C R R R ]) 1( [ ) ( + 1 + 1 _ − + = = (cid:179) ∞ = 0 tR )( dt MTTF 5B-1 434                    1 nn ** λ By the same way, equation (3) is substituted into (4), the MTTF of  an (N+1)xN spared mesh is given by:   (6)  The MTTF for mesh (spared mesh) size from 3*3 (4*3) to 10*10  (11*10) is shown in fig. 7. The gain of MTTF is also depicted to  highlight that the effect of spared router grows with the NoC size.  C. Yield Analysis  The yield of our NoC router is modeled by the yield of router  switch fabric, control logic, and input ports (including multiplexers in  our design). Recent research has shown that correlation factor ((cid:1274)) between components should also be introduced in the yield  calculation [21]. According to [21], our router ’s yield is modeled by  equation (7). We assume a channel has 64-bit data wires, 4-bit control  and 8-bit parity wires. Table I lists the parameters used in our yield  evaluation work [21]. We perform the Monte Carlo simulation for the  NoC yield. Fig. 8 shows the flow chart of our simulation. The  experimental results are shown in fig. 9. The spared mesh with  SARA has the same yield curve in contrast with the traditional mesh.  However, the spared mesh with DAPA has different curve since it  drops slowly as the mesh size increases. The margin between SARA  and traditional mesh is purely earned by adding spare routers.  However, our architecture also provides path diversities between  adjacent router columns. DAPA takes advantage of this characteristic  and, as you can see, dramatically improve the system yield.   V. Performance Improvement with Application  Remapping The user applications of NoC-based manycore system are usually  optimized to meet the topology at the design time. Programmers need  to keep in mind the logical mesh topology. However, the underlying  physical interconnections are reconfigured to mask hardware defects.  A detouring wire introduces overhead of double wire length in  Manhattan grid as shown in fig. 10(a). This reveals the opportunity of  further performance tuning with application remapping. To map  applications onto a mesh topology is an instance of well known  NP-hard problem. We exemplify this remapping idea through a video  object plane (VOP) decoder [22] using parameterized simulated  annealing [23]. The task graph of the VOP decoder in [22] is redrawn  in fig. 10(b). A 4x4 mesh and a 5x4 mesh with spare routers are used  Fig. 7. MTTF and MTTF gain 7.7581 2.6988 1.2342 3.0864 0.7716 0.2778 2 2.5 3 3.5 4 4.5 8 7 6 5 4 3 2 1 0 3x3 4x4 5x5 6x6 Mesh Size 7x7 8x8 9x9 10x10 M F T T G n a i M F T T ( 0 1 5 H u o ) s r Spared Mesh Mesh MTTF Gain Fig. 9. Yield analysis  1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Y i e l d Mesh Size Spared  Mesh  (DAPA) Spared  Mesh  (SARA) Mesh Fig. 8. Monte Carlo simulation  TABLE I  PARAMETERS FOR YIELD CALULATIONS Parameter Description Clustering parameter  Correlation factor  Wire yield Yield of data, control, and parity wires Logic yield Yield of switch fabric, control, and port Value 2 0.5 99.99% 99.5% (cid:1257) (cid:1274) (7)  λ ) ∞ − 0 nn (* dt e MTTF t mesh (cid:179) = =         (5) [ [ ] RR ) ] dt R n nR dt C R MTTF n n r n r n n r r n n n r mesh spared (cid:179) (cid:179) 0 ∞ + ∞ + + + + − = − + = 0 1 1 1 _ )1 ( 1( − α 1 − α port 1 − α port − 1 α port 1 − α ctrl 1 − α port − 1 α sw 1 − α ctrl 1 − α sw 1 − α ctrl 1 − α sw 1 − α ctrl 1 − α sw σ ( Yield σ ( Yield σ ( Yield σ ( Yield − − − +− )1 − +− )1 − +− )1 − +− )1 +− )1 +− )1 += (1( Yield ))1 )(1 Yield )(1 Yield )(1 Yield )(1 Yield )(1 Yield ( Yield ( Yield router Yield 5B-1 435     5B-1 as the underlying topology. We consider the wo rst case of a defect  mesh with our spare router architecture usin ng remapping and  detouring schemes. That is, every column has a a faulty router. The  cost is calculated by multiplying the VOP task gra aph edge weight and  inter-router channel length (measured by Manha attan distance). Fig.  11 is an example of mapping result. Simulation  results are listed in  table II. Under the worst case mentioned above,  a defect mesh with  spare routers using remapping scheme introduces s only 6% overhead  compared to the non-defect version and the overh head increase is 22%  using detouring scheme.               (a)                      (b b) Fig. 10. (a) Detouring/Unchanged path cost under r Manhattan  distance (b) Task graph of VOP decoder   Fig. 11. Example of mapping VOP decoder onto  and a defect spared mesh with 4 faulty routers.   a non-defect mesh  APPLICATION REMAPPING AVERAGE C COST TABLE II  Non-defect  mesh  4153  Average  Cost  Defect mesh with  spare router using  remapping Defect mesh with  spare router using  detouring scheme 4424  5093  VI. Summary and Conclusio ons In this paper, we propose a router-level redu undancy scheme on  fault tolerance NoC design. The architecture is sim mple and structural.  The combination of spare routers and diversifie ed inter-router links  successfully improve the system reliability, MT TTF, and yield. In  addition, two notorious problems on NoC includ ding isolated PE and  faulty regions can be relieved through our  design. Two path  configuration algorithms are demonstrated. Faul lty routers/links are  hardware detoured and the resulting topology is s still consistent to the  original mesh. This implies that our design can a achieve transparency  to the upper layers, i.e. routing algorithms, oper rating systems, and  user applications. In addition, the reliability gai in and yield of our  design increases with the growth of NoC size b but the relative cost  decreases in the same time. This valuable chara acteristic convinces  that our fault tolerance scheme is especially sui itable for the future  large scale NoC design. "
2011,iWISE - Inter-router Wireless Scalable Express Channels for Network-on-Chips (NoCs) Architecture.,"Network-on-Chips (NoCs) paradigm is fast becoming a defacto standard for designing communication infrastructure for multicores with the dual goals of reducing power consumption while improving performance. However, research has shown that power consumption and wiring complexity will be two of the major constraints that will hinder the growth of future NoCs architecture. This has resulted in the investigation of emerging technologies and devices to alleviate the power and performance bottleneck in NoCs. In this paper, we propose iWISE, an inter-router wireless scalable express channels for NoCs architecture that minimizes the power consumption via hybrid wireless communication channels, reduces the area overhead with smaller routers and shared buffers, and improves performance by minimizing the hop count. We compared our network to leading electrical and wireless topologies such as mesh, concentrated mesh, flattened butterfly and other wireless hybrid topologies. Our simulation results on real applications such as Splash-2, PARSEC, and SPEC2006 for 64 core architectures indicate that we save 2X power and 2X area while improving performance significantly. We show that iWISE can be further scaled to 256 cores while achieving a 2.5X performance increase and saving of 2X power when compared to other wireless networks on synthetic workloads.",
2007,Avoiding Message-Dependent Deadlock in Network-Based Systems on Chip.,,
2006,Applying Partial Reconfiguration to Networks-On-Chips.,"This paper presents CoNoChi, an adaptable network-on-chip for dynamically reconfigurable hardware designs. CoNoChi is designed for taking advantage of the partial dynamic reconfiguration capabilities of modern FPGAs and applies this feature to adapt the network structure to the location, number and size of currently configured hardware modules. The network consists of the minimal number of switches required. Switches can be added or removed from the network by a global control instance at runtime. Compared to common fixed network-on-chip structures, the CoNoChi architecture reduces the area requirements and latency of the network and eases the online placement of hardware modules. Two variants of CoNoChi are presented: one is based on a homogeneous hardware structure that is dynamically reconfigurable on logic block level, and the other one is adapted to the limited partial reconfiguration capabilities of Xilinx Virtex-II (Pro) FPGAs",
2006,A Low Cost Network-on-Chip with Guaranteed Service Well Suited to the GALS Approach.,"The paper presents the DSPIN micro-network, that is an evolution of the SPIN architecture. DSPIN is a scalable packet switching micro-network dedicated to GALS (globally asynchronous, locally synchronous) clustered, multi-processors, systems on chip. The DSPIN architecture has a very small footprint and provides to the system designer both guaranteed latency, and guaranteed throughput services for real-time applications",
2006,A Hybrid SoC Interconnect with Dynamic TDMA-Based Transaction-Less Buses and On-Chip Networks.,"The two dominant architectural choices for implementing efficient communication fabrics for SoC's have been transaction-based buses and packet-based networks-on-chip (NoC). Both implementations have some inherent disadvantages - the former resulting from poor scalability and the transactional character of their operation, and the latter from inconsistent access times and deterioration of performance at high injection rates. In this paper, we propose a transaction-less, time-division-based bus architecture, which dynamically allocates timeslots on-the-fly - the dTDMA bus. This architecture addresses the contention issues of current bus architectures, while avoiding the multi-hop overhead of NoC's. It is compared to traditional bus architectures and NoC's and shown to outperform both for configurations with fewer than 10 PE's. In order to exploit the advantages of the dTDMA bus for smaller configurations, and the scalability of NoC's, we propose a new hybrid SoC interconnect combining the two, showing significant improvement in both latency and power consumption.",
2004,Topology optimization for application-specific networks-on-chip.,"Compared to the well understood macro networks, networks-on-chip introduce novel design challenges. The characteristics of the system data flows and the knowledge of the required wire lengths can be exploited to optimize for speed and power consumption. A component library for flexible construction of interconnection architectures is being developed at the Tampere University of Technology to enable the creation of application development platforms. The overall design flow of these development platforms is reviewed in this paper. Network-on-chip topology optimization is addressed by describing the methodologies used by an effective design automation tool. The detailed cost functions of the tool capture the factors contributing to the speed and power consumption of asynchronous interconnections, while different abstraction level input information is supported. A case study into the application domain of industrial process control and monitoring is presented in order to evaluate the result quality.",
2013,A Scalable 3D Heterogeneous Multicore with an Inductive ThruChip Interface.,"The authors developed a scalable heterogeneous multicore processor. 3D heterogeneous chip stacking of a general-purpose CPU and reconfigurable multicore accelerators enables various trade-offs between performance and energy consumption. The stacked chips interconnect through a scalable 3D network on a chip (NoC). By simply changing the number of stacked accelerator chips, processor parallelism can be widely scaled. No design change is needed, and hence, no additional nonrecurring engineering (NRE) cost is required. An inductive-coupling ThruChip Interface (TCI) is applied to stacked-chip communications, forming a low-cost and robust high-speed 3D NoC. The authors developed a prototype system called Cube-1 with 65-nm CMOS test chips, and confirmed successful system operations, including 10 hours of continuous Linux OS operation. Simple filters and a streaming application were implemented on Cube-1 and performance acceleration up to about three times was achieved.",
2012,A Reliable Routing Architecture and Algorithm for NoCs.,"Aggressive transistor scaling continues to drive increasingly complex digital designs. The large number of transistors available today enables the development of chip multiprocessors that include many cores on one die communicating through an on-chip interconnect. As the number of cores increases, scalable communication platforms, such as networks-on-chip (NoCs), have become more popular. However, as the sole communication medium, these interconnects are a single point of failure so that any permanent fault in the NoC can cause the entire system to fail. Compounding the problem, transistors have become increasingly susceptible to wear-out related failures as their critical dimensions shrink. As a result, the on-chip network has become a critically exposed unit that must be protected. To this end, we present Vicis, a fault-tolerant architecture and companion routing protocol that is robust to a large number of permanent failures, allowing communication to continue in the face of permanent transistor failures. Vicis makes use of a two-level approach. First, it attempts to work around errors within a router by leveraging reconfigurable architectural components. Second, when faults within a router disable a link's connectivity, or even an entire router, Vicis reroutes around the faulty node or link with a novel, distributed routing algorithm for meshes and tori. Tolerating permanent faults in both the router components and the reliability hardware itself, Vicis enables graceful performance degradation of networks-on-chip.",
2011,A Wireless Network-on-Chip Design for Multicore Platforms.,"Aggressive scaling of transistors allows integration of hundreds of processors on a chip. However, on-chip interconnects carrying signals between different blocks will be the bottleneck for system performance and reliability. To tackle this problem, we developed an on-chip communication infrastructure based on a network-on-chip architecture and developed a hybrid mechanism to transfer data among IP cores by taking advantages of both wired and wireless communications. By using on-chip antennas, one can provide on-chip wireless communication to transfer data across long distances and minimize transfer latency and energy dissipation accordingly. A wireless network-on-chip architecture was designed and evaluated, and the experimental results showed significant improvement in transfer latency, network throughput and energy dissipation.",
2008,Secure Memory Accesses on Networks-on-Chip.,"Security is gaining increasing relevance in the development of embedded devices. Towards a secure system at each level of design, this paper addresses security aspects related to network-on-chip (NoC) architectures, foreseen as the communication infrastructure of next-generation embedded devices. In the context of NoC-based multiprocessor systems, we focus on the topic, not yet thoroughly faced, of data protection. In this paper, we present a secure NoC architecture composed of a set of data protection units (DPUs) implemented within the network interfaces. The run-time configuration of the programmable part of the DPUs is managed by a central unit, the network security manager (NSM). The DPU, similar to a firewall, can check and limit the access rights (none, read, write, or both) of processors accessing data and instructions in a shared memory - in particular distinguishing between the operating roles (supervisor/user and secure/unsecure) of the processing elements. We explore different alternative implementations for the DPU and demonstrate how this unit does not affect the network latency if the memory request has the appropriate rights. We also focus on the dynamic updating of the DPUs to support their utilization in dynamic environments, and on the utilization of authentication techniques to increase the level of security.","1216 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Secure Memory Accesses on Networks-on-Chip Leandro Fiorin, Student Member, IEEE, G ian luca Pa lermo, Member, IEEE, S lobodan Lukov ic, Student Member, IEEE, Va ler io Cata lano, and Cr ist ina S i lvano, Member, IEEE Abstract—Security is gaining relevance in the development of embedded devices. Toward a secure system at each level of design, this paper addresses security aspects related to Network-on-Chip (NoC) architectures, foreseen as the communication infrastructure of next-generation embedded devices. In the context of NoC-based multiprocessor systems, we focus on the topic, not yet thoroughly faced, of data protection. In this paper, we present a secure NoC architecture composed of a set of Data Protection Units (DPUs) implemented within the Network Interfaces (NIs). The runtime configuration of the programmable part of the DPUs is managed by a central unit, the Network Security Manager (NSM). The DPU, similar to a firewall, can check and limit the access rights (none, read, write, or both) of processors accessing data and instructions in a shared memory. In particular, the DPU can distinguish between the operating roles (supervisor/user and secure/nonsecure) of the processing elements. We explore alternative implementations of the DPU and demonstrate how this unit does not affect the network latency if the memory request has the appropriate rights. We also focus on the dynamic updating of the DPUs to support their utilization in dynamic environments and on the utilization of authentication techniques to increase the level of security. Index Terms—Embedded systems, security, data protection, Multiprocessor System-on-Chip (MPSoC), Networks-on-Chip (NoCs). Ç 1 INTRODUCTION FUTURE technology trends [1] envision that the next g e n e r a t i o n o f M u l t i p r o c e s s o r S y s t em s - o n -C h i p (MPSoCs) will be composed of a combination of a high number of processing and storage elements interconnected by complex communication architectures. Processing elements will include general purpose processors and specialized cores, such as digital signal processors (DSPs), very long instruction word (VLIW) cores, programmable cores (FPGAs), application specific processors, analog front end, and peripheral devices. The integration of many heterogeneous cores will be possible thanks to advances in nanoelectronic technologies, enabling billions of transistors on a single chip, running at multigigahertz speed, and operating at supply voltages below 1 V. One solution to reduce design complexity and the gap between advances in the development of manufacturing technology and those of synthesis and compiler technology has been foreseen in the reuse of previously developed Intellectual Propriety (IP), which will constitute the basic blocks for the designers. However, the design of this type of heterogeneous systems raises the problem of having tools for synthesis and compilation that could efficiently exploit the large number of resources available to designers. The communication and interconnection between these basic blocks assume crucial importance when the number . L. Fiorin and S. Lukovic are with ALaRI, Faculty of Informatics, University of Lugano, Switzerland. E-mail: {fiorin, lukovics}@alari.ch. . G. Palermo and C. Silvano are with the Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy. E-mail: {gpalermo, silvano}@elet.polimi.it. . V. Catalano is with ST Microelectronics, AST Grenoble Lab, 12 Jules Horowitz, 38019, Grenoble, France. E-mail: valerio.catalano@st.com. Manuscript received 2 July 2007; revised 4 Mar. 2008; accepted 13 Mar. 2008; published online 10 Apr. 2008. Recommended for acceptance by R. Marculescu. For information on obtaining reprints of this article, please send e-mail to: tc@computer.org, and reference IEEECS Log Number TCSI-2007-07-0294. Digital Object Identifier no. 10.1109/TC.2008.69. of these elements increases. Indeed, the complexity of new systems spawns the challenge of enabling reliable communication channels between cores; a challenge that becomes more and more difficult as the number of integrated cores per design increases. The traditional solution for intercore communication based on shared bus will soon become unable to guarantee sufficient levels of efficiency, both from the performance and the power consumption perspectives. Networks-on-Chip (NoCs) [2], [3] appeared as a strategy to connect and manage the communication between several design elements and IP blocks, as required in complex Systems-on-Chip (SoCs). Even if the NoC idea seems an adaptation to the SoC context of parallel computer network concepts, many research issues are still open due to their different constraints and the amount of resources available. Key open points in the current literature are, for instance, the choice of network topology [4], [5], [6], [7], [8], [9], [10], routing strategies [11], [12], [13], [14], [15], flow control [11], [12], [16], queuing sizing and management [11], [17], and methods to guarantee Quality of Service (QoS) at low hardware cost [18], [19], [20], [21]. Another research problem only recently addressed by the community [22], [23], [24], [25], [26], [27] concerns the aspect of security in systems adopting the NoC paradigm. In fact, the advantages given by the use of such a complex communication infrastructure may introduce new weaknesses in the system that could be potentially critical and should be investigated [24]. Indeed, as computing and communication increasingly pervade our lives, security and protection of sensitive data are emerging as issues of extreme importance, in particular in the case of embedded systems, which, due to their intrinsic constraints, present several unique security challenges [28], [29]. Security problems in embedded systems may be caused by attacks exploiting software weaknesses (such as in the case of buffer overflow [30]) or information gained from the physical 0018-9340/08/$25.00 ß 2008 IEEE Published by the IEEE Computer Society FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1217 implementation of a system (such as in the case of side channel attacks [31]). In particular, we address the problem of protecting data in NoC-based MPSoCs from illegal access of unauthorized IP cores. We provide a solution to contrast attacks aiming at obtaining accesses to restricted blocks of memory and exploiting techniques (such as the buffer overflow) that have been the basis for a relevant number of attacks and the most common form of security vulnerability for the last 10 years [32]. While research on architectural aspects and design automation related to NoCs has been particularly active, security in such systems thus far remains mainly unexplored, even if, as previously said, security-aware design of communication architectures is becoming a necessity in the context of the overall embedded device. Therefore, in this work, we focus on security aspects related to NoCs, keeping in mind the overall goal that “security” should be considered at each level of design in future embedded systems. In this paper, we propose a secure network architecture —extending the work presented in [33]—based on Data Protection Units (DPUs) integrated into the Network Interfaces (NIs) of the NoC. The runtime configuration of the programmable part of the DPUs is managed by a central unit, the Network Security Manager (NSM). With respect to [33], this paper shows a flexible implementation of the secure network architecture that is suitable for dynamic systems characterized by multiple applications and a reconfigurable environment. The DPU guarantees secure accesses to memories and/or memory-mapped peripherals. The proposed DPU represents a hardware solution enabling access to a given memory space only if the initiator of the request is authorized. Access filtering is performed by considering not only the memory address but also the type of operation requested (data load/store and instruction execute) and the status of the initiator (user or supervisor mode and secure or unsecure mode [34]). The use of the DPU offers the possibility of easily loading/ storing critical data and instructions while protecting them from illegal accesses by malicious code running on compromised cores, without requiring time-consuming encryption/decryption and guaranteeing a fast memory access. The use of the NSM guarantees the runtime flexibility of the approach. The paper is organized as follows: Section 2 provides an overview of the current state of the art of security solutions implemented in NoCs. Section 3 discusses the model of thread that the solution we propose addresses. Section 4 defines the architecture of the proposed DPU and discusses several design alternatives and implementation issues. In Sect ion 5 , we extend the work to inc lude runt ime configurability of the protection system. Finally, experimental results are reported in Section 6 and conclusions are discussed in Section 7. 2 RELATED WORK Viruses and worms for mobile phones have been reported for several years now [35] and they are foreseen to develop and spread as the targeted systems will increase in functionalities offered and complexity. Security is gaining increasing relevance in the design of embedded systems [28], [29], [36]. In fact, in everyday life, we deal with an increasing number of electronic devices capable of communicating with each other and sharing critical information. Mobile battery operated embedded systems are likely to be the ideal target for malicious attackers [37], due in particular to the intrinsic constraints given by the limited amount of resources available and the limited autonomy of the power source. Secure architectures for processors have been the object of interesting studies in [38], [39]. However, only recently have the aspects of security related to NoC-based systems been taken into account. A specific solution to secure the exchange of cryptographic keys within an NoC is presented in [23] and [22]. The work addresses in particular protection from the power/EM attacks of a system containing not-secure cores, as well as secure ones, defined as hardware IP cores that can execute one or more security applications. The framework supports authentication, encryption, key exchange, new user keys and public key storage, and similar procedures. No unencrypted key leaves the cores of the NoC and only secure IP cores running trusted software are supported. At the network level, security is based on symmetric key cryptography, where each secure core has its own security wrapper storing a private network key in nonvolatile memory. Diguet et al. [25] propose a first solution to secure a reconfigurable SoC based on NoC. The system is composed of Secure NIs (SNIs) and a Secure Configuration Manager (SCM). The SNIs act as a filter for the network and handle attack symptoms that may be caused by denial-of-service attacks and unauthorized read/write accesses. The SCM configures system resources and NIs, monitoring the system for possible attacks. A routing technique based on reversed forward path calculation is proposed in [24]. The technique allows verifying that the sender of the packet that arrived at a specific SNI has the right to communicate with it. It is worth noting that the use of protected transactions is also included in the specifications defined by the Open Core Protocol International Partnership (OCP-IP) Association [34]. The standard OCP interface can be extended through a layered profile in order to create a secure domain across the SoC and provide protection against software and some selective hardware attacks. The secure domain might include CPU, memory, I/O, etc., that need to be secured by using a collection of hardware and software features such as secured interrupts, secured memory, or special instructions to access the secure mode of the processor. With respect to the above-presented related work, the subject of our paper can be considered orthogonal and complementary since we investigate a solution for the specific problem of data protection in NoCs. Memory data protection in more general embedded systems is another subject that should be considered as relevant to our work. A specific implementation of a protection unit for data stored in memory is described in [40]. The proposed module enforces access control rules that specify how a component can access a device in a particular context. AMBA bus transactions are monitored in order to discover specific attacks such as buffer overflow to steal cryptographic keys used in Digital Right Management. A lookup table indexed by the concatenation of the master identifier signals and the system address bus is employed to store and check access rights for the addressed memory location and to stop potential not-allowed initiators. 1218 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 1. Example of an application causing buffer overflow. Considering commercial implementations of on-chip memory protection units, ARM provides, in systems adopting the ARM TrustZone technology [41], the possibility of including a specific module—the AXI TrustZone memory adapter—to support secure-aware memory blocks. A single memory cell can be shared between secure and nonsecure storage areas. Transactions on the bus are monitored to detect the addressed memory region and security mode in order to cancel nonsecure accesses to secure regions and accesses outside the maximum address memory size. The module is configured by the TrustZone Protection Controller, which manages the secure mode of the various components of the TrustZone-based system and provides the software interface to set up the security status of the memory areas. A solution similar to the one presented above is provided by Sonics [42] in its SMART Interconnect solutions. An on-chip programmable security “firewall” is employed to protect the system integrity and the media content passed among on-chip processing blocks, various I/Os, and the memory subsystem. The firewall is implemented through an optional access protection mechanism to designate protection regions within the address space of specified targets. The mechanism can be dynamic, with protection region sizes and locations that can be programmed at runtime. It can also be role dependent, with permissions defined as a function of not only which initiator is attempting to access but also which processing role the initiator is playing at that time. Protection regions subdivide a target’s address space, where each target can have up to eight protection regions. Each protection region is assigned to one of the four levels of priority. This work represents a step further than previous implementations of data protection techniques since, for the first time, it faces the problem of the data protection on an NoC-based MPSoC. This work presents a solution for data protection with a finer granularity (especially with respect to the ARM TrustZone), which will be more useful for the next generation of security-enhanced multiprocessor systems. With respect to a bus-based solution, this work takes into consideration the characteristic of NoC-based systems of representing a distributed environment. To exploit the distributed nature of the network, in this paper, we analyze the possibility of implementing local or remote DPUs, we study different design alternatives for the target architectures Fig. 2. Stack behavior during the exploitation of buffer overflow. used as a case study, and we describe the design of a central unit to dynamically manage data protection. 3 MOTIVATIONS Protection of critical data represents a challenging task in MPSoCs, where blocks of memory are often shared among several IPs. Unauthorized access to data and instructions in memory can compromise the execution of programs running on the systems—by tampering with the information stored in selected areas—or cause the acquisition of critical information by external entities, such as in the case of systems dealing with the exchange and management of cryptographic keys [40]. Attacks exploiting buffer overflow aim at writing outside the bounds of a block of the allocated memory in order to corrupt data, crash the program, or cause the execution of malicious code. The buffer overflow [30] is probably the most well-known type of attack to obtain illegal memory accesses. In a traditional attack exploiting buffer overflow, the attacker passes as program argument data whose dimension will exceed the one allocated in the stack buffer. As a result, the information on the stack is overwritten, as well as the return address. The data passed to the program is crafted in order to set the value of the return address to point to the malicious code contained in the attacker’s data. When the function returns, the malicious code is executed. An example of a simple application vulnerable to buffer overflow attacks is shown in Fig. 1. In the code shown, strcpy() is the vulnerable function. In fact, this C function lacks bound checking and, when the string passed as funcðchar pÞ is bigger than the reserved argument of memory space for the buffer, the information passed overwrites the adjacent positions in the stack (see Fig. 2). The input string can be maliciously arranged in order to contain the attack code and a return address pointing to the initial instruction of the attack code, which can be, for instance, a virus or a program aiming at retrieving confidential information from the memory. In fact, once the malicious code is running on the compromised core, it can exploit the rights of the application and the core to access the memory. A practical example of exploitation of buffer overflow in embedded systems is presented in detail in [40], where the attacker tries to obtain a copy of the cryptograph ic key used to ver ify the integr ity and authenticity of the rights of the object employed in the Digital Rights Management protocol. Considering distributed off-chip shared-memory multiprocessors [43], [44], the main security problems are caused by the possibility of physically accessing the communication FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1219 subsystem. In this case, one of the most famous attacks is the insertion of a device targeting tapping or tampering with a bus to change program behavior [43], [45]. For example, Sony PlayStation and Microsoft Xbox can be hacked by modchips [45], which can be soldered to the buses on the motherboard, allowing the console to play pirated games. A clean machine always checks the digital signature and media flags from a registered CD by executing a small code in BIOS. A modchip monitors the buses to block the code from the BIOS and injects spoofing code at the appropriate time. The hacked machine will execute the new code that skips authorization checks. This kind of attack can be easily performed. In fact, the cost of the modchip is around $60, while installing the chip is a relatively easy operation [45]. In MPSoC architectures based on NoC, these direct attacks to the communication subsystem will be unfeasible since there is no physical network access. The presence of an NoC also avoids the possibility of sniffing (or snooping) the information that is passing through the communication channel if the messages are not explicitly broadcast by the initiator of the communication. The only way to replicate the previous attacks in such systems is to use direct read/ write operations to the memory subsystem since it stores the system status. According to [46], we can classify attacks to the memory or to the communication subsystem in three categories: . . Sabotage. This first type of attack has as its main goal crashing the application or damaging the target system. An example is the possibility of writing random values in the memory by overwriting the application source code and its data. This type of attack does not need any knowledge of the target application, but, on the other hand, it lacks incentive to be performed since the financial reward for a sabotage attack is very limited. Passive. The main characteristic of this attack is that, typically, it is noninvasive. In fact, the goal of the attacker is only to steal sensitive information without modifying the system behavior and without being discovered. Reading passwords or economic information directly from the memory are simple examples of passive attacks. . Active. This is for sure the most difficult attack to perform since it needs a deep knowledge of the target application, but, on the other hand, it is the most fruitful for the attacker. Active attacks result in an unauthorized state change of the target applications such as the manipulation of memory data to perform other unauthorized actions. We d id no t make any assump t ion on the spec i f ic capabilities of the attacker to obtain control of processing cores to illegally access the memory since it is out of the scope of this paper. However, it is possible to note how, without a mindful hardware design, simple software fallacies (such as the buffer overflow) can give the attacker the possibility of performing all of the above-mentioned memory attacks without much difficulty. The secure communication system we propose in this work is conceived to deal with the previously described memory-based attacks and weaknesses intrinsic to a multiprocessor system with shared memory, exploiting the characteristics of the NoC to detect and to prevent them. 4 SYSTEM ARCHITECTURE AND DATA PROTECTION UNITS In this section, a basic data protection infrastructure for architectures adopting the NoC communication paradigm is proposed. First, we discuss the target system architecture; then, we propose a hardware solution, called DPU, enabling accesses to memories and/or memory-mapped peripherals only to authorized requests. 4.1 Description of the System The target system of the proposed data protection infrastructure is a shared-memory multiprocessor architecture based on NoCs. We assume an NI compliant with the specifications of the OCP/IP interface [34], [27]. Signals coming from the processors are translated by the NI into packets of the protoco l used w ith in the NoC . The communication is transaction-based in order to offer to IP modules a shared-memory abstraction [47] and, therefore, we assume the elements on the NoC to be memory mapped. Following the transaction-based protocol, it is possible to distinguish between IP modules acting as initiators or as targets. Initiators are enabled to begin both a load (read) and a store (write) transaction to targets. The protocol used to exchange data between the initiator and the target in the network is simple and always requires sending back an acknowledgment (or not-acknowledgment) message to the initiator for each request, for both load and store transactions. If the transaction is accepted, the target replies by sending back an acknowledgment message (ack) and, in case of load, also the requested data. If the transaction is rejected, a not-acknowledgment message (nack) is sent back to the initiator. Within the NoC, we adopt a packet format such as the one presented in Fig. 3. The DPU exploits the information forwarded within the packet to perform access control on the requests arriving at the target. The implementation proposed for the DPU depends on the specific format of the packet. The proposed DPU architecture can be easily adapted to different protocol formats. The proposed format of the packet header (see Fig. 3) is compliant with the OCP/ IP interface and it is composed of the following fields: . . DestID is used to identify the target of the request (we assume a table-based routing depending on the source and destination addresses). The OCP/IP MAddr field is converted by the NI, following the shared-memory abstraction, to obtain the DestID identifier. SourceID identifies the initiator of the transaction and, depending on the granularity of the system, could refer to the identification number of the node in the NoC, to a single IP in a cluster (assuming more IPs are connected to the NoC through the same NI), or to a thread running on a specific IP core. This field comes from information provided by the OCP/ IP interface (MConnID and MthreadID), representing, respectively, the processor identifier and the thread identifier, and a value stored into the NI representing the network node identifier (NodeID). 1220 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 4. Simple system with three initiators (P s) and one target (Mem) showing the two different network architectures using the DPU (a) at the target NI and (b) at the initiator NIs. examples, the size of the SourceID fields has been designed in Fig. 3 for a system with a number of connections up to 255, where the connection number is a combination of the number of network nodes, the number of IPs on the same network node, and the maximum number of threads active in the same IP. 4.2 DPU: Basic Description The DPU is a hardware module that enforces access control rules specifying the way in which an IP initiating a transaction to a shared memory in the NoC can access a memory block. The partitioning of the memory into blocks allows the separation between sensitive and nonsensitive data for the different processors connected to the NoC. In the first proposed architecture (see Fig. 4a), the DPU is a module embedded into the NI of the target memory (or the memory-mapped peripheral) to protect, supplying services similar to those offered by a traditional “firewall” in data networks. In brief, the DPU filters the requested accesses to the memory blocks through a lookup of the access rights, done in parallel with the protocol translation within the NI. In the second proposed solution, the filtering of memory accesses is done at the NI of each initiator (Fig. 4b). A detailed description of the behavior of the protection system is given in the following sections, where we describe the two alternative implementations of the proposed solution for the data protection: the DPU architecture implemented at the target NI, called DPU@TNI (Section 4.3), and the DPU architecture implemented at the initiator NI, called DPU@INI (Section 4.4). 4.3 DPU at the Target NI (DPU@TNI) Figs. 5 and 6, respectively, show the architecture details and the whole system overview when the DPU is embedded at the target NI (DPU@TNI). For this architecture, the DPU checks the header of the incoming packet to verify if the requested operation is allowed to access the target. This access control is done mainly by using a look-up table (LUT), where entries are indexed by the concatenation of information ðD=I Þ, and the the SourceID, the type of starting address of the requested memory operation MemAddr. The number of entries in the table depends on the number of memory blocks to be protected in the system, as well as on the number of initiators. In the implementation shown in Fig. 5, we assume 4 Kbytes as the size of the smallest memory block to be managed for the access rights. Fig. 3. Interface between the OCP/IP signals and the packet format used within the NoC. . . . MemAddr is the memory address of the initiator requesting access and it is the direct translation of the MAddr signals of OCP/IP interface. Length field represents (in number of words) the length of the data to be sent/retrieved. The burst informat ion der ived by the OCP/IP interface (MBurstLength, MBurstPrecise, and MBurstSeq) is used to define the length of the information to be sent/received. L/S encodes which kind of operation ðload=storeÞ the initiator requests at the target memory address. It corresponds to the MCmd signal of the OCP/IP interface. . D/I and Role, respectively, identify data=instruction and initiator role ðuser=supervisorÞ associated with the request. These bits correspond to MReqInfo[2:3] signals that, following OCP/IP recommendations for the security profile [34], are used to forward information about the type of data and initiator role. . Opt represents an optional field that can be used to add further network services. The size of the DestID, SourceID, and Length fields depends on system parameters (the number of targets for DestID, the number of initiators and threads for initiator for SourceID, and the maximum burst size for Length). As FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1221 (shown in Fig. 5), avoiding access to a memory block not matching any entry in the DPU LUT by using a match line. The second one, less conservative, also enables the access in the case when there is no match in the DPU LUT. This corresponds to the case when a set of memory blocks does not require any access verification. The output enable line of the DPU is generated by a logic AND operation between the access rights obtained by the lookup, the check on the block boundaries, and, considering the more conservative version of the DPU, the match on the LUT. Given the complexity of the protocol conversion to be done by the NI kernel, we can assume that the DPU critical path is shorter than the critical path of the NI kernel (as confirmed in the results reported in Section 6). Under this assumption, integrating the DPU at the target NI guarantees that no additional latency is associated with the access right check since, as shown in Fig. 6 , the protocol conversion and the DPU access are done in parallel. 4.4 DPU at the Initiator NI (DPU@INI) Figs. 7 and 8 show, respectively, the architecture details and the whole system overview when the DPU is embedded at the initiator NI (DPU@INI). For this architecture, the DPU directly uses the signals coming from the OCP/IP slave interface of the NI for the access rights evaluation. As shown in Fig. 3, when the PE begins a transaction driving the OCP/IP Master interface signals, the NI looks up the MAddr signals in order to obtain the routing information to be inserted in the DestID field in the header of the packet. At the same time, the DPU looks up the information coming from the OCP/IP interface to check if the request has the right to access the addressed memory block. As shown in Fig. 7, in the DPU@INI architecture, each entry of the LUT is indexed by the concatenation of MConnID, MThreadID, and part of MAddr. In this case, the number of entries in the LUT depends only on the number of blocks to be protected in the target memories since the initiator NI is related to only one processing element. As well as in DPU@TNI, when the information present at the OCP/IP interface matches one entry line in the LUT, the LUT returns the access rights for the roles of the initiator (user load/store and supervisor load/store). The MCmd and MReqInfo signals coming from the OCP/IP interface represent the selection lines in the 4:1 multiplexer placed at the output of the RAM. A parallel check on the MBurstLength is done to verify if the block boundaries are respected. Fig. 5. DPU architecture at the Target Network Interface (DPU@TNI). This means that all data within the same block of 4 Kbytes have the same rights (corresponding to the 12 LSB in the memory address) and that we use only the 20 most significant bits of the MemAddr field for the lookup. The LUT of the DPU is the most relevant part of the architecture and it is composed of three parts: . A Content Addressable Memory (CAM) [48] used for the lookup of the SourceID and the type of data ðD=I Þ, . A Ternary CAM (TCAM) [48] used for the lookup of the MemAddr. With respect to the binary CAM, the TCAM is useful for grouping ranges of keys in one entry since it allows a third matching state of “X” (Don’t Care) for one or more bits in the stored datawords, thus adding more flexibility to the search. In our context, the TCAM structure has been introduced to associate to one LUT entry memory blocks larger than 4 Kbytes. . A simple RAM structure used to store the access right values. Each entry in the CAM/TCAM structure indexes a RAM line containing the access rights ðallowed=notallowedÞ for user load/store and supervisor load/store. The type of operation ðL=S Þ and its role ðU =S Þ taken from the incoming packets are the selection lines in the 4:1 multiplexer placed at the output of the RAM. Moreover, a parallel check is done to verify that the addresses involved in the data transfer are within the memory boundary of the selected entry. If the packet header does not match any entry in the DPU, there are two possible solutions, depending on the security requirements. The first is more conservative Fig. 6. Overview of the whole NoC-based architecture including the DPU@TNI. 1222 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 the system shown in Fig. 6 (DPU@TNI). In the example, we consider a store operation of 512 bytes of data, starting from the memory address equal to 0x01B02CF0. The PE is identified by a SourceID equal to 0x2D, its operating role is user ðRole ¼ 0Þ, and the target memory has a node identifier (DestID) equal to 0x0A. In case of a store operation, the PE drives the OCP/IP signals to begin the data transfer in a bursty way [34] and the NI behaves as a slave for the OCP/IP protocol. As described in Section 4.1, the front end of the NI looks up the information on the first address of the burst on MAddr to obtain the routing information to be inserted in the field DestID in the header of the packet. The control signals of the OCP/IP transaction are extracted from the OCP/IP adapter and coded into the NI kernel to build the packet header (see Fig. 3). Then, the NI samples data from OCP/IP MData and creates the payload of the packet. Considering the DPU@TNI architecture, the header of the packet, followed by the payload, is therefore sent through the network to the target NI. While the NI kernel is processing the header of the packet and waiting for the payload, the DPU checks in parallel the header information to verify the access rights. As shown in Fig. 9, since one of the LUT entries matches the request, the corresponding 4 bits stored in the RAM are passed to the multiplexer. In parallel, the DPU also verifies that the addresses involved in the data transfer (from MemAddr to MemAddr+512) are within the memory bounds of the selected entry (0x01B02000-0x01B02FFF). Because the header information matches one entry of the LUT, the related right value is equal to “1,” and the memory addresses are within the boundaries, the DPU enables the requested store operation, also allowing the NI to initiate the OCP/IP transaction for a write in the target memory. When the transaction completes, a signal of acknowledgment is sent back to the initiator NI to notify it about the end of the data transfer. In the case of a not-allowed memory request, the DPUs would stop the protocol translation, avoiding the OCP/IP transaction, notifying a security warning, and sending back to the initiator NI a not-acknowledgment message. The same example can be easily replicated by considering the system outlined in Fig. 8 (DPU@INI). The only significant difference is that, being the lookup at the initiator NI, while the NI kernel is processing the OCP/IP control signals to create the packet header, the DPU checks in parallel these signals to verify the access rights, blocking (or not) the packet generation. Fig. 7. DPU architecture at the initiator Network Interface (DPU@INI). As mentioned for DPU@TNI, given the complexity of the protocol conversion to be done by the NI kernel, we can assume that the DPU critical path is shorter than the critical path of the NI kernel (as confirmed in the results reported in Section 6). Under this assumption, integrating the DPU at the initiator NI guarantees that no additional latency is associated with the access right check since, as shown in Fig. 8, the protocol conversion and the DPU access are done in parallel. With respect to DPU@TNI, the overhead associated with the dimension of the CAM is smaller because it is not necessary to include the identifier of the initiator node (NodeID) in the LUT. Checking the access rights at the initiator NI avoids the network transaction if the request were to be rejected. As a matter of fact, with respect to DPU@TNI, DPU@INI blocks bad memory requests before they enter the network; this results in no NoC traffic and less energy consumption. As a drawback of the DPU@INI solution, when a target would not require data protection, we pay for the DPU accesses whenever not necessary. In fact, since the protocol translation (and, thus, the target identification) and the DPU access are done in parallel to hide the latency overhead, it is not possible to avoid DPU accesses to those targets not requiring data protection. As will be shown in Section 6, the choice of the best DPU architecture to implement depends on the target system. 4.5 Example of Data Transfer in Systems Adopting the DPU This section outlines through an example the steps performed during a memory transfer, taking as reference Fig. 8. Overview of the whole NoC-based architecture including the DPU@INI. FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1223 Fig. 9. Example of usage of DPU@TNI for a store memory access. 5 RUNTIME CONFIGURATION OF THE DPUS In this section, we extend the solution presented in the previous section to program DPUs at runtime. This feature allows the system to optimize the use of the protection units and to modify them in case of changing application scenarios. To configure the DPUs distributed in the system, we adopt a centralized approach. An overview of the overall system proposed to program the DPUs at runtime is shown in Fig. 10, where the main elements are the NSM and DPU@TNI. The proposed runtime configuration can also be applied to DPU@INI. The NSM is in charge of accepting or refusing new restriction rules on the memory blocks and appropriately configuring the DPUs. In this section, first, we discuss the configuration of the system, focusing in particular on the activities involving the initiators of the transactions and the NSM. Second, we focus on the DPUs, in particular analyzing the architectural changes necessary to support runtime configuration and the interaction with the NSM. Third, some possible security faults of the system and countermeasures are presented, especially to counteract spoofing attacks. 5.1 Network Security Manager The NSM is a dedicated IP block that, together with the DPUs, dynamically associates access rights to selected memory spaces. The possibility of dynamically managing the memory protection is useful in architectures where the number, position, and/or size of the memory regions to be protected cannot be resolved at design time. Since we possibly do not want every processing element to be able to request the assignment of access rights to the NSM, these service request messages are filtered by the NSM considering only those arriving from particular processing elements in a particular state and role. In detail, only initiators in secure status and acting as supervisor are enabled to communicate with the NSM. According to OCP/IP specifications, this is translated into the possibility of the initiator setting to “1” the values of specific bits in MReqInfo. Obviously, the access to these bits must be restricted to initiators acting in the previously specified operating mode. When an application requires that a memory space needs to be protected, the right assignment operation is issued by the initiator to the NSM. If that space is not yet under right management, the request is accepted and a Fig. 10. System architecture including the Network Security Manager (NSM) to program the DPUs at runtime. message is sent to update the DPUs involved in the process. The NSM keeps track of all successful protection requests in a record for managing successive requests. Each entry of the record contains the information regarding the access rights and the DPUs involved in the request. If the memory space requested to be protected is already under right management and the requesting initiator is the owner of the block, the request is accepted and the corresponding record is updated. If the requesting initiator is not the memory block owner, the request is rejected by the NSM. The transaction related to the right assignment can be considered completed when all of the DPUs involved in the update acknowledge to the NSM. When a protected region needs to be released from the access restriction, the request is sent to the NSM. If the source of the request is the owner, an update message is sent to the DPUs and only when all responses are received by the NSM can the protected region be considered released. If the requesting initiator is not the memory block owner, the request is rejected by the NSM. Besides the dynamic configuration of the DPUs, the NSM could be used more in general to reprogram all the programmable parts of the NoC, such as the NI registers. 5.2 DPU to Support Runtime Configuration The modified architecture of the DPU to support dynamic reconfiguration is shown in Fig. 11. We consider, without loss of generality, only the architecture previously named as DPU@TNI. However, similar considerations apply to DPU@INI. Fig. 11. LUT modified to support runtime configuration. 1224 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 Fig. 12. Overview of (a) the authentication protocol between an initiator and the NSM and (b) the identification of a possible attack. As shown in Fig. 11, a Validity Bit (VB) must be added to each line of the DPU. Only the entries of the LUT with a VB equal to “1” are taken into consideration when checking the access rights, while the others are ignored. To configure at runtime the protection module by writing the necessary data into the LUT, a port has been added to the DPU. The NI hosting the DPU manages the updates for the DPU, processing the requests coming from the NSM. When the NSM requests the storage of a new access restriction to the DPU, it communicates to the hosting NI the address of the lookup and the information to be inserted in the DPU LUT. To avoid conflicts between the requests of the NSM and the packets being processed by the DPU, priority is given to the former (configuration requests). In case of access requests arriving during the configuration of the DPU, they will wait in the NI’s input buffers until the LUT has been updated. After the successful completion of the update of the DPU, the NI enables the processing of the requests coming from the initiators and sends back to the NSM a signal of acknowledgment. In case of deletion of one of the access restrictions, the NSM sends a request to release the corresponding line of the LUT. The NI processes the request and notifies the NSM of the completion of the transaction. The overhead required by the dynamic reconfiguration of the DPU occurs only when the memory protection must be updated. However, this situation usually happens only once per application run. The possibility of dynamically reconfiguring the DPUs increases the flexibility of the system, but its variable overhead, involving several network messages, affects the time determinism of an application/context switching. For hard real-time systems, the use of this feature should be avoided. 5.3 Possible Security Faults and Countermeasures In this section, we consider a possible security fault that may affect the type of dynamic data protection mechanism we described and we propose a countermeasure. In particular, we focus our attention on those parts of the system—such as registers—that can be programmed and whose unauthorized or careless accesses could compromise the effectiveness of the NSM and the DPUs. As described in Section 4, the identifier of a request (SourceID) is mainly based on the identifier of the NI (NodeID) and the identifier of the connection (MConnID) . The possibility of maliciously modifying the information stored in those registers could imply the hiding of the identifier of the processor requesting access to the NSM or to the protected memory blocks by substituting it with that of an authorized processor with higher privileges. This fact could cause a serious security problem since, as an example, it opens the possibility of accessing the NSM and of reprogramming all of the DPUs, enabling the access to protected locations. In the context of network security, these attacks are called spoofing attacks [49]. To carry out this kind of attack, an attacker successfully masquerades as another by falsifying data and thereby gaining illegitimate access. In NoC implementations where the mentioned registers are not hardwired or efficiently secured, in order to avoid unauthorized accesses to the NSM, we propose a possible countermeasure to spoofing attacks. In Fig. 12a, we show a simple double-acknowledgment authentication protocol to overcome spoofing attacks. The protocol tries to identify a malicious substitution of the processor identifier by sending an acknowledgment message to the source of the request and requiring a correct answer, as shown in Fig. 12a. In this way, if the real source of the request is not the one written in the original request, the malicious processor cannot end the authentication protocol since it does not receive the acknowledgment message ACK1 . To also avoid the possibility that the malicious processor could answer to the NSM without having received the ACK1 (as in Fig. 12b), the ACK1 message also contains a T AG field that should be elaborated on by the source (by using a simple translation function f ) and sent back to the NSM, which will check the correctness. In fact, the attacker, represented in Fig. 12b by P2 , tries a spoofing attack by masquerading its real identity with the one of P1 in the request ðSRC ¼ P1 Þ. The NSM sends the ACK1 response to P1 including the T AG value k (since it is the requester in the message), but P2 cannot know what the T AG value of the response k is. Despite the fact that P2 does not know the real T AG value (as shown in Fig. 12b), it tries to end the authentication process by sending a random tag m. This tag value has a probability equal to 1=2n (where n is the number of bits of the T AG field) of being equal to the correct value. During this failed authentication, two security warnings are reported: the first one given by P1 , which receives the ACK1 message without any previous request, and the second one given by the NSM due to the T AG value mismatch. The same problem (just shown for the access to the NSM) could happen for the access to memory locations FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1225 TABLE 1 Area and Energy Dissipation Due to the NoC Components Considering a 32-Bit Data Path Running at 500 MHz Fig. 13. Architecture overview of the two case studies. Targets and Initiators are in gray and white boxes, respectively. (a) Arch1. (b) Arch2. protected by using DPUs, for the reconfiguration of DPUs, or, more in general, for the reprogramming of all the programmable parts of the network. The following two are the proposals to avoid spoofing attacks also in these cases by using an authentication mechanism: . . The first solution takes into consideration the same protocol, based on a double acknowledgment, as for the NSM, for all the restricted accesses. In this case, the restricted request is issued to the target passing through the DPU that will perform the authentication protocol, sending the ACK1 message together with the T AG information, and will wait for the ACK2 message from the initiator to check its identity. The second solution uses the double-acknowledgment protocol only to exchange a key, while the other accesses will be authenticated by appending the key to the request. To increase the level of security, we can restrict the use of a key by using the concept of session. A session represents a time slice, defined in terms of a fixed number of operations or fixed time duration, during which we can use the same key. When the session ends, a new key needs to be exchanged for the management of the accesses in the next session. The best solution to be adopted strongly depends on several factors, such as the level of security that we want to enable, the frequency of the accesses to a protected location, the position of the DPUs in the network, and the available overhead to meet the performance constraints. 6 EXPERIMENTAL RESULTS In this section, we discuss the experimental results related to the proposed data protection mechanism for NoC-based architectures, evaluating the overhead introduced by DPU modules into the communication subsystem. In particular, Section 6.1 presents the experimental setup, while Sections 6.2 and 6.3, respectively, show the synthesis results for the two different implementations of the DPU and the overhead introduced by the data protection mechanism for two case studies. 6.1 Experimental Setup To evaluate the impact introduced by the proposed data protection mechanism into an SoC architecture based on NoCs, we considered two systems representing a typical embedded architecture and a shared-memory multiprocessor. In particular, the DPU overhead has been evaluated in the context of the NoC subsystem. The two case studies are shown in Fig. 13: . Arch1 represents a typical embedded architecture with two initiators and eight target memories/ peripherals. For our purposes, we consider each target of the memory space to be partitioned into four blocks. . Arch2 represents a shared-memory multiprocessor composed of eight initiators and one target memory partitioned into 16 blocks. Within the NoC clouds represented in Fig. 13, we consider routers in a mesh topology, each connected with an NI. The type of the NI (initiator or target) depends on the type of the connected IP module. Both case studies are used to show how varying the system characteristics will also vary the best DPU configuration and its energy/area overhead on the communication subsystem. Concerning the performance results for the two case studies, we will show in Section 6.2 how no performance overhead is introduced by the DPU because the DPU critical path is less than the NI kernel critical path. Given that, the system-level performance is not impacted by the DPU insertion. Regarding the evaluation of the a single DPU module, synthesis and energy estimation have been respectively performed by using the Synopsys Design Compiler and the Prime Power with 0.13m HCMOS9GPHS STMicroelectronics technology library. To compare the area and energy overhead introduced by the proposed data protection mechanism into the NoC subsystem, Table 1 shows area and energy values for each NoC component, obtained by using the PIRATE-NoC compiler [50]. All of the results presented in Table 1 are obtained by considering a frequency of 500 MHz imposed by the critical path of the NI kernel at both the initiator and the target. The NIs implement the OCP/IP interface. The router adopts a wormhole control flow strategy; it includes input and output buffers, a three-stage pipeline, and tablebased routing [50]. The results in Table 1 have been generated by considering a target network characterized by a 32-bit data path, the router input/output buffer depth is equal to 4, and the target and initiator NIs’ buffer sizes are equal to 16 and 8, respectively. Since we considered a mesh topology, Table 1 shows the area and energy values considering the three possible router configurations in terms of number of ports (3p, 4p, and 5p), including the NI port. Table 1 also shows the values for each NI (initiator and target) for the two architectures (Arch1 and Arch2). The area and energy values for the NI initiator depend on the target architecture because the logic for the generation of the DestID field depends linearly on the number of targets in the system. According to [50], [51], [52], the energy consumption of the different network units must consider two different costs for the header flit of the packet and for each flit of the payload. The energy associated with the 1226 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 TABLE 2 DPU Area Comparison with Respect to the ARM920T Processor and 16 Kbyte SRAM Fig. 14b shows that, for both architectures (DPU@TNI and DPU@INI), the DPU area increases almost linearly with the number of entries. This is due to the fact that the most significant area contribution is given by the CAM/TCAM included in the DPU. Although the two versions of the DPU behave similarly, the area value of DPU@INI is always smaller than that of DPU@TNI with the same number of entries. This gap is due to the different type of interfaces (OCP/IP or packet-based) and to the reduced number of CAM bits. As expected, since the main part of the DPU is composed of a CAM/TCAM, the energy trends shown in Fig. 14c by scaling the number of DPU entries are similar to those already described for the area values. To evaluate the complexity of DPU architectures in an SoC context, in Table 2, we compare the area values with two widely used IPs for SoC architectures : an ARM920T processor with 16 Kbytes of instruction and data cache running at 250 MHz and a 16 Kbyte SRAM with 16 bytes for each entry and one read and one write port. The comparison has been done by considering the same technology (0.13m) for all IPs. For both DPUs, we selected the LUT with 128 entries. With respect to the area of the ARM920T processor [53] and to the area of 16 Kbyte SRAM [54], the area of DPU@TNI/DPU@INI is, respectively, 12 percent/10 percent and 25 percent/20 percent. A further comparison with the components of the NoC subsystem will be shown in the next section for the two selected case studies. 6.3 Case Studies Given that no performance overhead has been introduced by the proposed DPU, in this section, we evaluate the area and energy overhead introduced by the proposed data protection mechanism into the communication subsystem for the two case studies shown in Fig. 13. Table 3 shows the area and energy overhead due to both DPUs , app lied to al l of the memory elements and peripherals of the system. The column DPU Area reports the area overhead of each DPU, while the column Total DPUs Area reports the sum of the area of all of the DPUs distributed on the different NIs. The column Energy for DPU Access represents the cost for access to the DPU for each memory request. Considering Arch1, the area of a single DPU@INI is larger than that of DPU@TNI, since the number of entries is 32 (4 memory blocks  8 targets) in the former and 8 (4 memory blocks  2 initiators) in the latter. Similarly, the energy for DPU access is larger for DPU@INI than for DPU@TNI. Globally, for Arch1, there are 64 DPU entries (4 memory blocks  8 targets  2 initiators) distributed on the system for both DPU solutions. Since the number of bits for each DPU@INI entry are smaller than those for the DPU@TNI and the DPU area is mainly due to the LUT, the Fig. 14. Synthesis results in terms of delay, area, and energy by varying the DPU entries for DPU@TNI and DPU@INI. (a) Delay. (b) Area. (c) Energy. header flit is higher than that of the payload since the header flit activates all of the control parts of the network (e.g., routing unit and protocol translation). 6.2 DPU Synthesis Results In this section, we present the synthesis results for the two p roposed imp lemen ta t ions o f the DPU arch i tec tu re (DPU@TNI and DPU@INI) presented in Section 4. Fig. 14 shows the synthesis results for a single DPU module in terms of delay ½ns, area ½mm2 , and energy ½nJ  by varying the number of entries for DPU@TNI and DPU@INI. All of the results have been obtained by targeting the synthesis to a clock frequency of 500 MHz imposed by the critical path of the NI kernel. As shown in Fig. 14a, the critical paths of all of the explored DPU configurations (up to 128 entries) are below 2ns, confirming that the DPU does not introduce any additional cycle to each memory request. FIORIN ET AL.: SECURE MEMORY ACCESSES ON NETWORKS-ON-CHIP 1227 TABLE 3 Area and Energy Overhead Due to DPUs for the Two Case Studies Total DPU Area for the DPU@INI solution is smaller than that for the DPU@TNI solution. Considering Arch2, the area of a single DPU@TNI is larger than that of DPU@INI since the number of entries is 128 (16 memory blocks  8 initiators) in the former and 16 (16 memory blocks  1 target) in the latter. Similarly, the energy for DPU access is larger for DPU@TNI than for DPU@INI. Globally, for Arch2, there are 128 DPU entries (16 memory blocks  1 targets  8 initiators) distributed on the system for both DPU solutions. As before, since the number of bits for each DPU@INI entry is smaller than those for the DPU@TNI and the DPU area is mainly due to the LUT, the Total DPU Area for the DPU@INI solution is smaller than that for the DPU@TNI solution. In the following analysis, we consider only one DPU solution for each case study. While, for Arch2, we selected the DPU@INI architecture due to their better results in terms of both cost functions (Total DPU Area and Energy for Access), for Arch1, we selected the DPU@TNI showing a limited area overhead but a reduced energy cost for access. For both cases, Fig. 15 shows the area breakdown of the NoC subsystem in terms of NoC routers, target and initiator NIs (see Table 1), and DPUs (see Table 3). The area overhead introduced by the DPUs is limited to 9 percent and 17 percent with respect to the NoC subsystem for Arch1 and Arch2, respectively. The difference in the number of network targets and initiators in the two architectures is reflected in the area breakdown: the target/initiator NI rate results are 45 percent/11 percent with respect to 6 percent/43 percent for Arch1 and Arch2, respectively. Concerning energy, Fig. 16 shows the DPU energy overhead with respect to the energy consumed by the NoC subsystem for a memory access. Because the energy consumed by the NoC for a memory access depends on the length of the packet and on the network distance (the number of hops) between the initiator and the memory, we Fig. 15. Area breakdown for the NoC subsystem including DPUs. (a) Arch1. (b) Arch2. Fig. 16. DPU energy overhead with respect to the energy consumed by the NoC subsystem for a memory access. (a) Arch1. (b) Arch2. plotted the DPU energy overhead as a surface dependent on these two parameters. The DPUs energy overhead for Arch1 and Arch2 is up to 4.5 percent and 7.5 percent, respectively. Increasing the packet length, the energy to transmit and translate the packet due to NoC routers and NIs increases proportionally. For the DPU components, energy does not increase because the lookup is done by the header independently of the payload length. As a result, the DPU energy overhead decreases with the increment of the packet length. The same behavior can be noted by varying the number of hops: The increment of the number of hops does not influence the DPU energy cost since the lookup is done on the NI. The increment of the network distance increases the energy due to the transmission of the packet (NoC router) but not the energy due to the data protection (DPU). 1228 IEEE TRANSACTIONS ON COMPUTERS, VOL. 57, NO. 9, SEPTEMBER 2008 7 CONCLUSIONS In this paper, we presented an innovative solution for data protection in MPSoC architectures based on NoCs. We proposed a hardware module integrated into the NI that guarantees secure accesses to memories and memorymapped peripherals. The proposed solution for networkbased architectures takes into consideration a distributed infrastructure. The study of different design alternatives associated with the target distributed shared-memory architecture and the design of a central unit that dynamically manages the data protection are proposed in the paper. The experimental results obtained by considering two different case studies have shown that the introduction of the DPU has only limited area and energy overhead (up to 17 percent and 7.5 percent, respectively) without impacting the system performance. The secure communication system we proposed in this work is conceived to deal with the weaknesses intrinsic in a multiprocessor system with shared memory and to exploit the characteristics of the NoC to detect and prevent them. ACKNOWLEDGMENTS The authors would like to thank the anonymous reviewers for their constructive and useful comments and suggestions. The authors would also like to thank Professor Mariagiovanna Sami of the Politecnico di Milano and Marcello Coppola and Riccardo Locatelli of STMicroelectronics for encouraging this research. This work has been carried out under the MEDEA+ LoMoSA+ Project and has been partially funded by KTI—the Swiss Innovation Promotion Agency—Project Nr. 7945.1 NMPP-NM. Part of this work is under patent pending, European Patent Application no. EP 07301411.0. "
2007,An Empirical Investigation of Mesh and Torus NoC Topologies Under Different Routing Algorithms and Traffic Models.,"NoC is an efficient on-chip communication architecture for SoC architectures. It enables integration of a large number of computational and storage blocks on a single chip. NoCs have tackled the SoCs disadvantages and are scalable. In this paper, we compare two popular NoC topologies, i.e., mesh and torus, in terms of different figures of merit e.g., latency, power consumption, and power/throughput ratio under different routing algorithms and two common traffic models, uniform and hotspot. To the best of our knowledge, this is the first effort in comparing mesh and torus topologies under different routing algorithms and traffic models with respect to their performance and power consumption.",
2007,On network-on-chip comparison.,"This paper presents the state-of-the-art in the field of network-on-chip (NoC) benchmarking and comparison. The study identifies the mainstream approaches, how NoCs are currently evaluated, and shows which aspects have been covered and those needing more research effort. No single article can cover all the aspects, and therefore, possibility to compare results from various sources must be ensured by proper scientific reporting. Basic guidelines for achieving that are given.",
2018,MAERI - Enabling Flexible Dataflow Mapping over DNN Accelerators via Reconfigurable Interconnects.,"Deep neural networks (DNN) have demonstrated highly promising results across computer vision and speech recognition, and are becoming foundational for ubiquitous AI. The computational complexity of these algorithms and a need for high energy-efficiency has led to a surge in research on hardware accelerators. % for this paradigm. To reduce the latency and energy costs of accessing DRAM, most DNN accelerators are spatial in nature, with hundreds of processing elements (PE) operating in parallel and communicating with each other directly. DNNs are evolving at a rapid rate, and it is common to have convolution, recurrent, pooling, and fully-connected layers with varying input and filter sizes in the most recent topologies.They may be dense or sparse. They can also be partitioned in myriad ways (within and across layers) to exploit data reuse (weights and intermediate outputs). All of the above can lead to different dataflow patterns within the accelerator substrate. Unfortunately, most DNN accelerators support only fixed dataflow patterns internally as they perform a careful co-design of the PEs and the network-on-chip (NoC). In fact, the majority of them are only optimized for traffic within a convolutional layer. This makes it challenging to map arbitrary dataflows on the fabric efficiently, and can lead to underutilization of the available compute resources. DNN accelerators need to be programmable to enable mass deployment. For them to be programmable, they need to be configurable internally to support the various dataflow patterns that could be mapped over them. To address this need, we present MAERI, which is a DNN accelerator built with a set of modular and configurable building blocks that can easily support myriad DNN partitions and mappings by appropriately configuring tiny switches. MAERI provides 8-459% better utilization across multiple dataflow mappings over baselines with rigid NoC fabrics.",
2014,Photonic Network-on-Chip Design.,,
2008,A Reconfigurable Baseband Platform Based on an Asynchronous Network-on-Chip.,"In order to face the inherent complexity of new radio access technologies and to address the development of multi-standard devices, an innovative reconfigurable baseband architecture based on a distributed control and communication framework is proposed. This architecture is tailored to the possibilities and limitations of next-generation CMOS nanotechnologies in terms of leakage and timing closure. A combination of technology features, message passing control model, network-on-chip, asynchronous implementation, clocking and power reduction policies is used. The 79.5 chip was manufactured in a 130 nm CMOS technology and is integrated in a prototyping platform to perform real-time experimentation of advanced MIMO OFDM based telecom techniques. It is composed of 23 functional units, such as computing intensive IPs, channel coding blocks, programmable DMA engines, an ARM946ES core, and an Ethernet interface. These elements are interconnected via an asynchronous layered network-on-chip using an interface that controls the communication and configuration parameters during application scheduling.",
2010,Enhancing performance of network-on-chip architectures with millimeter-wave wireless interconnects.,"In a traditional Network-on-Chip (NoC), latency and power dissipation increase with system size due to its inherent multi-hop communications. The performance of NoC communication fabrics can be significantly enhanced by introducing long-range, low power, high bandwidth direct links between far apart cores. In this paper a design methodology for a scalable hierarchical NoC with on-chip millimeter (mm)-wave wireless links is proposed. The proposed wireless NoC offers significantly higher throughput and lower energy dissipation compared to its conventional multi-hop wired counterpart. It is also demonstrated that the proposed hierarchical NoC with long range wireless links shows significant performance gains in presence of various application-specific traffic and multicast scenarios.",
2007,Characterizing the Cell EIB On-Chip Network.,"On-chip network design has become an increasingly important component of computer architecture. the cell broadband engine's element interconnect bus, with its four data rings and common command bus for end-to-end transaction control, interconnects more nodes than most commercial on- chip networks. to help understand on-chip network design and performance issues in the context of a commercial multicore chip, this article evaluates the ElB network using conventional latency and throughput characterization methods.",
2005,Network-on-chip-centric approach to interleaving in high throughput channel decoders.,"Reliable wireless communication needs efficient channel coding schemes like turbo and LDPC codes. During decoding, data is exchanged iteratively between component decoders. Between iterations, however, the data blocks are subjected to a permutation (or interleaving). As parallelization of the decoder architectures is mandatory for high throughput, access conflicts can occur. For standard compliant decoders it is impossible to design, or pre-process, the permutation patterns such that conflicts are avoided. Therefore, we employ networks-on-chip capable of resolving access conflicts at run-time to support arbitrary interleavers without any pre-processing.",
2006,On-line Fault Detection and Location for NoC Interconnects.,"A novel method for on-line fault detection and location in network-on-chip (NoC) communication fabrics is introduced. This approach is able to distinguish between faults in the communication links and faults in the NoC switches. The idea is based on the use of code-disjoint routing elements, combined with parity check encoding for the inter-switch links. We analyze the effect of our method on relevant performance parameters - power, latency, and throughput. Experiments show that our approach is effective and requires minimal modifications of the existing design methods for NoC interconnects",
2011,Design of Sequential Elements for Low Power Clocking System.,"Power consumption is a major bottleneck of system performance and is listed as one of the top three challenges in International Technology Roadmap for Semiconductor 2008. In practice, a large portion of the on chip power is consumed by the clock system which is made of the clock distribution network and flop-flops. In this paper, various design techniques for a low power clocking system are surveyed. Among them is an effective way to reduce capacity of the clock load by minimizing number of clocked transistors. To approach this, we propose a novel clocked pair shared flip-flop which reduces the number of local clocked transistors by approximately 40%. A 24% reduction of clock driving power is achieved. In addition, low swing and double edge clocking, can be easily incorporated into the new flip-flop to build clocking systems.",
2008,Concepts of Switching in the Time-Triggered Network-on-Chip.,"This paper presents the concepts of switching in the Time-Triggered Network-on-Chip (TTNoC), which is the communication subsystem of the Time-Triggered System on-Chip (TTSoC) architecture. This includes the design of the switching components that make up the network-on-chip (NoC), as well as the switching algorithm applied in those components. Furthermore, we focus on the implications for the operation of the TTNoC entailed by these design choices, and deal with frequently used scenarios in a NoC, particularly multi-casting. Finally, we present results of a prototype implementation based on FPGA technology.",
2004,NoCGEN - A Template Based Reuse Methodology for Networks on Chip Architecture.,"In this paper, we describe NoCGEN, a Network On Chip (NoC) generator, which is used to create a simulatable and synthesizable NoC description. NoCGEN uses a set of modularised router components that can be used to form different routers with a varying number of ports, routing algorithms, data widths and buffer depths. A graph description representing the interconnection between these routers is used to generate a top-level VHDL description. A wormhole output-queued 2-D mesh router was created to verify the capability of NoCGEN. Various parameterized designs were synthesized to provide estimated gate counts of 129 K to 695 K for a number of topologies varying from a 2/spl times/2 mesh to a 4/spl times/4 mesh, with constant data bus size width of 32. The NoC was simulated with random traffic using a mixed SystemC/VHDL environment to ensure correctness of operation and to obtain performance and average latency. The results show an accepted load of 53% to 55.6% with an increase in buffer depth from 8 to 32 flits for the 4/spl times/4 mesh router.",
2013,An Analytical Latency Model for Networks-on-Chip.,"We propose an analytical model based on queueing theory for delay analysis in a wormhole-switched network-on-chip (NoC). The proposed model takes as input an application communication graph, a topology graph, a mapping vector, and a routing matrix, and estimates average packet latency and router blocking time. It works for arbitrary network topology with deterministic routing under arbitrary traffic patterns. This model can estimate per-flow average latency accurately and quickly, thus enabling fast design space exploration of various design parameters in NoC designs. Experimental results show that the proposed analytical model can predict the average packet latency more than four orders of magnitude faster than an accurate simulation, while the computation error is less than 10% in non-saturated networks for different system-on-chip platforms.",
2008,Design Exploration of Optical Interconnection Networks for Chip Multiprocessors.,"The network-on-chip (NoC) paradigm has emerged as a promising solution for providing connectivity among the increasing number of cores that get integrated into both systems-on chip (SoC) and chip multiprocessors (CMP). In future high performance CMPs, however, the high bandwidth requirements will not be adequately provided by electronic NoCs without dissipating large amounts of power. Previously, we have made the case for the photonic NoC as a unique interconnect solution for delivering scalable bandwidth-per-watt performance that surpasses equivalent electronic NoCs. Building on this work, we study the adoption of photonic communication for CMPs and we present three main contributions: (1) we propose two nonblocking topologies for photonic NoC designs and we assess both qualitatively and quantitatively the pros and cons that they offer with respect to the original (blocking) topology, (2) we show how a photonic NoC is better suited for a CMP made of complex multi-threaded cores, and (3) we present the first simulation based assessment of the benefits of using a photonic NoC for a real application, i.e. computing a large FFT.",
2005,A robust self-calibrating transmission scheme for on-chip networks.,"Systems-on-Chip (SoC) design involves several challenges, stemming from the extreme miniaturization of the physical features and from the large number of devices and wires on a chip. Since most SoCs are used within embedded systems, specific concerns are increasingly related to correct, reliable, and robust operation. We believe that in the future most SoCs will be assembled by using large-scale macro-cells and interconnected by means of on-chip networks. We examine some physical properties of on-chip interconnect busses, with the goal of achieving fast, reliable, and low-energy communication. These objectives are reached by dynamically scaling down the voltage swing, while ensuring data integrity-in spite of the decreased signal to noise ratio-by means of encoding and retransmission schemes. In particular, we describe a closed-loop voltage swing controller that samples the error retransmission rate to determine the operational voltage swing. We present a control policy which achieves our goals with minimal complexity; such simplicity is demonstrated by implementing the policy in a synthesizable controller. Such a controller is an embodiment of a self-calibrating circuit that compensates for significant manufacturing parameter deviations and environmental variations. Experimental results show that energy savings amount up to 42%, while at the same time meeting performance requirements.",
2004,Power analysis of system-level on-chip communication architectures.,"For complex system-on-chips (SoCs) fabricated in nanometer technologies, the system-level on-chip communication architecture is emerging as a significant source of power consumption. Managing and optimizing this important component of SoC power requires a detailed understanding of the characteristics of its power consumption. Various power estimation and low-power design techniques have been proposed for the global interconnects that form part of SoC communication architectures (e.g., low-swing buses, bus encoding, etc). While effective, they only address a limited part of communication architecture power consumption. A state-of-the-art communication architecture, viewed in its entirety, is quite complex, comprising several components, such as bus interfaces, arbiters, bridges, decoders, and multiplexers, in addition to the global bus lines. Relatively little research has focused on analyzing and comparing the power consumed by different components of the communication architecture. In this work, we present a systematic evaluation and analysis of the power consumed by a state-of-the-art communication architecture (the AMBA on-chip bus), using a commercial design flow. We focus on developing a quantitative understanding of the relative contributions of different communication architecture components to its power consumption, and the factors on which they depend. We decompose the communication architecture power into power consumed by logic components (such as arbiters, decoders, bus bridges), global bus lines (that carry address, data, and control information), and bus interfaces. We also perform studies that analyze the impact of varying application traffic characteristics, and varying SoC complexity, on communication architecture power. Based on our analyses, we evaluate different techniques for reducing the power consumed by the on-chip communication architecture, and compare their effectiveness in achieving power savings at the system level. In addition to quantitatively reinforcing the view that on-chip communication is an important target for system-level power optimization, our work demonstrates (i) the importance of considering the communication architecture in its entirety, and (ii) the opportunities that exist for power reduction through careful communication architecture design.","Power Analysis of System-Level On-Chip Communication Architectures Kanishka Lahiri and Anand Raghunathan fklahiri,anandg@nec-labs.com NEC Laboratories America, Princeton, NJ ABSTRACT For complex System-on-chips (SoCs) fabricated in nanometer technologies, the system-level on-chip communication architecture is emerging as a significant source of power consumption. Managing and optimizing this important component of SoC power requires a detailed understanding of the characteristics of its power consumption. Various power estimation and low-power design techniques have been proposed for the global interconnects that form part of SoC communication architectures (e.g., low-swing buses, bus encoding, etc). While effective, they only address a limited part of communication architecture power consumption. A state-of-the-art communication architecture, viewed in its entirety, is quite complex, comprising several components, such as bus interfaces, arbiters, bridges, decoders, and multiplexers, in addition to the global bus lines. Relatively little research has focused on analyzing and comparing the power consumed by different components of the communication architecture. In this work, we present a systematic evaluation and analysis of the power consumed by a state-of-the-art communication architecture (the AMBA onchip bus), using a commercial design ﬂow. We focus on developing a quantitative understanding of the relative contributions of different communication architecture components to its power consumption, and the factors on which they depend. We decompose the communication architecture power into power consumed by logic components (such as arbiters, decoders, bus bridges), global bus lines (that carry address, data, and control information), and bus interfaces. We also perform studies that analyze the impact of varying application trafﬁc characteristics, and varying SoC complexity, on communication architecture power. Based on our analyses, we evaluate different techniques for reducing the power consumed by the on-chip communication architecture, and compare their effectiveness in achieving power savings at the system level. In addition to quantitatively reinforcing the view that on-chip communication is an important target for system-level power optimization, our work demonstrates (i) the importance of considering the communication architecture in its entirety, and (ii) the opportunities that exist for power reduction through careful communication architecture design. Category and Subject Descriptors: C.5.4 [VLSI Systems] General Terms: Design, Experimentation Keywords: Communication Architectures, System-on-Chip, LowPower Design, Power Analysis, Network-on-Chip 1. INTRODUCTION Increasing System-on-Chip (SoC) complexity, coupled with poor scaling trends of global interconnect, are together making on-chip communication a bottleneck to improving overall system performance and power consumption [1, 2]. As a result of this trend, recent research has focused on analyzing and optimizing the power consumed by global interconnect wires, which represent one part of the on-chip communication architecture. However, a state-of-the-art communication architecture, viewed in its entirety, is signiﬁcantly Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’04, September 8–10, 2004, Stockholm, Sweden. Copyright 2004 ACM 1-58113-937-3/04/0009 ...$5.00. Table 1: Power consumption of SoC components @ 200 Mhz System Component System Component Part Name Part Name Power (mW) Power (mW) Embedded Processor Embedded Processor Memory Controller Memory Controller On-Chip Bus On-Chip Bus Cache Cache Interrupt Controller Interrupt Controller UART UART ARM946E-S1 ARM946E-S1 DW_ahb_memctl2 DW_ahb_memctl2 DW_amba2 DW_amba2 ARM946E-S1 ARM946E-S1 DW_ahb_ictl2 DW_ahb_ictl2 DW_apb_uart2 DW_apb_uart2 60 60 29.1 29.1 22.6 22.6 36 36 2.6 2.6 4.1 4.1 1 http://www.arm.com/products/CPUs/ARM946ES.html 2 Gate-level measurements of Synopsys Designware Library Cores more complex, comprising numerous components, such as arbiters, bridges, decoders, data/address multiplexers, control logic, and bus interfaces, in addition to the interconnect wires. The amount of logic in a complex communication architecture can easily rival an embedded processor of moderate complexity. Very little work has addressed analyzing the nature of power consumption in the communication architecture as a whole. To highlight the need for studying communication architectures and their power requirements, we compare the power consumed by a typical communication architecture to the power consumed by other system components in Table 1. The table presents data obtained from gate-level power measurements, and manufacturer data sheets, of several commercial SoC components, including a complete communication architecture (the AMBA on-chip bus [3]). The table indicates that the communication architecture can consume signiﬁcantly more power than many system components, and in fact, its power is comparable in magnitude to well-known primary sources of power consumption (e.g., processors, caches). With increasing system complexity, and shrinking feature size, the relative contribution of the communication architecture can only be expected to increase, motivating the need to better understand and optimize communication architecture power consumption. 1.1 Paper Overview and Contributions In this paper, we present a systematic evaluation and analysis of the power consumption of a commercial, state-of-the-art, on-chip communication architecture (the AMBA on-chip bus [3]), using a commercial design ﬂow. We focus on developing a quantitative understanding of the relative contributions of different parts of the communication architecture to its overall power consumption, and the factors on which they depend. We decompose the communication architecture power into power consumed by logic components (such as arbiters, decoders, bus bridges), global bus lines (that carry address, data, and control information), and bus interfaces. We also analyze the impact of varying application trafﬁc characteristics, as well as the impact of varying SoC complexity, on the power consumed by the communication architecture. In addition to quantitatively reinforcing the view that on-chip communication is an important target for system-level power optimization, our studies demonstrate the importance of considering the communication architecture in its entirety (and not just individual components, such as interconnect wires) for power optimization. To support this viewpoint, we consider various alternatives for communication architecture power reduction, and based on the insights gained from our studies, compare their ability to achieve power savings at the system level. The rest of this paper is organized as follows. In Section 2, we provide background on the AMBA on-chip bus, and the experimental methodology used. In Section 3, we present a structural breakdown of the power consumed by the AMBA architecture. In Section 4, we analyze the impact of application trafﬁc characteristics, and in Section 5, we analyze the impact of varying system complexity, on AMBA power consumption. In Section 6, we evaluate different techniques for communication architecture power optimization, and conclude in Section 7. 1.2 Related Work There is a large body of work that addresses power consumption of global bus lines [4, 5, 6, 7, 8, 9, 10], or the interaction of global bus lines with other components, such as processor caches [11, 12]. As mentioned earlier, these techniques do not consider the power consumption of the communication architecture in its entirety. Recognizing this, recent work has addressed communication architecture components other than global wires. Such work includes techniques for analyzing and optimizing the power consumed in on-chip routers [13, 14], and enabling power-conscious routing in complex communication architectures [15]. Many of these techniques are targeted towards on-chip networks, and do not directly apply to busbased architectures, which are the focus of our work. Integration of power models of certain AMBA components into a transaction-level modeling framework was explored in [16]. In contrast, our work aims at understanding the different sources of power consumption in the AMBA architecture, through detailed (gate-level) power analysis. To the knowledge of the authors, this paper is the ﬁrst attempt to experimentally quantify the different factors that contribute to the power consumption of a commercial, bus-based, SoC communication architecture. We chose the AMBA architecture since it is one of the most popular commercial on-chip communication architectures in use today. 2. BACKGROUND In this section, we ﬁrst present an overview of the AMBA onchip bus architecture, highlighting its different components, and their functions. We next describe the methodology used for the experimental studies described later in this paper. 2.1 AMBA On-Chip Bus: Overview For our studies, we used an implementation of the AMBA onchip bus that is available in the Synopsys Designware library [17]. Complete details of AMBA functionality may be obtained from [3, 17]. Figure 1 depicts the class of AMBA architectures that we consider. The AMBA architecture is based on a hierarchy of buses. The AHB (Advanced High Performance Bus) integrates high performance components (e.g., processors, DMA controllers). It is a pipelined bus, implying that address and data belonging to different transactions may overlap in time. The bus can support upto 16 masters (components that can initiate bus transactions) and upto 16 slaves (components that only respond to transactions initiated by a master). All the slaves are memory mapped. For each transfer, the decoder generates slave select signals to notify the correct slave. Multiplexers properly route address, write data, and control parameters from the masters to the slaves, as well as slave responses and read data, from the slaves back to the masters. The arbiter regulates access to the shared bus using a conﬁgurable arbitration scheme. Burst transactions enable a master to perform a sequence of transfers without requiring arbitration for each transfer. The AHB is connected to the APB (Advanced Peripheral Bus) via the AHB-APB bridge. The bridge behaves as a slave to the AHB, and as a master to the APB. The APB supports only one master, is not pipelined, and AHB_Master_1 AHB Master IF AHB  Logic Addr, Control,  Write Data,  Request G r n a t G r n a t G r n a t Arbiter Write Muxes Address Decoder AHB_Master_16 AHB Master IF AHB Master IF AHB Slave IF Memory Cntl. AHB Slave IF AHB Slave IF Interrupt Cntl. Read Data,  Slave Resp. S c e e l t S c e e l t S c e e l t S l e v a R e s n o p s e , R d a e D a t a Addr, Control,  Write Data,  Request AHB Slave IF AHB_SLV_16 S c e e l t Read  Muxes A d d r s s e , C n o r t o , l W r t i e D a t a Addr, Control,  Write Data,  Request Select APB Slave IF GPIO GPIO Select APB Slave IF UART UART Select APB Slave IF APB Slave IF Interrupt Ctrl. Interrupt Ctrl. Select Select APB Slave IF APB_SLV_16 APB_SLV_16 Address,  R/W Data, Control APB Master IF Bridge AHB APB Read Data,  Slave Resp. Read Data,  Slave Resp. Read Data,  Slave Resp. Figure 1: Overview of the AMBA on-chip bus can integrate upto 16 peripherals (e.g., GPIO interface, UART). Any master/slave that communicates over the AMBA architecture is enhanced with AHB and/or APB interfaces. Finally, the physical connectivity between components is achieved using global interconnect wires, that carry address, data and control values between masters and slaves. 2.2 Power Estimation Methodology The power estimation methodology used in this work is illustrated in Figure 2. Architectural conﬁguration parameters of the AMBA bus (e.g., address width, data width, number of masters, number of slaves) are speci ﬁed to Synopsys CoreTools [18], which generates synthesizable RT-level descriptions of the bus hardware. In our experiments, while the number of masters and slaves vary, the address and data widths are held constant at typical values (32-bit addresses, 32-bit AHB data width, and 16-bit APB data width). The arbiter is conﬁgured to use static priorities, a scheme wherein access rights are determined by examining the set of pending requests from masters, and selecting the one with the highest ( ﬁxed) priority. Synopsys Design Compiler [19] is used to synthesize the bus hardware to the gate level, using CB-12L, NEC’s low-power 0.15 m standard cell library [20]. Vectors to drive power estimation are obtained via RT/gate level simulations using the Modelsim simulator [21]. The systems into which the AMBA bus is integrated consist of a variable number of master and slave components, and numerous peripherals, such as a memory controller, interrupt controllers, etc. Transaction-level testbenches are constructed using programmable Gate-Level  Power  Estimation (NEC POWERD) Synthesis (Synopsys DC) AMBA RTL Configure &  Generate  AMBA bus  (Synopsys  CoreTools) AMBA netlist T r c a s n a i t n o l e v e l t h c n e b s e t ( S s y s p o n y V e I tio rific a n P ) Bus logic and interface  power estimates AMBA parameters Vectors RTL  descriptions of  system  modules Global Wire  Length  Estimation Bus line power  estimates W i r e l s h g n e t S s y t ( e m M e S d o l i m m ) a u s l i t n o i Vectors Repeater  Insertion Module gate counts Capacitance  Estimation Power  Estimation  of Global  Wires NEC CB12L 0.15 um Lib Figure 2: Methodology for communication architecture power estimation …             … …             functional models of masters for bus trafﬁc generation. Power simulation vectors are provided to POWERD, NEC’s gate-level power estimator [22] to obtain power measurements for different components. Pre-layout wire length estimation techniques are used to compute global wire lengths [23, 24], which take into account area estimates and pin counts for each system component. Wire capacitances are extracted from the technology library, and the number of repeaters and their sizes are calculated using a delay-optimal algorithm described in [25]. The capacitances are used to calibrate a transitioncount based power model for estimating the power consumed by bus lines [11]. 3. STRUCTURAL BREAKDOWN OF AMBA POWER In this section, we present a relative comparison of the power consumed by different parts of the AMBA on-chip bus. For this study, we used a conﬁguration of the AMBA bus that integrates 2 AHB masters, 2 AHB slaves (a memory controller and an interrupt controller), an AHB-APB bridge, and three APB peripherals, including a General Purpose Input/Output (GPIO) device, an interrupt controller, and an I2C (external bus) interface. The testbench consists of an even mix of different types of transactions, including burst transactions on the AHB, and regular transactions between AHB masters and APB slaves. Reads and writes are equally distributed, and addresses are generated uniformly at random, while staying within valid regions of the memory address map. The computed global wirelengths lie between 1.5 and 3 mm. The total power consumed by the communication architecture for this study was 12 mW, and the breakdown of the power among the various components of the AMBA bus is presented in Figure 3. The components whose power is shown in the ﬁgure include the AHB arbiter, multiplexers, and address decoder, the AHB-APB bridge (which also implements the APB bus logic), the AHB and APB address, data, and control bus lines, two AHB master interfaces, two AHB slave interfaces (corresponding to the memory controller and the interrupt controller), and three APB slave interfaces (corresponding to the GPIO, interrupt controller, and I2C peripherals). APB Bus Lines APB Bus Lines 2% 2% AHB Arbiter AHB Arbiter 18% 18% AHB Multiplexers AHB Multiplexers 6% 6% AHB Bus Lines AHB Bus Lines 12% 12% APB Intr. Ctrl IF APB Intr. Ctrl IF 1% 1% APB I2C1 IF APB I2C1 IF 1% 1% APB GPIO IF APB GPIO IF 6% 6% AHB Mem Ctrl IF AHB Mem Ctrl IF 9% 9% AHB Int. Ctrl IF AHB Int. Ctrl IF 8% 8%   In contrast, the total power consumed by the logic components (arbiter, multiplexers, decoder, and bridge) constitutes about 51% of the total communication architecture power.   The power consumed by bus interfaces (master and slave) constitutes the remaining 35%. In summary, our analysis demonstrates that while a large portion of the power consumed by the communication architecture is dominated by logic (86%), it is spread across numerous components. Hence, in order to address communication architecture power consumption, the contributions of several different components needs to be addressed. As discussed in detail later in this paper, approaches that focus on speci ﬁc components in isolation ( e.g., global wires) may have limited impact at the system level. In the next two sections, we consider different factors on which the communication architecture power depends. We examine the impact of variable trafﬁc characteristics, and variable system complexity, on the power consumed by the AMBA on-chip bus. 4. IMPACT OF ON-CHIP COMMUNICATION TRAFFIC CHARACTERISTICS In this section, we analyze how application trafﬁc characteristics inﬂuence communication architecture power consumption. In the following subsections, we consider the quantitative impact of variations in (i) spatial distribution of communication transactions, (ii) transaction pipelining, and (iii) different transaction types, on communication architecture power. 4.1 Spatial Distribution of Transactions Since all the devices attached to the AMBA bus are memory mapped, the spatial distribution of communication transactions is determined by the address values generated by each master. For this study, a set of test programs were written for an AHB master to generate single (non-burst) write transfers (NONSEQ transfers, in AMBA terminology) to each of a set of AHB/APB slaves, choosing addresses at random from within the address space of each slave. In each case, the power consumed by the entire communication architecture was measured. Figure 4 presents a few illustrative cases. Bars 1 and 2 correspond to trafﬁc directed towards APB slaves (the GPIO Interface and the APB Interrupt Controller, respectively), while bars 3 and 4 correspond to trafﬁc directed towards AHB slaves (the AHB Interrupt Controller and Memory Controller, respectively). AHB APB 12 10 8 6 4 2 0 test_gpio.v test_intr_apb.v test_intr_ahb.v test_memctl.v Address Map Tests APB buslines AHB bus lines Int. Ctrl APB IF I2C1 APB IF GPIO APB IF Mem Ctrl AHB IF Int. Ctrl AHB IF AHB-APB bridge AHB Logic r e w o P AHB Decoder AHB Decoder 1% 1% AHB-APB bridge AHB-APB bridge 26% 26% ) W m ( AHB Master IF AHB Master IF 10% 10% Figure 3: Breakdown of power in the AMBA on-chip bus From Figure 3, we observe that the total power consumed by the communication architecture is not dominated by any single component, but has several important contributors. We next group together some of the components in order to gain a better understanding of the relative contributions to the overall power consumption.   The power consumed by the bus lines (considering both the AHB and APB together) represents 14% of the total power consumed by the communication architecture. The power consumed on the APB bus lines is relatively small since (a) it operates at half the clock frequency, (b) it is not pipelined, and (c) it has a narrow data width (16-bit). Also, all APB transfers are associated with AHB transfers, but not vice versa. Figure 4: Comparison of communication architecture power consumption for different target slaves From the ﬁgure, we observe that with variation in the address values (or target slaves), the total power consumed by the communication architecture varies appreciably (upto 19%), but more importantly, the relative contributions of each component varies even more       signiﬁcantly. We next discuss the power consumed by each component in further detail. Bus Lines: The power consumed by the AHB bus lines varies signi ﬁcantly (3.8X) across the 4 tests. In bar 4, its contribution is the largest, owing to the larger size of the address map of the memory controller (which results in higher switching activity on the address bus). The power consumed by the AHB bus lines during APB transfers (bars 1 and 2) is, on average, 2.3X less than during pure AHB transfers (bars 3 and 4). This may seem counter-intuitive, since all APB trafﬁc also goes through the AHB bus. The reason behind this is that APB slaves are only 16 bits wide, causing the more signi ﬁcant AHB data bus lines to remain idle during APB transfers. The power consumed by the APB lines, while only 4% in the ﬁrst two cases, is zero in the latter two cases, due to the absence of APB trafﬁc. Bus Bridge: The contribution of the AHB-APB bridge varies significantly across the different cases, from 22% (2.2 mW in bar 3), upto 40% (3.85 mW in bar 1). In bars 3 and 4, the bridge behaves as an AHB slave that merely observes AHB trafﬁc, but does not respond to it. Hence, the APB related logic (decoding, multiplexing, mastering) remains idle. In the ﬁrst two cases, however, the bridge’s AHB slave interface is always selected, which results in activation of the bridging and APB mastering logic, causing higher power consumption. Slave Interfaces: The contribution of the slave interfaces varies, depending on whether or not the corresponding device is selected. For example, the power consumed in the memory controller’s AHB interface varies from 18% (2.02 mW in bar 4) to 9% (0.87 mW in bar 1). It should be noted that even when a slave device is not selected, the power contribution of its bus interface is appreciable. For example, when all the trafﬁc is directed towards APB slaves, the power consumed by AHB slave interfaces (excluding the bridge) is as high as 18%. In addition, the power consumed by a slave interface can vary signi ﬁcantly, even when the slave is not selected. For example, in bars 1 and 4, the AHB Interrupt Controller interface is never selected, but a variation of as much as 1.8X is observed. In fact, its power consumption in bar 4 is 22% higher than in bar 3 (where the AHB Interrupt Controller is selected). This apparent anomaly is attributed to the dependence of the slave interface power on the switching activity of the address and data values observed at its inputs, even when it is not selected. The high switching activity is also borne out by the signi ﬁcantly higher power consumption on the AHB bus lines in bar 4 as compared to bar 3. AHB Bus Logic: In these experiments, the variation in the power consumed by the AHB logic is less signiﬁcant. This is because the AHB logic power is in large part dominated by the arbiter, which is not affected by variations in slave access proﬁles. 4.2 Pipelined Transactions AHB transfers are split into an address phase, in which address and control signals are asserted by the master, and a data phase, in which data is written to (or read from) a slave device. The AHB supports pipelined transfers by allowing the address phase of one transfer to overlap with the data phase of the previous transfer. This enables the initiation and completion of one transfer per clock cycle. In this study, we compare the power consumed by transactions that exploit the AMBA architecture’s pipelining capability, versus transactions that execute sequentially (without pipelining). Intuitively, we expect the pipelined case to consume more power (owing to the processing of multiple transactions simultaneously). We study the power consumed when transferring a 2 KB block of data from a master to a slave under two scenarios. In the ﬁrst case, single word transfers are initiated every clock cycle, in a pipelined fashion. In this case, each transaction takes two cycles to complete. In the second case, each transaction is allowed to complete before initiating a new transaction. In this case, each transaction takes four cycles to complete (request, grant, address, and data phases each consume one cycle). For this discussion, we focus on the AHB subsystem, since the APB does not support pipelined transactions. The results of this experiment are depicted in bars 1 and 2 of Figure 5. We observe that the power consumed by the non-pipelined trafﬁc is 1.5X higher than the power consumed by pipelined trafﬁc. The higher power dissipation is reﬂected in almost all the components: the bus lines (2X), multiplexers (4X), and arbiter (1.5X). Upon further analysis, we found three reasons that explain this result. In the non-pipelined case, there are many unutilized bus cycles, during which the bus logic drives the address and data buses to zero, resulting in relatively high switching activity. In the pipelined case however, every cycle is utilized and hence, successive values on the bus are correlated, resulting in lower switching activity. In addition, in the non-pipelined case, global control lines between the master and the bus logic undergo frequent switching activity, owing to assertion/de-assertion of requests, grants, and transaction parameter values. In the pipelined case, these lines hold their values, since on every clock cycle, a new transaction starts with identical parameters. While the above arguments explain the disparity in the power consumption of the bus lines and multiplexers, the difference in the power consumed by the arbiter requires further explanation. In the non-pipelined case, upon successful transaction initiation, the request lines are de-asserted and are then re-asserted for the next transaction. This causes the inputs to the arbiter to change frequently, resulting in higher power consumed by the arbiter, as it computes which master should be granted next. In the pipelined case, the inputs to the arbiter rarely change, leading to lower power consumption. ) W m ( r e w o P 6 5 4 3 2 1 0 AHB Bus lines AHB Decoder AHB Muxes AHB Arbiter NONPIPELINED, SINGLE PIPELINED, SINGLE PIPELINED, BURST (INCR16) AHB Traffic Type Figure 5: Comparison of power consumption of different types of communication traf ﬁc 4.3 Burst Transactions The AHB supports the use of different transaction types. These include single transactions (denoted by NONSEQ), wherein the master requests access for the bus to carry out a single transfer (8, 16 or 32-bit), and a variety of burst transactions, wherein the master is granted the bus for a sequence of transfers. For each transaction, the type is controlled by the HBURST parameter, whose value determines the burst length (4, 8, 16 or undeﬁned), and whether or not the burst wraps at certain address boundaries. In this study, we repeat the experiment described in the previous subsection, but use nonwrapping, 16-word bursts (denoted by INCR16) to transfer the 2 KB block of data. We compare the power consumed during this transfer with pipelined, single transactions. Note that, within a burst, the transactions are always pipelined. Figure 5 presents the results for the burst case in bar 3, alongside the results described in the previous subsection. From the ﬁgure, we observe that the power consumed during the burst transfer is 34% higher than the power consumed during pipelined, single transfers. This is due to a 29% increase in arbiter power, a 68% increase in multiplexer power, and a 34% increase in bus line power. There are two factors that inﬂuence the difference in power consumption between these cases. The ﬁrst factor is related to the additional functionality executed by the arbiter during a burst transaction, which keeps track of information regarding the progress of the burst,   such as a count of the number of words transfered. This state is maintained by the arbiter to ensure that the burst can be restarted in case it has to be terminated by some external event. The second factor (which inﬂuences both arbiter and bus line power) is the manner in which bus control signals are asserted in the two cases. In the ﬁrst case (pipelined, single transfers), control lines and request/grant values remain unchanged throughout the experiment. In the burst transfer case, there is activity on the control lines within bursts (to indicate start, progress, and end of a burst), and between bursts (assertion/deassertion of control signals at the start/end of each burst). This causes higher power consumption in the control lines and arbiter. 5. IMPACT OF SYSTEM COMPLEXITY We next analyze how the power consumption of the communication architecture varies with system complexity. For this study, we scale system complexity along two natural dimensions from the communication architecture standpoint, namely, the number of masters and the number of slaves that are connected to it. For each system , we apply the methodology of Figure 2 to generate the communication architecture hardware and analyze its power consumption. For fair comparison, all the testbenches in this study generate trafﬁc consisting of pipelined, single, write transactions, with contiguous addresses, uniformly distributed data values, and no wasted bus cycles. For systems with multiple masters, testbenches were designed to create maximum contention for access to the bus. 25 ) W m ( r e w o P 20 15 10 5 0 AHB Interfaces AHB Bus Lines AHB Logic 1 2 4 8 16 No. of AHB Masters Figure 6: Communication architecture power consumption versus increasing system complexity The results of these studies for increasing number of masters are presented in Figure 6. For brevity, we omit the results for varying number of slaves, which demonstrate similar trends. From the ﬁgure, we observe that the power consumed by the interface logic exhibits the most signi ﬁcant variation with system complexity, scaling proportionally to the number of components. The relative contribution of the interfaces increases from 29% of the total for the 1 master system, to 67% for the 16 master system. While the power consumed by the bus lines also increases with increasing system complexity (by 57%), owing to longer wire lengths and larger number of repeaters, their relative contribution to the total decreases from 49% (in the 1 master system), to 19% (in the 16 master system). The impact on bus logic was observed to differ, depending on whether system complexity is scaled in terms of the number of masters or slaves. While increasing the number of slaves has little impact on the bus logic power, increasing the number of masters results in a 59% increase (from 1.7 mW to 2.71 mW), owing to increased arbitration and multiplexer complexity. 6. COMMUNICATION ARCHITECTURE POWER REDUCTION TECHNIQUES Having presented studies that analyze the sources of power consumption in a communication architecture, we next discuss opportunities for power reduction. We consider a suite of techniques for optimizing communication architecture power: bus encoding, segmented bus design, interface power management, and trafﬁc sequencing. The purpose of this discussion is to obtain an understanding of which portions of the communication architecture are addressed by each technique, and to quanitfy the impact of these techniques on communication architecture power. We consider an example in which two masters communicate with the AHB memory controller in an interleaved manner. In addition, one of them executes a sequence of transactions with the APB GPIO peripheral. The power breakdown corresponding to this case is shown in bar 1 of Figure 7. In the following subsections, we use this as a base case for comparison, and analyze each of the above techniques in terms of the power reductions they achieve. 6.1 Bus Encoding Numerous encoding schemes have been proposed to reduce switching activity on global buses (e.g., [5, 6, 9, 26]). While the impact of bus encoding on the power consumed by bus lines has been well documented, here we are interested in its impact on the power consumption of the communication architecture as a whole. In order to evaluate the savings via bus encoding on the AMBA on-chip bus, we consider an scheme that reduces address bus transitions by 60%, and data bus transitions by 20%. Note that, a simple scheme, in which the encoder/decoder circuitry resides between the bus interfaces and the bus lines affects only the bus line power. In a more sophisticated scheme, the codecs are implemented within each bus interface. In such a scheme, since the signals received/transmitted by the bus interface are encoded, there is reduced activity within each bus interface, leading to additional power savings. We analyzed the data collected for the example AMBA-based system, and estimated the potential power savings achievable by the latter scheme. From bar 2 of Figure 7, we observe that while the technique achieves a 30% reduction in the power consumed by bus lines, the overall communication architecture power reduction is only 14%. The impact is relatively small, owing to communication architecture components whose power is unaffected by bus encoding, such as the control lines, bus arbiter, bus bridge, and idle bus interfaces. ) W m ( r e w o P 12 10 8 6 4 2 0 APB Bus Lines AHB Bus Lines APB Slave I/Fs AHB Slave I/Fs AHB Mast. I/Fs AHB-APB Bridge AHB Logic Base Case Bus Encoding Segmented Buses Power Mgm Traffic Sequencing Traffic Seq. + Power Mgm Figure 7: Comparison of different approaches for communication architecture power reduction 6.2 Segmented Buses One of the causes of power dissipation in the communication architecture is the broadcast nature of address and data values to all the slaves attached to the bus, which results in unnecessary switching in long capacitive bus lines and slave interfaces. A solution to this problem is to use a segmented bus architecture [7, 8]. In this architecture, long nets (such as the address bus) that fan out to multiple components, are split into segments, with neighboring segments connected by control logic (e.g., pass transistors). The slave select logic (implemented in the bus address decoder) can be enhanced to activate only those segments that are required for each transaction, thereby propa    gating the address/data values to only the relevant slave. While this approach can achieve power savings, it may result in increased delay on the bus lines, due to the additional control logic. The approach could also be applied to regulate activation of bus segments when slave responses and read data are propagated back to the masters. We evaluated the potential impact of applying such a strategy on the slave side, by analyzing the data collected from the example AMBA-based system. Bar 3 of Figure 7 indicates that using a segmented bus, an overall savings of 16% are achieved. This is due to 70% savings in bus line power, and 11% savings in interface power. The impact on interface power (and hence on the overall power) is less signiﬁcant, due to the relatively high power consumed by the interfaces even when there is no activity on their inputs. 6.3 Power Management Several power management techniques lend themselves naturally to reducing communication architecture power. For example, idle slave interfaces could be shut down, to be woken up on-demand, by the bus logic (arbiter). However, slave wake-up latencies may subject masters to additional delay before receiving grants. While time-out based techniques may be effective, we observe that the communication architecture could make better informed power management decisions (when to shut down/wake up components), based on systemlevel information. For example, the bus arbiter may be capable of predicting idle times for slaves, based on information that it possesses about the set of current and pending transactions. During the progress of a ﬁxed length, locked burst, it might conclude that all the slaves, except the one participating in the burst, are likely to remain idle for a certain number of cycles; hence it can save power by shutting them down. The notion of shutting down interfaces can be applied to entire levels of the bus hierarchy. For example, if the AHB slave interface of the AHB-APB bridge is inactive for prolonged periods, the APB subsystem may be shutdown. An analysis of the potential savings of interface and hierarchy shutdown for the example AMBA-based system reveals a power reduction of 26% (bar 4 of Figure 7), due to savings in slave interfaces and the bridge. Signi ﬁcantly larger savings may be achievable for systems comprising many more slaves and/or hierarchy levels. 6.4 Trafﬁc Sequencing In our experiments, we observed that the interleaving of transactions from different masters leads to increased power consumption due to more frequent arbitration, and increased switching activity on the bus lines. Trafﬁc sequencing is a proposed approach that aims to reduce the extent to which multiple masters obtain interleaved access to the bus. This could be achieved either by modifying the application itself, or by employing a more sophisticated bus protocol in which masters are provided with feedback regarding the current state of the bus. For example, if the bus is busy executing a sequence of pipelined transfers, a competing master could “back-off ” and retry at a later time. We analyzed the advantage that such a technique might provide (bar 5, Figure 7) for our AMBA-based system. While the overall savings is only 14%, it is worth noting that this is the only technique that signi ﬁcantly reduces the AHB logic power (30%). 6.5 Summary The above analysis suggests that, in practice, none of the described techniques may be individually capable of achieving large power savings for the entire communication architecture. This is because the different techniques, while effective in terms of reducing the power consumption of certain components, may have little or no impact on the rest of the communication architecture. However, we observe that most of the techniques are complementary. For example, an analysis of the beneﬁts of combining trafﬁc sequencing with power management indicates that almost 40% savings may be achievable (bar 6 of Figure 7). Our studies show that signiﬁcant opportunities for power reduction exist, through appropriate combination of strategies that address the power consumption of different parts of the communication architecture. 7. CONCLUSIONS This work demonstrated that communication architecture power is a subject that needs to be addressed through careful consideration of all its constituent components. We presented a ﬁrst-of-its-kind study to analyze the power consumed by a commercial SoC communication architecture, and quantitatively analyzed the various factors on which it depends. Based on the insights gained, we evaluated a suite of power reduction techniques, and discussed their effectiveness in optimizing communication architecture power. 8. "
2006,A buffer-sizing algorithm for networks on chip using TDMA and credit-based end-to-end flow control.,"When designing a system-on-chip (SoC) using a network- on-chip (NoC), silicon area and power consumption are two key elements to optimize. A dominant part of the NoC area and power consumption is due to the buffers in the network interfaces (NIs) needed to decouple computation from communication. Having such a decoupling prevents stalling of IP blocks due to the communication interconnect. The size of these buffers is especially important in real-time systems, as there they should be big enough to obtain predictable performance. To ensure that buffers do not overflow, end- to-end flow-control is needed. One form of end-to-end flow- control used in NoCs is credit-based flow-control. This form places additional requirements on the buffer sizes, because the flow-control delays need to be taken into account. In this work, we present an algorithm to find the minimal decoupling buffer sizes for a NoC using TDMA and credit- based end-to-end flow-control, subject to the performance constraints of the applications running on the SoC. Our experiments show that our method results in a 84% reduction of the total NoC buffer area when compared to the state-of- the art buffer-sizing methods. Moreover, our method has a low run-time complexity, producing results in the order of minutes for our experiments, enabling quick design cycles for large SoC designs. Finally, our method can take into account multiple usecases running on the same SoC.","A Buffer-sizing Algorithm for Networks on Chip using TDMA and credit-based end-to-end Flow Control Mar tijn Coenen1 1Philips Research Eindhoven, The Netherlands Srinivasan Murali2 2CSL, Stanford University Stanford, USA mar tijn.coenen@philips.com smurali@stanford.edu Andrei R ˘adulescu1 & Kees Goossens1 andrei.radulescu@philips.com kees.goossens@philips.com Giovanni De Micheli3 3LSI, EPFL Switzerland giovanni.demicheli@epﬂ.ch ABSTRACT When designing a System-on-Chip (SoC) using a Networkon-Chip (NoC), silicon area and power consumption are two key elements to optimize. A dominant part of the NoC area and power consumption is due to the buﬀers in the Network Interfaces (NIs) needed to decouple computation from communication. Having such a decoupling prevents stalling of IP blocks due to the communication interconnect. The size of these buﬀers is especially important in real-time systems, as there they should be big enough to obtain predictable performance. To ensure that buﬀers do not overﬂow, endto-end ﬂow-control is needed. One form of end-to-end ﬂowcontrol used in NoCs is credit-based ﬂow-control. This form places additional requirements on the buﬀer sizes, because the ﬂow-control delays need to be taken into account. In this work, we present an algorithm to ﬁnd the minimal decoupling buﬀer sizes for a NoC using TDMA and creditbased end-to-end ﬂow-control, sub ject to the performance constraints of the applications running on the SoC. Our experiments show that our method results in a 84% reduction of the total NoC buﬀer area when compared to the state-ofthe art buﬀer-sizing methods. Moreover, our method has a low run-time complexity, producing results in the order of minutes for our experiments, enabling quick design cycles for large SoC designs. Finally, our method can take into account multiple usecases running on the same SoC. Categories and Sub ject Descriptors: B.4.3 Input / Output and Data Communications: Interconnections General Terms: Algorithms, Veriﬁcation Keywords: Systems-on-Chip, Networks-on-Chip, Area, Buﬀers Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. CODES+ISSS’06, October 22–25, 2006, Seoul, Korea. Copyright 2006 ACM 1-59593-370-0/06/0010 ...$5.00. 1. INTRODUCTION To eﬀectively tackle the increasing design complexity of SoCs, the computation architecture needs to be decoupled from the communication architecture [16]. By such decoupling, the computation and the communication architectures can be designed independently, thereby speeding up the entire design process and hence reducing the time-to-market of SoCs. NoCs can oﬀer such decoupling with decoupling buﬀers between the computational blocks and the communication blocks, thereby hiding the diﬀerences between the operating speeds and burstiness of the cores and the NoC. This allows the cores to execute their transactions without noticing the presence or impact of an interconnect, for example they will not stall if the NoC is busy with another core. Methods to ﬁnd the minimum size of the NoC decoupling buﬀers for the set of applications that are run on the SoC is an important problem for two reasons. First, the decoupling buﬀers take up a signiﬁcant amount of the NoC area and power consumption, thus ﬁnding the minimum buﬀering requirements is key to achieve an eﬃcient NoC implementation. Second, for a predictable system behavior, we need to compute the minimum buﬀering that still satisﬁes the application requirements. Moreover, some NoCs employ credit-based end-to-end ﬂow control mechanisms to provide guaranteed system operation and to remove message-dependent deadlocks in the system [1]. In this case, additional buﬀering is required to hide the end-to-end latency for the ﬂow control mechanism and to provide full throughput operation. If the buﬀers are too small, then the throughput and latency are aﬀected and no end-to-end guarantees can be given. In this paper we address the problem of computing the minimum size of the decoupling buﬀers of the NoC. We present an application-speciﬁc design method for determining the minimal buﬀer sizes for the Guaranteed Throughput (GT) connections of the Æthereal NoC architecture [15]. We model the application traﬃc behavior and the network behavior to determine the exact bounds on buﬀer-sizing. In our method, we also consider the buﬀering requirements due to the use of credit-based end-to-end ﬂow control. We apply our method to several SoC designs, which show ward channel requests may be sent from a master to a slave, and on the reverse channel a response can be sent (in case of a read transaction for example). On the forward channel therefore the master is the producer and the slave is a consumer; on the reverse channel these roles are reversed. Each connection has four buﬀers in the Network Interfaces (NIs) connecting the IP cores to the network: β F,M and β F,S , indicating the buﬀers in the master and slave NIs for the forward channel, and βR,S , βR,M for the reverse channel. The buﬀers in the NI are needed to compensate for the diﬀerences in operating speed and burst sizes between the IP cores and the NoC. The reason for each connection to have its own queues is that if connections would share a single queue, dependencies between these connections would arise. If on one connection data is not consumed, it will block the other connections, which in turn could lead to not meeting timing requirements or even deadlock [1]. The NoC provides throughput and latency guarantees by using TDMA [14]. This is implemented by means of slot tables in the NIs, where each slot represents an equal amount of time. Each connection is then assigned a number of slots to match its bandwidth and latency requirements [4]. In every slot a ﬁxed number of words can be sent into the network. The ﬁrst word is always a packet header, unless the previous slot was occupied by the same connection. Once data leaves the NI, the NoC guarantees a contentionfree path to the target NI [14]. This is achieved by reserving time-aligned slots for each router link. The calculation of the slots and the corresponding contention-free paths through the router network is currently done at design time [4]. Having a contention-free path results in minimal buﬀers in the routers, because no packet ever has to wait. It is necessary though that data from the routers is always accepted by the NIs, otherwise, if the consumer is slow or does not respond at all, the NI buﬀers would ﬁll up, ﬁnally spilling over in the network. This would break the contention-free routing and guarantees. In order to avoid this, the Æthereal NoC employs end-toend ﬂow-control using a credit-based mechanism [17]. Local counters in the NI keep track of the amount of space in buﬀers of the remote NIs for each connection. Whenever a word leaves a NI, the counter is decremented by one. If the counter reaches zero, the NI is not allowed to send data into the network. Whenever a word is consumed at the consumer NI, a credit is generated and sent back over the network when a time-slot is available for the connection. Because the credits do not arrive instantaneously, a producer does not immediately know when its data has been consumed. To avoid stalling of the producer if the NI runs out of credits, we must account for the end-to-end ﬂow control in our buﬀer calculation as well. This aﬀects the buﬀering calculations both on the forward and the reverse channel. On the forward channel, ﬂow control credits for the reverse channel are sent. On the reverse channel, ﬂow control credits for the forward channel are sent. The ﬂow control credits are sent in the packet header [14]. As a result, the available payload bandwidth is independent of the credit bandwidth. Within one connection the forward and reverse channels can also be computed independently of eachother. Finally, since each connection has its own buﬀers in the NIs, the other connections cannot interfere, and we can look at each connection in isolation when considering the size of the buﬀers in the NI. These independencies reFigure 1: The buﬀers for a connection that the proposed method leads to a large reduction in the total NoC buﬀer area (84% on average) and power consumption when compared to an analytical method. Our method has a low run-time complexity and is therefore applicable to complex SoC designs too. The method can be applied for designs with multiple usecases, by taking the maximum required buﬀer size over all usecases for each buﬀer. Finally, the method is also integrated into our fully automatic design ﬂow, enabling fast design cycles over a SoC design. Although the algorithmic method is presented for the Æthereal architecture, it can be applied to any NoC for which the behavior of both the IP cores and the network is periodic, such as aSoc [5] and Nostrum [6]. Traditionally, simulation (or trace) based approaches such as [12] are used to compute the buﬀering requirements in systems. While they provide an optimal bound for the given trace, there is no guarantee that the derived buﬀer sizes will satisfy diﬀerent traces. Hence, they cannot be used to build predictable systems. Analytical methods for sizing buﬀers based on jitter-constrained periodic behavior are known, such as the ones presented in [2, 3]. These methods are usually too pessimistic and can result in larger buﬀers than required for the design. We quantify this in Section 5. Stochastic approaches based on queuing theory are shown in [7]. Such stochastic models can only approximate the actual traﬃc characteristics of the application, and hence system behavior cannot be guaranteed. A general mathematical theory, network calculus [8], has been established to model network behavior.It allows computing bounds on delays and back-logs in networks. The foundations of our proposed algorithmic approach to buﬀersizing are based on the models of network calculus. Synchronous Data Flow (SDF) graphs to model signal processing and multimedia applications have been presented by several researchers [9]. Using SDF models to minimize buﬀering requirements of processors has been presented in [10]. The use of SDFs to model NoCs has been presented in [11]. The SDF models however assume a uniform data production and consumption to compute the buﬀering requirements. In NoCs that provide throughput guarantees, the TDMA slots allocated to a traﬃc stream need not be uniformly spread over time. Thus, SDF models can not model the network in such detail as shown here, and the results are hence less optimal. 2. THE Æthereal NOC The Æthereal NoC architecture uses the notion of connections to represent communication streams between IP cores [15]. Such connections are needed in order to allocate resources such as TDMA slots and buﬀers for real-time behavior. A connection consists of two channels, a forward channel and a reverse channel (see Fig. 1). On the forFigure 2: Periodic (left) and Aperiodic (right) Figure 3: The ﬂow of data and algorithm variables sult in compositionality; connections can be removed and added without aﬀecting the others, thereby making veriﬁcation easier, and real-time guarantees can easily be maintained. This also allows for simpler and incremental algorithms, such as the buﬀering algorithm described in this paper, which can calculate the buﬀering requirements for each connection in isolation. We describe the buﬀer-sizing algorithm for the forward and reverse channels. Before this, we need to characterize the application behavior. 3. APPLICATION BEHAVIOR In order to compute the sizes of the decoupling buﬀers in the NI, we need to characterize the application behavior of the IP cores. We consider three types of production patterns for the IP cores. First, the periodic production pattern, in which a producer produces a burst of ﬁxed size at the same time in each period. An example of the periodic producer pattern with burst size Di and period Ti is shown on the left in Figure 2. Second, the aperiodic production pattern, in which a producer produces a burst of ﬁxed size, but the bursts can appear anywhere within the period. Such a model is characteristic of applications with some uncertainty in the time at which the bursts are generated. Most traﬃc patterns of video processing applications are periodic and bursty in nature [13] and can be modeled by the periodic or the aperiodic production patterns. An example of the aperiodic production pattern is shown on the right in Figure 2. Finally, the multi-periodic production pattern, in which a producer produces multiple bursts, with diﬀerent burst sizes and time between the bursts. As an example, in video display systems the bursts of data for each horizontal scan line have a ﬁxed burst size, with a ﬁxed blanking (quiet) period between two scan lines. However, after a full set of horizontal scans, there is a bigger blanking period for the vertical scan. Even if a certain producer behavior does not ﬁt in one of these three production types, several methods can be used to transform it to one of them. Worst-case speciﬁcations could be used to compute the period and burst size, for example obtained from analytical estimates or from several experimental runs of the application. 4. COMPUTING THE NI BUFFER SIZES In order to compute the buﬀer sizes in the NIs, we want to compute the maximum diﬀerence between the number of words produced and the number of words consumed at any point in time. We ﬁrst describe the problem of buﬀer sizing for a general producer and consumer. We introduce two arrays input and output representing the production patterns of a producer and a consumer, where: Deﬁnition 1. input[t] has value ’1’ if the producer produces one value at time t, otherwise it has value ’0’ Deﬁnition 2. output[t] has value ’1’ if the consumer is ready to consume exactly one value at time t, otherwise value ’0’ Note that output describes the availability of the consumer to remove data from the buﬀer. The buﬀer may contain data, or may be empty. We deﬁne input.t to be the number of data items produced in the [0..t): input.t = input[i] (1) X 0≤i<t X Similarly we deﬁne output.t to denote the number of data items consumed in the interval [0..t). Recall that the output array only indicates whether the consumer is ready to consume a value, not that a value is actually consumed, because that depends on the availability of data in the buﬀer. To match the deﬁnition of output.t with the array output we therefore need to include an additional condition to check whether there is currently data in the buﬀer. Data is available at time-point j, when the number of words produced in the interval [0..j ] exceeds the number of words consumed in the interval [0..j ), input.(j + 1) > output.j . output.t = output[j ] (2) 0≤j<t∧input.(j+1)>output.j (3) Using Equation (1) and Equation (2) the speciﬁcation of the minimum required buﬀer size is the maximum diﬀerence between the number of words produced and consumed in an interval of length T: maxbuﬀer = max0 ≤t<T {input .t − output .t } To compute this, producer and consumer traces for an interval can be used to compute the required buﬀer size in that interval. There is of course no guarantee that a value derived from one trace satisﬁes the trace of any other, nor that the buﬀer will be big enough for any data produced outside the interval. In the next section we show how having periodic producer and consumer behavior allows us to compute the buﬀering requirements for an inﬁnite amount of time. In the next sections, we ﬁrst consider the calculation for the NI buﬀers connected to the producing IPs. Here the IPs are the producer and the NoC is the consumer. Then, we will look at the NI buﬀers connected to the consuming IPs, where the NoC is the producer and the IPs are consumer. In both cases we only consider the periodic production pattern. In section 4.3, we will show how to extend the algorithm to the other production patterns. 4.1 Producer NI buffer calculation When considering the producer NI buﬀering for a connection we need to calculate both the size of the forward master buﬀer β F,M for the master who produces requests on the forward channel, and the size of the reverse slave buﬀer βR,S for the slave who produces response data on the reverse channel. Below we discuss only the forward channel, because the same algorithm is used for the reverse channel. The algorithm for calculating the producer NI buﬀer requirements is a straightforward implementation of Equation (3), where two array variables P I P (Producer IP) and P N I (Producer NI) are used to capture the input/output patterns of the IP and NI, and two running variables I P prod and N oCC ons are used to store the total number of words produced by the IP and consumed by the NoC respectively, reﬂecting the left-hand side of Equations (1) and (2) respectively. We compute the consumer NI buﬀer in the same algorithm, which is explained in detail in the next section. We have visualized the variables in Figure 3, where both the IPs and the NIs are shown. Counter variables such as I P P rod, N oCC ons are indicated by square boxes, whereas the array variables are shown in the IPs and NIs with brackets behind them. Now let Ti be the period of the IP block producing data. The consumer in this case is the NI connected to the producer IP, the“producer NI”. Because of the slot table, the producer NI is also periodic with a period of To , equal to the number of slots multiplied by the time duration of one slot. Additionally in each period both the producer IP and producer NI produce/consume a ﬁxed number of words, Di and Do , respectively. Di corresponds to the burst of the producer, and Do is equal to the total number of words allocated for the connection in one slot table revolution. With this information, we can ﬁll the arrays ’PIP’ (Producer IP) and ’PNI’ (Producer NI). Because of the periodicity the arrays need only be as long as their respective periods. The P I P array is constructed as follows for a pe 1 if 0 ≤ t < Di ; riodic producer: 0 if Di ≤ t < Ti . P I P [t] = The P N I array is constructed according to the known slot  1 if consumer is ready to consume at time t; table allocation for the corresponding NI: 0 otherwise. P N I [t] = As mentioned in Section 4, we do not have to simulate for an inﬁnite period of time to compute the maximum, because the behavior of both producer and consumer is periodic. The crucial observation is that the behavior of two periodic intervals repeats itself after the least common multiple (lcm) of the two periods. This leads us to calculate the least common multiple of Ti and To , Tlcm . After Tlcm the producer and consumer will be realigned and the pattern repeats itself. We present Algorithm 1 for calculating the producer buﬀer requirements. Lines 1 through 7 initialize. Note that on line 1 we also need to take the period of the consumer into the calculation of the lcm, when considering the consumer NI buﬀering in the next section. Line 8 shows the time loop which has lcm iterations, in order to compute the maximum diﬀerence between producer and consumer in the timeinterval [0..lcm). In line 9, the number of words produced until time n is updated by adding P I P [n%Ti ] to I P P rod. Line 10 checks whether there are currently words in the producer NI buﬀer. If there are, in line 11 the N oCC ons variable is updated by adding P N I [n%To ] (which is one if the NI can send data at that point and zero if not). In line 12, the N ocArriv ing variable is updated to indicate whether a word of data will arrive at the consumer NI TF wd (the time it takes to traverse the network) time from now. This variable is used to capture the production pattern at the consumer NI, and will be explained in more detail in the next section. Finally in line 14, we see if the current diﬀerence between the number of words produced and the number of words consumed is bigger than the current maximum, and if so we replace it in line 15. Lines 17 to 29 are used for the consumer NI buﬀer calculation and will be explained in the next section. Algorithm 1 Calculates the buﬀer requirement in producer and consumer NIs for a periodic producer and consumer Require: Arrays PIP[0..Ti ], PNI[0..To ], CNI[0..To ] and 1: lcm ⇐ the least common multiple of Ti , To and Tc CIP[0..Tc ] 2: I P P rod ⇐ 0 3: N oCC ons ⇐ 0 4: N oC P rod ⇐ 0 5: I P C ons ⇐ 0 6: maxprodbuﬀer ⇐ 0 7: maxconsbuﬀer ⇐ 0 8: for n = 0 to lcm − 1 do I P P rod ⇐ I P P rod + P I P [n%Ti ] 9: if I P P rod − N oCC ons > 0 then 10: N oCC ons ⇐ N oCC ons + P N I [n%To ] 11: N oCArriv ing [n + TF wd ] ⇐ P N I [n%To ] 12: 13: end if if I P P rod − N oCC ons > maxprodbuﬀer then 14: maxprodbuﬀer ⇐ IPProd − NoCCons 15: 17: N oC P rod ⇐ N oC P rod + N ocArriv ing [n] 16: end if if N oC P rod − I P C ons > 0 then 18: I P C ons ⇐ I P C ons + C I P [n%Tc ] 19: credit ⇐ credit + C I P [n%Tc ] 20: 21: if CN I [n%To ] ∧ credit > 0 then end if 22: creditArriv ing [n + TRev ] ⇐ credit 23: credit ⇐ 0 24: 25: C reditsReceived ⇐ C reditsReceived end if 26: +creditArriv ing [n] if N oC P rod − C reditsReceived > maxconsbuﬀer then maxconsbuﬀer ⇐ NoCProd − CreditsReceived 28: 29: end if 30: end for 27: Note that the computation of I P P rod is only dependent on the producer itself, but the number of words actually consumed (N oCC ons) also depends on the availability of ﬂow-control credits. We will deal with ﬂow control in the consumer NI buﬀering, and make sure that the consumer NI buﬀer is big enough (and hence enough credits are available to the producer NI) to sustain the required throughput. 4.2 Consumer NI buffering When data is sent from the producer NI, it arrives at the consumer NI after TF wd time. We assume that we can characterize the behavior of the consumer similar to that of the producer: the consumer is periodic with a period Tc and consumes bursts of size Dc at the beginning of each period Tc . We store this information in the array C I P . The total number of words produced and consumed by the NI and the IP are stored in N oC P rod and I P C ons respectively. Once the consumer consumes data, it produces a credit as shown in Figure 3. The credits are sent back in the ﬁrst slot that is available for the connection in the consumer NI (the slot table of the consumer NI is contained in the CN I array). Whenever the credits are sent out, they still take the constant network delay TRev before the producer NI receives them, and there the total number of received credits is stored in a variable C reditsReceived. The producer NI hence does not get credits as soon as data has been consumed but only after a delay, and in the meantime a new burst of data from the producer may arrive. Since in the producer NI buﬀering we assumed there were enough credits available (in order to avoid stalls), we have to make sure the consumer NI buﬀer is big enough to receive additional words of data while the credits are underway. This leads us to compute the maximum diﬀerence between the number of words produced by the network and the number of credits received by the producer NI (instead of the number of words consumed by the consumer). Lines 17 to 29 of Algorithm 1 are used to calculate the required size of the consumer NI buﬀer. Line 17 updates the variable N oC P rod to reﬂect the number of words the network has produced until time n, by adding the N oC Arriv ing [n] variable to it. This variable is set to 1 whenever the producer NI produces a word TF wd time earlier in line 12. In line 18 the current ﬁlling of the consumer NI buﬀer is determined. If the diﬀerence is greater than zero, C I P [n%Tc ] (indicating if the consumer IP consumes at time n) is added to I P C ons in line 19. In order to model the credit mechanism, we also add C I P [n%Tc ] to the credit variable, which eﬀectively adds a credit whenever the consumer consumes a word. Credits are sent back to the producer NI once there is a slot available, which is checked in line 22. If a slot is available, in line 23 the creditArriv ing array is updated to reﬂect the arrival of a credit in the producer NI at time n + TRev . Line 24 resets the credit counter after credits have been sent. In line 26 the number of credits that are due to arrive at the producer NI are added to the variable C reditsReceived. Finally, the diﬀerence between the number of words produced by the network and the number of credits received is calculated and the maximum is stored. In Section 2 we mentioned that in each slot a packet header needs to be sent before any data, unless a connection was granted the previous slot also. We also mentioned that the ﬂow control credits are stored in a reserved part of the packet header with a size of 5 bits [14], allowing only for a maximum of 32 credits to be sent in each slot. While not shown in Algorithm 1 for simplicity, these issues are taken into account in our implementation. The producer, NoC and consumer periodic behavior need not be aligned. Therefore we shift two of the three input arrays to and rerun the algorithm for each combination. Thus we compute the minimum buﬀer size for all possible alignalgorithm is therefore O(Ti × To × (lcm(Ti , To , Tc ))) and thus ments of the periodic intervals. The time complexity of this polynomial. 4.3 Other production patterns In Section 3 we mentioned two other production patterns, Figure 4: Relative buﬀer sizes for various designs . Figure 5: Eﬀect of burst size on buﬀer-sizing. the aperiodic production pattern and the multi-periodic production pattern. Both of them can easily be incorporated in the presented algorithm. For the aperiodic pattern, we consider the worst case that can occur: in any time-interval with a length of 2 periods (essentially a sliding window), a maximum of three bursts may arrive. We then model the aperiodic pattern periodically by making the period twice as large and the burst three times as big. This can be reﬂected in the producer array easily. Whereas this might seem like a lot of overhead, in practice the period of the NI is much smaller than the period of the IPs. During one period of the IP block the NI might have 10 periods in which it consumes data half of the time, thus requiring a much smaller buﬀer. For the multi-periodic production pattern, we can consider the highest level at which the production pattern is periodic. For the video display system mentioned in Section 3 this would be the frame period. We can then create a producer array with the length of this period, and then ﬁll in each of the bursts by setting values to 1 whenever a word of data is being transferred in this period. 5. RESULTS We have compared the method described in this paper with the analytical method in [2] and with simulations of the applications. We benchmark the buﬀer-sizing methods using two diﬀerent in-house SoC designs, a set-top box SoC (D1) and a multimedia SoC for phones (D2). Each of these designs contains a large number of IP cores (10+) and a large number of connections (20+). In addition to these two designs, we have generated a large amount of synthetic designs divided in two classes: designs with a bottleneck IP core such as a memory (D3) and designs with evenly spread communication (D4). We calculated the buﬀer sizes for each of these designs, using algorithmic and analytical methods, and compare them to the maximum buﬀer ﬁlling observed during a simulation. between the IP core and the NoC. These buﬀers are the dominant factor in NoC area and power. Minimizing buﬀers while still matching the required application behavior is an important problem. In this paper we presented a novel design method for sizing the decoupling buﬀers in the NIs of the Æthereal NoC. The method exploits knowledge we have about the behavior of the IP cores and the NoC and can reduce the buﬀer area in designs on average by 84%, when compared to an analytical worst-case method. The method also takes into account the complicating eﬀects of end-to-end credit-based ﬂow-control on the required buﬀer sizes. The method is fast for all applications considered, and supports a wide variety of application behavior. Finally, the method can take into account multiple usecases for a single SoC design. Future work includes research on the the eﬀect of good alignment between the IP cores and the NoC, therefore reducing the buﬀering requirements even further. 7. "
2009,"Low-Power, High-Speed Transceivers for Network-on-Chip Communication.","Networks on chips (NoCs) are becoming popular as they provide a solution for the interconnection problems on large integrated circuits (ICs). But even in a NoC, link-power can become unacceptably high and data rates are limited when conventional data transceivers are used. In this paper, we present a low-power, high-speed source-synchronous link transceiver which enables a factor 3.3 reduction in link power together with an 80% increase in data-rate. A low-swing capacitive pre-emphasis transmitter in combination with a double-tail sense-amplifier enable speeds in excess of 9 Gb/s over a 2 mm twisted differential interconnect, while consuming only 130 fJ/transition without the need for an additional supply. Multiple transceivers can be connected back-to-back to create a source-synchronous transceiver-chain with a wave-pipelined clock, operating with 6sigma offset reliability at 5 Gb/s.",
2009,A variable frequency link for a power-aware network-on-chip (NoC).,"Although the technology scaling has enabled designers to integrate a large number of processors onto a single chip realizing chip multi-processor (CMP), problems arising from technology scaling have made power reduction an important design issue. Since interconnection networks dissipate a significant portion of the total system power budget, it is desirable to consider interconnection network's power efficiency when designing CMP. In this paper, we present a variable frequency link for a power-aware interconnection network using the clock boosting mechanism, and apply a dynamic frequency scaling (DFS) policy, that judiciously adjusts link frequency based on link utilization parameter. Experimental result shows that history-based DFS successfully adjusts link frequency to track actual link utilization over time, demonstrating the feasibility of the proposed link as a power-aware interconnection network for system-on-chip (SoC).",
2011,A low overhead fault tolerant routing scheme for 3D Networks-on-Chip.,"Three-dimensional integrated circuits (3D-ICs) offer a significant opportunity to enhance the performance of emerging chip multiprocessors (CMPs) using high density stacked device integration and shorter through silicon via (TSV) interconnects that can alleviate some of the problems associated with interconnect scaling in s ub-65nm CMOS technologies. However, network-on-chip (NoC) fabrics that will connect the cores together in 3D-ICs will increasingly be susceptible to permanent and intermittent faults, which can cause catastrophic system failure. To overcome these faults, NoC routing schemes can be enhanced by adding fault tolerance capabilities, so that they can adapt communication flows to follow fault-free paths. Existing work has proposed various fault tolerant routing algorithms for 2D NoCs. In this paper, for the first time, we investigate fault tolerant routing schemes in 3D NoCs. To achieve high arrival rates in the presence of faults, we propose a novel low-overhead fault tolerant routing scheme (4NP-First) for 3D NoCs. The proposed scheme is shown to have better resilience and adaptivity to f aults compared to e xisting dimension-order, turn-model, and stochastic random walk based 2D NoC routing schemes extended to 3D NoCs.",
2007,Bringing NoCs to 65 nm.,"Very deep submicron process technologies are ideal application fields for NoCs, which offer a promising solution to the scalability problem. This article sheds light on the benefits and challenges of NoC-based interconnect design in nanometer CMOS. The experimental results from fully working 65-nm NoC designs and a detailed scalability analysis are presented. The network on chip (NoC) is a promising solution to the scalability problem. NoCs build upon improvements in bus architecture-for example, in terms of topology design.",
