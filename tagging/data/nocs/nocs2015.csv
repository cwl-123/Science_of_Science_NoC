title,abstract,full_text
Networking Challenges and Prospective Impact of Broadcast-Oriented Wireless Networks-on-Chip.,"The cost of broadcast has been constraining the design of manycore processors and of the algorithms that run upon them. However, as on-chip RF technologies allow the design of small-footprint and high-bandwidth antennas and transceivers, native low-latency (a few clock cycles) and low-power (a few pJ/bit) broadcast support through wireless communication can be envisaged. In this paper, we analyze the main networking design aspects and challenges of Broadcast-oriented Wireless Network-on-Chip (BoWNoC), which are basically reduced to the development of Medium Access Control (MAC) protocols able to handle hundreds of cores. We evaluate the broadcast performance and scalability of different MAC designs, to then discuss the impact that the proposed paradigm could exert on the performance, scalability and programmability of future manycore architectures, programming models and parallel algorithms.","Networking Challenges and Prospective Impact of Broadcast-Oriented Wireless Networks-on-Chip Sergi Abadal NaNoNetworking Center in Catalonia UPC - BarcelonaTech Barcelona, Spain abadal@ac.upc.edu Eduard Alarcón NaNoNetworking Center in Catalonia UPC - BarcelonaTech Barcelona, Spain Mario Nemirovsky ICREA Professor Barcelona Supercomputing Center (BSC) Barcelona, Spain Alber t Cabellos-Aparicio NaNoNetworking Center in Catalonia UPC - BarcelonaTech Barcelona, Spain ABSTRACT The cost of broadcast has been constraining the design of manycore processors and of the algorithms that run upon them. However, as on-chip RF technologies allow the design of small-footprint and high-bandwidth antennas and transceivers, native low-latency (a few clock cycles) and lowpower (a few pJ/bit) broadcast support through wireless communication can be envisaged. In this paper, we analyze the main networking design aspects and challenges of Broadcast-oriented Wireless Network-on-Chip (BoWNoC), which are basically reduced to the development of Medium Access Control (MAC) protocols able to handle hundreds of cores. We evaluate the broadcast performance and scalability of diﬀerent MAC designs, to then discuss the impact that the proposed paradigm could exert on the performance, scalability and programmability of future manycore architectures, programming models and parallel algorithms. Categories and Subject Descriptors B.4.3 [Hardware]: Interconnections (subsystems)—Topology (e.g. bus, point-to-point) ; C.0 [Computer Systems Organization]: General—System Architectures Keywords Network-on-Chip, Wireless On-Chip Communication, Multicast, Broadcast, MAC Protocols, Manycore Processors 1. INTRODUCTION In the ever-changing world of microprocessor design, multicore architectures are currently the dominant trend for Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profi or commercial advantage and that copies bear this notice and the full citation on the fir t page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specifi permission and/or a fee. Requests permissions from permissions@acm.org. NOCS ’15 September 28 - 30, 2015, Vancouver, BC, Canada c(cid:13) 2015 ACM. ISBN 978-1-4503-3396-2/15/09 $15.00 DOI: http://dx.doi.org/10.1145/2786572.2788710. both conventional and high-performance computing. These architectures consist of the interconnection of several independent processors or cores, as well as of a multilevel cache to improve overall performance. Communication between cores and the memory hierarchy is not only a requirement to ensure the correct operation of a multiprocessor, but also a main determinant of its performance [14]. Networks-on-Chip (NoCs) are currently the paradigm of choice to meet the communication demands of multiprocessors beyond a handful of cores [7]. The packet-switched and point-to-point nature of NoCs provides better scalability in terms of throughput than buses and improved energy-delay proﬁle as long as most of the traﬃc is local. In light of this, multiprocessing architectures and algorithms generally take base on the well-known locality of reference properties and attempt to reduce the amount of global and broadcast communication, which incur into non-local traﬃc and are thus detrimental to most switched NoCs. Performance reductions are more severe in scaled processors, a scenario wherein communication is of critical importance [38]. The limited scalability of conventional NoCs in the presence of certain types of traﬃc is a factor that sets important restrictions upon the design of architectures and algorithms for manycore processors. For instance, the prohibitive cost of broadcast communication has important implications upon the performance, complexity, and programmability of manycore systems. In shared memory, having ordered broadcast capabilities could simplify the design of coherence protocols and increase their performance by reducing the number of race conditions [41] and the amount of indirection in certain situations [9], respectively. In message passing, a number of algorithms would highly beneﬁt from better one-to-all and all-to-all routines [43]. Further, eﬃcient hardware synchronization through broadcast would ease the complexity of parallel programming [33]. Recently, a plethora of works have tried to address these issues by proposing ways to improve the performance and scalability of NoCs. Topologies with higher connectivity [32, 38], sophisticated router pipeline designs [20, 35], or the use of high-radix switches [5] have consistently delivered better performance for most types of traﬃc. However, the inherently point-to-point nature of these networks prevents the design of truly scalable broadcast schemes without signiﬁcantly aﬀecting other traﬃc ﬂows. The advent of novel interconnect technologies has opened a set of new design opportunities to complement conventional NoCs [6, 10, 19]. Vertical stacking enables new topologies not feasible in planar environments and brings nodes closer both physically and logically, thereby improving performance. The use of nanophotonic components has been also proposed as it promises great energy eﬃciency, as well as outstanding performance via speed-of-light propagation and virtually unlimited bandwidth. Similarly, RF communication via transmission lines oﬀers improved energy efﬁciency and long-range communication support. However and as indicated in Section 2.1, all these technologies have their caveats, which may reduce their applicability. Last but not least, the concept of Wireless Network-onChip (WNoC) has recently garnered considerable attention due to its unique latency, reconﬁgurability and broadcast capabilities [1, 10]. In a WNoC, a transmitting antenna radiates RF signals at a given frequency, which propagate throughout the chip and may be received by any other antenna tuned to the same frequency. In other words, all antennas tuned at the same frequency channel share the medium similarly to in a bus. Most works make the case for the use of multiple channels, approach that reduces the probability of two or more antennas trying to access to the same channel simultaneously. These advanced designs have reported outstanding performance and power improvements when augmenting a conventional NoC by reducing the cost critical transmissions, alleviating certain network bottlenecks, or adapting to the traﬃc of diﬀerent applications [11, 13, 25, 31]. In this paper, we present the concept of Broadcast-oriented Wireless Network-on-Chip (BoWNoC, see Fig. 1), a WNoC design that basically diﬀers from most proposals in that all cores share a single broadband channel. This approach reduces the attainable throughput of the WNoC, but instead provides a simple and eﬀective vehicle for the ordered delivery of multicast and broadcast traﬃc in a single hop. As such, the BoWNoC will only transport broadcast and latency-critical messages, thereby complementing a conventional NoC that will deal with the rest of communication ﬂows. Although this strategy is not new [27, 34], this is the ﬁrst work that discusses the use of a wireless plane for broadcast purposes as a complement of a unicast and throughput-oriented network. The motivation of this research resides in the limitations cast upon current manycore systems, which we expect to largely eliminate with the introduction of BoWNoC. Besides presenting BoWNoC, the contributions of this work are: • An outline of its enabling technologies, design aspects and networking challenges. • An evaluation of its attainable broadcast performance, which is later compared to that of conventional NoCs with state-of-the-art broadcast support. • A qualitative analysis of the impact of this paradigm upon the scalability, performance and programmability of future manycore systems. The remainder of the paper is as follows. In Section 2, we present the concept of BoWNoC and outline their main characteristics and diﬀerences with respect to other designs. Section 3 summarizes the methodology used for the modEĞƚǁŽƌŬ/ŶƚĞƌĨĂĐĞ ZŽƵƚĞƌ ĞE/& Z K  ŽŶƚƌŽůůĞƌ dƌĂŶƐĐĞŝǀĞƌ ǁE/& D W,z ŶƚĞŶŶĂ Figure 1: Schematic diagram of a Broadcast-oriented Wireless Network-on-Chip. eling and simulation of diﬀerent BoWNoC schemes. Section 4 presents the results of a performance evaluation that compares the performance of BoWNoC with that of other advanced NoCs. Then, in Section 5, we discuss the prospective impact that the improved capabilities of BoWNoC could have on the design of future architectures and algorithms. Section 6 concludes the paper. 2. BROADCAST-ORIENTED WIRELESS NETWORK-ON-CHIP 2.1 Motivation and Related Work Ever since NoCs started replacing buses for scalability reasons, several works have acknowledged the lack of proper multicast/broadcast support. Given the unicast nature of NoCs, multicast packets need to be replicated at some point. If the destination set is large, this process causes a severe performance drop in the whole network [16]. This situation is expected to worsen as the number of cores grows, and may lead to a remarkable slowdown in the execution speed of multiprocessors [21]. To remedy this, improved router designs have sought to minimize latency by reducing the pipeline depth [35] or even allowing multiple hops within the same clock cycle [22], and to maximize throughput by balancing the load [21]. Prototypes have shown impressive performance gains and even demonstrated that ordered delivery of broadcasts is possible in switched NoCs, which typically do not guarantee ordering [9]. However, these works have recognized important latency and throughput scalability concerns beyond 100 cores: messages still need to traverse a potentially large number of routers to reach the furthest nodes, and contention will still be signiﬁcant for large destination sets. Another set of proposals broke away from the switched paradigm and, instead, have proposed to use globally shared media to carry broadcast communication ﬂows. Manevich et al proposed to overlay buses on top of a mesh NoC [27]. Oh et al presented a shared transmission line ring that supports the broadcast of RF signals [34]. Such design uses very similar principles than IBM’s nanophotonic platform Corona [42], which has a shared waveguide exclusively for broadcast signals. Kurian et al also leveraged nanophotonics to create a set of independent logical rings, each of which broadcasts signals from a given transmitter [23]. However, all cases entail scalability concerns that may limit their usefulness: the design complexity of buses and transmission  ŽŶƚƌŽůůĞƌ ŝнϬ ŽŶƚƌŽůůĞƌ ŝнϭ ŽŶƚƌŽůůĞƌ ŝнϮ ŽŶƚƌŽůůĞƌ ŝнϯ Ɛ ǁ ŝ ƚ Đ Ś ϰ ͗ ϭ  tŝƌĞůĞƐƐE/& tŝƌĞůĞƐƐE/& ŽŶƚƌŽůůĞƌ ŝнϬ ŽŶƚƌŽůůĞƌ ŝнϭ ŽŶƚƌŽůůĞƌ ŝнϮ ŽŶƚƌŽůůĞƌ ŝнϯ (a) Upstream (b) Downstream Figure 2: 4-way concentration in BoWNoC. lines does not scale well and worsens when broadcast capabilities are required, whereas the logarithmic nature of losses in the nanophotonic case complicates the design of scalable networks within strict laser power budgets [2]. 2.2 Design Aspects and Benefit BoWNoC adopts wireless communication technologies to create a globally shared medium and uses it as a broadcast plane. This is accomplished by resorting to the inherently broadcast nature of WNoC and tuning all the antennas to a unique frequency channel. The use of a single channel forces BoWNoC to manage access to the shared medium through arbitration, but also guarantees one-hop delivery with all nodes having a consistent view of the order of delivery. In other WNoC designs, nodes are divided in diﬀerent subsets and assigned one channel per subset. Thus, broadcast messages still need to resort to the switched NoC, thus requiring multiple hops and losing ordering guarantees. Figure 1 depicts the scheme that bridges the processors with the network. Ideally, one small-footprint antenna and transceiver will be integrated within each computing tile to provide broadcast capabilities at the core level. If it is necessary to reduce the number of on-chip antennas as per area or power reasons, k-way concentration can be leveraged with an asymmetric design. As shown in Fig. 2, a switch can arbiter access of k controllers to the antenna, whereas received signals can be ampliﬁed and delivered to all k controllers. For small k values, the latency overhead would be one clock cycle per direction at most. The shared channel should support very high data rates in order to ensure that the transmission of a single message does not take more than a few clock cycles. Even so, it is expected that the attainable throughput will be low as compared to in conventional NoCs. Consequently, the use of BoWNoC will be limited to broadcast transmissions and, in rare occasions, latency-critical messages (this basically concerns to the design of the controller). Overlaying such a network over a throughput-oriented NoC would not only provide scalable, uniform, and low-latency support for broadcast, but also dramatically reduce contention eﬀects in the conventional NoC plane by preventing it from having to deal with such type of traﬃc. To quantify the potential improvements achievable with this scheme, we evaluated the performance of E-MESH depicted in Sec. 3.1 with and without an idealized instance of BoWNoC. Figure 3 shows that the low-load latency is cut by a factor proportional to both the system size and the percentage of broadcast transmissions, whereas the saturation throughput increases signiﬁcantly for a wide range of broadcast percentages. 2.3 Main Enabling Technologies To maximize the beneﬁts of the BoWNoC approach, it is required that antennas and transceivers (i) be commensurate in size with future computing tiles, (ii) oﬀer data rates in the N=16 N=64 N=256 20 t n e m e v o r p m I y c n e t a L 10 8 6 4 2 0 0 t n e m e v o r p m I t u p h g u o r h T 1.6 1.4 1.2 1 0.8 0.6 100 40 60 Broadcast Percentage 80 100 N=16 N=64 N=256 101 Broadcast Percentage 102 Figure 3: Improvement in terms of (a) latency and (b) throughput delivered by BoWNoC as a function of the broadcast percentage and system size. order of one ﬂit per clock cycle, and (iii) consume low power. Fortunately, this three requisites could be met by increasing the frequency at which the wireless network operates, as this increases its capacity and reduces both the size and energy per bit of the antennas and transceivers [2]. Assuming a clock frequency of 1 GHz, an operation frequency of a few hundreds of GHz seems an appropriate target. Antennas would have a lateral size of a few tens of micrometers and potential to deliver data rates of several tens of Gbps. Reaching such frequency bands becomes possible as CMOS technology evolves and advanced devices such as FinFETs and III-V on silicon are implemented [1, 24, 39, 45]. A growing number of publications also addresses mmWave and THz on-chip antennae that are suitable for silicon-based transceivers [15, 29]. Additionally, novel technologies such as graphene could introduce further improvements at the chip scale: graphene-based planar antennas are expected to radiate in the THz band while being two orders of magnitude smaller than their metallic counterparts [1], whereas graphene-based transceivers can be envisaged as the predicted operating frequency of graphene devices lies within the same band [44]. Another technology that may conﬁrm the feasbility of BoWNoC is surface wave technology [17]. Instead of propagating in all directions, radiated signals are bound to the surface and propagate along it as in a transmission line. This shrinks the spreading loss and, if feasible, opens the door to higher throughput schemes without the design complexity of transmission lines. 2.4 MAC: The Grand Challenge The design of a WNoC implies addressing important challenges at the diﬀerent levels of the protocol stack [1, 10]. For instance, ﬁnding lightweight coding and modulation schemes able to maintain a graceful balance between speed, power, and transceiver complexity is one of such challenges. But, given that the medium is shared by a potentially large number of nodes, resource management and access control are arguably the most critical design challenges. On top of that, there is a need to revise addressing and routing mechanisms             Table 1: Simulation Parameters System Die Size 400 mm2 Number of Cores 16 - 1024 Operation Frequency 2 GHz Flit Size 128 bits Wireline Network-on-Chip Topology Mesh Router Pipeline 1-cycle (bypass) Flow Control Credit-based Wireless Network-on-Chip Number of Channels 1 Channel Capacity 256 Gbps1 Propagation Delay <0.25 cycles a state-of-the-art switched NoC. The simulator employed to this end is PhoenixSim [8], a cycle-accurate NoC simulator. It includes a complete set of methods and primitives for the evaluation of switched NoCs, on top of which we implemented the necessary modules for the simulation of WNoCs. To model the system, we used the scheme depicted in Figure 1 with the parameters shown in Table 1. Cores simply inject traﬃc following the directives of a centralized generator, which models ﬂows with a given burstiness and distributes them according to a given spatial distribution [40]. All packets are broadcast and, for simplicity, their length equals to the ﬂit size. We stress the network with a variable number of injected packets between 10K and 100K, with appropriately sized warm-up and cool-down periods. The wireless network is modeled as a shared medium in which any node can transmit following the policies set by the MAC protocol. During the propagation time, receiving nodes may still not be aware that the medium is being used. In contention-based schemes, this can lead to collisions even if the transmitters check the medium before occupying the channel. Nodes that are not transmitting will automatically detect collisions whenever two incoming transmissions overlap in time. Both messages are internally discarded and the collision is generally notiﬁed to the MAC module. 3.1 Investigated Network Architectures We aim to cover a large fraction of the solution space by considering the following schemes. Unless noted, acknowledging is implicit since negligible bit error rates can be assumed with proper coding and power allocation. Wireless capabilities are given at the core level. Multihop Token Passing [W-MTKN] - where only the core that possesses the token is able to transmit. We consider a asynchronous wired ring for token passing purposes, as represented in Fig. 4. Each MAC module is connected to the ring through a register controlled by a seize bit, which is in those WNoCs where packets may go through both the wired and wireless planes to reach its destination. The BoWNoC paradigm has substantial diﬀerences with respect to other WNoC designs, subtly aﬀecting the design challenges. Since the wired and wireless planes are isolated in BoWNoC (i.e., a message will only go through one of the planes to reach its destinations), a revision of the addressing and routing mechanisms may not be needed. Instead, even more emphasis must be put on the criticality of the MAC protocol design as a given channel will be shared by a noticeably larger number of nodes. To take full advantage of the broadcast capabilities of BoWNoC, the MAC protocol must be: 1. Scalable: the zero-load broadcast latency of BoWNoC is scalable as it remains constant when varying the number of cores. Therefore, the MAC protocol must also be scalable (which is a challenge in itself ) in order to retain such latency advantage. Due to this, distributed mechanisms may be preferred. 2. Performance and cost eﬀective: the overhead introduced by the protocol is another important aspect. Lengthy or power-hungry arbitration mechanisms cannot be applied in this scenario due to its stringent performance and power requirements. The main challenge here is to design a protocol that, while keeping the overhead low, performs well even in the expected presence of bursty traﬃc [3]. 3. Fair: fairness generally implies providing service with a rather uniform latency, with independence on the source of the message. This is a diﬃcult task when accounting with few resources and using a distributed protocol. The expected presence of hotspot traﬃc [3] may further complicate this goal. In order to achieve this goals, the chip scenario oﬀers unique opportunities not available in conventional wireless networks. The possibility of implementing a dedicated lightweight wired network to help with arbitration, or of exploiting spatiotemporal traﬃc correlations to predict the source of broadcast transmissions, represent two clear examples. The WNoC scenario admits both collision-free schemes (any combination of multiplexing and centralized or distributed arbitration) and contention-based schemes (where cores contend to access the medium) as long as the area and power overheads are low. First designs heavily relied on frequency-multiplexing [25], which were later enhanced with basic time-multiplexing or token-passing arbitration schemes to scale to a larger number of cores and still avoid collisions [13,31]. Another collision-free mechanism has been recently proposed in [12], consisting of distributed protocol where nodes request access using tightly-synchronized codemultiplexed packets. Contention-based mechanisms, which can virtually eliminate the overheads associated to accessing the channel, have received less attention due to their poor performance when high loads cause recurrent collisions. To address this issue, authors of [28] propose an adaptive scheme that switches between a contention-based protocol and a token-passing scheme depending on the level of contention. 3. SIMULATION METHODOLOGY In this work, we evaluate the performance of a set of representative BoWNoC designs and benchmark them against token line MAC  i seizei seizei+1 seizei+1 MAC  i+1 seizei Figure 4: Multihop ring for token passing. ] s e l c y c [ y c n e t a L d a o L − w o L t 150 100 50 W−MTKN W−CSMA W−CARB E−MESH 0 16 200 400 600 Number of Cores ] u p h g u o e c h y T c e s b s s l t i i l f [ r l / i m d A 1 0.8 0.6 0.4 0.2 0 16 200 400 600 Number of Cores energy consumption [20]: we choose M = 4 as a conservative value. Token passing overlaps with part of the transmission. Carrier Sensing [W-CSMA] - with which we aim to represent contention-based protocols. We model a simple non-persistent MAC protocol based on collision avoidance: when a node is ready to send data, it listens to the medium and only transmits if the medium is idle. Otherwise, it waits during a backoﬀ period and checks again whether the medium is idle. We adopt a negative acknowledgment (NACK) strategy to reduce the control overhead: NACKs are sent through the same channel than data, seeking to create a burst of NACKs that will be interpreted by the source as an erroneous transmission. A packet will be forwarded to an alternative network plane in the unlikely case that it exceeds the maximum number of retries (8). Centralized Arbitration [W-CARB] - where contention is progressively resolved using a lightweight wired network consisting of a hierarchical set of 4:1 switches. Transmitters send their source ID to the buﬀer through such arbitration network, the last layer of which is connected to a FIFO buﬀer. This buﬀer grants access to the node whose request is in the head of the buﬀer using, to this end, a dedicated 1-bit wire. We assume that each switch stage and the access granting take one clock cycle, and that the latter partly overlaps with the wireless transmission. The main reason for evaluating such potentially unrealistic scheme is to quantify the improvement margin of the protocols mentioned above in terms of throughput. Routed Mesh [E-MESH] - as baseline, we consider an aggressive mesh design where router and link traversals take one clock cycle each when there is no contention, which is achievable with bypass strategies [35]. Multicast is treebased with deterministic routing. We consider multiport switch allocation and ﬂit forking at the crossbar [21], which allows to keep the router traversal time to one clock cycle even for multicast packets. 4. PERFORMANCE EVALUATION The networks discussed above are evaluated in terms of latency for low loads and of throughput for high loads. For the latter, we obtain the throughput for a given latency limit to be considered the maximum admissible for the on-chip scenario. Here, this limit is set to 250 clock cycles. Figure 5 shows how the performance of the diﬀerent options scales with the number of cores. In this case, we modeled traﬃc as broadcast with exponential arrivals and uniform source distribution. It is observed that W-CSMA oﬀers the best performance in terms of latency, which is of a few clock cycles and is maintained constant for all system sizes for low loads, with a reasonable throughput for high loads. Even though the latency of W-CARB slightly increases with the system size due to the growing number of 800 1024 800 1024 Figure 5: Low-load latency and admissible throughput (at 250 cycles) as a function of the system size. switch stages that messages need to traverse to reach the buﬀer, the results are extremely competitive and yielding the best throughput among the wireless options. The propagation of signals to all cores, which takes ∼0.2 clock cycles in this conﬁguration, prevents the throughput from being larger; however, this could be improved by increasing the wireless capacity a bit further. In W-MTKN, the latency grows linearly with the number of cores due to the increasing diameter of the token ring, to the point of limiting the admissible throughput for high core counts. Both metrics are improvable, though, by using adaptive designs such as the one proposed in [28] or by letting tokens do more hops in the same clock cycle. Another possible enhancement would consist of partially or completely overlapping the wireless transmission and the passing of the token. Finally, E-MESH shows poor latency scalability but the best throughput of all options, accomplished by virtue to the aggressive router design and the huge bisection bandwidth of the network. Note, though, that such high broadcast throughput implies signiﬁcant in-network contention for the rest of traﬃc ﬂows. 4.1 Sensitivity Study Several studies have revealed that on-chip communication in general, and multicast in particular, is potentially bursty and may be concentrated around a reduced number of cores [3, 40]. Burstiness can be modeled through the Hurst exponent H , which takes values between 0.5 (exponential) and 1 (extremely bursty). We generate bursty traﬃc by alternating ON/OFF periods, the length of which follows Pareto distributions deﬁned by H [26]. Spatial concentration is modeled through a gaussian parameter σ , which takes values between 0 (concentrated) and ∞ (spread out) and describes the percentage of the load to be randomly assigned to each node. Previous results assumed H = 0.5 and σ/N = 100. Due to the random nature of bursts, we performed 15 runs for each {H, σ, λ} tuple, where λ is the aggregated load, and calculated the geometric mean. Figure 6 the results of the evaluation in a 256-core system for diﬀerent levels of burstiness and concentration. On the one hand, all networks see their performance signiﬁcantly reduced as the burstiness of               5. IMPACT ON FUTURE MANYCORE SYSTEMS The capabilities and limitations of the on-chip interconnect have traditionally guided the design of parallel architectures and of the algorithms that run over them. For a few cores, buses with ordered broadcast capabilities are feasible and broadcast-based architectures yield better performance. As processors scale and the interconnect design shifts to switched NoCs, though, broadcast becomes a costly feature. This encourages the design of systems that actively avoid it, impacting upon programmability and performance. Having an eﬀective broadcast plane with uniform latency and total ordering would therefore be invaluable as it potentially relaxes a large number of constraints cast upon architects and parallel programmers. As we discuss next, the potential advantages are manyfold and we speculate that they will be thoroughly investigated once the feasibility of the BoWNoC approach is demonstrated. 5.1 Synchronization Primitives Synchronization among a large set of cores is one of the functionalities that may beneﬁt most from BoWNoC. Notiﬁcation and release stages of most methods (e.g. barriers) can be easily implemented with broadcast. Moreover, unique properties of the transmission of RF signals through a shared medium allow the design of alternative schemes for such synchronization methods [4, 33]. By reducing the cost of global synchronization, programmability is improved as maintaining sequential consistency becomes easier and less expensive. Moreover, the bottleneck of synchronizationintensive kernels and applications (e.g. after many OpenMP loops there is an implicit barrier) would be alleviated. 5.2 Architectures Shared memory systems normally heavily rely on an architecture that, among other aspects, ensures the coherency and consistency of shared data and, by doing so, generates on-chip communication. With the advent of NoCs, broadcast-based snoopy methods for coherence have progressively given way to directory-based protocols that only use multicast to invalidate shared data [37]. However, this comes at the cost of signiﬁcant area, energy, and performance overheads [9], as well as of higher design complexity. The availability of inexpensive broadcast may not represent the return of snoopy coherence, but could help increase performance and reduce the complexity of existing protocols. Variants of token coherence [30], which decouple performance and correctness (thereby reducing complexity), generate considerable broadcast. Their use may be extended beyond a few tens of cores. Using renewed synchronization methods, a reduction of the race conditions of coherence protocols could be also envisaged as proposed in [41]. Additionally, explicit communication could be enforced to help coherence protocols in performance-degrading situations (e.g. automatic updates on each write to a producer address in producer-consumer access patterns). 5.3 Algorithms In systems such as message passing, communication is explicit and the programmer needs to orchestrate it in order to optimize performance and ensure correctness. One-to-all and all-to-all communication routines such as MPI_Bcast or Figure 6: Low-load latency and admissible throughput (at 250 cycles) in a 256-core system as a function of the temporal and spatial characteristics of traﬃc. traﬃc increases: W-CSMA and E-MESH show particularly dramatic growths in terms of latency, whereas in all cases the throughput is approximately cut to half. On the other hand, the impact of the traﬃc concentration on performance is generally minor with notable exceptions in WMTKN and E-MESH, where the throughput is slightly higher if the load is spread out. 4.2 Energy In a conventional mesh, broadcasts invariably imply N − 1 link traversals and buﬀer writes/reads, as well as a total of 2(N − 1) ﬂits being output by routers (either towards the next router or when being ejected). Assuming 45nm technology and a 128-bit datapath, low-swing links would approximately consume 40 fJ/bit/hop [35], while the router considered in this work consumes 117 fJ per buﬀered bit and between 65 and 221 fJ per each bit that performs a crossbar traversal [21]. With all this, the dynamic cost of a broadcast in such an optimized scheme sits between 0.29 and 0.6 pJ/bit/core. In BoWNoC, the cost will highly depend on the modulation used. Recent implementations of simple On-Oﬀ Keying (OOK) working at 60GHz attain speeds around 16Gbps while consuming 17mW at the transmitter and 15mW at the receiver [45]. With these ﬁgures and given that in a broadcast we have one transmitter and (N − 1) receivers, the total energy consumption would be of around 0.94 pJ/bit/core, assuming a negligible MAC overhead. This is between 2X and 4X larger than in an aggressive switched NoC design, diﬀerence that could be compensated by the use of concentration as outlined in Fig. 1. We also envisage a strong reduction of the energy consumption in BoWNoC by virtue of (1) custom designs increasing the power at the transmitter in order to relax the consumption at the receiver, and (2) the use of higher frequencies allowing the design of transceivers with lower energy per bit (see [2]). MPI_Allgather are available to the programmer, yet their use may be limited in manycore processors due to their increasing cost and reduced performance. The main issue is that certain widespread applications exhibit bottlenecks due to these collective operations [43]. With BoWNoC, collective communication routines could be redeﬁned seeking greater performance and lower cost. This would increase the performance of unmodiﬁed versions of the applications; however, larger beneﬁts will be reaped if algorithms are re-deﬁned taking into consideration the improvement of collective communication support. In extreme cases, programmers may want to go back to the original problem and re-implement a solution without global communication constraints. 5.4 Programming Models The work in [36] discussed several programming models that aim to combine the ﬂexibility of shared medium and the hand-tuned performance of message passing, and that would beneﬁt from an improved broadcast mechanism. One example is Consumer Tagging, where the programmer tags addresses susceptible of being producers and the consumers associated to them. Writes to the tagged addresses will be automatically updated without the intervention of the coherence protocol. With broadcast, the programmer does not even need to specify the consumer set. Other examples are Adaptive Constraint-Based Programming and Application Heartbeats, both of which periodically broadcast information. We also speculate that an eﬃcient broadcast plane could be also used to improve the performance and redundancy properties of the well-known MapReduce model. 6. CONCLUSIONS As advancements in RF technologies push the operating frequencies towards the mmWave and terahertz bands, the implementation of antennas and transceivers comparable in size with the processing cores becomes feasible. This enables the creation of wireless on-chip networks with unprecedented broadcast capabilities even in manycore settings. We have shown that, when overlaid to a conventional NoC, such networks will provide dramatic performance improvements for a wide range of cases. To harness such potential, it is indispensable to account for scalable, lightweight and eﬀective MAC schemes capable of coping with the stringent communication requirements of manycore chips. Through performance evaluations, we have observed that simple MAC implementations could consistently provide latencies several times lower and throughputs comparable to those of conventional NoCs. As discussed, the availability of such a broadcast medium will have multiple implications on future systems from the architectural and algorithmic perspectives. Acknowledgments This work was supported by SAMSUNG under the GRO Program, INTEL under the Doctoral Student Honor Program, and the Technical University of Catalunya (UPC). 7. "
Novel Hybrid Wired-Wireless Network-on-Chip Architectures - Transducer and Communication Fabric Design.,"Existing wireless communication interface of Hybrid Wired-Wireless Network-on-Chip (WiNoC) has 3-dimensional free space signal radiation which has high power dissipation and drastically affects the received signal strength. In this paper, we propose a CMOS based 2-dimensional (2-D) waveguide communication fabric that is able to match the channel reliability of traditional wired NoCs as the wireless communication fabric. Our experimental results demonstrate that, the proposed communication fabric can achieve a 5dB operational bandwidth of about 60GHz around the center frequency (60GHz). Compared to existing WiNoCs, the proposed communication fabric can improve the reliability of WiNoCs with average gains of 21.4%, 13.8% and 10.6% performance efficiencies in terms of maximum sustainable load, throughput and delay, respectively.","Novel Hybrid Wired-Wireless Network-on-Chip Architectures: Transducer and Communication Fabric Design [Extended Abstract] Michael Opoku Agyeman1 , Wen Zong1 , Ji-Xiang Wan2 , Alex Yakovlev 3 , Kenneth Tong4 , Terrence Mak1 1Department of Computer Science and Engineering, The Chinese University of Hong Kong: michael, wzong, stmak@cse.cuhk.edu.hk 2Xian Institute of Space Radio Technology, 150 Wei Qu West Street, Changan District, P.O. Box 165, Xian, 710100 PRC 3 School of Electrical & Electronic Engineering, Newcastle University, UK: Alex.Yakovlev@newcastle.ac.uk 4Department of Electrical and Electronic Engineering, UCL, London, UK: K.tong@ucl.ac.uk ABSTRACT Existing wireless communication interface of Hybrid WiredWireless Network-on-Chip (WiNoC) has 3-dimensional free space signal radiation which has high power dissipation and drastically aﬀects the received signal strength. In this paper, we propose a CMOS based 2-dimensional (2-D) waveguide communication fabric that is able to match the channel reliability of traditional wired NoCs as the wireless communication fabric. Our experimental results demonstrate that, the proposed communication fabric can achieve a 5dB operational bandwidth of about 60GHz around the center frequency (60GHz). Compared to existing WiNoCs, the proposed communication fabric can improve the reliability of WiNoCs with average gains of 21.4%, 13.8% and 10.6% performance eﬃciencies in terms of maximum sustainable load, throughput and delay, respectively. 1. INTRODUCTION The slow multi-hop communication as well as poor scalability with technology of the conventional metal based interconnects has propelled the research for alternative communication fabrics for modern System-on-Chip (SoC) design [1]. Millimeter-wave has been investigated as a suitable candidate with promising CMOS components that can scale with transistor technology. Traditional wire based NoCs on the other hand, are highly eﬃcient for short distances despite their limitations over long distance. Consequently, hybrid wired-Wireless Networks-on-Chip (WiNoCs) have emerged to combine wireless millimeter wave (mm-Wave) and wired communication fabric in NoCs. However due its 3-D free space signal radiation the wireless communication fabric is lossy and hence lowers the overall reliability of WiNoCs. Conventional wires have extremely low bit error rate (BER) of around 10−14 compared to that of mm-Wave (around 10−7 ). In NoCs, a single message loss can have drastic effects on the performance of the multi-core system. Hence, novel wireless communication fabrics that oﬀer high data Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s). NOCS ’15, September 28-30, 2015, Vancouver, BC, Canada ACM 978-1-4503-3396-2/15/09. http://dx.doi.org/10.1145/2786572.2786586 bandwidth as well as improved reliability with BER similar to the wired communication fabric are required to provide a good trade-oﬀ for WiNoCs. 2-D guided wave in the form of surface wave (SW) interconnect is an emerging wireless communication fabric that is power eﬃcient and has a highly reliable data throughput for long distance communication [2]. However, previous contributions on SW have not focused on optimizing the communication fabric to improve reliability wireless interface [2]. We propose a highly reliable SW communication fabric along with an eﬃcient transducer interface that is able to match the signal integrity of short range wired NoCs. 2. DESIGN OF RELIABLE CMOS-BASED 2-D WAVEGUIDE FOR WINOCS ∇ 2 l + (1) (cid:21) Xs = 2πf µ0 We replace the wireless channel with a reliable 2-D communication fabric which radiates signals in the form of surface waves as shown in Fig 1(a). Transverse Magnetic mode (TM) surface wave can be supported by a dielectric-coated metal surface. To enable the ﬁeld concentration in Layer 2 nearer to the surface of Layer 1 for TM-surface wave propagation, a positive surface reactance is required. The surface (cid:20) r − 1 reactance, Xs is given by: r It can therefore be deduced from Eq. 1 that, the eﬃciency of the TM surface wave propagation depends on the operating frequency, f , dielectric constant, r , thickness of the dielectric material, l, and the skin depth of the metal conductor, ∇. To generate an eﬃcient TM surface wave signal in a 2-D waveguide sheet, we use commercially available low loss cost-eﬀective laser ablatable Taconic RF − 43 material [3] with 0.2mm thickness as the dielectric (Layer 1 in Fig. 1(a)). By introducing the 0.25mm thick Taconic material, we can achieve a surface reactance Xs of 30Ω to 150Ω over the wide frequency range of 20GHz to 100GHz for TM mode surface wave. The designed transducer consists of a parallel waveguide fed by a quarter-wavelength monopole through an open aperture. The transducer is coupled to a transceiver circuit which is responsible for modulation, signal transmission and receiving capabilities. We adopt the low-power non-coherent on-oﬀ keying (OOK) modulator for our implementation (Fig. 1(b)) which has been demonstrated to achieve a BER less than 10−14 [4]. We have performed simulations in Ansys HFSS. As shown in Fig. 1(b), the electric ﬁeld distribution demonstrates that a high percentage of the (a) (b) (c) Figure 1: Proposed wireless communication fabric for WiNoCs. In Fig. 1(a) a dielectric-coated plane surface with a loss tangent tan ∇ is used. Fig. 1(b) shows transceiver and transducer (inverted quarter-wavelength monopole) components stacked over the CMOS-based 2-D waveguide sheet [2]. Fig. 1(c) represents the simulated S21 (dB) over wide-band frequency on the reactive surface with diﬀerent lossy dielectric materials bility of the wireless communication channel in WiNoCs. A Figure 2: Average percentage improvement of wired-SW over mm-Wave WiNoC of varied VCs (2, 4 and 6) and buﬀer sizes (4, 6, 8, 10, 18) thin metal layer coated with Taconic RF-43 dielectric material is designed as the 2-D wireless communication medium. A low noise quarter-wave transducer is proposed as the interface between the SoC blocks and the wireless interface. HFSS results show that, the proposed transducer has a signiﬁcantly high bandwidth (45GHz - 60GHz). Cycle-accurate simulations results show signiﬁcant reductions in the average packet delay and power consumption compared to millimeter wave hybrid wired-wireless NoCs. 5. "
Mathematical Modeling and Control of Multifractal Workloads for Data-Center-on-a-Chip Optimization.,"Building autonomous data-centers-on-chip (DCoC) for exascale computing requires mathematical frameworks that account and exploit the non-stationary and multi-fractal characteristics of computation and communication workloads. Towards this end, relying on DCoC (Intel's SCC) measurements, we propose a complex dynamical modeling approach that captures the observed multi-fractal characteristics of inter-event times between successive workload changes and the magnitude of the increments in DCoC workloads. Our novel mathematical framework allows for the analysis of higher order moments and enables the formulation of more accurate model predictive control strategies for multi-fractal dynamics. We investigate the impact of the multi-fractal spectrum richness on the performance of the control algorithm. Our mathematical formalism can further be used to model, analyze and solve DCoC design problems (e.g., topology reconfiguration, buffer sizing, mapping, scheduling, resource management, congestion control).","Mathematical Modeling and Control of Multifractal Workloads for Data-Center-on-a-Chip Optimization Paul Bogdan Ming Hsieh Depar tment of Electrical Engineering University of Southern California 3740 McClintock Ave., Los Angeles, CA 90089-2562 pbogdan@usc.edu ABSTRACT Building autonomous data-centers-on-chip (DCoC) for exascale computing requires mathematical frameworks that account and exploit the non-stationary and multi-fractal characteristics of computation and communication workloads. Towards this end, relying on DCoC (Intel’s SCC) measurements, we propose a complex dynamical modeling approach that captures the observed multi-fractal characteristics of inter-event times between successive workload changes and the magnitude of the increments in DCoC workloads. Our novel mathematical framework allows for the analysis of higher order moments and enables the formulation of more accurate model predictive control strategies for multi-fractal dynamics. We investigate the impact of the multi-fractal spectrum richness on the performance of the control algorithm. Our mathematical formalism can further be used to model, analyze and solve DCoC design problems (e.g., topology reconﬁguration, buﬀer sizing, mapping, scheduling, resource management, congestion control). Categories and Subject Descriptors C.1.2 [Computer Systems Organization]: Multiprocessors; Interconnection architectures; G.1.9 [Mathematics of Computing]: Integral Equations; B.8.2 [Hardware]: Performance and Reliability; C.4 [Computer Systems Organization]: Performance of Systems; G.3 [Mathematics of Computing]: Probability and Statistics General Terms Theory, Measurement, Performance, Algorithms, Design Keywords Data center-on-a-chip, networks-on-chip, workload, complex dynamics modeling, fractional calculus, fractals, control 1. INTRODUCTION Bringing the petascale (soon exascale) computing to reality in the cloud computing era calls for designing eﬃcient data-centers-on-chip (DCoC). Moving from chips to truly system-of-systems that integrate hundreds and soon Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM ISBN 978-1-4503-3396-2/15/09 DOI: http://dx.doi.org/10.1145/2786572.2786592 ...$15.00. thousands of cores communicating via the Network-on-Chip (NoC) paradigm [16][22][24] raises numerous challenges (e.g., data movement, power consumption, memory / interconnection capacity, scaling). The DCoC performance is highly dependent on the traﬃc pattern dynamics, injection rates, routing protocols, and on-chip buﬀering resources [9][32]. Moreover, increasing the information density by mapping multiple heterogeneous big data applications onto DCoC resources leads to high contention levels and calls for designing autonomous DCoCs [13]. An autonomous DCoC should (i) monitor its resources usage, (ii) analyze and predict the computing and communication requirements, and (iii) selfoptimize its dynamics (e.g., ﬁnding the number of cores and uncore components to meet the performance bounds while minimizing energy consumption or power/ thermal proﬁles). Thus, designing such autonomous DCoC requires a comprehensive understanding of the workloads (e.g., How does workload vary with time? What are the underlying arrival/departure processes? How does the inter-arrival / departure times deﬁne the mathematical models?). Although sensors and performance counters exist on current DCoCs [24], mathematical models of DCoC workloads that can be used for performance analysis and dynamic optimization are missing. In this paper, we propose an alternative approach to Poisson modeling based on non-stationary analysis of both the core workloads and the on-chip traﬃc. We argue that, for a wide class of applications, any optimization approach should take into account the non-stationarity and multi-fractality of the computation and communication workloads since this leads to more accurate decisions (e.g., the multi-fractality of DCoC traﬃc has profound implications for dynamic power management in voltage/frequency island designs, chip temperature regulation, etc). Consequently, we describe a complex dynamics modeling approach of DCoC workloads that captures the characteristics of interevent times and magnitude of the workloads. This formalism is used to derive a model predictive control (MPC) approach for regulating DCoC dynamics as a function of the frequency. The paper is organized as follows: Section 2 reviews the prior work on workload characterization. Section 3 summarizes several fractional calculus concepts essential for our formalism. Section 4.1 describes two state-of-the-art multicorebased DCoC platforms considered in this work and main mathematical characteristics of their workloads. Sections 4.2, 4.3 and 4.4 show how the empirical mathematical characteristics can be encapsulated in a dynamical equation, analyzed in terms of higher order statistical moments and controlled via a calculus of variations approach. Finally, Section 6 points out several open problems and future directions. 2. RELATED WORK AND CONTRIBUTION The modeling of computation and communication workloads (e.g., Ethernet [30][38], Internet [37] traﬃc) has its roots in statistical physics. Performance analysis was done either via equilibrium [19][35] or non-equilibrium [41][25][6] [21][28] queueing theory; however, a detailed review of these queueing-based approaches is beyond the scope here. Over the years several non-equilibrium statistical physics inspired models (e.g., diﬀusion, kinetic theory) to performance modeling and analysis of computer networks have been proposed [44][18][14] [27][5][15]. For instance, Antoniou et al. [5] adopted the Prigogine-Herman kinetic formalism [42] to model the packet velocity distribution. Although the importance of non-stationarity is recognized, the authors focus on non-fractal dynamics (i.e., the evolution of probability densities is governed by a ﬁrst order time derivative which implies that the inter-event times are exponentially distributed). In contrast, measurement driven studies of multicore [51][9] and computer network traﬃc [30][2][38][37][50] prove the existence of self-similar, bursty and long range dependence [17] behavior. To reconcile the performance models with these characteristics (e.g., bursty, long range dependence), Norros [34] employed the fractional Brownian motion. Upon revisiting the analysis of computer network traﬃc, several researchers emphasized the multi-fractal characteristics [49] and proposed several abstract multi-fractal models [1][45]. Despite signiﬁcant contributions, none of these models were closely connected with the characteristics of workloads (e.g., non-stationarity, statistical asymmetry in the increments). Thus, our contribution is three-fold: • First, employing fractional calculus and statistical physics concepts, we show how the multi-fractal characteristics of both inter-event times between successive changes and magnitude increments of the workload can be modeled through a multi-fractal master equation (MME). An essential aspect of this complex dynamical modeling is that it accounts for the statistical asymmetry existing between the positive and negative increments of DCoC workload. The MME oﬀers a compact, yet comprehensive description of workloads and enables the quantiﬁcation of higher-order moments dynamics. • Second, using measurements of computation and communication workloads from Intel’s Single-Chip Cloud Computer (SCC) and a 64-core NoC-based multicore simulation environment, we illustrate the relationship between the workload characteristics and the mathematical concepts (e.g., multi-fractality, fractional order derivatives) captured in our MME formalism. • Third, using an extended calculus of variations approach, we discuss the design of optimal control algorithms for DCoC workloads. The goal of this optimal control algorithm is to account for the multifractal characteristics of workloads and regulate the DCoC knobs (e.g., supply and threshold voltage, operating frequency, allocated number of threads per core, thread complexity/priority) such that the predeﬁned performance levels and design constraints are met. To prove the beneﬁts of our mathematical model, we investigate its capabilities for dynamic power management and study how the degree of multifractality inﬂuences the control performance. As such, our results can further be used not only to develop new non-stationary fractal queueing models, but also to address optimization aspects of multi-fractal processes. 3. FRACTIONAL CALCULUS Unlike classical integer calculus, fractional calculus deals with integrals and derivatives of non-integer order and studies functions that are non-local (possessing memory), nonsmooth, or non-diﬀerentiable [26][47]. To better understand the non-locality accounted via fractional operators we consider a β -th times integration of a function: t(cid:82) · · · tβ−1(cid:82) t1(cid:82) a t(cid:82) (t−τ )β−1 f (τ )dτ Γ(β−1) a a a (1) f (tβ )dtβ = I β a+ f (t) = dt1 where a is the lower limit of integration. For a non-integer 0+ f (t) = (cid:82) t β , the Riemann-Liouvil le fractional integration reads: I β By using the convolution deﬁnition, we can re-write Riemann0+ f (t) = f (t) ∗ Liouville fractional order integral in (2) as I β t(β−1) /Γ(β ). Making use of the fact that the diﬀerentiation operator is the inverse of integration, we express the Riemann-Lioville fractional order derivative for 0 < β < 1 as follows: (t−τ )β−1 f (τ )dτ Γ(β ) , β > 0 (2) 0 Dβ 0+ f (t) = dβ f (t) dtβ = I 0+ f (t) = 1 Γ(1−β ) −β f (cid:48) (τ )dτ (t−τ )β (3) t(cid:82) 0 Of note, the time fractional order derivative does not violates the basic principles of physics being causal [23]. Due to the existence of various degrees of asymmetry in DCoC computation and communication workloads, we only brieﬂy review the Riesz-Feller operators. The Riesz-Feller fractional order integral proposed by Feller [20] in 1952 as a fractional calculus generalization to the integration operator initially deﬁned by Riesz [46] is deﬁned as follows: x I α θ f (x) = 1 Γ(α) (x − ξ )α−1 f (ξ )dξ+ sin + 1 Γ(α) sin(απ) (ξ − x)α−1 f (ξ )dξ (4) x(cid:82) −∞ (cid:105) sin (cid:104) (α+θ)π 2 (cid:104) (α−θ)π 2 sin(απ) (cid:105) ∞(cid:82) x (cid:104) (α+θ)π (cid:104) (α−θ)π 2 2 (cid:105) x(cid:82) (cid:105) ∞(cid:82) sin −∞ x where 0 < α < 2 [47]. Similarly, the Riesz-Feller fractional order derivative can be deﬁned as follows: xDα θ f (x) = Γ(1+α) π + Γ(α) π sin f (x−ξ)−f (x) (x−ξ)α+1 dξ+ (ξ−x)α+1 dξ f (ξ) (5) where α is the fractional order of the derivative and θ is the skewness parameter. From equation (5), one can clearly see that we can use this operator to characterize asymmetry in the positive and negative changes in the magnitude of a stochastic process by using diﬀerent α power law exponents and θ skewness parameter (see Fig. 2). Over the years, fractional calculus has found applications in physics (e.g., modeling fractal processes [31][39][43]) and engineering (e.g., control [36][4][40]), signal processing [1][11]) disciplines. In contrast, we propose a fractional calculus approach to time-dependent queueing modeling for capturing the non-stationarity and multi-fractality of workloads. Figure 1: a) Cache read misses for cores 20, 30 and 35 on the Intel SCC running a multi-threaded large-scale atomic/molecular massively parallel simulation. b) Multifractal spectrum of cache read misses for cores 20, 30 and 35. c) Cache write misses for cores 1, 5 and 20 on SCC running the lammps multi-threaded benchmark. d) Multifractal spectrum of the cache write misses time series from cores 1, 5, 15, 20, 24, 30, 32 and 47. 4. MODELING OF DCOC WORKLOADS 4.1 Mathematical Characteristics of Workloads We begin by emphasizing the characteristics of computation (e.g., CPU utilization/usage) and communication (e.g., cache read misses, cache write misses, memory access reads, memory access writes) processes in NoC-based DCoCs. Generally speaking, there are two main characteristics: • Non-stationarity: A stochastic process displays a non-stationary behavior if its probability distribution and implicitly its higher order moments (e.g., mean, variance, skewness) vary with time (or shifts in time). • Mono- and multi-fractal behavior: A stochastic process displays a mono-fractal behavior if its statistical realization displays a self-similar1 behavior and is characterized by a single fractal dimension2 . A stochastic process is multi-fractal if it is characterized by a range of fractal dimensions over various scales. Unlike mono-fractal ob jects which are characterized by one fractal dimension, the multi-fractal ob jects are characterized by a distribution of Holder exponents which describe the scaling and singularity properties of a stochastic path at any point in time. To make the discussion more concrete, we consider timed traces of various processes from two computing platforms: • Intel SCC [24]: The SCC is an DCoC research platform consisting of 48 IA-32 (x86-32) cores (organized into 24 tiles, 2 cores per tile) interconnected in a 4 × 6 mesh NoC and connected to the main memory via 4 DDR3 memory controllers. Each core runs its own Linux OS and the inter-core communication is realized via a message passing scheme. The SCC workloads are obtained by running SPEC MPI2007 benchmark [48]. • 64-core cache coherent NoC: We consider a full system simulation of a 64-core NoC via Simics with GEMS [33] and Garnet [3] for timing of memory system and on-chip network and running PARSEC [8] benchmark. It uses directory based MOESI CMP cache 1Self-similarity deﬁnes the property of geometric ob jects or time series to look the same under the magniﬁcation at various scales in space or time [31]. 2The fractal dimension quantiﬁes the complexity of fractal ob jects/sets and is deﬁned as the ratio between the logarithm of the number of self-similar pieces and the logarithm of the magniﬁcation factor (or piece size). coherent protocol for shared memory mechanism of communication between cores. Figure 1.a shows the cache read misses of cores 20, 30 and 35 of the Intel SCC. These core IDs were selected from 35 cores running a multi-threaded large scale atomic/molecular massively parallel simulation (lammps) benchmark. One can see that cores get exercised diﬀerently over time which implies the existence of a non-stationary and self-similar behavior. To verify the existence of fractal behavior, Figure 1.b shows the multi-fractal spectrum of the cache read misses time series obtained from the three SCC cores. One can observe that all three cores exhibit a wide range of fractal dimensions and so their mathematical characterization needs to take this multi-fractal behavior into account. We also analyzed the cache write misses. Figure 1.c shows the cache write misses of Intel SCC cores 1, 5 and 20. One can notice that all three cores exhibit a diﬀerent behavior. Core 1 displays fewer spikes that are larger in magnitude than core 20. In contrast, core 5 displays numerous slightly smaller spikes than those of core 1. To investigate the self-similar behavior, we estimated the multi-fractal spectrum (see Figure 1.d) from the cache write misses of cores 1, 5, 15, 20, 24, 30, 32 and 47. Similar multi-fractal behavior was observed for workloads obtained on the SCC running the SPEC MPI2007 benchmark or the 64-core NoC running PARSEC benchmark, but due to space constraints are not summarized. Consequently, we focus on encapsulating the exhibited multi-fractal and nonstationary features into a multifractional order derivative based master equation which has not been addressed in modeling workloads in parallel computing. Our mathematical formalism is general and applicable to modeling multi-fractal stochastic processes. 4.2 Multifractal Master Equation In subsection 4.1, we showed that workloads exhibit nonstationary and multi-fractal behavior. Thus, we adopt a statistical physics approach to modeling DCoC workloads probability density function (PDF) P (x, t|α, β ) which indiand build a master equation describing the evolution of the cates that the stochastic process x(t) attains value x at time t. The stochastic process x(t) denotes an DCoC workload. Our aim is to capture the characteristics of workloads: First, by analyzing the time series of inter-event times between successive changes in the magnitude of process x(t) and ﬁnding whether it exhibits a fractal behavior, we model its dynamics via a time fractional β -order derivative. Note Figure 2: a) The positive (top) and absolute value of negative (bottom) increments in the cache write misses for core 1 of Intel SCC running lammps multi-threaded benchmark. As one can notice, the two time series display an almost identical behavior implying a zero skewness. b) The probability that the positive increments in cache write misses at core 1 exceed a certain threshold is best ﬁtted by an α-stable distribution. c) The probability that the absolute value of negative increments in cache write misses at core 1 exceed a threshold is best ﬁtted by an α-stable distribution. Similar behavior that is better ﬁtted by α-stable distribution has been also observed for other workloads obtained from Intel SCC by running SPEC MPI2007 benchmark such as the memory access write time series when running the MIMD lattice computation (milc) benchmark. that we consider a conditional PDF P (x, t|α, β ), where β represents a random variable to account for the case when x(t) dynamics is characterized by multiple fractal exponents. Second, we analyze the exceedance probabilities of observing increments in the magnitude of process x(t) larger than a threshold and study whether these probabilities exhibit a power law behavior. When consecutive increments in the stochastic process x(t) exhibit a correlated behavior, the mathematical description of the evolution of PDF P (x, t|α, β ) can be expressed via a spatial fractional α-order derivative. P (x, t|α, β ) through a generalized master equation: Towards this end, we describe the evolution of the PDF P (x, t|α, β ) = P (x0 , 0) + I+ (x − ξ , t − τ )× (6) x(cid:82) t(cid:82) dτ 0 −∞ t(cid:82) ∞(cid:82) which allows for incorporating the memory of both interevent times and magnitude increments of the process x(t). To make the mathematical description more intuitive, Figure 2.a shows the realization of positive (top) and negative (bottom)3 increments of the cache write misses from core 1 of Intel SCC running the lammps multi-threaded benchmark. One can observe that the positive and negative increments exhibit not only an approximate symmetric behavior, 4 , but also a highly variable, non-smooth, and fractal. To study the existence of fractal behavior in the successive series of positive and/or negative increments in the magnitude of stochastic process x(t) and to probe the adequacy of modeling this spatial variation via a Riesz-Feller fractional order derivative, Figures 2.b and 2.c show the empirical probabilities that the positive (blue) and the absolute value of negative (red) increments exceed a certain threshold. In addition, we also show the best maximum likelihood ﬁt for these empirical probabilities in Figures 2.b and 2.c. By carefully analyzing these two plots, one can conclude that the PDF of both positive and negative increments can be well approximated by α-stable distribution with the next parameters: α = 1.5, β = 1, δ = 1250, γ = 3500. More importantly, we can also conclude that both the positive and negative increments display a power law behavior. Of note, a similar asymmetric dynamics in the positive and negative increments of workloads that are ﬁtted by αstable distributions with diﬀerent parameters has been observed for other workloads collected from either Intel SCC 3Note that, for simplicity, we choose to plot the absolute value of the negative increments obtained from the consecutive realizations of stochastic process x(t). In order to keep a symmetric connection with the analysis of positive increments, we will analyze the probability that the absolute value of negative increments exceed a certain threshold. Nevertheless, a similar strategy can also be applied solely for the negative increments. 4By approximate symmetric behavior we mean that large positive increments are almost preceded / followed by large negative increments. Nevertheless, the mathematical formalism we present is able to capture both symmetric and symmetric behavior via the skewness parameter. 0 x P (ξ , τ |α, β )dξ + I− (x − ξ , t − τ )P (ξ , τ |α, β )dξdτ where P (x0 , 0) denotes the (initial condition) probability that x(t) was initiated at time t = 0 and had magnitude x0 (i.e., P (x0 , 0) = δ(x−x0 )δ(t−0), δ(x) is the Dirac delta function), α is the scaling exponent characterizing the tra jectories of increments observed in the magnitudes of stochastic process x(t), β is a scaling exponent characterizing the trajectories of inter-event times between changes in the magnitudes of process x(t), I+ (x − ξ , t − τ ) and I− (x − ξ , t − τ ) are kernels showing that the evolution of P (x, t|α, β ) depends on both positive (see the top part of Fig. 2.a) and negative (see the bottom part of Fig. 2.a) increments that occurred at previous times. By integrating from 0 until time t, the master equation captures the non-Markovian behavior induced by interactions between the hardware (e.g., network topology, protocol stack), operating system (e.g., memory reading/writing libraries), and applications (e.g., data and instruction task/thread dependencies). Master equation (6) can also be written as follows: T+ (x − ξ )[P (ξ , t|α, β )− W (t − τ ) ∂P (x,τ |α,β ) ∂ τ x(cid:82) t(cid:82) dτ = −∞ 0 P (x, t|α, β )]dξ + T− (x − ξ )[P (ξ , t|α, β ) − P (x, t|α, β )]dξ ∞(cid:82) x Figure 3: a) Probability of inter-event times to exceed a certain threshold obtained from the cache read misses time series at core 1 on the SCC running the lammps multi-threaded benchmark. The inter-event times represent the intervals of time until the cache read misses at core 1 are within the (200050,200900) interval. b) Probability of inter-event times to exceed a certain threshold obtained from the memory access reads time series at core 1 on the SCC running the lammps multi-threaded benchmark. The inter-event times represent the intervals of time until the memory access reads at core 1 are within the (11020000,11020100) interval. c) Probability of inter-event times to exceed a certain threshold obtained from the cache write misses time series at core 16 on the SCC running the lammps multi-threaded benchmark. The inter-event times represent the intervals of time until the cache write misses are within the (43200,43300) interval. running SPEC MPI2007 benchmark or 64-core NoC cache coherent platform running the PARSEC benchmark. One can associate the fact that α-stable distribution ﬁts well the workload data with the existence of multi-fractal characteristics/behavior which can be either due to intrinsic dependencies existing in the application or due to contentions for network/memory resources, routing arbitration, OS mapping / scheduling schemes, etc. As shown in Figure 3, a similar power law behavior can also be observed in the inter-event times of various DCoC workloads. Figure 3.a shows that the intervals of time between consecutive moments at which the cache read misses processes to a certain queue. However, in order to keep the discussion simple, we will not make this distinction. Asymmetric evolution θ (cid:54)= 0 : Substituting the power law relations in equations (7), (8), and (9), multiplying the relation in (7) with g(α)h(β ) and integrating over the set of fractal dimensions α and β characterizing the changes of both the magnitude increments of the stochastic process x(t) and the time increments τ leads to the following multifractional space-time Fokker-Planck type of equation: h(β ) ∂β P (x,t) ∂ tβ dβ = dα g(α){c+ − dr +c ∂α P (x,t) ∂ (−x)α + c+ dif ∂ 2α P (x,t) ∂x2α + c − dif ∂α P (x,t) ∂xα + dr ∂ (−x)2α } ∂ 2α P (x,t) (10) βmax(cid:82) βmin αmax(cid:82) αmin − − dif = c Symmetric evolution θ = 0 : Substituting the power law relations in equations (7), (8), and (9), assuming that c+ dr = c dr = cdr and c+ dif = cdif , multiplying equation (7) with g(α)h(β ) and integrating over the set of fractal dimensions α and β characterizing the changes of both magnitude increments of process x(t) and time increments τ leads to the following multi-fractional Fokker-Planck equation: ∂ |x|2α }dα (11) h(β ) ∂β P ∂ tβ dβ = Of note, when h(β ) = δ(β − 1) and g(α) = δ(α − 1), (11) reduces to a classical diﬀusion equation and can be related to the diﬀusion-based queueing models [44][18][14][27][29][15][10]. αmax(cid:82) αmin βmax(cid:82) βmin ∂α P ∂ |x|α + cdif g(α){cdr ∂ 2α P 4.3 Higher Order Statistical Moments (cid:68)|x|k (cid:69) Next, we characterize the evolution of DCoC workloads by analyzing the time dependence of the statistical moments associated with stochastic process x(t) deﬁned as follows: −∞ |x|k P (x, t)dx where k is the order of the statistical moments. By multiplying both sides of (11) with |x|k , integrating over the x-magnitude space, and using the integration by parts formula, the k-th order moment of x(t) can be expressed as: = (cid:82) ∞ mk = (12) βmax(cid:82) βmin αmax(cid:82) αmin + αmax(cid:82) αmin h(β ) ∂β mk ∂ tβ dβ = cdr g(α) Γ(k+1)mk−α Γ(k+1−α) dα cdif g(α) Γ(k+1) Γ(k+1−2α) mk−2α dα (13) Equation (13) represents the dynamics of k-th order moment of a multi-fractal process as a function of the scaling exponents α and β . Nevertheless, relying on such dynamical recurrence relationship allows to develop rich optimal control strategies with applications to power / thermal management of DCoCs and this will be described in the next section. 4.4 Optimal Control of DCoC Workloads Next, we introduce a constrained ﬁnite horizon multifractal optimal control problem - given a start ti and a ﬁnal tf time, the goal of the controller is to ﬁnd signal u(t) which minimizes the squared time-dependent error between the kth order moment mk (e.g., CPU utilization) and a desired (cid:2)mk (t) − mk ref (t)(cid:3)2 reference mk ref , as well as control eﬀort u2 (t): + q 2 u2 (t) (cid:110) w minu(t) dt s.t (cid:111) 2 tf(cid:82) ti αmax(cid:82) αmin dβ = cdr g(α) Γ(k+1)mk−α (t) Γ(k+1−α) dα+ βmax(cid:82) βmin h(β ) ∂β mk (t) ∂ tβ αmax(cid:82) αmin ∂ tf ∂H max (cid:16) = 0 (15) (14) ∂H ∂mk ti Dβ (cid:48) ∂H ∂mk−2α ∂H t mk (t) cdif g(α) Γ(k+1) βmax(cid:82) βmin βmax(cid:82) βmin + Γ(k+1−2α) mk−2α (t)dα + bu(t) mj min ≤ mj (t) ≤ mj j = {k − 2α, k − α, k} umin ≤ u(t) ≤ umax t ∈ [ti , tf ] where w and q are positive weighting coeﬃcients, mj min and max are the lower and upper bounds on the (k − 2α)-th, mj (k − α)-th, and k-th order moments, umin and umax are the lower and upper bounds on the control signal, and b is a proportionality coeﬃcient for the eﬀect of the control signal u(t) on the dynamics of k-th moment mk (t). Using calculus of variations concepts, the optimality conditions for the above multi-fractional optimal control problem can be written as follows: (cid:17) dβ (cid:48) dβ = 0 h(β (cid:48) ) ∂H ∂mk−α h(β ) ∂β mk (t) ∂ tβ + h(β )tDβ where H (t, mk , u, (cid:82) βmax ∂u = 0 H (t, mk , u, = 0 (16) (cid:2)mk (t) − mk ref (t)(cid:3)2 dβ ) is given by: dβ ) = w dβ − αmax(cid:82) mk−α (t)dα − αmax(cid:82) 2 + λ(t)[ A(k , α)· B (k , α)mk−2α (t)dα − bu(t)]+ (17) +γ1 (t)[mk (t) − mmin ] + γ2 (t)[mmax k − mk (t)] +γ3 (t)[mk−α (t) − mmin k−α − mk−α (t)] k−α ] + γ4 (t)[mmax +γ5 (t)[mk−2α (t) − mmin k−2α − mk−2α (t)] k−2α ] + γ6 (t)[mmax +γ7 (t)[u(t) − umin ] + γ8 (t)[umax − u(t)] with λ and γl , for l = 1 : 8 being the Lagrangian multipliers associated with the constraints on both moments and control variable, A(k , α) = cdr g(α)Γ(k + 1)/Γ(k + 1 − α) and B (k , α) = cdif g(α)Γ(k + 1)/Γ(k + 1 − 2α). Thus, the multi-fractal optimal control problem reduces to discretizing the optimality conditions in (16) and solving them via mathematical programming techniques. βmin βmax(cid:82) βmin βmax(cid:82) βmin h(β ) ∂β mk (t) ∂ tβ h(β ) ∂β mk (t) ∂ tβ + qu2 (t) αmin αmin k 2 5. EXPERIMENTAL SETUP AND RESULTS Impact of multifractality on control eﬀort: To study the eﬀect of the wideness of multi-fractal spectrum, we consider the two multi-fractal spectrums corresponding to two DCoC workloads shown in Figure 4.a. We assume that the dynamics of the k-th moment in equation (19) is only affected by the multi-fractal spectrum h(β ) (also shown in Figure 4.a) and the control signal u(t) weighed by the following coeﬃcient b = 1. The initial and ﬁnal conditions were set as follows: mk (ti ) = 1 and mk (tf ) = 0.1, respectively. To solve the multi-fractal control problem, we discretize the (cid:80)[ t optimality conditions via the Grunwald-Letnikov formula t m (t) ≈ 1 j=0 (−1)j m (t − j∆t) (cid:18)α (cid:19) 0Dβ (18) ∆t ] j ∆t where ∆t is a small interval, j = Γ(α)/ [Γ(j )Γ(α − j + 1)], (cid:18)α (cid:19) 6. CONCLUSIONS In this paper, we describe new mathematical models for performance analysis and dynamic optimization of DCoC from measured data. The nonstationarity and multifractality of DCoC workloads are captured into a master equation. Relying on this new multi-fractal modeling and using concepts from the calculus of variations, we derive the optimality conditions for constructing dynamic optimization strategies. We show that, contrary to conventional wisdom, the control of multi-fractal dynamics is possible via linear programming and that there is a trade-oﬀ between the control eﬀort and the required control frequency as a function of Holder exponents. Ignoring the non-stationarity and multi-fractality of DCoCs, may not only lead to poor performance estimates, but can also make the dynamic optimization harder. As outlined in this paper, relying on online algorithms for estimating the fractal characteristics of DCoC workloads and exploiting the inherent sparsity that may appear in DCoCs at run-time, one can design infrequent dynamic optimization schemes to adjust parts of the entire system instead of controlling them all at once. The presented mathematical framework for modeling DCoC workloads and deriving optimal control algorithms is applicable to more general settings (e.g., sensor networks, smart power grids, large-scale operational systems). Our future work will focus on identifying precisely the trade-oﬀ between the control eﬀort and the frequency of control invocations as a function of the degree of multifractality. 7. ACKNOWLEDGMENTS We thank to anonymous reviewers for their valuable feedback. This research was supported by NSF 1453860 and 1331610 grants, and University of Southern California. Special thanks to Y. Xue for help with some experiments. 8. "
NoC Architectures as Enablers of Biological Discovery for Personalized and Precision Medicine.,"This paper overviews the main computational issues in personalized and precision medicine (PPM), and present a cogent case for network-on-chip (NoC)-based multicore platforms as enablers in the process. We identify a series of challenges for the design and optimization of NoC-based solutions for PPM. To capture the characteristics of the cyber-physical sensing and processing, we propose a new computational model built on a dynamical heterogeneous hyper-graph description of application-to-architecture interactions. Starting from these premises, we summarize a few implications on NoC design methodologies, present some NoC-based solutions that deal with some of the challenges, and outline a few open problems.","NoC Architectures as Enablers of Biological Discovery for  Personalized and Precision Medicine Paul Bogdan  Department of Electrical  Engineering University of  Southern California  Los Angeles, CA 900892560  pbogdan@usc.edu   Turbo Majumder  Department of Electrical  Engineering   Indian Institute of  Technology Delhi  New Delhi 110016, India  turbo@ee.iitd.ac.in  Arvind Ramanathan  Oak Ridge National  Laboratory,   One Bethel Valley Road,  MS 6085, Bldg 5700  Oak Ridge, TN 37830  ramanathana@ornl.gov  Yuankun Xue   Department of Electrical  Engineering University of  Southern California  Los Angeles, CA 900892560  yuankunx@usc.edu ABSTRACT  This paper overviews  the main computational  issues  in  personalized and precision medicine (PPM), and present a cogent  case for network-on-chip (NoC)-based multicore platforms as  enablers in the process. We identify a series of challenges for the  design and optimization of NoC-based solutions for PPM. To  capture the characteristics of the cyber-physical sensing and  processing, we propose a new computational model built on a  dynamical heterogeneous hyper-graph description of applicationto-architecture interactions. Starting from these premises, we  summarize a few implications on NoC design methodologies,  present some NoC-based solutions that deal with some of the  challenges, and outline a few open problems.    Categories and Subject Descriptors  C.1.2 [Computer Systems Organization]: Multiprocessors;  Interconnection architectures;  General Terms  Design, Algorithms, Theory, Performance.  Keywords  Networks-on-chip, data-centers-on-chip, exascale computing,  computational intensive tasks, data-centric computing systems,  heterogeneity, power efficiency,  reliability, cyber-physical  systems, big data, personalized medicine, precision medicine.  1.  INTRODUCTION  The reductionism paradigm that governed science over the last  century has contributed not only to the identification of the basic  components of matter, but also to the quest for understanding the  multi-scale spatio-temporal interactions that are fundamental to  the complex yet robust dynamics of biological processes. Simply  speaking, genes, proteins and metabolic agents interact to either  sustain healthy behavior from cellular to organ to organism level,  or to trigger malfunctions with a possible domino effect that  results in a life-threatening infection or disease. Consequently, it  Permission to make digital or hard copies of all or par t of this work for  personal or classroom use is granted without fee provided that copies  are not made or distributed for prof it or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherw ise, to republish, to post on servers or to redistribute to lists,  requires prior specif ic permission and/or a fee. Request permissions  from Permissions@acm.org   NOCS '15, September 28 - 30, 2015, Vancouver, BC, Canada    © 2015 ACM. ISBN 978-1-4503-3396-2/15/0…$15.00    DOI: http://dx.doi.org/10.1145/2786572.2788706   is urgent to harness these technological advances (e.g., high  throughput sequencing of genomes and transcriptomes, high  resolution mass spectrometry for proteomic and metabolomic  analysis) not only for the acquisition of vast comprehensive multiomic data, but also for mining these data and analyzing the  complex interconnected dynamics of biological systems.   The cyber-physical systems (CPS) paradigm [35, 28, 37] sets  forth a transformative approach that tightly integrates the sensing  of physical world (e.g., genomic, proteomic, metabolic and  physiological processes) with computational processes (e.g.,  filtering, mining, decision making) for the purpose of realizing a  closed-loop control. Nevertheless, the real-time accumulation,  processing and analysis of the large amounts of cross-device  heterogeneous data raise numerous challenges. The increasingly  large, non-localized and multi-dimensional data makes it energy  and cost prohibitive to monitor physical processes and transmit  the collected data to supercomputing centers over geographically  large Internet. Simply speaking, the processing of these large and  heterogeneous data sets face the challenges of memory capacity,  data transmission, interconnection bandwidth, latency bound,  power consumption and scaling when considering  future  developments and requirements. In addition, besides the classical  high performance floating point computation,  there  is an  increasing need for efficient highly parallel architectures that can  support memory- and integer-intensive operations.      To overcome these challenges, we advocate for the need of  designing highly  efficient data-centers-on-a-chip  (DCoC)  architectures [30, 31] that exploit the network-on-chip (NoC)  paradigm  [38, 39]  for  interconnecting  large number of  heterogeneous processing elements (PEs). However, the design  methodologies for NoC-based multicore platforms proposed to  date suffer from a number of drawbacks: (i) Many of these design  methodologies relied on simplified computational models that are  inadequate for capturing the complexity of application in the CPS  domain. For instance, the current application / computational  models consider static deterministic graph representations of  interacting patterns among computational modules / tasks. This is  clearly not the case for CPS where the nature and volume of  computations vary over time, which further influences the  communication pattern and load. (ii) Most of the proposed design  methodologies are not scalable to large dimensions or can deal  with the multi-modality and heterogeneity of CPS domain. Simply  speaking, current algorithmic solutions cannot deal with dynamic  mapping, scheduling and routing on thousand core platforms. (iii)  Scalable algorithmic solutions (e.g., power / thermal / reliability  management) that can enforce and confer adaptation in DCoC  architectures are missing. Moreover, there is an urgent need for  self-reconfiguration approaches of PEs within the DCoCs to adapt        to the incoming CPS workloads for meeting the real time  performance requirements and improving energy efficiency.       Towards this end, in this paper, we call for a restructuring and  rethinking of the design methodologies of the envisioned DCoC  platforms as the distributed brains of the CPS architecture. One  fundamental requirement of this new design methodology is that it  needs to balance the data centric memory access / availability with  classical computation speed. Another fundamental requirement  for this new era of supercomputing is that the DCoC platforms  should be able to self-monitor, quantify the uncertainty associated  with its own dynamics, predict possible system trajectories and  take decisions at run-time for preventing performance loss, high  energy consumption or system failure. This calls for design  methodologies that build on accurate mathematical models of the  DCoC workload dynamics and exploit new  theoretical  developments for taking fast decisions in a distributed selforganizing fashion. Last but not least, the DCoC platforms have to  deal with both computationally intensive tasks and the datacentric computation efficiently.   The remainder of this paper is organized as follows: Section 2  reviews  the challenges we  face on mathematical and  computational modeling for making the PPM a reality. Section 3  integrates the algorithmic implications concerning genomics,  proteomics and cellular processes and translates them into  concrete challenges for designing NoC-based DCoC architectures.  Sections 4 and 5 review some progress on NoC-based multicore  platforms for genomics and proteomics respectively, and outlines  some open problems. Finally, Section 6 concludes the paper.   2.  CHALLENGES IN PERSONALIZED  AND PRECISION MEDICINE  Personalized and precision medicine (PPM) refers to a novel  paradigm of healthcare that aims to be predictive, personalized,  preventative and participatory by using “information from  genomes (humans and other organisms) and their derivatives  (such as proteins and metabolites) to guide medical decisionmaking” [12, 14, 21]. A central goal of PPM is to enhance the  genetic information obtained at a personalized level to predict  specific phenotypic response, typically captured by the inherent  molecular structure and interactions, mechanistic details and  therapeutic cogency  that can enable  the classification of  individuals into subpopulations based on their differences (and  similarities) [14]. Anecdotal success of precision medicine has  already been demonstrated for rare disorders and for common  diseases such as cancer [23]. Nevertheless, our ability to make  precision medicine a practical success for diseases such as  diabetes (and other metabolic diseases), neurological and  cardiovascular disorders remain a distant dream.   PPM has been largely driven by the success in developing highthroughput, next-generation sequencing (NGS) technologies [15,  33]. These NGS technologies, combined with advances in novel  proteomics techniques is enabling scientists to understand both  normal and disease states within patients. The emergence of  systems biology as a discipline to rationally understand and  perturb molecular interactions (between proteins, proteins and  DNA, and more generally between biomolecules and drugs)  within specific cells is resulting in novel ways to probe cellular  function. However, a central challenge in implementing PPM (at  scale) is the difficulty in storing, retrieving, integrating, analyzing  and visualizing  large-scale datasets emerging from NGS,  proteomics and systems biology experiments [21].   In this context, we highlight some of the PPM challenges. Most of  the problems highlighted share commonalities with emerging  hardware/software architectures for Big Data analytics [10]. This  is mainly because many of the problems within PPM involve  clustering, classification/regression and dimensionality reduction  with large-scale biological datasets. However, we make it a point  to distinguish how these challenges impact biological discovery  and its implications for clinical decision-making.   2.1. Challenges in Analyzing NGS Data  Even the most fundamental tasks in analyzing NGS datasets are  highly complex, multistep processes. Once the sequencing process  is complete, the immediate need for the biologist is to quickly  assemble the genome – i.e., compute the most probable order in  which the sequences were produced from the original sample.  This process is referred to as assembly. Assembling a complete  human genome and aligning it with respect to a reference genome  can take up to 4 hours (on a highly optimized system with 128  Gbyte memory and 2 CPUs) [34]. Thus, comparing even 1,000  genomes (e.g., the 1,000 Genomes Project [36]) can take a long  time for cross comparisons and clustering/ identifying subpopulations. Added to this complexity is the fact that many of the  current software pipelines to process NGS data are written to  exploit the cloud computing paradigm, where data and compute  resources can be distributed across wide geographic regions. This  can often result in fragmented datasets and therefore make data  integration more challenging for downstream processes.  More specifically, underexplored algorithmic structures and their  ignored architectural implications in current software tool chains  heavily curtail the performance returns of traditional computing in  relation to the massive power and infrastructure investment. The  bounding factors are largely derived from limited degree of finegrain parallelism and frequent fetching of large volumes of preanalysis data (e.g., the uncompressed individual data size of  sequenced whole human genome is greater than 100 Gbytes) and  intermediate results, which are either highly fragmented in local  memories or distributed over a wide geography, particularly on  super- or cloud-computing platforms. The resultant immense  traffic requirements through wide area networks easily render the  computation-intensive  genomics  analysis  tasks  into  communication-intensive ones,  thus bottlenecking possible  performance returns. In contrast, NoC-based platforms could  efficiently provide data migration channels of ultra-high  bandwidth required for carrying out integrated fetch and analysis  on  fragmented datasets, effectively supporting distributed  computing on-a-chip or data-center-on-a-chip [31]. NoC supports  large-scale integration of PEs, and allows for investigating the  design  space  for  exploitation of massive parallelism.  Communication through on-chip links experiences much lower  parasitic delay and consumes much lower energy than off-chip  buses and switches in clusters or supercomputers, leading to  shortened response time and lower power consumption.   One of the most frequently encountered among NGS applications,  sequence alignment can be done either pairwise or across multiple  sequences at the same time. Pairwise sequence alignment can be  solved efficiently using dynamic programming approaches and  has recently been implemented using conventional hardware  accelerators such as graphics programming units (GPUs) and  FPGAs, as well as NoC-based multicores (whose advantages we  discuss shortly). Aligning multiple sequences is known to be NPhard; however, efficient heuristics such as Clustal Omega [17] can  be attractive for hardware acceleration. Algorithms for aligning  sequences from NGS experiments can be broadly divided into the      following categories: (a) algorithms that construct auxiliary data  structures such as hash tables (e.g., Bfast, Mosaik, etc.), (b)  algorithms that build suffix trees (e.g., Bowtie, BWA, etc.), and  (c) algorithms that make use of merge sort (e.g., Slider) [25, 54,  19, 22, 26].   Once the genome has been assembled, the next step is to detect  where changes (or variants) in the genetic sequence occur.  Changes in the individual genome can be broadly classified as  single nucleotide polymorphisms (SNPs), insertions/ deletions  (indels) and copy number variations (CNVs) within a person’s  individual genome and are key indicators of disease-specific  genotypes. Given the importance of this step, NGS workflows  make use of a number of sensitive and specific statistical models  to perform variant calling [1]. These algorithms have been  implemented using cloud-computing platforms; however, face  increasing challenges as a consequence of longer reads (in NGS  platforms) and susceptibility to noise.   One of the most common operations on the assembled genome is  the query “what common substrings occur within the given  genome sequence?” This process of identifying short substrings,  called motifs, has wide ranging implications for detecting how  genes are regulated via cis-regulatory networks and identifying  protein/DNA binding sites.   Further down the NGS data processing pipeline, biologists  construct phylogenetic trees. These structures provide quantitative  means to infer a probable sequence of events involved in the  evolution of a species or a taxonomic group of organisms. This  assumes significance in the cases where there exists a multitude of  analyzable species, and their gene composition is subject to rapid  mutations over time, typically for pathogenic bacteria and viruses.  In such cases, carrying out upstream NGS analyses for each  individual genome leads to an unacceptable overhead. For  example, the analysis of over 28 million metagenomic sequences  took months to complete after parallelization at the coarse level  using a combination of 2,300 processors and high-end memory  systems [42]. Hence, there is a need for phylogenetic inference in  order to identify real or hypothetical ancestral “species”, which  form the basis for further analysis and modeling, e.g. drug  development. While this presents an application of immediate  pharmacological  interest,  inferring ancestral  species and  identifying points of divergence in the evolutionary tree is a longterm research goal that aids research and development in medicine  with particular focus on individuals and demographics, and the  role their genomic constitution and phenotype plays in their  susceptibility to certain exogenous and endogenous diseases, and  formulation of treatment following the principles of PPM.  Phylogenetic inference algorithms make use of distance-based,  maximum parsimony (MP), maximum likelihood (ML) and/or  Bayesian techniques. Most inference algorithms typically utilize a  distance-based or MP algorithm to create a plethora of “bootstrap”  trees, which provide the search space for further optimization  using statistical techniques (ML or Bayesian). Most of the  statistical techniques support one or more probabilistic models of  evolution. These models could be as simple as Jukes-Cantor or as  complex as General Time Reversible, in which rate variation  among multiple sites in the genome is supported. These problems  are challenging not only due to significant volumes of input data  generated from upstream NGS processes, but also due to the  computational complexity of  the underlying search and  optimization algorithms. Most phylogenetic inference methods  (MP, ML, Bayesian) rely on algorithms that are inherently NPhard, and are beset with exorbitant runtimes even with the use of  runtime heuristics that attempt to curtail the search space. For  example, one of the most widely used programs to compute MLbased phylogeny has been shown to take up to 2.25 million CPU  hours on an input comprising of 1,500 genes [24]. Hence,  algorithm- or software-level optimization, while still important,  leads to diminishing returns for these applications insofar as  tackling runtime resource consumption is concerned. NoC-based  platforms have been shown to not only tackle the runtime issue,  but also carry out these tasks in an extremely energy-efficient  manner compared to traditional parallel computing clusters, and  other popular hardware acceleration platforms, such as GPUs.  A consequence of NGS technology is that it is not only possible to  extract and analyze just a single sample of DNA, but also obtain  associated (and often partial) genomes of the entire microbiome of  the organism being studied. These genomes represent an  integrated picture of the complex interactions between the host  (e.g., human) and a wide range of species (e.g., bacteria, viruses)  that symbiotically live within a variety of organs / tissues. Usually  referred to as the microbiome [55], these species play an  important role in PPM, as subtle changes to the microbiome can  result in dysfunction of a tissue / organ and lead to debilitating  disease conditions. Thus, apart from extracting and analyzing the  host DNA, often it becomes critical to evaluate what types of  species (or taxa) inhabit the microbiome and evaluate how these  interactions affect the host’s health. Metagenomic analysis  involves mining for signatures from a sequence of paired-end  reads generated from fragmenting the genomic DNA into short  (<300 base pair) segments and sequencing both ends of the  segments [52]. Algorithms for metagenomic analyses are time  consuming and can benefit from NoC-based acceleration.  Each of the aforementioned computational problems would  benefit from tightly integrated hardware/software solutions that  can cater to the requirements of the high-throughout NGS data. In  particular, distributed computing platforms such as cloud  computing suffer from fragmentation of intermediate results,  which significantly impact the overall time-to-solution, mostly  because of the increased efforts they require to re-assemble these  fragmented datasets or partial solutions. On the other hand,  conventional hardware acceleration platforms (e.g., GPUs, Cell  Broadband Engines (CBE), FPGAs with embedded DSPs) and  high-performance computing resources are burdened with intense  computational and memory workloads, at the cost of greater  power consumption. NoCs can support and sustain greater  integration bandwidth and overcome the problems posed by  fragmentation of  intermediate results, while simultaneously  requiring lower power budgets. NoC-based solutions can be better  integrated within future NGS platforms and provide an attractive  solution for many of the NGS data analytics requirements.   2.2. Challenges in Modeling Cellular and  Biological Systems   Beyond analyzing NGS datasets for PPM, it is necessary to  understand  the molecular underpinnings of how genomic  variations observed within a patient sub-population translate to  disease-related phenotypes. It is also necessary to quantify which  groups of patients will respond to particular therapeutics or more  importantly predict which groups of patients may have adverse  effects to therapeutics. Dealing with the complex interconnected  dynamics of biological systems poses numerous challenges on  computational modeling and analysis, calling for transformative  approaches to software and hardware platforms. We highlight      some of the emerging challenges and how NoC architectures can  enable novel discoveries in this area.   2.2.1. Protein Folding and Drug-Discovery   Although special purpose architectures such as Anton [11],  distributed computing platforms such as Folding@home [18] and  crowd-sourcing platforms such as FoldIt [40] have been  successful in folding small proteins, there are many challenges  when it comes to understanding the biophysical processes that  control correct folding of long polypeptide chains. In particular,  many proteins are known to exist in a disordered state where by  they acquire context-sensitive structure upon binding to their  respective partners. Some of these proteins are extremely large  (having more than 1000 amino-acid residues in their polypeptide  chains) and are biologically extremely important for cell survival.  In fact, mutations in these proteins can lead to a variety of  disorders such as diabetes, cardio-vascular and neurodegenerative  diseases.   Another  important challenge  is  to understand how small  molecules bind to proteins / bio-molecules. Given the diversity in  small molecules (over 1 trillion), and the range of conformations  that proteins acquire, the aspect of finding viable drug targets is  critical. Current docking tools make use of only a static snapshot  or a small subset of conformers that a protein (or small molecule)  can access, which does not fully capture the biological process of  how small molecules (or drugs) interact with bio-molecules.  Development of novel hardware architectures for cellular and  molecular modeling is tremendously challenging, partly because  of (a) the high dimensionality inherent in biological systems, and  (b)  the complexity and uncertainty associated with  their  functionality. Biological systems and  their  interactions are  inherently multi-scale, meaning that they have a wide range of  spatial and temporal scales associated with them. Capturing these  stochastic events using molecular dynamics (MD) or Monte Carlo  simulations or other simulation approaches (such as MCell [43],  PySB [9]) at these biologically relevant time-scales can be  extremely challenging even for specialized hardware.   Apart from being able to simulate biological systems at scale,  there is an emerging need to analyze the large volumes of data  that they generate. Typically, MD simulations of even small  proteins can range from several gigabytes to terabytes (depending  on the time scales of the simulations) and therefore pose a  tremendous challenge in analysis and interpretation. Although  many static and streaming data analytic techniques have been  developed to handle large MD simulations [2-6], the inability to  keep up with large scale simulations is a limiting factor for  biologists in gaining insights into how bio-molecules function.   2.2.2. Modeling Cellular Signaling and Response  using Biochemical Reaction Networks  Cellular function is generally processed by interactions between  proteins that can act as complex machines. These interactions rely  on proteins to exist in a variety of distinct states and are achieved  through multiple biological mechanisms. These mechanisms are  captured succinctly using biochemical reactions, which capture  the kinetics and reaction mechanisms through which the complex  cellular machinery functions. These complex reaction networks  represent a tremendous challenge even for supercomputers to  accurately model a single signaling pathway mainly because of  the combinatorial explosion of potential states  that  these  molecules can exist in at any given time.   Modeling bio-molecular interactions is usually represented using  stochastic networks. These models are specified either by using  explicit models (i.e., enumerating the states of the molecule, such  as bound or unbound), or by using rules-based models (i.e., how  ligand X interacts and inhibits protein Y with some inhibition rate  kXY). Once the system is specified, we can use Gillespie-based   techniques, particle-based rule evaluation or spatial particle-based  methods to obtain quantitative insights into the function of how  cellular-level interactions enable normal function (or how disease  processes pervade the cell, e.g., how tumor cells survive and  rapidly progress). For example, DCoC platforms enabling the  analysis of cell-cell interactions can help understand the observed  patterns in stem cell dynamics [29] and identify optimization  strategies for regenerative medicine.  3.  CHALLENGES FOR NOC DESIGN   3.1. Application Features and Modeling  The biggest challenge before the architect of an NoC-based  solution lies in deciding the extent of the application domain for  which to design and optimize the NoC architecture. Real  applications offer far too many constraints and choices for the  architect [37]. Hence, modeling an application and characterizing  its communication traffic are of primary importance.   Since an NoC supports a distributed computing model on a single  chip, the parallelizability of an application is essential. The exact  programming model (e.g. SIMD vs. MIMD) or memory access  model (shared vs. message passing) determines the suitability (or  inapplicability) of the NoC paradigm. It is well-known that an  application with a purely SIMD programming model is better  suited for GPUs, and loosely distributed message passing models  are well adapted to conventional parallel computing clusters,  albeit with energy costs. However, as discussed in Section 2, most  of the NGS and downstream applications, as well as simulation of  molecular biochemical reaction systems, can be modeled as  shared-memory or tightly-coupled systems that require large  computation and communication bandwidths. While the concern  of high computational bandwidth comes from the volume of input  data and the computational complexity, the divide-and-conquer  approach and need for quick integration of intermediate solutions  drive the communication bandwidth requirement.   There are two broad aspects that need to be considered while  modeling an application – the nature and volume of the  computations involved, and the communication traffic among  computing nodes. It would be worthwhile to remember that NoCbased solutions are meant to support hardware acceleration of  compute-intensive tasks within an application. Most applications  require basic floating-point arithmetic, while some also require  very efficient implementations of elementary functions (e.g.  logarithm, exponential) and trigonometric functions. On the other  hand, there are applications (e.g., MP phylogenetic inference) that  are entirely based on integer arithmetic. For an applicationspecific solution based on a NoC, it is very important to address  the computation needs efficiently, as overdesign leads to wasted  power consumption and underdesign leads to reduced application  performance. Demarcation of the application domain of interest is  critical prior to crystallizing the architecture. A bigger challenge  comes from applications that fit heterogeneous computation  models. Modeling computation in such cases is very dependent on  the input data, and extensive characterization needs to be  performed on a carefully chosen large dataset.   Modeling communication among computing nodes is difficult  primarily due to two factors. Independent determination of      Figure 1. Cyber-physical application characterization graph set (CPACGS) is an expressive mathematical primitive and abstraction to describe the application  of high dimensionality and heterogeneity that changes over time. By associating each node with functional tags (FTs), the CPACGS is able to characterize  arbitrary functionalities using a compositional representation. The richness in expressivity of CPACGS comes from no single static task graph but evolution  over spatio-temporal domains that captures heterogeneous application and NoC architectures as well as the stochasticity.  communication patterns is very difficult, given that most profiling  tools would capture the traffic when an application is mapped to a  (possibly, virtual) machine, where the mapping process itself uses  techniques that alter the “native” communication pattern. One  alternative is to identify the task graph, and thereby infer the  communication traffic pattern. However, that brings us to the  second challenge, where the resultant communication pattern is  stochastic in nature, and possibly even non-stationary [27]. In  such cases, the exact identification of the communication graph is  not practical due to its dependence on inputs, random numbers  and time-varying (e.g., [51]). Extensive profiling is needed for  capturing the nature of traffic pattern covering the entire spectrum  of communication scenarios.    Thus, much of the design choice of NoC heavily relies on the  application model’s capability that recognizes the non-stationary  behaviors and extracts the richness of heterogeneity in both  computation and communication tasks involved at multiple scales,  where application task domains are distinctively focused to best  fit for widely ranged NoC architectures. To address this problem,  we propose a cyber-physical application characterization graph  set (CPACGS) as a new application modeling approach built on  mathematical characterization of the tight coupling between the  computation and communication and considering the highly  dimensional heterogeneity and dynamical characteristics of  applications for diverse architecting implications of best-fit NoC  architectures. In contrast to a static task graph for one application  or a single evolving stochastic task graph with nearly invariant  structural  features, we  emphasize  the  non-stationary  characterization of applications with an array of structure-evolved  dynamic task graphs for better capturing the spatio-temporal  behavior and their implications for various architectural settings.   In Figure 1, we present the CPACGS as a set of heterogeneous  time-dependent representations for applications at multiple scales  where each atomic node in the hyper-graph represents the data  sensing or the computation task (i.e., atomic tasks).  Atomic tasks  are identified as the minimal task units to be processed  distinctively depending on the finest architectural grain to which  the application could be possibly mapped. To encode the  interdependency between the computation or sensing task and the  heterogeneous architectural constraints posed by the nature of the  tasks, we associate each node in the hyper-graph with a set of  elementary function tags (FTs), which characterize the features  of computation or sensing process by a compositional  representation. For instance, to capture the heterogeneity of  inferred architectural structures by two tasks, v1 and v2 that take  integer and floating-point data as input to do addition, both the  types of data to be processed and computation involved could be  used as FTs. We encode “integer” as 1, “floating-point” as 0 and  “addition” as 3.  So FT(v1)={1,3} and FT(v2)={0,3}. The benefits  to introduce FT are at least manifold: (1) FT could provide a  detailed and accurate characterization of tasks by tagging the task  with sufficient elementary functions and features. Building up  from the simple tags, the overall FT set could be very expressive  yet mathematically strict and easy to handle. (2) FT is not only  applicable to modeling of applications, but also could be used to  characterize the architectures. The functionality of hardware  components could be also modeled accurately by the same  tagging process as we do for applications. (3) FT gives  architectural implications for justification and optimization of  design of NoC systems. By examining the FT set of the  application and the target architecture, we could evaluate whether  there is a feasible mapping from the application domain to the  architecture domain. On the contrary, we could check the FT set  of given application and propose architectures that cover the  compositional functionality indicated by it such that we do not  either over- or under-design the NoC systems since we have  captured the heterogeneity embedded in this application.  For  optimization given the FT sets of widely ranged architectures  candidates, we could merge the tasks in atomic task hyper-graph  (ATHG) together to search for a best-fit mapping from the task  domain to NoC architecture domain. The FT set could take unions  and the resultant FT set is able to convey a complex functionality  of separate unmerged tasks.  Last but not least, FT is not static but  coherently as time-dependent as the sensing and computation  tasks involved in the application, thus losing no richness in        (t), i = ∅} v V i j i R i = {Rk i = V0 i (t ) ⊆ V0 (t ) ∧ ∀l ≠ k , Rk ∈=∈ ∈ generality and expressivity for modeling. The hyper-edges  connecting arbitrary number of nodes capture  the multidimensional stochastic interactions among various data sensing  processes  and  computation  tasks  by  associating  the  communications with multi-valued random vectors modeling the  time-varying communication constraints (e.g., the randomness of  traffic volume, spatio-temporal behaviors of user-input and  dynamical bandwidth requirement).    By merging nodes  (i.e., composing multiple simple tasks into a  more complex one) and combining all the edges (i.e., to sum up  all the communications that happen between the merged and the  remaining tasks), the application profiling structure evolves to  generate a series of graphs for architecting design space  exploration at different scales. ACGS not only copes with the  uncertainty and time-varying computation and communication  patterns that exist in inherently stochastic applications such as  genomics and proteomics problems, but also provide an array of  evolving application models that could be better explored, tested  and enforced to optimize a wide range of target NoC architectures  compared to task graphs with stationary task structures.  Definition 1:  A cyber-physical application characterization graph  set (CPACGS) is a set of directed time-dependent multi-valued  hyper-graphs Γ t={Gi|Gi=(V0,E0,Vi,Ei,t)}, where G0(t)=(V0,E0,t)  is the atomic task hyper-graph (ATHG). Each node in V0=V0(t) is  a set of atomic computational/sensing tasks which can not be  partitioned finer at time=t under given architectural constraints.  Vi=Vi(t) is the node set of Gi. Each Vi induces a partition i | ∪ Rk i ∩ Rl such that  each node  is a node set or  hyper-node that represents a collection of atomic tasks in V0(t). E0  is the hyper-edge set of ATHG that represents the interaction  among sets of pair nodes in ATHG. Each ei j in Ei connects a pair   or more nodes in Vi(t) encoding the data and control interdependency between a group of application tasks. At time=t, by  varying the partition policy (randomly chosen or dictated by the  FT set of target architectures) for different Ri, the resultant series  of application characterization graphs Gi provide a evolutionary  tree rooting upon the ATHG showing differently changed  structures of the same application. To enrich the expressivity of  this model to capture a much broader features and dynamics of the  application over prior models, we augment the models with  specific functions and variables:    1. FTatom ={“func0”:0. “func1”:1,….} is a hash table that  encoding the elementary functions of interest into integer  representations. FTatom is not mathematically operational but  i∈Vi(t) and correlate them with a FT set  offers a mapping method to establish the initial FT set for  ATHG and target architectures.  ∪FT(vi i,t):  2NxR->RN is a time-dependent set function that take  2. FT(vj a set of atomic tasks vj application domain. At any time=t,  ∪FT(vi for compositional representation of these task complex.  j,t) characterizes the minimal functionality need to be  accommodated by the target architecture at time=t. Thus it  denotes the time-varying architectural constraints from the  j,t) should be a  subset of FT set of the target architectures.  3. Pe(vi j,t)/Pd(vi 2NxR->[0,1]  j,t):  is  the  time-dependent  multivariate distribution for execution time/deadline of a  atomic task or a collection of them. This models the  stochasticity of task execution time /deadline under the  collective multidimensional uncertainty from time-varying  { | v v i R } R i j k k v i j input, heterogeneous computation requirements and execution  order restricted by the data inter-dependency.  4. Pv(ei j,t)/Pb(ei j,t) is the time-dependent multivariate distribution  of communication volume/bandwidth requirement.  3.2.  Implications on NoC design  Designing an application-specific NoC depends on the results of  modeling and characterization of the application or a class of  applications. Once this is done, the next challenge is to outline the  various components of NoC architecture, viz., processing  elements, interconnection network topology, routing resource  requirement, routing policies, and implementation methodologies.  As discussed earlier, several of these applications require efficient  floating-point computation (including elementary functions) and  hence may require specialized floating-point arithmetic cores  (similar to VLIW or DSP-like cores in some respects). However,  there are some other applications that primarily rely on integer  operations (e.g. MP phylogenetic inference). Suitable choice of  cores is extremely important for application throughput.  The inferred application traffic pattern may suggest the suitability  of some NoC  topologies over others. While applications  generating fairly regular traffic patterns (e.g. parallel sequence  alignment) require regular topologies, applications with widely  distributed and irregular traffic patterns require different types of  NoC topologies. In cases where broadcast communication is  required, distributed topologies such as mesh or torus are suitable  but not sufficient. Further optimizations at architecture and  routing protocol  are needed  for  sustaining peta-scale  requirements. For  recursive or  tree-like communication,  hierarchical topologies might be more suitable. However, as  mentioned earlier, most of the applications in the domains of NGS  and structural biology generate time-varying irregular traffic  patterns, which are hard to model due to their stochastic and nonstationary nature. In such cases, interconnection networks using  long links (e.g. [47], [45]) or based on small-world graphs have  been shown to be very effective (e.g. [51]).  Router design for NoCs catering to these applications is intricately  tied to the topology. Since most of the problems in these domains  are parallelized into numerous sub-problems, one or more of  which is assigned to a core, the volume of data exchange in one  message is primarily determined by the data representation, and is  higher for precision floating-point arithmetic computations. This  impacts wired link widths (typically 32-bit and higher) and the  bandwidth required for non-conventional on-chip interconnects  (e.g. on-chip mm-wave wireless links). With deadlock-free  routing policies, we can guarantee high throughput for these  applications, which is the primary requirement from NoC based  solutions for PPM systems (as opposed to conventional cloud  computing  and  distributed  computing  infrastructure).  Implementation must take into account the special needs from the  architecture standpoint (e.g. broadcast medium, long-range links,  access latency) as also consider the impact on power consumption  and thermal stability of the IC.   4.  NOC FOR GENOMICS  Genomics includes the wide spectrum of applications from  sequence analysis and read mapping to phylogenetic inference.  Each of these applications has characteristic computation and  communication patterns, and present different requirements to the  NoC architect. Generic mesh-based NoCs may not be suitable for  all kinds of applications due to their widely different paradigms of  parallelization and data sharing. For example, the run-times of the      (a)  (b)  Figure 2. Profile of (a) power consumption and (b) temperature while running RAxML , an ML phylogenetic inference application on 16/32 cores of  a Tilera TILEGx-36 NoC platform  popular ML phylogenetic application RAxML [7], when run on a  NoC-based 36-core TILE-Gx-36 platform [16] lead to less than  desired speedup when using 32 cores instead of 16 cores of TILEGx-36, as shown in Figure 2. The reason behind this is two-fold:  (a) processing cores are not optimized to handle the floating-point  operations (including elementary functions) that are characteristic  of RAxML (or for that matter, most statistical phylogenetic  inference tools), and (b) the interconnection architecture on TILEGx-36 is a mesh that does not support the longer-range  communication that ensues when RAxML is mapped to 32 cores  instead of 16. Also, as can be seen from Figure 2 (a), the power  consumption profiles for 16-core and 32-core mappings reveal a  significant amount of residual power that is not directly related to  the application execution, and is spent on working on the OS and  other scheduling software running on the platform. Although  TILE-Gx-36 is a fairly advanced general-purpose multicore  platform, it is clear that such general-purpose platforms do not  meet  the energy-efficiency and communication-efficiency  requirements that are necessary to make NoC-based solutions  attractive for NGS and downstream applications in a PPM  scenario. It is worthwhile to note that the peak chip temperature  shoots up to 80°C in the 32-core case, which clearly makes such  general-purpose NoC platforms unreliable in the PPM domain.  Consequently, such high-impact applications warrant the design  of NoC-based multicores tailored to the application needs.  Sequence analysis applications, such as parallel sequence  alignment  (PSA) have been  shown  to be  successfully  implemented on NoC-based multicores [41]. The NoC-based  solution implemented both the parallel prefix (PP) and antidiagonal (AD) methods, and special attention is paid to the onchip communication infrastructure to efficiently execute the  forward and backward passes in each method. In the PP method,  the forward pass involves point-to-point communication among  the cores, each of which works on a fraction of the entire  sequence. The traffic generated out of this follows a hypercubic  pattern. However, a hypercube topology cannot be implemented  in a 2-D IC without significantly increasing routing congestion  and unacceptable wire delays. In [41], the authors implement a  mesh NoC with routers that can provide a “bypass” path  selectively to directly connect two next-to-neighbor routers along  x- or y-axes. This creates a logical hypercube on the mesh at  different stages of the forward pass by activating these passtransistor-based bypass switches. For the AD method, the forward  pass results in neighborhood communication; hence, mesh NoC  suffices. In the backward pass, the communication pattern  resembles a broadcast, and the mesh with bypass links helps in  reducing  the overall network diameter, and  thereby,  the  communication latency. The energy consumption and latency of  the NoC-based platforms for PSA consist of computation and  communication components. While the computation energy in the  PP method decreases with increasing number of cores, the system  energy is dominated by the communication energy that increases  with the number of cores. There is a tradeoff involved, and  energy-latency product analysis gives 16 as the optimum number  of cores on a chip. In the AD method, where the forward pass  involves neighborhood communication, both computation and  communication latencies scale down with increasing core count,  but communication energy increases beyond 64 cores, due to the  broadcast communication in the backward pass. Again, an energylatency tradeoff analysis gives 128 as the optimum number of  cores. The benefit of such tradeoff analysis and architecture  selection is evident in the performance of NoC-based platforms.  There is a ~23000x speedup over software in the PP method, and  ~9500x in the AD method. Each of these performance points  represents one to two orders of magnitude improvement over  conventional accelerators (such as CBE or GPU).  Downstream NGS applications such as phylogenetic inference  present a significantly more complex problem with respect to  accelerator architecture. There are applications that involve  combinatorial optimization over an integer space, which are often  solved using algorithms  that have non-polynomial  time  complexity. The other kind of applications involves statistical  optimization over a real-number space, and accelerator design for  these problems present several interesting architecture-level  challenges. Breakpoint or MP phylogeny applications belong to  the former category, while ML or Bayesian phylogeny inference  applications belong to the latter. Breakpoint phylogeny is usually  modeled a bounded-edge weight Traveling Salesman Problem  (TSP), which  is an NP-hard problem. Branch-and-bound  technique is a run-time heuristic that is commonly used to solve  TSP. Following this heuristic, some branches of the search tree  are abandoned or “bounded” if they are found to be yielding a  costlier Hamiltonian cycle based on the comparison of an estimate  of the lower-bound cost of the path remaining to be traversed, and  the exact cost of a search path already fully traversed (i.e. up to  the leaf node). The lower-bound cost computation involves a  “reduction” operation in the adjacency matrix representing the  original graph, and this constitutes nearly 99% of the overall                  software runtime of the application. This is the problem that needs  to be tackled in the computation core of the multicore accelerator.  This is the motivation behind the pipelined processing element  (PE) architecture in [49], where the fine-grained parallelism  inherent in the matrix reduction operation has been utilized to  improve the run-time performance from quadratic to linear with  respect to the genome length. Additional challenges such as  managing the memory requirement per PE (where the adjacency  matrix and its reduced versions need to be stored) are tackled  using a stack-like memory architecture that stores only the  changes in the adjacency matrix as it goes down a path on the  search tree [50]. Computational workload distribution is also a  challenge because that involves apportionment of search-space  subtrees to all the PEs. Due to the “bound” operation, several  subtrees may get pruned and this increases the workload  imbalance across PEs, which can be tackled by allocating more  subtrees per PE. However, this leads to memory and other  overheads, and a tradeoff needs to be achieved for workload  distribution as shown  in [50]. On-chip communication  is  generated when PEs share their exact path cost information with  other PEs. While this would normally lead to a broadcast-like  traffic, it is interesting to note that only the lowest path cost needs  to be propagated at any point of time, which leads to a  “conditional broadcast” and a greatly reduced traffic intensity.  This consideration has led to the choice of distributed topologies,  such as mesh and hierarchical tree, on which both latency and  energy performance have been evaluated. A quad-tree NoC  topology delivers the be8st energy-efficiency in a 64-core chip,  while running ~8400x faster than software, and at least an order of  magnitude faster than a highly customized FPGA solution.   In the case of statistical phylogeny inference applications, the  principal computation kernels revolve around computation of the  phylogenetic likelihood function (PLF) [20]. This computation  involves elementary functions (e.g. logarithm, exponential, etc.)  and a modified number system helps in improving the arithmetic  efficiency of the PEs [46]. Again, there is a fairly large number of  such kernels of varying computation footprints, and the next  challenge arises when one has to allocate a certain number of  computational resources to each kernel while maximizing their  co-locality (and minimize the dispersion) so as to minimize the  inter-PE communication latency. Given that this process needs to  be dynamic and with minimal overhead, breadth first search-based  allocation methods are inadequate. In [46], an allocation method  has been proposed where a Hilbert-curved that is logically  embedded within a folded torus NoC converts a two-dimensional  allocation problem to a linear one, where computational resources  are allocated following the Hilbert curve. The space-filling nature  of this curve ensures that co-locality is maximized in the process.  This approach has been extended to larger systems, where colocality is improved and overhead is reduced by parallelizing the  allocation process [44]. Similar approaches have shown to deliver  better runtime performance and energy efficiency for 3-D NoCs  as well, which can accelerate the region of interest (ROI) of the  application by over 1000x. 3-D NoCs have fewer horizontal wired  links than 2-D NoCs of the same system size (number of cores),  and are more energy-efficient.  Despite the advantages of 3-D NoCs, their fabrication, especially  using through-silicon vias (TSVs) remains a challenge, and yield  is typically low. Thermal issues related to 3-D NoCs also make  them unreliable for PPM solutions. Of note,  the major  performance improvement in 3-D NoCs comes from their reduced  network diameter, which can be achieved through introduction of  long-range links on 2-D mesh/torus NoCs. Implementation of  these links using metal wires leads to unacceptable energy  consumption, especially at sub-65 nm technology nodes. Hence,  there has been a great deal of interest in employing novel on-chip  interconnects, such as THz-wireless  links between carbon  nanotube antennas, or mm-wave wireless links using metal zigzag  antennas on the chip. These interconnects help in the realization  of small-world network topologies on a chip in an efficient  manner. Different kinds of wireless channels provide different  amounts of bandwidth and the application traffic determines their  number and placement on a chip. As shown in [48], use of  wireless links leads to lower number of inter-core communication  hops irrespective of the allocation process. This leads to better  run-time and energy-efficiency. Wireless link utilization is  however dependent on the allocation process, and greedy  allocation around wireless links improves wireless link utilization  but degrades latency due to bandwidth constraints. A combination  of efficient allocation of computational kernels on 2-D NoCs and  a few judiciously placed on-chip wireless links has been shown to  deliver extremely high sustained throughput (>1011 floating point  vector operations per second), low energy per operation (~0.5 nJ)  as well as reliable thermal performance (on-chip temperature  variation within 26°C) [12]. For ML applications, such wirelessenabled NoCs (WiNoCs) have been shown to achieve runtime  reduction of ~2x with respect to even 3-D NoCs [45].   Figure 3. MD protein folding simulations on a large scale cluster  5.  NOC FOR PROTEOMICS  Proteomics studies the proteins at a large scale in terms of their  structures and functions ranging from the identification of proteins  through protein alignment to predicative structure analysis based  on full-atom sampling approach (e.g., molecular dynamics (MD)  simulation) or optimization approaches  (e.g., evolutionary   computation analysis). The spatio-temporal complex dynamics of  proteins leads to exascale computation and communication  requirements that cannot be sustained by current supercomputers.  For instance, exhaustive search for similarities has to be  performed against huge databases such as UniProt and PROSITE  [53] for identification of proteins in different cell types. The  protein  identification challenges  traditional computing; for  instance, a recent meta-genomic study of 12 permafrost samples  for identification of proteins requires 800,000 CPU hours or 85  computer years using NERSC supercomputer at JGI [8]. The  protein structure prediction implies to study the folding process of  peptide chains. The geometrical conformations of proteins are  extremely rich (more than 4143) and environmentally sensitive  (e.g.,  small  regulatory molecules,  solvent molecules).  Traditionally, computational approaches were accelerated by  dividing a  long simulation across many general purpose        processors. This strategy is inefficient due to huge communication  overhead and poorly exploited fine-grain parallelism. For  instance, Figure 3 shows that to obtain the structural information  via the MD approach on a 4096-node cluster [13], the simulations  proceed at 289ns/day, which need 10 years for completing the  folding process. The gap between the ideal linear speedup and the  actual measured performance at  this cluster  indicates  the  unexplored parallelism and increased communication cost.  Therefore, the proteomics complexity raises numerous challenges:  i) how could the computing paradigm be designed to explore the  fine-grain parallelism and provide sufficient sampling for  characterization of the heterogeneous folding process. ii) how  could the communication infrastructure be designed to sustain  exascale transmission and avoid data fragmentation? Although  Anton represents one architectural option for speeding up the MD  simulations, it presents a number of limitations: a) Many folding  processes occur at longer timescales. b) These timescales imply  significant data processing and communication (i.e., all relevant  atoms are distinctively modeled and their movements and 3D  coordinates are recalculated every 10-12s based on the force-field  approach). c) The monolithic nature of Anton requires substantial  redesign efforts when new proteomic features are considered.  An alternative approach to MD for longer timescale is to relay on  optimization-based studies of protein folding. Along these lines, a  1200-core NoC for protein folding analysis based on evolutionary  algorithms was presented in [58]. This naïve NoC design attains  up to 310x speedup. These evolutionary computational efforts can  enable efficient ways for identifying the native state of a protein  for longer simulation lengths than the MD could reach. However,  there are still numerous challenges. i) How should the NoC be  designed to sustain long inter-node distance and extremely large  volume of communication? ii) How to predict the availability of  NoC resources without a global manager? iii) How to reconfigure  the NoC to adapt to highly varying workloads? iv) How to  integrate NoC with current proteomics analysis tool-chains for insitu and accessible computing platforms?  To address the problem of distant and large volume data  exchange, [56] presents a user-cooperation network coding  strategy for NoCs. Multiple routers in one region share their  routing resources for incoming and outgoing packets. Packets  from one source destined to multiple nodes in the NoC are XORcoded together, sent through long links and reconstructed at the  sinks. This leads to significant network throughput improvement  in a multicast session (up to 127x over multiple unicast  communication when delivering a 1024-packet long message to  63 nodes in a 8x8 mesh NoC) with minimal energy consumption.   To overcome the challenge of gathering global information in a  centralized fashion and relaying on randomized algorithms [32],  Xue et al. proposed a task mapping strategy [57] inspired from  self-organization in natural systems. The task moves from node to  node checking the availability of PEs and gets processed at the  very first available PE. This leads not only to a significant  improvement in the utilization of the NoC architecture, but also  considerably reduced the execution time (up to 200x improvement  in computation time). No global information transferred back and  forth are needed between the control node/host and PEs thus  reducing control complexity and power consumption.  6.  CONCLUSIONS  This paper highlighted the main computational challenges in  PPM, presented a few fundamental challenges faced by the design  of NoC-based multicores and outlined a few preliminary  solutions. However, we strongly encourage  the  research  community to enrich the design methodology for efficient large  scale NoC platforms and bring them to the point where we can  consider truly enablers for PPM.  Acknowledgement: ORNL is operated by UT-Battelle, LLC, for  the U.S. Department of Energy under contract DE-AC0500OR22725. The United States Government retains and the  publisher, by accepting the article for publication, acknowledges  that the United States Government retains a non-exclusive, paidup, irrevocable, worldwide license to publish or reproduce the  published form of this manuscript, or allow others to do so, for  United States Government purposes. A.R. acknowledges support  under Laboratory Director Research and Development (LDRD)  proposal 7417. P.B. and Y.X. acknowledge the support of US  National Science Foundation under 1331610 and 1453860 grants.  TM acknowledges the support of Department of Science and  Technology, Govt. of India through SERB grant Diary no.  SERB/F/1512/2014-15.  7.  "
Modeling and Design of High-Radix On-Chip Crossbar Switches.,"The crossbar is a popular topology for on-chip networks that offers non-blocking connectivity and uniform latency. However, as the number of nodes increases, crossbars typically scale poorly in area, power, and latency/throughput. To better understand the design space, we have developed an on-chip crossbar modeling tool based on analytical models calibrated using circuit-level simulation results in 40nm CMOS. We present a design space exploration showing how crossbar area, power, and performance vary across input/output node number, data width, wire parameters, and circuit implementation. Using the modeling results, we identify a design point that demonstrates 2X higher throughput, 1.4X lower power and 1.2X lower area compared to previous published designs.","Modeling and Design of High-Radix On-Chip Crossbar Switches Cagla Cakir Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA USA ccakir@andrew.cmu.edu Jon Lexau Oracle Labs 500 Oracle Parkway Redwood Shores, CA USA jon.lexau@oracle.com Ron Ho Altera Corp. 101 Innovation Drive San Jose, CA USA roho@altera.com Ken Mai Carnegie Mellon University 500 Forbes Avenue Pittsburgh, PA USA kenmai@andrew.cmu.edu ABSTRACT The crossbar is a popular topology for on-chip networks that oﬀers non-blocking connectivity and uniform latency. However, as the number of nodes increases, crossbars typically scale poorly in area, power, and latency/throughput. To better understand the design space, we have developed an on-chip crossbar modeling tool based on analytical models calibrated using circuit-level simulation results in 40nm CMOS. We present a design space exploration showing how crossbar area, power, and performance vary across input/output node number, data width, wire parameters, and circuit implementation. Using the modeling results, we identify a design point that demonstrates 2X higher throughput, 1.4X lower power and 1.2X lower area compared to previous published designs. Categories and Subject Descriptors C.2.1 [Computer Systems Organization]: ComputerCommunication Networks—Network Architecture and Design General Terms Design Keywords Network on Chip, Crossbar, Modeling 1. INTRODUCTION Networks-on-chip have emerged as an alternative to traditional buses by oﬀering modular, highly scalable, on-chip Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. NOCS’15 September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM 978-1-4503-3396-2/15/09 ...$15.00. DOI: 10.1145/2786572.2786579 Figure 1: System view of a crossbar. The crossbar is built as a compact, centralized switch that is connected to I/O nodes using global data links. communication platforms [2]. Crossbars are a popular topology that oﬀer non-blocking connectivity, uniform single-hop latency, and low complexity compared to multi-hop networks. However, as the radix of the crossbar (i.e., number of I/O nodes) increases, the crossbar overheads in area, power, and latency also increase signiﬁcantly. As the usecase for such high-radix crossbars typically involves physically disparate input and output nodes (e.g., multiple processors communicating with multiple L3 cache blocks), these structures are usually built as a compact, centralized crossbar connected to the input and output nodes via dedicated point-to-point data links [5] as seen in Figure 1. The main challenges in designing high-radix crossbars are the scheduling and the physical design of the crossbar switch itself. Previous work has shown that scheduling of highradix crossbars is a surmountable challenge [4, 5]. Further, as the network data packet size is usually larger than the physical data width of the crossbar, the scheduling decision latency can be amortized over the multiple cycles required to transfer the entire network packet across the crossbar. Thus, we focus on the physical design of the crossbar switches in this work. They typically scale poorly in area, power, and latency/throughput with increasing radix. The main challenges are nonlinear area growth, wire delay dominance, and circuit challenges of building high-radix switches. High-radix crossbar characteristics (area, power, performance) depend heavily on the ﬂoorplanning and layout, and hence the most accurate evaluation is achieved by postlayout or post-route simulations. This makes design optimization via iteration highly time and resource intensive, especially for full custom ASIC designs. Although standard cell designs have more ﬂexibility to optimize system level parameters such as number of modules and data width, these designs lack low level circuit and routing optimizations due to EDA tool limitations. Thus, we have developed an on-chip crossbar switch modeling tool based on analytical models to have a better understanding of the design space. We present a design space exploration showing how crossbar area, power, and performance vary across input/output node number, data width, wire parameters, and circuit implementation calibrated using circuit-level, post-layout simulation results in an industrial 40nm CMOS process. We also highlight a design point that demonstrates 2x higher throughput, 1.4x lower power and 1.2x lower area compared to previous published designs. Related work is discussed in Section 2. The basics of the crossbar topology and the design parameters are discussed in Section 3. Modeling, evaluation metrics, and the methodology are shown in Section 4. The evaluation results and the highlighted design are discussed in Section 5.The scaling of the crossbar design is discussed in Section 6. Finally, we conclude the paper in Section 7. 2. RELATED WORK The related work most similar to that present here is from Passas et al. [5] who present a cost analysis and modeling of crossbar switch area, delay, and power. Their main focus is the crossbar topology and the performance optimization for high radices across diﬀerent radices and data width. They use standard cell design ﬂow to build multiplexer tree based crossbars for the analysis and report post-route and simulation based results. Using standard cell design ﬂow gives them ﬂexibility to run an automated ﬂow for post-route simulations, but their experiments are limited to multiplexer tree based designs and limited by electronic design automation (EDA) tool routing options. In contrast, our analytical crossbar model covers both system level (number of modules and data width) and circuit level (multiplexer circuits, wire pitches, etc.) design parameters to achieve design optimization as close to full custom design as possible. We further take into account custom layout optimizations that are not possible in the previous standard cell synthesis based modeling work. As NoCs are in widespread use, other researchers have developed a number of on-chip network modeling tools for design exploration [1, 10–12]. These tools contain relatively simple crossbar models, as crossbars are typically at the core of routers used in multi-hop networks. Further, these crossbars are typically of low-radix as they only connect the local network node to the rest of the multi-hop network. The crossbar modeling is part of the router modeling and is based on the basic X-Y crossbar design where the inputs and outputs run in perpendicular to each other (usually using with minimum sized wires) and connected via tri-state buﬀers at each intersection point. These studies focus on the modeling and optimization of the entire multi-hop network itself. Although they provide good system level modeling and exploration, the crossbar design options are not explored, the modeling is at a relatively high level, and the radix of the crossbars modeled is relatively low. Finally, in the circuit design space, researchers have proposed improvement techniques for X-Y topology crossbar switches [6–8]. However, these are isolated point designs and there has not been signiﬁcant exploration of the design space at the circuit-level owing to the iteration diﬃculties mentioned earlier. As such, our work allows for incorporation of new circuit techniques into our overall modeling and optimization framework. Indeed, the impetus for our modeling eﬀort was our interest in designing high radix crossbar implementations, and our realization that there was not a modeling/optimization framework with suﬃcient level of detail and design options. 3. CROSSBAR ARCHITECTURE An N x N crossbar is a non-blocking switch that connects N input nodes to N output nodes, where each node has a data width (DW ). The crossbar architecture is shown in Figure 2, where the connection of every input data to an output forms an N :1 multiplexer. Figure 2: N xN crossbar architecture. Every input is connected to every output via N :1 multiplexers. The crossbar consists of N x DW input data bits, N x DW output data bits, and N x DW multiplexers, N :1 each. As N and DW increases, ﬂoorplanning and the total design area become signiﬁcant parts of the performance due to large number of long I/O wires, multiplexers, and challenging routing requirements. Physical design details such as ﬂoorplanning and area, as well as circuit details of multiplexers and I/O wires are discussed below. 3.1 Floorplanning One challenge in crossbar design is to arrange I/O data wires for easier access to/from multiplexer gates from/to edge of the design. Floorplanning options are port-slicing and bit-slicing as can be seen in Figure 3. Grouping the data bits together for each module (port) is called portslicing. The modules (module [0], module[1],...,module[N]) are placed next to each other where each module has DW data bits. This requires the output multiplexers to span the whole design width to get inputs from each module. On the other hand, grouping together a speciﬁc data from each module is called bit-slicing. In this case, data bits (data[0], data[1],...,data[DW]) are placed next to each other where each group has N data bits (one data bit from each module). This enables building smaller and faster multiplexers as inputs of each multiplexer are already grouped. However, it is typical to assume that the I/O data bits are grouped together for each node and routed to/from the edge of the crossbar design. Therefore, for bit-slicing, a rearrangement of the I/O data bits at the edge of the design is required. For large number of I/O data bits, this bit scrambling requires a large area, and extra clock cycles [5]. Therefore, port-slicing oﬀers better performance overall. 3.4.1 Architectural Implementation Options Designing a N :1 multiplexer, where N is large, is a challenge due to parasitic loading from the non-active inputs. A popular solution is to build the large radix multiplexer using smaller radix sub-multiplexers in a tree-structure to improve the performance. In a ﬂat multiplexer implementation, a single horizontal wire track is dedicated for every output bit. But if the multiplexer is built as a tree, the number of horizontal wire tracks is increased to logmN (the depth of the tree where m is sub-multiplexer radix) as seen in Figure 4. The length of the internal wires between the submultiplexers depend on the physical implementation choices as will be explained below. Further, increasing the depth of the multiplexer increases the design area, hence eﬀecting the length and latency performance of I/O wires. Figure 3: N xN crossbar with DW data bits implemented using port-slicing (a) and bit-slicing (b) ﬂoorplans. 3.2 Area Large number of wires, multiplexers, and the ﬂoorplanning details determine the area of the design, which is critical for the electrical parameters of the long I/O wires. Matrixstyle wiring, where input and output wires run perpendicular to each other, maximizes area utilization. Optimum size multiplexers usually ﬁt underneath the minimum pitch I/O wires for smaller radix designs, whereas for high radices, using larger wire pitches can improve the performance by increasing the design area for the multiplexers (for better drive strength). 3.3 Input Wires Each input bit should be distributed to every output multiplexer that means the input wires should span the whole height of the crossbar. In addition to quadratic latency growth of long input wires, fan out of the input bits increase as the design radix increases. Every multiplexer behaves as a constant load on input wires. Input drivers have more design ﬂexibility as they can be stacked physically without a signiﬁcant contribution to the overall core area and repeaters can be inserted when needed. However, the input wire delay is still a substantial portion of the overall delay at high radices. 3.4 Multiplexers and Output Wires Switch circuits are multiplexers that drive the long output wires. Since we adopted port slicing, each multiplexer spans the whole design width to access all input nodes and drives long output wires. Internal wires of the multiplexers are not negligible, and this increases the delay by adding intrinsic wire delay and extra load capacitance from the wires. Further, as they are placed underneath the I/O wires to have a smaller crossbar area, the multiplexer area, hence the drive strength, is limited. Figure 4: 8:1 multiplexer built using 2:1 sub-multiplexers. Length of the internal wires depends on the physical implementation of the multiplexer. 3.4.2 Physical Implementation Options As the inputs of the multiplexers span a large area, there are two main physical multiplexer implementation options: the distributed and centralized styles. The centralized style routes all the inputs to the multiplexer located in the middle and drives the output wire from that location, whereas in the distributed approach, the output wire spans all the input locations and the inputs tap-on to the output. Figure 5a and 5b show the centralized and distributed style implementations of an 8:1 multiplexer respectively. The centralized style minimizes the internal wires of the multiplexer, but it requires more horizontal wires dedicated to the input routing of multiplexers and suﬀers from larger area at higher radices. On the other hand, the distributed style has longer internal wires and cannot use unidirectional repeaters on the internal and output wires and suﬀers from quadratic wire delay scaling. 3.4.3 Circuit Implementation Options The critical path of the crossbar is the data propagation through the longest input wire to the longest output wire, which means the switch circuit connects two high resistive paths and has high susceptibility to noise. Therefore static tri-state inverters (shown in Figure 6) are used to implement the multiplexers as they oﬀer good performance due to low resistive paths to ground/power. The crossbar multiplexer is built by wiring together the tri-state inverters for each input module (diﬀerent options of architecture and physical implementation are discussed above). Every input module has a select signal that is activated if the input is granted priority. Therefore, only the chosen input module’s tri-state inverter drives the output wire. We also explored using dynamic tri-state buﬀers for crossbar multiplexers as can be seen in Figure 6. For hierarchical multiplexer implementations, precharging internal wires (sub-multiplexer outputs) are not feasible due to high switch(a) Centralized physical implementation of a 8:1 multiplexer. 4.2 Evaluation Metrics Sub-multiplexer Radix (m ): Radix of the sub-multiplexers that are used to build the N :1 switch multiplexer. Multiplexer physical implementation: Options are the centralized or the distributed styles as described above. (b) Distributed physical implementation of a 8:1 multiplexer. Figure 5: Centralized and distributed style physical implementations. ing energy, and extra wire routing for the precharge signal for each stage. But, it is an appealing option for ﬂat multiplexer implementations since only the output wire is precharged and it avoids the large PMOS pull-up devices. The PMOS transistor used for the precharge can be sized smaller, since the unselected tri-state inverters shares the same precharge signal and will also pull-up the output wires. Figure 6: A static tri-state inverter (left) and a dynamic tristate inverter. The static tri-state inverter drives the output wires when the input module is granted priority (SEL = 1). The dynamic tri-state inverter output is initially precharged high (PC = 0), and when in operating mode (PC = 1), the output is pulled-down if the input module is granted priority and the data is high. 4. CROSSBAR MODELING We built an analytical model of the crossbar using design options explained in Section 3 as design parameters. Models for the evaluation metrics (area, delay/throughput, and energy consumption) are calibrated using circuit-level, post-layout simulation results in 40nm CMOS bulk process. 4.1 Design Parameters The design parameters are listed below. Number of I/O nodes (N ): Radix of the crossbar. Data width (DW ): Number of data bits for each I/O node. Input and output wire pitches: Sum of the wire width and spacing. Input and output wire pitches are independent from each other and should be optimized considering their electrical wire parameters as well as how they contribute to the total design area. Number of metal layers: Number of metal layers dedicated for both input and output wires. Evaluation metrics are area, delay/throughput, and energy consumption. Area is calculated using design parameters. Delay and energy consumption is modeled with design parameters as well as wire characteristics determined by the area and the ﬂoorplan. 4.2.1 Area I/O wire length and design area are calculated as in Equation 1 and 2. Input wire pitch determines the output wire length and vice versa. Therefore, it is important to understand the trade-oﬀs for crossbar wire engineering, as the matrix style wire structure in the crossbar creates an interdependence of wire pitches and wire lengths. wire pitcho/i × DW × N number of metal layers area = wire lengthi × wire lengtho wire lengthi/o = (1) (2) 4.2.2 Delay and Throughput I/O wires play a substantial role in both delay and energy consumption. Wires are modeled as distributed RC lines [3]. Wire capacitance (Cwire , sum of four parallel-plate capacitances plus a fringe capacitance) and wire resistance (Rwire ) are calculated using wire length, width, and spacing. Figure 7: RC modeling of the driver, wire, and receiver for delay calculations. Delay is modeled by RC formulation as seen in Equation 3. Drivers are modeled as resistors (Rgate ) with parasitic loads (Cdiﬀ ), and receivers present capacitive loads (Cgate ). Delay for Figure 7 is calculated as in Equation 3. τ = Rgate × (Cdif f +Cwire )+Rwire × (1/2Cwire +Cgate ) (3) Input Wire Delay : Input data is distributed to every output multiplexer which behaves as a constant receiver load. Since receivers are distributed throughout the wire, parasitic loads contribute to the delay similarly as the distributed wire capacitance. τinput = Rgate × (Cdif f + Cwire + NoCgate )+ Rwire × (1/2Cwire + 1/2NoCgate ) Multiplexer and Output Wire Delay : The multiplexers drive the long output wires and the delay is modeled for diﬀerent physical implementation styles as shown below. If built in a tree-structure, each sub-multiplexer drives a wire since the internal wires are not negligible and the ﬁnal submultiplexer drives the output wire. The delay is the sum of all sub-multiplexer delays as in Equation 5 and 6. (4) For the centralized style, switch drivers (tri-state buﬀers) of the multiplexer are the wire drivers, and the driver parasitic load is not only the Cdiﬀ of the driver gate, but also the sum of all the unselected switch driver parasitic loads. If the input of the multiplexer (m ) is larger than 4 (can be anything from 2 to N ), we build it as quad-tree multiplexer using 4:1 multiplexers, since it is the most optimal way [9], and calculate the overall delay as the sum of the delay of each stage (as in Equation 5) . τcentralized = Rgate × (mCdif f + Cwire + Cgate )+ Rwire × (1/2Cwire + Cgate ) (5) For the distributed style, switch drivers of the multiplexer are distributed throughout the output wire; therefore the parasitic load from the unselected drivers can be modeled as extra distributed parasitic loading on the selected driver as well as the wire resistance. τdistributed = Rgate × (mCdif f + Cwire + Cgate )+ Rwire × (1/2Cwire + 1/2mCdif f + Cgate ) Size of the network packet is usually larger than the DW. In order ﬁnd the optimum DW, the throughput (TP ) of the design is also evaluated. T P = DW × 1 delay (6) (7) 4.2.3 Energy Our energy modeling focuses on the switch capacitive current and energy consumption is modeled as in Equation 8 where Cwire is the sum of input, output and internal switching wire capacitances and Cmux is the sum of the gate and diﬀusion capacitances of the switching devices of the multiplexers for a single data bit. energy = N × DW × (CwireV DD2 + CmuxV DD2 ) (8) 4.3 Methodology For a given N, we calculate area, delay, and energy using the models explained above in a ﬂow shown below. In order to ﬁnd the optimum design point, the ﬂow is repeated for every possible set of design parameters. 1. Input N 2. Set the design parameters : DW, number of metal layers, input and output wire pitch, sub-multiplexer radix, multiplexer physical implementation style 3. Calculate I/O wire lengths and design area 4. Placement of multiplexers: Multiplexer tree is structured and each sub-multiplexer is placed. 5. Calculate wire parasitics for I/O wires and the internal wires for the multiplexers: Length of the internal wires are calculated from locations of the current and the next sub-multiplexers. 6. Size the multiplexers: • If built as a tree, sizing starts from the last submultiplexer. • Multiplexer is sized according to optimal fan out (FO ) sizing [9] where load is gate capacitance of the next multiplexer and the wire capacitances. • Each multiplexer in the tree has an allowed area that is decided by design area and number of multiplexers in the tree. • If the sized multiplexer does not ﬁt in that area, FO is increased until the multiplexer is small enough. 7. Calculate delay and energy for multiplexers and output wires: Sum of delay and energy of all multiplexer stages. 8. Calculate delay and energy for input wires: Repeaters are inserted if necessary. 9. Calculate the total delay and energy 5. EVALUATION We run this ﬂow for diﬀerent sets of design parameters to understand the behavior of each parameter and the optimal design points. While sweeping a speciﬁc parameter, the rest of the parameters are set to the most optimal solution for that speciﬁc design point. First, we explore sub-multiplexer radix and the physical implementation style that lead us to an optimum design option. Using this design point, we look into the trends for the wire pitch and the number of metal layers. Further, we examine the eﬀects of DW on performance and changes with radix scaling. Finally, we highlight a design point optimized for minimum energy-delay product and compared its performance to previously published results. 5.1 Sub-multiplexer Radix The sub-multiplexer radix (m ) is swept from 2 (binary tree) to N (ﬂat) for both the centralized and distributed implementation styles to ﬁnd the optimum design point. For the centralized style, the most optimal implementation is to use a binary-tree multiplexer (m =2) as seen in Figure 8. The multiplexer is located in the middle where all the distributed inputs are driven to, therefore every stage of multiplexers have m /2 extra horizontal wire tracks dedicated for input wires. This results in a larger area, higher energy consumption, and delay with increasing m. On the other hand, for the distributed style, the best performance can be achieved using a ﬂat multiplexer (m = N ) as seen in Figure 8 as well. This implementation does not have extra wire tracks for the inputs that limits the m, and since the distributed inputs are connected via long wires, the parasitic loading from the other inputs are negligible. 5.2 Physical Implementation Style We compared the performance of diﬀerent physical implementation styles. The centralized style is implemented using a binary tree multiplexer, whereas the distributed style is implemented using a ﬂat distributed multiplexer. For the distributed, ﬂat multiplexer, there is a single output wire that all inputs are connected to. As mentioned in the previous section, this makes it possible to use dynamic logic to build the multiplexer. The switch connections of the inputs are built as pull down circuits, and pre-charge pull up devices are distributed on the output wire (number of pull up devices depend on the wire capacitance as well as the timing requirements). This style decreases the circuit area signiﬁcantly by removing large PMOS devices in the tri-state buﬀers, however introduces additional timing requirements because of the pre-charge scheme. Figure 8: Comparison of delay (left), energy (middle), and area (right) of centralized and distributed styles with diﬀerent sub-multiplexer radices. Figure 9: Comparison of delay (left), energy (middle), and area (right) of centralized, distributed, and distributed-dynamic styles for a radix-64 crossbar with 64b of data. The results in Figure 9 show that the distributed-dynamic style oﬀers the best performance in terms of delay, energy, and area. 5.3 Wire Pitch Increasing the input and out wire pitches increases the area as well as the energy consumption. Increasing the design area improves the switch driver strength, hence performance, but also increases the wire capacitance that potentially hurts the performance. The delay for diﬀerent input and output wire width and spacing can be seen in Figure 10. Both the input and output performances are more sensitive to wire width because increasing the wire width decreases resistance of that wire, improves the switch driver strength, but increases the capacitance of the corresponding wire as well as the opposite wire. On the other hand, increasing the spacing improves the driver strength, and only increases the opposite wire capacitance. The optimum input wire width and spacing are the minimum values. The optimum output wire spacing is the minimum as well, however the optimum output wire spacing is ∼ 6 times more than the minimum spacing. Increasing the output wire spacing increases the output driver area while increasing the input wire capacitance. But since the input drivers have more ﬂexibility in terms of area and drive strength, the overall delay performance is improved with increasing output spacing. 5.4 Number of Metal Layers Increasing the number of metal layers dedicated for input and output wires decreases design area linearly. But it also decreases switch driver area; therefore performance improvement saturates when drive strength of the switch circuits degrades signiﬁcantly and it becomes physically impossible to ﬁt minimum size transistors. Using 2 metal layers for each input and output wires (4 layers total) improves energy-delay product ∼ 4x as can be seen in the Figure 11. Although using more metal layers improve performance further (at a lower rate), it requires more than 6 layers dedFigure 10: Delay for diﬀerent input (top) and output (bottom) wire width and spacing. Table 1: Frequency, Throughput (TP), Power, Area, and Energy-Delay Product Comparison to Previously Published Results Design Proposed (40nm) [7] (45nm) [5] (scaled to 40nm) N DW Freq (GHz) 64 128 1.2 64 128 0.559 64 32 1.5 (3 stages) Throughput (Tb/s) Power (W) Area (mm2 ) Energy-Delay Product 9.8 0.9 3.2 6.2 4.47 1.3 4.06 41 0.048 2.75 4 110 Figure 11: Energy-delay product for diﬀerent number of metal layers for a radix-64 crossbar with 64b of data. icated just for the high level routing of the crossbar, which is a big portion of wire resources for current technologies. 5.5 Data Width Area and energy grows exponentially with data width (DW ) scaling. Delay, on the other hand, grows at diﬀerent rates for diﬀerent DW values for crossbars. Increasing the DW increases switch circuit area (improves drive strength) and IO wire lengths. When DW is small, constant overhead delay (timing margins for ﬂip-ﬂops and dynamic logic) and output parasitic loading of the switch is a bigger portion of the delay. Therefore, delay increases at an even lower rate than DW scaling. As DW gets larger, this rate becomes linear, and quadratic when unrepeated wire delay dominates. throughput (TP ) would stay constant with DW scaling if delay would scale linearly. Optimum design point is where delay starts scaling worse than linear. As shown in Figure 12 TP increases until the optimum point and declines afterwards. Furthermore, optimum DW point changes with radix scaling as well. Optimum DW is larger for smaller radices and vice versa as seen in Figure 12 as the main bottleneck of the crossbar design is total area determined by N and DW. 5.6 Highlighted Design Point Using the modeling and evaluation results, we propose a design point optimized for energy-delay product as the ﬁgure of merit in 40nm CMOS bulk process. Frequency, throughput, power, area, and energy-delay product of a radix-64 crossbar with 128b of data is shown in Table 1. Highlighted design uses ﬂat multiplexers implemented with distributed dynamic tri-state inverters. Input wire width, spacing, and output wire width are minimum size, whereas the output spacing is 6X the minimum spacing, and 2 metal layers are dedicated for both the input and the output wires. The optimum DW for radix-64 is 128b as seen in Figure 12. Layout of a single input/output switch is shown in Figure 13. We compared our design point to previously published results from [5] (scaled to 40nm from 90nm, post-route simulation Figure 12: Throughput for diﬀerent data widths and radices. Figure 13: Layout of a single input/output switch. results) and [7] (45nm, silicon results). The design point demonstrates 2X higher throughput, 1.4X lower power, 1.2X lower area, and 6.5X better energy-delay product compared to previously published designs. 6. RADIX SCALING AND FUTURE WORK Previous research [5, 7] as well as our results show that crossbars can be scaled to high radix while still operating eﬃciently. The area and the energy consumption scale quadratically with radix. The delay of distributed-dynamic style design scales at a lower rate than linear for low radices when the circuit overhead delay dominates, at a linear rate for medium and high radices, and at a quadratic rate for extremely high radices (more than 512) when the unrepeated wire delay dominates. Although centralized multiplexer implementation style oﬀers linear delay scaling with the use of repeaters, the distributed-dynamic style performance is much better for a wide range of radices as can be seen in Figure 14a and 14b. The main reason for the quadratic delay growth at extremely high radices is the long unrepeated wires in the crossbar design. The output wires cannot be repeated using unidirectional repeaters as the inputs are distributed, and using bi-directional repeaters introduce extra complexity to the switch design. We speculate that this can be overcome by using modular blocks to build the extremely high radix crossbars. An example block diagram can be seen in Figure 15. 7. CONCLUSIONS We developed a modeling tool for crossbar design to have 8. "
Parka - Thermally Insulated Nanophotonic Interconnects.,"Silicon-photonics are emerging as the prime candidate technology for energy-efficient on-chip interconnects at future process nodes. However, current designs are primarily based on microrings, which are highly sensitive to temperature. As a result, current silicon-photonic interconnect designs expend a significant amount of energy heating the microrings to a designated narrow temperature range, only to have the majority of the thermal energy waste away and dissipate through the heat sink, and in the process of doing so heat up the logic layer, causing significant performance degradation to the cores and inducing thermal emergencies. We propose Parka, a nanophotonic interconnect that encases the photonic die in a thermal insulator that keeps its temperature stable with low energy expenditure, while minimizing the spatial and temporal thermal coupling between logic and silicon-photonic components. Parka reduces the microring energy by 3.8--5.4x and achieves 11--23% speedup on average (34% max) depending on the cooling solution used.","Parka: Thermally Insulated Nanophotonic Interconnects Northwestern University, Department of Electrical Engineering and Computer Science, Evanston, IL, USA yigit@u.northwestern.edu, nikos@northwestern.edu Yigit Demir and Nikos Hardavellas Abstract—Silicon-photonics are emerging as the prime candidate technology for energy-efficient on-chip interconnects at future process nodes. However, current designs are primarily based on microrings, which are highly sensitive to temperature. As a result, current silicon-photonic interconnect designs expend a significant amount of energy heating the microrings to a designated narrow temperature range, only to have the majority of the thermal energy waste away and dissipate through the heat sink, and in the process of doing so heat up the logic layer, causing significant performance degradation to the cores and inducing thermal emergencies. We propose Parka, a nanophotonic interconnect that encases the photonic die in a thermal insulator that keeps its temperature stable with low energy expenditure, while minimizing the spatial and temporal thermal coupling between logic and silicon-photonic components. Parka reduces the microring energy by 3.8-5.4x and achieves 11–23% speedup on average (34% max) depending on the cooling solution used. I.  INTRODUCTION Silicon photonics have emerged as a promising solution to meet the growing demand for high-bandwidth, low-latency, and energy-efficient communication in manycore processors. Silicon waveguides are more efficient for long-distance onchip communication than electrical signaling [24], and nanophotonic devices can be manufactured by simply adding a few new steps in the CMOS manufacturing process [5]. While silicon-photonic devices can be manufactured alongside CMOS logic even on the same die [5], designers typically assume a simplified process where the photonic components are housed within a photonic die, which is 3D-stacked to a logic die that contains cores, caches, and other electronic components. Due to this arrangement, the thermal variations of the logic die directly couple to the photonic devices. These thermal variations may occur rapidly depending on the workload, are both spatial and temporal in nature, and can exceed 30 oC difference. Moreover, both processor and memory chips are susceptible to thermal variations [17]. As current silicon-photonic designs are predominantly based on microring resonators, these thermal fluctuations may prevent the optical interconnect from Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. NOCS '15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3396-2/15/09 $15.00  DOI: http://dx.doi.org/10.1145/2786572.2786597 functioning. Microrings are tuned to resonate at a particular wavelength when they are at a set temperature, but they are highly thermally sensitive devices. For example, the resonant wavelength of a microring modulator with 5 um diameter shifts by 0.11 nm/oC [18]. As a typical photodetector requires optical power no less than 3 dB below the peak to operate properly, the microrings can withstand no more than 2.8 oC of temperature shift assuming 5 nm wavelength separation. To keep the microrings resonating at their appropriate wavelengths designers employ trimming, a technique that dynamically shifts  the microring’s resonant wavelength towards the red through heating, or shifts it towards the blue through current injection. Trimming by current injection causes instability and thermal runaways [20], thus microrings are typically maintained at a constant temperature using the heaters only. Modulators with integrated heaters have been shown to produce error-free 10 Gb/s modulation across a 60 oK temperature variation range, with comparable tuning efficiencies [38]. Because only the heaters are used, the microrings are tuned to temperatures above the maximum temperature that the microprocessor reaches. Unfortunately this means that the heaters need to work continuously to keep the microrings at such high temperature, and at the same time the majority of the heating power is wasted as it dissipates through the package to the heat sink. As a result, it is common for microring heaters to consume upwards of 40 W [20], the majority of which is wasted. To make matters worse, this thermal energy heats up the logic layer to temperatures very close to its operational limit, which forces the system to throttle the cores, thereby reducing performance. The runaway heat also increases the frequency and magnitude of thermal emergencies, and accelerates the aging of the logic die. The solution we propose is rather simple: thermally decouple the 3D-stacked logic die from the photonics die by introducing an insulating layer between them to maintain higher thermal stability and easier trimming. More specifically, our contributions are: • We propose Parka, a nanophotonic NoC that encases the photonic die in a thermal insulator that keeps its temperature stable with low energy expenditure, while minimizing the spatial and temporal thermal coupling between logic and silicon-photonic components. • We quantify the ring heating power consumption for a large-scale multicore under a variety of insulation methods and cooling solutions. • We evaluate the performance impact of thermal decoupling on a multicore running a range of scientific workloads, under realistic physical constraints. TSVs HeatSink ProcessorDie Insulating Layer InsulatingLayer PhotonicsDie& RingHeaters Fig. 1.   Proposed Parka Architecture. Our results indicate that Parka reduces the ring heating power by 3.8-5.4x on average across our workload suite. Moreover, the energy savings allow for providing a higher power budget to the cores, which enables them to run faster. Parka on a radix-16 crossbar allows the multicore to achieve 11-23% speedup (34% max) over a baseline scheme with no insulation, depending on the cooling solution used. II.  PHOTONIC DIE INSULATION WITH PARKA The basic building block of silicon-photonic interconnects is the microring resonators, which are designed to resonate at a specific wavelength to realize add/drop filters and modulators. The microring resonators are very susceptible to temperature changes, because the refractive index of Si changes with temperature, in turn changing the resonance wavelength. Trimming keeps the microrings resonating at their appropriate wavelengths by dynamically shifting the microring’s resonant wavelength towards the red through heating, or towards the blue through current injection. Microrings are typically kept at a constant temperature using the heaters only, as current injection causes instability and thermal runaways [20]. The strong thermal coupling of the logic and photonic dies means that trimming by heating requires that the photonic die is heated to a temperature above the maximum temperature of the logic die.  This ring-heating power is mainly wasted, as it dissipates through the processor stack into the logic layer and eventually through the heat-sink, which is designed to remove heat from the processor stack. This heats the logic layer close to the limits of safe operating temperatures. A thermal emergency occurs when the logic die temperature exceeds the safe operation limits, at which point the cores are throttled or turned off to lower the temperature. Therefore, high ring heating power consumption makes the multicore processor more susceptible to thermal emergencies, and may decrease its performance significantly. Parka reduces the wasted energy and the heating of the logic layer by thermally decoupling the 3D-stacked logic die from the photonics die by placing an insulation layer between them (Figure 1). The insulation layer increases the thermal resistivity of the heat path from the photonics layer to the heat sink, and (a) allows for easier microring trimming by trapping the heat within the photonics layer, (b) reduces the temperature variation in the photonics layer, and (c) minimizes the heating of the logic die induced by the microring heaters. The processor die is placed close to the heat sink to allow better cooling, while an oxidized macro porous Si layer [19] realizes the thermal insulation, as porous Si has 100x lower thermal conductivity than Si [19]. The porous Si layer is 150 um thick, as we find that a thinner layer does not provide adequate thermal insulation. The power delivery and communication between the dies is maintained through high aspect ratio TSVs [12, 28, 35].  Adding the insulation layer is expected to increase the manufacturing cost only marginally. The porous Si insulation layer can be readily integrated into the CMOS process by passing a plain silicon die through a simple electrochemical process that oxidizes it [19]. This silicon die is not subject to the regular yield-induced costs of dies that implement complex logic and require multiple mask exposures and several metal layers, and thus it is significantly cheaper. The addition of the porous Si layer also does not affect the number of TSVs and the number of pins in the package, which together with the logic and photonic dies constitute the dominant cost factors [10,36]. The thickness of the insulation layer impacts the TSVs’ height, but the cost is highly insensitive to it [10,36]. The additional layer will incur 3D-bonding costs, but these will increase the total cost by less than 1.5% [10,36]. Insulation can be achieved also by a 5 um-thick air or vacuum cavity etched between layers, a technique for which prototypes have been successfully manufactured and characterized [35]. Air has a thermal resistivity of 40 m-K/W, which is 40 times higher than porous Si, so it would be an even better insulator. However, this technique is more challenging to employ than oxidized porous Si. Thus, we maintain our conservative assumptions using porous Si insulators and do not consider alternative insulation techniques further. It is important to note that Parka does not depend on the exact insulator technology used. As processes mature and better materials and techniques become available, they can be employed by Parka to achieve even higher power savings than the ones we show in this paper. III.  EXPERIMENTAL METHODOLOGY A.  Ring-Heater Power Consumption Analysis We model a photonic die with microrings tuned to 90 oC (363.15 oK), which is the maximum temperature that the logic die can reach. To calculate the total ring heating power we extend the method by Nitta et al. [20] by estimating the ringheater power consumption while accounting for the heating of the photonic die by the operation of the cores. While one can assume that the heaters are employed to shift the resonant wavelengths of the microrings only momentarily according to the local temperature, keeping a stable temperature for the die as a whole is a more realistic approach [20]. We model a multicore where 50 um-thick logic and photonic dies are 3D-stacked, and separated by a 150 um porous Si insulation layer, as shown in Figure 1. The thermal resistivity is 0.01 m-K/W for Si, and 1 m-K/W for the porous Si insulator [19]. We evaluate the ring-heater power consumption of Parka using the 3D extension of HotSpot [29], a thermal modeling tool based on an equivalent circuit of thermal resistances and capacitances. We evaluate Parka’s impact on the heat transfer rate between dies via a transient thermal analysis at 300 us time steps. The ambient temperature is fixed at 45 oC (318.15 oK). TABLE 1. ARCHITECTURAL PARAMETERS. TABLE 2. WORKLOAD DETAILS. CMP Size Processing  Cores L1 Cache L2 Cache Memory  Controllers Main Memory Networks 64 cores, 480mm2 ULTRASPARC III ISA, up to 5Ghz, OoO, 4-wide dispatch/retirement, 96-entry ROB Split I/D, 64KB 2-way, 2-cycle load-to-use, 2 ports,  64-byte blocks, 32 MSHRs, 16-entry victim cache Shared, 512 KB per core, 16 way, 64-byte blocks,  14 cycle-hit, 32 MSHRs, 16-entry victim cache One MC per 4 cores, uniformly distributed,  1 channel per MC, round-robin page interleaving Optically connected memory [1], 10 ns access SWMR crossbar, radix-16 Our model accounts for the thermal impact of TSVs, as they are highly conductive, and also for the individual ring trimming power required to overcome process variations, as described in [14]. We model a design that employs a total of 76,800 microrings, which are driven by one TSV each. We model high-aspect ratio TSVs with 10 um diameter [28]. All the TSVs together cover a 6 mm2 area, which corresponds to 1.25% of the chip area and contributes only 0.5% to the total cost [10,36]. It is important to note that this is not an overhead that Parka imposes to the system; rather, it is the overhead of 3D-stacking the photonic and the logic dies, and it is incurred by both Parka and the baseline system. B.  Multicore System Performance and Energy Analysis To evaluate the impact of Parka on a realistic multicore system, we model a multicore processor on a full-system cycleaccurate simulator based on Flexus 4.0 [13, 33] integrated with Booksim 2.0 [6] and DRAMSim 2.0 [25]. Figure 2 describes our simulation tool chain. We target a 16 nm technology, and have updated our tool chain accordingly based on ITRS projections [11]. We collect runtime statistics from full-system simulations, and use them to calculate the power consumption of the system using McPAT [16], and the power consumption of the optical networks using the analytical power model by Joshi et al. [14]. The analytical model we use for the power calculation of the photonic components results in similar overall power estimates as DSENT [30], but it also provides an easy breakdown of the power consumed by each one of the nanophotonic components in our network. We estimate the temperature of the chip using the 3D extension of HotSpot 5.0 [29]. The estimated y y DVFS for DVFSfor Temperature Limiting Flexus 4.0 Booksim 2.0 DRAMSim 2.0 RuntimeStatistics PowerCalculations Cores,Cache, MCs McPat 0.8 + Interconnect Analytical Model AccurateLeakage andDynamicPower Th ThermalModeling l M d li HotSpot 5.0 Operating Operating Temperature Fig. 2.   Simulation Flow Chart. Suite NAS appbt SPEC-CPU tomcatv barnes Workload Description Independent equations system solver 32x32x32 grid, 1e-12 tolerance, 8e-4 time  step, 1.2 SSOR iteration relaxation factor Vectorized mesh generation; parallel version  of 101.tomcatv from SPEC-FP 4,096 array size, 10 iterations Barnes-Hut hierarchical N-body simulation 64K particles., 2.0 subdiv. tol., 10.0 fleaves,  2.0 fcells, 0.025 time step, 0.05 softening Particle simulation via adaptive fast multipole 131K particles, two clusters, plummer distr.,  1e-6 precision, 30 steps, 0.025 step duration Eddy & boundary oceanic currents simulator 1026 x 1026 grid, 20,000 meters, 9,600 sec,  1e-7 tolerance Annealed particle filter to track human body 4 cameras, 4 frames, 4,000 particles, 5 annealing layers (simlarge) Molecular dynamics simulation 19,652 molecules, max interactions 3,200,000 Electromagnetic force simulation 768K nodes, degree 2, span 5, 15% remote bodytrack moldyn em3d fmm ocean SPLASH-2 PARSEC Other Scientific temperature is then used to refine the leakage power estimate. We adjust the voltage and frequency of the logic die based on the stable-state power and temperature estimates (Figure 2), and we repeat the process until the system reaches a stable state and additional iterations result in no further changes on temperature and overall power consumption. Using the methodology above, we simulate a 64-core multicore system. By scaling existing core designs down to 16 nm we estimate that 64 cores would require a 480 mm2 die. Table 1 details the architectural modeling parameters. We model realistic multicore systems that employ dynamic thermal management by throttling the voltage and the frequency of the chip to keep it within safe operational temperatures (below 90 oC, i.e., 363.15 oK). The simulated multicore executes a selection of SPLASH-2 and PARSEC benchmarks, and other scientific workloads. The workload parameters are detailed in Table 2. C.  Interconnect and Nanophotonic Parameters We employ a cycle-accurate network simulator based on Booksim 2.0 [6], which models a radix-16 SWMR crossbar. The simulator models a single-cycle router, with 1-cycle E/O and O/E conversions. We assume a 480 mm2 chip, which employs a 10 cm waveguide with a round trip time of 5 cycles. The link latency (1-5 cycles) is calculated based on the traTABLE 3. NANOPHOTONIC PARAMETERS. per Unit 0.3 dB/cm[3] 1 dB 0.5 dB 0.01 dB 1.2 dB 0.1 dB DWDM WG Loss Nonlinearity Modulator Ins. Ring Through Filter Drop Photodetector Total Loss Detector Mod./Demod. Energy (10 GHz) Radix-16 Total 16 3 dB 1 dB 0.5 dB 2.56 dB 1.2 dB 0.1 dB 8.36 dB -20 dBm 150 fJ/bit versed waveguide length. The buffers are 20-flits deep, with a flit size of 300 bits. The maximum core frequency is 5 GHz, and the optical interconnect runs at 10 GHz. We derive the nanophotonic parameters from [1] and detail them in Table 3. The data bus is 300-bits wide (300 wavelengths with 16-way DWDM) powered by an off-chip laser source. Unfortunately, there is little consensus on the optical loss parameters used or projected in literature, as parameters exhibit a variance over 10x across publications. However, the design of an optical interconnect highly depends on the losses of the optical components used. If the off-ring through loss on the radix-16 crossbar was 10x higher (i.e., 0.1dB), the interconnect wouldn’t employ 64-way DWDM, as this would increase the laser power to unsustainable levels. Rather, it would be optimized with a lower DWDM (using more waveguides), keeping the total optical loss (and hence laser power) the same. In our work we limit the network to 16 DWDM because the number of turned-off rings on a single optical path of a crossbar is high, so limiting the DWDM helps keep the total optical loss at reasonable levels. 16-way DWDM has already been demonstrated and it is a widely-accepted parameter. D.  Modeling Cooling Solutions The ring-heating power requirement depends highly on the cooling solution. Aggressive cooling solutions are capable of faster heat removal from the processor stack, which is likely to force the ring heaters to work even harder to keep the photonic layer at the tuned temperature. Therefore, the thermal decoupling that Parka advocates will be more important when better cooling solutions are employed. To evaluate the impact of Parka across cooling solutions we model both forced-air cooling (convective thermal resistance Rconv = 0.25 K/W) and a liquid cooling solution (Rconv = 0.15 K/W [27]). For the liquid cooling solution we assume that microchannels facilitate forced convective interlayer cooling with singlephase fluids, in particular water. While other single-phase fluids with higher thermal capacitance exist, they are toxic and thus impractical to deploy. We model high-aspect ratio TSVs with 10 um diameter [28], located and etched within 100 umwide microchannel walls as in [26]. We assume uniformly distributed microchannels, and equivalent fluid flow rate through each channel in the same layer. Although variation of the fluid flow due to nonuniform heat flux can exist, variations stay below 2% for single-phase flows and have negligible impact on the cooling system’s performance [26]. The fluid pump and valve consume 1.3 W per 10 ml/min flow, and the power is linear to the volumetric fluid flow [26]. IV.  EXPERIMENTAL RESULTS A.  Impact on the Ring-Heating Power Consumption Parka thermally decouples the photonics die from the processor die using a porous Si insulating layer which reduces the thermal fluctuations caused by the processor layer, and traps the heat in the photonics die allowing for easier trimming. In this section we evaluate the ring-heating power consumption of Parka on a 64-core processor, and compare it against an architecture with no insulation. ) s ʅ 0 0 3 ( ( p e t s e m m i T 140 120 100 80 80 60 40 40 20 0 Parka No insulator 65 75 85 Temperature (oC) Temperature ( C) 95 Fig. 3.   Transient analysis of temperature fluctuations in the photonics die. First we evaluate the thermal shielding effect of the insulating layer by observing the temperature variation in the photonics die resulting from temperature fluctuations in the processor die. We increase the power consumption in the processor layer (from its idle level) to its maximum allowed level, and observe the temperature change in the photonics layer (Figure 3). The processor die stays at 66 oC (339.15 oK) when in the idle state, and its temperature reaches 90 oC (363.15 oK) rapidly when it is turned on (~18 ms). The temperature of the photonics die closely tracks the temperature change of the processor die when there is no insulation. However, for Parka, it takes twice as long for photonics layer to reach 90 oC (Figure 3), because of the thermal shielding effect of the insulating layer. Note that the insulating layer not only shields the fluctuations towards the higher temperature levels, but it also shields from the dips in the temperature. Overall, Parka allows for easier trimming because it shields the photonics layer from the short temperature fluctuations occurring in the logic silicon layer. Thermally decoupling the photonics layer from the rest of the processor stack allows for trimming with less ring heater power consumption, because it does not allow the heat generated by the ring heaters dissipate through the heat sink easily. The insulating layer increases the thermal resistance on the heat path to the heat sink, so it traps the heat within the photonics die. Therefore, Parka’s ring-heaters can bring the whole photonics die to a stable temperature level which is higher than the maximum execution temperature at the processor layer with less power. Figure 4 shows a scenario where we present both the shielding and heat trapping effect of Parka. Figure 4.a shows a snapshot (at time t0) of the thermal map of the processor die when running a real workload (appbt). We assume that at time t0 all processors stop, and they only dissipate leakage power until time t1. We estimate that the processor die leakage power is ~30 W when idle. Figure 4.b shows the temperature maps of the photonics layer at time t1. We observe that the photonics layer stays at a higher temperature for Parka compared to no insulation, as it retains the heat due to the insulating layer. In the example in this figure we assume that the ring heaters are also off until time t1. At time t1, the ring heaters are turned on to bring the photonics layer to a stable 90 oC (363.15 oK), and Figure 4.c shows the power distribution of these ring heaters. We observe that Parka requires less ring-heating power. There are two reasons for this: first, the photonics layer is at a   higher temperature at time t1, so there is a smaller temperature difference (to 90 oC) to cover. Second, it is easier to close this temperature difference with Parka because the heat generated by the ring heaters stays within the photonics die.  The amount of ring-heating power required to keep the photonics layer at a stable 90 oC highly depends on the power consumption of the processor die. When the processor die is idle, the ring heaters have to work harder to warm up the photonics die. In Figure 5, we show the ring-heating power for a range of power consumption levels of the processor die. We observe that for every processor die utilization level, Parka consumes less ring-heating power than the no-insulation case. The maximum amount of ring-heating power required for Parka is 3.5x lower than the maximum ring-heating power required without insulation. It is important to note that the ring-heating power requirement highly depends on the cooling solution. Better cooling solutions are capable of removing the heat from the processor stack at higher rates, which may force ring heaters to work even harder to keep the photonics layer warm. Therefore, the thermal decoupling will be more important when better cooling solutions such as liquid cooling are employed. To observe this effect we repeat the same ring-heating power estimation with a liquid cooling solution (liquid cooling Rconv = 0.15 K/W [27], whereas forced-air cooling Rconv = 0.25 K/W).  We observe that with liquid cooling the operational temperature at the processor layer stays under 90 oC when the processor die consumes up to 250 W (Figure 6.a), while forced-air cooling can sustain at best only up to 130 W and passive cooling less than 100 W. More importantly, we observe that the magnitude of the thermal fluctuations on the processor layer is higher under an aggressive cooling solution, because higher utilization levels are permitted within the power budget, and the idle temperature is lower due to better cooling. Figure 6.b shows the instructions per second attained during the execution of a given code fragment of an application (appbt) when liquid or forced-air cooling are employed. We observe that liquid cooling allows higher performance, but also that the temperature under liquid cooling fluctuates between 54–90 oC, while for the same exact execution segment run under forced-air cooling the temperature fluctuates between 68–90 oC. Thus, the temperature fluctuation range on the simulated multicore is 14 oC wider with liquid cooling compared to forced-air cooling when running the same code fragment (Figure 6.b).  As processor temperatures fluctuate during execution, the ring-heaters have to step in to keep the photonics layer at a stable temperature. We analyze this effect by running a collection of diverse workloads on our simulated multicore system and calculating the average ring-heating power consumed by each application (Figure 7). We observe that the temperature fluctuations are higher when running memory-intensive workloads (e.g., bodytrack, em3d, ocean, appbt), hence the ring-heating power consumption is also higher. On average ring heaters consume 16.9 W (22.4 W maximum) when there is no insulation. Parka allows for easier trimming by shielding from short fluctuations and trapping the heat, so it consumes on average 3.8x less ring heating power (4.4 W on average). a.) Processor Die @ t0 c.) Ring Heater Power Map b.) Temperature @ t1 373 46 0K W 364 356 37 28 348 340 340 15 11 11 No Insulation 331 7 323 318 4 1 Parka Parka Fig. 4.   Case study: Impact of thermal insulation on the photonics layer temperature and the ring-heating power consumption. Parka Parka (liquid cooling) 220) 0 200 180 160 140 120 100 80 60 40 20 0 No Insulator No Insulator (liquid cooling) w e r ( W ) a e e t e r o P 30 30 80 80 130 130 Logic Layer Power (W) 180 180 230 230 H Fig. 5.   Ring -Heating Power vs. Processor Die Power 1 1 1.2 S S P ) Liquid Cooling Forced Air Cooling 90 0C 90 0C 0.8 e S S c d n o I ( 90 0C 0.4 0.6 t c c i n o s e P r 0 0 0.2 I n r t s u 54 0C 68 0C 0 50 100 Time Step (300 us) 150 200 100 Passive Cooling Forced Air Cooling Liquid Cooling 80 90 r e ( C ) 60 70 e T T m e p r a t u 40 50 0 50 100 150 Power (W) 200 250 300 Fig. 6.   (a) Processor die temperature vs. power consumption, (b) Instructions per second trace and thermal variation for the same execution segment (appbt).                 ) W ( r r e w o P g n i t a e H g g i n R 40 35 35 30 25 20 15 10 5 0 0 Parka  Parka (liquid cooling) No Insulator No Insulator (liquid cooling) w/o Insulator w/ Insulator Processor Die Photonics Die Photonics Die (fixed temperature) Tprocessor=90 0C Tprocessor=74 0C 366 366 361 356 356 351 346 341 336 333 Fig. 7.   Average ring-heating power consumption of real-world applications The liquid cooling solution keeps the processor cooler and allows for cores to run faster, however this results in higher temperature fluctuations at the photonics layer. On top of that, with better heat dissipation from the photonics layer, ring-heaters have to consume more power to keep the photonics layer at a stable temperature. Figure 7 shows that the ring heaters have to consume 28.2 W on average when there is no insulation and a liquid cooling solution is employed. However, employing an insulating layer in this case reduces the ring-heating power consumption by 5.4x on average (5.2 W),. Thus, Parka is essential when using aggressive cooling solutions. B.  Impact on the Processor Temperature Ring heaters warm up and keep the photonics die at a slightly higher temperature than the maximum operating temperature of the processor [20]. However, while heating the photonics die, the ring heaters also heat the processor die when there is no insulation. Heating the processor die forces it to operate close to its maximum operating temperature, even when it is idle. In this case, even a small increase in the utilization can cause a temperature spike which pushes the processor out of the safe operating limits causing it to throttle, and reducing performance. Thus, in the absence of an insulating layer the processor becomes highly vulnerable to thermal emergencies. On the other hand, ring heaters consume 3.8x less power on average with Parka, and thus the processor layer remains cooler, because the overall power consumption in the processor stack is lower (leakage power is exponentially related to temperature). For example, Figure 8 shows that when compute components consume 90 W at the logic layer, the ring heaters consume 36 W when there is no insulation, but only 7.2 W with Pheater=36 W Pheater=7.2 W Fig. 8.   Parka’s impact on the processor die temperature. Parka. As a result, the logic layer stays at 74 oC (347.15 oK) with Parka, while it reaches ~90 oC without insulation.  The ring heaters keep the processor die very close to the limit of safe operating temperature, so any increase in the processor utilization can push the processor into thermal emergencies. We present such an example in the execution window shown in Figure 9.a. The activity increase around time steps 12 and 62 push the processor temperature over 90 oC when there is no insulation, whereas with Parka the processor stays cooler and avoids the thermal emergencies. When running real applications, the processor runs into thermal emergencies up to 19% of the execution time (2% on average) when there is no insulation (Figure 9.b). The cores need to be throttled or completely turned off during a thermal emergency to allow for the processor to cool down and avoid permanent damage, so we expect that these thermal emergencies will significantly reduce the processor ’s performance. In contrast, Parka’s processor die largely avoids thermal emergencies, and only experiences them for less then 1% of the execution time (Figure 9.b). C.  Impact on a Realistic Multicore Under realistic thermal and power constraints, the dynamic thermal management system in the processor throttles the cores to keep the chip within a safe temperature. The insulating layer, however, reduces the ring-heating power and results in a cooler chip, causes less core throttling, and provides higher performance. Overall, Parka reduces the ring-heating power consumption by 3.8x, which allows for the cores to run faster. As a result, the processor with the insulating layer runs 11% faster Parka No Insulator Processor Die Parka No Insulator 93 88 83 83 78 ) C o ( e r u u t a r e p m m e 73T 68 68 0 20 40 60 80 Time Step (300 ʅs) p ( ʅ ) 100 120 ( i i ) i t s c e e % m 25%m 20% 15% 15% 10% 5% 5% 0% n e g m m e a E r l m r e e h T Fig. 9.   Temperature trace (appbt) presenting thermal emergencies in a multicore, and the percentage of execution time spent under thermal emergencies.               No Insulator Parka No Insulation (liquid cooling) Parka (liquid cooling) p u u d e e p S 1.6 1.4 1.2 1 1 0.8 0.6 0.4 0.2 0 Fig. 10.   Realistic Multicore Performance with Parka. on average (18% maximum) than the processor without the insulating layer (Figure 10). The ring-heating power consumption is higher when an aggressive cooling solution (e.g., liquid cooling) is employed, so the power savings of Parka are also higher. With liquid cooling, Parka outperforms the processor without the insulation by 23% on average (34% maximum). V.  RELATED WORK Silicon photonics are emerging as a promising technology for high-bandwidth, low-latency, and energy-efficient communication in multicore processors. Many different topologies that have been proposed, such as Corona [32] and many others [31,23,22], implement a nanophotonic MWSR crossbar topology for on-chip communication. Firefly [24] uses partitioned SWMR optical crossbars to connect clusters of electricallyconnected mesh networks. Batten et al. [1,2] connect a manycore processor to DRAM memory using SWMR crossbars.  The high laser and ring-heating power consumption reduce the energy efficiency of the nanophotonic interconnects. Zhou et al. [37] identify the constant laser power consumption as an inefficiency, and propose a mechanism to increase average channel utilization by controlling active splitters to tune bandwidth on a binary tree network. Kurian et al. [15] propose an optical SWMR crossbar and electrical hybrid network, and mention that a Ge-based laser can be controlled to improve the laser energy efficiency. Joshi et al. [4] propose a scheme to distribute laser power across multiple busses based on the utilization levels to provide higher bandwidth and achieve higher energy efficiency. Zhang et al. [34] investigate the temperature gradients for the multicores with photonic interconnects, and propose a temperature-aware job allocation scheme to minimize the temperature gradients among the ring resonators. Demir and Hardavellas [7,9,8] advocate laser gating as an effective technique to eliminate the energy waste of laser sources and improve the energy efficiency of optical interconnects. All these works are orthogonal to Parka and can be used in addition to Parka to achieve even higher energy efficiency. Parka covers the photonic die with an insulation layer that keeps its temperature stable with low energy expenditure, while minimizing the spatial and temporal thermal coupling between logic and silicon-photonic components. There are several techniques that can be used to resolve the thermal challenges of the silicon microring resonator devices. Methods to reduce the thermal dependence of microrings to tolerable levels include athermalization using negative thermooptic materials or the embedment of the microring in a thermally-balanced interferometric structure. However, it is challenging to integrate the necessary polymer and TiO2 materials into a CMOS-compatible fabrication process, and the interferometric structure still suffers from susceptibility to fabrication tolerances, increases the footprint of the microring, and it is challenging to adapt the technique to larger microring switch fabrics [21]. Thus, control-based techniques that aim to detect and react to the resonance shift due to thermal fluctuations are preferable, and several prototypes have been shown to withstand thermal variations across a wide temperature range up to 32–60 oK [38]. It is beyond the scope of this paper to provide a detailed review and comparison of such techniques. However, the interested reader could refer to some of the excellent surveys on this topic that are available in the literature, e.g., Padmaraju and Bergman [21]. VI.  CONCLUSION Silicon-photonics are rapidly becoming a serious contender for energy-efficient on-chip interconnects at future process nodes. However, current designs are primarily based on microrings, which are highly sensitive to temperature. As a result, current silicon-photonic interconnect designs expend a significant amount of energy heating the microrings to a designated narrow temperature range, only to have the majority of the thermal energy waste away and dissipate through the heat sink, and in the process of doing so heat up the logic layer, causing significant performance degradation to the cores and inducing thermal emergencies. To address this problem we propose Parka, a nanophotonic NoC that encases the photonic die in a thermal insulator that keeps its temperature stable with low energy expenditure, while minimizing the spatial and temporal thermal coupling between logic and silicon-photonic components. Our results indicate that Parka reduces the ring heating power by 3.8-5.4x on average across our workload suite, depending on the cooling solution used, thereby eliminating a significant source of power waste in silicon-photonic interconnects. Moreover, by eliminating the microring-induced heating of the logic layer, Parka allows for providing a higher power budget to the cores, which enables them to run faster. Parka on a radix-16 crossbar allows the multicore to achieve 11-23% speedup (34% max) over a baseline scheme with no insulation, depending on the cooling solution used. We also observe that as cooling solutions become more aggressive in future technologies, the impact and importance of Parka increases. VII.  ACKNOWLEDGEMENTS This work was generously funded by NSF CAREER award CCF-1453853. "
"A Low-Overhead, Fully-Distributed, Guaranteed-Delivery Routing Algorithm for Faulty Network-on-Chips.","This paper introduces a new, practical routing algorithm, Maze-routing, to tolerate faults in network-on-chips. The algorithm is the first to provide all of the following properties at the same time: 1) fully-distributed with no centralized component, 2) guaranteed delivery (it guarantees to deliver packets when a path exists between nodes, or otherwise indicate that destination is unreachable, while being deadlock and livelock free), 3) low area cost, 4) low reconfiguration overhead upon a fault. To achieve all these properties, we propose Maze-routing, a new variant of face routing in on-chip networks and make use of deflections in routing. Our evaluations show that Maze-routing has 16X less area overhead than other algorithms that provide guaranteed delivery. Our Maze-routing algorithm is also high performance: for example, when up to 5 links are broken, it provides 50% higher saturation throughput compared to the state-of-the-art.","A Low-Overhead, Fully-Distributed, Guaranteed-Delivery Routing Algorithm for Faulty Network-on-Chips Mohammad Fattah1 , Antti Airola1 , Rachata Ausavarungnirun2 , Nima Mirzaei3 , Pasi Liljeberg1 , Juha Plosila1 , Siamak Mohammadi3 , Tapio Pahikkala1 , Onur Mutlu2 and Hannu Tenhunen1,4 1Depar tment of Information Technology, University of Turku, Turku, Finland 2Electrical and Computer Engineering Depar tment, Carnegie Mellon University, Pittsburgh, PA 3School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran 4Depar tment of Electronic Systems, Royal Institute of Technology– KTH, Stockholm, Sweden {mofana, ajairo, pakrli, juplos, aatapa, hanten}@utu.ﬁ {rachata, onur}@cmu.edu n.mirzaei@ut.ac.ir, smohammadi@ece.ut.ac.ir ABSTRACT This paper introduces a new, practical routing algorithm, Mazerouting, to tolerate faults in network-on-chips. The algorithm is the ﬁrst to provide all of the following properties at the same time: 1) fully-distributed with no centralized component, 2) guaranteed delivery (it guarantees to deliver packets when a path exists between nodes, or otherwise indicate that destination is unreachable, while being deadlock and livelock free), 3) low area cost, 4) low reconﬁguration overhead upon a fault. To achieve all these properties, we propose Maze-routing, a new variant of face routing in on-chip networks and make use of deﬂections in routing. Our evaluations show that Maze-routing has 16X less area overhead than other algorithms that provide guaranteed delivery. Our Maze-routing algorithm is also high performance: for example, when up to 5 links are broken, it provides 50% higher saturation throughput compared to the state-of-the-art. Categories and Subject Descriptors C.4 [Computer Systems Organization]: Performance of Systems— Fault tolerance General Terms Algorithms, Performance, Reliability, Design Keywords Network-on-chips, permanent fault, link failure, routing algorithm, face routing, deﬂection routing, distributed algorithms 1. INTRODUCTION Aggressive scaling of transistor feature size comes with beneﬁts and curses. The key beneﬁt is the ability to integrate many more computational and storage components, including many processors, cache slices, memory controllers, and specialized accelerPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM 978-1-4503-3396-2/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2786572.2786591. ators, on the same die, which leads to greatly increased computational power in a System-on-a-Chip (SoC). To take advantage of this computational power effectively, these integrated components need to be connected to each other with an effective communication substrate. Network-on-chips (NoCs) are a promising way to interconnect on-chip components as they are shown to be more scalable than traditional bus-based interconnects [9, 14, 23, 41]. A major curse of aggressive transistor scaling is the reduced reliability of the on-chip components [8]. For example, fault mechanisms such as device wear-out caused by oxide breakdown, electromigration, and thermal cycling [8, 10], are expected to be exacerbated in future technology nodes, leading to more failed components during operation, as the SoC device ages [13]. Hence, it is critical to design both the components and the interconnect to operate in the presence of faulty components.1 While a faulty computational or storage component (e.g., a core or a cache slice) degrades SoC performance, a fault in a networkon-chip component (e.g., a router or a link) can be even more serious as the NoC provides the communication substrate between multiple components. Such a fault can potentially cripple system performance and perhaps even more severely become a single point of failure [19]. It is projected, therefore, that NoCs need to tolerate at least tens of randomly-located failures [32], in order to keep up with fault-tolerant processor designs. A (large) number of randomly-located failures can easily convert a regular network topology (with a simple routing algorithm) into a complicated maze of routers connected by links with some connections (i.e., routers or links) missing [3]. In such an SoC with some faulty NoC components, it is therefore critically important to have an efﬁcient routing algorithm that can deliver packets to destinations through the available links and routers (or otherwise ﬁnd out the destination is unreachable), in order to guarantee continued operation. We posit that a practical, effective and efﬁcient routing algorithm that can tolerate NoC faults should satisfy the following properties. First, guaranteed delivery: it should guarantee to deliver a packet to its destination when a path between the source and the destination exists or else indicate that the destination is unreachable, regardless of the number and location of faults. We also call this property full (fault) coverage. Second, it should be fully distributed: it should have no centralized component in ﬁnding non-faulty paths through the network to deliver a packet because a centralized component is not only a scalability bottleneck but also can constitute a single 1Faults can be permanent, transient and intermittent [24]. While we do not target a particular category of faults in this work, our discussion is focused more on permanent faults, i.e., faults that stay after they appear until the faulty components are repaired. point of failure in a fault-tolerant system. Third, it should have low hardware area cost, as any additional area overhead increases not only implementation cost but also vulnerability of the SoC to faults. Finally, it should have low reconﬁguration overhead: when a new faulty component is identiﬁed, the network should continue normal operation and adapt the routing mechanisms without affecting the system and applications running on it. We ﬁnd that, while some past fault-tolerant routing algorithm designs satisfy one, two or at most three of these goals, no previous work provides an algorithm that satisﬁes all four requirements. Our goal in this work is to devise a new, practical fault-tolerant routing algorithm that achieves all of these four goals. To this end, we develop a new algorithm called Maze-routing, taking inspiration from the idea of face routing, which was originally proposed for ad-hoc wireless networks [11]. Our algorithm, called Mazerouting, provides guaranteed delivery in a fully-distributed manner at low cost and low reconﬁguration overhead. We make several key choices in our design. First, to keep the algorithm simple and fully-distributed, each router makes standalone decisions based on limited local information. While this sometimes leads to routing via suboptimal paths, it greatly reduces hardware complexity and cost without compromising fault coverage. Second, to eliminate any need for routing tables, we use an algorithmic approach to routing that is based on face routing. This reduces the hardware cost and complexity in each router. Third, by eliminating the need for routing tables and ensuring that our algorithm is fully-distributed, we achieve the goal of low reconﬁguration overhead as each router discovers feasible paths on the ﬂy based only on local information without the need for global information or routing table updates. Finally, to avoid any deadlocks (and livelocks) when routing with limited connectivity, we make use of deﬂection routing mechanisms [16] that have been proven to be deadlock- and livelockfree [15, 16]. While our four major design choices can potentially (but not always) lead to routing via suboptimal paths in the network, resulting in slightly increased network latency under some conditions (which we evaluate in Section 4.2), they 1) greatly reduce hardware complexity and cost, 2) enable the four goals in the design of a fault-tolerant routing algorithm, and 3) lead to increased saturation throughput with our algorithm compared to state-of-theart fault-tolerant routing algorithms as face routing (and, hence, Maze-routing) can better exploit the NoC path diversity (which we evaluate in Section 4.2). Maze-routing works as follows at a high-level. A router tries to forward each packet to a productive output port2 , as long as possible. If this is possible, the packet is considered to be in normal mode. If the packet enters a router with no productive output port (i.e., encounters an obstacle due to faulty NoC components), the packet traverses around the faulty region hop by hop (called traversal mode) until it enters a node where it is safe to revert back to normal mode. This procedure continues until the packet reaches its destination or one of the routers it visits detects that the destination is unreachable. We describe the details of our algorithm, including exact conditions for entry and exit into the traversal mode and proof of its delivery guarantee, in the rest of the paper (Sections 3.2 and 3.3). We make the following contributions in this paper: • We propose the ﬁrst fault-tolerant routing algorithm, Mazerouting, for mesh-based NoCs that provides all of the following properties at the same time: 1) fully-distributed with no centralized component, 2) guaranteed delivery with livelock and deadlock freedom, 3) low area cost, 4) low reconﬁguration overhead upon a fault (§3.2). We made the source code of our algorithm and our simulator publicly available [1]. • We prove that our algorithm ﬁnds the path to destination, if one exists, regardless of the number and location of faults in the NoC (Section 3.3). We show that our algorithm can also detect when no such path exists, i.e., when the packet cannot reach its destination 2A productive output port is one that moves the packet closer to its destination. due to disconnected partitions in the network (Section 3.4). • We show that our proposed design avoids deadlocks (and livelocks) when routing with limited connectivity, via the use of deﬂection routing mechanisms [16] that have been proven to be deadlockand livelock-free [15, 16] (Section 3.5). • We extensively evaluate the hardware cost, performance and fault tolerance capability of Maze-routing in comparison to other works that aim to provide guaranteed delivery, with three major conclusions. First, our HDL synthesis results show that the area overhead of Maze-routing is 16 times smaller than the mechanism with the smallest routing table in literature (Section 4.1). Second, our performance evaluation shows, among other things, that Mazerouting is also high performance: for example, when up to 5 links are broken, it provides 50% higher saturation throughput compared to the state-of-the-art [3, 32] (Section 4.2). Third, Maze-routing incurs much smaller reconﬁguration overhead than the state-of-theart when a new fault is discovered in the NoC (Section 4.3). 2. MOTIVATION AND RELATED WORK There is an enormous amount of research carried out in detection and tolerance of different types of faults (permanent, transient, etc.) affecting operation of NoCs. In the following, we motivate four goals of this work in the design of a practical fault-tolerant routing algorithm, by reviewing some of the existing works. However, tolerating non-permanent faults, as well as proposing fault detection techniques fall beyond scope of this paper. As such, we narrow down our literature review to existing routing algorithms for tolerating permanent faults in NoC links and routers, a summary of which is reported in Table 1. Table 1: Comparison of state-of-the-art. Desirable characteristics are in bold. Reconﬁguration O(Area) O(Reconf.) Zhang et al. [43] LBDR [35] d2 -LBDR [7] OSR-Lite [38] TOSR [5] BLINC [25] uLBDR [36] Wachter et al. [39] Fick et al. [19] Face routing [11] FTDR-H [18] uDIREC [32] ARIADNE [3] Maze-routing Coverage few moderate moderate moderate moderate moderate high high high high high full full full fully dist. central central central distributed distributed central distributed distributed fully dist. fully dist. central distributed fully dist. low low low low high high high high high excessive high high high low on the ﬂy N/A N/A moderate fast fast N/A slow slow on the ﬂy fast excessive slow on the ﬂy Goal 1: Full Fault Coverage. As mentioned before, a large number of randomly placed failures may occur in NoC components, which may lead to disconnected (unreachable) destinations. As such, this work sets its ﬁrst goal as to achieve full (fault) coverage, which is to guarantee to deliver a packet to its destination when a path between the source and the destination exists or else indicate that the destination is unreachable, regardless of the number and location of faults. However, most of the past works only support a limited number and placement of faults [43]. For instance, the routing algorithm in [43] handles only one faulty router/region. On the other hand, some works (e.g. [11, 19, 36, 39]), denoted as high coverage, overcome a high number of faults, but do not guarantee a full coverage in all circumstances and/or cannot detect or tolerate unreachable destinations. Works with moderate coverage are also not limited to only few failures, but they place strict limitations on tolerable fault patterns as the number of faults grows. Some researchers (e.g. [7, 32, 34–36, 38]) propose methods with full/high/moderate coverage, where upon new failures, a central controller collects the fault information, computes the new conﬁguration, and distributes it back among routers. Such centralized methods suffer from two main challenges. First, the central controller can easily become the single point of failure as it is on the critical path of the reconﬁguration process [5]. Moreover, there needs to be an extremely reliable means for fault information collection, and routing distribution, usually addressed by use of TMR3 -based methods [32]. Thus, centralized approaches may become impractical and/or expensive to tolerate run-time faults. Goal 2: Fully Distributed Operation. Several researchers propose distributed reconﬁguration methods [3, 5, 19, 25, 39], where new failures are handled through a cooperative reconﬁguration process of routers. Though the reconﬁguration process is carried out without any central component, these methods are prone to failure within their reconﬁguration hardware/network. That is, a failed reconﬁguration unit in any single router cripples the functionality of the whole system, or a portion of it. For instance, [3, 5, 25, 39] require the use of TMR-based methods and/or error-correcting codes to shield their reconﬁguration process from run-time failures. This introduces a single points of failure in such otherwise distributed methods. We posit that a practical fault-tolerant method must work in a fully-distributed manner: any failed component of the network should have only local impact and there should not be a single point of failure in the network. Few works, including ours, propose methods with this property. The ability of the network to route around failures and ﬁnd the path to destination is an innate ability of our proposed routing algorithm. There is no separate reconﬁguration unit, and a failure in any parts of the network, including our algorithm instantiations, results only in the disabling of speciﬁc network link(s). Goal 3: Low Area Overhead. The imposed area overhead of a routing algorithm is of a great concern. The imposed overhead adds up not only to the implementation costs and power dissipation, but also to the vulnerability of the algorithm to run-time faults. However, most of the works that overcome a high number of faults make use of one or several routing tables [3,5,18,19,25,32,33,39]. For instance, routing tables of each node in a 8x8 network may need 256 bits [3], ∼500 bits [5, 25], or even ∼8K bits [39] to store healthy paths to destinations. As we will show in Section 4.1, routing tables signiﬁcantly contribute to the area overhead of fault-tolerant algorithms. Specially, since they need to have ﬁve read ports for simultaneous accesses of different ports of a mesh router. As a failed routing table or reconﬁguration logic cripples the functionality of the whole router, their imposed area overhead directly translates to increased fault probability within the whole router. Goal 4: Low Reconﬁguration Overhead. Finally, but also importantly, a practical fault-tolerance algorithm should provide uninterrupted operation of the network once some components become disabled. Fast reconﬁguration becomes a necessity especially with the use of aggressive online testing, where network components (e.g. network link) become unavailable not only because of detected faults, but also periodically and frequently during their online testing [25, 27]. As a result, it has attracted attention newly as studied in recent literature [5, 25, 38]. However, most of the existing works with moderate/high/full fault coverage suffer from long reconﬁguration phases [3, 19, 32, 39], during which they interrupt the normal operation of the network and pause the delivery of packets until the end of reconﬁguration. For instance, in a 10x10 network, upon a new fault occurrence, it takes up to 10K cycles [3], ∼ 100K cycles [39] or even ∼ 100ms [32] to reconﬁgure the network. As opposed to works with fast reconﬁguration, works with on the ﬂy reconﬁguration, including this work, have no separate reconﬁguration phase: a new path to destination is dynamically calculated per packet as the packet travels through the network. Summary. As shown in Table 1, to the best of our knowledge, this is the ﬁrst work that can satisfy all of the four mentioned goals. Our Maze-routing algorithm guarantees to deliver a packet to its destination when a path exists and to indicate it when destination is unreachable, i.e. it provides full coverage. In addition, our routers do not require any routing table, work in a fully distributed manner, and forward packets through the faulty network on the ﬂy. 3Triple Modular Redundancy. 3. MAZE-ROUTING We ﬁrst provide deﬁnitions and assumptions needed for the description and proof of our Maze-routing algorithm (§3.1). Afterwards, we introduce our proposed fully-distributed algorithm (source-code available at [1]) for fault-tolerant routing in meshes (§3.2), and prove that it guarantees to ﬁnd a path when exists (§3.3). Further, we extend our algorithm to detect when the network is partitioned and the destination is unreachable (§3.4). Then, we explain our use of deﬂection-based router design to provide deadlock freedom, and changes required to keep the original properties of our algorithm (§3.5). Finally, we provide a qualitative comparison between this work and some of recent related works (§3.6). 3.1 Preliminaries Fault Model: as mentioned above, we propose our fault-tolerant routing algorithm for mesh-based faulty NoCs, as shown in Fig. 1 (a). We model permanent failures in transistors of network components as one or several disabled links [3]. Accordingly, a failed router is modeled by disabling all of its four links. Figure 1: (a) Architectural diagram of a 4x4 mesh NoC with faulty routers and links. (b) The equivalent planar graph. Planar Graph: In graph theory, a graph (G) is called planar if one can draw it on a plane without having edges crossing each other [42]. Accordingly, a (potentially faulty) mesh NoC can be represented as a planar graph, shown in Fig. 1 (b). Note that in this work we only consider mesh topologies. However, one can modify our algorithm to ﬁt in other topologies, as long as the topology can be represented as a planar graph. Face: A planar graph partitions the plane into regions (faces) that are bounded by edges of the graph. Each connected component of a graph may have several inner faces (F1–F4 in Fig. 1 (b)), and has one outer face. Right/Left hand rule: Assuming a packet entering a node (e.g. (0, 1) in Fig. 1) from a direction (e.g. south), right/left hand rule (denoted as (cid:31) / (cid:30)) decides that the packet exits the node from the ﬁrst output on the packet’s right/left side (e.g. east/north). Note that following either (cid:31) or (cid:30) rules makes the packet traverse the boundary of inner (outer) faces in clockwise (counterclockwise) and counterclockwise (clockwise) directions, respectively. PRO P ERTY 1 : Let src and dst be nodes of a planar graph G with an existing path between them. Starting from src, by traversing the face F underlying line(src,dst) , the packet will deﬁnitely intersect line(src,dst) at some point (p) other than src [20]. 2 For instance, starting from src in Fig. 1 (b), traversing the underlying face (F1) in both directions will intersect line(src,dst) in point p. Note that p can be on either a node or an edge of the face. We refer interested readers to [20] regarding the proof of PRO P ERTY 1. 3.2 Maze-routing Algorithm Algorithm 1 shows the pseudo-code of our distributed routing algorithm. Our algorithm routes a packet from source node (src) to its destination (dst). As listed in Table 2, a packet carries along 4 new pieces of data. The ﬁrst two are required for guaranteeing the delivery of packets, while the two other are meant for detecting unreachable destinations (§3.4). MDbest stores the closest (Manhattan) distance (MD) to dst that the packet has reached so far.4 M ode denotes the routing mode used for the packet. Initially, the packet is routed in normal mode. In some circumstances, a packet might enter the traversal mode, wherein, the packet follows either the right hand ((cid:31)) or left hand ((cid:30)) rules. Algorithm 1 The basic Maze-routing algorithm. Inputs: Packet header as listed in Table 2, src and dst. cur indicates the coordinates of the current router. Productive output ports are calculated based on cur and dst. Healthiness of output ports is given by online testing modules. Outputs: dirout : the direction in which the packet is forwarded. Algorithm might also update values of packet header. 1: if cur = dst then dirout ← LOCAL; 2: 3: else if MDbest = MDcur,dst and ∃(healthy & productive output) then MDbest ← MDbest − 1; 6: mode ← normal; 4: dirout ← one of the healthy and productive outputs; 5: 7: else if mode ∈ traversal then dirout ← The direction given by (cid:31) / (cid:30) rule; 8: 10: mode ← (cid:31) / (cid:30); dirout ← The ﬁrst output in the left/right of line(cur,dst) ; 11: 9: else 12: end if 13: return dirout ; Table 2: Packet header ﬁelds needed by our algorithm. MDbest mode Ntrav D IRtrav Valid values integers ≥ 0 normal (N ), or traversal = {(cid:31), (cid:30)} node coordinates {↑, →, ↓, ←} MDsrc,dst Initial value Notes §3.2 §3.2 §3.4 §3.4 normal – – as shown in Fig. 2, a packet that is injected to network from src(0,0) , destined to dst(3,2) . Starting from src (MDbest = 5, and mode = normal), the router looks for at least one productive and healthy output (line 3 of Alg. 1). There are two candidates: north and east directions. The router arbitrarily chooses one (dirout ← north in our example), forwards the packet to north and decrements MDbest (lines 4–6). The same happens in the next router(0,1) and the packet is forwarded to north router(0,2) (with MDbest = 3 and mode = normal). Now, in the current router(0,2) , the only productive output (east) is disabled (because router(1,2) is faulty) and the packet is not in traversal mode. Hence (according to lines 9–11), without any changes to the MDbest value, the packet enters traversal mode and starts to traverse face F2 using either of the hand rules (mode ← (cid:31) in this example, determined randomly). The packet is forwarded to the north direction (the ﬁrst healthy output to the left of line(cur,dst) – line 11 of algorithm). Traversing the face with (cid:31) rule (lines 7–8), the router(0,3) forwards the packet to the east direction. Now in router(1,3) , MDbest = 3 happens to be equal to MDcur,dst and there exists a productive and healthy output (east direction). So, the packet exits traversal mode (lines 4–6), decrements MDbest and follows the productive output (east). Now, there are two productive outputs in router(2,3) to forward the packet (east and south directions). Assuming east direction is taken, the next router(3,3) forwards the packet to the only productive output (south). Thus, the packet reaches its destination. While the packet is in normal mode, each router tries to forward it to a productive output port (lines 3–6), until the packet reaches its destination. However, during normal mode, the packet might enter a router with no productive output port. In this case (line 9 onwards), the packet enters the traversal mode and starts traversing the face F underlying the line(cur,dst) . This is implemented by taking the ﬁrst healthy output to the left or right of the line(cur,dst) (line 11) and following the (cid:31) and (cid:30) rules5 , respectively, in the next routers (line 8). In this work, we select the hand rule ((cid:31) or (cid:30)) randomly. This does not void the full coverage guarantees of our algorithm (§3.3), but can potentially lead to suboptimal paths.6 The packet stays in traversal mode until it enters a router with 1) MDcur,dst = MDbest and 2) at least one productive and healthy output towards dst. In other words, a packet reverts to normal mode when it enters a router that can forward the packet closer to its destination than what is stored as MDbest . Later in Section 3.3, we prove that if a packet with a reachable destination enters traversal mode, it will deﬁnitely exit this mode at some node; i.e., MDbest is deﬁnitely decremented. Accordingly, since it is guaranteed that MDbest is gradually decrementing until zero, the packet is guaranteed to eventually reach the destination. Example. We now explain our algorithm in detail with an example that is based on the faulty NoC on Fig. 1 (b). Let us assume, 4MD is computed assuming a fault-free mesh. 5Once a hand rule is picked (as (cid:31) or (cid:30)), it cannot be changed while the packet is in traversal mode. 6We leave it to future work to develop a mechanism to pick a hand rule that can maximize performace. Figure 2: An example showing a possible path to deliver a packet from src to dst. The right ﬁgure shows the coordinates of the visited nodes and MDbest and mode values of the packet upon entering each node. The dashed line in the left ﬁgure is the line(cur,dst) , upon entering traversal mode in the router(0,2) . Short arrows on each node show cases where more than one output is eligible according to our algorithm. Note that, as also seen in the given example, it is an innate ability of our algorithm to route packets to their destinations in a fullydistributed manner; i.e., there is no routing table or reconﬁguration phase/hardware. This is a key advantage over previous works which either are not distributed, or require a routing table and/or reconﬁguration hardware to achieve full fault coverage. On the other hand, as in the example, there are two cases where the router needs to select between different output directions: 1) when there are more than one productive and healthy output ports, and 2) when selecting the hand rule for traversing around a face. Due to the distributed manner of our algorithm and thus lack of a global view, local selections done by the router in these two cases can potentially (but not always) lead to routing via suboptimal paths. For instance, in our given example, the packet would have routed through a minimal path, if router(0,0) (and consequently router(2,1) ) took the east direction. At the same time, the ability to choose from multiple output ports offers a high path diversity to our routing algorithm, which leads to improved latency compared to state-of-the-art when the network load is high (§4.2). We leave it for future work to develop better heuristics to pick the best output port when more than one selection is available. 3.3 Delivery Proof We now prove that our proposed algorithm guarantees to ﬁnd a path to destination when one exists. In other words, it does not lead to livelock as packets will eventually reach their destination. Note that, in our proof, we refer to PRO PERTY 1 of planar graphs, introduced in Section 3.1. TH EOR EM 1 . When a path exists between src and dst, using Alg. 1, a packet from src reaches dst in a ﬁnite number of hops. PROO F. Alg. 1 sends the packet closer to dst through productive outputs as long as they are healthy (lines 3–6). This continues until the packet reaches dst (line 1), or reaches a point (u) which does not have a productive and healthy output towards dst (line 9). In the latter, the packet enters traversal mode, during which, according to to PRO PERTY 1, the packet eventually will cross line(u,dst) , at p (cid:54)= u. Because p is on line(u,dst) , MDp,dst < MDu,dst . Before reaching p, thus, the packet must have entered a node (v ) with a productive and healthy output where MDu,dst = MDv,dst . That is, before intersecting line(p,dst) at p, the condition of line 3 of Alg. 1 gets satisﬁed at v . At that point, the packet exits to normal mode and MDbest is decremented. Thus, MDbest is guaranteed to be decremented in traversal mode. Since, MD is a discrete value and MDbest is guaranteed to be decremented in either modes (normal or traversal), it eventually reaches zero in a ﬁnite number of steps; i.e. the packet reaches dst in a ﬁnite number of hops.2 To get an intuition of the presented proof, one may replace u with router(0,2) , p with router(2,2) , and v with router(1,3) in Fig. 2. Algorithm 2 The enhanced Maze-routing algorithm that detects unreachable nodes. 1: if cur = dst then dirout ← LOCAL; 2: 3: else if MDbest = MDcur,dst and ∃(healthy & productive output) then if cur = Ntrav and dirout = D IRtrav then MDbest ← MDbest − 1; 6: mode ← normal; 4: dirout ← one of the healthy and productive outputs; 5: 7: else if mode ∈ traversal then dirout ← The direction given by (cid:31) / (cid:30) rule; 8: 9: 10: 11: 13: mode ← (cid:31) / (cid:30); dirout ← The ﬁrst output in the left/right of line(cur,dst) ; 14: 15: 16: Indicate dst as unreachable; end if 12: else D IRtrav ← dirout ; Ntrav ← cur ; 17: end if 18: return dirout ; (cur = Ntrav ) and 2) the (cid:31) rule guides the packet to the same direction (north) as stored in D IRtrav (D IRtrav = north). Note that our algorithm detects such network partitioning due to faulty nodes and links, and guarantees the packet delivery within each partition; i.e., it provides full coverage. However, a higher level mechanism is required to recover the system from a fault; e.g., the operating system needs to migrate disconnected threads to connected nodes. This is a complementary problem and is out of this paper’s scope. 3.4 Detecting Unreachable Nodes When there is no path between src and dst, it means that the packet cannot decrement its MDbest value down to zero, but only to a minimum value of MDmin (cid:54)= 0. Accordingly, when the packet enters a node (called Ntrav ) with MD Ntrav ,dst = MDmin , there is no productive and healthy output (Otherwise, MD Ntrav ,dst > MDmin ). In such a case, the packet traverses the current face forever in traversal mode and does not exit to normal mode again (Otherwise, MDmin is not the minimum MD possible). To develop an algorithm that can recognize an unreachable destination, we utilize the above reasoning. Algorithm 2 shows our resulting algorithm. In this algorithm, a packet needs to store the node it enters traversal mode (Ntrav ) and the direction D IRtrav that it is ﬁrst forwarded to (lines 15 and 16). The destination is declared unreachable when the packet is revisiting Ntrav again and the (cid:31) / (cid:30) rule guides to the same output as D IRtrav (lines 9 and 10). An example is shown in Fig. 3, where destination dst is unreachable. The time-line on the right shows different values in packet header when entering a node. In the last step, dst is detected unreachable as 1) the packet is revisiting the router(0,2) Figure 3: (a) The path a packet takes until its destination dst is detected unreachable by router0,2 . Right ﬁgure shows the coordinates of visited nodes and MDbest , mode, D IRtrav and Ntrav values of the packet upon entering each node. 3.5 Deadlock and Livelock Avoidance As mentioned before, we use deﬂection based routing to provide our algorithm with the ﬂexibility to take any output port, while avoiding deadlocks and livelocks. At the algorithm level, livelocks are also prevented as our algorithm guarantees to ﬁnd the path to destination, as described in Section 3.3. Deﬂection based routing and the design choices to avoid deadlocks and livelocks are thoroughly studied in literature [4, 6, 16, 21, 28, 29]. Deﬂection routing can provide deadlock freedom by deﬂecting ﬂits when there is contention. In order to guarantee that our design has no deadlock, our mechanism always ensures that the number of output ports is equal to the number of input ports. If there is a broken input or output link in the router, a corresponding output/input link will also get disabled to ensure the number of input ports equals to the number of output ports at all times. In this work, we have modiﬁed the deﬂection router used in minBD [16] to incorporate our proposed algorithm. In order to avoid livelocks, minBD applies two mechanisms: 1) golden and silver ﬂits, which guarantee that each ﬂit will eventually arrive at its destination [4, 15, 16] and 2) re-transmit once, which guarantees that ﬂits can be reassembled at the destination in order to make forward progress [4, 15, 16]. Furthermore, re-transmit once ﬂow-control avoids additional buffering cost, otherwise necessary for deadlock avoidance, by using cache miss buffers (MSHRs) as reassembly buffers. In conclusion, the combination of deﬂection routing, golden and silver ﬂits, and re-transmit once provides endto-end guarantees for all ﬂits and ensures that the network is always deadlock- and livelock-free. Note that the exact proof of deadlock and livelock freedom of deﬂection based mechanisms is beyond the scope of this paper. We refer interested readers to the original works for details of each mechanism [15–17]. Moreover, our algorithm can work with any deﬂection based mechanism proposed in literature. We chose minBD [16] due to its ease of adaptation and high performance. Deﬂection implications. With a deﬂection-based router, in some cases, a ﬂit might not be forwarded to the output port indicated by our routing algorithm (Alg. 1 and 2). As such, a deﬂected ﬂit is no longer following our algorithm: it exits the face it is traversing or takes a non-productive output, both of which, result in inconsistency of the MDbest and mode values of the packet. In order to ensure correct functionality of our algorithm, in the presence of deﬂection, the MDbest and mode values of the ﬂit are reset as if the packet were just injected to the network in the next router, rD (MDbest ← MDrD ,dst and mode ← normal). 3.6 Qualitative Comparison with Previous Methods Basic face routing algorithm [11] draws line(p,dst) between sour-ce src and destination dst, and traverses the underlying face until an edge intersects the line(p,dst) . The procedure of shortening line(p,dst) is continued until reaching dst, as shown in Fig. 4. The face routing algorithm is not a suitable candidate for on-chip implementation in its basic form. It needs to store coordinates of p, which are real (vs. integer) numbers, and requires realization of ﬂoating-point operations (with the associated area and energy overheads) at every input port. Moreover, the intersection check can lengthen the critical path of the algorithm and add up to the hardware overhead. Finally, the basic face routing algorithm does not provide a method to detect it when nodes become unreachable due to faults. Figure 4: An example of the basic face-routing algorithm. line(src,dst) is shown in red, and intersection points are indicated by . Tunneled OSR (TOSR) [5] tries to overcome two main drawbacks of its predecessor, OSR-Lite [38]. TOSR reconﬁgures the network in a distributed manner, and achieves much faster reconﬁguration. Their reconﬁguration speed clearly stands out among related state-of-the-art [25, 38]. However, TOSR (like OSR-Lite) has limited coverage capabilities; e.g., it cannot always recover the network when there are two failed links. Moreover, it makes use of routing tables (464 bits per router) imposing a high area overhead (§4.1). In addition, the reconﬁguration logic of TOSR needs to be shielded by use of TMR-based methods (as mentioned in Section 2); otherwise, a failed unit can damage the functionality of the technique. In contrast, in our method, failed routing logic of a router can be simply taken ofﬂine by disabling the associated input and output ports. Logic based distributed routing (LBDR) [35] based methods are introduced to remove the area overhead of routing tables. LBDR works with few conﬁguration bits (around 26) per router, and can implement several routing algorithms. Nevertheless, naïve LBDR is not capable of providing high coverage in case of failures, when shortest path routing is not possible. Universal LBDR (uLBDR) [36] is proposed to overcome this shortcomings. Unfortunately, d2 -LBDR [7] reports 3x area overhead for uLBDR due to the need of virtual cut through switching, use of FORK modules, and complex arbitration. Moreover, LBDR and its derivatives are not routing algorithms by themselves and need a central module to collect fault data, compute new conﬁguration bits, and update each unit accordingly. Our technique is free of such overheads due to its four desirable characteristics, explained in Sections 1 and 2. FTDR-H [18] is a hierarchical reinforcement learning based algorithm which uses deﬂection based routing. It achieves high coverage and can route packets to their destination on the ﬂy upon new failures. However, it uses large routing tables (around 600 bits) per router and leads to livelock once a destination gets disconnected. Our Maze-routing mechanism is livelock free and does not need routing tables. 4. RESULTS We evaluated our proposed algorithm using a publicly available simulator, NOCulator [2], modeling out-of-order x86 CPUs each with a private L1 cache and a share L2 cache. The simulator has been used and veriﬁed in many previous works [4, 12, 15, 16, 30, 31]. L2 cache slices are connected together with a mesh interconnect. In this work, we model 64 CPU cores in an 8x8 network, each of them running a SPEC2006 application [22]. In addition, we present synthetic trafﬁc analysis. 4.1 Area Overhead For the area overhead evaluation, we implemented our algorithm using Verilog HDL. We then synthesized the design using Cadence RC (RTL compiler) tool at the STMicro 60nm technology node. Five copies of the algorithm are instantiated, one for each input port of a router. We also implemented the routing table used by related works [3, 5, 19, 25, 32, 33, 39]. Among these, ARIADNE [3] uses the smallest table in comparison to others, and we compare to it. Note that we did not implement the reconﬁguration logic of each work, which will lead to even a higher area overhead for these past works. In addition to ARIADNE, for the sake of fair comparison, we implemented LBDRe, a logic based table free method based on the LBDR [35] method. Table 3 shows the silicon area required by our mechanism compared to ARIADNE and LBDRe, for 8x8 and 16x16 meshes. Compared to ARI ADN E , the area reduction of our mechanism is 3.8 and 15.9 times for 8x8 and 16x16 meshes, respectively. Though LBDR based method imposes a lower area overhead compared to our method, both methods scale well as network size increases. However, LBDR suffers from being a central approach with limited coverage, and uLBDR [36], an extension to achieve high coverage, is reported to impose 3x overhead in the entire router area [7]. Table 3: Silicon area (in µm2 ) required by ﬁve instances of our algorithm (one for each port), routing table of ARIADNE [3], and logic-based LBDRe mechanism [35]. Mesh size Maze-routing ARI ADN E LBDRe 1184 4471 568 1505 23921 606 8 × 8 16 × 16 In addition to the efﬁciency and scalability of our algorithm, the use of deﬂection routing signiﬁcantly reduces our technique’s area overhead as it reduces buffering in routers. The minBD router we use has 39% smaller area than a buffered wormhole router [16]. In addition, the use of retransmit-once scheme [15] reduces the buffering overhead at receiving nodes in our technique. On the other hand, because each ﬂit of a packet is treated independently in deﬂection-based methods [29], the packet header information listed in Table 2 should be sent along with all ﬂits. This means that the channel width of routers needs to be lengthened to accommodate this information, which results in increased area in channels and routers (there is an almost quadratic relation between the channel width and the router area [26]). The ﬁelds of Table 2 can be coded in 14/17 bits in 8x8/16x16 meshes. Assuming a baseline router with 144-bit channel width [23] , we need to widen the channel by 10%/12%, which results in almost 20%/25% increase in the router area. Note that, even with the imposed overhead of the widened channels, the area cost of our method is far less than methods with routing tables. We leave a more precise and accurate study/comparison of the area overhead to future work. 4.2 Throughput In order to evaluate the performance of our algorithm, we extracted the average ﬂit latency in the network under different injection rates using a uniform trafﬁc. Fig. 5 shows the result for both our algorithm (blue lines) and the up*/down* [37] (red lines) using an 8x8 network. We study two cases (1 and 5 randomly failed links), generate 10 different fault patterns for each case, and provide average results across all of them. We run the simulations for 10 million cycles. Figure 5: Average ﬂit latency for both up*/down* algorithm and our mechanism, over different injection rates with uniform random trafﬁc. Solid and dashed lines, respectively, correspond to 1 and 5 randomly failed links. We compare our technique against the up*/down* proposal, as the latter is the core algorithm implemented in several related works [3, 32, 35, 36] and can provide full coverage. Our algorithm utilizes a router design proposed in minBD [16] with 16 buffer entries. Up*/down* is implemented using normal buffered wormhole routers [40], with 40 buffer entries in each router (8 to each port). As up*/down*, on average, provides a shorter path to destination compared to our technique, its average packet latency is smaller at low network loads. However, at high injection rates, our algorithm achieves better latency results as well as higher saturation throughput due to its better exploration of path diversity compared to up*/down*. In another set of experiments, we run a mix of 15 different workloads from SPEC CPU2006 [22]. Accordingly, we split benchmarks into three categories based on their L1 misses per kilo instruction (MPKI), as these are the misses that will go over the network. High intensity benchmarks have MPKI greater than 50, Medium intensity ones fall between 5 and 50 MPKI, and Low intensity benchmarks are the remainder. Based on these categories, we randomly pick a number of applications and form the following mixes: L (all Low), ML (Medium/Low), M (all Medium), and H (all High). Table 4 shows the average network latency of the mentioned workload mixes, when there is no failure and when there are up to 5 failed links in the network. Our mechanism achieves lower average packet latency compared to up*/down*, especially in the high load cases, due to the offered path diversity. 4.3 Reconﬁguration Overhead In this subsection, we evaluate the performance of our algorithm in achieving our fourth goal, minimal reconﬁguration overhead. As described in Section 3.2, there is no reconﬁguration phase that a router enters upon a failure detection. Instead, each router tries to traverse around the failed link by forwarding the packets in traversal mode. In contrast, in related work [3, 5, 25, 32, 38, 39], a router enters the reconﬁguration phase and network operation is interrupted until a Table 4: Average packet latency with our techniques vs. up*/down* on an 8x8 mesh, running different mixtures of SPEC benchmarks. workload Up*/Down* mix 5 failures L 16.7 ML 18.8 M 27.7 H 54.4 AVG 29.4 no failure 16.4 18.2 25.7 50.5 27.7 Maze-routing 5 failures 17.8 18.9 21.6 25.8 21.0 no failure 16.4 17.2 19.2 23.1 19.0 new routing solution is found. Accordingly, these works’ intrusions on normal operation of the network increases with the time it takes to ﬁnd an alternative solution. For an 8x8 mesh, it is reported that it can take ∼20 [5], ∼30 [25], ∼350 [38] and even 4K [3] cycles to reconﬁgure the network. However, most of these works can work only for 1 failure per their deﬁned segment [5, 25, 38], and only ARIADNE can guarantee full coverage as our method. To demonstrate the on-the-ﬂy reconﬁguration capability of our proposal, we simulate a fault free 8x8 network with injection rate constantly set to 0.2 f lits/node/cycle. We inject two random link failures to the network, one at cycle 200K, and the other at cycle 400K. As shown in upper part of Fig. 6, while ARIADNE takes only 4K cycles to reconﬁgure the network, it takes over 40K cycles for the network to return to its steady state latency. This becomes even worse when the second failure occurs. In contrast, using our proposed algorithm, the network latency only slightly increases (∼0.25 cycles) upon every failure (Fig. 6– lower part). Continuing new failure injection, ARIADNE design gets saturated once the 5th link fails, while our algorithm continues to deliver ﬂits with a slight increase in latency (from 16.5 cycles to 18.4, with 6 link failures). We believe the main advantage of on-the-ﬂy reconﬁguration is that, using our algorithm, one can freely use online testing methods. Links and network components can be silently disabled to run test methods on them, without any major impact on performance. Figure 6: The moving average of network latency when new failures are injected during normal operation of the network. (upper) It takes several kilo cycles for ARIADNE to return to steady state. (lower) The zoom-in of the same experiment: using our algorithm, ﬂits experience around 0.25-cycle additional latency for each new failure 5. CONCLUSION We introduced Maze-routing, a new, practical fault-tolerant routing algorithm with delivery guarantees for networks-on-chip. We have shown that Maze-routing 1) is fully-distributed, 2) guarantees delivery when a path exists and, otherwise, indicates that the destination is unreachable, 3) has low hardware area overhead, 4) incurs low reconﬁguration overhead upon a new fault. We experimentally evaluated the area overhead, performance, and fault tolerance capability of Maze-routing, with comparisons to state-ofthe-art routing algorithms that provide guaranteed delivery. Our evaluations show much lower area overhead and much higher saturation throughput (when faults exist in the NoC) than the state-ofthe-art. We conclude that our proposal can provide an efﬁcient and high-performance routing substrate for future NoCs, where fault tolerance is expected to become increasingly important. Acknowledgments We thank the anonymous reviewers for their valuable feedback and suggestions. We acknowledge the support of Turku University Foundation and Ulla Tuominen Foundation. This research was also partially supported by grants from the European COST action for manufacturable and dependable multicore architectures at nanoscale (median project), Academy of Finland, NSF (grants 0953246 and 1212962), the Intel Science and Technology Center for Cloud Computing, and SRC. "
Achievable Performance Enhancements with mm-Wave Wireless Interconnects in NoC.,"On-chip wireless links have been shown to overcome the performance limitations of wired interconnects in Networks-on-chip (NoCs). However actual performance gains obtained are largely dependent on efficient data transmission between on-chip antennas. An analysis of on-chip wireless channel shows that propagation is highly affected by different components of the chip. In this work, we include the effects of chip environment on wireless propagation to obtain a more realistic performance evaluation of Wireless NoC (WiNoC). Using these, we derive the latency and energy characteristics of WiNoC and quantify the achievable performance. Results presented show wireless received signal with on-chip effects considered and compare them with that of a wired link.","Achievable Performance Enhancements with mm-Wave Wireless Interconnects in NoC Sri Harsha Gade Depar tment of ECE IIIT Delhi New Delhi, India narayana1294@iiitd.ac.in Sujay Deb Depar tment of ECE IIIT Delhi New Delhi, India sdeb@iiitd.ac.in ABSTRACT On-chip wireless links have been shown to overcome the performance limitations of wired interconnects in Networks-onchip (NoCs). However actual performance gains obtained are largely dependent on eﬃcient data transmission between on-chip antennas. An analysis of on-chip wireless channel shows that propagation is highly aﬀected by diﬀerent components of the chip. In this work, we include the eﬀects of chip environment on wireless propagation to obtain a more realistic performance evaluation of Wireless NoC (WiNoC). Using these, we derive the latency and energy characteristics of WiNoC and quantify the achievable performance. Results presented show wireless received signal with on-chip eﬀects considered and compare them with that of a wired link. Categories and Subject Descriptors C.4 [Performance of Systems]: Design Studies; C.2.1 [Computer-Communication Networks]: Network Architecture and Design—Wireless communication General Terms Performance Keywords NoC, On-chip wireless channel, Signal distortion 1. INTRODUCTION Existing Network-on-Chip (NoC) architectures with planar metal interconnects have high latency and power consumption due to multi-hop wired links. Several novel approaches like optical interconnects, RF and wireless interconnects have been explored to address this issue. Of these, wireless interconnects can be implemented with existing fabrication methods. Studies on wireless interconnects show that they provide performance enhancements through long range, high bandwidth, low latency and low power wireless links in large multi-core systems. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s). NOCS ’15, September 28-30, 2015, Vancouver, BC, Canada ACM 978-1-4503-3396-2/15/09˙ http://dx.doi.org/10.1145/2786572.2786584 . Recent works have shown the performance improvements gained by using judicially placed Wireless Interfaces (WIs) at some nodes in NoC architectures [1]. But most of these works assume that the behavior of on-chip antennas used for WIs resembles free space propagation. On-chip environment aﬀects the characteristics of antennas and subsequently the WIs. Studies on integrated antennas have shown that the characteristics vary signiﬁcantly in intra chip environments [2, 3]. Such characteristics aﬀect the overall performance beneﬁts of the WIs at the system level. To obtain a more realistic measure of WI performance, we include these eﬀects in system level evaluations. To achieve this, we represent the wireless propagation using its channel impulse response derived using Finite Diﬀerence Time Domain (FDTD) techniques. In this work, the eﬀects of WIs on the data transmission in NoC is analyzed by using the impulse response of wireless channel. We observe the eﬀects of on-chip wireless channel and obtain a more realistic estimate of signal distortion, communication latency, data rate and path loss when using WIs. This allows us to identify any adverse eﬀects on signal transmission and reliably retrieve the data back. The work provides insights to optimize design parameters for antennas, transceivers and network topologies on the basis of underlying channel propagation physics. 2. WIRELESS CHANNEL AS FILTER We simulate the electromagnetic propagation between two on-chip antennas using FDTD method and derive the impulse response of the wireless channel. The coeﬃcients of Figure 1: A typical Communication Path using WIs Figure 2: Transmitted and Received Signals Figure 3: Per bit Energy Consumption the impulse response, its magnitude and delay are dependent on the distance between transmitter and receiver. A typical communication path in NoC that uses WIs is shown in Figure 1. The modules associated with the wireless communication are shown in the inset of Figure 1. A parallel-to-serial buﬀer converts n-bit parallel input data to a serial data feed and is then modulated, On-Oﬀ Keying (OOK) in our case. The frequency of the carrier is set to 60GH z for our experiments. The modulated data is then fed to the transmitting antenna. The signal propagates through the on-chip wireless channel and is received at the appropriate receiving antenna. The transmitting antenna, wireless channel and receiving antenna together are modeled as a ﬁlter and are represented by appropriate impulse response. The received signal is ampliﬁed, ﬁltered through a bandpass ﬁlter (BPF), demodulated and original data is retrieved back. We use this setup to analyze the end-to-end communication using wireless and evaluate the performance. 3. RESULTS AND ANALYSIS We implement diﬀerent modules of WI in MATLAB and analyze the received signal, its distortion, delay, power and then compare the measures with a similar setup for wired path. 3.1 Signal Distortion First, we analyze distortion in the received signal of due to on-chip environment and measured as correlation between transmitted and received signals. The received signal contains high frequency distortions whenever the data switches between 0 and 1 which are removed using a BPF. The received signal at 5mm distance for data stream {0, 1, 1, 0} is shown in Figure 2. The correlation coeﬃcients for transmission over 1, 5 and 10mm distances are 0.6287, 0.6020 and −0.5117 (- represents 180◦ shift) respectively. 3.2 Delay The analysis of wireless impulse response shows that propagation delay increases at a higher rate with distance than free space delay. But WIs still perform much better than wired links. At distance of 20mm, delay with unbuﬀered & buﬀered wire and wireless is 3.86nsec, 1.16nsec and 0.15nsec respectively. Serialization and ﬁltering delays add to the higher wireless delay. Taking into account all delays, achievable bandwidth that can be supported by WIs is ≈ 9Gbps as opposed to 16Gbps obtained using idle conditions. 3.3 Energy Consumption The higher delays also eﬀect the energy consumption since WI need to be active for longer periods. All modules of WI combined consume 36.7mW of power. To transmit one bit of data over 20mm distance, WIs consume an energy of 7.9587pJ/bit. For same distance, unbuﬀered and buﬀered wires consume 82.0527pJ/bit and 18.2517pJ/bit respectively. The variation of energy per bit with distance is shown in Figure 3. As the distance increases, energy saving with WIs becomes signiﬁcant compared to wired links. From the ﬁgure, use of WIs is suitable for distances over 10mm. 4. CONCLUSION In this paper, we have taken into account the realistic propagation characteristics of on-chip antennas to measure the performance of WIs and WiNoCs. Analysis of signal transmission between two WIs show the presence of high frequency distortions. Propagation delay and energy per bit, though higher than ideal values, are still signiﬁcantly better than that with wired interconnects. Use of WIs provides gains beyond 10mm distance. Dedicated ﬁlter might be required to remove distortions adding additional overhead to the WI. All these results show that characteristics of on-chip antennas and wireless propagation impact the performance gains of WIs and must be considered for their design. 5. ACKNOWLEDGMENTS This work is supported by the DST INSPIRE Fellowship Award by the Government of India. 6. "
MapPro - Proactive Runtime Mapping for Dynamic Workloads by Quantifying Ripple Effect of Applications on Networks-on-Chip.,"Increasing dynamic workloads running on NoC-based many-core systems necessitates efficient runtime mapping strategies. With an unpredictable nature of application profiles, selecting a rational region to map an incoming application is an NP-hard problem in view of minimizing congestion and maximizing performance. In this paper, we propose a proactive region selection strategy which prioritizes nodes that offer lower congestion and dispersion. Our proposed strategy, MapPro, quantitatively represents the propagated impact of spatial availability and dispersion on the network with every new mapped application. This allows us to identify a suitable region to accommodate an incoming application that results in minimal congestion and dispersion. We cluster the network into squares of different radii to suit applications of different sizes and proactively select a suitable square for a new application, eliminating the overhead caused with typical reactive mapping approaches. We evaluated our proposed strategy over different traffic patterns and observed gains of up to 41% in energy efficiency, 28% in congestion and 21% dispersion when compared to the state-of-the-art region selection methods.","MapPro: Proactive Runtime Mapping for Dynamic Workloads by Quantifying Ripple Effect of Applications on Networks-on-Chip Mohammad-Hashem Haghbayan1 , Anil Kanduri1 , Amir-Mohammad Rahmani1;2 , Pasi Liljeberg1 , Axel Jantsch3 , and Hannu Tenhunen1;2 1Depar tment of Information Technology, University of Turku, Finland 2Depar tment of Industrial and Medical Electronics, KTH Royal Institute of Technology, Sweden 3TU Wien, Austria {mohhag, spakan, amirah, pakrli}@utu.ﬁ, hannu@kth.se, axel.jantsch@tuwien.ac.at ABSTRACT Increasing dynamic workloads running on NoC-based many-core systems necessitates efﬁcient runtime mapping strategies. With an unpredictable nature of application proﬁles, selecting a rational region to map an incoming application is an NP-hard problem in view of minimizing congestion and maximizing performance. In this paper, we propose a proactive region selection strategy which prioritizes nodes that offer lower congestion and dispersion. Our proposed strategy, MapPro, quantitatively represents the propagated impact of spatial availability and dispersion on the network with every new mapped application. This allows us to identify a suitable region to accommodate an incoming application that results in minimal congestion and dispersion. We cluster the network into squares of different radii to suit applications of different sizes and proactively select a suitable square for a new application, eliminating the overhead caused with typical reactive mapping approaches. We evaluated our proposed strategy over different trafﬁc patterns and observed gains of up to 41% in energy efﬁciency, 28% in congestion and 21% dispersion when compared to the state-of-the-art region selection methods. Categories and Subject Descriptors D.4.7 [Operating Systems]: Organization and Design (cid:0) Real-time systems and embedded systems General Terms Algorithms, Performance, Management, Design Keywords On-chip many-core systems, Application mapping, Task allocation, Proactive Runtime Mapping 1. INTRODUCTION Networks-on-chip (NoC) based many-core systems have accelerated the performance of computationally intensive applications Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. NOCS ’15 Vancouver, BC Canada Copyright 2015 ACM 978-1-4503-3396-2/15/09$15.00 ...$15.00. http://dx.doi.org/10.1145/2786572.2786589. by providing a better communication infrastructure [8]. Applications running on a system are modelled as task graphs where tasks are individual computational blocks that communicate with each other [17]. Application mapping is the phase where a tile for a task is chosen in order to maximize the cores’ and network’s performance while minimizing latency and power consumption. Given the un-predictable nature and sequence of incoming applications [4] [5], mapping has to be performed dynamically rather than at design time [7] [2] [10]. With a wide range of applications entering and leaving such a system, runtime application mapping policies become crucial factor in determining the chip’s performance, power consumption and reliability [6]. We consider run-time mapping as one of the ﬁrst steps in servicing an incoming application as opposed to reactive steps like task migration. Mapping an entire application consisting of several communicating tasks, satisfying power and performance constraints is a complex process. Assuming that there can be other applications running in parallel on the chip, mapping a new application adds to the complexity and consumes more execution time, degrading the expected performance from a parallel system. Finding a preferable region to map an incoming application with least possible overhead is thus important to ensure high performance of the chip. Runtime mapping is split into two phases viz., ﬁnding a suitable region to map an application [7], followed by mapping tasks of the application in the selected region [11]. Optimal region for mapping an application is the one that results in lower congestion, dispersion, power consumption and higher performance. An optimal region for an application can be found starting with an optimal node in the network, referred to as the f irst node, around which an application can be mapped. First node should have unoccupied nodes around it in a contiguous manner, forming a near convex shape which will be ideal for lower congestion and dispersion. First node selection effects internal and external congestion, dispersion and fragmentation of NoC-based systems, creating a signiﬁcant impact on performance [12]. For a network of size n (cid:2) n, ﬁnding the optimal ﬁrst node and a region in the mesh for an incoming application is of polynomial time complexity, of the order O(n3 ) [9]. Adding the above mentioned constraints on congestion and dispersion to the mapping issue makes it an NP-hard problem [15]. Although ﬁrst node selection is an important phase that determines performance of the system, it is not desirable to exhaustively search the network for an optimal ﬁrst node. A near exhaustive search might offer an optimal ﬁrst node, however the time spent in ﬁnding the ﬁrst node nulliﬁes any performance gains that come with it. Keeping in view the growing computational demands and scalability of networks, it is of critical importance to design fast and adaptive ﬁrst node ﬁnding strategies. Signiﬁcant work has been done so far on runtime mapping [11] [13] [7], yet not many existing techniques have optimized the ﬁrst node selection. Existing ﬁrst node selection strategies either do not consider the combination of spatial availability, congestion, dispersion [6] [7] [16] or involve expensive computations to search the network and ﬁnd an optimal region [12]. In this paper, we propose a proactive ﬁrst node selection strategy that provides a near convex (square shaped) region with minimal congestion and dispersion. We cluster the network into square shaped regions of different radii to ﬁt applications of different sizes, and quantify spatial availability and probability for internal congestion of each square. We minimize the search to only those squares that can ﬁt the size of a newly arrived application. We consider the impact of currently mapped applications on remaining un-occupied nodes by updating their availability and congestion metrics. This helps our proactive strategy of ﬁnding a preferable region for the next incoming application of any size with a single look-up for the square that can accommodate it. Our idea is to map the application in a suitable region up on its arrival itself, limiting the need for an expensive task migration later. The contributions from our work are: (cid:15) Quantiﬁcation of spatial availability, internal congestion and dispersion into a uniﬁed metric (cid:15) Modeling the of ripple effect of a newly mapped application on remaining un-occupied nodes. (cid:15) Proactive ﬁrst node selection for a generic NoC mesh running dynamic workloads. The rest of the paper is organized as follows. We formulate the problem of ﬁrst node selection and motivate its importance in Section 2. Section 3 formally introduces the preliminaries of our ﬁrst node selection method and later details the proposed algorithm. The evaluation platform and results in comparison to state-of-theart ﬁrst node selection methods are presented in Section 4. Finally, Section 5 concludes the paper and discusses possible future works. 2. MOTIVATION First node selection has a signiﬁcant effect on internal and external congestion, and dispersion of applications running, which subsequently reﬂects in the chip’s performance [12]. It is necessary to ﬁnd an optimal ﬁrst node that satisﬁes congestion and dispersion metrics, with minimal execution time. First node selection not only effects the current application, but also on future incoming applications. The effect of ﬁrst node selection on current and future incoming applications is explained through a motivational example. Figure 1(a) shows the status of a network with three applications App1, App2 and App3 of sizes 6, 8 and 10 running on it. With the arrival of a new application App4 with 9 tasks, a suitable region has to be found such that all tasks of App4 are mapped with minimal congestion and dispersion. A naive ﬁrst node selection allocates a random node located at (6,3) to App4 and subsequent mapping is shown in Figure 1(b). All the tasks are spread around the ﬁrst node, which does not lead to a convex shape. Although it is near convex, it leaves the nodes located at (5,3), (5,4) and (7,5) fragmented. These three nodes do not form a convex shape are less likely to be part of future incoming applications. They either stay un-occupied resulting in poor resource utilization, or become part of same application resulting in a higher communication penalty. In addition, tasks of any application mapped onto these nodes in the future would contend with packets of App4 leading to external congestion. In contrast, a congestion, dispersion and spatial availability aware ﬁrst node selection is shown in Figure 1(c). The node located at (1,4) is selected as ﬁrst node and App4 is mapped around it in a perforate convex shape. This mapping of App4 ensures that all of its tasks are at minimal communication distance, and do not conﬂict with any other running applications. It causes no fragmentation leaving convex shapes for future incoming applications which would also minimize dispersion. 2.1 Problem Formulation The foremost requirement of a ﬁrst node is the availability of enough number of free nodes in its proximity on to which incoming application’s tasks can be mapped. The next requirement is to have lower internal congestion - the communication penalty that arises from communicating tasks of an application that are mapped far apart. Contiguous nodes are the nodes that are adjacent to each other which ensure a minimal hop distance among communicating tasks of an application. Mapping an application onto contiguous nodes can minimize internal congestion. The other metric to be considered during ﬁrst node selection is dispersion - a case where un-occupied nodes are far apart and spread out across the network into concave and irregular geometric shapes, leading to poor resource utilization. This will also result in external congestion contention between packets belonging to different applications. A square shaped region has a minimal radius among regular geometric shaped regions, making it a compact ﬁt for an application. Application mapped onto a square shaped (or almost square shaped) regions is less likely to interfere with other applications, minimizing both the probability for dispersion and external congestion. In view of these metrics, an optimal ﬁrst node for a new application thus has to be: (cid:15) Spatially available - enough number of free nodes around it to map the application. (cid:15) Contiguous - free nodes that are contiguous to minimize internal congestion. (cid:15) Near Convex - free nodes forming a near convex geometrical shape to minimize dispersion and external congestion. Finding the appropriate ﬁrst node is the key factor to ﬁnd the optimal region. However, all the aforementioned metrics have to be quantiﬁed to prioritize one node over the other. In addition, exhaustively searching for an optimal node has to be avoided. A state-of-the-art ﬁrst node selection through a hill climbing approach is proposed in [12]. Three applications App1, App2 and App3 are currently running and App4 is about to enter the system, as shown in Figure 1(a). A hill climbing approach for ﬁrst node selection proposed in [12] deﬁnes an open direction, the direction in which probability of ﬁnding free nodes is higher. Upon arrival of a new application, it randomly chooses a free node, identiﬁes the open direction for the chosen node and expands the search space towards it iteratively. The search stops when the number of free nodes around a selected node is equal to the new application’s size. It tries to walk through the mesh with the intention to ﬁnd the smallest possible, contiguous region that can ﬁt the new application. On an average, complexity of this method is of the order O( n), while on a worst case, it is O(n2 ), where n (cid:2) n is the network size. Although this approach results in lower dispersion and higher contiguity, its random nature and scenario of other applications running on the mesh affects its time complexity. While certain combination of occupied nodes on network favor hill climbing, some other combination might result in a worst case time complexity. Most importantly, with availability of contiguous free nodes being the only criteria, this approach limits itself to ﬁnding only one suitable p (a) 3 Applications Mapped (b) Naive region selection for App4 (c) Optimal region selection for App4 (d) Limitation of Hill Climbing Figure 1: Impact of ﬁrst node selection ﬁrst node, while there might exist a much better alternative. Figure 1(d) shows the possible open direction traversal of hill climbing approach in two Region-1 and Region-2. Randomly choosing a node in one region will ignore other possible optimal nodes. In case the random nature results in choosing a node from Region-2, hill climbing gets conﬁned or stuck at this region and is less likely to ﬁnd an optimal node. As mentioned in previous section, we cluster the network into squares of different radii and assign a combinatorial value of availability and congestion to each square. Figure 1(c) shows the mapping of App4 in square centered at (1,5), although there are other possible squares, we choose the best possible region for the new application so as to ensure contiguity with other applications. We have the bird-eye view of entire network, as opposed to hill climbing approach that allows us to make rational decisions for incoming applications. In the next section, we present our approach on quantifying these parameters and our proactive approach that eliminates ﬁrst node ﬁnding overhead. 3. PROACTIVE FIRST NODE SELECTION 3.1 Preliminaries Each application in the system is represented by a directed graph denoted as a task graph Ap = T G(T ; E ). Each vertex ti 2 T represents one task of the application, while the edge ei;j 2 E stands for a communication between the source task ti , and the destination task tj . Task graph of a Gaussian Elimination application [3] which is extracted using TGG [1] is shown in Figure 2(a). The wi;j values, i.e. the amount of data transferred from ti to tj of edge ei;j , is indicated on each edge. An architecture graph AG(N ; L) describes the communication infrastructure of the processing elements. Given its simplicity and popularity, we considered a 2Dmesh NoC (Figure 2(b)) with XY deterministic wormhole routing. Other network topologies can also use our ﬁrst node selection strategy, however it might lead to inconsistent square regions towards the edges, as opposed to the center. The AG contains a set of nodes nw;h 2 N , connected together through unidirectional links lk 2 L. Each node is the combination of the Processing Element (PE) connected to the router. Mapping of an application onto the system is deﬁned as a one-to-one function from the set of application tasks to the set of nodes: map : T ! N ; s:t:map(ti ) = nw;h ; 8ti 2 T ; 9nw;h 2 N (1) Figure 2(b) illustrates a possible mapping of the application in Figure 2(a), onto the described platform.To attain a near convex shape, Figure 2: Mesh-Based platform with an application mapped onto it (the highlighted region.) for simplicity and ease of application assignment, we cluster the network into squares of different radii, intuitively to ﬁt applications of different sizes. A square region and its features are mentioned below. p S quare(S r ij ): A square S r ij is a square shaped collection of nodes, centered at node nij with r being its radius i.e., the distance from the center of the square to any of its edges. A square region can have both free and occupied nodes. The number of nodes in each square shape region in the network ranges in 1, 9, 25, ... , (2i + 1)2 , M (cid:0) 1)=2 . There can be different squares for radii 0, 1, 2, 3.... ( of same size, but with different centers. Figure 3 shows a squares centered at two different nodes, n3;7 and n6;3 , with radius 1 and 2. The node n3;7 is a center for the squares S 1 3;7 and the noden6;3 is a center for the squares S 1 6;3 . Note that each node is a center for squares with radius 1, 2, 3, ... up to M=2. All the squares of same size are grouped together into a square group, SGr , where r is the radius of squares in the group. On the whole, total number of square groups in the mesh is expressed as: p 3;7 and S 2 6;3 and S 2 M (cid:0)1)=2∑ i=1 ( groups = p (2i + 1)2 = k(2k + 3)2 + 2k 3 (2) M (cid:0) 1)=2. Searching for a square for an incoming Where k = ( application among groups results in a time complexity of order O(M 3=2 ), where M (cid:2) M is the size of the network. For applications of every size within the mesh limits, there exists a square that has enough number of nodes to accommodate the application. For instance, an incoming application of size 7 can ﬁt in a square of size 9 (radius 1). In general, an application of size size can be ﬁt in square with radius r such that size 2 ((r (cid:0) 2)2 ; r2 ]. We ﬁnd a perfect square even for applications that do not perfectly ﬁt in a square, leaving few cores un-occupied. In such cases, we consider these un-occupied cores as available for mapping, but belonging to squares with a different ﬁrst node than the current square and also with a different radius. With the arrival of a new application, a square suitable for the application size is chosen. However, there might be more than more than one square that can accommodate the new application. We resolve this by quantifying spatial availability and congestion of a square by assigning weighted parameter called Vicinity Counter to the center of a square. Deﬁnition: Vicinity counter, V C r ij , for a node located at (i,j) is the weighted sum of number of free nodes in the square centered at (i,j) with radius r . We assign the weights to a node ni;j as: { 1 (cid:0)1 W ni;j = if ni;j is unoccupied if ni;j is occupied A free node has a weight 1 while an occupied node has a weight -1. Further, we consider the impact of occupied nodes in the square on congestion. A node that is occupied in the inner most proximity, close to the ﬁrst node has more affect on internal congestion than the ones that are occupied, far from the ﬁrst node. We quantify this by pegging the weight of an occupied node with its distance from the central node by assigning a higher penalty to occupied nodes closer to central node and relatively lower penalty to the ones that are far. The vicinity count for a node (i,j) is expressed as: V C r i;j = W ni;j (cid:2) (r (cid:0) d + 1) (3) ∑ Where r is radius of square and d is the distance from occupied node to the center. The VC of a node (i,j) qualitatively represents the dispersion, internal congestion, and contiguity of the node (i,j) and thus of the selected square centered at (i,j). This makes it easier to choose a ﬁrst node and thus the region for mapping an incoming application minimizing congestion. DistanceF actor(Dij ): Distance Factor of a node located at (i,j) is the sum of distance of the node from all the other occupied nodes of the network. Distance Factor is expressed as: Dij = j (i (cid:0) x) j + j (j (cid:0) y) j (4) X;Y∑ x;y where Dij is the Distance Factor of the node located at (i,j), (x,y)2 (X,Y) are occupied nodes of the network. We use the Distance Factor to represent the contiguity of the chosen ﬁrst node located (i,j) with respect to all the current occupied nodes. A higher D indicates that the chosen node is far from existing applications and is likely to violate contiguity metric. In contrast, a node with lower D value is nearer to existing applications and is more likely to be contiguous with them. For different ﬁrst nodes with same V C value, we use the Distance Factor to prioritize nodes that result in a contiguous mapping. Figure 4 shows the vicinity count values for two different scenarios of occupied nodes. In case of square centred at tile t37 , number of occupied nodes in the square are 2, with both the nodes being in the inner most square close to the ﬁrst node. The VC for t37 = 25-(1*2 + 1*2) = 21. The other scenario presented is the square Figure 3: Example of the square regions Figure 4: Quantifying probability of congestion centred at node t63 , with 3 nodes occupied, all being in outer most square far from the central node. The VC for this square = 25-(1*1 + 1*1 + 1*1) = 22. Square centred at t63 has a better VC value and would be the preferred despite having more number of occupied nodes than that of square centred at t37 . This can be attributed to the fact that t37 has occupied nodes closer which would result in higher congestion and dispersion. The fact that tasks with higher communication volume will be mapped onto the central node and its neighbours, makes the impact of occupied nodes in inner squares more signiﬁcant. 3.2 Ripple Effect of Mapping When a new application has arrived and gets mapped onto the system, it effects its neighboring un-occupied nodes in terms of probability of congestion and dispersion. This propagates similar to the ripple effect of stone in water such that the impact decreases with distance from point of impact. We model this effect by updating the V C value for each node (thus squares) in the network once a new application is mapped. When a node gets occupied, other nodes surrounding it gets assigned a lower V C (as in Equation 3), subject to the distance from occupied node. When the system is initialized, all the nodes are assumed to be un-occupied. Figure 5 shows the Vicinity Counter values for square groups 1 to 4(SG-1 SG-4) with radii 1 to 4 under initial conditions. Nodes on the edges have lesser neighbors reﬂecting in lower V C values and hence lower the chance of being prioritized. Nodes towards the center of the network tend to have higher V C values due to abundance of neighbors. Although for squares with lower radius V C value is almost even throughout the network, except for the edges. With increase in radius, resulting in squares that can ﬁt applications of higher size, V C value increases towards the center of the network. Figure 5 shows the top view of the network which distinguishes beAlgorithm 1 First Node Selection Inputs: appS ize: Size of the entering application, newM apped: Incoming application; newReleased: Released application; Outputs: Cf n : The selected ﬁrst node for the mapping; Constants: M : Size of the network; groupLength: Number of square groups equal to [( Global Variables: V C [M ][groupLength]: Vicinity counter array; maxV C [groupLength]: Maximum vicinity counter in each group; M (cid:0) 1)=2]; p Body: p 1: Cf n maxV C[( 2: if newM apped then for each Cxy 2 newM apped do addC ore(Cxy ); appS ize(cid:0)1)=2] 7: if newReleased then for eachCxy 2 newReleased do releaseC ore(Cxy ); 3: 4: 5: end for 6: end if 8: 9: 10: end for 11: end if Algorithm 2 Updating VC Values Inputs: nxy : Input core located in Row x and Column y ; Variables: V C : Vicinity counter for each node in a square; maxV C : Node with the maximum vicinity counter in square; D : Distance variable; Constants: maxRadius: The maximum radius length of the square M (cid:0) 1)=2); //M is the network size; (( Outputs: Updating the global variables deﬁned in Algorithm 1; p Body: 1: for each core nij located in Row i and Column j do 2: ′ = maximum(ji (cid:0) xj; jj (cid:0) y j); r 3: Dij + = r for r = 1 to maxRadius do ′ ; ′ (cid:21) 0 then ′ ; V C r ij -= r - r if V C r ij > maxV Cr then maxV Cr V C r ij ; else if r (cid:0) r 4: 5: 6: 7: 8: 9: 10: 11: 12: end if 13: end if 14: end if 15: end for 16: end for if V C r ij = maxV Cr and Dij < DmaxV Cr then maxV Cr V C r ij ; tween optimal and non-optimal regions for incoming application of any size. This approach makes it simpler to choose preferable ﬁrst node by prioritizing nodes with higher V C . With every new application mapped onto the system, the V C values for all corresponding un-occupied nodes gets updated accordingly. Figure 6 shows the updated VC values after 3 applications App1, App2 and App3 being mapped for square groups of radius 1 to 4 (SG-1 - SG-4). Nodes in the proximity of mapped regions gets assigned to a lower VC value , while this impact lessens as we move away from occupied regions. Since SG-3 and SG-4 can ﬁt applications of higher sizes compared to that of SG-1 and SG-2, the degradation of VC is much higher for SG-3 and SG-4. The network’s status gets updated and once again is ready to choose preferable ﬁrst nodes for next incoming applications of any size based on updated V C values. Figure 7 shows the updated V C values for square groups 1 to 4, after another application App4 enters the system. The updated values show a further deterioration in VC, making it easier to classify preferable regions for future incoming applications. The proceappS ize(cid:0)1)=2] is chosen dure for handling requests of incoming and exiting applications is shown in Algorithm 1. When an application of size appS ize enters the system, the ﬁrst node that can ﬁt the new application has to be selected. The node which centers the square that can ﬁt appS ize with best possible V C value, maxV C[( p (line 1). Application is then mapped onto the system around the selected ﬁrst node and all the nodes onto which application is being mapped are marked as occupied (lines 2-5). If an application ﬁnishes its execution and leaves the system, all the nodes on which the exiting application ran are now marked as un-occupied. Every time an application enters or leaves the system, status of nodes gets changes. This reﬂects in changing V C values of all the remaining nodes, which is updated as shown in Algorithm 2. For every node, the effective distance from the node to the center of square(s) it belongs to is calculated (line 2). These values accumulated as a sum to compute distance factor for each node (line 3). The V C value for the node is updated based on the node status (W nij ) and its distance from center (r (cid:0) r ′) (line 5). When an application has entered the system, the V C value is computed as a subtraction of node status, while it is computed as addition in case an application has exited (line 5). The node with highest V C value in the group of squares with radius r and with lowest Distance Factor is chosen as the maxV Cr , which in turn will be the ﬁrst node for any incoming application that ﬁts in square with radius r (line 7). V C values get updated progressively node by node starting from a recently occupied ﬁrst node. So, the complexity of the algorithm would be O(appS ize (cid:2) M ). This latency consumed in updating VC values may affect a newly arriving applicationâ ˘A ´Zs throughput, if it arrives while the VC values are still being updated. In case a new application arrives later, the ﬁrst node can be calculated immediately as the VC values are already updated, proactively. In practice, the algorithm is much faster than the worst case and terminates in a constant time, subject to arrival of new applications. Therefore, the speedup of the algorithm depends on the probability of application arrival in time. If the application queue is full, calculating ﬁrst node is of O(appS ize (cid:2) N ) complexity, as V C values should be updated with exit of an application and arrival of a new application. When the application queue is empty (not full) and also in case of time gap between the arrival of two consecutive applications, the ﬁrst node for the next application can be proactively calculated. For example if App1 arrives at t=0 and the next application App2 arrives at t=1ms, there would be 1ms time for the algorithm to calculate the ﬁrst node for App2, and this time consumed will not reﬂect in App2’s throughput. 4. EXPERIMENTAL RESULTS AND EVALUATION To evaluate our proposed ﬁrst node selection approach (MapPro), we compare it against state-of-the-art ﬁrst node selection by hill climbing (SHiC) proposed in [12], along with other relevant ﬁrst node selection strategies of Nearest neighbor (NN) [6] and Incremental selection (INC) [7]. In order to gain insight on impact of ﬁrst node selection strategies, we employed the same contiguous mapping approach proposed in [11], CoNA, for all cases. The evaluation is consolidated to four NoC-based systems that use MapPro, SHiC, INC and NN as ﬁrst node selection methods followed by CoNA for mapping around selected ﬁrst node. 4.1 Evaluation Metrics We evaluate all the ﬁrst node selection strategies over different metrics that indicate network efﬁciency in terms of performance, energy efﬁciency, dispersion, internal and external congestion. The (a) SG-1 (b) SG-2 (c) SG-3 (d) SG-4 Figure 5: Initial VC values for different Square Groups (a) SG-1 (b) SG-2 (c) SG-3 (d) SG-4 Figure 6: VC values for different Square Groups with 3 applications mapped Table 1: AMD, MRD and APL of ﬁrst node selection strategies over 12(cid:2)12 NoC Table 3: AMD, MRD and APL of ﬁrst node selection strategies over 16(cid:2)16 NoC Method AMD MRD Avg. Latency Method AMD MRD Avg. Latency MapPro SHiC INC NN 2.38 3.08 3.76 3.71 2.81 3.39 3.14 3.96 22.96 23.33 23.51 23.59 MapPro SHiC INC NN 2.30 2.74 3.74 2.98 2.65 3.13 4.09 3.41 21.25 22.50 25.44 23.26 Table 2: AMD, MRD and APL of ﬁrst node selection strategies over 14(cid:2)14 NoC Table 4: AMD, MRD and APL of ﬁrst node selection strategies over 18(cid:2)18 NoC Method AMD MRD Avg. Latency Method AMD MRD Avg. Latency MapPro SHiC INC NN 2.23 2.31 3.16 2.46 2.66 2.76 3.50 2.81 21.40 21.48 23.99 21.73 MapPro SHiC INC NN 2.38 2.53 2.95 2.52 2.71 2.81 3.41 2.79 21.34 22.26 22.95 21.81 evaluation metrics used are listed below. AMD and AWMD: Manhattan distance (MD) is the number of hops to be traversed by a packet from its source node to destination node. Average Manhattan Distance (AMD) is the average of hops traversed (MD) by all the communicating nodes in a mapped application. A lower AMD indicates fewer number of hops traversed by packets indicting lower energy consumption. Average Weighted Manhattan Distance (AWMD) represents the volume of packets that traverse each hop as opposed to hop count alone. AWMD represents energy consumption of the network, as it is directly related to number of packets and number of hops each packet traverses. APL: The time taken by a packet injected into the network from a source node till it is received at the destination node is traced as packet latency. Average of latencies of all the plackets in the network is reported as Average Packet Latency (APL). APL represents networks’s performance in terms of total time consumed to route all packets. External Congestion: Number of contended packets belonging to different applications is the external congestion. We trace the packets congested from different applications as a metric representing the interference of one application’s trafﬁc on another. MRD and NMRD: Mapped region dispersion (MRD) is the average of pairwise Manhattan distances of all communicating nodes of a mapped application. Higher MRD indicates longer distance (a) SG-1 (b) SG-2 (c) SG-3 (d) SG-4 Figure 7: VC values for different Square Groups with 4 applications mapped (a) 12(cid:2)12 (b) 14(cid:2)14 (c) 16(cid:2)16 (d) 18(cid:2)18 (e) 20(cid:2)20 Figure 8: Performance, Congestion and Dispersion of ﬁrst node selection strategies over different network sizes Table 5: AMD, MRD and APL of ﬁrst node selection strategies over 20(cid:2)20 NoC Method AMD MRD Avg. Latency MapPro SHiC INC NN 2.24 2.31 2.49 2.42 2.60 2.68 2.82 2.70 21.37 21.14 21.86 21.65 among communicating nodes and hence more probability of interfering with mapped regions of other applications. The Normalized MRD (NMRD) is a metric that evaluates the squareness of the mapped region, independent of the size of the application such that NMRD for a perfect square region is 1 [12]. A dispersed mapping results in NMRD higher than 1, indicating more fragmented regions. 4.2 Experiment Setup We evaluate our proposed approach against other relevant peer works on a cycle-accurate many-core platform implemented in SystemC. We used a pruned version of Noxim [14] to provide the communication architecture between Processing Element modules. Dynamic application mapping is handled through a central manager (CM) assigned to the node n0;0 , which is responsible for servicing incoming application requests by ﬁnding a suitable ﬁrst node. It behaves as a master core that implements software routines for ﬁst node selection, task allocation and updating VC values of other nodes. Since it holds information regarding mapping decisions and task allocation, it automatically updates VC values of nodes with arrival of a new application without any communication overhead. Applications of different sizes in the range of 4 tasks up to 20 tasks with synthetic trafﬁc patterns are generated from [1] for evaluation. The communication volume of each application is distributed as gaussian variation. In addition to the synthetic trafﬁc, we also used soft real-time applications of MPEG4 and VOPD in our evaluation. Applications arriving the system enter the schedule’s FIFO like buffer and are serviced in ﬁrst-come-ﬁrst-serve basis. The CM services incoming application’s request by ﬁnding a suitable ﬁrst node, subject to spatial availability of the network. Applications that ﬁnish execution are released from the network, making space for new applications to enter. 4.3 Results We simulated ﬁrst node selection methods of MapPro, SHiC, INC and NN over a same sequence of 200 applications that entered, executed and released from the system. We collected AWMD, external congested packets and NMRD metrics to evaluate perforover network sizes ranging from 12(cid:2) 12 up to 20(cid:2) 20. Figure 8 mance, congestion and dispersion of the approaches respectively shows these evaluation metrics over different network sizes. MapPro has better AWMD, NMRD and external congestion in comparison with all the other ﬁrst node selection strategies. It performs particularly well in minimizing external congestion and dispersion due to allocation of square shaped regions and selection of contiguous regions for every new application. The turn around time of an application is the time elapsed between its arrival at the scheduler until it exits the system, while execution time is the time elapsed from the task allocation till the end of execution. MapPro provides a turn around time that is same as execution time unlike the other strategists which spend considerable amount of time in calculating an optimal region. The other metrics of AMD, MRD and Average packet latency (APL) for different network sizes are presented in Table 1 - 5. MapPro has a better MRD attributed to its favoring of square shaped regions. A square has the least possible radius among convex regions and thus the maximum hop distance in a square is limited (as opposed to a rectangle). This also reﬂects on AMD, although AMD and APL can be inﬂuenced by the chosen mapping algorithm CoNA to a large extent. 5. CONCLUSIONS A proactive region selection strategy (MapPro) for mapping applications onto NoC-based many-core systems at runtime was proposed. Our strategy proactively calculates the propagated impact of spatial availability and dispersion on the network with every new mapped application. We exploited the idle time between two consecutive mapping requests to perform quantitative analysis on the network and ﬁnd rational candidate regions to accommodate an incoming application that results in minimal congestion and dispersion. Our approach eliminates the overhead caused with typical reactive mapping approaches. The performance, congestion and dispersion metrics are used to compare MapPro against other recently proposed ﬁrst node selection methods. Simulations of different trafﬁc patterns over different sizes of networks showed considerable improvement in terms of higher network performance, lower congestion and dispersion, at a minimal execution time. First node selection based on power constraints and thermal issues is planned for future work. Acknowledgment The authors acknowledge the ﬁnancial support by the Academy of Finland project entitled ""MANAGE: Data Management of 3D Systems for the Dark Silicon Age"", University of Turku graduate school (UTUGS), EU COST Actions IC1103: Manufacturable and Dependable Multicore Architectures at Nanoscale (MEDIAN) and IC1202: Timing Analysis on Code-Level (TACLe). The authors want to thank Mr. Mohammad Fattah for setting up NoC based system simulator with dynamic mapping feature. 6. "
Dark Silicon - From Computation to Communication.,"In the emerging Dark Silicon era, not all parts of an on-chip system (i.e., cores, Network-on-Chip, and memory resources) can be simultaneously powered-on at the full speed. This paper aims at exposing dark silicon challenges to the NOCS community with an overview of some of the early research efforts that are attempting to shape the design and run-time management of future generation heterogeneous dark silicon processors. The goal is to cover both the computation and communication perspectives. In particular, we exploit computation and communication heterogeneity at multiple levels of system abstractions to design and manage dark silicon processors. The available dark silicon is leveraged to improve power/energy, performance, and reliability efficiency.","Dark Silicon – From Computation to Communication Jörg Henkel* , Haseeb Bukhari§ , Siddhar th Garg† , Muhammad Usman Karim Khan* , Heba Khdr* , Florian Kriebel* , Umit Ogras‡ , Sri Parameswaran§ , Muhammad Shaﬁque* † ‡ § *Chair for Embedded Systems (CES) Karlsruhe Institute of Technology Germany Depar tment of ECE New York University USA Depar tment of ECEE Arizona State University USA School of Computer Science and Engineering University of New South Wales Australia Corresponding Author : muhammad.shaﬁque@kit.edu ABSTRACT In the emerging Dark Silicon era, not all parts of an on-chip system (i.e., cores, Network-on-Chip, and memory resources) can be simultaneously powered-on at the full speed. This paper aims at exposing dark silicon challenges to the NOCS community with an overview of some of the early research eﬀorts that are attempting to shape the design and run-time management of future generation heterogeneous dark silicon processors. The goal is to cover both the computation and communication perspectives. In particular, we exploit computation and communication heterogeneity at multiple levels of system abstractions to design and manage dark silicon processors. The available dark silicon is leveraged to improve power/energy, performance, and reliability eﬃciency. 1. INTRODUCTION The cost of designing compute-eﬃcient on-chip systems has increased dramatically with shrinking node sizes as the limits of the laws of physics are reached [2, 25, 26]. Due to the exponential dependency of the leakage power on the threshold voltage, the (threshold and supply) voltage scaling does not keep pace with the area scaling. This results in the discontinuation of the Dennard’s scaling model that leads to high on-chip power densities and thermal hotspots, which cannot be mitigated through economically feasible cooling techniques and packaging. Its consequence is the so-called Dark Silicon problem, where a signiﬁcant amount of computation, communication, and memory resources of an on-chip system cannot simultaneously be powered-on at full speed for a given Thermal Design Power (TDP) constraint, and thus must stay dark (i.e., power-gated) or gray/dim (i.e., operating at a low power, low-throughput mode). During the recent years, a number of research groups have explored design issues for dark silicon processors. A comprehensive survey of such techniques can be found in [21, 22]. For eﬃcient design and management of on-chip systems in the dark silicon era, it is crucial to accurately estimate the amount of dark silicon in the upcoming technology nodes and analyze the resulting thermal proﬁles of such processors under diﬀerent TDP constraints. Early eﬀorts by Esmaeilzadeh et al. [7] provided over-estimations, for instance, they predicted that about 80% of the chip area will be dark at the 8nm technology node. Furthermore, their predictions for 22nm already did not show up in the current generation Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org NOCS’15, September 28-30, 2015, Vancouver, BC, Canada. Copyright 2015 ACM ISBN 978-1-4503-3396-2/15/09 ...$15.00. http://dx.doi.org/10.1145/2786572.2788707. of processors. The main reason of inaccuracy in their prediction is the modeling of dark silicon as a function of the chipwide constant power budget, such that the number of active cores are chosen based upon their total power consumption, which should not exceed a predeﬁned TDP budget. However dark silicon is the direct consequence of the increased power density and its thermal eﬀects. Therefore, considerations of peak/critical temperature and thermal simulations, under given coolant and packaging settings, are important for accurate dark silicon estimation. Esmaeilzadeh@ISCA'11 Henkel@DAC'15 100 75 50 25 0 n e o g c a i l i t n S e k c a e P r r D 16 nm 11 nm 8 nm Figure 1: Comparing Diﬀerent Prediction Trends. Recently, in [10], we have performed a new set of dark silicon predictions based on the technology scaling data from ITRS [1] and Intel [6] and using advanced processor power management features. This work models dark silicon based upon the temperature constraints. According to it, for the 8nm technology node, the estimated dark silicon is about 50% at the full performance mode and about 30% in the low-power operational modes. Furthermore, the amount of dark silicon also depends upon the ILP and TLP1 nature of the applications. Figure 1 illustrates both previous and recent dark silicon predictions at diﬀerent technology nodes. Detailed predictions for diﬀerent operational scenarios can be found in [10]. Given dark silicon estimates, the design automation and architecture communities need to address several new challenges related to eﬃcient design and management of dark silicon processors. It is envisaged that the dark silicon processors will potentially feature a heterogeneous mix of computing and communication resources. Examples of such architectures have already started showing up on the processor landscape, like the ARM big.LITTLE processor. Further, dark silicon processors will experience diﬀerent patterns of dark/powered-on cores and/or cores running at different voltage-frequency levels, that will introduce additional challenges to realize eﬃcient on-chip communication networks, unseen before the dark silicon era. Towards this end, this paper aims at exposing several critical challenges related to computation- and communication that are introduced by dark silicon, and highlights some of the early research eﬀorts that are attempting to shape the design and run-time management of future generation heterogeneous dark silicon processors. The key is to leverage the available dark silicon budget to improve quality metrics 1 ILP and TLP stand for Instruction- and Thread-Level Parallelism, respectively. 1       (like performance, power/energy eﬃciency, and reliability) within peak power and thermal constraints. Our broader goal is to spur greater awareness of these challenges in the relevant communities like Network-on-Chip (NoC), design automation, and architecture, and to position the dark silicon challenges such that these communities can have a large impact on solution of these problems. 1.1 Contributions of This Paper The key idea is to overprovision the chip with heterogeneous computing and communication resources and to select the subset of these resources at run-time, that maximizes the desired ob jective within the TDP budget and/or thermal constraints. For instance, one can employ compute resources (e.g., application-speciﬁc accelerators or cores) and communication networks with diﬀerent power, performance and reliability characteristics, and ob jectively select them at run time for eﬃcient processing. The contributions of this paper are: • We provide an overview of research challenges for dark silicon processors from the perspective of computation and • We present a comprehensive design and management ﬂow communication resources. (Section 2). • We explain some recent techniques on dark silicon-aware for heterogeneous dark silicon processors (Section 3). design and management of heterogeneous computation and communication resources aiming at performance and reliability optimization under peak power or thermal constraints (Sections 3.1, 3.2, 3.3, 3.4, 3.5). 2. CHALLENGES IN DARK SILICON ERA 2.1 Computation Challenges At design-time, the challenge is how to design computational resources (like cores and accelerators) that can support heterogeneity w.r.t. functionality, area, power, performance, and reliability properties. A mixture of such heterogeneous resources will not only alleviate the dark silicon problem but will also enable an eﬃcient run-time management of computational resources. The subsequent challenge is to devise eﬃcient lightweight management policies, considering mixed multithreaded workloads (i.e., concurrently executing applications with diverse ILP and TLP properties), that aim at improving performance, power/energy eﬃciency, and reliability under TDP, peak power and/or thermal constraints. For throughput maximization, the dark silicon-aware run-time system must determine the type, number, location, and power-state (i.e., dark or power-on, and voltage-frequency level) of the computational resources. In fact, as we will discuss in Section 3.4, this problem is challenging even if all cores on the chip are homogeneous. In addition, in Section 3.3, we will discuss potential scheduling solutions for heterogeneous processors such as the ARM big.LITTLE. Similarly, for minimizing the overall power consumption or to improve the energy eﬃciency, the workload from the cores can be oﬄoaded to the energy-eﬃcient shared pool of hardware accelerators that are connected via an on-chip network; see Section 3.1. Afterwards, the frequencies of the cores can be adjusted by solving a power optimization problem under throughput constraints. Besides performance and power, improving reliability eﬃciency and predictability have also emerged as the ﬁrst-class design metrics in the nanoscale technologies. Therefore, another important question is: whether and how can the potentially dark silicon be leveraged to improve the reliability of on-chip systems. Towards this end, Section 3.5 will discuss the exploitation of dark silicon to enable reliabilityheterogeneous cores and to mitigate diﬀerent reliability threats. 2.2 Communication Challenges Another important challenge in a dark silicon processor is: how to eﬃciently interconnect a large pool of computational resources (cores and accelerators) operating in diﬀerent power states (dark/on, diﬀerent voltage-frequency levels) while fulﬁlling the communication requirements of the active resources. Furthermore, considering the diversity in applications’ requirement, designing a NoC that can be used for diﬀerent scenarios and diﬀerent applications is an uphill task as designers have to cover potentially contradicting design requirements, like reduce power/energy consumption, improving throughput, and reducing error rates (i.e., improving reliability). In Section 3.2, we will discuss one solution towards leveraging dark silicon to realize optimized heterogeneous NoC architectures for multiple use scenarios. It will introduce darkNoC [4] that supports multiple energy-eﬃcient network layers consisting of architecturally identical routers, but are optimized at design time to operate within diﬀerent voltage and frequency ranges. Only one network layer is active at a given time while the rest of the network layers are dark (deactivated). We will show that an adaptive dark siliconaware NoC is another way to increase performance within the TDP constraints or alternatively, to reduce communication power without sacriﬁcing communication latency and throughput, and thus providing a larger share of the TDP to the computational resources. 3. HETEROGENEOUS DARK SILICON PROCESSORS Fig. 2 shows the proposed architectural template of heterogeneous dark silicon processors along with its architectural, management, and application layers. The architecture consists of Heterogeneous Tiles (HTs) connected via a darkNoC on-chip interconnect. The heterogeneous tiles can be composed of diﬀerent core types following diﬀerent forms of heterogeneity, a couple of example forms of which are listed below. Functional Heterogeneity exists in the form of computing resources with diﬀerent functional behaviors and architectural properties, for instance, application-speciﬁc hardware accelerators, general purpose RISC and superscalar cores, GPU, and reconﬁgurable fabrics. A tile may exhibit multiple of these compute resources. Accelerator Heterogeneity denotes the ﬂexibility in accessing the on-chip hardware accelerators. An accelerator can be classiﬁed depending upon its accessibility by the following: (1) In-core accelerators that are embedded inside the computational pipeline of a core and only accessible by that core; (2) Tightly-coupled accelerators that are available to a speciﬁc set of cores (e.g., inside a tile); and (3) Decoupled accelerators that are available to all the cores via interconnect fabric (i.e., darkNoC). Micro-Architectural Heterogeneity enables cores with the same instruction-set architecture (i.e., iso-ISA cores) but diverse power, performance, and reliability characteristics. For example, the “Accelerator Tile” in Fig. 2 contains multiple clusters of so-called Big and Little cores that implement same ISA but provide performance-power tradeoﬀs (see details in Section 3.3). Similarly, the “Reliability Tile” exhibits iso-ISA cores with diverse reliability properties, such that, diﬀerent types of cores are protected using diﬀerent reliability mechanisms, and thus enabling area-power-reliability tradeoﬀs (see details in Section 3.5). 2 Application Layer  Malleable Applications with Varying  Degree of Parallelism (DoP)  App1  Appj  AppK-1  AppK  Application   Characterization  P o D V/F levels VF vf1 ... vfmax TH 1 . . thmax (Power,  Throughput) Dark Silicon-Aware  Power, Thermal  and Reliability  Management  Hardware Layer with Computation and Communication Heterogeneity  Figure 2: Heterogeneous Dark Silicon Processors: Architecture and Management Layers. On-chip Interconnect Heterogeneity is enabled by iso-functional routers with heterogeneous microarchitecture providing diverse power, performance and area properties, and that are leveraged to realize multiple cascaded interconnection networks (see “Router” box in Fig. 2) and even using diﬀerent network topologies. Depending upon the execution context, only one network layer is active at any point in time while the others are kept dark. Besides the above-discussed forms, heterogeneity may exist in form of: (1) Technology Heterogeneity that results from deploying device technologies for each component, for instance, CMOS or steep-slope technologies providing a tradeoﬀ between performance and power; and (2) Process Variation -Induced Heterogeneity that manifest as core-to-core and chip-to-chip variations in the leakage power and frequencies even for identical core / tile architectures. In a heterogeneous dark silicon processor, several applications with diverse ILP/TLP (Instruction- and Thread-Level Parallelism) properties execute. These applications are malleable in nature, i.e., can adapt their degree-of-paral lelism (DoP) by incarnating less or more threads depending upon the workload requirements, available resources, and system state (e.g., temperature). While the performance of TLP applications improve with increasing DoP, high ILP applications beneﬁt from high V/F (voltage-frequency) levels. A Dark Silicon-Aware Management System manages the set of active/dark cores, applications’ DoP, thread-to-core mapping, reliability levels, active NoC layer, and the V/F levels of active cores and routers (i.e., Dim or Gray levels for computation and communication resources), under peak power and/or thermal constraints. This correspond to diﬀerent run-time contexts, each providing diﬀerent performance/power, spatio-temporal thermal proﬁles, and reliability while satisfying the given TDP or critical temperature constraints. In the following, we will discuss our early research eﬀorts on addressing the computation and communication challenges that we highlighted in Section 2 for the heterogeneous dark silicon processors. 3.1 Accelerator-Based Design for Dark Silicon Applications running under strict throughput constraints enforce a heavy computational pressure on the underlying hardware. Such applications include video encoding/decoding, video pre- and post-processing, audio processing, encryption/decryption etc. Most of these applications demand large amount and high clock frequency of the underlying resources. Thus, the dark silicon might prohibit meeting the deadline constraints of the current solution, or its future extensions, as the power required to sustain the throughput might exceed TDP. An interesting solution is to employ application-speciﬁc hardware accelerators (a compute intensive, highly accessed part of the program running in custom hardware). Accelerators are a natural remedy to the Dark Silicon, whereby a reduced clock frequency of the accelerator (a lower impact on the temperature of the physical area occupied by the accelerator) can be leveraged by its high computational eﬃciency. Scheduling the hardware accelerator for power minimization of a many-core system, such that multiple competing soft-cores (cores running software part of the application) can oﬄoad their tasks to the accelerator and meet their deadlines. Since accelerator is allocated to a single soft-core at a time, it is possible that if not properly designed, the applications/threads might miss their deadlines or consume more than required power (elevate chip’s temperature). In [12], we propose a hardware accelerator scheduling scheme to allocate a shared hardware accelerator to competing cores on a many-core system, while fulﬁlling the above mentioned challenges. The architecture of the system is shown in Fig. 3(a), where a control module derives the voltage/frequency levels of the cores. Cores, external memory and the accelerator module are connected with each other via a NoC. Note that the accelerator module has an inbuilt controller (used for arbitration), custom-logic and on-chip scratchpad memory. The proposed scheduler actually controls the arbiter, by granting access to individual cores, such that the selected core can oﬄoad its workload to the accelerator. The goal of the scheduling and control strategy is to minimize the system power, while meeting the throughput requirements of the parallel executing applications. In Fig. 3(b), an instance of scheduling scheme is shown for 4×4 variance computing applications, running as separate parallel threads on an eight core system. Note that due to solving the optimization problem for accelerator scheduling, 3 some threads execute more time on hardware than software. Fig. 3(c) reports the frequency of the cores required for this scheduling scenario. Usually, the applications which oﬄoad more require lesser frequency of the cores, to support their throughput and vice versa. ward error correction code (FEC) and detecting and correcting any errors in the incoming data. Equivalence Checker are also used for implementing the Reliability Mode. The checker circuit asserts that the control bits of the two NoC channels are equal. Monitor, Control and Scheduler (a) (b) s r o t l a u g e R y c n e u q e r F d n a e g a t l o V C C C . . . C ) s C o N ( c i r b a F t c e n n o c r e t n I Ctrl Acc SP External  Memory  (DRAM) (c) 2.5 2 1.5 1 0.5 0 ] c e s [ e m i T 1000 800 600 400 200 0 ] Z h M [ . q e r F Hardware Software 1 2 3 4 Core # 5 6 7 8 886 773 679 592 293 248 204 171 1 2 3 4 5 6 7 8 Core # Figure 3: (a) Many-core system with a shared accelerator, (b) time spent by an application on hardware accelerator and in software and (c) frequency of the cores running the respective application. 3.2 On-Chip Networks for Dark Silicon To address the communication-related challenges in dark silicon processors, we present a dark silicon-aware multimode NoC architecture called SuperNet [5]. The architecture consists of parallel architecturally homogenous, but voltagefrequency(VF) optimized heterogeneous NoCs. For energy eﬃcient mode, we leverage the two NoCs for dynamic voltage and frequency scaling (DVFS) by switching on only one NoC depending on application requirements or static conﬁguration. In performance mode, we classify the network packets under the category of critical and non-critical packets, and steer the packets accordingly into either low VF or high VF NoC. In the reliability mode, the two NoCs work in dual lock step mode where one NoC carries the actual data while the other NoC carries the error correction codes. This scheme improves the reliability by mitigating the eﬀects of soft errors in control and data path. We exploited the multiVt circuit optimization available in CAD tools to synthesize architecturally identical NoC routers for a set of target VF levels. • NoC A: This NoC consists of routers designed for [V 1,f ]. NoC A can either be operated at [V 1,f ] or [V 2,f /2] de• NoC B: This NoC consists of routers designed for [V 2,f /2]. pending on the operating mode. NoC B can only be operated at [V 2,f /2]. The layers in the darkNoC [4] are managed by a hardwarebased Fabric Manager (F M ) that switches between network layers when directed by the dark silicon manager through V/F adaptations. At each network node, multiple routers are managed by a local hardware-based Manager (LM ) which controls the power-gating and port enabling signals for each router. At runtime, F M and LM s autonomously coordinate to seamlessly switch between operating modes without any software intervention. Each node also contains an Application P rof iler U nit. This proﬁler unit keeps track of vital information on application behavior. Each proﬁler unit is augmented with two saturating counters, an instruction counter and a L1 cache miss counter. The counter information is used by FM to implement either the Energy Eﬃcient Mode or the Performance Mode. Every Network Interface (NI) is augmented with an Error Detection and Correction Unit for use in the Reliability Mode. The EDC unit is responsible for encoding the outgoing data from NI with for4 Figure 4: Overview of SuperNet Design and Management Methodology [5] based on the darkNoC Architecture [4] When the chip is switched on, FM by default initializes the SuperNet in the normal mode (i.e, only NoC A is powered on with [V 1,f ]). Depending on various factors such as power budget, reliability requirement etc., chip user can decide to activate a certain SuperNet mode.The NoC modes are as follows: Energy Eﬃcient Mode: We base our Energy Eﬃcient Mode on the fact that not all applications need a low latency NoC. Application with higher cache misses per kilo instructions (MPKI) [17] values spend a ma jor portion of time waiting for the cache load miss to be served from memory controller through the NoC. Therefore, depending on application’s current MPKI, the NoC can be clocked at different frequencies. SuperNet implements a coarse grain DVFS method with two VF levels. When the VF level [V 1,f ] is used, NoC A is operational and NoC B is power gated. Whereas, when the VF level [V 2,f /2] is used, NoC B is used and NoC A is switched oﬀ. In [4], we showed that using NoC that is optimized for a speciﬁc VF level is more energy eﬃcient than using a scaled VF on a NoC that has been designed for a higher VF level. Type Length Load Request 1f lit Load Request Reply (cache line size)/8 + 1f lits Store Request (cache line size)/8 + 1f lits Store Request Ack 1f lit Critical? yes yes no no Table 1: Packet Classiﬁcation Performance Mode: The Performance Mode for SuperNet is based on the fact that not all packets in the NoC are critical to the performance of the application. We have classiﬁed the possible packet types in Table 1. We assume an MPSoC with an in-order core and therefore the core stalls in case of a cache loads misses. Thus, it is critical to deliver the LoadRequest and LoadRequestReply as quickly as possible. Whereas, the process of sending the evicted cache line to the memory controller happens in parallel to the execution and therefore the StoreRequest and StoreRequestAck packets are not critical for application performance. We leverage the two NoCs available in SuperNet to implement the performance mode. FM switch on both NoC A(with [V 1,f ]) and NoC B at the same time. At runtime, the cores in                  ject LoadRequest packets in the NoC A and StoreRequest in the NoC B. Whereas, the memory controller inject the LoadRequestReply packets in the NoC A and StoreRequestAck packet in the NoC B. The intuition behind the steering scheme is to reduce the contention between critical and non-critical packets by physical separation. However, this scheme is implemented at the cost of increased NoC power as compared to normal operation because two NoCs are used instead of a single NoC. Moreover the performance mode is only useful for applications where network load is high due to a high application MPKI. Therefore, FM can enable or disable the performance mode based on power budget and application characteristics. Figure 5: An overview of SuperNet Architecture Reliability Mode: The Reliability Mode for SuperNet enables the detection and correction of soft errors in the NoC. The scheme can provide protection against soft errors in both data path and control path. In this mode both NoCs are used at the same time. Reliability Mode use NoC A and NoC B in parallel by operating them at [V 2, f /2]. Router’s data path is protected through the use of strong single error correction, double error detection codes (SECDED) in a forward error correction mode (FEC). The Error Detection and Correction Unit (EDC) is used to generate a (13,8) BCH code (8 bit data generate 5 bit code). In SuperNet we only encode the data at the time of packet injection and only try to check and correct the data at the receiver node. In SuperNet, we employ the idea of dual modular redundancy (DMR) and lock step processing to protect the router control path against the soft errors. Both NoCs are architecturally homogenous and are operated at the same frequency. Therefore, routers from diﬀerent NoCs at a given mesh node are expected to generate the same output. In case the equivalence check fails, an error is raised for LM. For evaluation, we performed experiments on a 64-core mesh NoC-based dark silicon manycore processor. We used two step system simulation methodology where memory access trace of each application executing on a processor is collected from Xtensa instruction set simulator. These memory access traces are then simulated through a closed loop cycle-accurate NoC and DRAM simulator. We selected 8 application from SPEC2006 and MediBench suits. We target two VF levels for the router design in this paper, [1GHz, 0.9V] and [500MHz, 0.81V]. We synthesized the router RTL with Synopsys Design Compiler version H-2013.03-SP4 using TSMC 45nm libraries. The results for experiments with the performance mode are shown in Figure 6. We report the values for N oC P ower and Average I P C . All the results are normalized to a system where only [1GHz, 0.9V] NoC is used. The performance mode for SuperNet is clearly useful for application with high MPKI. For the application h264enc, the average IPC is improved by 17%. Similarly for another application bz ip2, the average IPC is improved by 14%. This improvement comes at a cost of increase in NoC power by 13% and 11% for h264enc and bz ip2, respectively. The results for experiments with the energy eﬃcient mode are shown in Figure 7. All results are normalized to a system where only [1GHz, 0.9V] NoC is used with a ﬁxed VF level. it is evident that using multiple multi-vt optimized NoCs provide better power savings than using DVFS with a single NoC. by using Energy Eﬃcient Mode of SuperNet we are able to save NoC power by 75% for mpeg2enc, 65% for j peg enc, and 81.5% for sha applications. The power saving comes at a cost of small decrease in I P C by 0.9%, 6% and 0.1% for mpeg2enc, j peg enc, and sha applications, respectively. The results for experiments with the reliability mode are shown in Figure 8. unning SuperNet in reliability mode can cause some degradation in chip performance for applications with moderate to high MPKIs. The reason for drop in performance is the fact that the NoC is operated at a lower frequency of 500M H z . Overall, the relative NoC power is low due to two reasons: (1) reduced VF level, and (2) longer execution times. Therefore, Reliability Mode can be used even when there is strict power or thermal constraint. 3.3 Scheduling Policies for Heterogeneous Dark Silicon Processors ) C o ( 100 90 80 70 60 50 40 30 e r u t a r e p m e T Platform Shuts down  Default OS Policy   Little + Big Opportunistic  Little Preferred (proposed) Throttling of big cores  due to temperature spikes  0 200 400 600 Time (s) 800 1000 1200 Figure 9: Thermal proﬁle for three diﬀerent scheduling policies. Integration of big and little cores results in a large dynamic range both in power consumption and performance by dynamically controlling the type, number, and frequency of active cores. Consequently, traditional scheduling policies, which have been typically limited to homogeneous processors with the sole goal of performance optimization, need to be reconsidered by accounting for heterogeneity and energy efﬁciency explicitly. As a motivational case study, we examine the use of a big-little processor used as a microserver, i.e., a low power server, in a datacenter to serve web search queries. Scheduling policies that focus only on performance can quickly exceed the chip thermal budget and result in system shut-down for dark silicon chips. Indeed, the default scheduling policy on the commercial big-LITTLE platform opportunistically uses more big cores as jobs arrive, and then turns on little cores when the big cores are fully utilized. Consequently, the core temperature spikes quickly causing the platform shut down despite the fan, as depicted in Figure 9. An alternative is to utilize the little cores ﬁrst, and start using the big cores only after all the little cores are fully sient temperature spikes, shown in Figure 9 (blue ◦ markers), utilized. Although this prevents system shut-down, trancause the big cores throttle, thus reduce performance. The motivational example above illustrates that indiscriminate use of big cores results in thermal instability. To address this issue, in [11] we propose a new class of scheduling policies that activate big cores judiciously based on the fol5     Figure 6: Results for Performance Mode Figure 7: Results for Energy Eﬃcient Mode Figure 8: Results for Reliability Mode lowing two criteria: (i) the number of outstanding search queries exceeds a certain threshold (these are referred to as threshold policies in literature); (ii) there are “critical” jobs in the queue that may miss their deadlines. The queue-based threshold serves as a measure of workload intensity, and allows the scheduling policy to adapt to dynamic variations in arrival rate. When there is only one big and little core, the threshold policy that preferentially uses the big core and only uses the little core when the occupancy exceeds a threshold has been shown to minimize mean service time [16]. However, this policy leads to thermal instability. In contrast, by preferentially using the little cores and judiciously activating the big cores, the proposed policies result in not only thermally-safe behavior (as shown in Figure 9 (red (cid:2) markers)), but also signiﬁcantly improve power and energy-eﬃciency compared to baseline approaches. What is more, we also account for SLAs by explicitly checking for deadline violations, and scheduling the critical jobs to the big cores. To further illustrate the proposed solution, Figure 10 illustrates the number of big cores activated with time for the baseline policy in which big cores are opportunistically used whenever all little cores are occupied, and our proposed policy in which big cores are only activated when the number of outstanding jobs exceeds a threshold. The proposed threshold policy is thermally stable because it accounts for the dark silicon constraints — note that all in almost all cases only two big cores are activated simultaneously. The baseline policy, which is not thermally stable, attempts to turn on three and sometimes four big cores too frequently. Figure 10: Number of big cores active for ”Little + Big Opportunistic” and proposed threshold policy. 3.4 Thermal Constrained Dark Silicon Management The state-of-the-art models dark silicon as a power budget constraint and propose power management techniques to choose the number of active cores and the voltage frequency levels such that the total power consumption does not exceed the predetermined power budget; i.e., Thermal Design Power (TDP). However, as illustrated in [18], TDP constraint is not 6 enough to model dark silicon, because TDP does not guarantee avoiding thermal violation. When a thermal violation occurs, dynamic thermal management (DTM) on chip will be triggered, which might power-gate some cores to reduce the temperature, and that in turns leads to additional dark cores. Therefore, a new aspect of power budgeting is proposed in [18] that provides a thermally safe power budget that guarantees avoiding thermal violation. However, applying a uniform power budget on the cores can limit the ability of maximizing the performance, especially when multiple applications with diﬀerent power characteristics are mapped to the chip. TDP Tcritical Offline  Management Optimal Resource  Distribution Application Mapping Dark Cores  Adaptation Hardware Model Process Variation Application Model App1 … Appj …AppK Runtime Management Temperature  Prediction Light-weight Patterning and  Application  Mapping Monitoring  Constraints DVFS /  Task Migration Update Pattern Figure 11: Dark Silicon Management: Illustrating oﬄine and online dark silicon management under thermal constraint. Therefore, recent works [13, 23] model dark silicon as a thermal constraint, and they directly manage the temperature in their proposed technique in dark silicon chips. Unlike conventional chips where it is assumed that all cores are powered-on, dark silicon processors exhibit multiple modes of the cores, which are: 1) Active cores that are powered on at full voltage frequency level. 2) Grey cores that are powered on at lower voltage frequency levels. 3) Dark cores that are powered gated. These modes result in starkly diﬀerent thermal proﬁles, and that should be taken into account in the proposed thermal management technique. An oﬄine scheme presented in [13], namely DsRem determines the mode of each core (active, grey, dark) in order to maximize the performance under thermal constraint. DsRem consists of three steps: 1) Optimal resource distribution under TDP constraint considering diﬀerent Thread Level Parallelism (TLP) and Instruction Level Parallelism (ILP). 2) Application mapping that considers the locations of dark cores such that the peak temperature is reduced as possible, which ultimately helps in avoiding thermal violation. 3) Resource adaptation under thermal constraint to avoid any potential thermal violation and exploit any thermal headroom. The last step can be implemented at runtime. A recent runtime scheme is proposed in [23] that deﬁnes what is called dark silicon patterning, which determines the locations of the threads (active cores) on the chip to reduce the peak temperature. Reducing the peak temperature allows to activate more cores and thereby execute more threads within the safe limits of the temperature. Figure 11 illustrates the main steps of these techniques, while their details are explained in [13, 23]. We conduct experiments using these techniques in a previous work [10] to show their impact on both thermal proﬁle and system performance. Figure 12 illustrates the results of these experiments. In summary, the aforementioned works present a new aspects in exploiting dark silicon to maximize the performance. However, these techniques focus only on the computation parts of the chip, and does not consider the communication. Therefore, new research is required to consider both computation and communication in dark silicon management. Active Core Dark Core  [°C] 82 76 70 64 Pattern(a): is exceeded, 52 cores@3.6 GHz, Ptotal=196 W Tcritical Pattern(b): Using DaSim [8] Tcritical is not exceeded 60 cores@3.6 GHz, Ptotal=226 W  ] S P I m e G t [ s e y c S n a a l l m r r e v o O f r e P 2X Speedup  using DsRem TDPmap [4] DsRem [4] 400 300 200 100 0 Parsec Applications Figure 12: Evaluation of dark silicon patterning technique DaSim [23] and comparison between DsRem [13], which is a dark silicon resource management under thermal constraint, and TDPmap which is a resource management under TDP constraint. These experiments are conducted in [10]. 3.5 Addressing Reliability and Variability Besides targeting the optimization of performance, energyeﬃciency and temperature in the era of dark silicon, two additional important aspects associated with the technology scaling have to be considered: transient bit ﬂips due to energetic particles [3] and manufacturing process variations [19]. To increase the reliability of a system, traditionally redundancy is used, e.g., by triplicating hardware structures (TMR) or executing multiple copies of the same thread on diﬀerent cores. However, as the TDP constraint limits the transistors being simultaneously powered on, a full redundancy solution is typically infeasible due to a signiﬁcant degradation of the system performance. Therefore, a library of core types (ranging from unprotected over partiallyprotected to fully protected cores) with the same instruction set architecture, but diﬀerent reliability, power, performance and area properties is provided (see Figure 13(a) for two cores with diﬀerent protection levels and Figure 13(b) for their power/area consumption and the vulnerability of different applications), taking the diﬀerent reliability requirements and characteristics of individual applications [20, 24] into account, that might not demand full TMR. However, due to manufacturing process variations, even cores of the same type and also the same cores on diﬀerent chips can have diﬀerent leakage power consumption and operating frequency characteristics. Consequently, for such variability-aware reliability-heterogeneous architectures two challenges arise: (1) Finding an appropriate set of core types at design time, exploiting the abundance of transistors to cover a wide spectrum of possible runtime scenarios: For that, the level of overprovisioning of cores on the chip is analyzed [14] to be able to avoid using cores with a high leakage power at runtime. The architectural synthesis challenge can then be formulated as a Bounded Knapsack Problem [15] which is solved using a polynomial time algorithm. (2) Managing thread to core assignments at runtime to optimize the systems’ reliability and performance requirements considering the TDP constraint under process variations: For that, a runtime scheduler is used that allocates cores to concurrently executing applications while selecting the cores in a way that minimizes the system vulnerability while staying within in the TDP constraint [14, 19]. Two example architectures with a diﬀerent amount of dark silicon and the respective leakage power of the cores available are shown in Figure 13(c), illustrating that dark silicon can be leveraged to combat the reliability and manufacturing variability problems. 4. CONCLUSION In this paper we have shown that the dark silicon problem pro jected for future technologies requires new solutions to design and manage upcoming on-chip systems eﬃciently. A key aspect is to consider and take advantage of the heterogeneity of both the computation and communication at diﬀerent abstraction layers in future generation dark silicon processors. Early research eﬀorts have been presented that leverage the available dark silicon to improve quality metrics like performance, energy/power-eﬃciency and reliability without violating peak power and thermal constraints. The overall goal of this work is to highlight the dark silicon challenges for the relevant communities (Network-on-Chip, Design Automation and Architecture) in order to motivate new solutions for the problems shown. 5. ACKNOWLEDGMENTS This work is supported in parts by the German Research Foundation (DFG) as part of the Transregional Collaborative Research Centre Invasive Computing [9] (SFB/TR 89 – http://invasic.de) and as part of the priority program Dependable Embedded Systems [8] (SPP 1500 – http://spp1500. itec.kit.edu). 6. "
Improving DVFS in NoCs with Coherence Prediction.,"As Networks-on-Chip (NoCs) continue to consume a large fraction of the total chip power budget, dynamic voltage and frequency scaling (DVFS) has evolved into an integral part of NoC designs. Efficient DVFS relies on accurate predictions of future network state. Most previous approaches are reactive and based on network-centric metrics, such as buffer occupation and channel utilization. However, we find that there is little correlation between those metrics and subsequent NoC traffic, which leads to suboptimal DVFS decisions. In this work, we propose to utilize highly predictable properties of cache-coherence communication to derive more specific and reliable NoC traffic predictions. A DVFS mechanism based on our traffic predictions, reduces power by 41% compared to a baseline without DVFS and by 21% on average when compared to a state-of-the-art DVFS implementation, while only degrading performance by 3%.","Improving DVFS in NoCs with Coherence Prediction Rober t Hesse Natalie Enright Jerger Edward S. Rogers Sr. Depar tment of Electrical and Computer Engineering University of Toronto, Toronto, Canada {hesserob, enright}@ece.utoronto.ca ABSTRACT As Networks-on-Chip (NoCs) continue to consume a large fraction of the total chip power budget, dynamic voltage and frequency scaling (DVFS) has evolved into an integral part of NoC designs. Efﬁcient DVFS relies on accurate predictions of future network state. Most previous approaches are reactive and based on networkcentric metrics, such as buffer occupation and channel utilization. However, we ﬁnd that there is little correlation between those metrics and subsequent NoC trafﬁc, which leads to suboptimal DVFS decisions. In this work, we propose to utilize highly predictable properties of cache-coherence communication to derive more speciﬁc and reliable NoC trafﬁc predictions. A DVFS mechanism based on our trafﬁc predictions, reduces power by 41% compared to a baseline without DVFS and by 21% on average when compared to a state-of-the-art DVFS implementation, while only degrading performance by 3%. Categories and Subject Descriptors C.1.2 [Processor Architectures]: Multiple Data Stream Architectures(Multiprocessors)—Interconnection architectures General Terms Design, Performance Keywords Networks-on-chip, dynamic voltage/frequency scaling, chip multiprocessor, cache coherence 1. INTRODUCTION The steady increase in core counts coupled with power density limitations and the breakdown of Dennard scaling [10] demand NoCs that provide a scalable communication fabric for connecting a large number of resources within a chip. As the NoC expands to meet the performance demands of future many-core processors, it has also become a critical consumer of the CMP’s overall power budget [11]. Dynamic Voltage and Frequency Scaling (DVFS) Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS’15 September 28-30, 2015, Vancouver, BC, Canada c(cid:13)2015 ACM. ISBN 978-1-4503-3396-2/15/09 ...$15.00 DOI: http://dx.doi.org/10.1145/2786572.2786595 . Figure 1: Aggregation of individual trafﬁc ﬂows can limit the NoC’s contribution to the chip’s overall power envelope [16, 7, 5, 20]. Although DVFS has been extensively studied in NoCs [16, 7, 5, 20], previous work mostly focuses on network-performance metrics, e.g., buffer occupation [7], channel utilization [20], roundtrip latency [6], or injection rate [14] to adjust the voltage/frequency (V/F) state of the NoC. Most of these approaches are reactive – they set V/F state based on currently observed network conditions and do not attempt to actively predict future communication requirements. For example, increased buffer occupation only triggers a reaction after the onset of congestion in the NoC and does not attempt to prevent congestion prior to its occurrence. These techniques assume that the future state of the network is predictable solely based on current network state, rather than application behaviour. This only works well when network trafﬁc changes slowly and future network utilization correlates with its current state. In general, this is not the case for most real application trafﬁc that exhibits abrupt changes and phase behaviour [1]. In Sec. 2.3, we show that no obvious correlation exists between current and future channel utilization. We ﬁnd that predictions based purely on past and current network-centric metrics lead to high prediction errors. Poor DVFS decisions can be very costly, either through performance loss due to underpredicting network utilization or wasted energy caused by overpredicting NoC demands. Furthermore, it takes a long time to recover from poor DVFS decisions due to slow transition times for adjusting the voltage and frequency levels (∼100s of cycles [7]). To avoid such costly mistakes, our work focuses on a novel, more reliable method to predict future NoC trafﬁc based on the cause of the trafﬁc, rather than its effect. Trafﬁc prediction in NoC is difﬁcult [1] because every router in a NoC simultaneously transmits multiple trafﬁc ﬂows between many sources and destinations. Additionally, every source/destination pair exhibits its own dynamics. When we observe these individual dynamics in aggregate, it is almost impossible to detect predictable behaviour, since all trafﬁc ﬂows are interleaved, as seen in Fig. 1 at router 6. However, if instead of looking at the aggregate effect and trying to predict the future based on that, we look at the source of the individual trafﬁc ﬂows at routers 0, 4, 8, and 12, we can observe much more regular trafﬁc patterns. We ﬁnd that individual trafﬁc ﬂows are much more predictable than their aggregate. To predict the behaviour of individual trafﬁc ﬂows, it is important to understand the underlying, dynamic causes of the trafﬁc. For example, in NoCs for cache-coherent CMPs, the aggregate trafﬁc consists of coherence protocol communication. In this work, we introduce a trafﬁc prediction mechanism that relies on data collected from the coherence protocol, rather than the current state of the network. Recent work by Demetriades et al. [9] shows that coherence targets, deﬁned as the subset of communication destinations for a particular thread, can be predicted with high probability by exploiting the inherent correlation between synchronization points in a program and coherence communication. We extend these ﬁndings and apply them to the prediction of bandwidth requirements to control DVFS in the NoC. Our approach differs from existing DVFS techniques because it employs inherent application characteristics, rather than purely network-related metrics and it uses them to proactively predict DVFSrelevant properties of NoC trafﬁc. This leads to a reduction in V/F mispredictions and more accurate DVFS decisions during runtime, which ultimately results in a more power-efﬁcient NoC implementation without negatively impacting application throughput. The primary contributions of this work are as follows: • We show that current reactive DVFS mechanisms are not efﬁcient at predicting future NoC demands. • We develop a reliable trafﬁc prediction mechanism that is 87% accurate in predicting the bandwidth requirements based on application cache coherence behaviour. • We propose a low-overhead hardware implementation of our predictive DVFS mechanism for router-based voltage frequency islands (VFI), which improves power-delay product by 39% over a baseline with static V/F levels and by 21% over prior work. 2. BACKGROUND AND MOTIVATION First, we discuss the basics of cache coherent NoCs and dynamic voltage and frequency scaling (DVFS). Next, we cover related work in DVFS for NoCs. Finally, we motivate our novel DVFS prediction mechanism. 2.1 Background Cache-Coherent NoCs In this work, the NoC provides the communication infrastructure for a shared-memory CMP that relies on a directory-based cache coherence protocol. Here, NoC trafﬁc consists of messages deﬁned by the coherence protocol (e.g., MESI, MOESI), such as data requests and replies, acknowledgements (e.g., ACK, NACK), and invalidation requests, which are sent between communication end points. Communication end points are cache controllers, directory controllers, and memory controllers. In general, NoCs are oblivious to the type of trafﬁc they transfer; we exploit properties of cache coherence trafﬁc. Speciﬁcally, we use the predictability of destination sets [15], which are deﬁned by the collection of processors that receive an individual coherence request. Therefore, our work is fundamentally tied to cache-coherent NoCs. DVFS Dynamic voltage and frequency scaling can adaptively decrease the supply voltage by reducing the switching frequency. This can achieve signiﬁcant power and energy savings (energy consumption is reduced quadratically with the decrease of voltage), but may incur various performance penalties due to lower switching frequency. Therefore, DVFS must carefully trade off power and energy consumption with performance. Voltage and frequency islands (VFIs) [18] allow for ﬁne-grained adjustment of voltage and frequency (V/F) levels throughout the NoC. Coupled with globally asynchronous, locally synchronous design in which a CMP is divided into individual tiles operating with their own clock and voltage domains [17], designers can exploit both temporal and spatial variation in NoC trafﬁc to reduce power consumption during runtime. Recent developments in onchip voltage regulators [21] are key enablers for ﬁne-grained VFIs. 2.2 Related Work We focus our discussion of related work on DVFS mechanisms for NoCs and coherence prediction. DVFS Work on DVFS for NoCs can generally be divided into single V/F domain scenarios and more ﬁne-grained designs based on multiple VFIs. Policies for a single V/F domain usually measure some network performance metric, such as injection rate [14] or Average Memory Access Time (AMAT) [6] and adjust the entire NoC’s voltage reactively. Won et al. [23] rely on Artiﬁcial Neural Networks to predict program phase patterns and their inﬂuence on NoC trafﬁc. Their proactive DVFS approach allows for additional energy savings without degrading performance. Our work also focuses on proactive DVFS policies, but applies them to VFIbased DVFS instead of a single V/F domain, because it allows us to exploit more ﬁne-grained spatial and temporal trafﬁc variations. While VFI-based DVFS incurs more interfacing overhead [14], the goal of our work is to mitigate the additional overhead by increasing DVFS efﬁciency. VFI-based DVFS policies include dynamic voltage scaling of individual links [20] and an approach based on a fractional state model [5]. DVFS can be applied by monitoring queue occupancy [7] on the Intel SCC [11] or using a combination of link utilization and buffer occupancy [19]. Mishra et al. [16] use the buffer occupancy of neighbouring routers to adjust the V/F level of upstream routers. These proposals rely on purely network-related metrics and use a reactive DVFS approach. Our work differs from prior work in that it makes proactive predictions about the future NoC state and that it relies on coherence communication, as an application-centric metric, rather than purely network-based metrics. Coherence Prediction Cache misses in directory-based coherence protocols rely on indirections through the directory for cache-tocache communication, which incurs additional latency. Destination set predictors can improve miss handling latency by predicting the destination of a coherence request instead of a costly indirection to the directory [15]. Demetriades et al. [9] improve the prediction accuracy of destination set predictors by exploiting the inherent correlation between synchronization points in a program and coherence communication. Our work is based on their ﬁndings and applies it to DVFS for cache-coherent NoCs. Coherence property Destination set (Destinations and corresponding volume of messages) Type and mix of coherence messages Derived NoC property Bandwidth requirements (Exact location and volume of trafﬁc) Trafﬁc ﬂows Hotspot prediction Buffer requirements Criticality/priority Volume and burstiness of trafﬁc Average packet size Are responses expected? Possible action DVFS Power gating Set up forwarding paths, adaptive routing Adapt routing, throttle injection Dynamic buffer allocation Adjust QoS Resource allocation (bandwidth, circuits) Buffer requirements Set up circuit/return path Table 1: Relation between coherence communication properties and their NoC implications Figure 2: Channel utilization prediction 2.3 Motivation In this section, we ﬁrst show how current DVFS solutions fail to predict future trafﬁc demands and explore why trafﬁc prediction in NoCs is a difﬁcult problem. Next, we show how properties of the cache coherence protocol can improve prediction accuracy. Although recent DVFS approaches improve NoC energy efﬁciency by adapting network bandwidth based on spatial and temporal variations in trafﬁc requirements [5, 20], they are mostly reactive and focus on general network-related metrics and thus do not immediately take changes in application behaviour into consideration. For good power and performance results, DVFS needs to be aware of an application’s network demands ahead of time and needs to be tuned to ﬂuctuating network bandwidth requirements based on the actual application’s requirements and not a proxy value that may not correlate well. Common proxies include link utilization [20], buffer occupation [7], injection bandwidth [14], and round-trip delay [6]. Based on the individual metric’s past behaviour in a local network context, the voltage and frequency of either individual links [20] or entire routers [16] are adjusted. However, we do not ﬁnd a strong, intuitive correlation between these metrics and the actual future bandwidth demands. For example, simply because a link has been utilized heavily in the past, does not guarantee that it will show the same behaviour in the immediate future. This is especially true for sporadic changes that occur with the phase-based communication behaviour seen in CMP workloads [1]. To demonstrate this misFigure 3: Prediction error for channel utilization in PARSEC benchmarks match, we pick a random interval from ﬂuidanimate executed on a 4×4 mesh NoC, and show one link’s actual utilization compared to its predicted utilization in Fig. 2. The particular prediction algorithm used in this experiment [20] results in a prediction error of 270% because there is no obvious correlation between past and future behaviour. We measure the prediction error to be 39% on average across a selection of PARSEC [3] benchmarks, as shown in Fig. 3. Prediction mechanisms that focus on these types of networkrelated metrics have limited accuracy; DVFS mechanisms that rely on their predictions perform poorly. Consequently, there exists a need for more accurate trafﬁc prediction to improve NoCs power efﬁciency using DVFS. NoC trafﬁc prediction is difﬁcult; the NoC is a shared communication medium which transmits the trafﬁc of several sources simultaneously. This leads to the overlap of individual trafﬁc ﬂows at each router. Additionally, each thread running on a different core may be in a different state and therefore exhibit changes in communication behaviour. Each node experiences interleaved trafﬁc behaviour from different threads at different times. We need to understand the origin of the trafﬁc to make proper assumptions about their behaviour and their individual contributions to the entirety of the NoC’s trafﬁc. Once we are able to understand and predict the communication behaviour of each individual thread at its source, we can derive their contributions to the local context of a router or link and thus deduce a global picture of the upcoming bandwidth requirements. In cache-coherent NoCs, the trafﬁc at each source consists of (a) (b) (c) Figure 4: Communication distribution of Core 0 in ﬂuidanimate: (a) as seen during the whole execution. (b) as seen during the execution of four consecutive ﬁxed-time sub-intervals. (c) as seen across four different dynamic instances of the same sync-deﬁned interval messages deﬁned by the coherence protocol, i.e., data requests and replies, invalidations, ACKs, sent between cache, directory, and memory controllers. In Table 1, we take a detailed look at how certain properties of cache coherence trafﬁc can inﬂuence NoC metrics and be exploited by the NoC. For example, certain types of coherence messages are followed by a direct response; NoC performance could be improved by anticipating this response and setting up an optimized return path. While many interesting NoC-related properties can be derived from coherence protocol messages, we are mainly interested in temporal and spatial variations of bandwidth requirements; thus we limit the scope of our observations to the volume of data communication between source/destination pairs over time, which is deﬁned by the amount of coherence messages exchanged. Since coherence messages generally follow more regular and predictable patterns [15] than aggregate bandwidth in the network, we use them to derive more accurate predictions about upcoming NoC bandwidth requirements. Fig. 4 demonstrates how we can use synchronization points and destination sets to expose more predictable trafﬁc patterns. Fig. 4a shows the communication volume between core 0 and all other cores over the entire runtime. If we analyze the communication volume per destination for ﬁxed time intervals (Fig. 4b), distinct predictable features that could be used to predict core 0’s bandwidth contribution do not emerge. Recent work by Demetriades et al. [9] uses an application’s synchronization points as interval boundaries, rather than predetermined, ﬁxed time intervals. Synchronization points, such as locks, barriers, joins, etc. indicate points when certain data private to a processor will become visible–and possibly be communicated–to other processors. Synchronization points likely indicate behaviour change and thus the data communication following different instances of the same synchronization point should be more predictable and have greater repeatability. In Fig. 4c, we demonstrate how the granularity of synchronization-based intervals exposes repeatable and predictable trafﬁc patterns when communication volume is tracked per synchronization point. Synchronization-based intervals allow us to create highly accurate destination set predictors, which we can use to determine temporal and spatial bandwidth requirements throughout the NoC to trigger informed DVFS decisions. To the best of our knowledge, this work is the ﬁrst to predict NoC-related metrics derived from the behaviour of cache coherence communication. 3. IMPLEMENTATION In this section, we describe how DVFS based on coherence prediction can be implemented in hardware and detail the prediction algorithm. Our design is presented in the context of a Global Asynchronous Local Synchronous (GALS) 2D mesh NoC design [17]. In this implementation, we assume separate voltage-frequency islands for Figure 5: Overview of the architecture. each router.1 Fig. 5 shows an overview of the architecture. In addition to an existing router-based DVFS mechanism, the architecture adds two modules at each tile: a Coherence Prediction Engine (CPE), co-located with the cache and directory controllers, and an Accumulation and Decision Module (ADM) in every router. The basic idea is that CPEs predict future NoC communication requirements based on coherence behaviour and communicate those predictions through the NoC. ADMs in the routers then collect this data and evaluate it to make appropriate changes to the voltage and frequency levels. 3.1 Coherence Prediction Engine (CPE) The CPE is the main architectural component of our implementation. It is designed to accurately predict future NoC communication based on current and previously experienced coherence behaviour and then send that data to relevant ADMs. To extract relevant data from the coherence protocol, the CPE is connected to the coherence controllers (cache and directory) at its tile and monitors their trafﬁc. It records synchronization epochs (sync-epochs) along with the 1 Implementations with different granularities of VFIs [18] are possible with only minor adjustments. corresponding communication set (trafﬁc volume per destination) and later predicts NoC trafﬁc based on those recordings. Sync-Epoch Based Prediction As brieﬂy motivated in Sec. 2.3 and described in more detail by Demetriades et al. [9], synchronizationpoints (sync-points) can be used for accurate communication set prediction. A sync-point is an execution point at which a software synchronization routine is invoked (e.g., barrier, join, wakeup, broadcast, lock, unlock). Each sync-point can be identiﬁed by its type, its static calling location (program counter), and a dynamic ID, which expresses multiple dynamic instances of the same static sync-point. Sync-epochs deﬁne the execution time between two consecutive sync-points. Therefore, each sync-point marks the end of one sync-epoch and the beginning of the next. Sync-points are executed repeatedly and create a sequence of dynamic instances for each sync-epoch. As these instances exercise the same or similar code and operate on the same (or related) data structures, it is likely that there are behavioural similarities between them [8]. Such similarities may also be reﬂected in the communication behaviour. We use this property to recall past communication patterns at a sync-epoch granularity to predict future communication sets. Sync-epoch based prediction requires synchronization primitives to be exposed to the hardware. Prediction Table A prediction table keeps track of past communication sets. During the execution of a sync-epoch, communication counters monitor the spatial distribution of the trafﬁc that originates at a particular node. At the end of a sync-epoch, the current communication set is stored in the prediction table and a prediction is made for the next sync-epoch. For this prediction, previously stored communication sets for the current static sync-point are retrieved from the prediction table. Each table entry holds a sequence of communication sets for a single static synch epoch. Each communication set holds N w-bit integers, representing the amount of trafﬁc to the N possible destinations in a NoC with N nodes. w is a design parameter that we chose as 8. Empirically, the amount of trafﬁc to a single destination during a sync-epoch never exceeded 100,000 ﬂits, so a 17-bit integer is able to hold this information. At the same time, we determined that small values (less than 512) are insigniﬁcant for our purposes, so we truncate the 17 bits down to 8 to minimize storage overhead. Table entries are indexed with the program counter of the sync-epoch. Since none of the PARSEC benchmark includes more than 64 static sync-points and prior work [9] suggests a history depth of 2 as sufﬁcient for most trafﬁc patterns, we design the prediction table with 128 entries. Therefore, the storage requirement for a single prediction table is 128 × w × N = 2KB for a 16-node NoC. Once a prediction has been retrieved from the prediction table, the CPE sends single-ﬂit control packets containing the 8-bit trafﬁc volume prediction for the new sync-epoch to each of the destinations recorded in the communication set. These control ﬂits are injected into the NoC alongside regular data packets and do not require a separate control network. The overhead caused by control ﬂits is minimal (∼ 0.2% ) due to the low frequency of sync-points. 3.2 Accumulation and Decision Module (ADM) The ADM (Fig. 5) collects the bandwidth prediction from those control ﬂits that pass through a speciﬁc router. Per-destination control ﬂits traverse the same route through the NoC as their corresponding trafﬁc ﬂow when using a deterministic routing algorithm such as dimension-order routing. These control ﬂits carry the impending bandwidth requirements between a source-destination pair during the upcoming sync-epoch. The ADM extracts the bandwidth prediction from all control ﬂits that pass through and accumulates them to gauge the impending aggregate bandwidth requirements for all relevant trafﬁc ﬂows. Each ADM keeps track of all bandwidth requirements in aggregate, instead of storing individual trafﬁc ﬂow bandwidths for each source-destination pair. This allows us to reduce the storage requirements per router signiﬁcantly by only saving its aggregate bandwidth prediction in a single register. Control ﬂits passing through an ADM indicate a change in bandwidth requirements for a speciﬁc source-destination pair by containing a delta value (difference between its previous prediction and its current prediction), which is used to update the ADM’s aggregate bandwidth prediction. For example, let us assume that router 6’s ADM currently holds an aggregate bandwidth prediction of 20000 ﬂits in its register, when a new control ﬂit from router 0 on its way to router 10 passes through. It carries a value of -4000, because the communication set prediction at router 0 predicted 4000 fewer ﬂits will be sent to router 10 during the current sync-epoch compared to the last sync-epoch, which will update the aggregate bandwidth prediction at router 6 to 16000 ﬂits. Based on the aggregate BW prediction, the ADM makes a decision regarding the V/F level of its router and communicates this to the voltage regulators. We use empirically determined static thresholds to map bandwidth ranges to V/F levels (Table 3). Decisions are made whenever a new control ﬂit arrives–after the aggregate BW has been updated. Initially, we enforced minimum intervals between V/F updates as a safety measure against too frequent updates to limit transition overheads. However, we found them to be unnecessary due to sufﬁciently spaced control ﬂits (millions of cycles). 3.3 DVFS mechanism Our implementation uses per-core on-chip DVFS, where each router represents a different VFI. We adopt the two-step voltage regulator conﬁguration as proposed by Kim et al. [13]. An off-chip regulator performs the initial step down from the supply voltage to 1.8V, followed by multiple on-chip voltage regulators. The onchip regulators operate at 125MHz switching frequency and provide voltage transitions between 1.25V to 0.8V. This allows for router frequencies ranging from 1.0GHz to 2.25GHz. The routers can operate at the lower frequency during frequency step-down by quickly ramping down the frequency before the voltage steps down. For stepping-up the frequency using DVFS, we ﬁrst step-up the voltage before ramping up the router frequency. The overhead in every transition is primarily the voltage settling time which is 13ns for every 100mV change [13]. Therefore, due to higher than required voltage during step-down (and lower frequency during stepup), the power consumed by the router during a transition lies between the values before and after the scaling. All our evaluations take this overhead into account. It is important to note that the entire mechanism, including CPE and ADM, works asynchronously and can therefore be implemented off the critical path. 3.4 Discussion Here, we discuss some of the implementation details that are not directly related to the architecture. VFI Granularity Our particular implementation relies on routerbased voltage frequency islands, however coherence prediction can also be used for different granularities of VFIs with minor modiﬁcations. It is equally applicable to cluster or region-based DVFS [18] by using one ADM per cluster, instead of one per router. In this case, the ADM would keep track of cluster-based bandwidth requirements. Alternatively, by using one ADM per link, very ﬁnegrained DVFS could be implemented. Topology and Routing The way bandwidth predictions are com# of Cores/Threads L1 Cache (D & I) L2 Cache Cache Coherence Router VCs/Buffer Depth Control Interval 16/16, 1GHz private, 4-way, 32KB each, 64 Byte Blocks shared, distributed, 8-way, 512KB each MOESI distributed directory wormhole, VC, 3 stages, 2GHz, DOR 4/4 Flit, 8 Bytes 100,000 cycles at 1GHz Table 2: Simulation parameters Voltage level [V] Frequency level [GHz] BW range [104 ﬂits] 0.8 1.0 <1 0.85 1.25 1-2 0.9 1.5 2-4 1.0 1.8 4-7 1.1 1.2 2.0 2.25 7-8 >8 Table 3: DVFS parameters and mapping from ADM’s aggregated BW prediction to corresponding V/F levels municated through the NoC and accumulated at the routers, currently relies on a deterministic routing algorithm. We require that control ﬂits take the same path as other packets belonging to a speciﬁc trafﬁc ﬂow. Adjusting the implementation for adaptive routing algorithms is possible, but would be slightly more complicated. Bandwidth estimates per path would need to be probabilistic and account for path diversity. Control ﬂits would need to be sent along each possible path between two nodes. Optimizations We consider several optimizations to our base implementation, which can be used to trade off implementation cost and prediction accuracy, as well as bandwidth overhead. For example, the number of control ﬂits sent can be reduced by omitting minor updates to the bandwidth prediction and instead bundling multiple minor updates into a single, less frequent control ﬂit. Another optimization addresses the storage overhead of both CPEs and ADMs. Instead of keeping track of exact bandwidth numbers, coarse bandwidth categories (e.g., low, medium, high) could be deﬁned. Prediction tables and ADMs would then store and operate on these less-accurate categories. We evaluate this optimization in Sec. 4. Lack of Sync-Points and Fallback If no history exists for a particular sync-epoch, or a substantial mismatch between predicted bandwidth and actual bandwidth is detected, the CPE performs a new prediction based on recent communication history and ADMs are updated accordingly. As a fallback to prevent severe performance penalties in the case of mispredictions, routers additionally monitor their buffer occupancy and can override the bandwidth prediction if occupancy levels exceed a predetermined threshold. 4. EVALUATION In this section we describe our experimental setup and subsequently evaluate our proposed prediction mechanism. Our baseline platform is a 16-core CMP with a 2-level cache hierarchy, split, private L1 caches, and a distributed, shared L2 last-level cache. Cache coherence is maintained via a MOESI directory cache coherence protocol. The NoC topology is a 4×4 2D mesh, with each router attached to a single processor core. Table 2 summarizes the baseline CMP setup. Simulation experiments are performed using the gem5 [4] full system simulator, with the Ruby memory model and a modiﬁed version of BookSim [12] for cycle-accurate NoC simulation. The benchmark applications are taken from the PARSEC benchmark suite [3]. Each application is executed for 100 million cycles within its region of interest (ROI), using the simmedium input set. We use DSENT [22] to model delay, static and dynamic power for a 22nm process. Additionally, we implemented an RTL Figure 6: Power results model of our mechanism on top of the standard BookSim router RTL implementation by Becker [2]. Synthesis using Synopsys Design Compiler with a TSMC 65nm standard library conﬁrms the DSENT model and results in 0.3% area overhead per tile. To focus on the evaluation of the NoC DVFS mechanisms, the core frequency is ﬁxed at 1GHz throughout the simulations. We use 6 frequency levels between fmax = 2.25GHz and fmin= 1.0GHz for the NoC (see Table 3). For each frequency, there is a corresponding voltage level between 1.2V and 0.8V, which is roughly the minimum voltage allowing correct operation. We assume that each step V/F level change takes 100 core cycles (100 cycles per step is sufﬁcient assuming on-die regulation [21]). During V/F transitions, the router operation is halted. All V/F related parameters are inspired by the Intel SCC [11] DVFS implementation. We compare the following 5 mechanisms; the last two are our proposals in this work: • 2D Mesh-2GHz: The baseline mesh constantly operates at 2GHz • FreqThrtl: Proposed by Mishra et al. [16] as a reactive mechanism that adjusts V/F according to local congestion. Routers operate at 0.8*fbase (fbase=2.0GHz) without congestion and faster in a congested state. • DVFSL: Proactive DVFS mechanism, proposed by Shang et al. [20] that relies on buffer occupancy and channel utilization to adjust link V/F. Instead of link V/F, we use their algorithm to adjust router V/F to provide better comparability. • CoP-Coarse: Coherence Prediction using sync-epochs and bandwidth categories instead of exact bandwidth estimates. • CoP: Coherence Prediction using sync-epochs with exact bandwidth predictions We chose FreqThrtl and DVFSL, because both are mechanisms that use VFI at a router granularity–one represents a reactive DVFS mechanism (FreqThrtl) and the other is predictive (DVFSL). Normalized power results are displayed in Fig. 6. Naturally, the baseline uses the most power, because it cannot scale down its voltage or frequency. Compared to the baseline, our best mechanism can reduce power consumption by 41%, while the performance only degrades by 3% (Fig. 7), which leads to a power-delay reduction of 39% (Fig. 8). Both, FreqThrtl and DVFSL perform better than the baseline in terms of power consumption, but worse than any of our proposed mechanisms. Figure 7: Performance results Figure 9: Prediction error Figure 8: Power delay results FreqThrtl suffers from the fact that buffer utilization is generally low for PARSEC benchmarks and only rarely exceeds its congestion threshold to increase the frequency. Hence, all routers operate at 1.5GHz (0.8*fbase ) for most of the time, which leads to 17% power savings, but at the same time performance drops signiﬁcantly due to the slow routers. We tried to adjust FreqThrtl’s buffer utilization thresholds to gain a more even distribution of frequency states, but the low buffer utilization prevented us from ﬁnding a suitable setting. Depending on the chosen threshold, either all routers were running at fbase , or all routers were running at 0.8* fbase with little variation in between. DVFSL performs better than FreqThrtl, but is negatively affected by a high prediction error rate, which result in non-optimal V/F choices. Fig. 9 shows that DVFSL’s mean average percentage error (MAPE) for predicting buffer occupancy and channel utilization is 39%. CoP, on the other hand, is able to predict the bandwidth requirements per router with 87% accuracy on average. The high prediction accuracy is the main reason for making correct and beneﬁcial DVFS decisions. CoP-Coarse trades off prediction accuracy (26% error rate) for smaller prediction tables, which leads to 8% worse power consumption and 3% lower performance. At the same time, it reduces storage overhead for prediction tables inside the ADMs by 75% to 512B each. These results emphasize the importance of accurate, proactive DVFS decisions in order to save signiﬁcant amounts of energy while not degrading performance. Figure 10: Distribution of dynamic power consumption between different V/F levels (averaged across PARSEC benchmarks) Design space exploration To provide more insight into the choice of some of our parameters, we performed a design space exploration for the amount of different V/F levels provided by the DVFS mechanism, and the history depth of the CPE’s prediction table. In Fig. 10 we measure the reduction of dynamic power consumption when the number of V/F levels is increased for CoP. The results show each V/F level’s contribution to the total dynamic power consumption, as well as how much additional power can be saved by adding another V/F level. We found that providing more than 6 V/F levels leads to diminishing returns. From Fig. 11 it is evident that a prediction table history depth of more than 2 also leads to diminishing returns for the prediction error. While costly in terms of area and power consumption, adding a second entry for the history depth signiﬁcantly reduces the prediction error by 15% due to the added ability to recognize alternating patterns across sync-epoch instances, which occur relatively frequently. Figure 11: Effect of prediction table history depth on prediction accuracy 5. CONCLUSION The NoC constitutes a signiﬁcant and increasing part of overall CMP power consumption. This work focused on a novel prediction mechanism for improved VFI-based DVFS in order to reduce power consumption while maintaining performance. Instead of predicting bandwidth requirements using unrelated metrics or in aggregate throughout the network, this work uses sync-epoch based cache coherence prediction to reliably predict individual trafﬁc ﬂows. The individual trafﬁc ﬂows are then used to infer aggregate bandwidth demands in the network that enable informed DVFS decisions. A high prediction accuracy of 87% leads to an improved power-delay product of 39%. Acknowledgements The authors thank the anonymous reviewers for their thorough suggestions on improving this work. This work is supported by the Natural Sciences and Engineering Research Council of Canada, the Canadian Foundation for Innovation, the Ministry of Research and Innovation Early Researcher Award and the University of Toronto. 6. "
Exploiting Transmission Lines on Heterogeneous Networks-on-Chip to Improve the Adaptivity and Efficiency of Cache Coherence.,"Emerging heterogeneous interconnects have shown lower latency and higher throughput, which can improve the efficiency of communication and create new opportunities for memory system designs. In this paper, transmission lines are employed as a latency-optimized network and combined with a packet-switched network to create heterogeneous interconnects improving the efficiencies of on-chip communication and cache coherence. We take advantage of this heterogeneous interconnect design, and keep cache coherence adaptively based on data locality. Different type of messages are adaptively directed through selected medium of the heterogeneous interconnects to enhance cache coherence effectiveness. Compared with a state-of-the-art coherence mechanism, the proposed technique can reduce the coherence overhead by 24%, reduce the network energy consumption by 35%, and improve the system performance by 25% on a 64-core system.","Exploiting Transmission Lines on Heterogeneous Networks-on-Chip to Improve the Adaptivity and Efﬁciency of Cache Coherence (cid:3) Qi Hu, Peng Liu College of Information Science and Electronic Engineering Zhejiang University Hangzhou 310027, China {huqi_isee, liupeng}@zju.edu.cn Michael C. Huang Dept. of Electrical and Computer Engineering University of Rochester Rochester, NY 14627 michael.huang @rochester.edu Xiang-Hui Xie State Key Laboratory of Mathematical Engineering and Advanced Computing Wuxi 214125, China xie.xianghui @meac-skl.cn ABSTRACT Emerging heterogeneous interconnects have shown lower latency and higher throughput, which can improve the eﬃciency of communication and create new opportunities for memory system designs. In this paper, transmission lines are employed as a latency-optimized network and combined with a packet-switched network to create heterogeneous interconnects improving the eﬃciencies of on-chip communication and cache coherence. We take advantage of this heterogeneous interconnect design, and keep cache coherence adaptively based on data locality. Diﬀerent type of messages are adaptively directed through selected medium of the heterogeneous interconnects to enhance cache coherence eﬀectiveness. Compared with a state-of-the-art coherence mechanism, the proposed technique can reduce the coherence overhead by 24%, reduce the network energy consumption by 35%, and improve the system performance by 25% on a 64-core system. Categories and Subject Descriptors B.4.3 [Input/Output and Data Communications]: Interconnections (Subsystems); B.3.2 [Memory Structures]: Design Styles—cache memories, shared memory General Terms Design Keywords Cache coherence, heterogeneous networks-on-chip (cid:3) Corresponding author: Peng Liu, liupeng@zju.edu.cn. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permission from Permissions@acm.org NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3396-2/15/09 ...$15.00 DOI: http://dx.doi.org/10.1145/2786572.2786576 1. INTRODUCTION To carry on-chip traﬃc faster and in a more energy-eﬃcient manner in modern chip multiprocessor (CMP) systems, there are emerging works investigating heterogeneous interconnects [7, 8, 17]. The shortcuts in the heterogeneous interconnects provide scalable, ﬂexible, and low-latency communication, which greatly reduce the overhead of accesses to a data block cached in the shared lower level cache on a remote node [8]. Such high performance interconnects reduce the latency of communication and create new opportunities for coherence optimizations. For instance, multiple L1 copies could be avoided for some data by restricting them to the shared last-level cache (LLC), so that cache coherence could be simpliﬁed. In conventional directory-based protocols, the number of coherence operations (including invalidation, downgrading, and the corresponding acknowledgements) are on the critical path of data requests, which are referred to as coherence overhead in this work. In particular data blocks both shared and written (referred to as shared written blocks ) must be handled with care to guarantee correctness and consistency among cores. A write to a shared written block produces invalidations to other shared data copies, which consumes time, network bandwidth, and energy. In fact, for shared written blocks, sometimes multiple level-1 (L1) data copies bring little beneﬁt due to expensive coherence operations. Nevertheless, if only one data copy resides in cache hierarchy, the number of coherence operations can be reduced. In this paper, we exploit heterogeneous interconnects and reduce coherence overhead by adaptively activating or deactivating cache coherence. Transmission line [4, 5] is utilized as a latency-optimized interconnect and combined with the packet-switched network to create heterogeneous on-chip interconnects. Diﬀerent type of messages are adaptively directed through the proper medium. To exploit the performance potential created by the heterogeneous interconnects, we tune caching strategy adaptively based on on-line proﬁled block locality. Low-temporal-locality shared written blocks with high invalidation overhead are dynamically ﬁltered out from L1 caches and relegated to LLC. The latency-optimized interconnect well compensates for the latency of requests to the ﬁltered blocks in LLC. The directory stops tracking sharers for the ﬁltered blocks adaptively since only one data copy resides in LLC. The heterogeneous interconnects are adapted to the latency-sensitivity of messages and help enhance the cache coherence. Coherence operations and the traﬃc along with them are reduced, which helps reduce execution time and energy consumption. In this paper, we make the following contributions: (cid:15) We employ transmission lines to construct a substrate of low-latency on-chip interconnects, and take advantage of the interconnect to exploit more eﬃcient and ﬂexible caching strategy. (cid:15) By exploiting the advantages of heterogeneous interconnects, we optimize cache coherence adaptivity based on data temporal locality so that coherence overhead is reduced. (cid:15) We evaluate our mechanism with detailed experimentations on a 64-core system using multithreaded workloads. The rest of the paper is organized as follows: Section 2 describes our design in detail; Section 3 presents our simulation methodology; Section 4 shows our experimental analysis; Section 5 discusses related work; and ﬁnally Section 6 concludes. 2. MECHANISM 2.1 Heterogeneous Interconnects Transmission lines (TLs) can provide global low-latency communication. TLs exhibit much lower latency than traditional buses, and has one advantage of implementation in using the CMOS process compared to optical interconnects. We select the coplanar strips structure, as it utilizes the space of the top metal layer eﬃciently, and the conﬁnement of ﬁelds leads to minimized substrate loss and crosstalk [5]. The characteristics of the TL interconnect are listed in Table 1. TLs are laid in Z-shape connecting all cores in our work, as shown in Fig. 1. We use a centralized implementation of an explicit permission granting system. We assume an on-chip two-level cache hierarchy. Each tile has private L1 instruction and data caches, and a slice of the physically distributed shared L2 cache integrating sharer vectors in the tag segment. We utilize TLs as a latency-optimized interconnect, combined with a packet-switched network to construct a heterogeneous on-chip interconnection. Table 1: Characteristics of Transmission Lines [5]. Pitch ((cid:22)m) Data Rate (Gbps per line) Energy/bit (pJ) Crosstalk (dB) Power (mW) Latency (ps) Area ((cid:22)m2 ) 45 26.4 0.49 -30 Transmitter: 4.34; Receiver: 8.45 Transmitter: 592; Receiver: 655 Transmitter: 420; Receiver: 775 The messages caused by read requests (including coherence messages) are categorized as latency-sensitive messages, since read requests are more sensitive to latency than writes. The messages intended for a destination far away (at least half of network size) are categorized as long-distance messages. Latency-sensitive or long-distance messages are adaptively directed to the TL expressway to reduce transmission latency. The adaptive transmission process is listed as follows. 1. Cache/directory controller generates message ﬂits and inserts them into diﬀerent networks based on the characteristics of the message. 2. Message ﬂits are directed to the router of network or transmitter circuitry of TL interconnects. 3. Flits are routed through the packet-switched network or sent along TL interconnects. 4. Arrived message ﬂits are received from the router or receiver circuitry of the heterogeneous interconnects. 5. Arrived message ﬂits are processed. With the adaptive data delivery system, the low-latency interconnect is fully exploited to speed up data transmission and reduce the penalty of LLC accesses on remote nodes. The high-speed shortcut brings opportunities for more eﬃcient caching strategies. Some data could be kept in LLC without increasing much access latency. Thus multiple L1 data copies are eliminated and coherence operations could be reduced. 2.2 Target Blocks Our goal is to reduce coherence overhead and we target on shared written blocks. The shared written blocks could be further classiﬁed into two classes: read after written blocks (RAW) and written after read blocks (WAR). Our detailed evaluation results show that, diﬀerent from WAR blocks which are constantly written, RAW blocks are frequently read and seldom (only 0.5% of accesses) written to, thereby cause limited coherence traﬃc (15% on average). Relegating RAW blocks to LLC is unnecessary in most cases, and may cause on-chip traﬃc increase due to the many long-distance read requests to LLC. Hence in our mechanism, only WAR blocks are relegated to LLC. 2.3 Locality Proﬁling Data block temporal locality is exploited with runtime hardware proﬁling. High-temporal-locality means high utilization. We deﬁne a term as High Locality Threshold (HLT) for L1 data blocks. A block in L1 data caches is classiﬁed as a high-temporal-locality block if the number of reads from the local processor between two successive writes (by any threads) is above or equal to HLT, otherwise the block is Figure 1: System overview of a tiled 64-way chip multiprocessor. classiﬁed as a low-temporal-locality block. Our empirical observation (ranging HLT from 2 to 6) shows that choosing a static HLT of 3 for the simulated benchmarks gets the best performance. We set a locality counter in the tag segment for each block in L1 data caches tracking block utilization. The counter is initialized to zero when a block is fetched into an L1 data cache, incremented upon each read, and reset upon every write (invalidation). Low-temporal-locality shared written blocks will be relegated to LLC. The data blocks relegated to LLC are often used alternately by diﬀerent threads. Using only one counter for each block as in L1 data caches could not accurately track the utilization of a particular thread, while maintaining a counter for each thread has too much hardware cost. We use a simple method and take back-to-back read (read-read and writeread from one processor core) as a sign of enough temporal locality. Since there is already a sharer vector in each directory entry recording sharing processors in conventional directory-based coherence protocols, and the vector is idle when blocks are relegated to LLC with no private sharers, we could use the vector to keep track of requesters upon reads and discover back-to-back reads. The sharer vector is cleared and reset upon writes, since constantly written blocks are usually invalided soon and have low temporal locality. Hence for the data blocks relegated to LLC, the temporal locality is proﬁled at little cost of storage. 2.4 Coherence Adaptivity Since invalidation messages for shared written blocks add to communication traﬃc and latency, a write invalidation is used as a signal for coherence adaption. When a write invalidation message arrives at an L1 cache, the temporal locality of the block is checked by the L1 cache controller. This information is communicated to the directory (integrated with LLC) along with the acknowledgement message. The LLC controller checks every invalidation acknowledgement received. The block is delegated to LLC if none of the acknowledgements indicates high temporal locality of the block. Later accesses to the blocks delegated to LLC on remote nodes are sped up by the TL shortcut, thus onchip latency won’t increase much. Meanwhile, the directory stops tracking the sharers of the block. On the contrary, as long as one acknowledgement message indicates high temporal locality, the block is allowed to be fetched into L1 caches and tracked by the directory as before. The L1 cache controller is not aware of coherence deactivation. When a thread needs a block stuck in LLC, a L1 cache miss occurs and a data request message is sent to the directory. Based on the latency-sensitivity and the destination of messages, proper medium of the heterogeneous interconnects is selected for transmission to make sure onchip latency is not high. If the directory indicates that the block is temporarily untracked, accesses are serviced via inplace word read/write in LLC. This way data accesses become simpler without costly coherence operations. The TL shortcut speeds up latency-sensitive and long-distance messages, oﬀsetting the latency of accesses to the blocks stuck in LLC on remote nodes. However, the temporal locality of the stuck blocks might become high afterwards. To avoid suﬀering long-distance on-chip transmission, if the block begins to show enough locality (back-to-back read), the stuck block is fetched into the L1 cache again and the directory restarts tracking it. An example of state transitions and locality tracking for the blocks relegated to LLC is illustrated in Fig. 2: 1. At ﬁrst, a data block has two private copies cached in the private caches of processor 0 and processor 2. 2. Processor 1 writes to the block. So invalidation messages are sent to processor 0 and processor 2. Acknowledgements indicate that the block has low locality. The block is relegated to LLC and temporarily untracked by the directory. Later accesses to it from a remote node will be sped up by the TL shortcut. And the sharer vector stops tracking sharers, but starts to track back-to-back read instead. 3. Processor 2 reads the block and the sharer vector indicates low locality of the block. Processor 2 is recorded in the vector. Note that neither processor 1 nor processor 2 is a block sharer, since the block is stuck in LLC. 4. Processor 1 reads the block. The bit of processor 1 in vector is on, which indicates a back-to-back read. The block is fetched into the L1 cache of Processor 1. The directory tracks the block again, and the block state becomes Exclusive. (Since only Processor 1 has the Figure 2: An example of state transitions. The dark region represents the added bit indicating whether the data block is tracked by the directory. The other two bits of state represents Invalid(00), Exclusive(01), Shared(11), and Modiﬁed(10) states. The unrelated bits are omitted for clarity. Table 2: System parameters. Processor core Fetch/Decode/Commit ROB Issue Q/Reg. (int,fp) LSQ(LQ,SQ) Branch predictor - Gshare - Bimodal/Meta/BTB Br. mispred. penalty Feature size Frequency Memory hierarchy L1 D cache (private) L1 I cache (private) L2 cache (shared) Main memory Interconnects Network packets Mesh NoC Electric wire bus [21] Transmission latency Overhead Energy Transmission line link Transmission latency Data link Outgoing queue Overhead Energy 4 / 4 / 4 128 (32, 32) / (64, 64) 64 (32, 32), 2 search ports Bimodal + Gshare 8K entries, 13 bits history 4K/8K/4K (4-way) entries At least 7 cycles 45 nm 3.3 GHz 32KB, 2-way, 64B line, 2 cycles, 2 ports 32KB, 2-way, 64B line, 2 cycles 16MB, 8-way, 64B line, 15 cycles, 2 ports At least 250 cycles, 8 memory controllers Flit size: 72 bits Data packet: 4 ﬂits, meta packet: 1 ﬂit 4 VCs; 2-cycle router(x-y); Buﬀer: 5x12 ﬂits Wire delay: 1 cycle per hop 14 cycles 12 cycles 1.97 pJ/bit 1 cycle 36 links for data, 9 links for meta 12 packets 2 cycles each for (de)serialization, 30 ps propagation delay per hop, 2 cycles for arbitration delay 0.49 pJ/bit block locally cached, while Processor 2 does not.) The sharer vector restarts tracking sharers. 2.5 Overheads 64(cid:2)8 2 64(cid:2)8 1 (cid:2) 16M 64 = Storage: The locality counter needs two bits per block at private L1-D caches to track temporal locality with HLT=3. At directories, an extra bit is added in each directory entry to indicate coherence activity, showed in Fig. 2. The storage (cid:2) 32K = 128Byte. The overhead in an L1-D cache is storage overhead in the directory on one tile is 512Byte. In total the coherence adaptivity optimization only needs 640 bytes storage per core. Locality Tracking: The locality counter stored in the tag array in the L1 cache is updated on every cache read hit, which requires a read-modify-write operation. The twobit locality counter is stored in the tag array. The tag array already needs to be written on every cache hit to update the replacement policy counters, hence our protocol does not incur any additional cache accesses. In the directory, the sharer vector needs to be checked and updated if necessary to track locality for the stuck block. In conventional MESI-based coherence protocols, the sharer vector already needs to be checked and updated upon directory accesses, our protocol does not incur further overhead. Network Traﬃc: Sometimes more information needs to be contained in network packets for transmission, including the following three types: 1. One-bit mark indicates temporal locality of a block. This mark needs to be sent from an L1 cache to the directory along with the acknowledgement to the directory on an invalidation. For a 48-bit physical address and 72-bit ﬂit size, a message requires 42-bit for the physical block address, 12-bit for the sender and receiver core IDs. With the left 18-bit, there’re certainly enough spare bits to be used for locality mark besides message type. 2. The six-bit block oﬀset. It needs to be communicated during cache misses because the requester is not sure whether the block is stuck in LLC or not. In case an in-place word read/write is needed, the block oﬀset is used to select the right word. The block oﬀset could also be contained in a ﬂit with the spare bits. 3. The 64-bit data word to be written. It needs to be communicated on a cache miss in case an in-place word write is needed. This overhead is accounted for in our evaluation. 3. METHODOLOGY 3.1 Evaluation Framework We implement our mechanism on a cycle-level, executiondriven, CMP simulator [25]. The simulator takes DEC Alpha binaries and emulates system calls needed for parallel workload. Our code is an extensively adapted version of SimpleScalar [2] 3.0. For the processor microarchitecture, we model the DEC Alpha 21264 [9]. The processor microarchitecture, the cache coherence, and communication substrate are faithfully modeled. PopNet is used to model the packet-switched network. Another module independent from PopNet is added to model the transmission line expressway, which is simulated according to its characteristic metric [5]. The heterogeneous interconnects are self-throttling as real interconnects. If there are outstanding transmissions and the miss buﬀers are full, the core cannot inject more packets onto the interconnects. We use McPAT [18] for power analysis. The evaluation is performed at the 45 nm technology node. We simulate a MESIbased directory protocol with dirty bit on a 64-way chip multiprocessor on a packet-switched network as the baseline system throughout this study. The details of the architectural parameters used for evaluation are listed in Table 2. The proposed adaptive coherence on heterogeneous interconnects is referred to as TL-ADAP in the ﬁgures of next section. We compare our mechanism with SWEL [21], which also optimizes cache coherence on heterogeneous interconnects. Its ma jor architectural diﬀerence from ADAP is that, an electrical bus, instead of TL, is combined with the packet-switched network implementing heterogeneous interconnects. The electrical bus is exclusively used for invalidation broadcast in SWEL. While ADAP exploits heterogeneous interconnects by adaptively directing diﬀerent type of messages through proper medium. SWEL is oblivious to data locality and stores all shared written blocks in LLC. While ADAP fully exploits data locality and tunes caching strategy adaptively. To make comparison apples to apples, we implement two variants, B-ADAP and TL-SWEL. BADAP refers to the proposed adaptive coherence on heterogeneous interconnects with a conventional bus instead of TL shortcut as in SWEL. And TL-SWEL refers to SWEL with TL interconnect replacing the conventional bus. The architecture parameters of SWEL in simulation are the same as TL-ADAP. The bus parameters of SWEL are modeled exactly as in work [21]. SPLASH-2 barnes water-sp cholesky lu radiosity raytrace radix ﬀt ocean PARSEC blackscholes canneal dedup ferret streamcluster swaptions ﬂuidanimate Others mp3d jacobi tspo Table 3: Benchmarks. n-body simulation (16K particles) molecular dynamics (4096 molecules) sparse matrix factorization (tk15.O) matrix factorization (2048x2048 matrix) graphics (-ae 50000.0, -en 0.050, -bf 0.10) 3-D rendering (car) integer sort algorithm (1M integers) ﬀt algorithm (64K points) ocean movements (258x258 grids) ﬁnancial analysis (96K options) routing cost minimization (200K elements) data stream compression (184M data) data similarity search (34973 images) on line clustering (4K points) swaptions appraise (128 swaptions) interactive animation (100K particles) n-body simulation (40K molecules) diﬀerential equation solver (4096x4096) traveling salesman problem (18 cities map) 3.2 Application Benchmarks We perform the evaluation with a suite of parallel applications from SPLASH-2 [24], PARSEC [1], and other scientiﬁc workloads. Table 3 lists the applications used. Inputs for each application are listed along with a brief description of the application. 3.3 Evaluation Metrics In determining the value of adaptive coherence, we look at ﬁve main metrics: coherence overhead, cache miss delay, network utilization, network energy consumption, and cycles per instruction (CPI). All of the metrics are normalized to the baseline system. 4. EXPERIMENTAL RESULTS In this Section, we analyze the ﬁgures of merit on a 64-core system to justify the eﬀectiveness of the proposed mechanism and compare with the state-of-the-art work. 4.1 Coherence Overhead Coherence overhead is measured by accumulating the latency of all coherence operations. Fig. 3 shows the normalized coherence overhead. TL-ADAP sticks low-locality blocks at LLC and reduces costly coherence operations for shared written blocks. The TL shortcut speeds up accesses to the stuck blocks on remote nodes, oﬀsetting the latency and enhancing the cache coherence. As a result, coherence overhead is consistently reduced for all of the applications. For most applications, B-ADAP and TL-ADAP outperform SWEL and TL-SWEL at reducing coherence overhead, respectively. B-ADAP and TL-ADAP track block locality at runtime and do not fetch the blocks stuck in LLC to L1 caches until enough temporal locality is observed. While SWEL fetches the stuck blocks to L1 caches after a ﬁxed period of time without writes, despite the fact that many blocks have low locality. Those blocks fetched to L1 caches early by SWEL are likely to cause more coherence operations afterwards, like in ferret and raytrace applications. Besides, our adaptive data delivery system fully exploits the heterogeneous interconnects. Accesses to the blocks stuck in LLC are sped up by the TL shortcut. While SWEL uses the packet-switched network to access the stuck blocks, which has longer delay. On average, TL-ADAP reduces 24% more coherence overhead than TL-SWEL does. Applications mp3d and streamcluster have more producerconsumer data access patterns, leading to more RAW blocks. SWEL sticks these RAW blocks to LLC and reduces coherence overhead for these blocks, while TL-ADAP does not. Hence, for these two applications, SWEL gets more coherence overhead reduction compared to B-ADAP. However thanks to the fast TL shortcut which oﬀsets the latency of LLC accesses on remote nodes, TL-ADAP reduces more coherence overhead than TL-SWEL for streamcluster. Figure 3: Coherence overhead reduction. 4.2 Cache Miss Delay The evaluation result of total cache miss delay is shown in Fig. 5. The adaptive data delivery system of TL-ADAP reduces the transmission delay of latency-sensitive requests. Besides, TL-ADAP reduces the number of coherence operations by exploiting heterogeneous interconnects and tuning cache coherence adaptively. The critical path to solve a cache miss is reduced. In addition, by ﬁltering out lowlocality blocks from L1 caches, the L1 cache space can be more eﬀectively used for high locality data, thereby decreasing the amount of evictions and capacity misses. Various cache misses are tracked and classiﬁed as the following types: (1) Cold miss, (2) Capacity miss, (3) Sharing miss (cache miss to a block that was brought in previously but invalidated due to a write request by another core), (4) Upgrade miss (cache miss to a block in read-only state when a write request is made for it), and (5) Word miss (cache miss to a block that was ﬁltered out from L1 caches and accessed in LLC). Fig. 4 shows the breakdown of cache misses. TL-ADAP converts either capacity misses (in tspo and ferret ), sharing misses (in swaptions, canneal, water, tspo, ocean, and streamcluster ), or upgrade misses (in canneal ) into cheeper word misses. A sharing miss or upgrade miss is more expensive due to the additional network traﬃc generated by coherence operations like invalidations and synchronous write-backs. Capacity misses may also generate coherence operations depending on the block coherence state and request type. In addition, the TL interconnects speed up access to LLC on remote nodes and reduce the penalty of latency-sensitive requests, further reducing cache miss penalty. Overall, TL-ADAP reduces cache miss delay by 60% on average. For applications mp3d and streamcluster, more blocks (RAW) are stuck in LLC using SWEL, leading to more word misses and increased cache miss delay. For tspo and ferret, sharing misses are converted to cheaper word misses by both methods. TL-ADAP exploits data temporal locality, and allows the blocks stuck in LLC to be fetched into L1 caches again when they show high locality. While SWEL does not, leading to more word misses and increased Figure 4: L1 data cache miss type breakdown. The ﬁve bars from left to right represent baseline, SWEL, B-ADAP, TL-SWEL, and TL-ADAP. is similar since the total traﬃc is seldom aﬀected by the type of interconnects. 4.4 Network Energy Consumption Fig. 7 gives the evaluation result of network energy consumption. TL-ADAP reduces network energy consumption for all of the applications. The reason is twofold. Firstly, TL-ADAP consistently reduces communication traﬃc (subsection 4.3). Secondly, the TL interconnect is more energy eﬃcient. The average network energy consumption reduction using TL-ADAP is 48%. Even though the total traﬃc is almost equal using B-ADAP and TL-ADAP, the network energy consumption using TL-ADAP is much lower, thanks to the high energy eﬃciency of TL interconnect. Other than that, the network energy results of SWEL, B-ADAP, TLSWEL, and TL-ADAP are basically inline with communication traﬃc measurement. Figure 6: Normalized network utilization. Figure 7: Variation of network energy consumption. 4.5 CPI Fig. 8 shows the application CPI variation. TL-ADAP fully takes advantage of the heterogeneous interconnects to Figure 5: Variation of cache miss delay. cache miss delay. In dedup, data locality is not enough for B-ADAP to fetch the stuck blocks into L1 caches in time. The resulting cache miss delay is longer compared to that using SWEL. However TL-ADAP reduces more cache miss delay with fast TL shortcut oﬀsetting the latency of accesses to LLC. On average, due to better adaptation to data locality and deeper exploitation of heterogeneous interconnects, B-ADAP and TL-ADAP outperform SWEL and TL-SWEL at reducing cache miss delay by 20% and 44%, respectively. 4.3 Network Utilization Fig. 6 plots the network utilization (or communication traﬃc), which is calculated by multiplying the amount of messages, the average message size, and the average communication distance. TL-ADAP exploits block locality and reduces the number of coherence operations. For all of the applications, the resulting communication traﬃc required by TL-ADAP is reduced, on average by 32%. Our detailed experimental results (not shown in the ﬁgure) indicate that on average TL carries 18% of total traﬃc, which occupies 8% of total execution time. For most applications, TL-ADAP shows superiority at reducing on-chip communication traﬃc. TL-ADAP takes advantage of the heterogeneous interconnects and tunes cache coherence adaptively, eﬀectively reduces coherence traﬃc. Besides, in contrast to TL-SWEL, TL-ADAP allows RAW blocks to be placed in L1 caches since they are frequently read, thereby reduces accesses to LLC (as in mp3d and streamcluster ). On average, TL-ADAP reduces 18% more on-chip communication traﬃc than TL-SWEL does. Application dedup, however, does not show enough temporal locality for TL-ADAP to fetch the stuck blocks into L1 caches in time. Hence for dedup, TL-SWEL requires less communication traﬃc. The comparison between SWEL and B-ADAP improve the eﬃciency of memory subsystems. TL-ADAP exploits block locality and adaptively tunes cache coherence to reduce the number of coherence operations. Thus cache miss delay and on-chip communication traﬃc are both reduced (subsection 4.2 and 4.3). All of the applications beneﬁt from TL-ADAP, especially for raytrace. For raytrace, the proportion of shared data is large and the latency caused by coherence operations has big inﬂuence on performance. TL-ADAP adjusts to block locality and adaptively tunes cache coherence, largely reduces coherence overhead and cache miss delay, thus gets signiﬁcant speedup. On average TL-ADAP improves system performance by 36%. SWEL is oblivious to data locality and sticks frequently read RAW blocks to LLC, which increases word misses and cache miss delay (as in mp3d, tspo, and ferret ). Besides, SWEL does not fully exploit the advantages of heterogeneous interconnects as TL-ADAP does. On average, BADAP and TL-ADAP outperform SWEL and TL-SWEL by 14% and 25%, respectively. Figure 8: Speedup on 64-core system. 5. RELATED WORK Cache Coherence Exploiting Heterogeneity: The emerging heterogeneous interconnects provide more room for cache coherence improvement. SWEL [21] is proposed as a simple protocol with reduced coherence operations on heterogeneous interconnects. The L1 caches attempt to store only private or read only blocks, while shared and written blocks reside at the shared LLC regardless of locality. It is implemented on heterogeneous interconnects consisting of a mesh network and an electrical shared bus. The bus is exclusively used for invalidation broadcast to reduce latency. We fully exploit data locality and tune caching strategy adaptively. Besides, we exploit heterogeneous interconnects by adaptively directing diﬀerent type of messages through proper medium, fully taking advantage of the TL latencyoptimized interconnects. Lodde et al. [19] exploit a heterogeneous interconnect to improve the eﬃciency of broadcast-based cache coherence by implementing a control network exclusively for acknowledgement messages. They focus on broadcast-based cache coherence, while our work optimizes the more popular directorybased cache coherence. In heterogeneous systems integrating CPUs and GPUs, Power et al. [20] mitigate the coherence bandwidth eﬀects of GPU memory requests by optimizing the directory and adjusting coherence granularity. Utilization of TL: TL based globally shared on-chip interconnect [3, 4, 5, 6] performs well compared to conventional packet-switched networks. Heterogeneous interconnects utilizing a multi-band TL bus [7, 8] provide higher bandwidth. TL interconnect could also provide ultra-lowlatency communication for the ﬂow control signals [14]. Our work fully takes advantage of low-latency TL to reduce onchip delay. The TL expressway speeds up access to LLC on remote nodes and enhances the proposed cache coherence. Cache Coherence Optimization: Cache coherence optimizations have been studied deeply, including larger granularity coherence [28, 26] and active invalidation [13, 22]. Some eﬀorts are devoted to directory optimizations, such as entry emergence [27] and hybrid representation [10]. The L1 caches are left unmanaged in their works. We exploit the heterogeneous interconnects and tune caching strategy adaptively, the L1 cache space is more eﬀectively used for high locality data. Adaptive Caching: Selective caching between diﬀerent cache levels has been studied for both single core systems [23, 12] and multiprocessor systems on homogeneous interconnects [16]. They overlook data access patterns and target on all blocks. We exploit heterogeneous interconnects and optimize caching strategy targeting on shared written blocks with high coherence overhead. Some works [11, 15] exploit block placement and/or replication policy in LLC based on block access patterns, which optimize block placement on LLC. While our work carefully orchestrates caching strategy for diﬀerent blocks in the memory hierarchy. 6. CONCLUSION Emerging heterogeneous interconnects have shown high performance and could provide more room for cache coherence improvement. In this paper, the TL interconnect is utilized as a latency-optimized network and combined with a packet-switched network to create heterogeneous on-chip interconnects. We exploit the advantages of heterogeneous interconnects and improve cache coherence adaptivity to attack the high coherence overhead of directory-based MESI cache coherence protocols. Through on-line block locality proﬁling and adaptive caching strategy for shared written blocks, coherence operations could be greatly reduced. We adaptively direct diﬀerent type of messages to the proper medium of heterogeneous interconnects, so that on-chip latency is reduced and the eﬀectiveness of proposed coherence adaptivity optimization is enhanced. 7. ACKNOWLEDGMENTS This work has been supported in part by NSF under grants 1217662 and 1255729, and NSFC under grants 60873112 and 61028004, and the Open Pro ject Program of the State Key Laboratory of Mathematical Engineering and Advanced Computing under grant 2014A08, and Huawei Technologies Co., Ltd under grant YB2014100047 and a gift. 8.  [1] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The PARSEC benchmark suite: Characterization and architectural implications. In Proc. of the 17th Int’l Conf. on Paral lel Architectures and Compilation Techniques, pages 72–81, 2008. [2] D. Burger and T. M. Austin. The SimpleScalar tool set, version 2.0. ACM SIGARCH Computer Architecture News, 25(3):13–25, 1997. [3] A. Carpenter, J. Hu, M. Huang, H. Wu, and P. Liu. A design space exploration of transmission-line links for on-chip interconnect. In Proc. of the Int’l Symp. on Low-Power Electronics and Design, pages 265–270, 2011. [4] A. Carpenter, J. Hu, O. Kocabas, M. Huang, and H. Wu. Enhancing eﬀective throughput for transmission line-based bus. In Proc. of the 39th Int’l Symp. on Computer Architecture, pages 165–176, 2012. [5] A. Carpenter, J. Hu, J. Xu, M. Huang, and H. Wu. A case for globally shared-medium on-chip interconnect. In Proc. of the 38th Int’l Symp. on Computer Architecture, pages 271–282, 2011. [6] A. Carpenter, J. Hu, J. Xu, M. Huang, H. Wu, and P. Liu. Using transmission lines for global on-chip communication. Emerging and Selected Topics in Circuits and Systems, 2:183–193, 2012. [7] M. F. Chang, J. Cong, A. Kaplan, C. Liu, M. Naik, J. Premkumar, G. Reinman, E. Socher, and S.-W. Tam. Power reduction of CMP communication networks via RF-interconnects. In Proc. of the 41st Int’l Symp. on Microarchitecture, pages 376–387, 2008. [8] M. F. Chang, J. Cong, A. Kaplan, M. Naik, G. Reinman, E. Socher, and S.-W. Tam. CMP network-on-chip overlaid with multi-band RF-interconnect. In Proc. of the 14th Int’l Symp. on High Performance Computer Architecture, pages 191–202, 2008. [9] Compaq Computer Corporation, Shrewsbury, Massachusetts. Alpha 21264/EV67 Microprocessor Hardware "
Fault-Tolerant 3D-NoC Architecture and Design - Recent Advances and Challenges.,"In this paper, we survey recent research work in the design of fault-tolerant three-dimensional (3D) network-on-chip (NoC), which has drawn lots of research attention from both academia and industry. To be specific, we discuss the emerging defects introduced in 3D integration, the state-of-the-art fault-tolerant 3D router designs, various fault-tolerant routing algorithms in three-dimension, as well as the architecture and design methodologies to tolerate defective TSVs in 3D-NoC. Finally, we highlight open challenges and future research directions in this domain.","Fault-Tolerant 3D-NoC Architecture and Design: Recent Advances and Challenges Li Jiang† and Qiang Xu‡ † Depar tment of CS&E, Shanghai Jiao Tong University, Shanghai, China ‡ Depar tment of CS&E, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong ABSTRACT In this paper, we survey recent research work in the design of fault-tolerant three-dimensional (3D) network-on-chip (NoC), which has drawn lots of research attention from both academia and industry. To be speciﬁc, we discuss the emerging defects introduced in 3D integration, the state-of-the-art faulttolerant 3D router designs, various fault-tolerant routing algorithms in three-dimension, as wel l as the architecture and design methodologies to tolerate defective TSVs in 3D-NoC. Final ly, we highlight open chal lenges and future research directions in this domain. 1. INTRODUCTION With continuous technology scaling, we are able to integrate tens or even hundreds of intellectual property (IP) cores in today’s multi-processor system-on-chip (MPSoC) [1, 2]. To provide a reliable, scalable and eﬃcient communication infrastructure for such giant chips, the conventional busbased architectures have been gradually replaced by networkon-chips (NoCs) [3], as shown in [4, 5]. When the number of cores in a single silicon die increases to several tens, the latency and energy consumption spent on the global wires grow rapidly, even with NoC employed for communication [2]. To tackle this problem, three-dimensional (3D) integration has emerged as a promising design paradigm, which oﬀers high integration density yet short global interconnection by vertically stacking multiple dies with dense and high-speed through-silicon-vias (TSVs) [6]. The power/performance improvement arising from 3D integration and NoC architecture makes the amalgamation of these two emerging paradigms - 3D-NoCs - outperform their planar counterparts at power, performance and scalability [7]. Consequently, various 3D-NoC architecture and designs have been introduced in the literature. A survey is presented in [8], which outlined the opportunities and challenges associated with 3D-NoC and compared diﬀerent architectures on various system characteristics. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM . ISBN 978-1-4503-3396-2/15/09 ...$15.00 http://dx.doi.org/10.1145/2786572.2788709. Generally speaking, 3D-NoC architectures are used in very large chips fabricated with advanced nanometer technology, wherein circuits are prone to parameter variations and faults. Consequently, fault-tolerance is an important design issue for 3D-NoC, especially considering defects introduced in vertical integration. On the one hand, as the number of TSVs increases, the possibility of defective TSVs grows, and the manufacturing yield decreases exponentially when the number of TSVs goes beyond a certain value. Many 3D-NoCs designs take this constraint into consideration and propose irregular topologies [9, 10] and router designs [11, 12]. On the other hand, main-stream 3D-NoCs based on 3D-mesh topology and even more aggressive architecture [13, 14] advocate the massive use of the TSVs to enhance the communication bandwidth of 3D-NoCs, which inevitably increase the risk of chip failure during fabrication and runtime operation, and thereby require eﬃcient and eﬀective fault-tolerant mechanisms for yield and reliability enhancement. The ob jective of this survey is to clarify the failure mechanisms and fault models associated with 3D-NoCs and summarize the scientiﬁc eﬀorts made to achieve fault tolerance from various aspects. We not only put existing works in perspective and consolidate existing results and insights, but also highlight the general trends and open challenges for future research. The remainder of this paper is organized as follows. Section 2 describes the failure mechanisms, new types of defects, and the corresponding fault models in 3D-NoCs. In Section 3 and Section 4, we discuss fault-tolerant 3D architecture designs and fault-tolerant routing algorithms, respectively. Next, the defect tolerance techniques for TSVs are described in Section 5. Finally, we point out future research direction in this domain in Section 6 and conclude this paper in Section 7. 2. FAULT MODELS FOR 3D-NOCS A 3D-NoC architecture is composed of multiple layers of planer dies, in which a conventional 2D NoCs is accommodated. TSVs are deployed in the routers to provide extra ports in vertical direction, linking to the routers in other layers. However, 3D integration involves disruptive processes, such as TSV fabrication, wafer thinning and die bonding, rendering various defects and reliability issues in TSVs, microbumps, horizontal metal wires and transistors. In this section, we introduce the failure mechanisms of these defects, and the consequent impacts on 3D-NoCs, speciﬁcally in the inter-die links, the intra-die links and the routers. The resulting fault models are summarized in Table 1. Table 1: Defects and fault models in 3D-NoCs. Table 2: Functional fault models in 3D-NoCs. Location TSV Microbumps, solders Metal Device Failure Mechanism Bad plating Oxide defects doping concent. Rapid Gain growth Mismatch Electromigration Cycling Electromigration Cycling Chip warpage Mismatch Stress migration Local stress TDDB Physical defects Voids, pinch -oﬀ of TSV [15] Short TSV to substrate [16] Path delay, wrong logic [17] Void/crack formation & growth [18] TSV extrusion [19] Increase resistance, Disconnection [20] Crack [21, 22] Increase resistance, Disconnection [20] Crack [21, 22] Cracks, deformation & fracture [23, 21] Delamination [24] deform composition , vacancies in the metal [25, 26] Transistor carrier mobility [27, 28] Dielectric breakdown [29] Fault Model Delay, Open Bridging Delay, Bridging Delay, Open Open Delay, Open Open Open, Short Delay Stuck-at 2.1 Failure Mechanisms and Fault Models A failure mechanism is a mechanical or chemical action that renders the manufactured circuit diﬀerent from the desired one. The location, the failure mechanisms of physical defects, and the resulting faults are summarized in Table 1. The imperfect copper plating results in two types of defects: 1) Voids in TSVs or even Pinch-oﬀ of the TSV [15], causing delay fault and/or open fault. 2) Oxide defects (e.g., pinholes) along the TSV wall that makes short between the TSV and the substrate [16], leading to bridging fault. During TSV fabrication, temperature is ﬁrst increased for TSV electroplating and then is brought down to the ambient temperature. 3) Thermal-mechanical stress thus appears owing to the large mismatch of coeﬃcients-of-thermalexpansion (CTE) between the copper TSV and the silicon. The resulting faults can be categorized into three classes in terms of their area [21]: i) The strains in Cu (intrinsic stress) enforce micro-voids and cracks in TSVs to grow and coalesce, which lead to delay fault and even open fault in the runtime [24]. ii) Thermal mismatch (extrinsic stress) exacerbated by the thermal cycling leads to TSV extrusion, microbump deformation, and cracks in the interfacial area among TSVs, microbumps and metals and results in open fault [21, 22]. iii) In silicon around TSVs (local stress), the carrier mobility of a transistor may be altered [27]. This effect increases up to 10% delay for each individual transistors, which may lead to delay fault in the circuit path [28]. The nonuniform TSV placement and the microbump process on the thin and fragile wafer induce 4) Die warpage (global stress). It generates crack and fracture in the global area of microbumps and solders [23, 21]. Other failure mechanisms are listed as follows: 5) Electromigration that causes the metal atoms to migrate and form voids in the metal lines, resulting in the increased resistance and even disconnection for TSVs [30, 31, 32], microbumps [33] and the metal wires around TSVs [26]. 6) TSV coupling causes serious delay or mutual coupling among adjacent TSVs. It may result in critical delay fault or bridge Fault models Header/data ﬂit loss Packet drop Packet truncation Packet latency Misrouting Timing jitter Flit corruption Disconnection Vulnerable area crossbar switch, FIFO controller, intra-router link input buﬀer pointers/counters or output switch crossbar switch arbiter logic, inter-router link, TSV link intra-router link, routing unit, TSV link TSV link fault for signals passing through the coupled TSVs. Previous study [34] showed the inductive coupling is more critical in 3D-NoCs. 7) Time-Dependent Dielectric Breakdown (TDDB) happens when the leakage current of gate oxide reaches its limitation, which results in the failure of device. TDDB is more critical in 3D-NoCs due to the inherent weakness of thermal dissipation, and other thermal eﬀects (e.g., thermomigration) [35]. The aforementioned failure mechanisms aﬀect various circuitries in 3D-NoCs, resulting in diverse functional faults [35]. We summarize them in Table 2. Note that, the TSV link includes the body of TSV, microbump and the interface between metal wires. 2.2 Test Methods Existing works have presented several functional-level fault models and the corresponding test methods for interconnects and switches in the context of 2D NoCs. Based on single stuck-at functional fault models, Raik et al. [36] proposed an external test method for NoCs switches without using scan paths and wrappers. In [37, 38], on the other hand, the same set of test vectors are broadcasted among all switches, and the faults are detected through comparison of switch outputs with each other. Later, Karimi et al. [39] proposed a periodical online testing method to screen out the functional faults located in the switches. The fault model mainly focused on the faults in the switch that may route the packet to the wrong port. Grecu et al. [40] presented a BIST method for testing inter-switch links in a NoC structure, which employed a high level fault model [41] to deal with the crosstalk eﬀects due to inter-wire coupling. The high-level fault models presented in the literature include i) dropped data fault that the switch receives the data, but never sends it to the intended output port; ii) corrupt data fault that the switch corrupts the incoming data; iii) direction fault that the switch sends the incoming data to unintended output port; iv) multiple copies in space fault that the switch sends an incoming packet to the correct output port as well as another output port; and v) multiple copies in time fault that the switch sends multiple copies of an incoming packet to the intended output port throughout the time. These fault models have overlapped some of the fault models appeared in table 2, however, particular fault models for 3D-NoCs, such as thermal and stress induced latency faults are not considered. Moreover, the functional faults in 3D-NoCs may happen in the runtime operation, leading to performance degradation and functional failures. Few works have been proposed to tackle these issues. 3. FAULT-TOLERANT ROUTER DESIGN Few fault tolerance techniques are proposed for the routers in 3D-NoC. The underlying reason lies on the assumption that the router in 3D-NoC can be decoupled into the conventional 2D router and the TSV-based vertical links. Then, fault tolerance techniques can be applied to them, respective. On the one hand, conventional fault tolerance router design can be used in the 3D-NoC context, leveraging redundancies in diverse level of granularity, in order to achieve a good tradeoﬀ between cost-eﬀectiveness and error resilience. For example, in [43], ﬁne-grain redundancy at data path level was adopted for input buﬀer and crossbar. Hosseinzadeh et al. [42] extended the application-speciﬁc NoCs from 2D context to 3D, and proposed a fault tolerance technique using redundant routers and link bypassing. These redundancybased strategies, however, result in large hardware cost. While on the other hand, a strategy adopted in several 3DNoCs router designs is to reduce the usage of vertical connections. In this section, we highlight several works that advocated reducing the number of TSVs in the router for lower risk of defects within the routers and the vertical links. Pasca et al. [11] designed a router with the serialization of TSV interconnects, which can reduce the number of TSVs as well as the cumulated thermal. Meanwhile, this vertical channel can also tolerate TSV defects.1 Rahmani et al.[12] explored a mechanism to reduce the number of TSVs: the pair of unidirectional vertical channels between layers are replaced by a bidirectional channel that is dynamically self-reconﬁgurable to be used in either out-going or incoming direction. However, the drawback of these mechanisms are the inevitable degradation of performance when the inter-die communication become signiﬁcant [8]. The extra design logics involved in these special TSV channels also increase the possibility of manufacturing defects and reliability issues. A similar strategy -reducing the design complexity of the routers associated to TSVs - is applied in the architectural level. Not like conventional 3D-NoCs wherein a homogeneous topology is adopted and all tiers are vertically fully connected, vertically partially connected 3D-NoCs was proposed in [9]. It is ﬂexible to deﬁne i) the number of vertical links and their locations in 2D planner, ii) the topologies of each layer, and the structure of router design for vertical links. Routing algorithms in this irregular topologies can also provide fault tolerance and will be discussed in section 4. A full crossbar switch is the most complex circuity in a 3D router and it has a high risk of suﬀering physical defects and reliability crisis. Therefore, Kim et al. [13] proposed a partially-connected 3D crossbar structure which decomposes the crossbar into the one with sparse connections based on dimensions. Although these routers have less likelihood to be faulty, however, the limited usage of vertical links may be an obstacle for future exploration of the high-bandwidth computing platforms deployed with 3D-NoCs. 4. FAULT-TOLERANT ROUTING In general, existing fault tolerant routing schemes can be broadly classiﬁed into three categories [44]: i) stochastic routing that provides fault tolerance through data redundancy by probabilistically replicating packets multiple times and sending them over diﬀerent routes, ii) fully adaptive routing that 1Lots of TSV defect-tolerance techniques have been proposed at the circuit level, which will be discussed in Section 5. makes use of routing tables in every router to reﬂect the runtime state of the NoC and periodically update the tables when link or router failures occur to aid in adapting the packet path, and iii) partially adaptive routing that enables a limited degree of adaptivity by placing various restrictions and requirements on routing around faulty nodes, primarily to avoid deadlocks. Fault tolerant routing mechanisms for 3D-NoCs are mainly extended from the latter two routing methods. For the fully adaptive routing mechanisms in 3D-NoCs, the diﬃculty lies on the deﬁnition of the faulty region in three dimension and the cost-eﬀective distribution schemes of the faulty regions. For partially adaptive routing, the main eﬀorts of the proposed works are to ﬁnd an eﬃcient and cost-eﬀective way to deﬁne the dimension orders and turn models in 3D dimension. Because the fault tolerant routing involving only one plain (i.e. XY) in 2D-NoCs now faces a larger complexity in 3D-NoC involving three plains (i.e., XY, XZ and YZ). In particular, fault tolerant routing methods are also proposed speciﬁcally for vertical links due to its high vulnerability to defects. Designing a deadlock-free routing algorithm has been always a challenge even in the 2D-NoC. In the 3D-NoC, the situation becomes even more diﬃcult due to the possibility of forming a cycle within and between three plains. 4.1 Fully Adaptive Routing Fault tolerant routing for large scale interconnect networks has been addressed in early works in the context of 3D topologies. Nordbotten et al. [45] presented an adaptive and faulttolerant routing for 3D meshes and tori. Each router contains a routing table for information about the destination and the list of intermediate nodes, with which the faulty nodes can be avoided. Li et al. [46] studied the fault-tolerant routing for another 3D topology - 3D torus - with similar techniques. The proposed algorithm performs nondeterministic. That is, the probability of ﬁnding a valid route is higher than 90%, when the rate of faulty-node is up to 30%. In these methods, a global routing table is associated with each router, leading to large area cost and huge power consumption. To reduce the overhead of preserving the routing table, follow-up works are proposed by distributing less faulty information to less fault-free nodes. The basic idea can be traced back to an early work - Planar Adaptive Routing (PAR) presented by Chien et al. [47]. This method builds convex faulty regions, into which other nodes are notiﬁed to avoid before they route the packets. They also used three VirtualChannels (VCs) for deadlock-recovery. The drawback of this scheme is that the amount of healthy nodes within this region will be disabled. Routing scheme in [48] used another model - faulty cube - to tolerate faults. The information of these faulty cube contained in the 3D mesh is represented by a vector called extended safety level, which will be distributed to suﬃcient number of nodes to support minimal routing. Above works are extended to support Manhattan-distance path routing, which is minimum guaranteed in [49]. They presented a fault model based on PAR [47], named 3D minimumconnected component (MCC), in which a healthy node will be included only if using it in the routing will deﬁnitely cause a non-minimal routing-path. Further, they built a distributed process to collect & distribute MCC information to a limited number of nodes along so-called boundaries based on [48]. Only the routing having a Manhattan-distance-path will be Routing Resilience Deadlock Method PAR [47] Safety Level [48] MCC [49] PN [50] Deﬂection [51] 3D-FAR [52] 4NP-First [44] Fault Info Global routing table (RT) Minimum Layer RT & TSV state vectors 2,2,4 VCs 2 redundant pkts Sometimes non-minimum Non-minimum Non-minimum AFRA [53] Global Info Non-minimum Vertical links FT-Z-OE [54] AdaptiveZ [55] AdaptiveXYZ [56] Hamiltonian [57] LAFT [58] HLAFT [59] Circular path [60] Elevator ﬁrst [9] Redelf [10] No local exchange Adjacent link Best-eﬀort minimum sometimes non-minimum minimum non-minimum global info of elevator Links& routers Links Links& routers (t=0,t>0)link fault Permanent vertical link faults With VCs Yes Yes two VCs No VCs for same -direction links 1/0 VC for bi/directional fault vertical link With VCs Horizontal & Vertical links one-faulty link Vertical link No VC for one -faulty link No Use buﬀer No VC 2 VCs No VC Table 3: Existing fault-aware routing algorithm. activated at the source, and its success can be guaranteed by using the information of boundary in routing-decisions at the intermediate nodes. Later, Xiang et al. [50] proposed a fault model, named planar network (PN), that needs to store much less safety information at each faulty-free node. Overall, the overhead of these schemes makes them prohibitive for implementation on a chip in the context of 3D-NoCs with stacked dies. Therefore, these routing strategies are seldom adopted. Several works devoted themselves to reducing the above overhead when conducting fault tolerant routing for 3D-NoCs. Feng et al. [51] proposed a low-overhead fault-tolerant deﬂection routing algorithm. To reduce the overhead of a large global routing table, this algorithm decouples the global routing table into a layer routing table and two TSV state vectors to make eﬃcient routing decision to avoid both TSV and horizontal link faults. Compared to the previous solutions, this lightweight switch occupies 40% less area and consumes 49% less power consumption. However, the deployment of routing tables is still costly in terms of hardware and suﬀers from poor scalability due to the area required for the tables. A fully adaptive routing algorithm for tolerating faults in either inter-layer or intra-later connections, denoted as 3DFAR, uses two, two and four virtual channels along the X, Y and Z dimensions respectively [52]. In this algorithm, the network is divided into four disjoint networks and packets can use any shortest paths between the source and destination nodes. Minimal routing is guaranteed for faulty routers, while non-minimal routes are used in the case of faults. The idea behind this method is to allow packets to switch between disjoint subnetworks in an ascending order to provide a high fault-tolerant capability. Similarly, the deadlock freedom is guaranteed by the deployment of virtual channels. 4.2 Partial Adaptive Routing In order to diminish the negative impacts of routing tables and centralized approaches, partial adaptive routing was proposed by restricting the route by certain rules, such as dimension orders and turning models. The dimension orders restrict the movement of the packets in certain dimension before it changes the direction. As long as the packet enters another dimension, it may not move along the original dimension anymore. A turning model refers to a 90-degree change of traveling direction for a packet. Whenever packet encounter one or more faulty links for the output ports, the router will change their route from the remaining directions based on the turn model. The one without any choice for a fault free output port will be dropped. Both of these two methods allow deadlock-free routing. The ﬁrst partial adaptive fault-tolerant routing schemes in 3D-NoCs was presented in [44] based on a turning model called 4NP-First. Two out of the three possible positive directions need to be selected as the last two directions before routing a packet to its destination. Two redundant packets are sent, each of which takes one of the turn model. Two dedicated virtual channels are provided for these two packets to ensure deadlock freedom. However, these restrictions cause a non-minimal routing selection whenever it may take too many additional hops for the packet to reach its destination. Consider the high failure rate of TSVs, some works only provide the fault-tolerance for vertical links to save the cost. A deadlock-free routing algorithm for 3D mesh-based NoCs named AFRA [53] was proposed that tolerates faults on vertical links. The algorithm is simply applying ZXY and XZXY routings in the absence and presence of fault, respectively. This enables the routing to save virtual channels for performance rather than scarifying them for deadlock avoidance. However, AFRA is deadlock-free only if all vertical faulty links have the same direction. Another distributed routing, namely FT-Z-OE (Fault Tolerant Z Odd-Even) routing [54], was proposed to tolerate permanent faults on vertical links of 3D mesh NOCs. In this algorithm, the columns of mesh are classiﬁed into odd and even columns, to which diﬀerent turn model is applied, respectively. Compared with AFRA [53], it needed no global information about the faulty vertical-links in each router. Compared with 4NP-First [44], it had no redundant packets. In terms of the overhead of virtual channels, only one extra virtual channel is needed for bidirectional faults and no virtual channels is required for the case that all of faults have the same direction (similar to AFRA). Rahmani et al. [55] presented a fault-tolerant routing algorithm -AdaptiveZ - for Hybrid-3D-NoC architecture, where the vertical inter-layer links are based on a mixture infrastructure of packet switching router and a bus architecture. A faulty TSV links is recognized as a bus failure, which will be notiﬁed by the arbiter to the router and the corresponding packets want to go through it will be rerouted to the neighboring bus based on the static XYZ/YXZ 2D routing algorithm. The same authors extended above work in [56] by integrating an online monitoring scheme in the arbiter who can know the faulty information of the surrounding buses (arbiters). Utilizing these information, they proposed a routing algorithm - AdaptiveXYZ [56] - to globally balance the load across all vertical buses. These algorithms are customized in this hybrid architecture. Despite the overhead is reduced by constraining the protection sphere to the TSV-links, the fault models mentioned in section 2 indicates that the horizontal links are also vulnerable in 3D-NoCs. Therefore, some works were proposed to tolerate faults in both vertical links and horizontal links. To diminishing the overhead of distributing the fault information, they all leverage the local information stored in the router, which indicates the adjacent faulty links, to guide the packet swithcing. Ebrahimi et al. [57] took advantages of the Hamiltonian path to tolerate faults in 2D and 3D-NoCs. The presented approach is not only very simple but also able to tolerate almost all one-faulty links either in horizontal or vertical links without using any virtual channels. However, it cannot tolerate multiple vertical and horizontal faulty links. The Look-Ahead-Fault-Tolerant (LAFT) was developed [58] based on Look-Ahead XYZ model. By requesting information about fault-link in next node in look-ahead function, LAFT can avoid blocking path in routing. The number of possible minimal routing, the congestion are considered to evaluate the path quality: a value for the router to choose the port for forwarding the packet. However, in some case of error, LAFT provides non-minimal routing path. Moreover, LAFT is still struggling with deadlock. In order to overcome the deadlock, the same authors extended LAFT to Hybrid-Look-Ahead-Fault-Tolerant (HLAFT) [59]. The proposed HLAFT is based on LAFT architecture and adds some functions: Local RC (Route Calculating) which supports change routing path instead of using predeﬁned nextport value; Random-Access-Buﬀer technique on input-port which supports deadlock recovery. Another strategy without distributing the faulty information in both TSVs and horizontal links was proposed by Alizadeh et al. [60]. The proposed routing algorithm is based on deﬁning some circular routing paths which oﬀers a deadlockfree routing for packets in mesh-based topologies. In addition to tolerating faults, these circular paths help in reducing congestion in the central part of the network at high injection rates, by avoiding packets through central parts. The proposed circular routing algorithm is able to tolerate all one-faulty links. 4.3 Routing in Irregular 3D-NoCs In this section, we discuss the routing algorithm for irregular 3D-NoCs wherein diﬀerent layers are sparsely connected. Elevator-ﬁrst [9] - a distributed routing algorithm - rein [69], targeting on the resistive or partial open TSVs induced by the interfacial cracks and electromigration exacerbated by the thermal stress, denoted as latent TSV defects. They described a reconﬁgurable in-ﬁeld TSV repair solution that is able to eﬀectively tolerate unpredictable through the judicious use of the timing slacks belonging to the signals passing through the TSV links. The basic idea is that a sequently, it can reroute the signal connecting to a defective TSV to a redundant one for repair. It has a ﬂexible redundancy ratio (1 : N for a N × N TSV grid), and it can tolerate any single TSV failure in each row/column in the grid. Due to the area cost of the crossbar design, however, N cannot be a large value, which limits its usage in 3D-NoCs with large bandwidth. In spite of the diﬀerent redundancy strategies used in these works, they all replace faulty TSVs with neighboring ones. In practice, if one TSV is defective after the bonding process, it has a high likelihood of neighboring TSVs being faulty due to the failure mechanisms mentioned in section 2, such as chip warpage, TSV coupling, prorogated cracks in TSVs and microbumps, debonding phenomenon etc. Due to such clustering eﬀect, earlier TSV repair techniques are less eﬀective. To address this problem, a novel TSV redundancy architecture was proposed to enable faulty TSVs to be repaired by spares that are distant with the help of a simple switch design (see Fig. 1(d)) and a repair-path routing method used to search spare TSVs for each faulty ones in the cluster [65]. However, the reparability of above method is bounded by the length of the interconnect along the repair path, because the rerouted signal passing through the repair path has to meet the timing requirement. Thus, an alternative method uses ILP to minimize the interconnect involved in switching from functional TSVs to spares [66]. Furthermore, a topology mapping method was proposed to construct a virtual TSV grid from a physical TSV layout, wherein a topological neighbor is not necessary a physical neighbor. This method can help the TSV redundancy architecture with neighboring TSVs as replacements for faulty ones to recover from catastrophic clustered faults [67]. 5.2 Temporal Redundancy In this category, the timing requirement of the signals passing through the TSV links are relaxed for defect tolerance. In [11], when the faulty TSVs are detected then the links serialize data transmission and re-map signals on the fault free TSVs. The serial channel is composed of a self-controlled multiplexer (SCM) and demultiplexer (SCD) localized in each vertical channel achieving asynchronous serialization and deserialization. The capability of transmitting any subset of data bits on any functional set of TSVs makes it highly ﬂexible when a high TSV failure rate (> 5%) occurs, in which the redundant TSVs are not feasible. Based on above serial TSV link architecture, Kologeski et al. [68] proposed to make use of the low quality TSVs with resistive/partial open TSVs and send data bits through them in lower speed compared to other fault-free TSVs, in order to cope with the delay variation in TSVs. In addition, an Elevator First routing algorithm [9] is adopted in case a TSV is fully open. However, these technique have two potential weakness i) the corresponding conﬁguration logic leads to large overhead and area cost, especially when the bandwidth of TSV links is large; ii) the link performance in terms of latency decreases because the links need extra clock cycles to transmit all the data through the link and the serialization itself requires extra delay. Therefore, the links are designed to degrade their performance up to a serialization rate above which they are non-functional. This puts a strong assumption on the system performance, which needs the corresponding design and management schemes to support system degradation. Another method to explore the timing redundancy is shown 6.2 Latent Defect Tolerance Most existing fault-tolerant design techniques in 3D-NoC domain assume the failure are caused by manufacturing defects and are known after manufacturing tests. As discussed in Section 2, however, 3D-NoC may suﬀer from serious reliability degradation at runtime. To be speciﬁc, the increased resistance in TSVs, microbumps as well as the horizontal links may slow down the signal transmission in vertical direction. The mobility changes in the transistors surrounding TSVs may reduce the processing speed of internal logics in the switches. There are few works proposed in the literature to extend the lifetime of NoC-based systems [76, 77], and more works are desired in this direction. In particular, all the above reliability threats would lead to NoC performance degradation before catastrophic failures appear. However, it is hard to tell the root cause of performance degradation, as such phenomenon may also be caused by network and system issues like congestion and improper task mapping among the PEs. Therefore, it is essential to develop eﬃcient and eﬀective online fault detection techniques in future 3D-NoCs to observe and root cause performance degradation at the router level, in order to apply the right fault-tolerant solution. But again, the cost and impact on power and performance must be low. Moreover, the clustered faults in TSVs and microbumps make the existing TSV fault tolerant mechanisms less eﬃcient and only a few works [65, 67] have tried to address these problems in circuit level. Future works may reconsider the cost-eﬀectiveness of countermeasures for these defects in 3D-NoC architecture and router design. 7. CONCLUSION 3D-NoC is a promising design paradigm for high-performance MPSoC designs. In this paper, we focus on the reliability aspects of 3D-NoC and survey existing fault-tolerant mechanisms in 3D-NoC architecture design, router design, routing algorithms and dedicated TSV defect-tolerance solutions. Future works in this ﬁeld should pay more attention to emerging 3D-NoC architectures and topologies and latent defects occurred online. 8. ACKNOWLEDGEMENTS This work was supported in part by the Hong Kong S.A.R. General Research Fund (GRF) under Grant No. 418112 and Grant No. N CUHK444/12, in part by National Natural Science Foundation of China under Grant No. 61432017, and in part by Shanghai Science and Technology Committee under Grant No.15YF1406000. 9. "
"Designing High-Performance, Power-Efficient NoCs With Embedded Silicon-in-Silica Nanophotonics.","On-chip electrical links exhibit large energy-to-bandwidth costs, whereas on-chip nanophotonics, which attain high throughput, yet energy-efficient communication, have emerged as an alternative interconnect in multicore chips. Here we consider silicon nanophotonic components that are embedded completely within the silica (SiO2) substrate as opposed to existing die on-surface silicon nanophotonics. As nanophotonic components now reside subsurface, within the silica substrate, non-obstructive interconnect geometries offering higher network throughput can be implemented. First, we show using detailed simulations based on commercial tools that such Silicon-in-Silica (SiS) structures are feasible, and then demonstrate our proof of concept by utilizing a SiS-based mesh-interconnected topology with augmented diagonal optical channels that provides both higher effective throughput and throughput-to-power ratio versus prior-art.","Designing High-Performance, Power-Efﬁcient NoCs With Embedded Silicon-in-Silica Nanophotonics Elena Kakoulli, Vassos Soteriou, Charalambos Koutsides, Kyriacos Kalli Department of Electrical Engineering, Computer Engineering and Informatics {elena.kakoulli, vassos.soteriou, c.koutsides, kyriacos.kalli}@cut.ac.cy Cyprus University of Technology, Limassol 3603, Cyprus ABSTRACT On-chip electrical links exhibit large energy-to-bandwidth costs, whereas on-chip nanophotonics, which attain high throughput, yet energy-eﬃcient communication, have emerged as an alternative interconnect in multicore chips. Here we consider silicon nanophotonic components that are embedded completely within the silica (SiO2 ) substrate as opposed to existing die on-surface silicon nanophotonics. As nanophotonic components now reside subsurface, within the silica substrate, non-obstructive interconnect geometries offering higher network throughput can be implemented. First, we show using detailed simulations based on commercial tools that such Silicon-in-Silica (SiS) structures are feasible, and then demonstrate our proof of concept by utilizing a SiS-based mesh-interconnected topology with augmented diagonal optical channels that provides both higher eﬀective throughput and throughput-to-power ratio versus prior-art. Categories and Subject Descriptors B.4.3 [Input/Output and Data Communications]: Interconnections (Subsystems) General Terms Keywords Performance, Design On-chip Nanophotonics, Silicon-in-Silica, Topology 1 Introduction On-chip nanophotonics have recently emerged to address the scalability challenges faced by all-electrical Networks-onChips (NoC) of chip multicores, oﬀering higher bandwidth and shorter message delivery latency at manageable power budgets [1, 2]. Prior-art has demonstrated various hybrid silicon-based electrical/nanophotonic designs where all components, i.e., photonic, electrical, and optoelectronic, all reside on the silicon chip’s surface [1, 2]. As such, two chip fabrication technologies exist: (1) where all components inhabit a single die, or (2) where optical and electrical components each occupy a dedicated silicon plane(s) that are connected vertically, forming an architecturally dense 3D die structure. Such 3D architectures, however, entail both high design complexity and fabrication intricacy as die have to be perfectly aligned, along with exacerbated heat dissipation requirements. In this paper we consider an alternative architecture where silicon (Si) nanophotonic components are embedded completely in silica (SiO2 ), i.e., reside subsurface, as opposed to existing on-surface silicon photonics. As nanophotonic components now reside subsurface, within the silica substrate, a greater portion of a chip’s area can be utilized by cores and routers, while non-obstructive interconnect geometries oﬀering higher network throughput can be fabriPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s). NOCS ’15, September 28-30, 2015, Vancouver, BC, Canada ACM 978-1-4503-3396-2/15/09. http://dx.doi.org/10.1145/2786572.2786588 cated with standard lithography methods, including elaborate topologies that contain and utilize diagonal waveguides (nanophotonic channels or links). The contributions of this paper are that: (1) we show using detailed simulations based on the RSoft commercial software tool [3] that such subsurface Silicon-in-Silica (SiS) structures are feasible, with optical signal integrity highly maintained, achieving up to 99% eﬃciency, (2) provide their design features, and (3) then demonstrate our proof of concept by using a SiS-based mesh-interconnected nanophotonic topology with augmented diagonal waveguides that attains higher eﬀective throughput and throughput-to-power ratio vs. prior-art. 2 SiS-Embedded Nanophotonics: Background, Components Characterization and Design Photonic NoCs comprise: (1) waveguides, i.e., photonic signal-carrying channels, that interconnect routers, (2) MicroRing Resonators (MRRs) that are connected to waveguides serving as either optical modulators or as ﬁlters for sending/extracting data to/from a waveguide, respectively, and (3) transceivers that mark the electro-optical boundary, converting signals from the optical domain to the electrical domain (to be utilized by routers) and vice-versa. MRRs are key to the design of optical NoCs. They act as modulators, where optical data can be inserted into a bus waveguide that is coupled to the MRR’s closed-loop waveguide at a speciﬁc wavelength through electro-optical modulation. They also act as versatile resonant optical ﬁlters, extracting light of a speciﬁc wavelength from an input bus waveguide carrying optical data to an output bus waveguide that is coupled to the same closed-loop waveguide at its opposite side. A photo-detector then measures the light intensity at the device output for a given ﬁltered wavelength. Since MRRs resonate at distinct wavelengths, and remain quiescent otherwise, this behavior serves as the primary mode in realizing ultra-high bandwidth wavelengthdivision-multiplexing, where waveguides simultaneously carry multiple optical signals without interference. For resonance to occur in MRRs the condition 2πrnef f = mλm must be met, where nef f is the eﬀective refractive index of the ring (implemented in silicon) that must be greater than the surrounding material (silica in our case vs. air in conventional silicon nanophotonics implemented onto the silicon die surface), r is its radius, m is the mode number of the MRR (a positive integer number), and λm is the resonant wavelength. Unlike previous works in which silicon nanophotonic components reside on the silicon surface along with electrical components [1, 2], here we take a substantially diﬀerent fabrication approach where MRRs and waveguides made of silicon are embedded within the silica surface, forming a Silicon-in-Silica (SiS) structure, with electrical components placed onto the silica surface on top of them. Our SiS structure consists of two waveguides and a ring resonator made of pure silicon (Si) embedded within a bulk volume of silica (SiO2 ) using lithographic techniques described by White et al. [4]. To implement our SiS structure we calculated the time-dependent electromagnetic ﬁeld, using the RSoft commercial software tool [3]. For optimal results we carefully deﬁned the dimensions and refractive index proﬁle of the proposed subsurface structure. With regard to the behavior of the electromagnetic ﬁeld at the diﬀering material boundaries, we applied the perfectly matched layer bound(a) ;Ϭ͕ϬͿ ;ϭ͕ϬͿ ;Ϯ ͕ϬͿ ;ϯ͕Ϭ Ϳ ;Ϭ͕ϭͿ ;ϭ͕ϭͿ ;Ϯ ͕ϭͿ ;ϯ͕ϭ Ϳ ;Ϭ͕ϮͿ ;ϭ͕ϮͿ ;Ϯ͕ϮͿ ;ϯ͕Ϯ Ϳ ;Ϭ͕ϯͿ ;ϭ͕ϯͿ ;Ϯ ͕ϯͿ ;ϯ͕ϯ Ϳ (b) Coupler Of f-Chip Laser Data Send Path TX Tile 0 RX TX Tile 1 RX TX Tile 2 RX TX T ile 3 RX Data R eceive Path Ϭ ϭ Ϯ ϯ Figure 1: (a) a 4× 4 topology with horizontal (black) and vertical (green) subnets augmented with diagonal (red) and anti-diagonal (blue) subnets, (b) a subnet of 4 nodes with transmit (TX) and receive (RX) groups of rings (circles) related to each tile (ovals). ary conditions. The following structural data were found or set for our SiS design: working wavelength of 1.593635 μm, MRR ring diameter of 3.6 μm, waveguide length of 5 μm and width of 0.2 μm, component width of 4 μm, where the separation distance between the waveguide and the ring resonator is 0.05 μm; this gap leads to optimum coupling between the waveguide and the ring. The SiS MRR works eﬀectively, extracting 99% of the waveguide-propagated light power due to the high refractive index contrast between silicon and silica, with just 0.98 dB/cm waveguide loss. Lastly, our SiS structure can work bi-directionally, i.e., either as a light receiver or as a light transmitter. 3 Mesh Topology With Augmented Diagonal Waveguides and Adaptive Routing Algorithm Our interconnect architecture utilizes SiS-embedded waveguides and MRRs exclusively. To avoid the large power overheads of chip-spanning optical channels utilized in priorart [2], we instead break the network into shorter and hence power consumption-limited bus waveguides, a.k.a. “subnets,” similar to those used in the LumiNOC architecture [1]. As waveguides can now be fabricated at any angle within the silica substrate, i.e., subsurface, we extend the mesh-like subnet topology of LumiNOC to utilize diagonal waveguides that are augmented to the base mesh interconnect. Figure 1(a) shows such a symmetric 16-node realization, as a proof of our concept, where a Diagonal (D) subnet and an AntiDiagonal (AD) subnet are augmented to the base arrayinterconnected topology that comprises Horizontal (H) and Vertical (V) subnets. Each optical-electrical router assumes a conventional 4-stage pipelined organization, with (1) Optical to Electrical (O/E) conversion and routing computation, (2) Virtual Channel (VC) arbitration and photonic subnet allocation, (3) switch allocation, and (4) crossbar traversal and Electrical to Optical (E/O) conversion; ﬁnally, waveguide propagation follows. Each such router either uses two (H+V), or three (H+V+D, or H+V+AD), or all four (H+V+D+AD) input/output ports, according to its waveguide bus-connecting count, plus the processor injection/ejection e-ports. Each such input port extracts data using its SiS waveguide-MRR structure, and converts it to electrical signals (using a local O/E block) to be absorbed by the router (or to be further relayed); a router relays or sends optical data, pre-converted from their electrical form by a local E/O block, through its output ports, and are then modulated and inserted into the subnet via the associated MRR. We utilize LumiNOC’s [1] ﬂow-control protocol, where each waveguide double-backs (loops) from the external laser source, connects to each router input port (acting as the receiver), and then to each router’s output port (acting as the transmitter). In this way a single subnet, which contains as many wavelengths as the number of routers it connects, is used ﬁrst to arbitrate which router should gain access to the bus waveguide, using one-hot encoded control messages as in LumiNOC, and in the second phase the winner router with granted permission transmits its data (see Figure 1-(b)). Our SiS-based topology presents opportunities for routing optimization, so as to maximize network throughput, since ϮϬ ϭϴ ϭϲ ϭϰ ϭϮ ϭϬ ϴ ϲ ϰ Ϯ Ϭ Ϳ Ɛ Ŷ ;  Ǉ Đ Ŷ Ğ ƚ Ă >  Ğ Ő Ă Ɛ Ɛ Ğ D  Ğ Ő Ă ƌ Ğ ǀ  ϮŵĞƐŚ;ϰsƐͿ >ƵŵŝEKͲϭ> ^ŝ^Ͳϭ> >ƵŵŝEKͲϮ> ^ŝ^ͲϮ> >ƵŵŝEKͲϰ> ^ŝ^Ͳϰ> EĞƚǁŽƌŬĂŶĚǁŝĚƚŚ;dďƉƐͿ Figure 2: Latency-bandwidth curves under bit-complement trafﬁc. The term “L” denotes the number of photonic layers. in most cases alternative progressive routing paths may exist, where at most, a packet has to traverse a two-hop route along a path. As such, we develop an adaptive photonic routing algorithm where dynamic metrics, in terms of the number of pending arbitrations per alternative waveguide, are considered. The waveguide, or waveguide pair, with the least such number is chosen as the pro jected fastest route. 4 Experimental Setup and Results We implemented a cycle-accurate microarchitectural-level simulator that supports (1) 2D all-electrical meshes (EMesh), (2) the LumiNOC architecture, and (3) our proposed SiSbased topology; all utilize four-stage pipelined routers with prises a 64-node CMP with its tiles arranged in an 8 × 8 input Virtual Channels (VCs) (see Section 3), and each comarray - the SiS-based topology was scaled linearly using the base 4 × 4 SiS topology of Figure 1-(a). We assume a 10 GHz waveguide modulation rate, with routers clocked at 5 GHz [1]. Synthetic bit-complement traﬃc traces, with packets comprising four 128-bit ﬂits, are utilized. Figure 2 shows our SiS topology outperforming LumiNOC under all equivalent photonic layer counts. All photonic interconnects outperform EMesh in terms of latency before reaching their saturation, while SiS-4L and LumiNOC-4L (4 optical layers), also outperform EMesh in terms of sustainable throughput. We next estimate both the electrical power consumption of NoC routers, using the Orion 2.0 power models library [5] at 45 nm CMOS process technology, and the photonic energy consumed using the Corona [2] architecture power models, except for where SiS parameters are available. We focus on the realistic throughput-per-power metric, in terms of Tbps/W. Under 1, 2, and 4 photonic Layers (“L”), our SiS-based topology achieves respective performances of 3.28 Tbps/W, 2.67 Tbps/W, and 2.58 Tbps/W, while LumiNOC equivalently attains 3.29 Tbps/W, 2.48 Tbps/W, and 2.41 Tbps/W; our SiS-based architecture, except with 1L, achieves both improved performance and eﬃciency vs. LumiNOC. 5 Conclusions We presented a photonic on-chip interconnect where silicon nanophotonic components are embedded in silica. We ﬁrst characterized such SiS structures and then constructed a photonic mesh NoC with augmented diagonal waveguides that provides higher throughput-to-power versus prior-art. Acknowledgments This work falls under the Cyprus Research Promotion Foundation’s Framework Programme for Research, Technological Development and Innovation 2009-10 (DESMH 2009-10), co-funded by the Republic of Cyprus and the European Regional Development Fund, and speciﬁcally under Grant IPE/PENEK/0311/06. 6 "
ARTEMIS - An Aging-Aware Runtime Application Mapping Framework for 3D NoC-based Chip Multiprocessors.,"In emerging 3D NoC-based chip multiprocessors (CMPs), aging in circuits due to bias temperature instability (BTI) stress is expected to cause gate-delay degradation that, if left unchecked, can lead to untimely failure. Simultaneously, the effects of electromigration (EM) induced aging in the on-chip wires, especially those in the 3D power delivery network (PDN), are expected to notably reduce chip lifetime. A commonly proposed solution to mitigate circuit-slowdown due to aging is to hike the supply voltage; however, this increases current-densities in the PDN due to the increased power consumption on the die, which in turn expedites PDN-aging. We thus note that mechanisms to enhance lifetime reliability in 3D NoC-based CMPs must consider circuit-aging together with PDN-aging. In this paper, we propose a novel runtime framework (ARTEMIS) for intelligent dynamic application-mapping and voltage-scaling to simultaneously manage aging in circuits and the PDN, and enhance the performance and lifetime of 3D NoC-based CMPs. We also propose an aging-enabled routing algorithm that balances the degree of aging between NoC routers and cores, thereby increasing the combined lifetime of both. Our framework also considers dark-silicon power constraints that are becoming a major design challenge in scaled technologies, particularly for 3D stacked CMPs. Our experimental results indicate that ARTEMIS enables the execution of 25 percent more applications over the chip lifetime compared to state-of-the-art prior work.","ARTEMIS: An Aging-Aware Runtime Application Mapping Framework for  3D NoC-based Chip Multiprocessors  Nishit Kapadia, Venkata Yaswanth Raparti, Sudeep Pasricha  Department of Electrical and Computer Engineering  Colorado State University, Fort Collins, CO, U.S.A.  nkapadia@colostate.edu, yaswanth@rams.colostate.edu, sudeep@colostate.edu   I.  INTRODUCTION  II. ARTEMIS FRAMEWORK: OVERVIEW  Bias Temperature Instability (BTI) is the most dominant physical  phenomenon that degrades the maximum switching rate of transistors  under long periods of voltage stress. BTI causes gradual circuit  slowdown over the operational lifetime of an electronic chip. The  principal effect of such a circuit-aging mechanism is to increase  circuit-threshold voltage (VT), which results in higher circuit-delay.  From a system-level perspective, such VT-degradation causes  slowdown in critical paths of processor-cores and network-on-chip  (NoC)  routers,  thereby  limiting overall system performance.  Additionally, electromigration (EM) in metal wires on the chip leads  to increased interconnect resistance over time. This phenomenon is  most dominant in power delivery network (PDN) wires that carry  larger unidirectional currents compared to signal wires. The increased  resistance of the power-grid results in higher IR-drops in the PDN,  which causes further circuit slowdown due to degradation of supply  voltage. These adverse effects of EM are expected to be particularly  severe in 3D chip-multiprocessors (CMPs) that possess limited  number of power-pins and higher current densities.   A commonly proposed solution to mitigate circuit-slowdown due  to aging is to hike the supply voltage; however this increases current densities in the PDN due to the increased power consumption on the  die, which in turn expedites PDN-aging. Moreover, hiking supply  voltage also increases VT-degradation, further increasing the rate of  circuit-aging. We thus note that mechanisms to enhance lifetime  reliability in 3D NoC-based CMPs must consider circuit-aging  together with PDN-aging.  In this work, for the first time, we propose  a novel runtime framework (ARTEMIS) for intelligent dynamic  application-mapping and voltage-scaling to simultaneously manage  aging in circuits and the PDN, and enhance the performance and  lifetime of 3D NoC-based CMPs. We also propose a symmetrical  aging-enabled routing (SAR) algorithm that balances the degree of  aging between NoC routers and cores, thereby increasing the  combined lifetime of both. Our framework also considers dark silicon  power constraints that are becoming a major design challenge in  scaled technologies, particularly for 3D stacked CMPs.  Objective: Perform runtime application-mapping and DVS-scheduling  on a given 3D NoC-based CMP platform such that the total number of  applications executed over the lifetime of the chip is maximized,  while all application-specific minimum operating frequency- and  maximum runtime-constraints, as well as CMP platform-specific  dark-silicon power-budget (DS-PB) are satisfied.   Permission to make digital or hard copies of part or all of this work for  personal or classroom use is granted without fee provided that copies are not  made or distributed for profit or commercial advantage and that copies bear  this notice and the full citation on the first page. Copyrights for third -party  components of this work must be honored. For all other uses, contact the  Owner/Author.   Copyright is held by the owner/author(s).  NOCS '15, September 28-30, 2015, Vancouver, BC, Canada  ACM 978-1-4503-3396-2/15/09.  http://dx.doi.org/10.1145/2786572.2786578  The key aspects of our proposed framework are illustrated in  Figure 1. We consider a scenario where applications arrive at runtime  to be executed on the 3D CMP platform. The knowledge of the chipaging profile is continuously utilized in the application-mapping and  dynamic voltage scaling (DVS) scheduling steps. The applicationmapping at runtime consists of mapping the application task-graph on  to a chosen rectangular- or cuboidal-shaped region of tiles (similar to  [6] and [7]) on the 3D CMP admissible for the application (from the  list {B1,…,Bn}), as well as performing routing path allocation of the  intra-application communication-flows on the 3D NoC. At any given  time, the scaling-down of Vdd via DVS-scheduling to save power and  to limit aging is constrained by the frequency-constraints of the  applications running on the 3D CMP, whereas scaling-up of Vdd is  constrained by the DS-PB. Due to space constraints, all the details of  our aging-aware application mapping and DVS as well as our circuit-  and PDN-aging analyses are not discussed. Sections II.A and II.B  briefly describe the two main steps employed in ARTEMIS.  Figure 1. Overview of ARTEMIS runtime aging-aware applicationmapping and DVS-scheduling framework  A. Circuit- and PDN-aging Aware Mapping Region-Selection  and Voltage-Selection Heuristic  Our heuristic utilizes the runtime profiles of VT-degradation and  worst-case (WC) IR-drops of the 3D CMP (aging processes are  modeled based on [1] and [2] in our simulation framework) .  The  objective is to find the region on the 3D-mesh (with one of the  admissible shapes) so as to: (a) minimize leakage-power; (b)  minimize EM-induced degradation of PDN-paths supplying to cores  with high WC-IR-drops; (c) satisfy the frequency-constraint of the  application by all cores within the region; (d) satisfy the DS-PB. To  this end, we define the following cost-function (Ψ) for joint  optimization of leakage-power and PDN-degradation:  Ψ = ∑ 𝑘=𝐷𝑜𝑃 𝑘=1 {𝛼. ( max⁡_𝑉𝑇−𝑉𝑇𝑘 max⁡_𝑉𝑇−𝑛𝑜𝑚_𝑉𝑇 ) + 𝛽 ( 𝑊𝐶_𝐼𝑅_𝑑𝑟𝑜𝑝𝑘 max⁡_𝐼𝑅_𝑑𝑟𝑜𝑝 )} ⁡⁡⁡⁡….. (1)  The heuristic performs a simple exhaustive search over all tiles on  the 3D-mesh and over all admissible shapes {B1, …, Bn} for the  application. The VT-profile and WC-IR-drop profile inputs are used  for calculating the value of Ψ. The region with the least Ψ value that  satisfies the frequency-constraints and at the same time does not                              violate the DS-PB, is selected for mapping the application under  consideration. If no region on the 3D-mesh is found to satisfy the  frequency-constraints, we repeat the search for successively higher  Vdd-levels.  B. Symmetric Aging-enabled Routing Path Allocation (SAR)  In this step, we map the communication-flows of the current  application on to the designated cuboidal region on the 3D NoC-based  CMP. We propose a symmetric aging-enabled and congestion-aware  routing scheme (SAR) to produce a balanced core-router aging profile  and extend the lifetime of the 3D NoC. The main objective of SAR is  to minimize the number of runtime scenarios where applicationmapping on a given cuboidal region is precluded due to aging in  routers. Note that an application can be mapped only if all tiles (each  tile has a compute-core and a NoC-router) within the region under  consideration satisfy the minimum application-frequency constraint.  Prior work on aging- enabled routing (such as [5]) considers the aging  in NoC-routers but does not consider the aging in compute-cores.  Such an approach could lead to a somewhat imbalanced aging within  tiles of the CMP, thus potentially preventing application mapping  onto desirable CMP regions due to excessive aging in NoC routers.  SAR on the other hand enables symmetric aging on individual tiles of  the 3D-CMP to extend the service life of NoC routers. Additionally,  SAR efficiently trades-off aging with network-congestion in the NoC  by choosing routing paths to maximize NoC-lifetime while leveraging  the knowledge of maximum execution  time constraints of  applications, i.e., the aging metric in the routing cost function is  prioritized by varying degrees, given the time-slack available for  application-completion.   III. EXPERIMENTAL RESULTS  Our experiments compare our ARTEMIS framework with two other  runtime mapping approaches derived from prior work: (i) traditional  worst-case guard-banding approach (WC-GB): region selection is  done based on the runtime area constrained mapping approach [6] that  attempts to fit the maximum number of applications on the chip. This  approach neither assumes DVS nor assumes runtime inputs from  aging-sensors to make mapping decisions and thus is not aging-aware;  (ii) wear-leveling approach with DVS (WL+DVS): region-selection  for application-mapping is always done based on the lowest average  VT-degradation in cores, as proposed in [3] and [4]; in addition, Vdd is  opportunistically reduced when possible and adaptively hiked with  aging to meet application performance constraints.  Figure 2(a) shows the total number of applications serviced over  the chip lifetime, across the three different types of application-inputsequences. The error-bars in all our plotted results represent the range  of results across simulations with five different randomly generated  application-sequences (with individual applications derived from the  SPLASH-2 and PARSEC benchmarks). As expected, the WL+DVS  framework outperforms the WC-GB approach that does not perform  DVS. By intelligently selecting application-regions on the 3D-die  with its region-selection heuristic, our ARTEMIS framework achieves  a further reduction in leakage-power dissipation and stress on the  more highly degraded PDN-paths. The ARTEMIS framework produce  9%–40% (25% average) improvement in the total number of  applications serviced over the next best framework, WL+DVS.   We also analyze the distribution of percentage worst-case IR-drops  (%WC-IR-drops) at the end of lifetime with different frameworks.  Figure 2(b) shows the maximum %WC-IR-drops obtained for  different frameworks at the end of chip lifetime. The aging-unaware  WC-GB framework maps applications such that some cores are more  heavily loaded than others, thus resulting in the shortest lifetimes with  high maximum WC-IR-drops. With our strategy to prioritize mapping  on cores with less WC-IR-drops, ARTEMIS framework produces  lower maximum %WC-IR-drop-values (by up  to 9%  lower),  compared to WL+DVS, despite ARTEMIS having a longer lifetime  and servicing a higher number of applications. Figure 2(c) shows the  variance in the WC-IR-drop-distribution on the 3D chip obtained at  the end of lifetime with different frameworks. A smaller variance of  IR-drops with ARTEMIS framework (up to 24% lower compared to  WL+DVS) signifies efficient management of PDN-aging that aides in  improving the longevity of the PDN.   Figure 2(d), shows the mean effective VT-degradation in computecores at the end of lifetime. As discussed earlier, the VT-values of  circuit components increase with aging. Given the nominal-VT of  0.3V at the start of lifetime,  observe in figure 2(d) that the mean VTdegradation values at the end of lifetime for ARTEMIS framework are  significantly higher (by up to 30% for compute-intensive workloads)  compared to the WL+DVS framework. By restricting the EM-induced  PDN-degradation, ARTEMIS can extend the tolerable degree of  circuit-aging (VT-degradation) in compute-cores, while meeting the  same performance constraints. Thus the 3D CMP remains functional  for much higher VT-degradation with ARTEMIS compared to other  approaches, highlighting a key feature of our framework.  Figure 2. Results obtained at the end of lifetime with all frameworks  IV. CONCLUSION  We proposed an aging-aware application-mapping and DVS  scheduling framework (ARTEMIS) that considers PDN-aging of 3D  NoC-based CMPs in addition to circuit-aging in both the performance  and aging evaluation stages, and  the  lifetime optimization  methodology. Compared to a framework based on the best known  prior works on aging-aware mapping techniques, ARTEMIS is able to  service 25% more applications (on average) over the chip lifetime.  ACKNOWLEDGEMENTS  This research is supported by grants from SRC, NSF (CCF1252500, CCF-1302693), and AFOSR (FA9550-13-1-0110).  "
Highly Fault-tolerant NoC Routing with Application-aware Congestion Management.,"Silicon devices are becoming less and less reliable as technology moves to smaller feature sizes. As a result, digital systems are increasingly likely to experience permanent failures during their life-time. To overcome this problem, networks-on-chip (NoCs) should be designed to, not only fulfill performance requirements, but also be robust to many fault occurrences. This paper proposes a fault- and application-aware routing framework called FATE: it leverages the diversity of communication patterns in applications for highly faulty NoCs to reduce congestion during execution. To this end, FATE estimates routing demands in applications to balance traffic load among the available resources. We propose a set of novel route-enabling rules that greatly reduce the search for deadlock-free, maximally-connected routes for any faulty 2D mesh topology, by preventing early on the exploration of routing configuration options that lead eventually to unviable solutions. Our experimental results show a 33% improvement on average saturation throughput for synthetic traffic patterns, and a 59% improvement on average packet latency for SPLASH-2 benchmarks, over state-of-the-art fault-tolerant solutions. The FATE approach is also beneficial in the complete absence of faults: indeed, it outperforms prior fully-adaptive routing techniques by improving the saturation throughput by up to 33%.","Highly Fault-tolerant NoC Routing with Application-aware Congestion Management Doowon Lee, Ritesh Parikh and Valeria Ber tacco Depar tment of Computer Science and Engineering, University of Michigan {doowon, parikh, valeria}@umich.edu ABSTRACT Silicon devices are becoming less and less reliable as technology moves to smaller feature sizes. As a result, digital systems are increasingly likely to experience permanent failures during their lifetime. To overcome this problem, networks-on-chip (NoCs) should be designed to, not only fulﬁll performance requirements, but also be robust to many fault occurrences. This paper proposes a fault- and application-aware routing framework called FATE: it leverages the diversity of communication patterns in applications for highly faulty NoCs to reduce congestion during execution. To this end, FATE estimates routing demands in applications to balance trafﬁc load among the available resources. We propose a set of novel route-enabling rules that greatly reduce the search for deadlock-free, maximallyconnected routes for any faulty 2D mesh topology, by preventing early on the exploration of routing conﬁguration options that lead eventually to unviable solutions. Our experimental results show a 33% improvement on average saturation throughput for synthetic trafﬁc patterns, and a 59% improvement on average packet latency for SPLASH-2 benchmarks, over state-of-the-art fault-tolerant solutions. The FATE approach is also beneﬁcial in the complete absence of faults: indeed, it outperforms prior fully-adaptive routing techniques by improving the saturation throughput by up to 33%. Categories and Subject Descriptors C.1.2 [Processor Architectures]: Multiprocessors—Interconnection architectures; B.8.1 [Performance and Reliability]: Reliability, Testing, and Fault-Tolerance General Terms Reliability, Performance, Algorithms, Design Keywords Network-on-Chip, Fault-Tolerance, Adaptive Routing 1. INTRODUCTION Advances in semiconductor fabrication technology have enabled the design of modern chip multiprocessors (CMPs) and systems-onchip (SoCs) consisting of billions of transistors. They deploy tens, or even hundreds, of communicating components and, therefore, efﬁcient on-chip communication is increasingly becoming a critical design bottleneck. Networks-on-chip (NoCs) are a promising interconnect solution because they provide massively concurrent, scalable Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS’15, September 28 - 30, 2015, Vancouver, BC, Canada c(cid:13) 2015 ACM. ISBN 978-1-4503-3396-2/15/09 ...$15.00 DOI: http://dx.doi.org/10.1145/2786572.2786590 (a) Trafﬁc pattern for lu_con (b) Routing function 1 (c) Routing function 2 Figure 1: Trafﬁc-aware routing restrictions. (a) The normalized trafﬁc pattern for a portion of lu_con [25] shows that the largest fraction of trafﬁc is between nodes 0-4 and 8. (b) When selecting the routing function 1, which forbids the north-east turns at node 3, 4, 6 and 7, there are only two allowed turns to cross the mid-diagonal line. (c) In contrast, the placement of routing restrictions as in the routing function 2 allows four distinct turns across the mid-diagonal. and power-efﬁcient communication. However, the increasing susceptibility to faults of nano-scale semiconductor devices [13] makes it extremely challenging to maintain the correctness and low-latency characteristics that are desired for NoCs. To make matters worse, NoCs constitute a single-point-of-failure for the entire system. Fault-tolerant NoC routing solutions [1,14,20,21] tackle this challenge by leveraging their inherent routing ﬂexibility. In other words, the routing solutions react to faults by limiting communication to ﬂow only along fault-free paths. In this context, topology-agnostic routing algorithms [10,22,23] offer highly ﬂexible routing, preserving network connectivity even in the presence of many faults. Nonetheless, they often lead to severe performance degradation after only a few faults, making the continued deployment of the chip impractical. For example, in [20], the throughput of an 8×8 mesh network drops by over 20% after only 10 faults. This steep loss is mainly due to increased trafﬁc congestion on the remaining healthy paths. Thus, runtime-management of trafﬁc ﬂow has a critical impact on the performance of faulty networks. Adaptive routing techniques to manage trafﬁc congestion have been extensively investigated [2,12,17,19]. They mitigate interference among packets by routing some of them through underutilized network links. Prior adaptive routing solutions can be partitioned in two main groups: one group includes those optimized for regular topologies (e.g., mesh) [12,17], while the other targets very general, topology-agnostic solutions [7,8,19]. Unfortunately, the former is inadequate to tackle faulty regular networks (which reduce to irregular topologies), while the latter entails almost always extremely complex and resource-demanding computations. CMP applications [5,25] exhibit communication patterns [4] where most packets ﬂow among only a subset of the NoC nodes. This aspect could be leveraged to focus the limited routing options available towards a handful of high-trafﬁc communication paths. This is the key observation that led to our solution: if the high-trafﬁc communication patterns in a faulty NoC are known (or can be estimated), then we can select the routing function so as to provide both deadlock freedom and maximum path diversity (and thus low congestion) among the high-trafﬁc nodes. In other words, the routing function eliminates only underutilized routes. Consequently, we can provide high-bandwidth, low-latency communication even in faulty networks. Consider, as an example, the trafﬁc pattern shown for a portion of the lu_con benchmark from SPLASH-2 [25] in Figure 1a, where the majority of the packets are transferred between nodes 0-4 and node 8. Using the route restrictions shown in Figure 1b to break deadlock cycles, there are only two turns that allow transferring trafﬁc from the upper-left region of the network to its lower-right region. In contrast, the route restrictions shown in Figure 1c allow four distinct turns. As a result, the routing solution of Figure 1c is less likely to cause congestion. Application-aware solutions of this type have been investigated in [7,8,16,19,24], but they often entail high routing computation overheads. Contributions. Our proposed solution is called FATE, Fault- and Application-aware Turn model Extension. It manages congestion in faulty networks by selecting routing restrictions appropriately. Speciﬁcally, restriction placements are optimized to the application’s network trafﬁc. We attain this goal by introducing a set of turnenabling rules that allow to quickly prune the search of deadlockfree routes in faulty network topologies. We leverage these rules to provide adaptive, application-aware routes for packets ﬂowing in the network, maximizing the number of distinct available routing paths. The rules can be applied to any irregular topology derived from a 2D mesh network by injecting faults. Unlike previous topology-agnostic routing solutions, FATE takes into consideration bandwidth demands, in addition to fault locations, when placing the turn restrictions. Moreover, it also keeps its computation lightweight, when compared to existing application-aware solutions. In summary, we make the following contributions: • We present a novel, fault- and application-aware routing restriction placement solution, called FATE. FATE improves the performance of faulty 2D mesh networks by leveraging the application’s communication patterns. • We demonstrate a method to quickly prune the exploration of viable routes in faulty networks, in order to consider only deadlock-free options, and we reduce the number of routes evaluated by two orders of magnitude over prior application-aware solutions. 2. RELATED WORK Fault-tolerant routing. Fault-tolerant, deadlock-free routing solutions have been extensively investigated in the past. Glass and Ni propose three turn-models that provide adaptive, fault-tolerant routing [11]. Note, however, that their fault-tolerance is limited to only a few faults [21]. In contrast, Ariadne [1], uDIREC [20], CBCG [21] and Hermes [14] put no constraints on the number and location of faults, and hence, they are more reliable. While these latter works provide deadlock-free, maximally-connected routes, none of them take trafﬁc ﬂow into consideration to optimize for throughput. Similar to the above on-chip solutions, in the off-chip network domain, topology-agnostic routing algorithms [10,22,23] focus mostly on placing routing restrictions using topological characteristics, while ignoring trafﬁc ﬂow during the placement. On the other hand, we exploit communication patterns to ﬁnd better routing restrictions. Application-aware routing. Application-aware routing solutions tune the routing function to trafﬁc ﬂow. APSRA [19] strives to meet the bandwidth requirement of an application, while achieving deadlock freedom by breaking cyclic dependencies. However, deploying this solution to identify optimal routes in faulty networks has an extremely high computational cost. Addressing APSRA’s limitation, ACES [8] investigates a quick application-aware routing heuristic in irregular topologies by partitioning VCs to break cycles. LBDRx [7] Figure 2: Overview of FATE. FATE is triggered by either a new application launch or a new fault occurrence. It leverages a trafﬁc load estimator to compute a deadlock-free routing function that minimizes congestion. The new routing function is then stored at the routers. develops a resource-mapping tool and a routing algorithm for SoC applications, while reducing routing overheads by leveraging logicbased routing instead of routing tables. Note that all of the above solutions use adaptive routing to mitigate congestion. In contrast, BSOR [16] selects load-balanced, oblivious paths via either mixed integer linear programming (MILP) or Dijkstra’s shortest path algorithm to approximate optimally balanced paths. Similarly, ETM [24] reduces the computation requirements of the MILP problem with the aid of a genetic algorithm. These latter two oblivious routing solutions, however, suffer from low performance as they do not manage runtime congestions well. Although all of these application-aware solutions can be deployed in faulty networks, they often require either intractable computation or extra hardware. Application-aware routing techniques can manage congestion more efﬁciently when employing runtime congestion monitoring. Various monitoring schemes have been explored in 2D mesh NoCs. For example, DyXY [17] observes buffer occupancy in adjacent routers, and then favors forwarding packets to routers with more vacancies. NoP [2] and RCA [12] extend this idea by monitoring congestions in routers farther away. All such solutions are fullyadaptive, and thus, require dedicated VCs to guarantee deadlock freedom, a costly endevour in area- and power- constrained NoCs. 3. OVERVIEW AND BACKGROUND FATE is a software-based solution that generates a deadlock-free routing function, while maximizing the number of distinct paths available between nodes with high communication requirements, for applications running on faulty 2D mesh networks. Figure 2 shows how FATE operates: it is triggered by a new fault occurrence or an application launch. It then uses the CMP’s idle cores to compute a new routing function. If no idle core is available, the start of the application may be delayed to compute the routing function, or a prior, possibly non-optimal, function may be used, until a core becomes available. While ﬁnding optimal, deadlock-free routes is an intractable problem [8,16,24], FATE’s efﬁcient heuristic quickly discovers a near-optimal routing function: it ﬁrst computes the minimal number of turn restrictions that must be placed in the network. This value can be easily derived from the total number of cycles in the topology. The construction is then based on an iterative exploration, where turn restrictions are placed one at a time. After placing each turn restriction, FATE deploys its turn-enabling rules (Section 4) to enable turns that must be active in order to maintain connectivity in light of the most recent turn-restriction choice. Moreover, in choosing the location of each new turn restriction, FATE leverages trafﬁc load estimates that it derives from the communication patterns extracted via application analysis (Section 5). If a deadlocked or disconnected routing conﬁguration is encountered during the exploration, FATE uses backtracking to broaden the search until it ﬁnds a satisﬁable solution. Finally, the network’s routers are re-programmed using the new routing function. FATE assumes that information about the application’s communication patterns is available: indeed, these can be observed in CMP and SoC applications using runtime proﬁling, and then modeled through Markov chains [3,4]. As in many fault-tolerant routing solutions, we also assume that the NoC is equipped with a fault diagnosis solution (e.g., switch-to-switch detection [18]). In addition, we assume that our solution is deployed in systems where the OS is notiﬁed of new fault detections and can launch FATE’s routing computation software, updating routing tables accordingly. This assumption may not hold in some systems. For those systems, FATE can be adopted by deploying a dedicated network manager. In this setup, FATE calculates in advance optimized routing functions for representative communication patterns, and stores them in memory. At runtime, the network manager evaluates current trafﬁc patterns, and chooses the best routing function by comparing against the patterns of the stored ones. 3.1 Avoiding Deadlock by Removing Cyclic Resource Dependencies Deadlock situations can happen when packets wait for each other in a cyclic manner. Such situations can be avoided by breaking cyclic resource dependencies [9], disabling at least one of the turns that contribute to the cycle [11]. For instance, Figure 1b forbids the turn 0-3-4 so that packets’ routes do not include the sequence 0→3→4 or 4→3→0. This turn restriction breaks the cycle along nodes 0, 1, 4 and 3. Note that FATE uses bidirectional turn restrictions. This deadlock-avoidance technique has been proposed in the past: for instance, the turn models [11] forbid certain turns in 2D meshes to break every possible cycle. For instance, the west-ﬁrst turn model disallows all turns towards the west direction, so that packets can only go west at the beginning of their routing path. However, this baseline turn model often fails to provide either deadlock freedom or maximal connectivity in the presence of many faults [1,21]. A class of topology-agnostic routing algorithms, however, can ensure both deadlock freedom and connectivity in any topology, providing strong fault-tolerance capabilities [1,10,21,22,23]. For instance, the up*/down* routing algorithm [1,22,23] builds a spanning tree of links. Links towards the root node are marked as up links, while links towards the leaves are marked as down links [20]. The routing algorithm then disallows down-up turns: once a packet takes a down link, it is not allowed to turn onto an up link. While this restriction rule can be applied to any up*/down* tree in general, the routing algorithm usually spans the tree in a ﬁxed manner (e.g., breadth-ﬁrst [1,23] or depth-ﬁrst [22]). Consequently, these topology-agnostic approaches often provide limited options in the placement of turn restrictions. Application-speciﬁc routing solutions aim at offering full ﬂexibility in the turn-restriction placement [7,8,19]. They analyze an application’s communication paths, and selectively remove some of those paths until no cyclic resource dependency exists. As discussed in [8], however, this type of approaches (e.g., [19]) scales poorly with network size. [8] tries to overcome this scalability issue in two steps. It ﬁrst minimizes the number of cyclic dependencies, and then uses VCs to break the remaining cycles. However, using VCs to avoid deadlock is a costly option in resource-constrained NoCs. In contrast, our approach does not require VCs for deadlock freedom, and VC resources can be entirely dedicated to prioritize trafﬁc or reduce congestion. 4. FATE’S TURN-ENABLING RULES This section discusses the rules that determine which turns must (a) Basic rules (b) Advanced rules Figure 3: FATE’s turn-enabling rules. Whenever FATE selects a new turn restriction, it can infer a number of other turns that should be enabled at other locations to obtain an optimal routing function (minimal number of disabled turns) faster. Basic rules (a) enable turns in adjacent locations, while advanced rules (b) impact remote turn locations. In the diagram for Rules 2 and 5, we show a deadlock cycle that we would obtain if we did not enable the turns indicated. be enabled as a consequence of another turn being disabled. These rules, grouped into basic and advanced, can be applied in any order, and are illustrated in Figure 3. We ﬁrst describe how the rules operate in regular meshes, and then extend them to faulty topologies. Note that our approach minimizes the number of turn restrictions, and thus maximize cumulative bandwidth to all destinations, but it does not necessarily enable minimal-length routes. 1) Basic rules identify which turns must be enabled because of a turn restriction on the surrounding cycle, node and links, and they are illustrated in Figure 3a. Rule 1 (cycle) — Once a turn in a cycle is disabled, all other turns in the same cycle should be enabled, so that all nodes in the cycle can still communicate. Rule 2 (node) — Once a turn in a node (router) is disabled, all other turns insisting on the same node should be enabled. Rule 3 (link) — Once a turn adjacent to a link is disabled, the turn to the same link, on the opposite side with respect to this turn and not insisting on the same router should be enabled. In a fault-free mesh network, there is only one turn that should be enabled for each link affected by a disabled turn as a result of Rule 3. Note that Rules 2 and 3 are not necessary to guarantee the connectivity of the network, but any violation of these rules would lead to a superﬂuous number of turn disabling. For instance, if both the turns 1-4-3 and 1-4-5 were disabled in the middle network of Figure 3a, then the network would still allow a dependency along the path 0→1→2→5→4→3→0 as shown in the ﬁgure (gray arrows), and we would need to include an additional turn restriction to break it. Similarly, with reference to the right network in Figure 3a, if turn 4-1-2 were disabled, a cyclic dependency would exist along the path 0→1→2→5→4→3→0. 2) Advanced rules force FATE to enable turns that are remote with respect to the restricted turn. They allow to aggressively prune the search space towards a solution with a minimal number of disabled turns. Figure 3b illustrates the two rules below; we marked in red the restricted turn, in teal the turns enabled by the basic rules, and in purple the turns enabled by the advanced rule being illustrated. (a) Cycle recomputation (b) Mutual turn (c) Finding deadlocks Figure 4: Extending turn-enabling rules to faulty topologies. The rules in Figure 3 can be applied in the presence of faults with a few modiﬁcations. For instance, (a) cycles must be recomputed in faulty regions, and (b) a turn shared by convex- and concave-shaped cycles should be used to break only one of the cycles. (c) A deadlock may occur when there is a path between two nodes belonging to different cycles and both nodes are the one with the disabled turn for its cycle. Rule 4 (common link) — If a cycle has only two undecided turns that share a common link, then all turns that are adjacent to that link and lie outside the cycle, should be enabled. This rule can be inferred from Rules 1 and 3. For a cycle with two undecided turns, by Rule 1, one of the two should be disabled. If these two turns are adjacent (i.e., sharing a link), disabling either of the two turns will always involve the shared link. We apply Rule 3 to this link so that we do not allow another cycle to also place its turn restriction on this link. An example is shown on the left side of Figure 3b, where the cycle 1-2-6-5 has two undecided turns after placing the turn restriction at 1-5-4: the turns 1-2-6 and 2-6-5, sharing the link 2-6. This shared link is also adjacent to two other turns: 3-2-6 and 2-6-7 (both belong to the cycle 2-3-7-6), which should be enabled by Rule 4. Note that Rule 4 can be applied to enable turns both on the horizontal and vertical directions. Also, it can be applied iteratively, to further reduce the disabled-turn-placement search space. Rule 5 (opposite-corner turn) — If two turns are located on opposite nodes in a cycle, and the two turns are not adjacent to any of the cycle’s links, then only one of them can be disabled. We say that such two turns are in opposite-corner locations. The reasoning behind this rule can be understood by considering the example on the right part of Figure 3b: if we had disabled both the opposite-corner turns 1-5-4 and 11-10-14, then we could no longer avoid a deadlock. Indeed, by Rule 2, only two turns would remain undecided in the central cycle (5-6-10-9): 5-6-10 and 5-9-10, and by Rule 1, we would have to disable one of them. However, disabling either of these turns creates a cyclic dependency that could lead to deadlock. As an example, the ﬁgure shows the cyclic dependency we obtain if we disable turn 5-910, as well as the two opposite-corner turns. Note that it is possible to apply Rule 5 repeatedly by considering increasingly larger cycles. For instance, the rule could be applied to the cycle 5-7-15-13, and force the south-east turn on node 15 to be enabled (assuming that we had a larger network where that turn existed). 4.1 Turn-enabling Rules in Faulty Topologies Among the basic rules, Rule 1 is the one that is affected the most by faults: cycles may become merged because of faults, as shown in the example of Figure 4a (link 1-4 is faulty). In the ﬁgure, the two cycles 0-1-4-3 and 1-2-5-4 no longer exist, and they are merged in the cycle 0-1-2-5-4-3. Moreover, faulty networks may have both concave and convex cycles (unlike fault-free mesh networks, which have only convex cycles) and Rule 1 must be appropriately applied in the case of concave cycles. When a turn is common to two cycles (e.g., turn 3-4-1 in Figure 4b), then disabling that turn can only be counted towards breaking one of the two cycles, not both. Rules 2 and 3 remain unchanged for faulty topologies. Consider link 3-4-5 in Figure 4a as an example: if we were to disable the turn 2-5-4, Rule 3 would require the turn 5-4-7 to be enabled. In addition, we limit the application of Rule 4 to links contributing (a) Path diversity (b) Link load (c) Turn load Figure 5: Link-load and turn-load estimation example. We compute trafﬁc load of links and turns using path diversity. (a) The path diversity is calculated at each link considering fault locations and turn restrictions. (b) The link load is computed by dividing its path diversity by the per-hop path diversity. (c) The turn load is derived from the load of its input link and the number of permissible outputs. to cycles that have not been affected by faults. For instance, with reference to the left network in Figure 3b, if the link 5-6 were to be faulty, we would not apply Rule 4 to link 2-6, because it contributes to a cycle that has been opened by a fault; but we would still apply the rule to link 8-9. The reason we limit the application of Rule 4 is that it could become complex to identify which turns should be enabled when a link spans multiple routers. Finally, we simply apply Rule 5 as we described for regular meshes. Applying this rule in faulty networks allows us to aggressively prune the search for an optimal disabled-turn placement. However, some turns enabled are not necessarily causing deadlock in faulty networks, and thus they should not be enabled. If the enabled turns should have been disabled, our backtracking step (Section 5.3) would correct the situation. To avoid the backtracking, it is also possible to pre-emptively check whether a turn enabled via Rule 5 could lead to a deadlock conﬁguration. Figure 4c shows how to check deadlock for this purpose: when there are two distinct cycles connected through a path starting at node 1 and ending at node 2, we cannot disable both the turns indicated in the ﬁgure, because this placement would enable the deadlock cycle shown in gray. 5. FATE ROUTING In this section, we propose FATE’s heuristic algorithm to identify a routing function with deadlock-free routing and minimal routing restrictions. FATE relies on the information it receives about the application’s communication patterns to strive to place turn restrictions on low-trafﬁc links. When the FATE algorithm begins, all turns are undecided. Turn restrictions are then placed one at a time, starting from the regions transferring the most trafﬁc. Upon placing each restriction, the turn-enabling rules are applied to enable the related set of turns. This process is repeated until each turn is either enabled or disabled. To identify which turn to disable next, we ﬁrst estimate the trafﬁc load on each link, turn and cycle. We then disable the turn that minimally worsens the heaviest load-transferring link, choosing among turns on the heaviest load-transferring cycle. The intuition behind this choice is that we want to resolve the routing function ﬁrst around the regions (i.e., cycles) transferring the most trafﬁc, so that we have plenty of ﬂexibility in our choices. Within each region, we want to disable the turn that minimally affects the congestion in the hotspot. 5.1 Link, Turn and Cycle Load Estimates To estimate the load on each network’s link, turn and cycle, we consider one source-destination pair provided by the application at a time. For each pair, we compute all the possible paths that packets can take from source to destination, and we then derive the fraction Figure 7: FATE’s routing algorithm example. We show the ﬁrst two iterations for a network with two failed links and an application with two communicating pairs. (a) Computation of turn loads. (b) Communication weights and cycle loads indicate that 10-9-13 is the most promising turn-disabling location. (c) Eight turns are then enabled by our turn-enabling rules. (d) Loads computation for the second iteration. of trafﬁc that would go through each link. The computation of all the loads proceeds with the four steps below (see Figure 5). Step 1 — Compute path diversity. We calculate the number of different routes (i.e., path diversity) to reach each link from the source node. For instance, in Figure 5a, the east link of node 9 can be used by two different routes from the node 12: 12→8→9 and 12→13→9, while only one route can use the north link of node 9: 12→13→9. In this process, we only allow minimal-length routes within the limits of the turn restrictions that are already in place. Step 2 — Compute link-load estimates. We now use the results of Step 1 to estimate the load on each link based on the path diversity available. We calculate the total path diversity at each hop from the source (as illustrated in Figure 5a), and divide the link’s path diversity by the total diversity. Figure 5b shows the computation for all the links associated with node 9. Step 3 — Compute turn-load estimates. To estimate the load at each turn, we divide the input load from the source direction of the turn by the number of output links allowed for that source. Figure 5c shows the computation for all the turns at node 9. Step 4 — Compute cycle-load estimates. For each cycle, the load is computed by simply summing the loads on all the turns in the cycle. 5.2 FATE Route-calculation Algorithm Once all load estimates have been computed, we can apply the FATE routing algorithm, as illustrated in Figure 6. Note that we weigh the load estimates by multiplying each estimate by the trafﬁc weight associated to its source-destination pair. The algorithm starts by selecting a turn to disable, choosing the turn with the lightest impact on the heaviest link load, among those in the highest-load cycle (lines 2-4). Once the turn to be disabled is selected, we apply the turn-enabling rules to enable as many other turns as possible (line 5). If the set of turns enabled/disabled leads to a deadlock or a disconnected network (line 6), we backtrack, and update the list of conﬂicting selections (line 8). Our backtracking algorithm is discussed in more detail in the next subsection. In designing our routing algorithm, we evaluated a few other strategies to select the next turn to be disabled: beside the one just 1: repeat until there is no undecided turn compute_link,turn,cycle_loads() cycle = cycle_with_heaviest_load() disabled_turn = turn_with_smallest_link_load_increase(cycle) enabled_turns = apply_turn_enabling_rules(disabled_turn) if( not (check_deadlock() or check_disconnected()) ) 2: 3: 4: 5: 6: 7: 8: disable(disabled_turn), enable(enabled_turns) else update_conﬂict_history(), backtrack() Figure 6: FATE routing algorithm described, we also tried (1) the turn with the absolute lowest load in the network, (2) the turn with the lowest load among those in the highest-load cycle, and (3) the turn connected with the highest-load link in the highest-load cycle. Experimentally, we found that those strategies performed slightly worse than the one we described. Figure 7 illustrates the algorithm with an example. The application provided two communication pairs: 0→15 (shown in orange), with a weight of 8, and 12→3 (shown in blue), with a weight of 20. We ﬁrst compute link and turn loads, as shown in Figure 7a. Then we apply the weights and compute cycle loads in Figure 7b. Cycle 9-10-14-13 is the one with the highest load. By analyzing each turn, one at a time, we ﬁnd that the one that entails the smallest link-load increase is 10-9-13, so we disable it. Figure 7c shows the network after the application of the FATE’s turn-enabling rules. At this point, 21 turns are left undecided, thus we start a second iteration by updating the link, turn and cycle load estimates as shown in Figure 7d. 5.3 Avoiding Illegal Routing Function (Backtracking) As mentioned earlier, the FATE routing algorithm may require backtracking if the set of turn restrictions in place allows for deadlock (usually along a complex cycle) or disconnects the network. These issues may arise because the FATE’s rules do not take into account all the implications of a turn restriction, but only the simpler ones, so that their application is computationally cheap. When these situations occurs, we record the location of all restrictions and we add the current set of turn-disabling placements to a conﬂict history, which we use to avoid repeating the same conﬁgurations. While the majority of topologies and communication patterns in our experiments have successfully completed with only a small amount of backtracking, we found a few cases (less than 1%) that result in more than 1,000 iterations to ﬁnish. We believe these situations occurred because of our simplistic backtracking model that rolls back to the most recent decision, instead of a more intricate model that selects a promising roll-back point. This limitation is partially contained by a random restart technique that we implemented, similar to that in some SAT solvers. Upon a restart trigger, previous decisions are forgotten, and a new initial turn location is selected. We set the restart threshold to 1,000 backtracking events in our experiments. 6. EXPERIMENTAL EVALUATION We evaluated FATE with a cycle-accurate NoC simulator [15] modeling an 8×8 2D mesh NoC. The network’s 3-stage routers are capable of look-ahead routing and speculative switch allocation (i.e., switch allocation is concurrent with VC allocation). Each input port within a router contains 2 VCs per protocol class, and 5 ﬂits per VC, unless otherwise noted. We utilized 3 protocol classes to support the MESI cache coherence protocol when running SPLASH-2 benchmarks, and a single protocol class when evaluating synthetic trafﬁc patterns. We apply the FATE algorithm to place turn restrictions, then deploy a minimal adaptive routing approach where packets choose at each router which direction to take among those enabled. In addition, we deploy a local congestion monitoring scheme based on the credit count, so that output channels towards non-congested input buffers are favored. We analyzed FATE’s performance both on fault-free and faulty 2D mesh networks, injecting a varying number of link faults in the latter scenario. Speciﬁcally, we experimented with conﬁgurations containing 1 (1%), 3 (3%), 6 (5%), 11 (10%) and 17 (15%) faulty links, and averaged the results over 10 different random sets of fault placements for each data point. Note that we do not consider conﬁgurations that lead to disconnected nodes, as this situation would require thread migration support when running parallel benchmarks. This requirement, in turn, would make it difﬁcult to reason about performance scaling due to a different number of active cores in different conﬁgurations. Even though we model only link failures, FATE is equally effective in tackling routers’ logic failures by mapping such failures to one or more links connected to the failed routers [20]. Please note that we evaluated our solution under various corner-case topologies to take into account unpredictability of fault locations. These random topologies include, for instance, nodes with only a single surviving link, cycles consisting of more than 10 nodes, etc. We evaluated our testbed with both synthetic trafﬁc [15] and traces from the SPLASH-2 benchmark suite [25]. We used 5 different synthetic patterns: bit complement (bitcomp), bit reversal (bitrev), shufﬂe (shufﬂe), transpose (transpose) and uniform random (uniform). Our synthetic trafﬁc consists of a mix of equal amounts of 1- and 5-ﬂit packets. The 11 SPLASH-2 traces we experimented with, on the other hand, were obtained from full-system simulation using gem5 [6] in the syscall emulation mode. Our gem5 model was conﬁgured as shown in Table 1. The traces were collected for 10 million cycles after spawning threads and initializing caches. The trafﬁc weights were calculated by counting the number of ﬂits per each source-destination pair. The latency values were capped at 1,000 cycles during the trace-based simulation to avoid extremely large latencies due to network saturation. We did not evaluate FATE with the PARSEC benchmark suite, because PARSEC is known to underutilize the network, and its trafﬁc is more evenly-distributed than SPLASH-2. We expect PARSEC to yield results similar to those of uniform. Table 1: gem5 conﬁguration for SPLASH-2 traces core 64 cores, x86 ISA, 2GHz, out-of-order, 8-wide issue cache coherence MESI, CMP directory, 64-byte block network 8×8 mesh, 3 classes/port, 2 VCs/class, 5 ﬂits/VC L1 cache private, 16KB inst. + 16KB data, 4-way set, 3-cycle lat. L2 cache shared, distributed, 256KB/node, 16-way set, 15-cycle lat. memory 1GB/controller; 1 controller at each mesh corner 6.1 Performance on Faulty Networks We compared our solution against fault-tolerant, application-oblivious routing solutions that are based on the construction of spanning trees: up*/down* with breadth-ﬁrst search (BFS) [1,23], and up*/down* with depth-ﬁrst search (DFS) [22]. For BFS, we experimented with 4 different conﬁgurations: each conﬁguration placed the root node at a different corner of the mesh. Then we calculated the geometric mean of the results obtained over all four conﬁgurations. For DFS, we implemented the two heuristics from [22]: Ht1 for selecting the root node, and Fv for choosing a tree-spanning direction. We also compared our solution against two existing applicationaware routing solutions: Application-Speciﬁc Routing Algorithm (APSRA) [19] and Bandwidth-Sensitive Oblivious Routing (BSOR) Figure 8: Saturation throughput for synthetic trafﬁc patterns over various fault rates and trafﬁc patterns. FATE provides 10%-33% better saturation throughput over BFS, and up to 9% better throughput over APSRA. [16]. Both algorithms are modiﬁed for distributed routing. For APSRA, we applied APSRA’s turn cost calculation instead of our load estimation method in Section 5.1. For BSOR, we ﬁrst placed turn restrictions according to the negative-ﬁrst turn model, then applied the Dijkstra’s shortest path algorithm. We tried four different turn restrictions, each with four rotations. The algorithm is then applied iteratively by reducing the link capacity to aggressively optimize for congested links, as shown in [16]. Figure 8 reports the average saturation throughput (i.e., when latency reaches 3 times the zero-load latency) across various fault rates and trafﬁc patterns. In the left half of the ﬁgure, we observe that the performance of our scheme degrades more gracefully than both application-oblivious spanning-tree solutions (BFS and DFS) as faults increase. FATE achieves a 10% improvement over BFS when there is only one faulty link. Although the network at this low fault rate maintains an almost-regular topology, FATE still offers a better throughput than BFS by leveraging distinct trafﬁc patterns. FATE’s improvement over BFS increases to 33% when 15% of the links are faulty. At this high fault rate, the spanning-tree solutions often fail to ensure minimal routing restrictions, leading to high performance loss. FATE also achieves consistently higher throughput at all fault rates than both APSRA and BSOR. While it shows comparable throughput with APSRA at low fault rates, FATE provides a 9% higher throughput at the 15% faulty-link rate. We believe that this is because APSRA’s trafﬁc estimation becomes inaccurate at high fault rates, as the estimation relies on the path diversity between sources and destinations using source routing. In contrast, FATE estimates trafﬁc load by considering hop-by-hop routing-decision using distributed routing. Finally, BSOR provides lower throughput than both APSRA and FATE, most probably because it lacks a dynamic approach to congestion management. FATE also performs better than BFS across various trafﬁc patterns at the 15% faulty-link rates, as shown in the right half of Figure 8. We observe that trafﬁc patterns where packets utilize a few turns more frequently (e.g., transpose and bitrev) are those that beneﬁt the most from FATE. Our solution provides at least at-par performance in the patterns where turns are used evenly (e.g., uniform). Figure 9 reports the average packet latency from our trace-driven SPLASH-2 simulations across various fault rates and benchmarks. As shown in the left half of the ﬁgure, FATE experiences negligible latency increase up to the 5% faulty-link rate. Beyond that point, the latency increase is more signiﬁcant. However, note that how the latency increase begins at lower fault rates: it is much steeper in BFS and DFS routing. This dramatic increase comes from the earlier saturation effect in resource-constrained faulty networks. Note also that in networks with only one faulty link, FATE performs worse than other solutions. This result is due to the high-impact contribution to the average by ocean_con, which exhibits phases with very high injection rates for short time periods. These phases are not Figure 9: Packet latency for SPLASH-2 traces over various fault rates and benchmarks. Except for the 1-fault case, FATE shows 18%-59% improvements in packet latency over BFS, and up to a 13% improvement over APSRA. representative of the entire benchmark execution, and hence our solution is unable to optimize for them. In addition, FATE attains lower latency than APSRA at all fault rates except one faulty link. The two solutions show comparable latency until the 5% faulty-link rate. At the 15% rate, however, FATE shows 13% lower packet latency than APSRA. FATE also outperforms BSOR at all fault rates. Finally, we show results for ﬁve selected benchmarks at the 15% faulty-link rate on the right side of Figure 9. FATE consistently provides much lower latency than BFS and DFS. For instance, when running fft, each node accesses frequently memory nodes located at the corners of the mesh, and communicates with a few other nodes. As a result, FATE enables more routes among these frequently communicating nodes. On the other hand, both BFS and DFS are application-oblivious, so their disabled-turn placements are not so favorable to those nodes. 6.2 Performance on Fault-free Networks We compared FATE’s fault-free operation and congestion management capabilities against 3 fully-adaptive routing techniques: DyXY [17], NoP [2] and RCA1D [12]. For those solutions, we implemented deadlock detection based on timeout, and reserved one VC for deadlock recovery. We also considered prior fault-tolerant solutions and application-aware solutions for fault-free networks. Figure 10 shows the average saturation throughput of FATE against all the solutions above across 3 different VC settings (3, 4 and 6 VCs), and synthetic trafﬁc patterns. As shown in the left part of the ﬁgure, FATE outperforms DOR: FATE achieves a 4.5% improvement when using 3 VCs, and up to 23% with 6 VCs. FATE’s advantage grows with the number of VCs since it manages resources more efﬁciently than oblivious routing techniques. However, the reverse trend holds when FATE is compared against fully-adaptive solutions, i.e., DyXY, NoP and RCA1D. FATE’s improvement over the fully-adaptive solutions diminishes as the number of VCs increases, because the cost of reserved VCs in the fully-adaptive solutions is amortized when more VCs per class are available. For networks with only 3 VCs, FATE shows a 33% improvement over DyXY and a 21% improvement over RCA1D. This advantage is lost at 4 VCs, while at 6 VCs FATE provides 13% lower throughput than RCA1D. In the area- and power-constrained on-chip environment, NoCs with fewer VCs are more prominent, and hence our solution is widely applicable. We further analyze FATE’s fault-free performance by considering various synthetic trafﬁc patterns. The right part of Figure 10 shows the average saturation throughput for networks with 3 VCs under various trafﬁc patterns. Our solution outperforms the fully-adaptive solutions for most patterns in this setting: the exceptions are bitcomp and uniform, where DOR is the best performer. Considering the beneﬁts of FATE for faulty networks (Section 6.1), we believe that a slight performance loss on fault-free networks for rare adverse trafﬁc Figure 10: Saturation throughput for synthetic trafﬁc patterns over a varying number of VCs and trafﬁc patterns. patterns is acceptable. Note that in our experiments, FATE leverages local congestion information to adaptively choose better routes at runtime. However, it has been shown in prior research [2,12] that global network-level congestion monitoring schemes deliver superior performance. In future work, we plan to evaluate the beneﬁts of applying some of these schemes to FATE. 6.3 Overheads Routing-function computation overhead. We evaluated the overhead of computing the routing function, and compared our ﬁndings against APSRA [19]. Table 2 reports the average computation time to derive a routing function, for both FATE and APSRA. In evaluating computation time, we only included the total time spent in estimating trafﬁc load (Section 5.1 for FATE), since that is by far the major contributor to the algorithm’s computation time, for both ASPRA and FATE. The other activities contributing to the routing function computation (e.g., backtracking, deadlock checking, etc.) are minor contributors and identical for both solutions. Execution times were measured by averaging over 5 executions for each routing function computation on an Intel Xeon E5520. Overall, it can be noted that FATE is a signiﬁcantly faster solution than APSRA. In the right portion of Table 2, we also compare the number of attempts of turn-disabling placement, averaged over 10 different faulty topologies and 16 trafﬁc weights (5 synthetic trafﬁc patterns and 11 SPLASH-2 benchmark traces) at each fault rate, in order to gain insights on the gap between the computation of FATE and APSRA. This value is the cumulative sum of each turn-disabling placement attempt, including all the placements that had to be removed because they led to a conﬂict or deadlock. Note that FATE’s number of attempts is minuscule compared to APSRA: this result comes from our turn-enabling rules, which greatly prune the search space for an optimal set of turn-disabling placements. In many situations, APSRA’s routing algorithm made extremely large turn-disabling placement attempts before reaching a stable solution. We capped those algorithm’s runs at 200,000 placement attempts and we report the fraction of occurrences where we reached the cap value. Note that FATE never had a case that required 200k placement attempts, while APSRA had a noticeable fraction of algorithm’s runs that went over the limit. Table 2: computation overhead for FATE and APSRA average time average number of % runs reaching (sec) placements attempted 200k cap APSRA FATE APSRA FATE APSRA FATE 3.61 71,321 117 19% 0% 3.27 94,639 107 31% 0% 3.29 107,956 107 41% 0% 3.21 120,877 105 48% 0% 3.62 151,802 118 69% 0% 2.93 159,667 96 74% 0% >500 fault-free 1 fault 3% faults 5% faults 10% faults 15% faults Although FATE requires much less computation than existing application-aware routing, it may still not be sufﬁciently fast because of its software-based computation. In those situations where recovery performance is of essence, alternative hardware-only solutions (e.g. retransmission [18] and BFS-based routing [1]) can be deployed concurrently with FATE, while it executes in software. Upon FATE’s completion, its solution can replace the interim recovery solution. Area and power overhead. FATE requires a reconﬁgurable routing infrastructure (e.g., routing tables) to recompute the routing function at runtime. We deploy routing tables as shown in [1,16], one for each router. Each table contains N entries where N is the number of nodes, and each entry contains four directional 2-bit ﬁelds (8 bits per entry). The 2-bit ﬁelds are used to prioritize valid output directions by using the number of hops to the destination. In addition, we utilize four routing-restriction bits (similar to [7]) to avoid making invalid decisions at each router. Thus, to store the computed routing function in memory, we require N×(N×8+4) bits per application of the FATE algorithm. Moreover, we use the number of used credits as our congestion metric: this is often already available in routers and comes at no extra cost. We evaluated the area overhead of routing tables and route-computation logic, targeting the Nangate 45nm library using Synopsys DC. The micro-architecture of a baseline router is conﬁgured as speciﬁed in Table 1 with an operating frequency of 400MHz. With this conﬁguration, our routing computation adds approximately 6% area overhead, mostly for the routing table. Note that the other fault-tolerant, adaptive routing solutions we compared against (BFS, DFS and APSRA) entail similar overhead, as they utilize similar routing intrastructures as FATE. While we have not evaluated FATE’s power overhead, we provide here a qualitative comparison. Our solution entails signiﬁcantly less computation than APSRA while, at the same time, producing routing functions that lead to lower packet latency. Thus we believe FATE would consume less power than APSRA. When comparing to BSOR, BFS and DFS, the two trends are in opposition: we do attain lower packet latency, at the cost of higher computation time for the routing function. Thus we only provide an overall power gain if we can absorb the additional power cost of the computation over the beneﬁts in packet latency. 7. CONCLUSIONS Maintaining high-throughput and low-latency after faults have occurred is critical to the continuous deployment of NoCs on unreliable silicon substrates. We proposed FATE, a high-performing, adaptive routing solution for faulty networks-on-chip, that leverages the knowledge of an application’s communication patterns. We developed turn-enabling rules to quickly determine the optimal set of turns that should be disabled to break all deadlocks, while still providing connectivity in faulty 2D meshes. Our application-aware heuristic balances load evenly among network resources using our novel load-estimation metrics, and chooses the most promising turnrestriction locations. Experimental results show improvements in throughput and latency for synthetic trafﬁc patterns and SPLASH-2 benchmark traces over state-of-the-art fault-tolerant and applicationaware routing solutions. Finally, FATE keeps a low cost proﬁle (6% area overhead), while providing a better routing performance than prior application-aware routing. We also showed that our solution is a viable, low-cost, adaptive-routing alternative even for fault-free networks when compared to fully-adaptive routing solutions. Acknowledgements. This work was supported by STARnet, a Semiconductor Research Corporation program sponsored by MARCO and DARPA. 8. "
Highway in TDM NoCs.,"TDM (Time Division Multiplexing) is a well-known technique to provide QoS guarantees in NoCs. However, unused time slots commonly exist in TDM NoCs. In the paper, we propose a TDM highway technique which can enhance the slot utilization of TDM NoCs. A TDM highway is an express TDM connection composed of special buffer queues, called highway channels (HWCs). It can enhance the throughput and reduce data transfer delay of the connection, while keeping the quality of service (QoS) guarantee on minimum bandwidth and in-order packet delivery. We have developed a dynamic and repetitive highway setup policy which has no dependency on particular TDM NoC techniques and no overhead on traffic flows. As a result, highways can be efficiently established and utilized in various TDM NoCs.
According to our experiments, compared to a traditional TDM NoC, adding one HWC with two buffers to every input port of routers in an 8×8 mesh can reduce data delay by up to 80% and increase the maximum throughput by up to 310%. More improvements can be achieved by adding more HWCs per input per router, or more buffers per HWC. We also use a set of MPSoC application benchmarks to evaluate our highway technique. The experiment results suggest that with highway, we can reduce application run time up to 51%.","Highway in TDM NoCs Shaoteng Liu Zhonghai Lu Axel Jantsch liu2@kth.se KTH Royal Institute of Technology zhonghai@kth.se KTH Royal Institute of Technology axel.jantsch@tuwien.ac.at Vienna University of Technology, Austria Abstract—TDM (Time Division Multiplexing) is a well-known technique to provide QoS guarantees in NoCs. However, unused time slots commonly exist in TDM NoCs. In the paper, we propose a TDM highway technique which can enhance the slot utilization of TDM NoCs. A TDM highway is an express TDM connection composed of special buffer queues, called highway channels (HWCs). It can enhance the throughput and reduce data transfer delay of the connection, while keeping the quality of service (QoS) guarantee on minimum bandwidth and in-order packet delivery. We have developed a dynamic and repetitive highway setup policy which has no dependency on particular TDM NoC techniques and no overhead on trafﬁc ﬂows. As a result, highways can be efﬁciently established and utilized in various TDM NoCs. According to our experiments, compared to a traditional TDM NoC, adding one HWC with two buffers to every input port of routers in an 8×8 mesh can reduce data delay by up to 80% and increase the maximum throughput by up to 310%. More improvements can be achieved by adding more HWCs per input per router, or more buffers per HWC. We also use a set of MPSoC application benchmarks to evaluate our highway technique. The experiment results suggest that with highway, we can reduce application run time up to 51%. I . IN TRODUC T ION Time Division Multiplexing (TDM) technique is frequently used for guaranteed data transfer in NoCs [1]–[5]. TDM NoC means that a physical link can be shared by different connections, with each connection allocated one or several speciﬁc time slots in a ﬁnite repeating time window. A connection can span many links from source to destination, by allocating slot(s) at each of the links in a consecutive manner. As illustrated in Fig. 1, connection v1 passes link 1 and link 2. If slot 0 and slot 2 of link 1 is allocated to v1, then slot 1 and slot 3 of link 2 must be allocated to v1. Once a TDM connection is established, packet delivery on the connection is free from contention. It can therefore provide hard guarantees on delay, throughput and in-order delivery. However, in TDM NoCs, quite often the TDM slot utilization is low due to unused slots including both unallocated and idle slots. Firstly, unallocated slots commonly exist inside a TDM NoC. TDM NoC requires that reserved slots on the links of a connection must follow a consecutive sequence. Such Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada 2015 ACM. ISBN 978-1-4503-3396-2/15/09$15.00 DOI: http://dx.doi.org/10.1145/2786572.2786577 Fig. 1. Illustration of connections in TDM NoC mandatory sequence makes it difﬁcult to utilize all the slots of links. For example, suppose there is a connection v4 wants to use link 3 and link 2 in Fig. 1, although both link 3 and link 2 have unallocated slots, they cannot be allocated to v4 since they are not consecutive. Also, when mapping an application onto a TDM NoC, it is common that some links have more bandwidth reservation requirements and some links less. Such unbalanced bandwidth requirements inside a network also cause slots of some links unallocated. Secondly, idle slots are common for a connection with dynamic ﬂuctuation of network trafﬁc. Idle TDM connections withhold all the pre-reserved slots even if they have no data to deliver. For example, as shown by Fig. 1, suppose connection v2 becomes idle, it still occupies one slot on link 1 and link 2, respectively. Also, busy TDM connections can just use their pre-reserved slots for data transfer. For example, no matter how many data ﬂits are waiting on connection v1, connection v1 can still just use the two reserved time slots in a time window, even if there are free slots available along link 1 and link 2. In the paper, we develop a new technique called highway which can enhance the performance of TDM NoCs by utilizing free slots. With this technique, a TDM connection can dynamically acquire both idle and unallocated time slots to enhance its throughput, while keeping its QoS guarantee on minimum bandwidth and packet order. In particular, our contributions are: • We develop the concept of highway to efﬁciently use time slots, which is applicable to many kinds of TDM NoCs. • We propose a distributed, run-time highway setup and reclaim policy. Whenever the necessary resources for building a highway become available, a TDM connection can make use of it. • We have made an efﬁcient implementation of our proposed technique. By taking advantage of the contentionfree property of TDM NoCs, we can set up a highway with 2D + 2 cycles and without head ﬂits, where D is the distance between source and destination. Besides, our HighWay Channel (HWC) allocation only needs a very simple allocator, since our highway setup method promises contention free. Thus, our hardware implementation has a relatively short critical timing path. • We evaluated our highway technique using both synthetic trafﬁc and application benchmarks and suggest how to efﬁciently use highways. I I . R ELAT ED WORK Goossens et al. [9]. tried to increase the slot utilization of TDM NoC by introducing best effort (BE) trafﬁc into a TDM NoC (Æthereal), free slots can be utilized to deliver best effort packets. However, the main issue with this mixed guaranteed and BE trafﬁc scheme is that it may cause disorder of arrival packets, as observed in [6]. Eg., suppose a sender sends a BE packet ﬁrst and sends a guaranteed packet second. At the receiver side, it is possible that the guaranteed packet arrives before the BE packet. This is due to that the transfer delay of a guaranteed packet is bounded, whereas a BE packet has no QoS guarantee. Besides, this solution is not cost-effective, as observed by Goossens et al. themselves [1]. The cost for supporting BE trafﬁc is relatively high due to virtual channels and their allocation. But the service given to BE trafﬁc is low. Since TDM NoC has to prioritize guaranteed trafﬁc, the BE packets can be blocked for a very long time. To solve the packet disorder problem as in Æthereal, Marescaux et al. [6] proposed a source routing based TDM NoC which provides a new QoS class called SuperGT to increase the slot utilization while maintaining packet order. However, this method suffers from several limitations. Firstly, it is tightly coupled to a source routing based TDM NoC. It forces the trafﬁc ﬂow of a connection to be divided into small packets. The packet size is limited by the number of reserved slots of the connection in a time window. Besides, each packet must have a head ﬂit, since the head ﬂit’s information is needed for source routing, virtual channel setup, connection identiﬁcation, and packet order maintenance. Secondly, it requires that each TDM connection must have at least two reserved TDM slots in a time window, and all reserved slots must be adjacent. Otherwise, the superGT technique cannot be utilized. Eg., connection v2 and v3 in Fig. 1 cannot use superGT because they only reserve one slot per time window. Connection v1 in Fig. 1 cannot use the superGT technique as well, because its two reserved slots are not adjacent. Because of these limitations, superGT can only be utilized in restrictive situations. Moreover, this technique always wastes bandwidth for head ﬂit delivery, due to the limitation on packet size. As an extreme case, suppose a connection has two reserved slots in a time window, the packet size of this connection is limited to 2 ﬂits, which means 50% of the throughput has to be wasted on the head ﬂits. Fig. 2. The function of highway In contrast, our highway technique can make use of unused TDM slots while keeping the packet order and minimum throughput guarantee. It needs no head ﬂits, has no limitation on packet size, introduces no interference to normal TDM trafﬁc ﬂows, puts no constraint on TDM slot allocation and conﬁguration method, and does not rely on particular routing mechanism or router architecture. As a result, our technique has no architecture dependency and thus can bring beneﬁts to many different kinds TDM NoCs. I I I . H IGHWAY CONCE PT AND D E S IGN CON S ID ERAT ION S A. Additional Motivation As we analysed in Section I, low utilization due to unused TDM slots is a common problem in TDM NoCs. Besides, this technique has to be leveraged in order to suit the needs of dynamic and mixed trafﬁc scenarios. Consider the following practical situations: 1) Dynamic trafﬁc: For streaming applications [7], [8], e.g., H.264 decoding, we just need the NoC’s promise on the lower bound communication bandwidth. The upper bound of a trafﬁc ﬂow can be dynamically and readily adjusted by applying a ﬂow control mechanism or adding ﬂow regulation components. 2) Mixed trafﬁc: As demonstrated in [6], consider a system with a guaranteed connection between a L1 cache and L2 cache. Since cache misses are not completely predictable, it is common practice to over-allocate bandwidth. Thus we might want a mechanism which can keep the guarantee on minimum throughput and on the predictable trafﬁc ﬂow, while offering additional non-guaranteed bandwidth to enhance the overall system performance or absorb peaks of less predictable trafﬁc ﬂows. B. The Concept of Highway Our proposed highway is an express path for a TDM connection. Based on an established TDM connection, it can speed up data transfer by using unused time slots along the links of the connection. This is made possible because a highway consists of one buffer queue at the input port per router. Arbitration is performed to use the free time slots of the output link of a router. We name these buffer queues as highway channels (HWCs). The function of a TDM highway is illustrated in Fig. 2. The two connections, v1 and v2 share link 2 in such a way that v1 reserves two slots (slot 1 and 3) of link2; v2 reserves one slot (slot 2) of link 2. Then, v1 also builds up a highway path by occupying one HWC in router 1 and one HWC in router 2. Thus, v1 can additionally use slots of link 1 and link 2 whenever they are free. For example, it can acquire slot 1 and 3 on link 1 and slot 0 on link 2. It can also acquire the slot 2 of link 2, if v2 does not use it. In contrast, connection v2 has no HWC and thus can only use the reserved one slot for data delivery. A HWC functions like an input queue: if the output link of a router is occupied, incoming ﬂits of a connection with a highway will be buffered in the HWC. When the output link becomes free, or a reserved slot of the connection is coming, the output link can immediately serve the HWC. C. Design Considerations The idea of our highway technique sounds simple. However, the details are complicated, especially when we try to make it commonly used for TDM NoCs. The principles and considerations are listed as follows: 1) With or without a highway, a TDM connection is promised to use its pre-reserved slots to offer a guaranteed service. Due to this principle, if a highway is used for a TDM connection, whenever any of the pre-reserved slots arrives, the queue of the corresponding HWC will be served. For example, as Fig. 2 suggests, connection v1 has an established highway. Therefore, at slot 1 or 3, its HWC in router 2 is guaranteed to be served. This is in contrast to normal virtual channels which have no service guarantee. Moreover, this principle also requires that the dynamic highway setup/release process should incur no additional trafﬁc to the guaranteed trafﬁc ﬂow. 2) We must guarantee that reordering of a trafﬁc ﬂow never happens in any situation. This rule sounds easy but it is tricky to follow. In Section IV-D, we will show our solution to keep ﬂits ordered during the highway release process. 3) A highway accelerates data transfer only if one HWC per router is allocated along the path of a connection, all the way from the source to the destination. This is due to that individual HWCs cannot ameliorate performance. For example, suppose connection v1 in Fig. 2 gets a HWC in router 1 but fails to get a HWC in router 2, then link 2 will be the throughput bottleneck, since still only the two reserved slots of link 2 can be used. Thus, during the highway setup process, our HWC allocation follows a win all or nothing principle that, if we fail in allocating one HWC in any of the routers along a connection, all allocated HWCs are canceled as soon as possible. IV. H IGHWAY IN TDM NOC S A. Design Overview An overview of a TDM router with highway is depicted in Fig. 3. Each input link has an input manager, which manages all the incoming ﬂits of that input. We can have one or several HWCs per input manager. With more than one HWC, the input manager needs additional logic for internal arbitration between the HWCs. To support our highway technique, each input /output link needs to have a f lag signal and a credit signal coupled with the data path. The f lag signal is in parallel to the data path. It is used for highway setup, transfer and release. The credit signal goes in the opposite direction of Fig. 3. The micro-architecture of a TDM router with highway the data path. It is used for ﬂow control in the data transfer phase and for Ack/Nack purpose in the highway setup phase. As Tables I and II suggest, we use 3 bits for the f lag signal and 2 bits for the credit signal. Because of the design considerations listed in Section III-C, we do not use head ﬂits in our highway technique. Instead, we use the 3-bit ﬂag signal for highway setup and release purpose. Unlike the information bits of a ﬂit, a ﬂag associated to a ﬂit can be changed during the transfer process. It does not need to be buffered together with the ﬂit. Instead, it is regenerated when a ﬂit leaves a router, based on the router’s current status. Inside each HWC, there is a set of registers. The ”next HWC Id” register stores the id of the HWC in the next router1 . The ”out dir.” register stores the output direction to reach the the next router. The credit counter records the available queue size of the downstream HWC. All of these 3 registers are commonly used in virtual channel techniques. The ”release mark” register is used in our highway release process. The ”allocated slot” register uses a vector of bits to mark which are the reserved slots in a time window of a connection. The size of the bit vector equals the time window size. For example, as Fig. 3 describes, if the reserved slots for a connection are slot 0 and slot 2 inside a time window of size 4, the ”allocated slot” register is conﬁgured as ”0101”. In our design, HWCs are dynamically allocated and reclaimed for connections. Note that, a HWC can only be assigned to one connection at a time. When a TDM connection has a certain amount of data buffered in the network interface, it may set up a highway for acceleration. The general operation for using a highway in a TDM NoC consists three phases, namely, setup, data transfer, and release. 1We do not need this register if each input manager only has one HWC. TABLE I U SAG E O F TH E FLAG S IGNAL Usage Flag 000 001 010 011 100 101 message Idle Setup HWC-RS HWC-NS No HWC Release – try to book a HWC Incoming ﬂit has a HWC and sent/received at a reserved slot (RS) Incoming ﬂit has a HWC and sent/received at a non-reserved slot (NS) Incoming ﬂit has no HWC Release the allocated HWC TABLE II U SAG E O F TH E CRED I T S IGNAL Credit 00 01 10 11 Usage during highway setup Idle – Nack (highway setup failed) Ack (highway setup success) Usage after highway is built – credit updating – – B. Highway Setup Phase Fig. 4 illustrates the setup process for a 2-hop TDM connection which has 2 reserved slots inside a time window of 4. From the source node, when a reserved slot (slot 0) is coming, a data ﬂit is sent out with f lag signal ”setup”. This ﬂit travels by using reserved slots of links, at a constant speed of one slot per hop. If it can acquire a HWC when arriving at a router during the traversal, its ﬂag remains ”setup”. When the destination node receives a ﬂit with ﬂag ”setup”, it will send back an ”Ack” message by using the credit signal of the allocated HWC in the destination node. Such a message will be delivered backward to the source node hop by hop, through the credit signal of each allocated HWC along the forward path of the ﬂit. When the source node receives ”Ack” , it can begin to use the established highway for data transfer. The following is worth mentioning. 1) The HWC allocation performs one hop in advance. For example, as suggested by Fig. 2, router 1 is responsible to allocate the HWCs at the input port of router 2. The allocation decision is put into ”next HWC Id” reg. This technique is inherited from the virtual channel allocation technique [12]. 2) If the ﬂit with ﬂag ”setup” fails to acquire a HWC in a router, the highway setup process stops. The ﬂit continues its traversal with f lag changed into ”No HWC”. Meanwhile, a ”Nack” signal will be sent back towards the source node hop by hop through the credit signals of the allocated HWCs in routers. As the ”Nack” signal travels, it will release the allocated HWCs. 3) Since ”setup” ﬂits are delivered without contention by pre-reserved slots of links, arbitration is not needed in the setup phase. Thus, we can simplify the logic for the HWC allocation inside each input manager. Moreover, the highway setup time is predictable. It is 2D + 2 cycles (assuming each slot is one cycle), where D is the distance between source and destination. 4) The whole setup process just utilizes f lag and credit signals, it generates no additional trafﬁc ﬂow overhead. 5) Our highway setup method is architecture independent. We do not care about how ﬂits of a connection are routed or how connections are established. As long as a ﬂit is Fig. 4. Highway setup, data transfer, and release process. With highway, the RSs (reserved slots) on a link are still guaranteed to use, while a NS (non-reserved slot) can be acquired by wining an arbitration. delivered without contention to the destination with a f lag as ”setup”, a highway has been established 2 . The highway conﬁguration process conﬁgures the registers inside each allocated HWC. During the setup phase, the ﬂit with ﬂag ”setup” conﬁgures the register ”next HWC Id” and ”out dir.” The ”allocated slots” register conﬁguration takes place in data transfer phase. In the case of failed highway setup due to HWC unavailability, we use a simple retry scheme until success. C. Highway Data Transfer Phase After a highway is established, ﬂits sent at a reserved slot have the ﬂag ”HWC-RS”, whereas ﬂits sent at nonreserved slots have the ﬂag ”HWC-NS”, as illustrated in Fig. 4. Arbitration for a non-reserved slot is needed, if it is requested by multiple input managers. The ”allocated slots” register of a HWC is conﬁgured by multiple ”HWC-RS” ﬂits arrived after the highway setup process, if the connection has multiple reserved slots. When a ﬂit with ﬂag ”HWC-RS” arrives at a HWC, it will set the corresponding bit of the HWC’s ”allocated slots” register according to the ID of the current slot, if the bit is unset (”0” means unset and ”1” set)3 . For example, if a ”HWC-RS” ﬂit arrives at a HWC on slot 0, it will set the bit 0 of the register. The function of a HWC in the data transfer phase is somehow similar to input queue based virtual channel. Incoming data ﬂit of a HWC is pushed into a queue according to the ﬂit’s HW C ID . If the desired output channel is granted, one ﬂit will be popped from the queue and sent with a valid HW C ID pointing to the HWC in the downstream. One specialty is that, when a reserved slot of an HWC comes, the queue of the HWC is guaranteed to be served. Besides, the transfer of ”HWC” ﬂits does not interfere with ”No HWC” ﬂits, since our arbitration mechanism prioritizes the data ﬂit sent by using reserved slots. 2 In source routing based TDM NoCs, we need to add a slot pointer inside each router to obtain the ID of the current slot for the ”allocated slots” register conﬁguration. 3Due to slots are reserved consecutively along the links of a connection, when an HWC receives a ”HWC-RS” ﬂit from its upstream node, it means its own reserved slot is met. A FIFO is implemented in an HWC for ﬂit buffering. However, we also add a bypass way to the FIFO. If the FIFO is empty and the desired output is ready, an incoming ﬂit can be directly forwarded, without being buffered in the FIFO. The credit based ﬂow control policy used in our HWCs is similar to that in Chapter 13.3.1 of [11], except that sending data ﬂit at reserved slots neither consumes credits nor generates credit updating signal to the upstream. D. Highway Release Phase If a connection no longer requires a highway, it should release all the occupied HWCs. To release a highway, the source node sends out a ”release” ﬂag. If a HWC is empty when a ”release” ﬂag arrives, the ”release” ﬂag will reset the HWC and get forwarded to the downstream node. However, if a HWC still has buffered data, the ”release” ﬂag will set the ”release mark” register and halt its forwarding until the HWC becomes empty. As mentioned in Section III-C, it is tricky to maintain ﬂit order of a connection during its highway release process. Let’s consider the following situation: Suppose the source node of a connection has sent out a ”release” ﬂag. After that, the source node continues to send ﬂits with the ﬂag ”No HWC”. The HWC release process is relatively slow, since the ”release” ﬂag may wait inside a HWC until it becomes empty. However, the ﬂit sent by the source node with the ﬂag ”No HWC” travels at a guaranteed speed of one slot per hop. Therefore, a ”No HWC” ﬂit of a connection may arrive at a router which still has an unreleased HWC for that connection. In this situation, this ”No HWC” ﬂit should go into the unreleased HWC to maintain the ﬂit order. However, since all the upstream HWCs have been released, this ﬂit arrives without a valid HW C ID . How can we ﬁnd the HWC for this ﬂit? Unlike [6], we do not use a head ﬂit for carrying the connection ID. Instead, we use the reserved slot information for connection identiﬁcation. Let us also consider the following facts: 1) ”No HWC” ﬂits are delivered by using reserved consecutive slots of links. 2) ”allocated slots” register of a HWC can be used to claim which slot is the reserved slots on a link of a connection. Therefore, when a ”No HWC” ﬂit arrives at an input manager of a router, normally it will be directly forwarded to an output. However, if a HWC at the same input manager also claims that it meets a reserved slot and must be served, the incoming ﬂit and this HWC must belong to the same connection and thus the incoming ﬂit should go into the HWC. In this way, we can identify whether or not a ”No HWC” ﬂit has an unreleased HWC. E. Implementation Cost Our highway TDM router is built on top of a base TDM router (similar to [2]) used for mesh topology. The additional components are 1) one input manager per input port, 2) an external arbitrator for the arbitration between all the input managers. Note the buffer size per HWC should be large enough to cover the round-trip delay of credit updating (see SYN TH E S I S R E SU LT S W I TH 45 nm TECHNO LOGY W I TH FL I T W IDTH O F 128 -B I T AND A BU FFER S I ZE O F 2 FL I T S TABLE III Component HWC Other logic Input manager total Comb. 298 457 755 Noncomb. 1588 28 1616 Flip-ﬂops 282 5 287 Total (um2 ) 1886 485 2371 Total (gates) 2694 693 3387 Chapter 13.3.1 of [11]). Thus, suppose that each slot is one clock cycle, and the credit-updating signal is one cycle per hop. Depending on the implementation details, the roundtrip delay is at least two cycles4 . Thus, the minimum buffer requirement is two ﬂits. We evaluate the additional costs in this section. The synthesis results are reported under 45 nm technology. The area costs of an input manager containing one HWC with 2 buffers and with a data ﬂit width of 128-bit and 16-slot window size are listed in table III. In our implementation, each slot represents one clock cycle. As Table III shows, the total area cost of a HWC manager is 2371 um2 , among which 1886 um2 is spent on the HWC. Inside a HWC, FIFO constitutes about 92% of the area. In our implementation, FIFO is built by using ﬂit-ﬂops. If we use SRAM cells, it can be a factor of 3 or 4 less expensive. The cost of the external arbitrator is only 161 um2 . It does not scale up with the HWCs per input. The critical timing path of a router consists of 3 components: an input manager, the external arbiter and the crossbar. The latter two components contribute a latency of 0.15 ns. The latency of a input manger varies with the number of HWCs it has. E.g., with one HWC, its latency is 0.36 ns; with 8 HWCs, its latency is 0.54 ns. Compared to the base TDM router, our highway TDM router (adding 1 HWC with 2 buffers per inport) causes an area overhead of 12016 um2 . This is the cost of leveraging the static inefﬁcient QoS guarantees. There are also additional costs on the network interface (NI) when applying the highway technique. We need a state machine to control the setup/release of highways, as well as credit based ﬂow control logic for data transfer. If a NI uses more than one highway, arbitration logic is also needed. However, since we do not need to increase the ﬂit buffers inside a NI, the additional costs in total are still relatively small. V. P ER FORMANC E EX PER IM EN T S AND R E SU LT S We present experiments and results concerning the beneﬁts of using highways in different conﬁgurations, under different test scenarios, and with different TDM NoC technologies. We utilize a popular mesh topology in our evaluation. To facilitate our evaluation, we assume that each slot is one clock cycle, and each HWC should have more than 2 buffers to cover the credit round-trip delay. The performance enhancements brought about by our highway technique are evaluated with both synthetic trafﬁc patterns and application benchmarks. 4 In this case, the credit updating signal needs to be sent out as soon as the arbitration succeeds. (a) Packet sizes (b) Increase HWCs (c) Increase buffers Fig. 5. Performance evaluation under uniform trafﬁc in an 8x8 mesh, with a window size of 16 slots. Each connection reserves 2 slots in a window. The packet size is 32 ﬂits for (b) and (c). Injection rate is in ﬂit/connection/cycle (fcc) (a) Uniform random (b) Tornado (c) Shufﬂe Fig. 6. Throughput evaluation under different trafﬁc patterns and different connection width and a packet size of 32 ﬂits A. Performance Evaluation with Synthetic Trafﬁc We assume that the static TDM NoC has an architecture similar to [2]. We designed a depth ﬁrst searching algorithm similar to [10] to do path searching and slot allocation for connections. After all the connections are conﬁgured, we can launch our NoC for data transfer by using these statically reserved connections. For a uniform random trafﬁc pattern, we randomly generated 64 connections and scheduled them in an 8×8 mesh with a window size of 16 slots. If a generated connection cannot be scheduled, we will regenerate it until it can be scheduled. We also use the Tornado and Shufﬂe trafﬁc patterns for which connections are generated according to the relationship of source and destination nodes as described in the Chapter 3.2 of [11]. Packets generated for each connection obey a Poison distribution. Therefore, the trafﬁc injection rate of a ﬂow can be controlled by adjusting the inter arrival time between packets, while the burstiness of the trafﬁc ﬂow can be controlled by varying the number of ﬂits in a packet. We vary the packet size from 16 to 64 ﬂits, the reserved number of slots per connection per time window from 1 to 4 slots, the HWC per input from 1 to 4 and buffer per HWC from 2 to 4. In our evaluation, we deﬁne injection rate as average ﬂits/connection/cycle (fcc). The packet delay includes both the waiting delay in the NI and the transfer delay of the network. The throughput results are also given as ﬂits/connection/cycle. The results under uniform random trafﬁc are shown in Fig. 5a. Our highway technique greatly reduces the average packet delay. Eg. with a packet size of 16 ﬂits, applying one HWC per input with 2 buffer stages can achieve a delay reduction of 77% at injection rate 0.1 fcc. As the packet size grows, the beneﬁts of using highways becomes more prominent. Eg. at packet size of 32 ﬂits, the delay reduction is 80% at injection rate 0.1 fcc, while at packet size of 64 ﬂits the reduction becomes 84%. Besides, the maximum throughput improvement also increases from 50% to 200%, when packet size increases from 16 to 64 ﬂits. This is because when the packet size grows, the network trafﬁc becomes more and more bursty and thus unbalanced. As a result, our highway technique gains more chances to utilize free slots for busy connections. We also observe that, increasing the number of HWCs per input can further improve performance. As Fig. 5b shows, increasing HWC from 1 to 2 can have a further 35% delay reduction at injection rate 0.15. However, more HWCs do not lead to apparent performance improvements, showing a performance saturation phenomenon. Compared with adding the buffers per HWC, increasing the number of HWCs per input is more effective on performance. As Fig. 5c suggests, two HWCs per input with 2 buffers in each is far better than one HWC with 8 buffers. Furthermore, we studied the effect of different number of reserved slots per connection and different trafﬁc patterns. All of these results suggest that using our highway technique can greatly reduce packet delay, which is similar to the delay curves in Fig. 5a. For example, when each connection reserves 4 slots in a time window, we can still have 47% delay reduction at injection rate 0.1 fcc and 70% delay reduction at 0.23 fcc with uniform random trafﬁc. We skip the delay results here due to space limitation. The effects on maximum throughput are shown in Fig. 6. We ﬁnd that the same HWC conﬁguration under different trafﬁc pattern and with different reserved slots per connection generates different throughput improvements, ranging from COMMUN ICAT ION PRO P ERT I E S O F TH E A P P L ICAT ION S TABLE IV Connections Avg. Burst size (ﬂits) Total Request (MB/s) Max Request (MB/s) Min Request (MB/s) AV bench 57 531.60 6772 1168 0.25 ERS 26 12797.0 4488 512 64 UMTS 11 14.1 94 246 2 OFDM 12 1.43 196 80 52 (TCGs) to model MPSoC applications. It contains a set of processor and DSP models. Tasks can be mapped and running on these processor and DSP models. [15] has already given the task mappings. It mapped all the applications to either a 2×2 or a 4×4 mesh based MPSoC platform depending on the size of the TCGs. Users of the NoC bench are required to use their own NoC to connect all the processor/DSP cores to run these applications for evaluation. The NoC bench contains four applications which have throughput requirements annotated on the edges of TCGs. The details of the four applications have been described in [14]. Their TCGs can also be found in [15]. Besides, we list the communication properties of each application in Table IV, in which Total Request means the total throughput requirement of an application. Min/Max Request refers to the minimum/maximum throughput requirement among all the connections’ requirements of an application. Note that the AV benchmark and Ericsson Radio System (ERS) are communication intensive, their Total Request are 6772 MB/s and 4488 MB/s respectively, whereas the trafﬁc ﬂows generated by the UMTS receiver and OFDM receiver are a magnitude less, which are 96 MB/s and 196 MB/s respectively. Before running an application on the statically scheduled TDM NoC, we ﬁrst establish TDM connections between processor/DSP cores to satisfy all the communication needs and throughput requirements described by the TCG of the application. We use a depth-ﬁst search algorithm to search paths and allocate slots to connections. We can statically optimize a TDM NoC for an application by tuning the NoC clock frequency and the TDM window size, in order to avoid too much bandwidth waste. For this reason, we gradually increase the NoC clock frequency and the time window size until reaching a condition where our search algorithm can schedule all the connections of an application. The clock frequency of the NoC ranges from 100 to 1000 MHz. The time window size is between 2 to 32 slots. As Fig. 8a shows, the highways signiﬁcantly improve the performance of AV benchmark and ERS. The average application run time is reduced by 24% and 52%, respectively. Meanwhile, as suggested by Fig. 8c, the throughput is enhanced by 6% in AV benchmark and 25% in ERS. Such performance improvement is due to the highways in the TDM NoC. For example, we see 14% (with one HWC per input link) and 15% (with two HWCs per input link) average ﬂit delay reduction with AV bench. We also ﬁnd about 20% (one HWC per input link) and 52% (with two HWCs per input link) delay reduction in the ERS application. For these two applications, improvements on communication can also help to enhance the overall system performance, which is reﬂected Fig. 7. Delay decomposition under uniform random trafﬁc and a packet size of 32 ﬂits. 417% to 8%. We also observe that, as the reserved slots per connection grows, the throughput improvements decreases. This is due to that given a ﬁxed number of connections, as the reserved slot per connection increases, the unallocated slots decrease. Finally, in our experiments we separate the total delay into: waiting delay and transfer delay. As shown in Fig. 7, compared with the transfer delay, the waiting delay of a ﬂit is much bigger. For example, without a highway, the average ﬂit waiting delay is more than 300 cycles, which will also increase dramatically when the injection rate increases, while the transfer delay is always 6 cycles. The large waiting delay of a ﬂit is due to two reasons: (1) when a burst of ﬂits arrives, the FIFO order requires the ﬂits waiting in a queue, if the service rate of the output is not enough; (2)Without a highway, a TDM connection mandates a ﬂit to wait for one of the reserved slots. The highway technique can reduce the waiting delay in both scenarios, by increasing the service rate of a connection as well as reducing the waiting time for a slot. As suggested by Fig. 7, the waiting delay is reduced from above 300 cycles to around 100 cycles, when applying 1 HWC with 2 buffers per input. With HWC, the transfer delay of a ﬂit may slightly increased due to buffering delay in the HWCs, for example, at injection rate 0.7 fcc, the average transfer delay with a highway is 7 cycles, which is 1 cycle more than without highway. However, when compared with the waiting delay reduction, such increase can be neglected. From these results, we ﬁnd that adding 1 HWC per input with two buffers can have up to 80% packet delay reduction and up to 310% throughput enhancement. Increasing the buffers per HWC does not have signiﬁcant improvements, whereas using more HWCs can further reduce the packet delay from 10% to 40% and increase the throughput by 4% to 75%. However, considering the doubled, even tripled area cost, as well as the more than the 15% increase on the critical timing path, we think it is not cost-effective to use more HWCs or more buffers per HWC. Applying one or two HWC for each input link, and 2 buffers in each HWC to cover the round-trip delay seems to be a reasonable compromise. B. Performance Evaluation with MPSoC Benchmarks We experimented with the NoC benchmarks designed by Pekkarinen et al [14] [15], to conﬁrm the beneﬁts of highways. The NoC benchmark utilizes task communication graphs (a) Application performance (b) Average ﬂit delay Fig. 8. Benchmark evaluation of our highway technique (c) Normalized throughput by the shortening of application run time and the increase of system throughput. Applications like the OFDM receiver and UMTS receiver have less communication needs and their performance mainly depends on the processor speed. Therefore, from Fig. 8b, we ﬁnd that for the OFDM receiver, although our highway technique can bring about 25% ﬂit delay reduction, such improvement on communication system does not help to increase the application performance, as suggested by Fig. 8a and Fig. 8c. We further studied the network performance, as described in Fig. 8b. We ﬁnd when using highways, applications with larger burst size tend to have more delay improvements. For example, the biggest delay improvement happens with ERS, since its trafﬁc ﬂows has an average burst size of 12797 ﬂits. In comparison, there is no improvement for the UMTS receiver, since it has a low trafﬁc generation rate and the average burst size is only 1.43. In this situation, the highway setup process is seldom initiated because of not enough ﬂits waiting in the network interface. Furthermore, we ﬁnd that the transfer delay of a ﬂit is very small, ranging from 3 to 7 cycles on average. However, the average waiting delay is relatively large, eg. it can reach up to 213 cycles. Our highway technique can greatly reduces the total delay by shortening the waiting delay, eg. from 213 cycles to 104 cycles. V I . CONC LU S ION S We have proposed a TDM highway technique to utilize free time slots in TDM NoCs. With the highway technique, the upper bound throughput of a connection is adaptive to link sharing situations, while it still offer QoS guarantees on the lower bound throughput and ﬂit order. The delay of packets are greatly reduced. We can dynamically setup highways on TDM connections. One prominent aspect of our highways is that the dynamic setup method has no interference with the normal TDM data transfer and no dependency on the TDM NoC architecture. Thus, it can be utilized by TDM NoCs with either a distributed or a centralized TDM connection setup method, with either source routing or distributed routing by using distributed slot tables. We use both synthetic trafﬁc pattern and application benchmarks to evaluate our highway technique. With synthetic trafﬁc pattern we ﬁnd a delay reduction up to 80% and a throughput enhancement upto 417% in a statically scheduled TDM NoC, as well as up to 80% delay reduction and 17% throughput enhancement in a dynamically allocated TDM NoC. Generally speaking, the more unused slots, the more beneﬁts; the larger the burst size, the more improvements. Also, using more HWCs for a link and more buffers per HWC can provide more performance enhancement. However, the cost-performance study suggests that using one or two HWCs per link and 2 buffers per HWC is most cost-effective in our extensive experiments. With application benchmarks, we conﬁrm that highways can enhance the performance of a TDM NoC. However, the enhancement on NoC can reduce the run time of an application only if it is communication intensive. "
Reconfigurable Wireless Network-on-Chip with a Dynamic Medium Access Mechanism.,"Wireless interconnects have emerged as an energy-efficient interconnection paradigm for multicore chips with Networks-on-Chips (NoCs). As wireless interconnects have the unique advantage of eliminating the need to layout physical channels they provide an inherent opportunity for dynamic reconfiguration of the NoC architecture. Large temporal and spatial variability in traffic patterns is expected in large multicore chips and especially in future heterogeneous systems-on-chips integrating different kinds of cores such as CPUs, GPUs, ASICs and memory. By establishing on-demand wireless links in response to dynamically varying traffic patterns the data bandwidth and energy efficiency of NoC architectures can be improved compared to static architectures with the same raw bandwidth. We present a dynamic medium access mechanism that establishes wireless links depending on traffic requirements while reducing the overheads. Such an interconnection system incorporating wireless links in a NoC fabric will be better suited to address non-uniformity and temporal variations in traffic patterns which are expected in future large multicore chips.","Reconfigurable Wireless Network-on-Chip with a Dynamic  Medium Access Mechanism  Naseef Mansoor, Amlan Ganguly  Rochester Institute of Technology  Rochester, USA  {nxm4026,axgeec}@rit.edu  ABSTRACT  Wireless interconnects have emerged as an energy-efficient  interconnection paradigm for multicore chips with Networks-onChips (NoCs). As wireless interconnects have the unique  advantage of eliminating the need to layout physical channels they  provide an inherent opportunity for dynamic reconfiguration of  the NoC architecture. Large temporal and spatial variability in  traffic patterns is expected in large multicore chips and especially  in future heterogeneous systems-on-chips integrating different  kinds of cores such as CPUs, GPUs, ASICs and memory. By  establishing on-demand wireless links in response to dynamically  varying traffic patterns the data bandwidth and energy efficiency  of NoC architectures can be improved compared to static  architectures with the same raw bandwidth. We present a dynamic  medium access mechanism  that establishes wireless  links  depending on traffic requirements while reducing the overheads.  Such an interconnection system incorporating wireless links in a  NoC fabric will be better suited to address non-uniformity and  temporal variations in traffic patterns which are expected in future  large multicore chips.  Categories and Subject Descriptors  C.2.1  [Computer-Communication Networks]: Network  Architecture and Design – Network Communications, Network  topology.  General Terms  Performance, Design.  Keywords  Network-on-Chip, Medium Access Control Mechanism, Wireless  interconnect.  1. INTRODUCTION  Network-on-Chip (NoC) has emerged as a communication  backbone, enabling the high degree of integration in the multicore System-on-Chips (SoCs) [2]. However, the traditional NoC  architectures suffer from latency and energy issues due to multihop data communication over the metal interconnects. To  alleviate this problem, insertion of long range links using  conventional metal wires in a mesh based NoC has been proposed  in [24]. In [18], ultralow-latency and low-power express channels  between communicating nodes has been proposed as an  alternative solution. However, due to these metal/dielectric based  Permission to make digital or hard copies of a ll or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that copies  bear this notice and the full citation on the first page. Copyrights for  components of this work owned by others than ACM must be honored.  Abstracting with credit is permitted. To copy otherwise, or republish, to  post on servers or to redistribute to lists, requires prior specific permission  and/or a fee. Request permissions from Permissions@acm.org.  NOCS '15, September 28 - 30, 2015, Vancouver, BC, Canada   © 2015 ACM. ISBN 978-1-4503-3396-2/15/09…$15.00   DOI: http://dx.doi.org/10.1145/2786572.2788711  communication channels, the performance gain is also limited by  the conventional interconnect paradigm [17]. Hence, novel  approaches like photonic interconnects [28], on-chip multi-band  RF transmission lines (RF I) [6], and wireless interconnects [15]  have been explored. The photonic and RF I based NoCs are  capable of achieving both low latency and low power dissipation  due to single hop communication between distant cores. Both  these technologies need the additional physically overlaid optical  waveguides or transmission lines to enable data transmission. On  the other hand, CMOS compatible long-range wireless shortcuts  operating in the millimeter-wave (mm-wave) frequencies [10] do  not require laying out physical interconnects.  On-chip miniature  antennas operating in the mm-wave bands are shown to be able to  communicate between wireless interfaces (WIs) deployed across a  die [10]. However, the bandwidth of the mm-wave wireless  channels is limited by the state-of-the-art in transceiver design. To  increase the utilization of the bandwidth , multiple wireless  interfaces (WIs) need to share the wireless bandwidth for data  communication. Hence,  judicious deployment of wireless  interconnects, novel topologies and efficient medium access  control (MAC) mechanisms need to be designed for such on-chip  wireless interconnections.  Modern and future multicore chips have dynamically varying  traffic patterns depending upon dynamic task mapping and  varying workloads. It is shown in [23] that even if the traffic  pattern is uniform due to particular routing algorithms all NoC  routers are not utilized identically. Such variations in utilization  results in congestions and degradation in performance in a  traditional NoC. On the other hand future multicore chips may  integrate heterogeneous cores like CPUs, ASICs, GPUs, FPGA  fabrics and memories [9]. These various types of processing  elements will have different rates of data consumption requiring  different communication bandwidths between  them. Such  heterogeneous systems will generate drastically non-uniform and  time-varying heterogeneous traffic demands. As wireless links do  not require physical layouts, they can be deployed adaptively to  form reconfigurable NoC architectures to cater to the time-varying  traffic requirements by dynamically activating the wireless links  between specific communicating pairs.  In order to establish this reconfigurable wireless links and  optimize the utilization of the wireless channel bandwidth an  adaptive as well as efficient MAC needs to be designed. Design of  non-overlapping channels in mm-wave frequencies to enable  Frequency Division Multiple Access (FDMA) based medium  access is non-trivial due to the challenges in transceiver design.  Code Division Multiple Access (CDMA) based medium access  scheme proposed in [29], requires power hungry transceivers for  maintaining  synchronization  for  the  sake of preserving  orthogonality between code channels in transmitters. Hence, in  order to utilize the on-chip wireless bandwidth, limited by the  state-of-the-art  transceiver design  and on-chip  antenna  technology, variations of Time Division Multiple Access (TDMA)              mechanisms like token passing [5, 12] and Carrier Sense Multiple  Access (CSMA) [7] has been proposed. The design of such  TDMA based medium access scheme is simple and does not  require centralized control, global synchronization or arbitration  among the transceivers potentially located in distant parts of the  die. However, the token circulation can cost prohibitively high  energy overheads at  low  load scenarios being constantly  circulated between the various WIs. On the other hand, the  performance of CSMA based systems can degrade rapidly with  increase in traffic loads due to increased probability of collisions.  Hence, a dynamic MAC mechanism that uses CSMA for low  traffic loads and token passing for high traffic loads, can achieve  the benefits of both approaches. So in this paper, we propose a  reconfigurable wireless NoC (WiNoC) that can deploy wireless  links on-demand enabled by a dynamic MAC mechanism.  Through system level simulation, we show that the proposed  WiNoC architecture with the dynamic MAC mechanism is  capable of providing the benefits of both CSMA and token based  MAC mechanisms in different traffic loads.  The paper is organized as follows: Section 2 outlines the related  work and describes how this work builds on previously published  work. Section 3 discusses the reconfigurable WiNoC architecture  in details. This section also discussed about the physical layer,  wireless flow control mechanism and  the dynamic MAC  mechanism. The experimental results are presented in section 4.  Section 5 concludes the paper.  2. RELATED WORK  A comprehensive survey regarding various WiNoC architectures  and their design principles is presented in [11]. Notable NoC  architectural innovations with wireless interconnects include  design of a WiNoC based on CMOS ultra wideband (UWB)  technology [31], hierarchical mm-wave WiNoC architecture [5],  2D concentrated mesh-based WCube architecture using sub-THz  wireless links [20], and the inter-router wireless scalable express  channel for NoC (iWISE) architecture [12]. A hybrid hierarchical  WiNoC designed with carbon nanotube (CNT) antennas [15] is  capable of achieving several orders of magnitude lower energy  consumption. All  these architectures can be classified as  hierarchical architectures, where neighboring nodes are connected  through local smaller subnetworks while nodes in different  subnetworks communicate  through hubs  that connect  the  subnetworks. On the other hand there are novel complex network  based small world topologies investigated in [15, 16] where local  communication are routed through wireline links whereas long  range communication is routed through energy-efficient wireless  links. However, the wireless interconnects in all these topologies  Figure 1. Reconfigurable WiNoC Architecture   did not require physical channels. In this paper we look at the  benefits of this flexibility of the wireless interconnections in a  NoC.  On the other hand, due to energy, area and memory constraints,  complex MAC mechanisms for WiNoCs are not suitable. Design  of low-overhead and efficient MAC schemes have also been  identified as one of the main challenges in a WiNoC in [1]. A  synchronous and distributed medium access mechanism (SDMAC) is proposed in [31] for the Ultra Wide Band (UWB)  wireless NoC. However, due to the use of impulse based  transceivers in UWB WiNoCs, wireless links can carry data over  a millimeter range only. Hence, local arbitration was necessary in  the MAC to acquire access to the medium. In order to efficiently  utilize the wireless bandwidth, authors in [29] proposed a CDMA  based medium access scheme. Authors have used orthogonal code  words to enable concurrent wireless transmission through the  wireless channel. However, to maintain the orthogonality of the  code channels the transceivers should be precisely synchronized.  Such synchronization  is difficult  to achieve among WIs  distributed over a large multicore chip. In [15], a hybrid medium  access scheme combining both TDMA and FDMA is reported for  WiNoCs based on CNT antennas. However, the CNT based  wireless technology used in that work is difficult to integrate in  current CMOS process. A distributed MAC protocol is proposed  in [14]. The proposed mechanism uses simple orthogonally coded  request packets, processing the request packets and granting  permission to the channel by a priority based mechanism.  However, this mechanism has an overhead of maintaining the  state of current transmission at each transceiver. In [26], authors  discussed the performance of ALOHA and CSMA for graphene  based WiNoCs. A comparative performance evaluation of CSMA  and Token based MAC is presented in [7]. For WiNoCs utilizing  mm-wave transceivers, a token passing based medium access  mechanism is used in [5, 12]. In a token passing MAC the access  to wireless medium is granted by a token circulation among the  transceiver requires no global synchronization mechanism and is  simple. In this work, we discuss a reconfigurable WiNoC  architecture with dynamic MAC mechanism that utilizes the  fairness of token passing mechanism as well as the energy  efficiency of CSMA based MAC.   3. RECONFIGURABLE WIRELESS NOC  ARCHITECTURE  Here we discuss the various aspects of the reconfigurable  WiNoC with dynamic MAC mechanism.  3.1 On-Demand Reconfigurable Topology  In this section, we describe how WiNoC architectures can provide  on-demand links between communicating cores and therefore  increase the data rate and reduce energy consumption in on -chip  data transfer. For this purpose, we investigate a hybrid topology  for  the WiNoC, which uses both wireline and wireless  interconnects in this work. While the wireline topology is static,  the wireless interconnection is dynamically reconfigurable and  hence can adjust to varying demands in traffic. The wireline part  of the topology is a hierarchical network (HiMesh). Each core is  connected to a switch. All the switches are interconnected in a  mesh based topology such that each switch is connected to only  its cardinal neighbors in the north, south, east, and west,  (NSEW)  directions. The whole NoC is subdivided into smaller logical  blocks called subnets. The number and size of subnets are  considered to be same to prevent any level of the hierarchy  becoming too large in comparison to the other and becoming a    bottleneck for performance. Within each subnet , all switches are  directly connected to a hub through wired links. In the upper level  of the hierarchy, the hubs are interconnected through wired links  in a mesh topology as well.  It is shown in [23], a planar mesh NoC fabric has uneven  distribution of traffic even if the original traffic pattern is uniform  between pairs. This is because deadlock-avoidance dimension  order routing can result in congestions at those switches that work  as relays for a large number of pairs of communicating cores. In  addition,  temporarily some pairs might have a higher  communication load than the rest due to temporal non-uniformity  in traffic distribution. Moreover, future multicore systems may  integrate heterogeneous cores on the same die [9]. Such  heterogeneous systems will have significantly heterogeneous  traffic patterns both in spatial and time dimensions. To address  such ephemeral traffic imbalances, we will utilize the wireless  links which are inherently reconfigurable. Hence, in addition to  this upper level mesh, the hubs are also equipped with WIs. This  topology (HiWiMesh) is shown in Figure 1. As will be discussed  in the next subsection the proposed dynamic MAC mechanism  enables the establishment of the reconfigurable wireless links with  on-demand interconnects based on dynamically varying traffic  demands.  3.2 Dynamic MAC Mechanism  The WIs need to access the wireless medium to communicate  through the energy-efficient wireless channel. A MAC protocol  enables the WIs to access the wireless medium thus forming ondemand links creating the reconfigurable topology. Depending on  the traffic which maybe point to point or multicast, a WI may  send data to only a single destination WI or to multiple WIs  respectively, thus forming a single wireless link or multiple ones.  Due to energy, area and memory constraints, MAC protocols in  WiNoCs have to be much simpler from traditional macro scale  wireless networks. Typical request and grant based transmission  requires multiple fields of data for a fair use of the wireless  channel. Such MAC protocols with large control information  overheads are not suitable for WiNoCs because of the limited  bandwidth of the wireless interconnect. Consequently, simple and  low overhead based token passing MAC protocol has been  proposed in [5, 12] that ensure fairness. However, when the  utilization of the WI is low because of the low traffic loads, token  passing becomes energy inefficient. This energy inefficiency in a  token passing MAC protocol is because of the overheads of the  token flit circulation even when the WIs does not have data to  send. This waste of energy due to token circulation in low  wireless utilization can be avoided by using a CSMA based MAC  protocol. When the utilization of the WI is low, there is low  probability of collision between the transmitting WIs and hence  the consumed energy is due to valid transmission only. However,  the performance and energy efficiency degrades in a CSMA based  MAC due to excessive collision when the WIs are highly utilized  in high traffic load. The dynamic MAC proposed in this paper,  has two operational modes (token passing mode and CSMA  mode) based on the utilization of the WIs.  When the utilization of  the WIs is high, the dynamic MAC operates in a token passing  mode. As the wireless utilization is low it switches and operates in  the CSMA mode. To enable this mechanism, each WI will be  equipped with a dynamic MAC unit. The following subsections  discuss the modes of operations and the proposed mechan ism to  switch between these modes.  3.2.1 Token passing Mode  The dynamic MAC operates as a token passing MAC when the  wireless utilization is higher than a pre-set threshold. In the token  passing mode, the access of wireless medium is granted by  possessing a token flit, circulating between the WIs in a roundrobin fashion using the wireless interconnection itself. A WI can  transmit data through the wireless medium only if it possesses the  token. The round robin circulation of the token to ensure fair  access of the wireless medium is maintained by using the address  of the WI that is supposed to receive the token next and the  address of the WI that has released it, in the token [22]. The  address of next WI is necessary to distinguish the intended WI  from other WIs as the adopted on-chip antennas are not  directional and all the WIs receive the token flit. Moreover, the  address of the WI releasing the token is required by all WIs to  update the utilization metric for the releasing WI in their local  array used to monitor the utilization of the WIs. These fields in  the token flit are required for the switching mechanism discussed  later in this section. The token is released to the next WI when the  current WI has no more data flits to transmit or has transmitted  one whole packet. After the token is received successfully at the  next WI, it checks the wireless buffers for flits. If the WI has flits  to send, it broadcasts a transmit flit with the address of the  destination WI and the number of flits for that WI. The number of  flits to send in transmit flit will indicate the duration of  transmission to the other WIs. Hence, upon receiving the transmit  flit, all the WIs expect the destination set a wake-up timer and  the  transceiver at the WIs switch to sleep mode for that period.  Consequently, the energy consumption in the token passing mode  is reduced to the consumption of only the sending and receiving  WIs.  3.2.2 CSMA mode  The dynamic MAC operates in the CSMA mode when the  wireless utilization is low. In this mode, all the WIs sense the  wireless channel for ongoing transmission. When the channel is  sensed to be free and the WI has data to send, the WI transmits a  small query flit, only with the address of the destination WI it  wants to send the data to. As the query flit reaches the desired WI,  the WI will copy the content of the query flit (i.e. the address) and  broadcasts a reply flit containing this address. As the sender WI  receives back this reply flit, it creates a transmit flit with the  number of flit it will be sending to the destination WI and  broadcasts this transmit flit. Both the query flit and transmit flit  are received by all the WIs, only the intended WI will keep its  receiver on for the time period mentioned in the transmit flit.  Other WIs start a wake-up timer initialized with the value  provided in the transmit flit and goes to sleep. This helps in  maintaining energy-efficiency further for the dynamic MAC in the  CSMA mode. After the timers expire, all the WIs wakes-up and  goes back to their sensing mode.   A collision is detected if there is a failure in receiving the reply flit  at the sender WI within a specific time after the query flit is sent.  In case of a collision, the colliding WIs backs off from  transmitting through the wireless channel for time BT given by,  𝐵𝑇 = 𝑟 × 𝑛𝐵 × 𝑡𝑓𝑙𝑖𝑡  (1)  where nB is the number of flits a WI must wait before trying to  access the wireless channel, tflit is the time to transmit a flit over  the wireless medium and r is a random integer generated by a  linear feedback shift register (LFSR) within the range 0 to R.  Here, R is the maximum number of collisions any WI can have.  This range is chosen such that it is large enough to ensure that the    MAC mechanism switches from CSMA to token mode before any  particular WI has so many collisions. Such back-off, reduces the  probability of the WIs from retransmitting at the same time after a  collision and  reduces probability of collision  in  future  transmissions [19]. When a WI enters the back-off state it can  only receive flits transmitted through the wireless medium. In the  back-off period, if a WI receives a query flit and a transmit flit,  the back-off timer is paused till the wake-up timer expires. The  back-off timer restarts counting as the wake-up timer expires. The  dynamic MAC unit described below enables the switching  between the token based and CSMA modes. The structures of the  various control flits that are required in both token passing and  CSMA mode is shown in Figure 2.  3.2.3 Dynamic MAC Unit  The dynamic MAC unit enables the switching between token  mode and CSMA mode.  This switching is based on monitoring  the utilization metric of the WIs. The utilization of a WI is  measured as the number of flits in the wireless buffers of that WI.  Hence the utilization of the WI is an indication of the  instantaneous traffic load on the WI. If this load is higher than an  upper threshold the MAC scheme switches from CSMA to token  passing. When the utilization is lower than a lower threshold the  MAC switches from token passing to the CSMA mode. The two  separate thresholds are used to avoid frequent switching between  the  two modes and are determined experimentally. The  architecture of the dynamic MAC unit is shown in Figure 3. The  dynamic MAC unit contains a back-off counter (Bcounter) and a  wake-up counter (Wcounter). There are five status registers. The  status register CMs is used to store the current operational mode of  the dynamic MAC, T is used as an indicator of token possession  when CMs is set to token passing mode, IDself and IDnext are  registers to store the ID of the WI itself and the next WI in the  round robin token circulation order. A register UTILIZATIONself  stores  the utilization for  the WI. An array of registers  UTILIZATION_ARRAY is used to store the utilization of the  other WIs. The switching unit (SU) is the control unit that decides  on switching between different operational modes based on the  utilization of the WIs. The next two subsections explain the  switching mechanism.  3.2.3.1 Switching from token passing mode to CSMA  mode  The dynamic MAC switches from the token passing mode to the  CSMA mode when the utilization of no more than one WI is  greater than the lower threshold. In the token passing mode, the  WI that possesses the token, passes it to the next WI after  transmitting all the flits in the WI to be sent. This token is passed  to the next WI in the form of a token flit. In the dynamic MAC,  this token flit is used to instantiate the switching from token  passing mode to CSMA mode. Before transmitting this token flit,  the WI currently possessing the token compares the value of its  Figure 2. Flit Structures for a) Token flit b) Control flit c)  Transmit flit d) Query flit e) Reply flit  UTILIZATIONself  register  and  all  registers  in  the  UTILIZATION_ARRAY with the pre-set lower threshold value.  If the value for no more than one utilization register is greater than  the lower threshold, the dynamic MAC switches to CSMA mode.  This switching is initiated by updating value of CMs register to  CSMA mode at the WI possessing the token. Then, the token flit  is constructed using the updated CMs value and broadcast to the  other WIs to enable them to switch simultaneously.  The fields,  IDs, IDR and the Utilization of the token flit are populated using  the  IDself,  IDnext and UTILIZATIONself  registers of  the  transmitting WI. The value in the CMs register is used to set the  field called Mode in the token flit. To indicate the token being  passed to the next WI, the Token field of the token flit is set to 1.  Then the WI possessing the token transmits this token flit and  updates the value in the T register to 0 as it no longer possess the  token. On the other hand, as other WIs receive this token flit they  will update the value of their CMs status register with the content  of the Mode field of the token flit. Hence, all the WIs will switch  to CSMA mode. The value of the T register is updated only for  the WI for which the value in IDR field matches its own ID (i.e.  IDself) indicating this WI now possesses the token.  3.2.3.2 Switching from CSMA mode to token passing  mode  A switching from CSMA mode to the token passing mode occurs  when the utilization of more than one WIs are greater than the  upper threshold. In the CSMA mode, after a WI is done with  transmitting the number of flits mentioned in the transmit flit, it  transmits a control flit similar to the token flit. Before transmitting  this control flit, the transmitting WI determines the number of WI  with a utilization greater than the upper threshold by comparing  the values in the UTILIZATIONself and UTILIZATION_ARRAY  registers with the upper threshold. If the utilization for more than  one WI is greater than the upper threshold the dynamic MAC  switches to token passing mode by updating the value of the CMs  register to token mode at the transmitting WI. This updated CMs  value is used as the Mode field in the control flit to initiate the  switching from CSMA to token mode at the other WIs. Both ID  fields (i.e.IDS and IDR) in the control flit are set to IDself of the  sender WI. The Token field is set to 0 as no token is passed in the  CSMA mode. The value of the UTILIZATIONself register is  appended in the control flit as the Utilization field. As other WIs  receive this control flit, they will update the value in their CMs  register with the Mode field of the control flit and will switch to  token mode simultaneously. In all the WIs receiving the control  flit, the value in the UTILIZATION_ARRAY corresponding to  the sending WI (i.e. IDs field in control flit) is updated with the  utilization value from the control flit.   In either CSMA or token mode, when a particular WI acquires  access to the medium it sets up an on-demand wireless link to the  destination and this link is disabled once the access is relinquished  for the next WI.   3.3 Antenna and Transceiver  In addition to the novel topological concepts and dynamic-MAC,  the two principal components of the WI are the antenna and the  transceiver. The on-chip antenna for the WiNoCs has to provide  the best power gain for the smallest area overhead. A metal zigzag  antenna has been demonstrated to possess these characteristics  [21]. Therefore in this paper we consider the antenna design from  [5] which provides a 3dB bandwidth of 16GHz with a center  frequency around 60GHz for a communication range of 20 mm.  For optimum power efficiency, the quarter wave antenna uses an      axial length of 0.38 mm in the silicon substrate. This antenna is  not directional  thus enabling communication  towards all  directions to WIs located in all parts of the NoC.  To ensure high throughput and energy efficiency, the WI  transceiver circuitry has to provide a very wide bandwidth as well  as low power consumption. Hence we adopt the transceiver design  from [5] where low power design considerations are taken into  account at the architecture level. Non-coherent on-off keying  (OOK) modulation is chosen, as it allows relatively simple and  low-power circuit implementation.  3.4 Packet Flow Control and Routing  We adopt wormhole switching in both wired and wireless links in  the proposed wireless NoC. Packets are broken down into smaller  flow control units (flits) which can travel inter-switch links in one  clock cycle [13]. The first flit of the packet called the header  carries all the address information and gets routed to the final  destination. The body flits simply follow the established path.  Virtual channel based three-stage pipelined switch architecture is  adopted for all the switches and hubs [25]. The WI is  implemented as a separate port in each hub (Figure 1).   In the hierarchical wireless NoC data is routed via a threshold  based routing, which chooses the underlying mesh links if the  source-destination pair is nearer than the threshold. Otherwise, the  data is routed through the hubs. The packets get routed to the hub  in the subnet of the source node and then get routed to the hub in  the subnet of the destination node. Then the packet gets routed  from the hub to the final destination. Routing through the hubs is  adaptive in the sense that if the distance between source and  destination hubs is more than one hop then the packets use the WI  to reach the hub in the destination subnet directly using the onehop wireless channel.  Deadlock is avoided in this routing mechanism as the lower and  the upper level of the hierarchy are completely separate physical  networks which do not share any link or router. At each router in  the lower level mesh, the destination address is checked and if the  destination is less than the threshold, Th, then X-Y routing is  adopted through the mesh routers using only the NSEW links. On  the other hand, if the destination is more than Th away then the  packet is sent to the hub of the subnet of the current router  through the additional link connecting the router to the hub. Once,  Figure 3. Architecture of the dynamicMAC Unit  Table 1: Characteristics of the Dynamic MAC unit  Property  Value  Power  Area  Delay  1.6374 mW  2433.08 µm2  330ps  the packet gets routed to the hub it is in a different physical  network and due to the adopted routing policy will never use the  links of the lower level mesh again. The upper level network  using hubs are interconnected with wired links to form a mesh  topology among the hubs while also being augmented with  wireless shortcuts. The wireless links do not require physical links  but can form on-demand links between any pairs of hubs forming  a virtual all-to-all wireless network between the hubs. The routing  algorithm is simply to try to send every packet arriving at a hub  through the direct wireless links to the destination hub in one-hop  if the destination hub is more than one-hop away over the wired  mesh links between the hubs. In case the VCs of the wireless port  are all occupied or the destination hub is only one hope away from  the current hub, then the packet is routed through the wired mesh  link following X-Y routing. On reaching the hub in the destination  subnet the packet is routed to the destination core through the  direct wired link from the hub to the final destination. Again, as  the wireless links are direct point to point and are not shared with  any wired paths, they do not contribute to any cyclic dependencies  involving either wired or wireless links. Hence, the routing in the  upper level of the hierarchy is deadlock-free. In this way, by  avoiding deadlock in both lower and upper levels of the hierarchy,  the overall adopted routing policy is deadlock free.  4. EXPERIMENTAL RESULTS  In this section, we evaluate the performance, energy efficiency of  the reconfigurable WiNoC architecture. The performance is  measured as the maximum achievable bandwidth which is the  peak sustainable data rate in number of bits successfully reaching  their destination per second. The energy efficiency is measured as  the packet energy, defined as the average energy required to  successfully route an entire packet from source to destination. The  packet energy includes both the energy in the switches as well as  the energy in the links for a packet. The link energy is calculated  by determining the energy required to send the packet through the  wired or wireless interconnects. The delay and energy dissipation  on the wired link is obtained through Cadence simulations taking  into account the specific lengths of each link based on the  established topology in the 20mmx20mm die. The wireless  transceiver adopted from [5] is shown to dissipate 2.3pJ/bit  sustaining a data rate of 16Gbps with a bit-error rate (BER) of less  than 10-15 while occupying an area of 0.3mm2 in TSMC 65nm  CMOS process. The network switches are synthesized from a  RTL level design using 65nm standard cell libraries from CMP  [8], using Synopsys. The delay and energy dissipation of these  digital components are then incorporated in the energy model to  evaluate the packet energy. The NoC switches are driven with a  clock of frequency 2.5 GHz and Vdd of 1V. NoC architecture is  characterized using a cycle-accurate simulator that models the  progress of the data flits accurately per clock cycle accounting for  those flits that reach the destination as well as those that are  stalled. Ten thousand iterations were performed eliminating  transients in the first thousand iterations. The width of all wired  links is considered to be same as the flit size, which is considered  to be 32 bits. We consider a moderate packet size of 64 flits for all  our experiments. For the mesh network, each switch is considered  to have 4 VCs with a buffer depth of 2. As the hubs in the        hierarchical network handles a large volume of traffic, an  increased number of VC of 8 with 16 buffer depth is used. Similar  to the hierarchical ports the ports associated with the WIs have an  increased buffer depth of 16 flits. For the token passing MAC the  maximum number of flits that a WI can transmit after possessing  the token is set to be 64 flits long. We have used both synthetic  and application specific traffic patterns in our experiments.  Uniform random traffic pattern where each core can address  packets to any other core with equal probability is used as the  synthetic pattern. Application-specific traffic patterns are obtained  from several SPLASH-2 [30], PARSEC [3] and MapReduce [27]  benchmarks. These traffic patterns vary in characteristics from  computation intensive to communication intensive in nature. We  use GEM5 [4], a full system simulator, to obtain detailed  processor and network-level  information. For full system  simulations we consider a system of 64 alpha cores running linux  within the GEM5 platform for all experiments. The memory  system is MOESI_CMP_directory, setup with private 64KB L1  instruction and data caches and a shared 64MB (1MB distributed  per core) L2 cache. The original frequency of traffic interaction  between the cores, fij, is obtained from GEM5 and used to  generate the benchmark traffic patterns in the NoC simulator to  model the WiNoC.  4.1 Overheads of the Dynamic MAC unit  In this section, we evaluate the overheads for the dynamic MAC  unit in terms of area, power and delay. These characteristics are  then incorporated in the NoC simulator to account for the  overheads. To evaluate the overheads, the RTL design of the  dynamic MAC unit was synthesized using 65nm standard cell  libraries from CMP [8], using Synopsys. The power, area and  delay characteristics of the dynamic MAC unit are listed in Table  1. The total area required for all the dynamic MAC units in the  proposed reconfigurable architecture is only .004% of the overall  chip area for a system size of 64 cores with 8 subnets or WIs and  a MAC unit in each WI. The power consumed by each dynamic  MAC unit is 4% of the wireless transceiver power. This power  overhead is considered to evaluate the  energy consumption in  data transfer as discussed in the next subsection.  The delay of the dynamic MAC unit is less than a clock cycle  which is 400ps (2.5GHz clock frequency). However, the dynamic  MAC unit operates in parallel with data transmission between the  WIs. Due to this parallel operation, the dynamic MAC unit can  decide on the operational mode for communication while there is  an ongoing transmission between two WIs. Hence, irrespective of  the time required by the dynamic MAC unit, it has no effect on  the data transfer rate between the WIs.   4.2 Comparative Performance Evaluation of  the Reconfigurable Wireless NoC  The peak bandwidth and packet energy at network saturation for a  system size of 64 cores with uniform random traffic distribution is  shown in Figure 4. We have used conventional wired mesh  architecture as a baseline to compare the proposed architecture. In  a mesh, each packet has to pass through multiple hops to reach the  destination. At each hop a packet occupies resources (i.e. VC)  before all the flits including the tail flit is successfully routed to  the next switch. Again, as dimension order routing is used for  mesh, the packets first travel in the X dimension and then in the Y  dimension. Hence, some switches that work as relays for other  communicating cores, handle significantly higher volume of  traffic. This imbalance of traffic load among different switches  results in an increased congestion. As a result, the packet energy  4 3.5 3 2.5 2 1.5 1 0.5 0 ) s p b T ( h t d i w d n a B Bandwidth Packet Energy 400 350 300 250 200 150 100 50 0 ) J n ( y g r e n E t e k c a P Mesh HiMesh HiMesh-2 HiWiMesh Figure 4. Bandwidth and packet energy for the proposed  architecture.  is significantly higher and the peak bandwidth is lower compared  to the HiMesh architecture discussed in this paper. The average  number of hops required by a packet to reach destination in  HiMesh is 1.5 times lower than the mesh. This reduction in  average hop-count enables a more efficient packet transmission  between any source to destination, which results in increasing the  system energy efficiency and bandwidth. To further optimize the  bandwidth we distribute the traffic in a way that does not create  excessive load on the hubs through the threshold based routing.  The performance is optimized when a threshold of 6 is chosen.  The performance and energy efficiency of the HiMesh can be  further improved by augmenting it with the energy efficient  wireless links as can be seen from Figure 4. Although as noted in  section 3, the total additional wireless bandwidth is only 16Gbps,  which is less than 1% of the aggregate data rate of the NoC, its  impact on the performance is 4.7% higher. This is because the  improvement in performance is not just due to the raw bandwidth  of  the wireless  interconnection but also because of  the  reconfigurable on-demand links between hubs. To illustrate the  benefit of the reconfigurable architecture, we compare the  proposed HiWiMesh architecture with a WiNoC architecture (i.e.  HiWiMesh-2) with a fixed wireless link between two diagonally  located hubs. With only one fixed wireless link between two hubs  the performance and the packet energy is almost similar to that of  the HiMesh. However, in HiWiMesh, this wireless link can be  established on demand between hubs, providing a better  connectivity. Consequently, there is a 3.4% increase in the peak  bandwidth and 8% reduction in packet energy for the proposed  architecture compared to the architecture with a dedicated  wireless link between two hubs.  4.3 Performance of different MAC schemes  In this section, we present the efficiency and energy consumption  of the reconfigurable WiNoC architecture with different MAC  mechanisms. The efficiency is measured as the ratio between the  throughput the flit injection load. The throughput is measured as  the number of flits successfully routed to the destination for each  core per cycle. Injection load is measured as the number of flits  injected into the NoC on an average per core per cycle. We  compare the dynamic MAC mechanism with token based and  CSMA based MACs under different traffic injection load with  uniform random traffic pattern. We have used different flit  injections (i.e. 1, 0.1 and 0.01 flits/core/cycle). The efficiency of  different MACs is shown in Figure 5. In high injection loads, the  WIs handle a higher volume of traffic. With higher volume of  traffic passing through the WIs, multiple WIs needs to access the  wireless channel frequently. Consequently, this increases the rate  of collision in CSMA based MAC resulting in a degraded                n o i t c j e n I / t u p h g u o r h T 1 0.8 0.6 0.4 0.2 0 Throughput/Injection (CSMA MAC) Throughput/Injection (Token MAC) Throughput/Injection (Dynamic MAC) Packet Energy (CSMA MAC) Packet Energy  (Token MAC) 10000 1000 100 10 1 ) J n ( y g r e n E t e k c a P 1 0.1 0.01 Injection Load (flits/core/cycle)  1 0.1 0.01 Injection Load (flits/core/cycle)  Figure 5. Throughput/Injection for different MACs with  varying injection load architecture.  efficiency. On the other hand, in a token based MAC, the collision  is prevented using a token circulating between the WIs. This  reduction of collision in the wireless transmission results in a  higher efficiency for the token based medium access mechanism.  The dynamic MAC is as efficient as the token based MAC in high  injection load as it operates in a token passing mode due to the  high utilization of the WIs. As the injection load reduces to 0.01  flits/core/cycle, the number of collisions also decreases resulting  in an improved efficiency for the CSMA based MAC. In the token  passing MAC, the efficiency degrades due to token returning  period to the WI willing to transmit data which is equal to the  number of WIs in worst case. The dynamic MAC has a similar  efficiency as the CSMA based MAC in low injection load. This is  because, in low injection loads, the WI utilization is also low and  the dynamic MAC operates in CSMA mode eliminating the  timing and energy overheads of the token circulation. Hence, due  to the adaptive nature of the dynamic MAC, it is able to achieve a  better performance than a token based or a CSMA based MAC  under different injection loads.  The energy consumption of the proposed WiNoC architecture  with different MACs is shown in Figure 6. Due to the similar  reasons discussed above, CSMA based MAC has a higher energy  consumption in high injection loads. With high rates of collisions  most packets are either stuck at the WIs or are diverted through  the wireline paths increasing the packet energy consumption  relative to the token based WiNoC. However, the token based  MAC has a high energy consumption in low injection load cases  due to the energy wastage for the frequent token circulation  without any WI having significant amount of data to send using  the token. The dynamic MAC is the most energy efficiency MAC  in all the injection loads considered in this paper because of the  adaptive switching capability that enables it to change between  the different MAC modes.  4.4 Comparison of different MACs for  Application Specific traffic patterns  We compare the energy efficiency of the token based MAC and  the dynamic MAC for application specific traffic patterns in this  section. Ten application specific traffic pattern is used to compare  the proposed reconfigurable architecture with token based MAC  and dynamic MAC. We have used two PARSEC, three SPLASH2 and five MapReduce benchmark traffic patterns for the  application specific traffic patterns. These traffic patterns vary in  their injection load due to their varying communication-tocomputation ratio. Hence, the chosen application specific traffic  patterns capture both high and low injection loads. The packet  Figure 6. Packet Energy for different MACs with varying  injection load.  energy for the different traffic patterns are shown in Figure 7. As  can be seen from Figure 7, the dynamic MAC has similar energy  efficiency as the token based MAC for the applications (i.e. PCA,  MatrixMul, StringMatch, Kmeans, LinearRegrssion)  in  the  MapReduce benchmark suite. This is because all these traffic  patterns here have a higher WI utilization due to higher traffic  injection loads. As mentioned in the previous section, in the  dynamic MAC, when the WI utilization is greater the upper  threshold for more than one WIs, the dynamic MAC operates as a  token based MAC and hence the performance is similar to that of  the token based MAC. On the other hand, for PARSEC and  SPLASH-2 benchmark traffic patterns, the injection load is low  and hence the WI utilization is lower than the lower threshold. In  these cases, the token based MAC has higher energy consumption  due to the frequent token circulation compared to the dynamic  MAC which operates in the CSMA mode. This is because, the  dynamic MAC operates as a CSMA based MAC when the  utilization of the WIs is low. In CSMA based MAC there is no  energy overhead for passing the token. Hence, the proposed  dynamic MAC has better energy efficiency for different  benchmark traffic patterns discussed in this paper, which utilize  the NoC to different.  5. Conclusions and Future Work  Wireless interconnections are one of the emerging interconnect  paradigms that can emerge as a solution to the scalability and  energy efficiency problems of the large NoCs. The unique  characteristics of the wireless interconnects compared to other  emerging interconnects like photonic and RF interconnects is that  there is no need for routing a physical channel. Hence, the  wireless interconnection is inherently reconfigurable. Using this  feature we can exploit the reconfigurability of a wireless NoC  ) J n ( y g r e n E t e k c a P 200 180 160 140 120 100 80 60 40 20 0 Token based MAC Dynamic MAC Figure 7. Packet energy with benchmark traffic.                        topology to provide on-demand links between communicating  nodes with dynamically varying traffic patterns. The medium  access mechanism studied in this paper achieves maximal  utilization of the wireless bandwidth for both low and high traffic  loads by switching between CSMA and token passing protocols.  In addition, the MAC itself establishes the wireless links as  required for data communication between hubs in the subnets. In  this way the wireless links can be used to create on-demand links  depending on traffic requirements and be used with maximal  efficiency to improve data rate as well as energy-efficiency of  large NoC based multicore chips. Future heterogeneous Systemson-Chips with CPUs, GPUs, ASICs and distributed memory  systems will benefit from such dynamic, adaptive NoC fabrics  providing on-demand bandwidth and energy-efficient connectivity  as and when required.  6. ACKNOWLEDGMENTS  This work was supported in part by the US National Science  Foundation (NSF) grant CCF-1162123.   7. "
On-Chip Millimeter Wave Antennas and Transceivers.,"The main mechanisms responsible for performance degradation of millimeter wave (mmWave) and terahertz (THz) on-chip antennas are reviewed. Several techniques to improve the performance of the antennas and several high efficiency antenna types are presented. In order to illustrate the effects of the chip topology on the antenna, simulations and measurements of mmWave and THz on-chip antennas are shown. Finally, different transceiver architectures are explored with emphasis on the challenges faced in a wireless multi-core environment.","On-Chip Millimeter Wave Antennas and Transceivers   Ofer Markish, Oded Katz, Benny Sheinman, Dan Corcos, and Danny Elad  IBM Research - Haifa  Mount Carmel  Haifa 31905, Israel  +972-4-8296571  {oferma, katzo, bennys, danco, dannye}@il.ibm.com  in size and speed with present day cores. In order to accommodate  these requirements, the WNoC needs to operate using carrier  frequencies at the mmWave (30-300GHz) or sub-mmWave  (>300GHz) range, since this reduces both the occupied die area, the  energy per bit, and increases the available bandwidth.      Since on-chip antennas often suffer from low efficiency [2] and  degraded characteristics, one has to first understand the effects  caused by the chip environment on the antenna. When designing  the WNoC system, these effects should be incorporated with further  interactions taking place within the multi-core environment.     The paper is organized as follows: in section 2, the main reasons  for the performance degradation of on-chip antennas are explained  and possible solutions are reviewed. The design and measurements  of W-band (75-110 GHz) and THz (0.5-2 THz) on-chip antennas  are presented in section 3. An overview on transceiver architectures  is given in section 4.  In section 5, the challenges that arise in a  multi-core environment are discussed followed by a conclusion in  section 6.   2. OVERVIEW OF ON-CHIP ANTENNAS  2.1 The Chip Environment   A typical cross-section of a chip is depicted in figure 1. The cross-  section consists of a silicon substrate and a metal stack located on  top of the substrate. The stack includes n metal (e.g. Copper or  Aluminum) layers M1-Mn, where usually n varies between 5 and  10.   ABSTRACT  The main mechanisms responsible for performance degradation of  millimeter wave (mmWave) and terahertz (THz) on-chip antennas  are reviewed. Several techniques to improve the performance of the  antennas and several high efficiency antenna types are presented.  In order to illustrate the effects of the chip topology on the antenna,  simulations and measurements of mmWave and THz on-chip  antennas are shown. Finally, different transceiver architectures are  explored with emphasis on the challenges faced in a wireless multicore environment.    Categories and Subject Descriptors  B.4.3 [Hardware]: Input/Output and Data Communica-  tions|Interconnections  General Terms  Measurement, Performance, Design, Experimentation, Theory.  Keywords  On-chip antennas, millimeter wave, terahertz, integrated circuit,  transceiver, wireless network on chip, multi-core.   1. INTRODUCTION  Multi-core microprocessors employ Network-on-Chip (NoC) for  core-to-core communication. Yet, wired based multi-hop NoCs,  suffer from high latency, limited data rate, and high power  consumption. In recent years it was suggested that a single-hop  wireless NoC (WNoC) can accommodate low-power high-speed  links between distant cores on a single die [1]. In a WNoC for intercore wireless communication, all the cores, as well as the wireless  transceivers and antennas have to be fabricated on a same silicon  die. Each processor core will include a transceiver module that has  to be implemented in a medium with a high capacity. This implies  that the on-chip antenna and transceiver should have a maximum  lateral size of a few hundreds of microns and that the data rate    should  be  of  several  tens  of  Gbps,  for  them  to  be comparable  Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that copies  bear this notice and the full citation on the first page. To copy otherwise, or  republish, to post on servers or to redistribute to lists, requires prior specific  permission and/or a fee. Requests permissions from permissions@acm.org.  NOCS '15, September 28 - 30, 2015, Vancouver, BC, Canada   © 2015 ACM. ISBN 978-1-4503-3396-2/15/09…$15.00   DOI: http://dx.doi.org/10.1145/2786572.2789983  Figure 1: Cross-section view of a typical chip.  The metals are separated by inter-level dielectric layers made of  silicon dioxide. Additional oxide passivation layers are placed  above the highest metal. The substrate height is usually around                                700 µm and the total metal stack height is around 15 µm. Typically,  the top one or two metals have a thickness of few microns, while  the bottom metals are less than a micron of thickness. Top metal  vias have a lateral size of few microns and bottom metal vias have  a lateral size of less than a micron. The typical conductivity of the  metal layers is around σm=107 S/m and that of the doped silicon  substrate is around σs=10 S/m (equivalent to sheet resistance of  rs  =10 Ω/sq or resistivity of ρs=1/σs.=10 Ω·cm). The real part of the  relative dielectric constant of the substrate is εr,s’=11.9 and that of  the silicon dioxide layers is εr,d’=4. The losses in the dielectric oxide  layers are negligible (εr,d’’~0). Note that substrate areas containing  active components will be more conductive due to the highly doped  diffusion regions.   2.2 The Effects of the Chip Environment   2.2.1  Substrate Losses  Part of the power fed to the antenna will not be radiated out of the  chip due to losses in the silicon substrate. The amount of power  dissipated in the substrate can be written as  ,                                  (1)  where V is the volume of the substrate, and E is the antenna’s  electrical field in the substrate. Since the field concentrations in the  silicon side tend to be large due to its large permittivity compared  to air, and since the conductivity of the silicon is relatively large,  Pdiss is usually non-negligible.   2.2.2 Substrate Surface Waves  Surface waves (SW) can be generated along metallo-dielectric  interfaces [3, 4], excited in patch antennas [5], and they can also be  interpreted as guided modes in dielectric slab waveguides [6]. The  last interpretation is useful since an antenna operating near the  substrate can be treated as an excited slab waveguide. Using the  modes expressions in the waveguide, the substrate thickness hsw  above which SW start to appear, is given by [7]   ,                                   (2)  where c=3·108 m/s is the speed of light. For f=200 GHz, we get    hSW =115 µm and therefore SW are likely to be generated. Since  the SW are confined to the substrate, they lead to efficiency  degradation. Moreover, in a substrate of finite lateral dimensions, a  portion of the SW may reach the chip edge and radiate. In this case,  the SW may interfere unpredictably with the antenna field, leading  to increased side-lobes, as well as pattern and polarization  distortion. Notably, in an on-chip antenna array, the SW can  increase the coupling between the elements and deform their  radiation pattern.   2.2.3 Metal Stack Considerations  By separating between the antenna and the substrate, and using the  lower metals as a screening ground plane, we can reduce the losses  and the SW in the substrate. However, this would result in a  relatively thin antenna. For example, a 200 GHz on-chip patch  antenna located 15 µm above the ground has a thickness of 0.02  wavelengths in matter. Typical patches would have bandwidth of  only a few percent and low efficiency under these conditions [7].     In addition to the thin metal stack, a minimum metal density is  often required by the foundry in order to ensure the wafer planarity  in the fabrication process.  Metal fillers might be added by the  foundry if the minimum metal density in the antenna area is not  achieved. These fillers can impair the antenna performance.  Moreover, some fabrication plants may require a chip-ring that  encloses the IC’s components and antenna area in order to protect  them from cracks during dicing. This chip-ring may interfere with  the antenna and should to be taken into account at the design stage.       Lastly, conductor losses in the metal stack may not always be  negligible. These losses depend on the field penetration depth into  the metal.  If the metal thickness of the antenna is smaller than the  penetration depth, the losses increase. Differently from the  relatively thick metals found in conventional on-package antennas,  the micron (and sub-micron) metal thickness in the chip, might not  be sufficiently thick. The field magnitude inside a metal of finite  conductivity decays exponentially. A specific skin depth is defined  by the place at which the field has fallen to 1/e from its value on the  surface edge:  ,                                      (3)  where µ=4π·10-7 H/m is the conductor’s permeability. For f=200  GHz and σm=107 S/m, the skin depth is δ=0.36 µm which is indeed  comparable to the metal thickness. By knowing the field  distribution on the antenna, the losses on the conductor can be  calculated similarly to (1).     The silicon losses, the surface waves, and the metal stack effects  were shown to degrade the on-chip antenna performance. In [8], a  slotted patch antenna with peak gain of -2 dBi, bandwidth of 7%   around 140 GHz and a cavity backed slot antenna with peak gain  of -2 dBi  and bandwidth of 3% around 140 GHz were reported. In  [9], an inverted F antenna with radiation efficiency of around 5%,  peak gain of -19 dBi at 61 GHz was presented. In [10], a Yagi  antenna with efficiency of 10% at 60 GHz was described.  2.3 High Performance On-Chip Antennas  Survey   Losses developed in the silicon can be reduced by increasing the  substrate resistivity. This can be done by using a proton  implantation process. After the implantation, the resistivity of the  substrate can reach a level of MΩ·cm. Explanation on the  implantation process and a comparison between planar inverted F  antenna (PIFA) on standard low resistivity silicon and implanted  high resistivity silicon are given in [11]. Better results were  achieved for the PIFA on the high resistivity substrate. In [12], a  Vivaldi antenna on high resistivity silicon was presented. In order  to further increase the efficiency, the antenna was elevated from the  substrate using special vias. The antenna achieved radiation  efficiency of 78%, peak gain of 5.5 dBi and more than 30% of  bandwidth around 150 GHz. Despite the potential for efficiency  improvement using proton implantation, this process may influence  the behavior of the Integrated Circuits (ICs) and therefore needs to  be carefully considered. Alternatively, in order to suppress SW and  increase the antenna efficiency, dielectric superstrates such as  lenses and resonators can be added to the standard silicon. In  addition, cavities can be etched using front-side or back-side post  processes to locally minimize the substrate thickness. The  superstrate and the etching concepts can be seen in figure 2.  In  [13], a cylindrical on-chip dielectric resonator antenna (DRA)  excited by a folded dipole achieved radiation efficiency of 45%,  peak gain of 1 dBi and bandwidth of 5% around 28 GHz. Meander  dipole excited DRA and slot coupled DRA were reported in [12]  and [14] respectively, achieving high performance as well. In a  work done by Shireen et.al. [15], lens coupled bow-tie antenna with            bandwidth of 55% around 85 GHz was demonstrated. In [16],  localized back-side dry etching was applied on a double folded  dipole. The radiation efficiency was 75%, the peak gain was 6 dBi,   and the bandwidth was 8% around 245 GHz. In [12], a cavity  backed monopole with radiation efficiency of 88%, peak gain of      6 dBi, and bandwidth of 13% around 130 GHz was proposed.         (a)                         (b)                         (c)                         (d)                                                   (a)  Figure 2: High efficiency on-chip antennas using (a) lens, (b)  DRA, (c) back-side etched cavity and (d) front-side etched  cavity.     The proton implantation, the superstrates and the cavities, all  .  required changes or supplements  to  the standard chip  manufacturing process. However, antenna types that use only the  standard fabrication methods, are naturally desired. In order to  improve the antenna performance over the thin metal stack, one can  increase the frequency and approach to the THz range [17]. Still, if  lower frequencies are used, meta-surfaces and periodic structures  such as high impedance surfaces (HIS), artificial magnetic  conductors (AMC) and electromagnetic band-gaps (EBG) [18] may  be able to improve the antenna performance. In [19], dipole over  HIS with peak gain of 1.2 dBi and bandwidth of 13% around 90  GHz was reported. In [20], dipole surrounded by EBG with  bandwidth of 12% around at 60 GHz was presented. Additional  techniques that do not require changes in the chip process can be  seen in [21] where a leaky wave antenna achieved gain of 4.9 dBi  and more than 26% bandwidth around 245 GHz. In [22] wire bond  antennas with radiation efficiencies larger than 50% at 40 GHz  were reported.   3. DESIGN AND MEASUREMENTS OF  ON-CHIP ANTENNAS                                                    (b)  3.1 MM-Wave On-Chip Loop Antenna                                                     (c)  A W-Band on-chip differential loop antenna was fabricated using  IBM 8HP SiGe process. Figure 3 shows two antenna versions  together with the chip surroundings. In order to measure the  antenna using standard ground-signal-ground (GSG) probes, a  differential to single ended balun transition , in the form of  microstrip (MS) to co-planar strip-lines (CPS), was added. To  improve the bandwidth of the antenna and in order to increase its  stability to the nearby chip-ring, an inner loop that effectively  thickens the antenna was added. Side walls were placed for  coupling reduction purposes, as future designs are planned to have  several antennas side by side. Special fill-exclude layers were  drawn in the layout with the purpose of preventing the foundry from  adding metal fillers. The exclude layers were located only in close  proximity to the antenna and a cross-sectional analysis of the  manufactured chips verified that their planarity was not affected by  deviant metal densities. The concentrations of the N+ and P+  diffusions in the P type substrate were brought to minimum using a  standard layout layer. Parametric  sensitivity  simulations   showed   Figure 3: On-chip differential loop antenna with a balun. (a) Die  photo.  (b) Layout. (c) 3D simulation model including all  relevant antenna surroundings.  that the antenna performance is stable over wide range of diffusion  conductivities. Since the loop is differentially fed, the antenna can  radiate without any adjacent ground plane. To improve the antenna  efficiency and suppress the surface waves, the substrate should be  thinned to 100 µm. This thickness is smaller than hsw inside the  band of operation while enabling high yield and mechanical  robustness. Return loss results of the first antenna version with the  balun, relative to 50 Ω and after launcher de-embedding, can be  seen in figure 4. Wide bandwidth of more than 35% between the    10 dB points can be observed with good agreement between the  simulation and the measurement. The simulated peak realized-gain  and radiation efficiency at 100 GHz, without the balun, are 1.9 dBi  and 63 % respectively. The three dimensional (3D) gain pattern can  be seen in figure 5. The end-fire behavior (radiation along the plane                                                                                           of the chip) is a result of the substrate influence and the loop  circumference, which is larger than a wavelength. S parameters  results of a back to back balun structure can be seen in figure 6.  Low one-side average loss of 0.7 dB can be approximated from the  graphs.    in figure 7. Two current modes travelling along the antenna wires  produce a relatively large bandwidth [23].  In order to increase the  antenna efficiency, back-side and front-side etching using a postproduction Microelectromechanical systems (MEMS) process  were carried out. After the MEMS process, the antenna is still  connected to the chip by two holding arms. The suspended antenna  is placed 70 um above an external reflecting surface (approximately  a quarter wavelength at 1.1 THz) to increase the peak gain.  Simulated return loss, relative to 200 Ω, can be seen in figure 8,  where a wide bandwidth of 65% around 1.25 THz can be observed.   Figure 4:  Return loss (relative to 50 Ω) of the on-chip loop  antenna together with its balun.                       (a)                                                   (b)  Figure 5:  Simulated 3D realized gain pattern at 100 GHz. The  orientation of the antenna relative to the pattern is added on the  right side.                            (a)                                               (b)  Figure 6: Back to Back balun results. (a) Return loss relative  to 50Ω.  (b) Insertion loss.  (b) Attenuation.  3.2 On-Chip THz Skirt-Shaped Antenna  A THz on-chip dual-polarized skirt-shaped antenna was fabricated  using IBM CSOI7RF CMOS-SOI process. The antenna can be seen                      (c)                                                   (d)  Figure 7: On-chip skirt-shaped antenna. (a) Die photo before  MEMS.  (b) SEM image after MEMS. (c) Layout. (d)  Simulation model.  Measured normalized 3D radiation pattern at 655 GHz can be seen  in figure 9. The simulated peak realized gain and radiation  efficiency at 1 THz are 7.1 dBi and 58% respectively. Although the  antenna is entirely released from the chip, the conductor losses are  not negligible. This is a result of the current distribution along the  antenna and a relatively high skin-depth to metal-thickness ratio of  around 0.3.  4. ON-CHIP MM-WAVE TRANSCEIVERS  4.1 CMOS Technology  Present day CMOS technology offers ever growing transistor cutoff  frequencies as transistor scaling progresses. While the scaling was  originally performed in order to improve the digital core  performance, it also became possible to raise a CMOS-based  transceiver’s carrier frequency into the mmWave and submmWave regions, thereby significantly increasing   the   modulated  signal bandwidth and at the same time decreasing the energy  required per bit of data. Promising results were achieved in recent  years: silicon RF based transmitters and receivers for multigigabit  communication at frequencies ranging from 60 to 400 GHz have  been published [24-27], while components reaching frequencies of    800  GHz are being investigated mainly for terahertz imaging  and                                                       wireless NoC systems [25-26] presented systems with a carrier  frequency around 60 GHz and bandwidth of ~20GHz. As CMOS  technology develops, systems with 120 GHz, 240 GHz and even  higher carrier frequencies will make it possible to increase the  channel’s data rate significantly.       The recommended approach for designing the transceiver should  be to use a topology as simple as possible (to reduce the dissipated  power and die area) employing a direct conversion architecture and  injection-locked Voltage Controlled Oscillators (VCOs) instead of  a full Phase Locked Loop (PLL).  A system level block diagram of  the transceiver is shown in figure 10 for both TDD (a) and FDD (b)  implementations. The half-duplex TDD system requires less area  for the transceiver as it requires a single antenna for both transmit  and receive channels at the expense of half the throughput of a full  duplex FDD system that requires two antennas and therefore larger  area. The system implementation is based on two mixers and a  synthesizer to generate the carrier signal. The synthesizer may be  injection locked to either the received signal or to the system clock  in a sub-harmonic synthesizer locking configuration. Additional  PA, LNA and BB circuitry may be required according to the link  budget which depends on distance between the cores and antenna  gain. Such elements have been demonstrated at extremely high  frequencies [27].  Figure 8:  Simulated return loss relative to 200 Ω.  Figure 9:  Measured   Normalized 3D   radiation    pattern    at  655 GHz.  sensing [24]. Published  CMOS   NoC   transceivers   demonstrated  data  modulation  on  a  high frequency carrier in the V band range  (45 - 65 GHz) [25-26]. High performance SiGe based mmWave  transceivers in the E band frequency range (71-86 GHz) were also  introduced [27].   4.2 Transceiver Architecture  The implementation of a wireless NoC transceiver follows different  considerations than those of other radio links, such as cellular  networks, backhaul, WiFi, and satellite communication systems.  While in these applications, over the air transmission bandwidth is  limited by regulation and consequently high modulation schemes  may be required, in a wireless NoC link, the system is isolated and  its  bandwidth is effectively unrestricted by regulations. In such  conditions, simple modulation schemes, such as On/Off Keying  (OOK), are recommended to improve the system power efficiency  per given data throughput. The low modulation order has the further  advantage of reducing the complexity and die area of the required  modulator and demodulator circuits. In order to incorporate the  envisioned wireless NoC  transceivers  in advanced CMOS  technologies, many challenges need to be overcome. The large  bandwidth requirement compels the use of a carrier frequency in  the upper mmWave or sub-mmWave range. Although technology  scaling allows using CMOS devices at mmWave or even THz  frequencies, aspects such as the device parasitics, low supply  voltage, device dimension limitations, and the complex metal stack  (which adds parasitic intrinsic inductance) limit the transceiver  operation frequency and performance. Previous publications on  (a)  (b)  Figure 10: Transceiver system block diagram, (a) TDD halfduplex implementation, (b) FDD full-duplex implementation.  4.3 Circuit Topology  The design of the NoC for a multicore processor is further  complicated by the small available area, power budgets, substrate  noise, and the use of a technology optimized  for  digital  operation   rather than RF-oriented. These challenges can be addressed by  the   use of forward body biasing to lower the threshold voltage [25], the                               inclusion   of    dedicated    CMOS    devices   with   improved   RF  performance, and techniques to reduce substrate noise. Yet, most  importantly, the circuit topology needs to be simplified using low  voltage headroom stages, and omitting and any redundant feature.  The conventional single-balanced Gilbert cell topology, which  requires increased headroom was abandoned in favor of a topology  with transformer based up and down converting mixers, as shown  in figure 11. In the up-converting mixer, the Local Oscillator (LO)  signal is fed through a transformer to the switching pair source,  while the Base Band (BB) signal is fed to the gate. The transformers  not only enable the coupling of LO feed, and RF output signals, but  also provide the bias to the switching transistors. This topology,  thus, allows reduction of the voltage headroom as there is no need  for current sources or extra load elements. The use of transformers  reduces the die area, since the transformers are implement in top  (BEOL) layers that overlap the lower metals (FEOL) and  transistors which are used for transceiver circuitry and for the actual  processor core. The down converting mixer consists of a single  transformer, which serves as a balun, used to feed the switching  stage pair with a differential RF input, and also for biasing the  transistors sources. The LO signal is fed to the gates of the  switching stage, while the BB outputs are sampled on resistive  loads on the stage drains.                           (a)                                             (b)  Figure 11: Schematics of (a) Up-conversion and (b) Downconversion mixers.  5. THE MULTI-CORE ENVIRONMENT  The chip effects discussed in section 2 were mainly relevant to  areas that are close to the antenna. These areas lie in the antenna  near-field region and have typical radius of one wavelength around  the antenna [28]. The effects can be predicted at the design stage  using full electromagnetic (EM) simulation tools such as HFSS or  CST. In a multi-core environment, additional effects arising from  the package and the interaction with the cores need to be  considered. Being located in the far field of the antenna, the core  environment does not necessary have an impact on the gain and  matching of the antenna. However, the environment can have an  effect on the link between the transmitting and receiving antennas  by causing increased path and polarization losses, and limiting the  data rates. As today’s computing power increases, the whole  environment may be solved directly using full EM tools . Still, for  very high frequencies, other methods might be preferable. The  methods can exploit the periodicity of the structure and solve only  a unit cell area or take advantage of the planar nature of the  structure and calculate the environment effects using fast two  dimensional calculations. Another possible approach is to use high  frequency (short wavelength) asymptotic ray methods such as  geometrical optics (GO), geometrical theory of diffraction (GTD),  and unified theory of diffraction (UTD) [29]. In the multi-core  environment, the rays can be secularly reflected from surfaces,  travel along interfaces, be scattered from finite size obstacles, be  scattered from rough surfaces (diffuse reflection [30]), and be  diffracted from corners. The different propagation mechanisms are  shown in figure 12.           (a)                 (b)                   (c)                 (d)                (e)  Figure 12: Ray propagation mechanisms in a multipath  channel. (a) Specular Reflection. (b) Rays along an interface.  (c) Scattering from a finite-size object (d) Rough surface  scattering.  (e) Diffraction.  The link between two antennas can be calculated by properly  weighting the rays according to the antenna pattern and tracing the  rays in the channel. An example of ray tracing analysis in a multicore environment can be seen in [31]. The associated power delay  profile, the RMS delay spread and the coherence bandwidth that  may limit the data rates in the multi-path dispersive channel are also  presented. In [32], Time domain analysis of a channel is carried out.   In [33], channel environment containing metallic strips between  two zig-zag antennas was explored.  6. CONCLUSION  The main reasons for performance degradation in on-chip antennas,  such as lossy substrate and thin metal stack were explained.   Possible approaches for improving the performance, such as  increasing the substrate resistivity, using dielectric superstrates,  etching cavities and adding meta-surfaces, were reviewed.  Simulations and measurements of high efficiency W-Band on-chip  loop antenna and THz skirt-shaped antenna were presented. Design  guidelines for transceivers that can operate efficiently in a multicore environment were given, as well as tools to determine the  propagation mechanisms in the multipath channel. This brief  overview is meant to introduce the designers to the challenges and  methods relevant to the design of future WNoC systems.   7. ACKNOWLEDGMENTS  The authors would like to thank Prof. Ullrich Pfeiffer, Richard Al  Hadi, and Hans Keller from the University of Wuppertal for their  help with the measurements of the THz radiation pattern. The  authors also wish to acknowledge Dr. Thomas Morf of IBM  Research - Zurich for the joint development of the micromachined  THz antenna.  8.  "
Data Criticality in Network-On-Chip Design.,"Many network-on-chip (NoC) designs focus on maximizing performance, delivering data to each core no later than needed by the application. Yet to achieve greater energy efficiency, we argue that it is just as important that data is delivered no earlier than needed. To address this, we explore data criticality in CMPs. Caches fetch data in bulk (blocks of multiple words). Depending on the application's memory access patterns, some words are needed right away (critical) while other data are fetched too soon (non-critical). On a wide range of applications, we perform a limit study of the impact of data criticality in NoC design. Criticality-oblivious designs can waste up to 37.5% energy, compared to an idealized NoC that fetches each word both no later and no earlier than needed. Furthermore, 62.3% of energy is wasted fetching data that is not used by the application. We present NoCNoC, a practical, criticality-aware NoC design that achieves up to 60.5% energy savings with no loss in performance. Our work moves towards an ideally-efficient NoC, delivering data both no later and no earlier than needed.","Data Criticality in Network-On-Chip Design Joshua San Miguel University of Toronto Toronto, Canada joshua.sanmiguel@mail.utoronto.ca Natalie Enright Jerger University of Toronto Toronto, Canada enright@ece.utoronto.ca ABSTRACT Many network-on-chip (NoC) designs focus on maximizing performance, delivering data to each core no later than needed by the application. Yet to achieve greater energy eﬃciency, we argue that it is just as important that data is delivered no earlier than needed. To address this, we explore data criticality in CMPs. Caches fetch data in bulk (blocks of multiple words). Depending on the application’s memory access patterns, some words are needed right away (critical ) while other data are fetched too soon (non-critical ). On a wide range of applications, we perform a limit study of the impact of data criticality in NoC design. Criticalityoblivious designs can waste up to 37.5% energy, compared to an idealized NoC that fetches each word both no later and no earlier than needed. Furthermore, 62.3% of energy is wasted fetching data that is not used by the application. We present NoCNoC, a practical, criticality-aware NoC design that achieves up to 60.5% energy savings with no loss in performance. Our work moves towards an ideally-eﬃcient NoC, delivering data both no later and no earlier than needed. Categories and Subject Descriptors C.1.2 [Processor Architectures]: Multiple Data Stream Architectures—interconnection architectures 1. INTRODUCTION As CMPs scale to hundreds and thousands of cores, the NoC becomes a signiﬁcant factor in the cost of accessing data from memory. Traditional processor designs have focused on accessing data with minimal latency, fetching in bulk and employing prefetchers to deliver data no later than needed by the application. However, energy consumption is now a ma jor concern, with NoC energy expecting to grow infeasibly high as we continue towards lower technology nodes [7]. Our work argues that NoCs should deliver data both no later and no earlier than needed to achieve ideal eﬃciency. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM. ISBN 978-1-4503-3396-2/15/09 ...$15.00 DOI: http://dx.doi.org/10.1145/2786572.2786593 Fetching data in blocks of 16+ words is beneﬁcial since it avoids large tag arrays, improves DRAM row buﬀer utilization and exploits spatial locality. But fetching some data prematurely wastes NoC energy. As an analogy, imagine multiple cars heading to the airport, each catching a different ﬂight. Bulk-fetching implies that the cars convoy together and take the fastest route such that all cars arrive in time for the earliest ﬂight. This is wasteful since some cars have later ﬂights and could take a slower route that burns less fuel. We deﬁne data criticality as the promptness with which an application uses data after its block is fetched from memory. When an instruction currently waiting in the pipeline uses a data word immediately upon its arrival, this word is critical. A non-critical word is fetched merely as a consequence of bulk-fetching the entire block and may (or may not) be used later by some yet to be issued instruction. Data criticality is an inherent characteristic of both an application’s memory access patterns and the processor microarchitecture. In this paper, we analyze criticality and perform a limit study to estimate the amount of energy wasted in using traditional, criticality-oblivious NoC designs. Compared to a theoretical, idealized NoC that fetches each data word both no later and no earlier than needed, we ﬁnd that up to 37.5% energy is wasted. In addition, we ﬁnd that 62.3% of energy is wasted in fetching data words that is never used by the application at all (dead words). To demonstrate the signiﬁcance of data criticality, we evaluate a practical NoC design that dynamically adapts to criticality. We show that a criticality-aware NoC achieves up to 60.5% energy savings with negligible impact on performance. We make the following contributions: • We study the impact of data criticality on PARSEC [5] and SPLASH-2 [35] applications. • We show that a criticality-oblivious NoC can waste up to 37.5% dynamic energy (17.3% on average). Furthermore, 62.3% of dynamic energy is wasted fetching dead words. • We present NoCNoC (Non-Critical NoC), a practical, criticality-aware design that achieves energy savings of 27.3% (up to 60.5%) with no loss in performance. 2. DATA CRITICALITY Data criticality deﬁnes how promptly an application uses a data word after its block is fetched from memory. A word is critical if an instruction that needs it is issued in the processor pipeline before the word arrives at the L1 cache. The instruction will stall, hurting application performance. Ideally, (a) blackscholes. (a) ﬂuidanimate. (b) bodytrack. (b) ﬂuidanimate. Figure 1: Examples of data criticality. we would like to fetch this word through the NoC with zero time. To mask the fetching latency, modern superscalar, out-of-order processors continue executing independent instructions while waiting. However, performance still suﬀers as many applications have limited instruction-level parallelism (ILP). Since data is fetched in blocks, many words arrive at the cache prematurely. A word is non-critical if it is not needed by any instructions currently in the pipeline. Even if this word was fetched with zero latency, it would not improve performance. Words with low criticality are less sensitive to NoC latency and can tolerate longer fetch delay without harming performance. Fig. 1 presents simpliﬁed examples of data criticality from PARSEC [5]. In blackscholes (Fig. 1a), sptprice is accessed sequentially, exhibiting spatial locality. However, the function BlkSchlsEqEuroNoDiv performs many ﬂoating point operations and takes a long time to complete. With 16word blocks, the ﬁrst iteration of the loop fetches not only sptprice[0] but all elements up to sptprice[15]. Since the execution of BlkSchlsEqEuroNoDiv is long, many of the elements—especially sptprice[15]—are fetched long before they are needed; these elements have very low criticality. Fig. 1b presents another example. Since array cell->p is invariant to the inner loops, there is a long delay between sequential array accesses. Synchronization can also yield noncritical words. Depending on a particle’s location, neigh->a may or may not be enclosed by a lock. As a result, the delay between accesses may be large due to lock contention. Data criticality is an inherent consequence of spatial locality and is exhibited by most (if not al l) real-world applications. Note that compiler optimizations can reorder instructions to improve ILP and thus increase criticality, but the amount of ILP is limited by both the microarchitecture and the application characteristics. In general, low criticality can arise in the following situations: • Long-running code between accesses. • Interference due to thread synchronization. • Dependences from other cache misses. • Preemption by the operating system. 2.1 Data Liveness We also study data liveness as an extreme case of criticality. A word is live-on-arrival (or live ) if it is accessed at least once while in the L1 cache. With perfect spatial locality, all 16 words of a block would be live. However, in many (c) canneal. Figure 2: Examples of data liveness. applications, many cache words are fetched but never used prior to eviction. A word is dead-on-arrival (or dead ) if it is never accessed before being evicted. Fetching dead words expends unnecessary energy. Fig. 2 presents simpliﬁed examples of data liveness. In Fig. 2a, elements of array cell->v are accessed sequentially by the inner loop. However, depending on the position, an element’s x, y or z member may not be accessed. As a result, dead words may be fetched. This is common in many applications since members of data structures are stored contiguously in memory but not always needed during a given phase of the application. Dead words can also arise from irregular access patterns. In Fig. 2b, mParticles is not accessed sequentially but rather accessed based on mIndex; some elements are used more than others and some are never used at all. As a more extreme example, simulated annealing (Fig. 2c) exhibits very little spatial locality since elements of _netlist are accessed randomly; neighbouring elements are brought into the cache but never used. Data liveness measures the degree of spatial locality. The more live words in a cache block, the better the spatial reuse. In general, words can be dead-on-arrival if they are evicted early or inherently unused by the application. Note that compilers can employ data packing and alignment optimizations to increase spatial locality and thus liveness, but this can potentially yield more false sharing of cache blocks. Dead words are commonly found in the following situations: • Unused members of structs. • Irregular or random access patterns. • Heap fragmentation. • Padding between data elements. • Early evictions due to invalidations, cache pressure or poor replacement policies. 2.2 Comparison to Instruction Criticality Instruction criticality [13, 15, 16, 31] is a measure of the relative importance of each instruction in the pipeline, typically based on how likely the instruction is to fall on the critical path of execution. For example, assume load instruction X accesses the word a[0] (i.e. the word at oﬀset 0 in block a) and load instruction Y accesses the data word b[0]. Both instructions are issued, miss in the L1 cache and are now waitProcessor Cache blocks L1 cache L2 cache Main memory Cache coherence Technology node 16 cores, 2 GHz, 4-wide, out-of-order, 80-instruction ROB 64 B (16 words) private, 4-way, 1-cycle latency, 64 kB per core shared, fully distributed, 16-way, 6-cycle latency, 16 MB total 4 banks, 160-cycle latency, 4 GB total MSI protocol 22 nm Table 1: CMP conﬁguration. Topology Frequency Voltage Channel width Virtual channels Router pipeline stages Routing algorithm Request/Response packet size 4×4 mesh 2.0 GHz 1.14 V 128-bit 6 per port (4 ﬂits each) 3 X-Y dimension-order 6B / 6+64B Table 2: Baseline NoC. ing for their data in the reorder buﬀer (ROB). NoC criticality schemes (e.g., Aergia [13]) would prioritize/deprioritize fetching either a or b to improve performance and/or save energy. This priority is based on the criticality of X and Y, deciding which of these two instructions is on the critical path of execution and more likely to stall the processor. We refer to this as instruction criticality. However, this form of criticality is incomplete; it does not capture data criticality. When we prioritize block a over b based only on the criticality of instructions X and Y, then we assume that all other words in the block—a[1], a[2], etc.—are as equally critical as a[0]. This may not be the case since we do not know which instructions will be issued in the future. Perhaps the application will need a[2] before a[1]. Perhaps the application does not access a[1] until many cycles later, wasting energy in fetching it as quickly as a[0]. Thus data criticality is separate from instruction criticality. Determining data criticality is challenging since it assesses words that may (or may not) be used by instructions that may (or may not) be issued soon or far into the future. 3. CRITICALITY STUDY We characterize data criticality across a range of applications. We model a theoretical NoC design for each application—ideally tuned to its criticality characteristics— which represents the lower-bound energy consumption when fetching data both no later and no earlier than needed.1 From this, we study the impact of criticality and estimate energy wasted in conventional, criticality-oblivious NoCs. 3.1 Experimental Methodology We assume a 16-core CMP, conﬁgured as in Table 1. Our baseline is a conventional NoC design, conﬁgured as in Table 2. We use FeS2—a full-system x86 simulator [25]— with BookSim [18] to run applications from PARSEC [5] and SPLASH-2 [35]. Energy consumption is measured using DSENT [32]. For each application, dynamic energy is measured using the number of injected bytes, hop count, and 1Note that just-in-time fetching may not always be optimal since it can alter congestion patterns in the network. For this study, it simply serves as a ﬁrst step towards designing criticality-aware NoCs. runtime collected from FeS2 and BookSim. NoC voltagescaling values are obtained from Shariﬁ et al. [29]. 3.2 Measuring Criticality To characterize criticality, we measure the fetch latency and access latency of all data words used in each application. For a data word a[x] (i.e., the word at oﬀset x in block a), its fetch latency is the time elapsed from the L1 cache’s request for a to the arrival of the data block at the cache. This is the uncore latency, much of which is contributed by the NoC. In a conventional, criticality-oblivious NoC design, the fetch latency of all words in a are identical. The access latency of a[x] is the time elapsed from the L1 cache’s request for a to the ﬁrst L1 access (hit) of a[x] by the application. This represents the data word’s criticality; the lower the access latency (i.e., the sooner it is used), the higher the criticality.2 Fig. 3 shows the distributions of access latency (normalized to fetch latency) of all words accessed. For now, we ignore dead words. By normalizing to fetch latency, we effectively estimate the amount of network slowdown that can be tolerated. For example, if a word’s access latency is 3× its fetch latency, then the NoC can fetch this word 3× slower (saving energy) without hurting performance. Applications are grouped based on their overall criticality from very low to very high. The distributions in Fig. 3 are cumulative. For example, in ﬂuidanimate (Fig. 3a), 20% of all words can tolerate a network that is 10× slower than the baseline. Words with a normalized access latency of 1× (or lower) are critical. These words are used immediately upon arriving at the L1 cache; instructions in the ROB are already waiting for them. Fig. 3 shows that non-critical words exist in all applications, even those with high overall criticality. Applications are generally written to exploit spatial locality, due to the bulk-fetching nature of conventional caches. Since processors cannot achieve perfect ILP, some words are bound to be fetched before the instructions needing them are issued. Applications with very low criticality (Fig. 3a) tend to fetch data too early. These include blackscholes and swaptions, which are ﬁnancial applications with many time-consuming ﬂoating-point operations in between data accesses (Sec. 2). Fluidanimate and streamcluster also exhibit very low criticality due to heavy synchronization and long delays between accesses. 3.3 The Impact of Criticality We aim to quantify the amount of energy wasted in conventional NoC designs, where in a given block a, the fetch latencies of all words—a[0], a[1], etc.—are equal. These designs are oblivious to the varying criticalities (access latencies) of the data words. Our goal is to model a theoretical, ideal NoC where every word is fetched such that its fetch latency is equal to its access latency; all data is delivered both no later and no earlier than needed. Experiments. Starting from the baseline, we divide the NoC into multiple subnetworks each operating at a diﬀerent frequency and voltage. The subnetworks split the baseline 128-bit channel width. Using the distributions from Sec. 3.2, each subnetwork is assigned to fetch a subset of words that share a common access latency. The subnetwork’s frequency is then conﬁgured such that the fetch latency is equal to the access latency. We perform a brute-force search of all possible subnetwork conﬁgurations to ﬁnd the one that yields the 2Access latency encapsulates the fetch latency. (a) Very low criticality. (b) Low criticality. (c) High criticality. (d) Very high criticality. Figure 3: Cumulative distribution functions of criticality of all words accessed. Applications grouped by degree of criticality. subnet 0 1 2 3 4 5 6 1× access / fetch 1× - 1.1× 1.1× - 2× 2× - 3.5× 3.5× - 7× 7× - 18× 18× - ∞ channel 76-bit 4-bit 4-bit 4-bit 8-bit 8-bit 24-bit frequency 2.0 GHz 2.0 GHz 1.8 GHz 1.0 GHz 571.4 MHz 285.7 MHz 111.0 MHz voltage 1.14 V 1.14 V 1.09 V 0.84 V 0.71 V 0.62 V 0.57 V Table 3: Ideal NoC model for bodytrack. Figure 5: Energy wasted due to non-criticality. to a given subnetwork. For example, only the words with normalized access latency between 7× and 18× are injected into subnetwork 5. Words with an access latency of 7× can tolerate a frequency of 285.7 MHz (baseline 2.0 GHz divided by 7). Each word is injected into the subnetwork with the highest fetch latency that is no greater than the word’s access latency. This allows us to estimate the lower-bound energy consumed when all data is fetched both no later and no earlier than needed. Results. Fig. 5 shows the amount of dynamic energy wasted in the baseline, criticality-oblivious NoC compared to the ideal NoC. On average, 17.3% of energy is wasted (up to 37.5% for swaptions). As expected, conventional NoCs are energy-ineﬃcient for applications with very low criticality (Fig. 3a), expending 27.6% of unnecessary energy. Wasted energy is driven by two factors: the fraction of words that are non-critical and their degree of non-criticality (the amount Figure 4: Word distribution of ideal NoC model for bodytrack. Areas under the curve represent subnetworks. lowest energy. Table 3 shows the ideal NoC conﬁguration for bodytrack.3 This is visualized in Fig 4, where each area under the curve represents a subset of words that are assigned 3We do not consider channel widths narrower than 4 bits. Logic overheads of routing and allocation and sideband signals make narrow channels unrealistic. Figure 6: Energy wasted in fetching dead words. of network slowdown they can tolerate, based on the ratio of access and fetch latency). Even though canneal and cholesky have a low fraction of non-critical words (Fig. 3d), signiﬁcant energy is still wasted since they can tolerate large network slowdowns beyond 10×. Data criticality is a function of not only the application’s memory access patterns but also the processor microarchitecture. Fig. 5 also shows results for a lean core, which is single-issue with a 20-entry ROB. Since the lean core exploits less ILP, at any given time, there are less instructions waiting in the processor pipeline for their data. This increases the fraction of non-critical words and their access latencies, reducing overall criticality. As a result, even applications with very high criticality—such as radix and radiosity (Fig. 3d)— waste signﬁcant energy. On average, 22.7% (up to 42.5%) is wasted with lean cores. It is important to design NoCs with criticality-awareness, particularly when running lowcriticality applications or when using lean processor cores. 3.4 The Impact of Liveness To explore the impact of data liveness, Fig. 6 shows the energy wasted in fetching dead words. On average, 62.3% (up to 87.9%) of energy is expended on fetching words into the L1 cache that are never used before being evicted. As discussed in Sec. 2, this is generally attributed to poor spatial locality and irregular access patterns. This is evident in both bodytrack and canneal, where 84.4% and 85.5% of energy is wasted. An ideally energy-eﬃcient NoC would not consume any unnecessary energy in fetching dead words. 4. CRITICALITY-AWARE NOC DESIGN We studied ideal, criticality-aware NoC designs in the previous section; however, in the real world, such designs are infeasible. It is impossible to achieve perfect criticalityawareness (i.e., all data is delivered both no later and no earlier than needed) because the access latency of a word is not known in advance. Thus we cannot guarantee a fetch latency that is exactly identical to the access latency. Fortunately, it is possible to implement a practical NoC design that can dynamically predict criticality with high accuracy and save signiﬁcant energy. In this section, we present such a design—NoCNoC (Non-Critical NoC)—which achieves energy savings of 27.3% (up to 60.5%) with no loss in performance. A criticality-aware NoC design needs to perform three key functions: 1. Predict the criticality of a data word prior to fetching it (Sec. 4.1). Figure 7: Data criticality predictor. 2. Physically separate the fetching of words based on their criticality (Sec. 4.2). 3. Reduce energy consumption in fetching low-criticality words (Sec. 4.3). 4. Eliminate the fetching of dead words (Sec. 4.4). 4.1 Predicting Criticality Ideally, we want to know the exact time a word will be accessed (if at all) before fetching it. However, measuring and storing the access latencies of every word in the application is impractical. To keep overhead and complexity low, NoCNoC employs a simple binary prediction scheme: a word is predicted to be either critical or non-critical. Fig. 7 shows the hardware predictor, which is inspired from previous work [20]. The predictor is coupled with the L1 cache. It utilizes a table of 31-bit vectors indexed by the instruction address. We use untagged table entries to keep overhead low. Each vector tracks the access history of each word in the cache block based on its oﬀset relative to the requested word (that caused the cache miss). Prediction Lookup. Fig. 7 demonstrates an example prediction. A cache miss occurs requesting the word at oﬀset 4. From the criticality vector, the words at oﬀsets 2, 5 and 7 are predicted to be critical since they are positioned -2, +1 and +3 respectively, relative to the requested word. A 16-bit prediction vector is extracted and appended to the L1 request packet. Note that the requested word is always critical because there already is an instruction (which caused the cache miss) waiting to access it. Prediction Update. Each block in the L1 cache stores the requested word oﬀset, a pointer to the prediction table entry and a 16-bit access vector. Starting with the initial request, the access vector keeps track of which words in the block have been accessed by instructions. When the block arrives at the L1 cache, the contents of the access vector indicate which words are critical (since they were accessed while the block was still being fetched). The criticality prediction table entry is updated based on this access vector. A hysteresis bit is used to account for infrequent deviations from the data access pattern. 4.2 Separating Criticality Ideally, we want each word to traverse a NoC optimized for its criticality. However, it is physically infeasible to implement such a NoC for all levels of criticality. Instead, NoCNoC employs a heterogeneous, two-network design, where one subnetwork is dedicated to critical words and the other is dedicated to non-critical words. For each L1 cache miss, the criticality predictor is invoked. The data response packet is then split into two separate packets: one containing the words predicted to be critical and the other containing those predicted non-critical. Recent work shows that using multiple physical subnetworks can improve energy-eﬃciency [2, 14, 34], even more so than multiple virtual networks [36]. We now have two routers per tile: one per subnetwork. With a mesh topology, this has negligible impact on chip area [4]. NoCNoC does not require any changes to the coherence protocol. Coherence still operates on a block granularity. It only requires that the processor core and L1 cache support early-restart; instructions waiting for a speciﬁc word can proceed immediately when the word arrives, without having to wait for the whole block. Entries in the L1 miss status handling registers are not cleared until after all words have arrived. All control packets—requests, invalidations, acknowledgements—are injected into the critical network. As writeback packets are not on the application’s critical path, we inject them into the non-critical network. 4.3 Saving Low-Criticality Energy Ideally, we want low-criticality words to be fetched no earlier than necessary to save energy. However, this is difﬁcult to implement since data words have highly varying criticalities, which can change throughout the execution of the application. In NoCNoC, we employ dynamic voltagefrequency scaling (DVFS) to slow down the non-critical subnetwork. This allows us to save energy on words predicted to be non-critical, since they can tolerate a higher fetch latency. However, we must avoid lowering the frequency too much. Recall that a word is deemed non-critical if its access latency is greater than its fetch latency (i.e., it is not used until sometime after it arrives). As a result, if the frequency of the non-critical network is set too low, the fraction of words that are deemed non-critical approaches zero (since fetch latency becomes too high). In NoCNoC, we set the frequency such that the utilization of the critical and non-critical subnetworks is balanced to prevent high congestion on either network. We deﬁne a DVFS threshold θ equal to the fraction of total NoC resources allocated to the non-critical network (e.g., if noncritical channel width is 4 bytes and critical channel width is 12 bytes, then θ is set to 25%). During runtime, in epochs of 10 ms (Sec. 4.5), we measure α, the fraction of total network traﬃc that is injected into the non-critical network. At the end of each epoch, if α exceeds θ, then the application is currently exhibiting low criticality, and the non-critical network is overutilized. NoCNoC responds by reducing the frequency of the non-critical network.4 This allows us to 1) save energy in the presence of low criticality, and 2) balance the utilization of the two networks (i.e., reducing frequency increases fetch latency, which reduces the fraction of words that are deemed non-critical). If α is below θ , then criticality is high, and the critical network is overutilized; NoCNoC responds by increasing the non-critical frequency. 4.4 Eliminating Dead Words Ideally, we only want to fetch data words that are needed by the application. However, it is impossible to determine whether or not a word will be used when fetching it. In NoCNoC, we employ speculative dead word elision to save energy. Using the same prediction scheme as with criticality (Sec. 4.1), each L1 cache is also equipped with a liveness predictor. Before fetching a block, the liveness predictor Figure 8: Criticality prediction accuracy of NoCNoC. generates a 16-bit vector where each bit represents a word in the block and is set if that word is deemed to be live. This vector is appended to the L1 request packet and used to omit dead words from the data response packet. Dead word elision requires the L1 cache to use a valid bit per word instead of per block.5 The liveness predictor is imperfect; it can occasionally mispredict a live word to be dead. When this occurs, the L1 cache must issue another request, retrieving the rest of the block. 4.5 Evaluation To show the promise of criticality-aware designs, we evaluate NoCNoC in terms of criticality prediction accuracy, dynamic energy consumption and application performance. We assume the same baseline CMP and NoC conﬁgurations as in Sec. 3.1. We conﬁgure NoCNoC such that the aggregate bandwidth of its two subnetworks is equal to that of the baseline conventional NoC; we implement 88bit channels on the critical subnetwork and 40-bit channels on the non-critical subnetwork. All overheads introduced by NoCNoC—such as the 16-bit prediction vectors and the extra requests upon liveness mispredictions—are accounted for in our measurements. Predictors are initialized to assume all words are live and critical to be conservative during warm-up. We assume 4 kB prediction tables, similar to the implementation by Kim et al. [20]. Typically only 10 or fewer static load instructions cause more than 80% of L1 misses in most applications [11]. Since our prediction tables are indexed by the addresses of load-miss instructions, we expect that the table size can be reduced further while still maintaining high accuracy. Using CACTI [33], we measure the NoCNoC energy overheads (criticality and liveness predictors, and additional metadata in L1 caches) to be 2.6% of total cache energy. We employ DVFS in 10 ms epochs, assuming a 20 µs actuation overhead. θ is set to 31.25% (40bit non-critical channels and 88-bit critical channels). DVFS metadata is piggybacked onto packets [10] and only aggregated once every 10 ms; thus overhead is negligible. In our implementation, DVFS for the non-critical network ranges from 500 MHz to 2 GHz (in steps of 250 MHz), initially set to 1.25 GHz. The critical network is ﬁxed at 2 GHz. Criticality Prediction Accuracy. Fig. 8 shows the criticality prediction accuracy of NoCNoC. Note that the yaxis begins at 70% for readability. A prediction is correct if the word is both critical and predicted-critical, or both non-critical and predicted-non-critical. On average, NoC4We vary frequency in steps of 250 MHz (Sec. 4.5). 5Coherence is still maintained on a cache block granularity. (a) Application runtime. (a) L2 miss-predecessors. (b) Energy consumption. Figure 9: NoCNoC performance and energy. NoC correctly predicts the criticality of words with 97.2% accuracy. As discussed in Sec. 4.1, our predictor uses relative word oﬀsets, which are highly eﬀective since in most applications, spatially-colocated data elements are typically accessed in a predictable order [27]. A word is underpredicted if it is critical but predicted-non-critical (false negative), and overpredicted if it is non-critical but predicted-critical (false positive). Overpredictions increase congestion on the critical network while underpredictions stall the processor, forcing it to wait for data that has been wrongly injected into the slow non-critical network. NoCNoC achieves very low overprediction and underprediction rates of 2.2% and 0.6%. Performance and Energy. Fig. 9a and 9b show NoCNoC performance and energy. We compare against the baseline conventional NoC with and without dead word elision (DWE). Although we demonstrate signiﬁcant energy wasted on fetching dead words (Sec. 3), the inaccuracy of our liveness predictors limits the savings. On average, speculative dead word elision still achieves 18.3% energy savings compared to the baseline. NoCNoC—which includes dead word elision—sees energy savings of 27.3% on average (up to 60.5%), while increasing runtime by only 3.6%. We note that canneal is a pathological case that performs poorly on any multi-network design. Due to its poor spatial locality (Fig. 2c), canneal exhibits the highest number of L1 misses per cycle (0.096) of any application, nearly double that of its nearest competitor (bodytrack with 0.058). This results in very heavy congestion in the NoC. By splitting the NoC into smaller subnetworks (even without reducing the frequency), the smaller channel widths increases the number of ﬂits per packet. This increases resource contention in the NoC (buﬀer stalls and head-of-line blocking), which is ampliﬁed by the baseline high congestion in canneal. (b) Data criticality. Figure 10: Breakdown of injected bytes. Comparison to Instruction Criticality. As discussed in Sec. 2.2, instruction criticality schemes [13, 15, 16, 31] try to determine which instructions fall on the critical path of execution. Speciﬁcally, Aergia—a NoC prioritization scheme [13]—characterizes criticality based on how likely an instruction is to stall the processor pipeline. These schemes are eﬀective in accelerating critical data blocks, but their opportunities for energy savings are limited. Unlike data criticality, they do not take into account the data that is fetched before any instructions that need it are even issued. To illustrate this, we compare Aergia’s classiﬁcation of criticality (Fig. 10a) with that of NoCNoC (Fig. 10b). To identify non-critical instructions, Aergia tracks L2-misspredecessors, which are older instructions that have missed in the L2 cache (suﬀering a longer latency to access memory). An instruction with one or two L2-miss-predecessors can tolerate some network slowdown while an instruction with >2 can tolerate even more; it is highly likely that an L2-miss-predecessor will stall the processor. Conversely, an instruction with zero L2-miss-predecessors cannot tolerate a slowdown, and thus no energy savings can be achieved. We ﬁnd that instructions with zero L2-miss-predecessors make up 89.9% of injected NoC traﬃc, leaving only 10.1% for potential energy savings. This is due to typically low L2 miss rates and limited MLP. On the other hand, with NoCNoC, only 56.1% of traﬃc is critical while 43.9% can be slowed down (non-critical) or even eliminated (dead). 5. RELATED WORK Liveness. Kim et al. exploit data liveness through a redesigned router microarchitecture [20]. Predictors have been implemented that recognize the spatial locality of memory accesses [9, 21, 30]. These focus on prefetching and cache power savings. Other techniques can identify when words and sub-blocks will no longer be used before eviction [1, 3, 19, 23, 28]. Kumar et al. exploit dead words using variable block granularity to reduce cache energy [22]. Unlike our work, these techniques do not target NoC energy. Criticality. Exploiting instruction criticality [13, 15, 16, 31] provides less opportunities for NoC power savings compared to data criticality as shown in Sec. 4.5. Low-latency and low-power main memory modules can be used to target data criticality in the form of latency-sensitive memory accesses [8, 26]. Critical words caches dedicate a separate L2 storage array to words that were requested ﬁrst in the past [17]. We observe that more than one word can be critical on each cache miss. Prioritization schemes characterize NoC packets based on latency-sensitivity [6, 12, 24]. They aim to boost performance while we aim to save energy. 6. CONCLUSION We study the impact of data criticality in NoC design. Data criticality is an inherent consequence of spatial locality; it deﬁnes how promptly an application uses a data word after its block is fetched from memory. We ﬁnd that all applications studied exhibt data criticality. Conventional, criticality-oblivious NoC designs waste up to 37.5% energy. Furthermore, 62.3% of energy is wasted fetching data that is never used by the application. To illustrate the importance of criticality-awareness, we show how NoCNoC can achieve up to 60.5% energy savings with negligible performance loss. We demonstrate that NoCs should be designed to deliver data both no later and no earlier than needed. Acknowledgements The authors thank the anonymous reviewers for their thorough suggestions on improving this work. The authors also thank the members of the Enright Jerger research group for their feedback. This work is supported by a Bell Graduate Scholarship, the Natural Sciences and Engineering Research Council of Canada, the Canadian Foundation for Innovation, the Ministry of Research and Innovation Early Researcher Award and the University of Toronto. 7. "
"Fabrics on Die - Where Function, Debug and Test Meet.","In this paper, we briefly present how packet-based networks or fabrics, have found their way into diverse usages on high-end industrial designs today. We outline the salient features, use models and challenges involved in implementation and application of these fabrics, not only in functional communication but also in power-management, silicon debug and high-volume-manufacturing test. Both debug and test hooks in SOC/NOC and some test/debug scenarios are discussed. We touch on some recent advances in functional networks and their implications to debug & test.","Fabrics on Die: Where Function, Debug and Test Meet  Priyadarsan Patra  Intel Corp.  Austin, Texas  priyadarsan.patra@intel.com Chinna Prudvi  Intel Corp.  Hillsboro, Oregon  chinna.prudvi@intel.com  ABSTRACT  In this paper, we briefly present how packet-based networks or  fabrics, have found their way into diverse usages on high-end  industrial designs today. We outline the salient features, use  models and challenges  involved  in  implementation and  application of these fabrics, not only in functional communication  but also in power-management, silicon debug and high-volumemanufacturing test. Both debug and test hooks in SOC/NOC and  some test/debug scenarios are discussed. We touch on some  recent advances in functional networks and their implications to  debug & test.    Categories and Subject Descriptors  C.1.2  [Computer Systems Organization]: Multiprocessors;  Interconnection architectures; Debug and Test  General Terms  Design, Verification  Keywords  Fabric, Interconnect, Design, Debug, Test, Validation, SOC.  1. INTRODUCTION  On-die interconnect (the fabrics) form      partitioned and logically segmented such that Memory data is  placed in a cache segment based on its physical address, and  interleaved on cache line boundaries with the address bits hashed  to avoid hot spots. The split cache segments each provide a  reasonable bandwidth (say half a cache-line per clock) for a much  higher combined bandwidth described by the formula:  guarantees of receipt upon arrival, although some sort  of bouncing mechanism allows acceptance &  processing, possibly at a later time. As an example, a  LLC bank cannot guarantee fixed-latency processing  of a cache-read request from a core, because the  request misses the LLC or needs a core snoop.             # rings * # Ring stops * Frequency / Average ring  occupancy         = 2 * N * Width * Frequency / (N/4)     = Width * Frequency * 8  where N is the number of ring stops and Width is the width of the  rings in bytes; the factor of 2 is because of bi-directionality, and  N/4 is the average occupancy of a ring transaction. This is a good  approximation for designs despite many design-specific functional  and positional asymmetries of the ring “stops”. A stop is a  component/node on  the  ring where packets may be  inserted/consumed/repeated. Note that bi-directional rings can  give 4 times the bandwidth at the cost of twice as many wires as in  the unidirectional. In order to facilitate better utilization and  deadlock/congestion avoidance, rings are often separated into  multiple, functionally separated rings such as (1) Read/Write  Requests, (2) Global Observation and Response messages, (3)  Snoops and (4) Data fills and write-backs.  Figure 2 A typical ring fabric topology  The nature of our multi-core and distributed cache  interconnect problem is that multiple senders need to send  messages to multiple receivers. Flow control is a major area  of validation for performance as well as functionality  (deadlock, starvation, hangs). The fabric Messages fall into  four flow-control categories:          Guaranteed-BW Messages are those that  the receiver can process as fast as the sender can send  through the fabric, without stalling or queuing for an  arbitrary duration.  Expected Messages are usually responses  where the receiver of the message had made some sort  of request earlier, allocated necessary buffer, and is  awaiting a response.  Credited Messages are only sent when the  sender has acquired a credit from the receiver.  Speculative Messages – are sent without  3. VALIDATION ISSUES AND  CHALLENGES  A critical challenge in the deployment of on-chip networks lies in  validation ([4]) of its operation – how designs can be ensured to  be functional and robust in the face of process and use-context  variations, within tight cost and time-to-market budgets.  A deadlock scenario can arise if there is a circular resource  dependency between two messages: e.g. a Core-to-Cache Request  may depend on a Cache-to-System Request in the event of a cache  miss, but both these messages are sent over the same Request  Ring.  An anti-deadlock mechanism is needed to break any  circular dependency. When a speculative message arrives at a  receiver that has no room, the receiver will bounce the message  which unfortunately remains ring resident for another full  rotation. Protocol deadlocks occur if one of the rings can fill up  with messages because a receiver ran out of buffers, and the  receiver cannot free up the buffers until it sends a message out  onto that same ring. This scenario can appear in case of a hot-spot  where a ring stop LLC is bombarded with data requests from  cores which themselves are LLC miss – thus, the LLC slice can  fill up its request queue with additional core requests bouncing  and clogging the ring – the very resource the LLC needs to reach  to the system interface to satisfy an earlier core request!  Similarly anti-starvation measures are incorporated to ensure  forward progress when a message trying to enter the ring can be  trapped between an eager Sender and Receiver pair on a separate  thread. When designing dynamic credit allocation to distributed  senders, in order to cope with asymmetric demands, one needs to  ensure fairness to avoid starvation. Missed credits and incorrect  credit initialization are dealt with through correct-by-construction  and validation techniques.  Fault tolerance needs and yield improvement objectives involve  spare cores, self-configuration for ring direction or width (use one  direction and subset of lanes/wires for communication in case of  hard fault).  For certain designs with relatively arbitrary topology for a group  of IPs, a point-to-point network such as the IOSF networks may  be used. IOSF preserves PCI-ordering without specialized OS  support (or explicit h/w flush).  Some of the challenges seen postsilicon  involve  timing  under multiple  voltage  and  (Plesiochronous) clock domains. Complications due to firewalls  and level-shifters can become sources of bugs – sometimes  leading to “shmoo” holes in the production ramp. IOSF sideband  networks are used  to bring “structure”  to out-of-band  communication by eliminating special-purpose wires.  4. DEBUG AND TEST  Designs often include other fabrics specialized for “Debug Trace  collection” or “Scan content delivery” or links for powermanagement messages, etc. Those fabrics often have their own  quirks.         Here we sketch the types of debug features needed to debug  NOCs in SOCs. We need the ability to control the processing  agents on the SOC (Start/Stop/Step/Break) individually or in a  coordinated manner. We also need the ability to get access to  registers on the chip through backdoor non-intrusive methods  (JTAG, Sideband, etc.). We need an ability to trace key  interfaces/fabrics in the chip and be able to send the traces out of  the chip in a non-intrusive way. We also need the ability to detect  and trigger on certain events (hangs, live locks, access to certain  address range, etc.) to be able to start/stop trace capture. We  enable the ability for all agents to send messages to the tracing  fabric (SW, FW & HW). The ability to freeze the entire SOC and  be able to dump the state of the entire SOC is also very helpful for  debug (but suffer from non-deterministic values due to the nature  of design today and hence unsuitable for manufacturing Test).  Silicon enabling work needs the simplest and most robust of the  networks, such as JTAG/Test-Access-Port network, which can  also benefit from packetized design.  Figure 3 Point-to-point sideband network connecting IP blocks  Next we consider one typical debug scenario and how the above  debug features can be used in the silicon and platform debug.  System hang is a case where some or all of the processing agents  are stuck and not making progress. This can occur when a request  is dropped in the fabric and the issuing agent is waiting for a  response and it is possible that other agents can also stall if they  have transactions that are dependent on the dropped transaction.  In this scenario, the SOC is frozen based on transactions not  making progress (Trigger). Once the SOC is frozen the state of the  SOC is dumped and analyzed. Based on the analysis, it is possible  to figure out the transaction that is stuck by analyzing pending  transactions across the entire SOC/fabrics. In subsequent debug  runs tracing transactions through various fabrics will help  understand the sequence that led up to the failure. The issues can  be root caused by analyzing the design or the design can be  simulated with the sequence of events captured in the system to  get to the root cause. The other typical failures are live locks, data  corruptions, issues with power management features (voltage  transitions, power on/off, clock on/off etc.). The debug features  described above can be used to debug these failures.   High-volume Manufacturing Test also on-die infrastructure for  modular, parallel and cost-effective Test, and this infrastructure  has begun to include sophisticated packet-based networks serving  the needs of both Structural Test (Scan, Array) as well as Testerfriendly Functional Tests. All these Test functions require  efficient, scalable and high-bandwidth content delivery and  response extraction from the hundreds of IP ’s that are integrated.  A Sideband network (Figure 3) often provides out-of-band  communication in presence of access “hazards” such as deadlocks  or power-down/sleep states, and is also used to implement virtual  wires, on-chip power management control, backdoor access to  device config space, to propagate shadow configuration register  read/writes to soft and hard IP’s and to control Test modes,  testability and security. On-die networks are often extended with  security features to protect assets such as the design IP and  manufacture’s keys, OEM keys, premium content, debug modes,  end-user information, and execution flow, etc. The networks  include a means to reliably identify initiators of transactions,  authorization and to enforce intended security policy based on the  security life-cycle of the product, the user and the attempted  usage. Debug and test demand flexible/easy visibility and control  of the SOC operation, while security raises the bar significantly,  thus a formidable design tension comes into play.  5. FINAL REMARKS  In conclusion, on-die fabrics are fast becoming the backbone of  communication for the three distinct use domains, namely, (1)  modular design & functional operation, (2) validation and debug,  and (3) manufacturing test.  6. ACKNOWLEDGMENTS  Our thanks to Intel Corporation and our colleagues for many  valuable discussions and support.  7. "
Fault-tolerant Network-on-Chip based on Fault-aware Flits and Deflection Routing.,"Deflection routing is a promising approach for energy and hardware efficient NoCs. Future VLSI designs will have an increasing susceptibility to failures and breakdowns. The inherent redundancy of NoCs can be used to tolerate such failures. We extended the non-fault-tolerant CHIPPER router architecture to enable fault-tolerance. This architecture is based on deflection routing and utilizes a permutation network instead of a crossbar. The permutation network eliminates the sequential dependence of the priority based port allocation. Compared to a crossbar based design, a permutation network allows a faster and smaller router design. Simulations of an 8 × 8 network and more than 30.000 it injections show, that our router architecture is competitive with existing crossbar based fault-tolerant router architectures.","Fault-tolerant Network-on-Chip based on Fault-aware Flits and Deﬂection Routing Armin Runge Depar tment of Computer Science Am Hubland Würzburg, Germany armin.runge@uni-wuerzburg.de ABSTRACT Deﬂection routing is a promising approach for energy and hardware eﬃcient NoCs. Future VLSI designs will have an increasing susceptibility to failures and breakdowns. The inherent redundancy of NoCs can be used to tolerate such failures. We extended the non-fault-tolerant CHIPPER router architecture to enable fault-tolerance. This architecture is based on deﬂection routing and utilizes a permutation network instead of a crossbar. The permutation network eliminates the sequential dependence of the priority based port allocation. Compared to a crossbar based design, a permutation network allows a faster and smaller router design. Simulations of an 8 × 8 network and more than 30.000 ﬂit injections show, that our router architecture is competitive with existing crossbar based fault-tolerant router architectures. Categories and Subject Descriptors B.4.5 [INPUT/OUTPUT AND DATA COMMUNICATIONS]: Reliability, Testing, and Fault-Tolerance—Hardware reliability General Terms Design Keywords Network-on-Chip, deﬂection routing, fault tolerance 1. INTRODUCTION Network on Chips (NoCs) are considered as the prevalent interconnection infrastructure for future many-core systems because of the demanding communication requirements of these systems [5]. Interconnection infrastructures like buses, rings or dedicated wiring, which are still frequently applied, do not scale to a high number of processing elements (PEs). Interconnection networks consist of a number of routers and Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. NOCS ’15 September 28 - 30, 2015, Vancouver, BC, Canada Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-3396-2/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2786572.2786585 links, connecting two routers with each other. A frequently used topology is the 2D mesh, in which each router has ﬁve ports: four ports connecting the neighboring routers (north (n), east (e), south (s), west (w)) and one local port (l) connecting a PE. Most of the current NoC designs adopt buﬀered routers with wormhole ﬂow control [20], which leads to a signiﬁcant energy and area consumption of such networks. The energy consumption of the network of a manycore system is substantial and will be a primary barrier in the future [2, 3]. The NoC of Intel’s 80-Core Teraﬂops Research Chip, for example, consumes 28% of system power [16]. A signiﬁcant proportion of energy and area used by the network is consumed by buﬀers. For example, 60% die area of the iMesh NoC of Tileras TILE64 many-core system is dedicated to buﬀering [25]. In the TRIPS chip, the router’s input buﬀers even occupy 75% of the NoC area [14]. Several researchers have already investigated buﬀerless NoCs in the past. Buﬀerless routers can drop [15] or deﬂect packets [21, 7] in the case of collision. In this paper we focus on deﬂection routing, where each router computes a permutation between all inputs and outputs. Deﬂection routing does not need buﬀers and allows simple local ﬂow control. These beneﬁts lead to area and power savings, as well as to a short router latency. The absence of routingdependent deadlocks and the adaptivity of deﬂection routing are further advantages. On the other side, precautions against livelocks are necessary and packet switching is not feasible. Each ﬂit needs routing information and therefore a distinction between head-, data- and tail-ﬂits is not possible. Deﬂection routing is proved to be a feasible solution for systems with low or medium network traﬃc [18, 4]. Recently, several authors have presented new approaches which can enhance the performance even for heavily loaded NoCs [19, 8]. The ever growing number of cores and resources per chip is caused by continued technology scaling. Unfortunately, the shrinking transistor size leads to increasing variability in performance and reliability. Static variations like random dopant ﬂuctuations lead to an irreversible device degradation over time. Therefore, the probability of link failures or even the breakdown of whole routers increases for structures in nanometer range [1]. Future NoCs, as well as processing units [23], should thus be able to cope with failures as they are inherent in those systems. Whereas forward error correction (FEC) and retransmission can be used to handle transient and intermittent failures, the inherent redundancy of NoCs should be used to tolerate permanent failures. This work introduces a fault-tolerant NoC, which utilizes that redundancy to tolerate arbitrary link failures. The remainder of the paper is organized as follows. In Section 2 we present related work. Section 3 introduces our basic router architecture, which is enhanced to a faulttolerant router architecture in Section 4. In Section 5 we evaluate the performance and hardware requirements of the herein presented architecture. Finally, this paper closes with a conclusion and an outlook to future work in Section 6. 2. RELATED WORK In recent years, several approaches have been investigated to achieve fault tolerant NoCs. An overview of failure mechanisms, fault models and fault tolerance methods is given in [22]. In buﬀered NoCs, special attention has to be paid to deadlock avoidance, as buﬀers are a shared resource, which may arise a circular dependence. This restricts the possible routing decisions for fault tolerant routing algorithms even more. Deadlock free routing algorithms are often based on the turn model [13], where some turns are prohibited, or on virtual channels [6] (VCs). In contrast, deﬂection routing is inherently deadlock free. Instead, routing algorithms must prevent livelocks. This can be achieved by prioritizing all ﬂits according to their age. This makes deﬂection routing attractive for small, energy eﬃcient and fault tolerant NoCs. However, only few fault-tolerant deﬂection-routing based router architectures exist. In [17, 24], the Nostrum NoC [21], which utilizes deﬂection routing, has been extended to tolerate transient, intermittent and permanent faults. Their fault-adaptive ”cost-based deﬂection routing” algorithm even employs the remaining functionality of partial defective routers. The main emphasis of their architecture lays on highest possible performance and optimal routing decisions. However, this is contrary to our approach, as our design focus lies on an energy efﬁcient and fast router architecture. This is why the cost based router architecture in omitted for the evaluation in Section 5. Feng et al. reported in [9] that the cost-based routing algorithm causes a drastic decline of over 60% of the achievable frequency. They presented a fault-tolerant deﬂection routing algorithm called FoN which makes routing decisions based on fault-information of two-hop neighbor routers [9]. FoN can only tolerate fault-regions with a single convex/concave point. In [10], Feng et al. also presented a fault-tolerant deﬂection routing algorithm FTDR based on Q-learning. FTDR is a table-based algorithm, which outperforms FoN and ”cost-based routing” in terms of throughput and average hop-count. However, even if the achievable frequency is quite similar to FoN, the required area is yet higher than that of cost-based routing. To reduce the routing table overhead, Feng et al. proposed FTDR-H, in which each switch contains a local and a region routing table. Additionally, a 3D version of FTDR was presented in [12], and a version that tolerates transient failures as well was presented in [11]. All these NoCs are based on a router architecture that utilizes a crossbar. To the best of our knowledge, the herein presented router architecture is the ﬁrst fault-tolerant architecture, that utilizes a permutation network (cf. Section 3) and fault-aware ﬂits (cf. Section 4). 3. ROUTER ARCHITECTURE Our router architecture FaFNoC (fault-aware ﬂits NoC) is based on the non-fault-tolerant CHIPPER architecture preFlit: Bits: dst x 4 y 4 src x 4 y 4 hc 8 fs 3 ret 1 pl x Figure 2: Flit structure consisting of destination and source address, hop-count hc , fault-status fs , return ﬂag ret and payload pl . sented in [7]. CHIPPER is an energy eﬃcient, simple and fast router architecture for on-chip communication. This is achieved by utilizing buﬀer-less deﬂection routing and additionally a permutation network instead of a crossbar. In deﬂection routing every router calculates a permutation between all input- and output-ports per each network clock cycle. This implies that every clock cycle, a ﬂit will be routed to one of the neighboring routers or ejected. As ﬂits can not be stored in a router, they ﬂow through the network until they arrive at their destination. Deﬂection routing is therefore inherently deadlock free. In particular, no virtual channels are needed and no routing restrictions are required to guarantee the absence of routing dependent deadlocks. Instead, attention must be paid to avoid livelocks. In contrast to packet switching, where packets can be stored in buﬀers, deﬂection routing requires no buﬀers and no buﬀer allocation. This allows a fast and energy eﬃcient router design. On the other hand, ﬂits will maybe be routed on nonminimal paths to their destinations because of deﬂections. Recent investigations have shown that deﬂection routing is competitive for low to medium traﬃc loads, as frequently encountered in real systems [7, 18]. An overview of the herein presented router architecture is depicted in Fig. 1. We adopted the injection and ejection stage as well as the permutation network from the non-faulttolerant CHIPPER architecture. The ejector enables the extraction of ﬂits that have reached their destination, from the network to the local port (l). Accordingly, the injector enables the injection of ﬂits from the l port into the network if at least one port is idle. The permutation network consists of four permuter blocks p1 . . . p4 and replaces the commonly used crossbar. Each permuter block pi can swap both inputs (st i := state (pi ) = 1) or pass the inputs to the corresponding outputs (identity function) (st i := state (pi ) = 0). In contrast to the commonly used crossbar, the utilized two-stage permuter network does not allow every reasonable permutation. It only guarantees that the highest prioritized ﬂit will be routed closer to its destination. However, besides this downside, the permutation network allows a simple and fast router architecture. Most NoCs, and even deﬂection routing based NoCs (e.g. Nostrum [21]), utilize a crossbar. Those NoCs sort all arriving ﬂits according to their priority at the port allocation. This yields in a longer critical path due to the sequential dependence of the ﬂit sorting. A permutation network avoids the crossbar and the corresponding arbitration logic, which enables a fast and simple router architecture. To avoid livelocks and handle prioritization of competing ﬂits at the ejection stage or at the permuter blocks, a prioritization scheme is required. Our router architecture prioritizes ﬂits according to their age. Therefore the ﬂit structure has been extended by an eight bit hop count ﬁeld hc (cf. Fig. 2). Further, the router architecture has been extended Figure 1: Fault-tolerant router architecture consisting of the basic router architecture (depicted in gray), the fault-handler, the fault-status-handler and a stress-value counter. Algorithm 1 Routing algorithm for fault-free routers 1: procedure Routing(f1 , f2 ) hp ← priority (f1 , f2 ) diﬀx ← x − hp (destx ) diﬀy ← y − hp (desty ) along x along y 2: 3: 4: // f1 , f2 are the two input ﬂits // ﬁnd higher prioritized ﬂit // hops from router to destination // hops from router to destination // avoid oscillating 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: 30: 31: 32: 33: if permuter is p1 or p2 then if hp from e and diﬀx < 0 then route hp to p3 else if hp from w and diﬀx > 0 then route hp to p3 else if hp from n and diﬀy < 0 then route hp to p4 else if hp from s and diﬀy > 0 then route hp to p4 else if diﬀx (cid:54)= 0 and diﬀy (cid:54)= 0 then route along direction with lower stress value else if diﬀy (cid:54)= 0 then route hp to p3 else route hp to p4 end if else if permuter is p3 then if diﬀy < 0 then route hp to n else route hp to s end if else if permuter is p4 then if diﬀx < 0 then route hp to e else route hp to w end if end if 34: end procedure // route along y direction to dest. // route along x direction to dest. // dest. is located in the north // dest. is located in the south // dest. is located in the east // dest. is located in the west by a hop count incrementer. Deﬂection routing does not specify which path a ﬂit has to follow. A great advantage of deﬂection routing is the absence of routing-dependent deadlocks, especially for partially defect NoCs (see Section 4). Hence, a ﬂit can be routed towards each direction and deadlocks do not need to be considered by the routing algorithm. Instead of simple dimension order routing, herein fault-free routers route ﬂits according to Algorithm 1. Routers dynamically decide if ﬂits are routed in x- or y -direction ﬁrst, depending on the load of the adjacent routers. Therefore, each router calculates four stress values sv i , i ∈ {n, e, s, w}, which are the average number of received ﬂits in the last four clock cycles. Two adjacent routers exchange their stress values of the corresponding input ports, which connect these two routers (cf. Fig. 1). Algorithm 1 is quite similar to the routing algorithm which is utilized in FON. In contrast to FON, the herein applied permutation network requires that the routing algorithm operates in a distributed manner, as all permuters determine their states independently of each other. The routing decision of every permuter is only based on the local information of arriving ﬂits and maybe on the stress value of the adjacent routers. First of all, each permuter determines which of the two ﬂits is higher prioritized (cf. line 2 or Algorithm 1). Permuter p1 and p2 decide if the higher prioritized ﬂit will ﬁrst be routed in x− or in y−direction to its destination. To avoid ﬂit oscillating between adjacent routers, a fault free router will never send a ﬂit back to its original direction. This is ensured in lines 6 - 13. If for example, a ﬂit arrived at the input port e and its destination is also located in the east (line 6), the ﬂit will be routed to permuter p3 which is connected to the vertical ports n and s. If the distance in both productive directions is not zero and the ﬂit has arrived from one of the two remaining directions, the direction with the smaller stress value will be chosen (line 14). Otherwise, the ﬂit will be routed in the direction which is not zero (line 16 and 18). Permuter p3 can forward the ﬂit to the north or to the south (y -axis). The routing decision is therefore straight forward. If the destination of the higher prioritized ﬂit is located in the north, the ﬂit will be routed to the n-port (line 22), otherwise it will be routed to the south (line 24). Accordingly, permuter p4 moves the higher prioritized ﬂit to the east (line 28) or to the west (line 30). 4. FAULT-TOLERANT ARCHITECTURE In this section we introduce our fault tolerant router architecture based on a permutation network with deﬂection routing. The beneﬁts of the non-fault-tolerant version are a fast, energy eﬃcient and small router architecture. We ensured that these features remain preserved as far as possible. Therefore, we avoided large routing-tables, as these require too much die area and energy. Further, we will show that solely local fault information and even two hop fault information is not suﬃcient to achieve fault tolerance in terms of realistic hop-counts and performance losses. Nevertheless, the storing of fault-information of neighbor routers is not necessary. Our fault-model takes permanent link failures into account, which can be caused e.g. by wearout mechanisms. Router failures can be represented by marking all links as faulty. Fault detection can be achieved, for example by simple acknowledgment of received ﬂits and the counting of failed transmissions, as presented in [17]. Fault detection is beyond the scope of this paper. We assume that every router has a four bit width fault information input f i, representing the fault status of each link (see Fig. 1). As a basic assumption of deﬂection routing is an equal number of inputs and outputs, link failures are considered as bidirectional. 4.1 Adjusting Permuter Blocks To enable fault-tolerance, ﬁrstly, broken links may not be used, and secondly, as much ﬂits as possible should arrive at their destination, nevertheless. To ensure that broken links are not used, the permuter blocks have to be conﬁgured accordingly. In case of four or three link failures the behavior of routers is obvious. If all four links are faulty, the router can not receive or send any message and the behavior of the permuters is not relevant. If three links are faulty, the behavior is also predetermined due to the lack of buﬀers. Every packet that arrives at the last working port has to leave the router via the same port at the next clock cycle or it has to be ejected to the local port. For one or two faulty links the routing decision is more complicated. Fig. 3 shows all of the one port fault situations. The local port is not considered here, as a fault at the local port does not inﬂuence the routing if the ﬂit has not yet arrived at its destination. If the local port of the destination of a ﬂit is defect, the ﬂit has to be ejected by another router. It can be seen that for every one port fault situation the two permuters connected to the faulty port are in state 0. If e.g. the north port is faulty (Fig. 3a), p1 can not be in state 1 (st1 (cid:54)= 1). Otherwise the ﬂit from the east port and possibly one ﬂit from p2 would arrive at p3 . As the north output of permuter p3 is defect, only a single ﬂit can be forwarded at this permuter. The two remaining permuters can be in state 0 or in state 1 (depicted as two parallel straight lines and a cross). In the case of no faults all four permuters can operate independently and without any information beside the two ﬂits at the input ports. To avoid bad routing decisions, ﬁrst stage permuters (p1 and p2 ) have to evaluate the complete fault information ﬁ of all four links. Permuter p2 in Fig. 3a, for example, needs information about the failure-state of p3 and p4 . Otherwise p2 could forward a ﬂit that has arrived at the south input with destination north to permuter p3 . Port p3 can only deﬂect the ﬂit back to the opposite direction (south output), as the north link is defect. This causes unnecessarily high hop-counts and could lead to livelocks, if the neighbor router sends the ﬂit again back to the defect router. Fig. 4 shows all possible two link failure situations. For Fig. 4a - 4d the state of exactly two permuters is 0 (permuters with exactly one faulty link) and the state of one permuter is 0 or 1 (permuter with no faulty link). The state of the fourth permuter is irrelevant (depicted as an empty square) as both input or output links are defect. This does not hold for Fig. 4f and Fig. 4e. If for example the north and the west link are defect, both routing decisions should be possible, e → s, s → e and e → e, s → s. Hence, all four permuters must be in the same state. If st i = 0 and st j = 1 for i, j ∈ {1, 2, 3, 4} with i (cid:54)= j , a defect link is utilized. This implies that even p1 (p2 ) has to consider the state of p2 (p1 ). In summary, every permuter has to evaluate the complete fault information ﬁ and further has to coordinate Algorithm 2 Fault handler 1: if no links are defect then fci = 00 ∀i ∈ {1, 2, 3, 4} 2: state // permuters determine their 4: 3: else if 1 link is defect then set fci according to Fig. 3 5: else if 2 links are defect then set fci according to Fig. 4 7: else fci = 01 ∀i ∈ {1, 2, 3, 4} 9: end if 6: 8: // 3 or 4 links are defect // state (pi ) = 0 Figure 5: Fault evasion for complex fault-situation. its state/routing decision with all other permuters. Instead of adding complex logic to all four permuters, we implemented a central fault-handler (fh ). The fh (see Fig. 1) has a fault information input (ﬁ ) and four 2 bit width outputs fc i , where the output fc i controls the behavior of permuter pi . At fc i = 00, the permuter operates according to its routing algorithm (normal operation). At fc i = 01, the state is set to st i = 0 and at fc i = 10 to st i = 1. Thus, at an erroneous router (at least one defect link) the fh determines the defect links, which are signaled by ﬁ , and takes over the routing decision by setting fc i = 01 or fc i = 10. The pseudo code of the fault-handler fh is depicted in Algorithm 2. In case of no link failures the fh sets the fc i bits to 00, which implies, that every permuter determines its state independently and by itself. In case of link failures, the fh checks for the special cases depicted in Fig. 4e and Fig. 4f. If none of the two special cases applies, the fh sets the state of every permuter which is connected to a faulty link to fc i = 01, accordingly to Fig. 3 and Fig. 4. That means, at least two permuters are set to state 0. The states of the permutes which are not directly connected to an erroneous link, are set randomly and uniformly distributed to fc i = 01 or fc i = 10. If one of the special cases applies (Fig. 4e and Fig. 4f), the fh sets all four fc i outputs with a likelihood of p = 2/3 to fc i = 10 and with p = 1/3 to fc i = 01. The reason for the uneven probability is that fc i = 01, ∀i ∈ {1, 2, 3, 4} implies, that all ﬂits are returned to their arriving direction, which is less frequently a good routing decision. 4.2 Fault-status-handler Complex fault-situations, as the one depicted in Fig. 5, can only be overcome if ﬂits are routed consciously away from their destinations. This implies that knowledge about (a) faulty North-port (b) faulty East-port (c) faulty South-port (d) West-port faulty Figure 3: Permuter blocks with one faulty port (dashed gray line). state (pi )=0 state (pi )=1 state (pi )∈{0,1} don’t care state (a) North- and east-port faulty (b) South- and west-port faulty (c) Northand south-port faulty (d) Eastand west-port faulty (e) Northand west-port faulty (f ) Eastand south-port faulty Figure 4: Permuter block with two faulty ports (dashed gray lines). the fault-situation has to be present, as otherwise the ﬂits would be routed towards their destinations. Such information can be stored in routers in terms of routing tables (as in FTDR) or it can be exchanged between adjacent routers (as in FON). Routing tables occupy buﬀer space which contradicts to our design goals and the exchange of fault information is limited to a small number of hops. Fault situations which are more extensive than this number can not be tolerated, why this method is only practical for small fault-situations. Deﬂection routing dispenses with buﬀers and, instead of being buﬀered, ﬂits are deﬂected in case of collisions. This means, ﬂits are not stored in routers, but kept on links. We transferred this approach to the fault-information keeping. Instead of adding fault awareness to every router, this information is added to the ﬂits. Therefore, we extended the router architecture by the fault-status-handler (fsh ) and the ﬂit structure (cf. Fig. 2) by a three bit width fault-statusﬁeld (fs ). To overcome a complex fault-situation, like the one depicted in Fig. 5, two turns against the direction of the deﬂection are necessary. Bit fs 0 implies in which direction (right (fs 0 = 0) or left (fs 0 = 1)) the fault region should be evaded. The other two bits fs 1−2 say how much turns are needed for the fault-region evasion. If a ﬂit is deﬂected to the left (right) because of link failures, the region evasion to the right (left) will be started and the fault status handler (see Fig. 1) sets the fs ﬁeld. Deﬂection herein means, that a ﬂit will be actually routed away from its destination. Accordingly to the evasion direction (fs 0 ), two turns are required to evade the fault region, whereas fs 1−2 provides the number of turns which are still required to complete the evasion successfully. Fig. 5 shows an example for a fault region evasion. Router r1 deﬂects the ﬂit to the east and therefore the fault status handler sets fs = 110. The ﬁrst bit indicates that left turns are necessary and 10 indicates that exactly two turns are still remaining. Router r2 performs the ﬁrst left turn and decrements the fault status ﬁeld by one (fs = 101). Unfortunately, r3 can not forward the ﬂit to the west or to the north and deﬂects the ﬂit to r4 . The fault status ﬁeld is set again to fs = 110. r4 performs a left turn (fs = 101) and also r5 performs a left turn (fs = 100). The fault status ﬁeld is then cleared by r6 . Please note that r8 does not set the fs ﬁeld even if r8 deﬂects the ﬂit to r9 Algorithm 3 Fault status handler 1: for all ﬂit ∈ {n, e, s, w} do */ fault status bits handling: /* if ﬂit (fs ) (cid:54)= ”000” then if outgoing port is on border position then set ﬂit (fs 0 ) to ﬂit (fs 0 ) else if turn was performed, in correct direction then decrement ﬂit (fs ) else if turn was performed, in wrong direction then set ﬂit (fs ) to ﬂit (fs 0 )10 else if deﬂection back to input dir then // same dir. and 2 turns // invert turn direction 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: set ﬂit (fs ) to ﬂit (fs 0 )10 // invert dir. and 2 turns // ﬂit (fs ) = ”000” end if else if link failure causes deﬂection then set ﬂit (fs ) to x10 end if end if 17: */ return ﬂag handling: /* if ﬂit is deﬂected and one link is defect and ﬂit traverses both defect permuters then set ﬂit (ret ) to 1 else if ﬂit is returned to input dir. then set ﬂit (ret ) to 0 end if 22: end for 18: 19: 20: 21: due to two link failures. This is because the west link to r9 is also a productive link. Algorithm 3 shows the pseudo code of the fault-statushandler. If the fault-status-ﬁeld is set (line 2), the fsh checks for every ﬂit in parallel if the fs -ﬁeld has to be adjusted. In order to check the routing decision of the permutation network, the fsh has to evaluate the states st i of all four permuters. If the fs -ﬁeld is not set and a link failure causes a deﬂection, the fsh sets the fs -ﬁeld accordingly. Line 17 21 show the return ﬂag handling, which will be described in Section 4.3. The fault-handler is complemented, as depicted in Algorithm 4, to realize the routing decisions, which are set by the fs -ﬁeld. For one link- and no link failure situations, the fault-handler checks if the fs -ﬁeld of the highest prioritized ﬂit is set, and adjusts the routing decision in this case. At one link failure situations the fault-handler has to pay attention that the defect link will not be utilized. Algorithm 4 Fault handler - with fs and ret handling 3: 1: hp ← priority (n, e, s, w) 2: if hp (ret ) = 1 then fci = 01 ∀i ∈ {1, 2, 3, 4} 4: else if no links are defect then if hp (fs ) (cid:54)= ”000” then evade fault region else 5: 6: 7: 8: 9: state // ﬁnd highest prioritized ﬂit // state (pi ) = 0 // fault status bits are set fci = 00 ∀i ∈ {1, 2, 3, 4} // permuters determine their // fault status bits are set 11: 12: 13: 14: 15: end if 10: else if 1 link is defect then if hp (fs ) (cid:54)= ”000” then try to evade fault region without using faulty links else set fci according to Fig. 3 end if 16: else if 2 links are defect then set fci according to Fig. 4 18: else fci = 01 ∀i ∈ {1, 2, 3, 4} 20: end if // 3 or 4 links are defect // state (pi ) = 0 17: 19: 4.3 Return ﬂag A two-stage permutation network does not allow every permutation, i.e. it is only guaranteed that the highest prioritized ﬂit will be routed to its preferred direction. This downside gets even more serious if links fail. If for example, the n port fails (as depicted in Fig. 3a), a ﬂit arriving from e with destination in the south should be routable, as both links are not defect. Unfortunately, permuter p1 has to forward this ﬂit to p4 , as otherwise two ﬂits could arrive at p3 . The permutation network prohibits this routing decision as well, and the ﬂit from e can only be routed to e or w. Even for small numbers of link failures, as shown in Section 5, fault situations may arise, at which this downside prohibits the only path from source to destination. In order to overcome such fault situations, the ﬂit structure is complemented by an one bit width return ﬂag ret . This ﬂag signals the adjacent router to return the ﬂit to the arriving direction. In the example above, the ﬂit would be routed to w and will then arrive at the same router from w in the next clock cycle, whereas w → s is possible. The routing decision is again adjusted by the fault-handler, which sets state (pi ) = 0 if the ret -ﬂag of the highest prioritized ﬂit is set (line 3). Setting and resetting of the ret -ﬂag is done by the fault-status-handler (cf. Algorithm 3). 5. EVALUATION In this section we evaluate the performance and the costs of our router architecture FaFNoC (fault-aware-ﬂits NoC) introduced in Section 4 and compare the results to existing fault-tolerant deﬂection routing based architectures. 5.1 Test method All router architectures are simulated for an 8 × 8 NoC using our in-house cycle accurate simulator implemented in VHDL. We also reimplemented the router architectures (FON [9], FTDR [10], FTDR-H [10]), which are compared against our router architecture. Every router is connected to a traﬃc generator, which is able to generate uniform random, bit complement, shuﬄe and transpose traﬃc. Flits are injected at every router with a given injection probability, which was set to 10% for all presented results. If a ﬂit could not be injected at a certain router due to congestion, the ﬂit was discarded and never injected. Every simulation took 5000 clock cycles, which means, that every simulation tried to inject approx. 32000 ﬂits. For comparability, every reported value is an average value of three simulations. That means, every depicted plot consists of 48 simulations. The location of the link failures, and also the traﬃc in case of random traﬃc, are generated by an uniform distributed random process with the same seed for every router architecture. Only connectivity was ensured at the link failure placement. 5.2 Performance evaluation To evaluate the fault-tolerance, we investigated the impact of diﬀerent link-failure rates to the achievable throughput (Fig. 6), the average hopcount (Fig. 7) and the number of lost ﬂits (Fig. 8). For all traﬃc pattern and all three evaluation criterions, FTDR performs best. Even for high fault rates (up to 30% of all links are broken) only a slight decline of the throughput and the average hopcount could be observed. As FTDR learns the interconnection topology, almost no ﬂits are lost (cf. Fig. 8) and ﬂits use the shortest paths to their destinations, even for complex faultsituations. This does not apply for FON and FTDR-H. At FON, every router only has two-hop fault-information and hence, only fault-situations which do not exceed this number of hops can be tolerated. FTDR-H utilizes a localand a region-routing-table at every router. The region-table stores the distances to other regions (in total four regions for our 8x8 NoC) and the local-table stores the distances to all routers in the same region. Complex fault-situations which cause that the only path between source and destination traverses at least two regions can therefore also not be tolerated. The throughput of FTDR-H is slightly better than that of FON but the throughput of both architecture degrade signiﬁcantly with higher fault rates, as complex faultsituations occur more frequently for higher fault rates. The average hopcount of FTDR-H is even higher than that of FON for mot traﬃc pattern (Fig. 7). The reason for this is, that lost ﬂits (ﬂits are discarded at hopcount overﬂow) are not considered for the average hopcount. Our architecture performs slightly better than FON and FTDR-H in terms of throughput and average hopcount. However, FaFNoC loses almost no ﬂits, whereas up to 800 ﬂits (out of approx. 15.000 ejected ﬂits) are lost at FON or 200-400 lost ﬂits at FTDR-H. 5.3 Synthesis results To evaluate the hardware costs and the achievable clock frequency, we synthesized all four router architectures using Xilinx’s XST [26].Please note that XST synthesizes a design for FPGAs and uses not a standard cell library like ASIC synthesis software. Nevertheless, this enables us to compare the hardware requirements and the achievable speed of our router architectures. Fig. 9 shows the number of required look-up tables (LUTs) for one switch of diﬀerent NoC dimensions. It can be seen, that the required LUTs for FTDR and FTDR-H increase with the NoC dimension, as both architectures utilize a routing table. The increase at FTDR-H is comparatively moderate, because of the region routing table. FON and FaFNoC require a comparable amount of LUTs, which is constant for all NoC dimensions. The achievable clock frequency for all four router architec(a) Uniform random (b) Bit complement (c) Shuﬄe (d) Transpose Figure 6: Throughput for an injection rate of 0.1 and a variable number of random link failures for diﬀerent synthetic workloads. (a) Uniform random (b) Bit complement (c) Shuﬄe (d) Transpose Figure 7: Average hop count for an injection rate of 0.1 and a variable number of random link failures for diﬀerent synthetic workloads. (a) Uniform random (b) Bit complement (c) Shuﬄe (d) Transpose Figure 8: Number of lost ﬂits for an injection rate of 0.1 and a variable number of random link failures for diﬀerent synthetic workloads. tures is depicted in Fig. 10. 6. SUMMARY & CONCLUSION In this paper we presented a fault-tolerant buﬀerless NoC. To the best of our knowledge, this is the ﬁrst approach that utilizes deﬂection routing combined with a permutation network, which enables a simple, fast and energy-eﬃcient router design. In order to preserve this beneﬁts, our router design avoids the exchange of fault-information between routers and requires no routing table. We showed, that a central unit coordinating all four permuter blocks would be useful, if two-link failures shall be tolerable. To overcome even complex fault situations, we introduced the fault status handler (fsh ) and fault aware ﬂits. Such fault situations can only be circumvented, if a ﬂit is consciously routed away from its destination. This is achieved by extending the ﬂit-structure by three additional bits. These bits signal adjacent routers to forward this ﬂit in the necessary direction in order to circumvent the fault-region. We evaluated hardware costs as well as achievable performance for our router architecture FaFNoC and compared the results to existing fault-tolerant, deﬂection routing based architectures. FaFNoC achieves slightly Figure 9: Synthesis results for all four router architectures and diﬀerent NoC dimensions. Figure 10: Achievable frequency for all four router architectures. better results than FON or FTDR-H for throughput and average hopcount, whereas FTDR achieves signiﬁcantly better results for those values. However, the existing architectures FON and FTDR-H lose a huge amount of injected ﬂits. At FTDR and FaFNoC almost all injected ﬂits arrive at their destinations. The synthesis results for our router architecture lay close to them of FON. 7. "
Runtime Detection of a Bandwidth Denial Attack from a Rogue Network-on-Chip.,"In this paper, we propose a covert threat model for MPSoCs designed using 3rd party Network-on-Chips (NoC). We illustrate that a malicious NoC can disrupt the availability of on-chip resources, thereby causing large performance bottlenecks for the software running on the MPSoC platform. We then propose a runtime latency auditor that enables an MPSoC integrator to monitor the trustworthiness of the deployed NoC throughout the chip lifetime. For the proposed technique, our comprehensive cross-layer analysis indicates modest overheads of 12.73% in area, 9.844% in power and 5.4% in terms of network latency.","Runtime Detection of a Bandwidth Denial Attack from a Rogue Network-on-Chip Rajesh JS Dean Michael Ancajas Koushik Chakrabor ty Sanghamitra Roy USU BRIDGE LAB, Electrical and Computer Engineering, Utah State University {jsrajesh34, dbancajas}@gmail.com, {koushik.chakrabor ty, sanghamitra.roy}@usu.edu ABSTRACT In this paper, we propose a covert threat model for MPSoCs designed using 3rd party Network-on-Chips (NoC). We illustrate that a malicious NoC can disrupt the availability of on-chip resources, thereby causing large performance bottlenecks for the software running on the MPSoC platform. We then propose a runtime latency auditor that enables an MPSoC integrator to monitor the trustworthiness of the deployed NoC throughout the chip lifetime. For the proposed technique, our comprehensive cross-layer analysis indicates modest overheads of 12.73% in area, 9.844% in power and 5.4% in terms of network latency. Categories and Subject Descriptors B.4.3 [INPUT/OUTPUT AND DATA COMMUNICATIONS]: Interconnections (Subsystems) General Terms Security Keywords hardware trojan, network-on-chip, bandwidth denial 1. INTRODUCTION Emerging global semiconductor environment has seen a rapid growth in demand for Multiprocessor System-on-Chips (MPSoCs) to sustain ubiquitous computing [20]. With unprecedented pressure of time-to-market, modern MPSoCs integrate many different Third Party Intellectual Property (3PIP) components within a single die. These components, coming from a diverse pool of design houses, may introduce security loopholes in the system [2, 10]. Security assurance and veriﬁcation of 3PIPs are challenging due to limited design information available from the respective IP providers. Consequently, many existing techniques based on internal signal inspection are useless for detecting 3PIP trojans (e.g., [25]). Network-on-Chip (NoC) 3PIPs present several unique challenges in trustworthy computing, compared to other 3PIP Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org NOCS ’15, September 28-30, 2015, Vancouver, BC, Canada Copyright 2015 ACM 978-1-4503-3396-2/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2786572.2786580. processing elements, hardware accelerators, and memory modules. First, a NoC has direct access to all the components in an SoC, and therefore plays a central role in resource availability of a chip. Second, unlike processing elements or specialized components, there is only one instance of a NoC in an MPSoC. Consequently, validating its security assurance and performance guarantee becomes hard, as one cannot deploy 3PIP trustworthiness based on replicated execution [20]. These unique aspects conspire to create a perfect security storm when the NoC assumes a malicious role in an MPSoC. A rogue 3PIP NoC (rNoC) can cause a plethora of damages like data corruption, denial of service, and information stealing. A secure system must provide three central aspects of trustworthiness: conﬁdentiality, integrity and availability [22]. We focus on the impact of rNoCs maliciously manipulating the availability of on-chip resources through a focused bandwidth denial attack. Such an attack can directly translate to application performance degradation in modern many-core systems. Emerging many-cores employ rudimentary in-order cores lacking in the ability to tolerate on-chip communication latency [15, 28]. While many recent works have explored secure NoC design [7, 8, 12, 17], techniques to thwart a rNoC have not been well explored. Ancajas et al. recently addressed the violation of conﬁdentiality through a rNoC, and proposed techniques to protect against it [4]. However, due to the fundamental differences in their threat model, their protection mechanism cannot detect or protect against a bandwidth denial attack that we explore in this work. To counter this imminent threat from a rNoC, we propose a novel runtime technique to detect this attack, termed as Runtime Latency Auditor for NoCs (RLAN). RLAN is non-invasive, and does not rely on any support from the NoC IP provider. RLAN injects carefully selected monitoring packets in the network. Through these packets, the SoC ﬁrmware can audit the application driven trafﬁc and detect anomalous delays in their transit. Fundamentally, RLAN exploits spatio-temporal similarities in NoC routes, where two packets traveling on paths with signiﬁcant overlap, within a short interval of time, are expected to experience comparable latencies. We make the following speciﬁc contributions in this paper: • We establish a potent threat model in the on-chip communication infrastructure that can have a signiﬁcant impact on application performance (Section 2). • We provide a detailed design of a rogue NoC, analyze its design footprint and threat signiﬁcance (Section 3). • We present RLAN, a technique to systematically monitor the trustworthiness of a 3PIP NoC during runtime AA Analog • Arbiter: The role of an arbiter is to resolve multiple requests to a single resource shared by many agents. Round Robin (RR) is one of the common mechanisms used, which allows ﬂits to reserve the crossbar traversal slots uniformly. To enable the attack, the trojan circuit de-prioritizes the ﬂits destined to (or sourced from) the victim node, deviating from the uniform scheduling. Consequently, ﬂits may be delayed at a given router for a pre-designated number of cycles. • Allocator: An allocator matches resources to requesters under constraints to allow ﬂits to traverse through the crossbar. By suppressing the request made by a ﬂit from the victim node, the trojan induces a delay in allocation. 3.3 Area and Power Footprint To evaluate the area and power overhead of the Trojan in a NoC, we augment the RTL of an open-source Stanford Verilog model of a modern NoC router [5] with the modules discussed in Section 3.2. We assume that the router is used as a part of a mesh topology with 5-input/output ports (4 cardinal directions + 1 local) and 5 virtual channels in each port. We synthesize the design with the TSMC 45nm library using Synopsys Design Compiler. We observe negligible overheads of 4.32% and 0.014% in area and power, respectively. Hence a rNoC presents a potent threat to impact the application performance while using a low design footprint. Unfortunately, a 3PIP rNoC cannot be detected by internal signal inspection (e.g, [25]) as modern IP providers are reluctant to release their proprietary RTL. To mitigate this threat, we investigate a non-invasive runtime trojan detection method. 4. RUNTIME LATENCY AUDITOR FOR NOCS (RLAN) In this section, we describe our proposed technique RLAN to detect trafﬁc abnormalities in the NoC caused by a malicious NoC IP. While the performance degradation is evident at the application level (Section 2), runtime detection of such malicious activities has several key challenges, outlined in Section 4.1. These challenges lay the foundation of our proposed technique RLAN (Section 4.2). RLAN is a non-invasive technique that can work without any modiﬁcation to a 3PIP NoC IP. To realize this goal, we integrate our technique in the SoC ﬁrmware module that interfaces the processing element to the network interface (NI) of the NoC IP. We discuss RLAN variants in Section 4.3, scalability of RLAN in Section 4.4 and outline the role of the SoC ﬁrmware design in Section 4.5. 4.1 Design Challenges The crux of RLAN is to identify the latency elongation of packets caused by a bandwidth denial attack. The three key challenges in runtime detection are outlined next. • Understanding Attack Semantics: We cannot detect an ongoing attack on a given node by comparing the latencies of packets sourced (or destined) to that node. This is because, once under attack, there will be little anomaly in latencies between similar packets from/to the victim node, thereby defeating the purpose of the detection mechanism. • Limiting False Positives: False positives may arise because the latencies of packets between a given source-destination incur variations based on normal network level activities. Figure 3: Hierarchical approach for Victim Selection. In stage 1, aggregate bandwidth information of the region is collected and in stage 2, a victim is identiﬁed based on high usage rates. or processing elements (PE). The trojan causes performance degradation at the application level, to implicate a potentially inferior IC/chip design. 3.2 Realizing a rNoC To realize a rNoC, we modify the router microarchitecture, and augment the routing protocol and messages to a standard four-stage virtual channel NoC router. The four pipe stages are input buffer, route calculation, VC allocation and switch traversal. The control and data path of the trojan are fed to various router pipe stages to allow covert manipulation of the router functionality. The trojan has three modules: activation, victim node selection and trafﬁc ﬂow manipulation. 3.2.1 Activation Module Trojan activation modes are broadly classiﬁed under external and internal [24]. Activation can be achieved using various methods such as software-hardware coalition [4,19], time based triggers or triggered using the trafﬁc activity and trafﬁc patterns in the NoC. Since 3PIPs allow limited opportunity for introspection, a smart designer can carefully create an activation module that will elude existing trojan detection techniques. 3.2.2 Victim Node Selection Module The rNoC can choose a victim node based on different criteria. The challenge in victim IP selection is ﬁnding a victim node that can cause a noticeable drop in application performance. In a large network, this can be a complicated problem. One possible attack is to ﬁnd a node that has a high ingress/egress rate. To ﬁnd a node that has a high usage rate, the rNoC uses a two-level hierarchical approach, where the whole NoC is subdivided into smaller regions. Figure 3 illustrates this model. In the ﬁrst stage, each region will send bandwidth information to a master node similar to the way congestion-aware networks aggregate trafﬁc information [18]. In the following stage, one or more nodes with high ingress/egress rates are chosen as the victim nodes. This hierarchical approach with minimal information passed makes victim selection low overhead and scalable. In larger networks, the hierarchical levels can be further increased to maintain low overhead. 3.2.3 Trafﬁc Flow Manipulation Module The trojan manipulates the trafﬁc ﬂow at each router. In our implementation, we augment the resource contention module. Two speciﬁc stages of the router microarchitecture are modiﬁed: Arbitration and Allocation. The goal of these modiﬁcations are denying fair crossbar traversal slots for the ﬂits originating from (or destined to) the victim node. Figure 5: Overview of RLAN. a) Proximal nodes around the victim act as proxy destinations for PAPs. Source (B) sends a PAP to one of the proximal nodes (P), which is forwarded to the original packet destination (A). b) Proximal nodes around the victim act as proxy sources. Source (A) sends a signal to one of the proximal nodes (P), which injects a PAP to the destination (B). c) Nodes around the victim IP act as proxy sources (egress) and destinations (ingress). PAP path is spatially and temporally similar to that of the original packet. 4.2.1 Tagging Timestamps To compare latencies, during the operational phase of RLAN, all packets are tagged with a timestamp. Figure 4 illustrates the required design. During the operation, the PE forwards the data to be communicated to the SoC Firmware, where a clock module tags a timestamp and dispatches it to the NI for packetization and injection into the network. At a destination, the incoming packet is depacketized in the NI and forwarded to the SoC ﬁrmware where timestamps are extracted. By scrutinizing extracted timestamps, RLAN establishes healthy interconnect latency thresholds and detects irregularities in the NoC fabric. An auxiliary beneﬁt obtained from tagging timestamps is isolation of communication time from the computation time in a SoC. This aids in dynamic assessment of performance levels of different IPs. 4.2.2 Creating Source/Destination in RLAN We recognize three subtle variations in the attack semantics to guide our PAP creation. In particular, packets of a victim node may observe excess latency on their egress path, ingress path, or both. It turns out that these variations lead to intricate design implications for creating an effective PAP. Hence, it becomes essential to create topology aware monitoring packets to weed out false negatives. We outline our proposed approach to tackle all of these variations next. An underlying theme of our approach is limiting the complexity through maximal use of local network activities and minimizing the need for global information. • Scenario 1–Attack on ingress packets: The trojan targets packets that are destined to the victim node (A). We use Figure 5(a) to explain the operation of RLAN, where the victim node A’s ingress packets suffer from latency elongation. Consider that node B sends a packet (X) to node A. We create a PAP and inject it from B directed to one of the nodes (P) proximal to X’s destination. When the PAP arrives at P, the SoC ﬁrmware identiﬁes and re-injects it towards A. At A, the SoC ﬁrmware stores the arrival time and compares it with the arrival time of X. Repeated deviations of packet arrival times are ﬂagged as abnormal network activities. • Scenario 2–Attack on egress packets: The trojan tarFigure 4: The SoC integrator augments the RLAN control logic in the SoC Firmware. The SoC Firmware pads a timestamp to the data before forwarding it to the NI for packetization. In an MPSoC environment, different applications may coexist at different times, resulting in a wide variation in network level congestion during their runtime. As a result, RLANs must distinguish latency elongation due to normal network activities from those of malicious activities. • Managing Overhead: To create a practical solution, it is critical to manage its circuit-architectural overhead in terms of performance impact, area and power. With growing network size, scalabilty of the proposed technique is another important consideration. We explore several RLAN variants to balance overhead and efﬁcacy in Section 4.3. 4.2 Design of RLAN The insight of our RLAN design is that packets traversing routes with signiﬁcant overlap (spatial similarity) around the same time (temporal similarity) have comparable latencies. We exploit this phenomenon to devise our solution. Essentially, given an existing packet, we create a Proximal Analogous Packet (PAP) by slightly altering the source and/or destination. PAP have similar priority and hop count to the original packets and contain information to relate to their original counterparts. Subsequently, we compare the latencies among these two, and gather statistics over a signiﬁcant sample size to detect any malicious activities. Our proposed design involves two major steps: (a) Tagging Timestamps (Section 4.2.1); and (b) Creating Source/Destination in RLAN (Section 4.2.2). 0 0.04 0.08 0.12 0.16 0.2 b l a b Figure 6: Variation of the detection point (dp) across benchmarks with n=100000. Detection point is evaluated for the 4 RLAN variants represented by detection factors (df ) of 0.1, 0.25, 0.5 and 0.8 (lower is better). The runtime is considered to be 10 minutes. c k s c h o l e o d s y t r a c c k a n n e a l f e r r e t n i m a t e f l u i d a a s w p t i o n s v i p s x 2 6 a 4 v e r a g e D e t c e i t n o P o i n t 0.1 0.25 0.5 0.8 0.36 0.29 df gets packets originating from the victim node (A). In this scenario, we cannot inject a PAP from the same source as all packets originating from the source are delayed. To tackle this case, we propose using a node close to the source as a proxy. Figure 5(b) illustrates the operation, where the original source A sends a signal to any one of the proximal nodes (P) every time it injects a packet (X). P interprets the signal and injects a PAP to the same destination (B). At B, the SoC ﬁrmware compares the arrival time and ﬂags abnormal activity if repeated large deviations occur. The solution complexity is higher, as the proximal nodes are unaware of neighboring activities and need a signal from A. We deliberated on a solution where PAP is injected as a reply to an original packet and compare their latency. But the solution is inaccurate due to variation in sporadic network congestion as the path taken by the two packets is different both spatially and temporally. • Scenario 3–Attack on egress & ingress packets: In this scenario, the embedded trojan attacks all packets originating from and destined to the victim node. This variation escalates solution complexity further as PAPs should neither originate nor travel to the victim node directly. We combine the two solution variants presented above. Here, the SoC ﬁrmware is responsible for sending a signal to generate an effective PAP, as well as, comparing arrival time. Figure 5(c) illustrates the operation. 4.3 Variants of RLAN A particular design challenge in RLAN is managing its runtime overhead, as PAPs introduce additional resource contention in the system. On the other hand, speedy detection of trojan activity in a NoC is critical for the security assurance of the MPSoC. To perform a trade-off analysis between overhead and fast detection, we use an analytic model. The key insights behind this model are explained below. • We assume that RLAN is intermittently active. To model this behavior, we deﬁne test phase (P) and test length (T). P deﬁnes the time period of successive RLAN invocations, while T indicates the active duration of RLAN within P. • To assess RLAN’s overhead, we deﬁne a ratio detection factor (d f ), which is T/P. A high d f shows that RLAN is active most of the runtime, and thus incurs a large overhead. 0 2 4 6 8 10 b l a c b Figure 7: Scalability of RLAN. Variation of detection point for three NoC sizes: 4x4, 8x8 and 16x16 for a detection factor (df ) of 0.5 (lower is better). k s c h o l e o s d y t r a c k c a n n e a l f e r r e t n i m a t e f l u i d a a s w p t i o n s v i p s x 2 6 4 a v e r a g e D e t c e i t n o P o i n t 4x4 8x8 16x16 NoC Size 18.72 15.03 • To assess the detection point (d p) of RLAN, we need to consider two aspects: (a) required number of ﬂits to make a decision (n); and (b) total runtime of the program, modeled as m phases of length P. Both are application dependent, as n is driven by the packet injection rate (i) of the program. We represent d p as the percentage of total runtime required to accurately identify the presence of the trojan. d f = T P (1) d p = n d f × i × 1 mP (2) Equation 1 and Equation 2 presents our analytic model to explore the trade-off between d p and d f . The ﬁrst term of Equation 2 (for d p) denotes the total time for n samples to be taken, while mP in the second term shows the total runtime of the program. Ideally, we want the detection point to be low so that the trojan can be quickly detected. Figure 6 shows the variation of detection point across benchmarks for different RLAN conﬁgurations (based on d f ) that we used: 0.1, 0.25, 0.5, 0.8. We observe two key patterns. Certain benchmarks (eg. bodytrack, vips) have worse detection points compared to others. These benchmarks have low injection rates. Hence, RLAN takes a longer time to obtain the required samples. We also notice that for a given benchmark, with increasing detection factor, detection point reduces. We will explore the trade-off between detection factor and its incurred overhead in Section 6.4. 4.4 Scalability of RLAN With increasing levels of integration, next generation systemon-chips will feature larger NoCs [13]. Hence, solutions to current issues must be scalable to the larger networks. We evaluate the scalability of RLAN in terms of the increase in detection point. We compare the detection points for three different network sizes: 16 (4x4), 64 (8x8) and 256 (16x16) nodes. For this comparison, we consider a detection factor of 0.5 and runtime of 10 minutes. Figure 7 shows the increase in dp with increase in network size. Since each node in the network has to be assessed individually, detection point increases as a factor of network size. We notice that for a network consisting of 256 nodes, the average detection point is at 8.2% of the total runtime compared to 2% for 64 node NoC. 4.5 Role of the SoC Firmware The SoC ﬁrmware is an integral component of our pro    posed solution. Its role, listed next, helps to explore the design trade-offs to successfully realize RLAN. • The SoC integrator must decide parameters (test length and test phase) to limit overhead. The SoC ﬁrmware must have provisions to hold the above test parameters and inject PAPs at suitable periods. • In all scenarios, proximal nodes serve as proxy nodes to mask the original source/destination of the victim. The SoC ﬁrmware must have the capability to inject, identify and forward PAPs. At the same time, it must encode adequate information to associate PAPs to their original counterparts, for arrival time comparison. • Another prominent role is to accurately identify abnormal network activity. The SoC ﬁrmware must only ﬂag repeated deviations and be able to distinguish abnormal activity from intermittent delays caused by sporadic congestion in the network. We implement these functions in a standard SoC OCP interface [21], and evaluate the overhead from its synthesized hardware (Section 6.4). 5. METHODOLOGY We employ a rigorous cross-layer methodology combining application induced trafﬁc simulation on a cycle-accurate NoC simulator with detailed circuit level analysis from the synthesized hardware. Architecture Layer: We consider a traditional NoC without any security features as our baseline and evaluate our design cost. For our evaluations, we consider a 64 node, 8x8 mesh topology. The router has a 4 stage pipeline of route computation, virtual channel allocation, switch allocation and switch traversal. We carefully model the RLAN technique in Booksim 2.0 and simulate real world application traces from Netrace 0.9 [14]. The network latency overhead includes the effect of routing resource contention arising from the additional trafﬁc introduced through our techniques. Circuit Layer: We evaluate the area/power overheads of the rNoC design by augmenting the open-source Stanford Verilog model of a modern NoC router, and subsequently synthesize it using the Synopsys Design Compiler and a 45nm TSMC standard cell library. To assess the area/power overhead from our proposed techniques, we implement our proposed technique in a standard SoC OCP interface [21], and subsequently compare the design footprint in the synthesized hardware. 6. EXPERIMENTAL RESULTS In this section, we provide the results on the efﬁcacy of RLAN (Section 6.1), and discuss area, power and performance overheads of RLAN (Sections 6.3 and 6.4). 6.1 Efﬁcacy We deﬁne Network Latency Differential (NLD) as the difference in packet latency between a PAP and its original counterpart. Figure 8(a) presents the CDF (cumulative distribution function) of PAPs with respect to NLD1 . In the absence of a bandwidth denial attack, a large percentile of PAPs will have small to negligible NLDs. In Figure 8(b), we observe 1 To eliminate obvious noise, we truncate the data at a minimum NLD of 6. that only 4% of packets have an NLD greater than 12 for the no-attack case. However, during an attack, a signiﬁcant percent of PAPs are expected to have a higher NLD. We clearly see this contrast in an attack scenario, where more than 60% of packets have an NLD greater than the chosen NLD(12). Hence, there is a clear separation between a no-attack and attack scenario that enables the identiﬁcation of a trojan. Simultaneous Applications: Given that an MPSoC may have multiple co-scheduled applications, it is imperative that we study the efﬁcacy of RLAN under such an environment. We subject RLAN under rigorous testing by superimposing heavy random trafﬁc with an injection rate of 0.25, on top of application induced trafﬁc. Figure 9 shows the CDF plot for such a situation. We can observe that NLD characteristics of noattack and attack scenarios are still distinct. For example, if we consider the NLD of 12 again, the percentage of packets above the NLD in the no-attack case increases to 8%. In contrast, for different attack scenarios, the corresponding percentile is still over 40% for all benchmarks. 6.2 CDF-NLD Threshold To accurately identify the presence of a trojan, we need to carefully select the CDF-NLD threshold and thereby minimize the false positives(FP) and false negatives(FN). In Figure 8(b) (single application), point P1 denotes the maximum percentile of packets with NLD-12 under no-attack and P2 denotes the percentile of packets having the same NLD (12) under an attack scenario. We notice that, the difference in CDF for these two scenarios is more than 50%. By choosing a CDF threshold of 30% (for NLD 12), we can ensure that there are no FP or FN. Due to the clear distinction between noattack and attack scenario, we can also use the CDF threshold of 16% for a NLD of 16. Hence, if more than 16% of packets have NLD greater than 16, the NoC’s availablity is said to be compromised by trojan activity. Under the simultaneous application environment, we see that the contrast between no-attack and attack scenarios reduces considerably. Increased network trafﬁc and interference due to multiple applications induces sporadic delays in the network. If we retain the same threshold of 16% for NLD of 16, we see a false negative rate of 2.74% for ferret benchmark. Under this scenario, an attack having delay of 1 cycle per hop may not be ﬂagged as trojan activity. By reevaluating the threshold to 23%(CDF) for NLD of 12, we can ensure zero FP and FN. Figure 9(b) illustrates two threshold combinations that can result in accurate identiﬁcation of trojan activity. Points (M1 , M2 ) and (M3 , M4 ) denote the extremes of CDF for NLD of 12 and 14 respectively. Table 1 presents the false positive(FP) and false negative(FN) rates in both single and multiple application environments. We select a CDF threshold of 30% and assess the FP and FN rates for four different NLD values: 10, 12 14 and 16. We notice that for NLD value of 12, the FP and FN are zero in both environments. For NLD of 10 we see a high false positive rate in the multiple application environment. Network congestion due to multiple application will result in sporadic delays which are wrongly ﬂagged as trojan activity. On the other hand, selecting a high NLD threshold(16) can result in FN of 1.8% and 6.2% in the two environments. 6.3 Performance Overhead Figure 10 presents a comparative analysis of performance overhead across different RLAN variants. The maximum  0  20  40  60  80  100  10  20  30  40  50  60 C u m u l a i t v e D i s t r i u b i t n o Network Latency Differential (NLD) AVG_NA AVG_T1 AVG_T2 AVG_T3(cid:10) (a) 0 20 40 60 80 100 6 8 10 12 14 16 18 20 22 24 C u m u l a i t e v D i s i r t u b i t n o Network Latency Differential (NLD) AVG_NA AVG_T1 AVG_T2 AVG_T33 X X P1 P2 P3 P4 (b) Magniﬁed section Figure 8: Eﬃcacy of RLAN. For a given NLD (x-axis), the y-axis shows the percentage of PAPs suﬀering equal of greater NLDs. We show four diﬀerent cases: no-attack, and three attack scenarios, T1,T2, T3, with delay per hop as 1,2 and 3, respectively. All benchmarks are shown in lighter shade, with the average shown in the darker shade. Figure 8(b) shows the magniﬁed section for selection of CDF-NLD threshold and analysis of false positives and false negatives  0  20  40  60  80  100  10  20  30  40  50  60 C u m u l a i t v e D i s t r i u b i t n o Network Latency Differential (NLD) AVG_NA AVG_T1 AVG_T2 AVG_T3 (a) 0 20 40 60 80 100 6 8 10 12 14 16 18 20 22 24 C u m u l a i t e v D i s i r t u b i t n o Network Latency Differential (NLD) AVG_NA AVG_T1 AVG_T2 AVG_T3 X M1 M2 X M3 M4 (b) Magniﬁed section. Figure 9: Eﬃcacy of RLAN under multi-program environment. Figure 9(b) shows the magniﬁed section for selection of CDF-NLD threshold and analysis of false positives and false negatives 0 2 4 6 8 10 % o l e n i m a t e f e r r o f l u i d b l a c b Figure 10: Runtime Overhead of the RLAN technique under diﬀerent detection factors. We evaluate the performance overhead for detection factors of 0.1, 0.25, 0.4 and 0.8. k s c h s d y t r a c k c a n n e a l e t a v i p s x 2 6 4 A v e r a g e P e f r o r m a n e c O v e r h a e d ( ) 0.1 0.25 0.5 0.8 df overhead (10.48%) is seen in x264 when the detection factor is 0.8. This conﬁguration ensures high detectability as the test is active for a majority of the application runtime. On an average, for d f = 0.8, the overhead incurred is 5.47%. The variation in overheads for different benchmarks is due to the different injection rates of the applications. At low injection rates, the relative impact of PAP induced congestion is larger, resulting in higher RLAN overhead. 6.4 Area and Power We evaluate the overheads by adding the security features in a standard SoC OCP interface [21]. RLAN incurs an area overhead of 12.73% due to the hardware for PAP creation and latency comparison. Table 2 shows the power overhead for NLD Single Application Multiple Application FP FN FP FN 10 12 14 16 Table 1: False Positive(FP) and False Negative(FN) rates with CDF threshold of 30% and four NLD values: 10, 12, 14 and 16 for both Single and multiple application environment. 2.13% 0% 0% 0% 0% 0% 0% 1.83% 17.88% 0% 0% 0% 0% 0% 0.76% 6.21% df 0.1 0.25 0.5 0.8 Power Overhead 1.49% 3.28% 6.26% 9.84% Table 2: Power Overhead due to RLAN conﬁgurations (df ) with the standard OCP interface as our baseline. different conﬁgurations of RLAN. The RLAN circuit is active only for the length of the test and is power gated for the rest of the application execution time. Hence, the detection factor plays a role in deciding the power overhead incurred. For a detection factor of 0.8, the RLAN circuit is active for 80% of the test phase and incurs a power overhead of 9.84%. 7. RELATED WORK Security assurance of on-chip hardware components is an obstacle of growing magnitude and importance. We limit our discussion primarily on NoC security—the focus of our work. Broadly, we can classify recent works on two major axes based on their underlying assumptions: (a) the source           of threat and (b) the nature of security violation. We can assess the ﬁrst component by inspecting the threat model, while the second component can be determined by understanding the malicious activity from the perspective of the security properties of a system—conﬁdentially, integrity, and availability. A vast majority of recent works assume a secure NoC, where the threat is assumed to rise from the software or the processing elements. Data Protection Unit (DPU) proposed by Fiorin et al. [8] and Secure Network Interface (SNI) by Diguet et al. [7]) are two such works that analyze secure access control on memory banks. Few works employ encrypted data transmission over the NoC (e.g., [12, 17]) or partition the NoC into separate zones based on trust [26, 27]. On the other hand, some works have looked into creating efﬁcient chip resource partitioning to isolate secure and non-secure applications [3, 27]. These works are also primarily concerned with the conﬁdentiality of the transmitted data. Sonics interconnects [1] provides a programmable ﬁrewall to protect the system integrity. Another class of works inspects security threats violating the availability of the on-chip NoC bandwidth, and explores techniques within the scope of a secure NoC. Diguet et al.’s work on SNI can protect from denial of service (DoS) attack caused by replay, livelock, deadlock and incorrect path. Fiorin et al. propose the use of DoS probe as a part of the NoC monitoring architecture [9]. Parallel to these works in security, there have been numerous proposals to provide quality of service (QoS) guarantees in a NoC [6]. QoS techniques reserve a desired fraction of bandwidth to each IP core to mitigate bandwidth reduction attacks from malicious code running on the cores. Sepulveda et al. [23] implemented security as a dimension of QoS also aimed to avoid denial-ofservice attacks. While these works are conceptually closer to our work, the proposed mechanisms are impractical in our threat model, as we cannot modify the NoCs derived from a 3PIP vendor. Similarly, recent work by Ancajas et al. explores a rNoC [4], but their threat model and protection mechanisms are focused on conﬁdentiality and are unable to detect or thwart malicious manipulation of resource availability from a rNoC. We explore a new threat model based on a key underlying assumption: a rogue NoC manipulating the availability of the on-chip communication bandwidth. With NoCs being such an integral part of present and future MPSoCs, the need to investigate trustworthiness of a third party NoC IP is immense. The work presented here is distinct from contemporary secure 3PIP works, primarily in two aspects. • In the light of proliferation of 3PIP NoCs, we explore a threat where the NoC is malicious. Hence, unlike a majority of existing works, we cannot assume that security measures can be placed inside the NoC architecture. • Our threat model is concerned with the perceived availability of on-chip resources. 8. CONCLUSION This papers outlines a new security threat stemming from the pervasive use of a 3PIP NoC, where a rogue NoC can disrupt the on-chip resource availability. We determine the feasibility of rNoC design by evaluating its design footprint. We propose a low overhead runtime latency auditor for NoCs to dynamically monitor the availability on-chip resources throughout the chip lifetime, thereby effectively countering this emerging security threat. Our technique RLAN is scalable to larger networks and has a modest overhead of 12.73% in area, 9.34% in power and 5.4% in terms of network latency. Acknowledgments This work was supported in part by National Science Foundation grants (CNS-1117425, CAREER-1253024, CCF-1318826, CNS-1421022, CNS-1421068). Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views of the NSF. 9. "
A Framework for Combining Concurrent Checking and On-Line Embedded Test for Low-Latency Fault Detection in NoC Routers.,"The focus of the paper is detection of faults in NoC routers by combining concurrent checkers with embedded on-line test to enable cost-effective trade-offs between area-overhead and test coverage. First, we propose a framework of tools for formally evaluating the quality of the checkers and for optimizing the overhead area with given fault coverage constraints. The stress is in particular on the minimization of the error detection latency, which is a crucial aspect in order to eliminate (or limit) error propagation. Second, the concurrent checkers will be complemented by embedded on-line test packets which are to be applied as a periodic routine during the idle periods in router operation. The framework together with the corresponding methodology has been successfully applied to a realistic case-study of a fault tolerant NoC router design. The case study shows that combining concurrent routers with embedded test allows reducing the area overhead of the checkers from 31--35% down to 1.5--10% without sacrificing the fault coverage.","A Framework for Combining Concurrent Checking and OnLine Embedded Test for Low-Latency Fault Detection in  NoC Routers  Pietro Saltarelli  Università degli Studi di Ferrara   Via Savonarola, 9  44121 Ferrara FE, Italy  pietro.saltarelli@student.unife.it  Ranganathan Hariharan  Behrad Niazmand, Jaan Raik,  Vineeth Govind, Thomas  Hollstein, Gert Jervan  Tallinn University of Technology  Department of Computer Engineering  Akadeemia 15a, 12618 Tallinn, Estonia  Phone: +372 6202257  <behrad|jaan>@ati.ttu.ee    not achieve 100% fault detection. For these checkers the formal  qualification step described above is not possible and traditional  fault injection experiments are carried out by a sequential fault  simulation tool included to the framework.  Finally, the checkers for the control part of the router are to be  complemented by embedded on-line test packets which are to be  applied as a periodic routine during the idle periods in router  operation, e.g. slacks in the task scheduling. The framework  together with  the corresponding methodology has been  successfully applied to a realistic case-study of a fault tolerant  NoC router design. The case study shows that combining  concurrent checkers with embedded test packets allows reducing  the area overhead of the checkers from 31-35% down to 1.5-10%,  depending on the router bitwidth, without sacrificing the fault  coverage.  The paper is organized as follows. Section 2 provides an overview  of related works in concurrent online testing and embedded test  for NoC routers. Section 3 explains the concurrent online  checking concept. Section 4 discusses application of embedded  test packets. In Section 5, the automated framework and the  corresponding methodology for checkers’ minimization combined  with the embedded test are presented. Section 6 discusses  application of the framework and the underlying methodology to  the NoC router design. Section 7 provides the experiments.  Finally, Section 8 concludes the paper.  2. RELATED WORKS  Online detection of errors in logic is a thoroughly studied  research area. Traditional Triple-Modular Redundancy (TMR)  and duplication based approaches are too costly in terms of  multiplying the area and correspondingly the power consumption.  An alternative to minimize this overhead is the selective TMR that  identifies Single Event Upset (SEU) sensitive sub-circuits that are  to be protected [1].  In addition, there exists a variety of solutions based on coding  techniques such as Berger [2] or Bose-Lin [3] codes. In many  works the coding techniques are combined with synthesis [4,5].  The approaches suffer from significant area overhead to the  design to be checked.  Concurrent on-line built-in self-test techniques such as BuiltIn Concurrent Self-Test (BICST) [6] and Reduced Observation  Width Replication (ROWR) [7] provide high fault coverage at  low area overhead but only consider a limited subset of precomputed test vectors. Hence these approaches are likely to miss  faults occurring in a normal circuit operation.   Several alternatives based on checkers that do not require  modification of the circuit under test have been developed.  Creating checkers automatically based on logic implications  derived from the circuit structure [8] is feasible but suffers from  low fault coverage and high area overhead, often exceeding the  duplex solutions. On the other hand, deriving checkers from  functional assertions, or reusing verification assertions,  is  similarly known to yield low coverage of structural faults as it is  difficult to correlate functional coverage to structural one [9].  Many previous works have focused on addressing faults in the  control logic of NoC routers. In [16], Yu et al. have addressed  fault tolerance for NoC topologies and proposed an error control  method for detecting transient errors in routing logic implemented  using Logic-Based Distributed Routing (LBDR) mechanism and  its extension for high-radix topologies, LBDRhr. The proposed  error control method utilizes the inherent information redundancy  (IIR) to reduce the error control overhead. However, the method  does not guarantee full fault coverage.  Authors of [17] have presented a method for online error  detection and diagnosis of NoC switches. The proposed method  deals with routing faults that cause packets to be forwarded to  unintended output ports. Regarding modeling routing faults in  switches, a high-level fault model has been introduced in this  work. The fault coverage is measured only at the functional level  and there is no estimates on correlation to gate-level fault  coverage.  In order to deliver correctness guarantees for the complete  network, Parikh et al. have proposed a network-level detection  and recovery solution ForEVeR [14] that monitors the traffic in  the NoC and protects it against functional bugs that were not  detected during design time. To this end, ForEVeR augments the  baseline NoC with a lightweight checker network that alerts  destination nodes of incoming packets ahead of time and is used  for the recovery process. The approach suffers from extremely  high latency. Only 30% of the faults will be detected during the  first clock cycle by the approach.  The work in [15] proposes checkers synthesized from a set of  32 verification assertions. The checkers detect most of the injected  faults. The faults that are not covered correspond to non catastrophic failures. The work proposed in [15] is not automated  and lacks the completeness and minimization aspects present in  the current paper.  In [18] a hybrid method is introduced for synthesis of faultsecure NoC switches utilizing error detecting codes for the data  path (data flits) and a concurrent error detection structure for  dealing with faults not covered by the flit encoding (using  multiple parity trees). However, the work still results in more than  50% area overhead.  The use of embedded test configurations for testing the  datapath of NoC routers has been proposed in [19], with designfor-testability structures included in [20] and built-in self-test  application in [21]. However, all the mentioned approaches are  targeting  the global network and not a concrete router.  Furthermore, only off-line test scenarios have been considered in  [19-21].  This paper exceeds the existing state-of-the-art in fault  tolerant router design by proposing:  -  a framework for formal checker qualification. The underlying  approach is complete, i.e. it allows proving the absence or  presence of true misses by the checkers. In addition, it provides  minimal fault detection latency due to the fact that the circuit is  transformed into a pseudo-combinational one and therefore only  checkers with a single clock cycle latency are considered.  - automated minimization of checkers. The formal qualification  of the combinational checkers provides the fault detection  capabilities for them. These, along with the checker area  requirements are applied in an automated minimization process  resulting in a minimal area overhead checker solution under  certain fault coverage constraints.  complementing the resulting checkers withtemporal checkers  and on-line embedded test packets. This enables combining best  -  of both worlds. In the case of NoC control part, where  embedded test packet based approaches have proven inefficient,  low area concurrent checkers are applied. On the other hand, in  the datapath, the embedded test yields full fault coverage  whereas error correcting codes would be expensive.  Experimental results on a realistic NoC router design demonstrate  the efficiency of the proposed approach.  3. THE CONCEPT OF CONCURRENT  CHECKERS  Fig. 1 presents the role of concurrent on-line checkers in detecting  faults within a circuit. In addition to the original circuit  (functional logic), a set of checkers (checker logic) will be  connected to functional inputs/outputs of the circuit. These  checkers are derived based on functional assertions obtained from  relationships between variables corresponding to inputs and  outputs of the circuit. The checker logic targets the faults at lines  at the inputs of each gate within the functional logic (marked by  green circles). The lines at the functional outputs succeeding the  checker inputs (marked by a red cross) cannot be detected by the  checker. In addition, the checkers are not targeting the faults at  functional inputs preceding checker inputs, since the checker may  not detect that the input value has been altered by a fault (such  functional input lines are also marked by a red cross in Fig. 1). In  this paper, we consider the single stuck-at fault model. However,  due to the fact that concurrent checkers are implemented and atspeed embedded test packets are applied, the model also covers  timing related faults.  outputs and onwards to the system. However, the system has no  information that a critical fault has occurred.  Traditionally, in order to evaluate the fault detection quality of  the checkers, fault injection has been applied. Fault injection  refers to injecting faults into a circuit at a certain time step and  simulating it with the input stimuli to see whether any functional  output of the circuit changes and whether any of the checker  output fires. Due to the fact that it is generally impossible to inject  and simulate all the faults at each circuit line at each time step, a  statistically significant sample of random faults would normally  be injected and simulated.   However, in this paper a methodology is proposed which is  based on automated extraction of a pseudo-combinational circuit  out of the original functional logic by breaking the flipflops and  converting them to pseudo primary inputs and pseudo primary  outputs. Further, an exhaustive test for the extracted circuit is fed  through a filtering tool in order to derive the complete valid set of  input stimuli which will serve as the environment for checker  evaluation. This means that in this paper full formal qualification  of the combinational checkers with all possible stimuli and faults  can be obtained.  Let D be the number of true detections, X be the number of benign  misses, F be the set of false positives and W be the number of true  misses over all the injection runs. In order to evaluate the fault  detection capabilities of the checkers we define the metrics of  Fault Coverage (FC), Checkers’ Efficiency Index (CEI) and False  Positive Ratio (FPR) as follows.  FC (cid:32) CEI (cid:32) FPR (cid:32) (cid:14) (cid:14) XD WXD D WD F XF (cid:14) (cid:14) (cid:14)                        (1)                                 (2)  (3)  Here, FC shows the probability of the checkers behaving correctly  over all possible fault cases, CEI shows the probability of  checkers ability to detect critical faults whereas FPR reports the  ratio of false positives over all the cases a fault did not propagate  to circuit outputs. The mentioned three metrics are calculated for  checkers by the automated checker qualification framework  proposed in this paper.  4. EMBEDDED ONLINE TEST PACKETS  The functional fault model that is applied to cover the stuck-at  faults in the datapath of the NoC router is based on the idea  proposed for fuctional testing of mesh-like NoC networks in [1921]. However, in this paper the fault model is applied to a  “localized” approach, where resources (i.e. processing elements)  connected to neighbouring routers West (W), East (E), North (N),  South (S), and Local (L) are utilized as senders/receivers of test  packets to test the central router as the Circuit Under Test (CUT).  Figure 2 visualizes the overall setup of the sending/receiving  resources and the CUT.  Figure 1. The concept of concurrent checking  Given a fault at a line within the functional logic and a set  of input stimuli, four possible scenarios may occur:  Case 1: Fault occurs at an internal line and is visible at functional  output(s) and checker logic flags a violation. The term True  Detection is used to describe this situation, since a critical fault is  effectively detected by the checker.   Case 2: Fault occurs at an internal line but is not visible at  primary output(s). Checker catches the fault and flags a violation.  The term False Positive is used to describe this situation. False  positive is not harmful because an error is flagged which did not  have any effect. However, it has negative impact on design’s  performance because normally it causes re-execution of the task.   Case 3: Fault occurs at internal line but is not visible at primary  output(s) and the checker logic does not detect the violation. The  term Benign Miss is used to describe this situation. Benign miss  shows correct operation by the checker.  Case 4: Fault occurs at internal node and is visible at primary  output(s). Checker does not detect violation. The term True Miss  is used to describe this situation, which is the worst possible case.  True miss means that the fault propagates to the functional                 circuit will be extracted from the circuit of the design under  checking. The pseudo-combinational circuit is derived out of the  original circuit by breaking the flipflops and converting them to  pseudo primary inputs and pseudo primary outputs. Note, that at  this point additional checkers that also describe relations on the  pseudo primary inputs/outputs may be added to the checker suite  in order to increase the fault coverage.  Subsequently, the checkers’ qualification environment is created  by generating exhaustive test stimuli for the extracted pseudocombinational circuit. This stimuli are fed through a filtering tool  that selects only the stimuli that correspond to functionally valid  inputs of the circuit. As a result, the complete valid set of input  stimuli  that will serve as  the environment for checkers’  qualification is obtained.  Figure 3. Checkers’ qualification and minimization flow  The obtained environment, pseudo-combinational circuit and  synthesized checkers are applied to fault free simulation. The  simulation calculates fault free values for all the lines within the  circuit. Additionally, if any of the checkers fires during fault-free  simulation it refers either to a bug in the checker or an incorrect  environment.   If none of the checkers is firing in the fault-free mode then  checkers’ qualification takes place. The tool injects faults to all  the lines within the circuit one-by-one and this step is repeated for  each input vector. As a result, the overall fault detection  capabilities for the set of checkers, in terms of FC, CEI and FPR  metrics will be calculated. In addition, each individual checker  will be weighted by summing up the total number of true  detections by the checker.  The weighting information will then be exploited in minimizing  the number of checkers, eventually allowing to outline a trade-off  Figure 2. The setup for sending/receiving test packets  In the proposed setup, whenever there are idle periods or slacks in  scheduling with length K for the send/receive resources, K test  patterns will be applied from them. This will be done periodically  fetching K next tests from the test set in a circular manner, i.e. if  the end of the test is reached then it starts again from the  beginning. This scenario provides online test capabilities for  regularly checking the health of the datapath of the routing  infrastructure.  A fault model proposed in [19-21] is applied, where the value at a  selected router input is distinguished from the values at other  inputs of the router. In order to fully cover the structural faults in  the multiplexers of the crossbar, tests for each address value have  to be performed. An additional constraint is that all turns must be  covered by the distinguishing tests. In [19] it was shown that by  applying them, near 100% fault coverage for the crossbar switch  and the I/O buffers comprising the datapath of the NoC router is  achieved.  5. FRAMEWORK AND METHODOLOGY  This Section presents the framework for fault tolerant NoC router  design that has been developed as an extension of the Turbo  Tester test framework [10]. The proposed methodology of  combining concurrent checkers with embedded online test  consists of three main steps:  1. Checkers’ qualification and minimization (combinational  checkers);  2. Checkers’ evaluation by  checkers);  3. Fault simulation of the embedded online test packets.  In the following, these steps are explained in more detail.  (temporal  fault  injection  5.1 Checker Qualification and Minimization  Fig. 3 presents the qualification and minimization flow for the  checkers. The flow starts with synthesizing the checkers from a set  of combinational assertions. Thereafter, a pseudo-combinational          between the fault coverage, and the area overhead due to the  introduction of checker logic.  5.2 Checkers’ Evaluation by Fault Injection  There are cases when a module under checking cannot be handled  by the combinational checker qualification and minimization  approach. For example the module may have a large number of  inputs so that the set of generated valid input stimuli would be too  large (e.g. datapath modules) and/or the fault coverage reached by  the combinational checkers is too low.  In those cases, the checkers are to be evaluated by traditional fault  injection. Here a test bench is created for the design and the  circuit with the checkers is simulated by a sequential fault  simulator with a sufficiently large random sample of faults  injected into the circuit. In this paper, all the datapath checkers  and the FIFO checkers were evaluated using this approach.  5.3 Fault Simulation of the Embedded Test  Finally, the stuck-at fault coverage of the online embedded test  packets for the datapath of the NoC router is measured by a fault  simulator belonging to the framework. As experimental results  show, full fault coverage for the datapath with the test application  time of 196 clock cycles is achieved.  6. EXPERIMENTAL RESULTS  Fig. 4 demonstrates the high-level overview of a 5-port 2D NoC  router that we have chosen as a target architecture for applying the  checkers. The router consists of a datapath and a control part. The  datapath is composed of input buffers (implemented as FIFO),  one for each input port, a crossbar switch and an output buffer for  each output port. The control part contains routing units, arbiters  and FIFO control. For the routing unit of our target architecture,  we have opted for Logic-Based Distributed Routing (LBDR)[13],  which is considered as a scalable solution compared to routing  tables. As an arbiter, round-robbin arbitration was implemented.  Figure 4. High level architecture of the NoC router  6.1 Checker Qualification/Minimization for  LBDR/Arbiter  The pseudo-combinational circuit for ELBDR has 11 input  bits, as mentioned in the previous section, thus the exhaustive set  of stimuli presents 211=2,048. A filtering scheme based on the  following statements was devised:  (cid:131) if input buffer’s empty signal is high, any other input bit is  meaningless, and therefore any value is allowed for it;  (cid:131) if the incoming flit is a header, the destination address has to  be valid according to the XY routing and turns restrictions;  (cid:131) if the incoming flit is a body or tail flit, the previous output  values must be valid, they must follow a one-hot fashion,  according to XY routing.  This allowed to obtain a valid and complete set of stimuli  consisting of 1536 vectors, which forms 75% of the exhaustive  set. The run-time for generating the stimuli was 2 seconds. (All  the experiments in this paper were carried out on an Asus ux32vdr4002v computer with a 1.9 GHz Intel Core i7-3517U processor  and 10 GB RAM.)  Table 1 lists the obtained minimized set of three checkers for the  LBDR. Reducing the set of checkers to the three most significant  ones allows to limit the area overhead to 78.57% over the ELBDR  circuit, far lower than 185.71% imposed by the initial nonminimized set of checkers, while the CEI and FC remain at 100%.  Table 1. A minimized list of checkers for the LBDR  Checkers for Routing Logic (LDBR)  1 Valid LBDR  If there is a request to the routing  output  logic (the corresponding input buffer  is not empty), LBDR has to compute  at least one valid output direction  (according to XY routing).   If no flit arrives (the corresponding  input buffer is empty), all the output  port signals of LBDR should remain  zero.  If the corresponding input buffer is  not empty (there is a request to  LBDR), because of using XY  routing, at most only one output port  signal of the LBDR logic can  become active.   Single LBDR  output  2 No LBDR output  3  Similarly, Table 2 lists the minimized set of two checkers for the  Arbiter that was obtained from an initial set of 28 verification  checkers by applying the checker qualification and minimization  framework.  Table 2. A minimized list of checkers for the Arbiter  Checkers for Arbiter logic  4  Valid Grant  If there is a request from LBDR,  output  arbiter has to assert at least one of the  grant signals for the corresponding  output direction.  State variable of the arbiter FSM has  to respect one-hot encoding.  Invalid arbiter  State  5              6.2 Fault Injection Experiments for the FIFO  Table 3 lists the set of 8 checkers generated from the verification  assertions for the FIFO control part. The checkers were evaluated  by the fault injection tool of the framework. A set of input stimuli  for the FIFO was devised, aiming to cover all the possible  situations for the control logic. The following conditions were  considered in the pattern generation procedure:  -  reset condition;  -  filling the FIFO, followed by reading up to empty condition;  -  smooth traffic condition, i.e. concurrent writing and reading  operations, avoiding the FIFO to get full;  idle condition, i.e. write and read enable signals low, during  reading and writing operations, in different conditions of  fulfillment of the buffer.  -  100% CEI and FC were achieved on the control part of the FIFO,  considering the patterns derived from the previously listed  conditions, amounting to 134. Run time for the experiment was  0.06 s. No false positives were encountered in this experiment.  Table 3. Checkers for the FIFO Control Part  Checkers for FIFO control part  6  Reset checker  Whenever reset goes high, at the  next clock cycle empty flag should  be high (reading and writing pointer  are reset to the same value).  Empty and full flags should never be  high at the same time. Whenever the  defining condition occurs, the  corresponding flag should go high at  the next clock cycle.  Reading and writing pointers have to  respect one-hot encoding.  Flags checkers  7  8  9  One-hot pointers  checkers  Registers enable  DMR checker  10 Reading pointer  update checker 1  11 Reading pointer  update checker 2  12 Writing pointer  update checker 1  13 Writing pointer  update checker 2  Duplication and comparison for the  logic enabling the writing operation  in data registers.  Whenever read enable is high and  the FIFO is not empty, at the next  clock cycle the reading pointer  should be updated.  If either read enable is low or the  FIFOis empty, at the next clock  cycle the reading pointer should  preserve its value.  Whenever write enable is high and  the FIFO is not full, at the next clock  cycle the writing pointer should be  updated.  If either write enable is low or the  FIFO is full, at the next clock cycle  the writing pointer should preserve it  value.  Table 4 lists the set of 3 additional checkers which were included  in order to achieve the full fault coverage after fault injection  experiments for the control part identified uncovered faults in the  interconnections of control part modules.  Table 4. Control Part Infrastructure Checkers  Control Part Infrastructure Checkers  14 FIFOs read  Logic producing read enable signals  for the FIFOs (5 OR gates) is  enable DMR  duplicated, then real and duplicated  checker  outputs are compared.  15 Output  Logic producing enable signals for  registers enable  the output registers (5 OR gates) is  duplicated, then real and duplicated  DMR checker  outputs are compared.  16 Flit type LBDR  Flit type field of a flit has to respect  error  one-hot encoding.  6.3 Checkers for the Datapath  In order to fully cover the faults in the NoC datapath two types of  concurrent checkers were introduced (listed in Table 5). First, for  each input port an even parity bit is included, whereas each output  port has a checker evaluating the even parity. Second, since fault  injection experiments for the whole router identified undetected  faults within the crossbar multiplexers, dedicated checkers for the  crossbar were devised.  Table 5. Checkers for the NoC Datapath  Datapath Checkers  17 Even parity  checker  An even parity bit is computed and  added to data entering each input  port, which is later evaluated before  data leaves the router through any of  the output ports.  Crossbar MUXs are duplicated, then  real and duplicated outputs are  compared.  18 Crossbar   checker  6.4 Putting It All Together  Fig. 5 reports the area overhead required by the checkers for  routers of varying bitwidth (from 32 bits to 256 bits). It can be  observed from the Figure that the required area for the control  part checkers stays constant while the overhead area of datapath  checkers (parity and crossbar) grow proportionally to the router  size.                        overhead of the checkers from 31-35% down to 1.5-10% without  sacrificing the fault coverage.  8. ACKNOWLEDGMENTS  The work has been supported in part by EU’s FP7 STREP project  BASTION and H2020 RIA IMMORTAL, by Estonian ICT  program project FUSETEST, by Research Centre CEBE funded  by European Union through the European Structural Funds and  by Estonian SF grant 9429.   "
An Interconnection Architecture for Seamless Inter and Intra-Chip Communication Using Wireless Links.,"With increase in complexity of multicore chips, efficiency of data transfer between cores of a chip is becoming increasingly challenging. Several novel on-chip network architectures are proposed to improve the design flexibility and communication efficiency in multicore chips. On the other hand, computing modules in typical data center nodes or server racks consist of several multicore chips on either a board or in a System-in-Package (SiP) environment. State-of-the-art interchip communication over wireline channels require data signals to travel from internal nets to the peripheral I/O ports and then get routed over the interchip channels to the destination chip. After reaching the destination chip they will be finally routed from the I/O to the internal nets there. This multihop communication increases latency and energy consumption while decreasing data bandwidth in a multichip system. Moreover, intrachip and interchip communication within such a multichip system is often decoupled to facilitate design flexibility. However, a seamless interconnection between on-chip and off-chip data transfer can improve the communication efficiency significantly. In this work we propose the design of a seamless hybrid wired and wireless interconnection network for multichip systems in a package with dimensions spanning up to tens of centimeters with on-chip wireless transceivers. This enables direct chip-to-chip communication between internal cores. We demonstrate with cycle accurate simulations that such a design increases the bandwidth and reduces the energy consumption in comparison to state-of-the-art wireline I/O based multichip communication.","An Interconnection Architecture for Seamless Inter and  Intra-Chip Communication Using Wireless Links  Md Shahriar Shamim   Jagan Muralidharan   Dept. of Computer Engineering   Rochester Institute of Technology  Rochester, NY-14623  +16319658435  ms5614@rit.edu  Dept. of Computer Engineering  Rochester Institute of Technology  Rochester, NY-14623  +15857333999  jm4880@rit.edu  Amlan Ganguly   Dept. of Computer Engineering  Rochester Institute of Technology  Rochester, NY-14623  +15094324028  axgeec@rit.edu  ABSTRACT  With increase in complexity of multicore chips, efficiency of data  transfer between cores of a chip is becoming increasingly  challenging. Several novel on-chip network architectures are  proposed to improve the design flexibility and communication  efficiency in multicore chips. On the other hand, computing  modules in typical data center nodes or server racks consist of  several multicore chips on either a board or in a System-inPackage  (SiP)  environment.  State-of-the-art  interchip  communication over wireline channels require data signals to  travel from internal nets to the peripheral I/O ports and then get  routed over the interchip channels to the destination chip. After  reaching the destination chip they will be finally routed from the  I/O to the internal nets there. This multihop communication  increases latency and energy consumption while decreasing data  bandwidth in a multichip system. Moreover, intrachip and  interchip communication within such a multichip system is often  decoupled to facilitate design flexibility. However, a seamless  interconnection between on-chip and off-chip data transfer can  improve the communication efficiency significantly. In this work  we propose the design of a seamless hybrid wired and wireless  interconnection network for multichip systems in a package with  dimensions spanning up to tens of centimeters with on-chip  wireless  transceivers. This  enables  direct  chip-to-chip  communication between internal cores. We demonstrate with  cycle accurate simulations that such a design increases the  bandwidth and reduces the energy consumption in comparison to  state-of-the-art wireline I/O based multichip communication.    Categories and Subject Descriptors  C.2.1  [Computer-Communication Networks]: Network  Architecture and Design – Network Communications, Network  topology.  General Terms  Performance, Design.  Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for components of this work owned by others than ACM must be  honored. Abstracting with credit is permitted. To copy otherwise, or  republish, to post on servers or to redistribute to lists, requires prior  specific  permission  and/or  a  fee. Request  permissions  from Permissions@acm.org.  NOCS  '15, September 28 - 30, 2015, Vancouver, BC, Canada   ©  2015  ACM.  ISBN  978-1-4503-3396-2/15/09…$15.00   DOI: http://dx.doi.org/10.1145/2786572.2786581  Keywords  Network-on-Chip,  interconnect.  Inter-chip  communication,  wireless  1. INTRODUCTION  Computing modules with multiple multicore chips are allpervasive in hardware infrastructures from servers to datacenters.  An example of such multicore multichip module is the IBM  Power Series which  is a processor system designed for  sophisticated clusters [13]. Due to scaling up of number of  individual computing nodes by several orders of magnitude in  these systems,  interconnection between  them has become  increasingly complex. Moreover, in typical data center or server  environments lower level cache is physically distributed between  all cores. Hence, cache or memory access eventually requires  communication between cores in different chips. While intrachip  communication infrastructure is seeing a paradigm shift from busbased systems to Network-on-Chip (NoC) architectures [3],  interchip communication is also evolving at a rapid pace to cater  to increasing bandwidth demands within strict power envelopes.  Interchip interconnections vary from solder bumps or C4  interconnects in multichip modules within a System-in-Package  (SiP) spanning 10mm in range on one end , to ethernet used in  datacenter warehouses spanning about a kilometer on the other as  shown in Figure 1. Other chip-to-chip interconnects such as  Peripheral Component Interconnect (PCI) is the most common  standard local I/O bus technology to interconnect board-level  multichip modules. Recently, PCI express (PCIe) [23] is presented  as next generation I/O technology. For improved scalability,  latency and bandwidth requirements in large High Performance  Computing (HPC) environments the use of specialized hardware   Figure 1. Range of different interconnection architectures        and communication protocols such as InfiniBand [14] or Myrinet  [17] is commercially used.   2. RELATED WORK  Recent trends according to the International Technology Roadmap  for Semiconductors (ITRS) predict that the pitch of the I/O  interconnects in ICs is not scaling as fast as the gate lengths or  pitch of on-chip interconnects [15]. This implies a gap in density  and performance of traditional I/O systems relative to on-chip  interconnections. The wiring complexity of both on-chip and offchip interconnects exacerbates the problem by posing design  challenges, crosstalk and signal integrity issues. Additionally,  because of different interconnection frameworks for on-chip and  off-chip communication, data from cores located within the chips  need to travel to the I/O blocks, traverse the interchip link and  then be routed to the final destination inside the destination chip.  Besides, switching between protocols is necessary if the off-chip  communication protocol is different from the on-chip one. All  these factors reduce the efficiency in terms of energy consumption  as well as latency and bandwidth of the data transfer between  cores in a multichip system. Integrated inter and intra chip  photonic interconnections [12] and vertically integrated 3D ICs  [26] are promising solutions to the off-chip interconnection  challenges of traditional I/O. However, the pitch of photonic  interconnects do not scale well due to the limitations in size of  silicon-photonic devices. Moreover, the manufacturing of electrooptic components to enable such a photonic interconnection is not  compatible with standard CMOS processes. On the other hand 3D  Integration requires sophisticated thermal management techniques  while achieving low yields.  Research in recent years has demonstrated the on-chip and offchip wireless interconnects which are capable of establishing  radio communications. Wireless data communication links up to  10m in length with multi GigaHertz bandwidths in millimeterwave (mm-wave) bands are fabricated and demonstrated [18].  Using such on-chip antennas embedded in the chip wireless NoC  architectures have been proposed [5]. These wireless NoCs are  shown to improve energy efficiency and bandwidth of on -chip  data communication in multicore chips. However, the design of  low-power wireless transceivers to create multiple frequency  bands for on-chip communications is a non-trivial challenge.  Hence, these limitations need to be overcome with innovative  architecture design and medium access mechanisms.  In this work we propose to use wireless interconnects to establish  a seamless communication backbone for multichip systems within  a single package which enables data exchange between cores in a  single chip as well as between chips in a multichip system with  dimensions spanning up to a few tens of centimeters. The same  communication protocols used for on-chip data transfer will be  used for off-chip data as well, eliminating the need for protocol  transfer. Few cores inside the chips will be equipped with wireless  transceivers which will be capable of establishing direct one-hop  communication with other such cores in the same as well as other  chips. By deploying the wireless transceivers in the internal nodes  of the chips such that all cores are within a short distance from  their nearest transceivers, energy-efficient inter and intrachip  communication can be achieved. Here, we present the design  methodologies for two different interconnection architectures for  such multicore multichip systems in packages and demonstrate  that the proposed design outperforms traditional wired I/O based  multichip systems through system-level simulations.  According to ITRS the pitch of chip-to-chip I/O does not scale in  the same proportion as on-chip global wires [15]. This creates a  gap in performance of on-chip interconnections with respect to  off-chip communication. Conventionally, C4 bumps coupled with  in-package transmission lines are used to interconnect chips  within a multichip system [16]. Integrated intra and interchip  photonic network have been proposed to mitigate the performance  issues of conventional I/O based on-board systems [25]. A  wireless data center with mm-wave inter-rack links is envisioned  in [25]. In [29] wirelessly connected multichip module are  proposed for a High Performance Computing (HPC) environment.  In  [19]  transceivers  for 60GHz  inter  and  intra-chip  communications are designed. In [4] on-chip wireless transceivers  are used to facilitate fast prebonding wafer testing enabled by  direct accesses to components under test within the ICs.  On the other hand, novel interconnect paradigms such as wireless  links are envisioned for on-chip data communications as well. A  comprehensive survey regarding various wireless NoC (WiNoC)  architectures and their design principles is presented in [7].  Onchip antennas from graphene or Carbon Nanotube (CNT) based  structures are predicted to provide high bandwidth wireless  communication channels [1] [10]. However, integration of these  antennas with standard CMOS processes needs to overcome  significant challenges. Whereas mm-wave CMOS transceivers  operating in the sub-THz frequency ranges is a more near-term  solution. In [18] mm-wave wireless on-chip embedded antennas  for intra chip and interchip communication are designed and  evaluated. Medium access mechanisms in WiNoCs using mmwave transceivers range from simple token passing based protocol  to more sophisticated CMDA based mechanisms [5], [30], [8],  [27]. In this work we propose a hybrid inter and intrachip  communication using both on-chip wired links and CDMA based  mm-wave wireless interconnects.  3. WIRELESS MULTICHIP  ARCHITECTURE   The architecture of the proposed multichip system with wireless  interconnects is a hybrid network with both wired and wireless  links. Each core in all the multicore chips is connected with a  NoC switch. The switches within a single chip are interconnected  with an intrachip NoC architecture. To realize the interchip  wireless communications certain switches in the NoC are  equipped with wireless interfaces (WIs). These switches can  directly communicate with their counterparts in the other chips.  Figure 2 shows the conceptual architecture of the multichip  system interconnected with inter and intrachip wireless network.  3.1 Topology  In the proposed architecture cores within each individual chip is  interconnected using an  intrachip NoC. We discuss  the  interconnection architectures for the multichip systems with two  different intrachip NoC topologies as described below:  3.1.1 Multichip System with Intrachip Mesh  In the first multichip architecture the intrachip interconnection  topology is a traditional mesh based NoC. For interchip  communication traditional chip I/O is connected to the periphery  of the chip in one of the corner switches. This requires interchip  data between cores embedded inside the chips to travel to the  periphery then be transferred over the I/O resulting in high latency  and high energy consumption. To alleviate this problem we equip  certain NoC switches associated with cores embedded within the  chip with WIs. In order to deploy the WIs each multichip system  is divided into a certain number of logical subnets. The WIs are  deployed in a switch at the center of the subnets to avoid long  multihop paths from all cores in its subnet, assuming any core can  transmit inter-chip data at some point during the operation of the  system. This improves the connectivity of the entire multichip  system by establishing direct wireless links between internal  switches eliminating the need to travel to and from the periphery  of the source and destination chips respectively.  3.1.2 Multichip System with Intrachip Small-world  Insertion of bypass paths or long-range shortcuts realized with  metal interconnects is shown to improve the performance in a  conventional mesh-based NoC [21]. Small-world networks are a  type of complex networks often found in nature that are  characterized by both short-distance and long-range links. This  improves the efficiency of the network as they have very low  average number of hops between nodes even for very large  network sizes. Hence, such network topologies are suitable for  designing scalable, hybrid intra and interchip interconnection  networks using wireless links in [11].  To establish the wireline links within each intrachip NoC while  satisfying the properties of small-world graphs, we generate the  wireline topology according to the inverse power law to minimize  wiring costs [24].  𝑃(𝑖 , 𝑗) = −𝛼𝑓𝑖𝑗 𝑙𝑖𝑗 𝑛 𝑙𝑖𝑗 −𝛼𝑓𝑖𝑗 𝑗=1 ∑ .     ∑ 𝑛 𝑖=1 (1)  Where, 𝑃(𝑖 , 𝑗) is the probability of establishing a link, between  two switches i and j, lij is the manhattan distance, fij is the  frequency of communication between switch i and j and n is the  total number of switches. The value of α is chosen such that  optimal wiring costs [24] are obtained. The distance is obtained  by considering a tile-based floorplan of the cores on the die. The  frequency of traffic interaction between the cores, fij, is also  factored into (1) so that more frequently communicating cores  have a higher probability of having a direct link optimizing the  topology for application-specific traffic. This power-law based  link distribution results in both short distance connections and  long-range links due to the non-zero probability of links between  far-away nodes. The link setup method is repeated until no core or  groups of cores are left unconnected. In the system with smallworld NoC and wireless interconnects, the same switches are  equipped with the WIs as in the mesh based system to reduce the  path length of interchip data accessing the WIs.   3.2 Physical layer  We envision a multichip system where wireless interconnects will  enable seamless intra and interchip communications. On-chip  communication will happen over the hybrid wireline and wireless  NoC. Wireline links are realized with traditional global-wire  based interconnects depending on the specific topology adopted.   Several alternative technologies exist for realizing on-chip and  off-chip wireless interconnections [1][8][30][5][29]. We envision  the use on-chip embedded miniature antennas that can be  fabricated within the chip to establish direct communication  channels between internal switches of the chips. To realize such  wireless channels we choose on-chip metal zig-zag antennas  which have been shown to be effective in establishing both on chip and off-chip communication [18]. The on-chip antenna for  the WiNoC has to provide the best power gain for the smallest  area overhead. A metal millimeter-wave (mm-wave) zigzag  antenna has been demonstrated to possess these characteristics as  they are more compact compared to a patch antenna. In addition  such mm-wave antennas fabricated using top layer metals are  CMOS process compatible making them suitable for near-term  solutions to the wired interconnect problem [18]. Such mm-wave  60GHz antennas are shown to have a bandwidth of 16GHz for  both intrachip [5] and interchip [29] communications links.  However, due to the significant variation in the antenna gain  between on-chip and chip-to-chip communication the adopted  transceiver needs to have a variable signal boosting capability. We  adopt the variable gain amplifier (VGA) proposed in [6] as it is  shown to be suitable for variable length wireless interconnects in  [20].   We propose to utilize the VGA module with two distinct gain  settings. The VGA based transmitter essentially uses two separate  amplification paths with two different gains. Only one path is  active at any instant of time depending upon whether the data is  traveling to an on-chip or off-chip destination. The control logic  that activates the respective amplifier paths can be easily created  depending on the destination address determined at the network  router or switch. In addition to the VGA the other components of  the transceiver depend on the wireless communication protocol as  discussed in the next subsection.   3.3 Wireless Communication protocol  In mm-wave interconnects wireless bandwidth is limited by the  state-of-the-art  transceiver design  and on-chip  antenna  technology. In order to improve performance, multiple wireless  transceivers need to access the wireless medium to communicate  via the energy-efficient wireless interconnects. Consequently,  multiple transceivers share a single wireless frequency channel.  A  token passing protocol has been adopted in multiple WiNoC  architectures for the WIs to access the shared channel avoiding  interference and contention [5]. However, this limits the access to  the wireless channel to a single wireless transmitter. In order to  alleviate this problem and to enable concurrent communication  between multiple WIs in the system we adopt a Code Division  Multiple Access (CDMA) based channel access mechanism. A  Direct Sequence Spread Spectrum (DSSS) based CDMA scheme  to establish multiple simultaneous code-channels between  multiple WIs is shown in [27]. In this work we use Walsh codes to  create orthogonal code-channels for multiple access of the  wireless medium. Walsh codes are commonly used in many  CDMA applications as they have a low spreading factor.  Spreading factor can be defined as the number of chips in a single  codeword. As each bit in encoded into one of these codewords the  effective data transfer rate decreases by the spreading factor.  Consequently, the latency in data transfer over the wireless link  Figure 2. Architecture of proposed wireless multichip system      routing tree extracted by Dijkstra’s algorithm, as it is inherently  free of cyclic dependencies.  4. EXPERIMENTAL RESULTS  In this section, we demonstrate the performance of the wireless  multichip system. For our experiments we use a cycle accurate  simulator implementing the architectures which monitors the  progress of flits over the switches and links per cycle. We  consider a switch architecture with 3-stages namely, input, output  arbitrations and routing [22]. The mesh and small world NoC  architectures are considered to have 4 VCs in each input and  output port. Each VC has a buffer depth of 2 flits. The wireless  ports with CDMA transceivers have an increased buffer depth of  32 flits to accommodate simultaneous reception from multiple  sources. A uniform random spatial distribution of traffic is used  for the all experiments except in subsection 4.3 where the  performance is evaluated for non-uniform traffic. A packet size of  64 flits is considered with a flit size of 32 bits. All the digital  components are driven with a 2.5GHz clock at 1V. All  simulations are performed for ten thousand cycles allowing for  transients to settle in the first few thousand cycles accounting for  flits that are routed and stalled. In the mesh based NoCs all wired  links are single-cycle links. In the small-world architectures if the  intrachip wireline links are long enough to take more than 1 clock  cycle for transmission of a flit they are pipelined by insertion of  FIFO buffers such that between any two stages it is possible to  transfer an entire flit in 1 clock cycle. The energy dissipation, area  overheads and timing requirements of the NoC switches and the  CDMA codecs are obtained from post synthesis RTL design using  65nm  standard  cell  libraries  (http://cmp.imag.fr) using  SynopsysTM tool suites. The energy dissipation of the intrachip  wireline links are obtained from Cadence layout tools considering  their actual dimensions obtained from assuming a tile-based  floorplan of the NoC on a 20mmx20mm die area for each chip.  The on-chip zig-zag antennas are able to provide a bandwidth of  16GHz around a center frequency of 60GHz [29].  The CDMA  based wireless transceivers achieve a total data rate of 6Gbps [27]  for all the channels while dissipating 20.6272mW power. This  power dissipation is the combined power consumption of all the  components  in  the WI  transceiver  including  the CDMA  encoder/decoder, BPSK modulator, LNA, mixer, ADC [27] and  VGA [6].   The wireline I/O system model is considered to be a high speed  serial I/O [2]. To model the wireline interchip interconnection we  consider traditional chip I/O being connected to the periphery of  the chip in one of the corner switches for both mesh and small world based architectures. To enable concurrent communication  between multiple chips we consider the interchip interconnection  to be a switch based architecture instead of a shared bus. This  chip-to-chip I/O has a bandwidth of 15Gbps and an energy  consumption of 5pJ/bit (75mW at 15Gbps) [2]. The simulator is  annotated with the power consumption parameters of the wireless  links and the serial I/O to model the energy consumption in data  exchange in the multichip systems.  4.1 Wireless link budget analysis  In this subsection we present a link budget analysis to determine  the transmitted power that is required to achieve an acceptable  BER on the intra and interchip wireless CDMA links. The  transmitted power, Pt in dBm on the wireless channels is given by  the following equation.  𝑃𝑡 = 𝑆𝑁𝑅 + 𝑃𝐿 + 𝑁𝑓                                    (2)  Figure 3: Block diagram of mm-wave CDMA based  wireless transceiver  increases by the same factor. Hence, the Walsh codes with a low  spreading factor have a lower impact on bandwidth of the  individual code-channels. The encoding can be performed  digitally by simply XORing the bit and the codeword. The result  is then amplified to the appropriate level by the VGA depending  on the destination. The amplified signal is then modulated and  mixed with the carrier using a Binary Phase Shift Keying (BPSK)  modulator.  At the receiver, a demodulator comprising of a Low Noise  Amplifier (LNA) and a mixer is combined with a low-power, high  speed Analog to Digital Converter (ADC) and a CDMA decoder.  Orthogonal codes ensure that the correlation between different  code-channels is zero and bits transmitted in other channels do not  affect the received bit. We adopt a Transmitter-based CDMA  protocol where each transmitter encodes the data into a specific  code channel whereas the receivers are equipped with decoders  for all the channels. Hence, each receiver can receive data from  multiple transmitters concurrently. However, each transmitter can  only send data to a specific destination using the CDMA based  wireless links. Figure 3 shows the mm-wave CDMA based  wireless transceiver used in this paper.  3.4 Routing   The routing protocol for the proposed multichip system is a  seamless intra and interchip data communication mechanism. We  adopt wormhole switching for both inter and intrachip data where  data packets are broken down into flow control units or flits [9].  All switches have bidirectional ports for all links attached to it.  All cores in the system have unique addresses. As the overall  system is not a regular network we adopt a shortest path routing to  optimize network performance. We use a forwarding-table based  routing over pre-computed shortest paths determined by Dijkstra’s  algorithm. As a result, the wireless links can also be used for  intrachip communication if they reduce the path lengths compared  to a completely wireline path. Each switch only forwards the  header flits to the next switch in the path to the final destination.  The body flits simply follow the path laid out by the header  according to the adopted wormhole switching protocol. Hence,  each switch only has local forwarding information eliminating the  need for maintaining non-scalable global routing information.  Deadlock is avoided by transferring flits along the shortest path    Where, SNR is the signal to noise ratio at the receiver in dB, PL is  the path loss in dB and Nf is the receiver noise floor in dBm.  Assuming perfect orthogonality in the CDMA code channels, an  SNR of 15dB results in a BER of less than 10-15 for the BPSK  modulated scheme adopted here. A BER of 10 -15 is comparable to  wireline data transfer in current technologies. Hence, we consider  a required SNR of 15dB in our link-budget analysis. The path  loss, PL in intra-chip links using mm-wave zig-zag antennas is  shown to be -26dB [5].  Similar antennas are shown to have path  loss of -35dB for typical interchip distances of a few centimeters  [29]. The noise floor of the receiver is given by,  𝑁𝑓 = 10 log 𝑘𝑇𝐵 + 𝑁𝐹                                     (3)  Where, k is the Boltzmann constant, T is the temperature, B is the  bandwidth of the receiver and NF is the noise figure of the  receiver in dB. The noise figure of the receiver depends on the  LNA and is given by,  𝑁𝐹 = 10 log(1 + 𝐹𝐿𝑁𝐴 + 𝐹𝑚𝑖𝑥𝑒𝑟 𝐺𝐿𝑁𝐴 )                    (4)  Where, FLNA, Fmixer and GLNA are the noise figure of the LNA,  mixer and the gain of the LNA respectively. The value of NF is  6.3dB [27]. This makes the receiver noise floor −69.43 dBm at  50 degrees C. Consequently, the output power of the transmitter is  −28.93 dBm and -19.43dBm for intra and interchip links  respectively. The two different transmitted powers are generated  by using the VGA module discussed in section IIIB. The power  consumption of the transceivers including the VGA module is  considered in the following sections for performance evaluation .  4.2 Performance evaluation  The metrics for performance evaluation are maximum achievable  bandwidth per core and packet energy dissipation. Maximum  achievable bandwidth per core is the peak sustainable data rate in  number of bits successfully routed per core per second as network  saturation. Bandwidth per core, B can be determined as,  𝐵 = 𝑡𝛽𝑓                                                         (5)  Where, t is the maximum throughput in number of flits received  per core per clock cycle at network saturation,  is the number of  bits in a flit, and f is the clock frequency. The throughput is  directly obtained from system level simulations performed by the  cycle accurate simulator.  The average packet energy dissipation, Epkt is the average energy  dissipated in transmission of a packet from source to destination.  It is measured by the sum of the energy dissipation of all the  components in the multichip systems such as buffers, switches  and links divided by the total number of successfully routed  packets. For the multichip systems with wireline I/O whenever a  flit traverses an interchip link the energy dissipated by the I/O is  added to the total sum. Conversely, in the wireless multichip  systems the wireless transceivers are always active and hence  their energy dissipation is added to the total energy dissipation.  In the following subsections we demonstrate the performance of  the CDMA-multichip system  in  terms of  the achievable  bandwidth per core and packet energy dissipation. We consider  four interconnection architectures for the multichip systems for a  comparative performance evaluation. These are as follows:  1. Mesh+I/O: the intra-chip communication occurs through a  conventional grid based mesh NoC whereas the interchip  communicaton happens through serial I/O where only one  switch at one of the corners of the mesh is connected to the  I/O module.  Mesh+I/O Mesh+CDMA Small-World+I/O SmallWorld+CDMA ) s p b G ( e r o c / h t d i w d n a B 60 50 40 30 20 10 0 0 1 2 No. of Chips  3 4 Figure 4. Peak achievable Bandwidth per core varying  system size for different architectures for uniform traffic  2. Small-World+I/O:  the  intrachip communication occurs  trough a  small-world wireline NoC. The  interchip  communication occurs through a single corner I/O module in  each chip.  3. Mesh+CDMA: intrachip communication happens over both  conventional mesh links as well the wireless links whereas  interchip communication solely uses the wireless links  connecting WIs in different chips.  4. Small-World+CDMA: Intrachip communication occurs over  a wireline  small-world NoC  and  the wireless  interconnections while the interchip communication uses  only the interchip wireless links.  4.2.1 Achievable Bandwidth  We evaluate the peak achievable bandwidth per core of the  multichip network at saturation using uniform random traffic in  this section. We consider the 4 different configurations for the  multichip systems studied here. Each individual multicore chip is  considered to have 64 cores and switches. The number of chips in  the system is varied from one to four interconnected together  yielding different system sizes of 64, 128, 192 and 256 cores  collectively. We have considered 4 CDMA based WIs per chip for  all the configurations studied here. In Figure 4 we show the peak  achievable bandwidth per core for the multichip system.   It can be observed  that both  the systems with wireless  interconnections have higher bandwidth compared to the wireline  I/O interconnection for all system sizes. This is because the  wireless nodes connect switches inside the chips directly over  single-hop links. On the other hand with wireline I/O the data  packets need to travel from internal cores to the peripheral I/O  module and then get routed over the interchip link and again  travel to internal nodes at the destination chip. Moreover, as the  access to the interchip links is achieved through only one switch,  it results in congestions at the I/O module eventually degrading  performance. Additionally, the wireless bandwidth is distributed  among multiple CDMA links. While the bandwidth of each link  reduces due to the spread spectrum CDMA technique the  simultaneous multiple access by multiple transmitters contribute  to an improvement in performance. So, although the aggregate  wireless channel bandwidth of 6Gbps is less than the I/O  bandwidth of 15Gbps, the overall performance is much better than  the wired multichip system. Consequently,  the wireless  interconnection system is more scalable compared to its wired  counterpart.        The small-world NoC performs better than the mesh based NoC  for both wired and wireless systems, due to direct one-hop  connections between distant nodes on the chip for both wireless  and wireline systems. However, this gain is the most apparent in  the single chip system. This is because with increase in the  number of chips, the impact of the local NoC in each individual  chip decreases the overall system performance. We believe this  trend to continue and hence, the importance of local NoC  architecture to diminish compared to the interchip interconnection  as the system scales up.  4.2.1 Packet energy  In this section we compare the packet energy dissipation of the  multichip systems  interconnected with wired and wireless  interconnects. Figure 5 shows the packet energy dissipation of the  systems investigated in this paper. It can be seen that the packet  energy increases significantly for the wireline system with  increase in the number of chips while the packet energy in the  wirelessly connected system does not increase as drastically. This  is due to the direct energy-efficient wireless links between cores  embedded in the multicore chips. As the number of chips increase  the interchip traffic also increases in proportion from zero  percentage in the single-chip scenario to 75% in the 4-chip case.  This implies that 75% of the total number of packets generated  uses  the wireline  I/O  in case of  the wired  interchip  interconnections. This creates bottleneck at the I/O modules and  causes a drastic decrease in bandwidth per core and hence an  increase in the buffering energy at those modules. In addition,  being switching based, the interchip communication dissipates  high energy due to the intermediate I/O switches in the path of  interchip data. This results in the sharp increase in packet energy  consumption with increase in the number of chips.  An interesting observation is that the gain in the energy efficiency  of the wireless multichip systems compared to the wireline I/O  based ones increases with increase in the number of chips. This is  because as the number of chips increases more traffic accesses the  interchip communication links causing that to become the  bottleneck. The wireless links being distributed among the cores  in the chips alleviates the problem of congestion more than the  wireline I/O and therefore is more energy efficient as the system  size increases.  The small world NoCs have lower packet energy compared to the  mesh based NoCs within the individual chips due to the direct  links. However, as in the case of bandwidth the gain with small  world topology diminishes with increase in system size due to  diminishing  impact of  individual NoCs on  the overall  performance.  Mesh+I/O Mesh+CDMA Small-World+I/O Small-World+CDMA ) J μ ( y g r e n E t e k c a P 120 100 80 60 40 20 0 0 1 2 No. of Chips  3 4 Figure 5. Average packet energy with varying system size for  different architectures with uniform traffic.  4.3 Performance evaluation with non-uniform  traffic  In this section we analyze the bandwidth and packet energy in the  small-world+CDMA based multichip system with non-uniform  traffic patterns and compare it with its wireline counterpart, smallworld+I/O. We use the small-world based configurations in this  section as they outperform the mesh based ones. We use hotspot  and an application specific traffic from a FFT based workload  mapped on the multichip system. In the hotspot, 5% of all traffic  generated from all cores has the same destination which is the  hotspot. A single core was chosen randomly from the system as  the hotspot. All other packets are distributed equally among all  other cores. To generate the FFT traffic a 256-point fast Fourier  transform (FFT) application was considered, wherein each core  performs a 2-point radix-2 FFT computation. The bandwidth and  packet energy for the small-world NoC based multichip system  for the one and two-chip cases are shown in Figure 6(a) and  Figure 6(b) at network saturation respectively. As can be seen  from results the wireless small-world interconnection outperforms  the I/O based multichip system for all the non-uniform traffic  patterns. In case of hotspot traffic, the interchip data transfer is  really high as all cores in all the chips send a certain percentage of  their packets to the hotspot core. This causes severe congestion at  the I/O modules severely degrading the bandwidth and increasing  the packet energy. This issue is significantly mitigated by the  distributed wireless links. In the case of FFT based traffic the  pattern is more distributed and hence, the degradation in  bandwidth and energy efficiency is less than that with hotspot  traffic. This indicates that the wireless interchip communication  paradigm can be beneficial for a variety of applications mapped  into such multichip multicore systems.  Figure 6(a). Bandwidth/core with non-uniform traffic  Figure 6(b). Packet energy with non-uniform traffic                      Our observations with the hotspot and uniform traffic patterns  indicate a strong correlation of the overall performance of the  multichip system with that of the proportion of interchip traffic.  Hence, we study the change in performance by varying the degree  of localization in the traffic as a direct parameter. We define the  localization parameter as the percentage of data packets from each  core that has a destination within the same chip. Figure 7 (a) and  (b) show the bandwidth per core and packet energy respectively,  as the localization parameter is varied from 25% to 100% for a 2 chip system with each chip having 64 cores interconnectedwith  the small-world architecture. This captures the possible spectrum  of traffic patterns while demonstrating how the performance  depends on it. It can be clearly observed that as the localization  parameter increases the performance of the multichip systems  increases and the packet energy consumption decreases. For low  localization the role of the interchip interconnections become  important and the gains of the wireless chip-to-chip links  increases compared to the wired I/O system.  4.4 Area overheads  In this section, we estimate the comparative area overheads of the  various architectures studied in this paper. The number of wired  intrachip links in all configurations are same as that of a  conventional mesh NoCs. This is because the number of intrachip  links  in  the small-world+I/O and small-world+CDMA  is  constrained to be the same as that of the conventional mesh. The  only difference is the I/O modules, wireless transceivers and the  area of ports associated with them. Figure 8 shows the total area  overhead of the various interconnection architectures for different  multichip configuration and sizes considered in this paper. In case  of CDMA based architectures, each transceiver occupies an area  of 0.4mm2 [27] whereas in I/O based architectures, each  transceiver has an area of 0.088mm2 [2]. For the wireless  multichip system of the largest configuration, the total area of the  interconnection network is 2.1% of the entire system while the  wireless overhead is only 0.6%.  5. CONCLUSIONS AND FUTURE WORK  High performance computing environments and data centers  employ modules with multiple multicore chips in a package or on  a board. The density and bandwidth of high speed I/O for  interchip interconnections are becoming the power-performance  bottleneck for such multichip systems. In this paper we explore  the advantages possible if interchip communication in multichip  modules can be realized with state-of-the-art mm-wave wireless  links operating in the 60GHz band. While the bandwidth of such  wireless links is not necessarily higher compared to the high speed  serial I/O links, the wireless links are capable of establishing  direct communication channels between cores in different chips  via on-chip embedded antennas. Moreover, the wireless links can  be used for a seamless data transfer between cores in the same  chip as well, to augment the traditional NoC backbone for  intrachip communications. These factors result in significant gains  in performance and energy efficiency in both intra and interchip  data communications. In the future we intend to explore the  possibility of a seamless wireless interconnection for large scale  computing infrastructure scaling up to several hundreds to  thousands of multichip modules encompassing entire datacenters.  6. ACKNOWLEDGMENTS  This work was supported in part by the US National Science  Foundation (NSF) grant CCF-1162123.   7. "
Wear-Aware Adaptive Routing for Networks-on-Chips.,"Chip-multiprocessors are facing worsening reliability due to prolonged operational stresses, with their tile-interconnecting Network-on-Chip (NoC) being especially vulnerable to wearout-induced failure. To tackle this ominous threat we present a novel wear-aware routing algorithm that continuously considers the stresses the NoC experiences at runtime, along with temperature and fabrication process variation metrics, steering traffic away from locations that are most prone to Electromigration (EM)- and Hot-Carrier Injection (HCI)-induced wear. Under realistic applications our wear-aware algorithm yields 66% and 8% average increases in mean-time-to-failure for EM and HCI, respectively.","Wear-Aware Adaptive Routing for Networks-on-Chips † Arseniy Vitkovskiy† , Vassos Soteriou† , Paul V. Gratz‡ ‡ Dept. of Electrical Eng., Computer Eng. and Informatics Cyprus University of Technology vassos.soteriou@cut.ac.cy Dept. of Electrical and Computer Engineering Texas A&M University pgratz@tamu.edu ABSTRACT Chip-multiprocessors are facing worsening reliability due to prolonged operational stresses, with their tile-interconnecting Network-on-Chip (NoC) being especially vulnerable to wearout-induced failure. To tackle this ominous threat we present a novel wear-aware routing algorithm that continuously considers the stresses the NoC experiences at runtime, along with temperature and fabrication process variation metrics, steering traﬃc away from locations that are most prone to Electromigration (EM)- and Hot-Carrier Injection (HCI)-induced wear. Under realistic applications our wear-aware algorithm yields 66% and 8% average increases in mean-time-to-failure for EM and HCI, respectively. Categories and Subject Descriptors B.4.3 [Input/Output and Data Communications]: Interconnections (Subsystems); B.8.1 [Performance and Reliability]: Reliability, Testing, and Fault-Tolerance General Terms Reliability, Design Keywords Hot-Carrier Injection (HCI), Electromigration (EM), Network-on-Chip, Routing Algorithm, Reliability, Lifetime 1 Introduction Today’s Chip Multiprocessors (CMPs) utilize tens or hundreds of processing cores that coordinate to execute applications in parallel. In these systems, processors, memories, IP blocks and peripherals, are serviced by high-throughput Networks-on-Chips (NoCs). Unfortunately, operational stresses imposed by CMP workloads make such chips increasingly ing a 10× increase in wear-induced failure over the next 10 prone to accelerated wearout, with recent studies pro jectyears [4]. The NoC is especially vulnerable to such failure, as a single component malfunction could render the CMP unusable [4]. NoC failure is unlike individual core failure, where error detection and appropriate operating system support can be used to re-map executing tasks to healthy cores [3]. Much prior work examines fault-tolerant routing, attempting to reactively manage faults as they occur [5]. Ideally, proactive schemes could extend the healthy status of the system without incurring faults, rather than to react to such fault occurrences. Thus, in this paper we develop a proactive Wear-Aware Routing Algorithm (WARA), which restricts network traﬃc-induced wear in the NoC. Our algorithm considers the stresses that NoC routers experience online, focusing on the data- and activity-dependent wearout eﬀects of Hot-Carrier Injection (HCI) and Electromigration (EM) that are most critical to the interconnect. Using micro-architectural-level models for HCI and EM wear, along with dynamic operating temperature, and process variation, WARA steers traﬃc in the NoC topology Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s). NOCS ’15, September 28-30, 2015, Vancouver, BC, Canada ACM 978-1-4503-3396-2/15/09. http://dx.doi.org/10.1145/2786572.2786573 to reduce wear on the NoC. WARA avoids those NoC components or routing paths most susceptible to wearout due to process variation, higher operating temperatures, or accumulated wear to-date. Under applications from the PARSEC Benchmark Suite, WARA yields an 66% and 8% increase in mean-time-to-failure for EM and HCI, respectively. 2 Background on CMOS Physical Wearout Two primary CMOS failure mechanisms are EM [1] and HCI [2]. In both cases, the proximate cause of failure is the activity factor (probability of bit transition) of the wire (EM) or transistor (HCI) under stress. Wear rate is further modulated by the temperature (in both EM and HCI), and process variation (PV) (in HCI). We next present models, for temperature and PV, as these are the primary aging accelerators for EM and HCI. 2.1 Dynamic Temperature Variation Chip operating temperature has a direct inﬂuence on both EM- and HCI-induced aging. CMPs exhibit uneven power dissipation among their component resources, dependent upon the speciﬁc task mapping, application load balance, etc., all of which are inherently unbalanced. We assume a per-tile random temperature distribution driven by the core-produced heat where the temperature remains constant within a tile but varies between tiles. The temperature range spans from 65 C to 85 C, with values altered periodically to mimic the CMP’s dynamic behavior (see Section 3). ◦ ◦ 2.2 Process Variation (PV) Process variation (PV) is a deviation in technology process parameters from their nominal values caused by imprecision in the fabrication process as feature size approaches the fundamental dimensions, leading to imbalance of electrical characteristics across the die. Within-die PV is a combination of systematic eﬀects (e.g., layout pattern density variation), and random eﬀects. Since variation has a very small eﬀect on wires [7], we consider the process parameters most vulnerable to variation: the transistor threshold voltage, Vth , and the eﬀective gate length, Lef f . The values of the systematic components, ΔVth,sys and ΔLef f ,sys , are assumed to be constant within one CMP tile. These may be modeled using a multivariate normal distribution with a spherical spatial correlation between the CMP tiles. The ﬁner-grained (i.e., at the level of an individual transistor) random components, ΔVth,rand and ΔLef f ,rand , are assumed both normally distributed with zero mean and standard deviation equal to 6.3% and 3.2%, respectively [7]. 2.3 Electromigration (EM) EM aﬀects metallic wiring on-chip, where current-driven stresses, as a result of bit transition switching, causes deformation due to the movement of metal ions, leading to fatal opens or shorts. Of particular concern for EM are the Vdd and GND connections of drivers for high-rate data transfer wires, where both current drive is high, due to long wire capacitance, and switching activity is high, exacerbated by high temperature. The Acceleration Factor (AF) is a relative metric of lifetime [2] for EM wear. Here, we assume the reference functional lifetime as that of a network with deterministic Dimension-Order Routing (DOR), where the EM (cid:2)(cid:2) (cid:2)(cid:2) M T T FEM M T T FEM AR , DOR acceleration factor is calculated as AFEM = (cid:2)(cid:2) where M T T FEM AR is the Mean-Time-To-Failure (MTTF) of the system, which runs WARA, and M T T FEM the reference MTTF of the standard DOR-running system. DOR is (cid:2)(cid:2) 2.4 Hot-Carrier Injection (HCI) HCI aﬀects transistors in proportion to the time they have been operating under stress, i.e., the switching frequency. HCI causes gradual shifts of a transistor’s threshold voltage (Vth ), which slows its switching time, eventually leading to timing guard-band violation, aﬀecting a device’s critical path. HCI has a further sensitive to process variation (PV) as PV can cause an initial shift in Vth , reducing the guard-band before HCI has even begun to eﬀect the transistor. The Acceleration Factor (AF) for HCI is calculated as (cid:2)(cid:2) AR (cid:2)(cid:2) (cid:2)(cid:2) DOR (cid:2)(cid:2) AFHC I P V = M T T FHC I P V M T T FHC I P V AR , where M T T FHC I P V is the MTTF of the system, which runs wearout-aware adaptive routing, and M T T FHC I P V DOR is the reference MTTF of the system, which runs standard DOR. 3 Wear-Aware Adaptive Routing Algorithm As discussed above, the cause of aging under both EM and HCI wear-inducing physical phenomena is switching activity, caused by packets being routed. Load within an NoC is often quite unbalanced, thus reducing the switching activity of nodes and links which have the greatest switching activity, can be done by using adaptive lifetime-extending routing that does not compromise the utility of the network. Our proposed WARA leverages a holistic view of the network’s wear-sensitivity, conveying distant accumulated wear to-date, current temperature state, as well as initial PV state, to the local router for the creation of a wear-reducing route. In gathering global statistics, WARA inherits features from a congestion-avoiding, globally-aware adaptive routing scheme, Global-Congestion Awareness (GCA) [6]. It holistically communicates wearout status information by “piggybacking” data that is back-annotated into the empty space of header ﬂits comprising (1) utilization to-date of the link that resides in the opposite direction of the packet’s ﬂow (Ulink ), (2) utilization to-date of the router’s critical path (Urouter ), and (3) temperature of the corresponding network tile. The Ulink and Urouter statistics are used to continuously estimate both EM and HCI activity-based wear, respectively, implemented as 32-bit counters, one for each router port, that are incremented with every ﬂit’s link traversal. At each hop, every node appends this information into the header ﬂit and then sends it out on its associated output port. Thus information, sampled every 104 cycles, from one router spans the entire topology and is received by all other routers. The average Urouter metric is then estimated by summing all perport counters and dividing by the packet’s ﬂit count. Last, fabrication-time PV constants are measured and stored once in tables at each router, while temperature data for each tile, also stored in router tables, are sampled every 107 cycles. Activity statistics, PV and temperature values, are all fed into the lifetime-determining equations of Black [1] and Hoskote et al. [2] that respectively calculate the MTTF of electronic devices for EM- and HCI-induced wear. WARA’s goal is to choose the packet route among the alternative progressive paths that incurs the least cumulative wear, for both EM and HCI in tandem. The path-accumulated, relativelyweighted lifetime, Wnorm , from a given source node to a ﬁnal destination, out of the set of all in-between minimal path permutations is proposed as WARA’s routing function: (C (M T T F )EM × M T T FEM normi + Wnorm = minpaths + C (M T T F )HC I P V × M T T FHC I P V normi ) (cid:3) where C (M T T F )EM ,HC I P V = expw M T T F −M T T Fmax M T T Fmax−M T T Fmin − exp−w (1) 1 − exp−w (2) where M T T FEM normi and M T T FHC I P V normi are normalized to the maximum MTTF values observed in the least worn-out path. C (M T T F )EM and C (M T T F )HC I P V are exponential functions that are speciﬁcally tuned to apply much lower weights to paths which are close to the lowest MTTF values, such that they are much less often chosen by WARA. M T T Fmax and M T T Fmin denote the maximum and minimum MTTF values along all alternative progressive paths residing between a source-destination pair. The exponential weight constant w scales the strength of the extra weight away from paths with small MTTFs, and is empirically set to 8. The intuition here, is that the path with the least relative MTTF value can be regarded as the “weakest link” in the topological “chain” - it determines the NoC’s overall lifetime duration and thus needs to be preserved as long as possible. Hence, WARA guides packets to traverse the path with the highest Wnorm , helping to unload the paths with shorter cumulative lifetime. Route calculation is implemented via a modiﬁed Bellman-Ford [6] shortest path algorithm which chooses the progressive path of greatest relative MTTF value, by utilizing weights obtained from Eq. 1. Hence, packets use previously precomputed routes. 4 Experimental Setup and Evaluation as an 8 × 8 array of tiles, each comprising an x86 processor The experimental platform is a 64-core CMP organized core, split L1i and L1d private caches, and a slice of the combined, shared L2 cache. A directory-based MESI protocol maintains cache coherence, and uses 3 virtual networks. We utilize 3-stage pipelined wormhole routers, with 4 virtual channels per router port, and 128-bit links. Experiments are run using the gem5 full-system simulator, with the Ruby shared memory model and the Garnet network simulator. Our workload comprises the PARSEC Benchmark Suite. We compare the respective CMP lifetimes achieved under each PARSEC benchmark run using WARA vs. a system with a baseline, wearout-unaware DOR routing algorithm. Each simulation is repeated ﬁfteen times with diﬀerent PV and temperature mappings and the ﬁnal results are averaged for each value obtained. In our MTTF Acceleration Factor (AF) for EM and HCI PV results, the bottom 10% of observable MTTF cases were considered, since those are the least reliable and hence most likely to lead to failure. WARA increases system lifetime under both EM and HCI PV, for all tested PARSEC benchmarks, providing 66% increase in M T T FEM and 8% increase in M T T FHC I P V , on average. Finally, WARA experiences a small performance degradation, at 2% on average versus a baseline, DOR design. 5 Conclusions We presented a novel, dynamic wear-aware routing algorithm for NoCs that continuously focuses on combating HCIand EM-induced wear in tandem. It yields an average 66% increase in M T T FEM and 8% increase in M T T FHC I P V . Acknowledgements This work falls under the Cyprus Research Promotion Foundation’s Framework Programme for Research, Technological Development and Innovation 2009-10 (DESMH 2009-10), co-funded by the Republic of Cyprus and the European Regional Development Fund, and speciﬁcally under Grant IPE/DIEJNHS/STOQOS/0311/06. 6 "
Multi-Layer Test and Diagnosis for Dependable NoCs.,"Networks-on-chip are inherently fault tolerant or at least gracefully degradable as both, connectivity and amount of resources, provide some useful redundancy. These properties can only be exploited extensively if test and diagnosis techniques support fault detection and error containment in an optimized way. On the one hand, all faulty components have to be isolated, and on the other hand, remaining fault-free functionalities have to be kept operational.
In this contribution, behavioral end-to-end error detection is considered together with functional test methods for switches and gate level diagnosis to locate and to isolate faults in the network in an efficient way with low time overhead.","Multi-Layer Test and Diagnosis for Dependable NoCs  Hans-Joachim Wunderlich  Computer Architecture  University of Stuttgart  Pfaffenwaldring 47, D-70569 Stuttgart  wu@informatik.uni-stuttgart.de  Martin Radetzki  Embedded Systems Engineering  University of Stuttgart  Pfaffenwaldring 5b, D-70569 Stuttgart  radetzki@informatik.uni-stuttgart.de  ABSTRACT  Networks-on-chip are  inherently fault  tolerant or at  least  gracefully degradable as both, connectivity and amount of  resources, provide some useful redundancy. These properties can  only be exploited extensively if test and diagnosis techniques  support fault detection and error containment in an optimized  way. On the one hand, all faulty components have to be isolated,  and on the other hand, remaining fault-free functionalities have to  be kept operational.  In this contribution, behavioral end-to-end error detection is  considered together with functional test methods for switches and  gate level diagnosis to locate and to isolate faults in the network in  an efficient way with low time overhead.  Categories and Subject Descriptors  B.4.5 [Input/Output and Data Communications]: Reliability,  Testing, and Fault-Tolerance – built-in tests, diagnostics.   General Terms  Performance, Design, Reliability  Keywords  Test, diagnosis, fault tolerance, network-on-chip, cross-layer.  1. INTRODUCTION & RELATED WORK  The inherent fault tolerance of networks-on-chips (NoCs) makes  them a special candidate to cope with the reliability threats that  accompany further CMOS scaling [25]. While the “power wall”  limits  the  frequency  increase and enforces performance  improvements by exploiting parallelism, the resulting “reliability  wall” can only be overcome efficiently by applying test and  diagnosis schemes at the various network layers of an NoC.   High quality  test and diagnosis schemes are  technology  dependent, and a purely functional approach is not sufficient for  reaching the same quality as obtained by structural techniques.  The abstraction levels of fault model are related to some extent to  the network layer definition of the ISO/IEC 7498-1:1994 OSI  seven layer model.  Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. Copyrights  for components of this work owned by others than ACM must be  honored. Abstracting with credit is permitted. To copy otherwise, or  republish, to post on servers or to redistribute to lists, requires prior  specific permission and/or a  fee. Request permissions  from  Permissions@acm.org.   NOCS '15, September 28 - 30, 2015, Vancouver, BC, Canada.  © 2015 ACM. ISBN 978-1-4503-3396-2/15/09…$15.00  DOI: http://dx.doi.org/10.1145/2786572.2788708  1.1 Physical Layer  Defects consist of additional, missing or wrong physical material,  and they are modeled by faults of a structural gate level circuit  model. Standard fault models include stuck-at faults, transition  faults, delay faults, crosstalk or various types of bridging faults.  They are associated in this paper with the physical network layer,  and require the classical structural methods of automated test  pattern generation (ATPG) [5] and test application through test  access mechanisms (TAM) such as scan chains [32].   NoC-specific adaptations of  these methods  include  the  optimization of scan structures according to NoC topology [14],  the transport of test patterns to scan chains using flits [22], and  standards-compliant test wrappers for NoC [3].  Beyond just identifying faulty circuits, the circuit’s test response  can be analyzed by structural diagnosis techniques to locate the  faulty circuit component (net or logic gate). Diagnosis can be  performed offline with automated test equipment or in situ with  dedicated built-in self-test (BIST) logic.   The diagnosis result can be used offline (to increase production  yield) or online (to cope with emerging faults) by repairing or  deactivating faulty circuitry. Repair requires redundant circuit  elements such as spare wires [21] to be designed in up-front  whereas deactivation keeps the circuit alive at the cost of reduced  functionality or performance (graceful degradation, e.g. through  reduced flit size [31]).  1.2 Data Link Layer  On the data link layer, which establishes connectivity and flow  control between adjacent switches, these classical structural test  methods are not anymore directly applicable as both, pattern  generation and pattern application, are constrained to a wellformed format for data transmission between two switches. On  one hand these constraints reduce the reachable fault coverage, on  the other hand overtesting is avoided and tests can be executed  more efficiently.  An NoC-specific BIST architecture featuring a dedicated test  controller and the usage of the NoC data links as TAM has been  described by Grecu et al. [13]. Lehtonen et al. show how links can  be reconfigured in order to cope with faults. A method for  mapping diagnosed faults to switch ports [9] enables graceful  degradation by deactivating defective ports and the connected  links and is also used in the paper at hand.  An alternative to these diagnostic approaches is concurrent error  detection and error correction. These techniques rely on the use of  error correcting or detecting codes (ECC/EDC). Since respective  codecs are required in each switch, cheap single error correcting  (SEC) codes such as Hamming codes are employed. In case of  EDC, switch-to-switch  retransmission can be applied  for  correcting transient errors, but is not effective against permanent            defects. Studies ([4][15]) show that the incurred area and power  overhead is not justified unless extremely high failure rates are  assumed, and suggest the application of such techniques on higher  layers instead.  1.3 Network Layer  The network layer establishes functionalities of packet routing and  switching in NoC switches (which include routing units). For  testing and diagnosis, the circuit-level structural fault model is  widely abstracted. For example, Kohler et al. [18] suggest a  functional fault model (xbar faults) that captures connection paths  in crossbar switches. Further abstracting, functional failure modes  like misrouting or data corruption are used to capture the effect of  low-level defects on switch functionalities ([2]).  When circuit-level structural diagnosis  is applied  to NoC  switches, a mapping of diagnosed structural faults to the affected  functionalities can be established [7]. Alternatively, functional  tests can be applied [1]. In reverse, structural faults can be  diagnosed with functional techniques [16], and SAT-based ATPG  can be employed to ensure high structural coverage of functional  software-based self-test (SBST) [10]. Like on other layers,  concurrent error detection with error detecting codes (e.g. [18])  can replace or supplement diagnostic techniques. The use of faultsecure synthesis techniques [11] ensures that all faults manifest as  detectable errors.  In order to achieve better graceful degradation than with a  complete switch shutdown, defective parts of a switch can be  bypassed by data path reconfiguration [23] or can be omitted by  local routing adaptation [18]. Potentially resulting problems  related to congestion or deadlocks can be avoided by aheadlooking adaptation of adjacent switches [27].  1.4 Transport Layer  Finally,  the  transport  layer  includes  the end-to-end data  transmissions from the original sender to the designated receiver.  The use of error-detecting codes (EDC) such as parity (single  error detecting), extended Hamming (double error detecting), or  cyclic redundancy check (CRC, capable of detecting error bursts)  is common for concurrent error detection on  this  layer.  Alternatively, the use of heartbeat messages has been suggested  [12], which replaces the overhead of equipping each packet with  an EDC field by the potentially smaller overhead of eventual test  packets. Also the use of forward error correcting codes (FEC) has  been investigated [20], but the cost of decoding advanced codes  with error-correcting capacity that goes beyond the single error  correction (SEC) of Hamming codes, e.g. Reed-Solomon or BCH,  appears prohibitive.  To diagnose NoCs on the network layer, Raik et al. [26] suggest a  method that uses end-to-end messages injected and ejected at test  access points at the boundaries of a mesh network. Zhang et al.  [34] describe a software-based localization method that gathers  information about the position of nodes that have been deactivated  after an unsuccessful BIST run. Contrary to that, in Section 2 we  outline a diagnostic method that locates defective NoC resources  (links, switches) on the network layer using regular data packets.  1.5 Cross-Layer Methods  It is advantageous to separate monitoring and coarse fault  diagnosis from the more expensive fine grained fault diagnosis for  defect location, at least if we are dealing with low and medium  error rates. Detecting faulty switches and links is targeted  efficiently at the transport layer, while diagnosis for defect  location needs finally structural information obtained by lowering  the abstraction level in a top down fashion. This leads to a topdown divide-and-conquer approach across the network layers and  will finally point to a defective structure, e.g. wire, port or gate.   However, the description of this proceeding is preferably done in  a bottom-up way, layer for layer as functionalities and concepts  can be reused this way. Hence, this paper is organized as follows:  After describing test and monitoring at the transport layer in the  next section, test, diagnosis and fault isolation at gate level are  discussed in section 3. Section 4 introduces software based selftest at the data link layer, and section 5 presents the concept of  functional failure modes at the network layer.  2. TRANSPORT LAYER  2.1 Transport Protocol  If the absence of post-manufacturing defects is a reasonable  assumption, as still the case with current technology, a minimal  transport protocol for packetization and re-assembly of end-to-end  messages is sufficient. For future technologies, adaptive repeat  request (ARQ) techniques can be employed for retransmission of  erroneous packets. This requires each packet to be equipped with  an error-detecting code (EDC).  To implement ARQ, a sender keeps a local copy of each sent  packet until it is positively acknowledged by the receiver. Should  the receiver detect an error by decoding the EDC, it sends a  negative acknowledgement. Multiple acknowledgements can be  bundled in a single protocol packet so as to reduce the incurred  traffic overhead. Upon receiving a negative acknowledgement, the  packet is re-sent. If the receiver is not capable of reordering  packets, subsequent packets must also be retransmitted.  Since data packets may be completely  lost,  the receiver  implements a time-out mechanism upon which expected packets  that did not arrive are negatively acknowledged. Missing packets  can be detected by gaps in the sequence IDs transmitted as part of  the packet header. Acknowledgement messages may be lost as  well. Therefore, the sender implements another time-out after  which a yet unacknowledged packet is automatically re-sent.  2.2 Diagnostic Protocol  Retransmission is able to correct transient faults by temporal  redundancy. However, in case of a permanent fault, deterministic  routing would lead any retransmitted packet though the same  defective component, where it is again corrupted. This situation  can be detected with an error counter for failed retransmission  attempts. A fault can thereby be classified as permanent, which  leads to the need of locating it so as to change routing paths.  For this purpose, a scoreboard-based mechanism has been  suggested [30] that narrows down fault location by using statistics  of faults occurred on multiple transmission paths: Those network  resources present in a maximal number of faulty paths are likely  fault candidates. To overcome the probabilistic nature of this  approach, we have proposed a bisection mechanism [28] to  iteratively narrow down fault location to a single switch, using a  single transmission path.  Our method assumes that the transport layer has some information  on the routing policy that is implemented on the network layer:  Namely, the path length be known and the switch in the middle of  the path be identifiable. This is easily implemented for a  deterministic routing scheme such as dimension order routing.  Also table-based routing information, where routing table entries  are computed in software by the processing elements, could be  exploited.  Given sender node ns and receiver node nr, the middle node ni is  identified as intermediate node. The sender directs the packet at ni  and supplies the final target address of nr in an additional header  data field. At ni, the packet is consumed and checked. If it is  erroneous, it is negatively acknowledged and ns further bisects the  path by addressing  the switch halfway  to  the previous  intermediate node. Otherwise, the fault must be on the second half  of the end-to-end path. Node ni takes over the role as the new  sender of the packet and continues with the same bisection  protocol. The process repeats until eventually the fault location is  narrowed down to a single network resource, namely the link  between two adjacent switches. Should the fault reside inside one  of the switches and affect multiple links, these links will also be  identified faulty as soon as they make other transmissions fail.   2.3 Fault-Tolerant Routing  When a faulty resource is identified, the routing should be adapted  to prevent further (re-)transmission using that resource. This can  be achieved by triggering routing adaptation on the network layer  [29]. For this purpose, information about the identified fault  location would have to be passed down the layer hierarchy. In  [28] we use a software re-routing approach that is implemented on  the transport layer only.  For software routing, the original sender identifies an intermediate  node so that the path to the intermediate node is not affected by  faults. Similar to the diagnostic protocol, this requires intelligence  on the routing policy. Moreover, each network interface (or its  attached processing element) has to keep track of faults diagnosed  on its packet transmissions. Packets are sent to the intermediate  node and the final destination is encoded in the additional address  field already  implemented  for diagnostic purposes. The  intermediate node consumes the packet, replaces the intermediate  address with the final address, and re-injects the packet. Should  the intermediate node know of a fault on the regular path to the  final destination, it chooses another intermediate instead.  The choice of intermediate nodes can be improved with global  knowledge of the network state. This enables the sender to  identify an intermediate node so that not only the path to the  intermediate but also the path from intermediate to destination is  free of known faults [17].  2.4 Assessment  The method described above can be classified as online and  concurrent, that is, it is performed while the NoC is in operation  and does not preempt the regular data traffic. The system thus  remains operative, albeit with a certain performance loss due to  the overhead for the diagnostic protocol, packet consumption and  re-injection. This graceful degradation is a preferable alternative  compared to system failure that would result from persistent  packet loss. Moreover, the hardware overhead is limited: Whereas  the network interface may need some additional hardware for  timers and error counters, the protocol is implemented in software  on the processing element. We also assume that memory space for  retransmission and reordering buffers  is allocated  in  the  processing element’s local memory that is shared with the  network interface.  On the downside, diagnostic quality is rather limited:   ·  ·  ·  The granularity of fault location is coarse, on the level of  network links and switches. More fine-grained diagnosis would  offer the potential of reducing performance degradation.  The method only diagnoses faults that manifest as observable  errors, but not latent faults. For example, packets may be  misrouted due to a defect in a switch, but still arrive intact at the  destination. Eventually such latent fault can lead to a deadlock  because the misrouting violates the otherwise deadlock-free  routing policy.  False positives can occur, i.e. the method may erroneously  diagnose  intact resources as faulty. This happens when  congestion appears due to retransmission, acknowledgement  and software  routing overhead.  In  this case, positive  acknowledgements may be delayed so much that the timeout  mechanism  lets  the diagnostic protocol assume negative  acknowledgement on intact path sections.  High diagnostic quality requires diagnosis on lower abstraction  levels, closer to the physical failure mechanisms. Yet transport  layer techniques are useful in narrowing down potential fault  locations so that the more costly lower-layer diagnostic techniques  can be constrained to a small section of the NoC. To this end,  interaction and sharing of information is required among NoC  layers:   To achieve finer granularity, the transport layer should  trigger detailed diagnosis on lower layer specifically for fault  candidates.  The lower layer diagnosis technique should give feedback on  false positives so that resources that were erroneously diagnosed  and deactivated on transport layer can be revived.  The lower layer can also give feedback on identified latent  faults so that the transport layer (or potentially, by routing  adaptation, the network layer) is able to avoid the use of  resources with latent problems.  ·  ·  ·  3. PHYSICAL LAYER  The faults at the physical layer are described by a structural fault  model at gate level. The faults at the interconnect lines between  switches or between switches and cores include open lines,  bridges, and delay, transition or crosstalk faults (Figure 1).  Network  Interface Switch (0,0) Switch (1,0) Switch (2,0) .. . Switch  (0,1) . . . Switch  (1,1) . . . Switch  (2,1) .. . . . . Figure 1: Port and link loss  In general, these faults can be mapped to a faulty port of the  involved switch (Figure 2).    P o r t W 5x Port N ... Route r (ro ut ing , sch ed uling ,  switching ) Recon fig ura t ion d ata E t r o P Rand om log ic (FIFO  controller s, send / re ceive co ntro l lo gic,  c ro ssba r sw itch es ) Port S Data_in WCLK tail Data_ou t RCLK he ad Dual Por t RAM Control Lo gic Figure 2: Generic switch structure  The usual way to deal with faulty switches or links at the physical  layer is disabling the complete switch. Diagnosis may try to locate  the fault with higher resolution, and to point to a faulty gate or  line at gate level. Then, only ports have to be disabled which may  be affected by this fault, and any remaining functionality can be  reused further on. Overall, this leads to a higher perfomability and  less degradation in the faulty case.  To a large part, the switch consists of combinational logic and  some rather regular memory elements, for instance FIFOs and  control logic. The regularity of the switch allows extracting a  substantial part of its circuitry as combinational logic, which can  be subject of further diagnosis.   3.1 Generalized Fault Modeling  For recent technologies, the stuck-at fault model reaches its limits  and more expressive fault models are needed. The conditional line  𝑎 ⊕ 𝑏 ∧ 𝑎 describes that 𝑏 = 1 overwrites the 0 at a, the  formula 𝑎 ⊕ 𝑎!! ∧ 𝑎 is a slow to rise transition fault, and  flip model [33] consists of a signal a at a certain fault site and a  𝑎 ⊕ [𝑏!! ∧ 𝑏 ∧ 𝑎] models crosstalk from b to a. This generalized  condition [cond] that activates the fault and is described by a  Boolean, temporal or even random expression. For instance,  fault model is able to describe both faults in the communication  links or at ports, and faults in the gate level structure.  3.2 Topological preprocessing  A structural fault has only impact on those ports, which are  topologically reachable from the fault site (see Figure 3). This  straightforward  observation  already  provides  a  good  approximation of the set of functions, which are not affected and  can still be used. However, most signals close to input ports have  structural paths to many outputs and even to the router state. Not  all of these paths can propagate the error signal. Hence, the  topological preprocessing is pessimistic and further analysis  techniques may obtain a better approximation of the intact  functions.  3.3 Functional reasoning  Functional reasoning determines exactly the switch functions  affected by a fault and the corresponding parts to be disabled. An  appropriate method for this is provided by combinational,  constrained ATPG. A fault f is injected, and the control inputs are  constrained in such a way that it can only be detected at a certain  subset of outputs.   C . . . Combinational switch . . . C N . . . W . . . Inp ut con e f . . . Router state  pseudo primary input/ouputs Ou tp ut co ne S . . . E . . . . . . N W . . . . . . S . . . . . . E •  Figure 3: Combinational switch representation  Complete structural fault coverage for the conditional line flip  model with SBST patterns poses a challenge, which is tackled by  innovative ATPG techniques. The SBST pattern generation is  modeled as a Boolean satisfiability (SAT) problem in conjunctive  normal form (CNF). The SAT instance has to model three aspects:  Tseitin transformation. The result is a set of clauses Φ!  • Circuit Model: The  combinational  logic  and  interconnect of the SUT is described in CNF using the  describing the combinational part of the switch.  Fault Injection: The Conditional Line Flip (CLF)  calculus described above is used as a generalized fault  and the fault has to be modeled by 𝑓 ⊕ 𝑐𝑜𝑛𝑑 . The  model to describe arbitrary defect mechanisms in the  switch logic and the links. In order to model a fault at  the location f the downstream logic has to be duplicated,  clauses Φ!! describes now fault free and possible  expression cond is a free variable to guarantee the  detection of any functional misbehavior. The set of  erroneous signals.  searching a satisfying assignment of Φ!! which also  • Output propagation: For each output port and for each  signal line to the router control logic it is checked  whether a fault can be propagated. This is achieved by  leads to a function mismatch at one of the outputs to be  checked.  If ATPG fails to propagate the error condition to these outputs, it  is proven that certain switch functions are not affected by this  fault. Otherwise, three cases have to be distinguished:  •  The switch has to be disabled completely, if  the faulty behavior cannot be explained by a  single fault site f;  the error signal can propagate to router states  o  o          • A switch function (𝑁𝑜𝑟𝑡ℎ    ⊳ 𝐸𝑎𝑠𝑡 , e.g.) has to be  • An output port has to be disabled, if it is not the  specified target of the switch function, but an error  signal can be propagated to this port.  disabled, if ATPG can propagate the error signal along  this functional path.  Since the complexity of the combinational parts of a single switch  is rather moderate, the technique is rather efficient despite the  repeated call of ATPG.  4. DATA LINK LAYER  In an embedded switch, the test data developed above cannot be  directly applied, but has to follow the network format. For  microprocessors, the benefits of structural testing and functional  testing are combined by a so-called structural software-based selftest (SBST) [6][7][24][19][35]. In this technique, ATPG provides  deterministic, structural test patterns, which are transformed into  arguments of a sequence of valid instructions. In a similar way, as  functional test of switches and links requires to transform  deterministic test patterns into valid packets of an NoC, this  approach can be considered as a structural software-based self-test  (SBST) scheme for Networks-on-Chip. Structural faults in NoC  switches and interconnects are targeted and tested by valid NoC  packets without the need for dedicated test infrastructure. Such an  SBST scheme combines  the advantages of state-of-the-art  structural and functional test approaches for NoC infrastructure.   Figure 4 illustrates the principle of SBST in the scope of NoCs.  As an example, in the mesh topology, every switch is connected  to four neighboring switches and a Processing Element (PE) is  attached to each switch. The Switch Under Test (SUT) is tested by  applying a set of test patterns to its incoming links and by  observing the test responses at the outgoing links. The test  patterns form valid NoC packets, and do not require putting the  system in a non-functional test mode. Here, we assume that the set  of test packets is generated by software running on the processing  elements (PE) attached to the NoC.   S .. . S S . . . S T est prog ram T est da ta S Swi tch  und er  Test S . . . S .. . S Figure 4: SBST for NoCs  The generated test packets target structural faults in the SUT and  its links under the single fault assumption. The resulting test  responses are captured and evaluated by the test programs in the  adjacent PEs. The SBST starts when all PEs surrounding the SUT  have sufficient resources to run the test program. A local signal  (such as the Ack/Req. signal used for link flow control) can be  utilized to synchronize the launch of the test programs running on  the PEs involved in testing a SUT. The switches and PEs give the  highest priority to test packets and bypass their caches.  Since the switches are identical, the SUT access time through all  the incoming links is deterministic. Moreover, once the test  begins, normal packets are not routed through the SUT. The  complete NoC is tested by consecutively testing all contained  switches. Depending on the network topology and the switch  location, the SBST pattern generation is adjusted such that only  available neighboring PEs contribute in testing. For example, in a  2D mesh a switch at the boundary has three neighbors,  consequently its test patterns contain input values for only three  input ports of the switch.  The key concept of SBST for NoC switches is the generation of  efficient test patterns that achieve high fault coverage. In contrast  to scan-based testing, direct controllability and observability of  frame expansion to the combinational circuit Φ! and obtain a  the sequential states of the switch (i.e. pseudo primary inputs and  sequential model Φ!! , where T denotes the necessary number of  outputs) is not possible, and the sequential behavior of the switch  has to be modeled as well. For this purpose, one can apply timetime steps as depicted in Figure 5.  PI1 PI2 PIT PPI1 1 cΦ PPO1 PPI2 2 cΦ PPO2 ... PPIT T cΦ PPOT PO1 PO2 POT Figure 5: Unrolled switch  complex set of clauses Φ!""! ,! for the faulty instance.  Also, fault injection becomes more difficult compared to the  techniques discussed above, since a structural fault has to be  modeled in all the T different time steps leading to a more  In addition, only valid packets can be accepted as test patterns in  order to utilize the packet based communication platform of the  NoC for SBST. For this purpose, we create a function fin(i)  denoting a Boolean formula that defines the functional input  constraints. Essentially, this formula describes a data sequence,  which is a well-formed package as seen in Figure 6.   Packet Containing n fl its k 1 k 2 k 1 k 2 ... ... k 1 k 2 Flit id Switch  One fl it per clock .  Flit is appl ied to data  inputs of a sw itch port ... n 2 Fli t: 1 A functional test input has to satisfy now the formulas Φ!""! ,! , Φ!! ,  and fin(i) and has to enforce at least one output variable in Φ!""! ,!     Figure 6: Packet format to be encoded by clauses  being different from the corresponding one in Φ!! . The test set  generated this way is valid for all regular switches and has to be  stored only once.         5. NETWORK LAYER  5.1 Fault Classification  On the network layer, the direct correspondence to structural  faults is lost and has to be reconstructed in order to evaluate the  fault coverage of a test procedure and to locate faults with  sufficient resolution. For this reason, the satisfiability-based  (SAT) approach outlined above is used to classify structural faults  into functional failure classes. Fault classification is especially  useful to extend the functional failure classes, so that the  structural fault coverage of the corresponding functional test  increases. It determines which structural faults cause a certain  functional failure. Besides, it provides a weighted functional  failure classification with respect to the number of structural faults  in each class.   The method includes four tasks:   1) Definition of functionalities of an NoC switch, and  formalization of the corresponding failure modes.   2) Mapping the failure modes to the switch structure in the  form of clauses to allow test generation by modern  satisfiability solvers.   3) Modeling structural faults by clauses and adding these  clauses to the failure mode description.  4) Solving the SAT problem allows now to generate data  input for the functional test and to quantify the  structural faults covered by each of the functional  failure modes.   The outcome of this method consists of functional data packets for  the switches and links, which can be applied in system mode and  form highly effective test sequences. The experimental results  show that functional tests generated this way achieve significantly  higher fault coverage than the ones obtained by commercial  sequential ATPG tools [7].   5.2 Functional Failure Modes for NoC  Switches  The correlation of structural faults to high level faults of an NoC  has a key role in the success of a functional test method. For this  reason, functional failure modes must be carefully defined. This  subsection describes some important failure modes.  The specification of an NoC switch implies the following  functionalities:  •  The received data is routed via the correct output port.  •  The data is left intact.  • No data is lost.  • No new data is generated.  Accordingly, the functional failure modes of an NoC switch are  defined as:  • Misrouting: The received packet is routed to the wrong  output port. This fault may cause deadlock in the  network.  • Data corruption: The data is corrupted for at least one  flit in the packet.  Packet/flit loss: At least one flit of the received packet is  never delivered to the output port of the switch.  • Garbage packet/flit: A new packet/flit is generated and  routed to the output port. This includes routing a  received packet to more than one output port, or  generating spurious flits among the flits of a packet.   •  5.3 Method Overview  In order to classify and weight the failure modes and additionally  generate the corresponding functional test, models have to be  generated which include the fault free switch, the faulty instance  and the functional failure modes. The clause sets have been  described in the sections above. This section concentrates on the  description of the functional failure by a set of clauses.  Figure 7 depicts the switch interfaces, which have to be used to  Boolean formula Φ!!! .   model a functional failure mode. By using the signals of the  interface, any of the four failure modes can be expressed as a  NoC Swi tch  Switch por t i send buffer_full ... Douti HSouti Dini HSini dout Handshake  signals din Handshake  signals The SAT instance Φ! explaining the relation between the target  Figure 7: Interface signals for modeling failure modes  functional failure and the structural faults is built using the  definition of the functional failure and the good and faulty copy of  the switch:  Φ! = Φ!!! ∧ Φ!! ∧ Φ!""! ,! .  This formula is used for fault classification in order to extract the  relation between low-level structural faults and the defined  functional failure classes.  The classification results can be used to find an appropriate fault  tolerant technique for the NoC switch. For more probable  functional failure modes, a faster fault tolerance technique is  preferred.   Checking for functional failures can be done either switch-toswitch or end-to-end. Detecting a functional failure in a switch-toswitch manner requires additional hardware and increases the  component’s latency. Nevertheless, an end-to-end retransmission  introduces a higher performance penalty in case of an error. The  classification does not only quantify the structural faults in the  functional failure classes, but also determines which structural  fault locations cause certain functional failures. This information  can be used to make a cost-aware fault tolerant decision at  multiple abstraction levels.  6. SUMMARY AND FUTURE WORK  Test, diagnosis and fault tolerance techniques are available on the  different layers of the network, but they have to date largely been  applied in isolation. Possible interactions between these layers  have to be described and investigated in order to optimize the  tradeoff between hardware and timing overhead for test and  diagnosis on the one hand and the fault efficiency on the other  hand.  Future work has to model and implement automated multi-layer  interaction with respect to concrete NoC topologies and routing  policies. An actual NoC design incorporating cross-layer test,  diagnosis, and eventually fault tolerance appears to be a still  distant future.     7. ACKNOWLEDGMENTS  This work has been supported by the German Research  Foundation (Deutsche Forschungsgemeinschaft - DFG) under  grant WU 245/12-1 and RA 1889/4-1 (project ROCK).  8. "
User Cooperation Network Coding Approach for NoC Performance Improvement.,"The astonishing rate of sensing modalities and data generation poses a tremendous impact on computing platforms for providing real-time mining and prediction capabilities. We are capable of monitoring thousands of genes and their interactions, but we lack efficient computing platforms for large-scale (exa-scale) data processing. Towards this end, we propose a novel hierarchical Network-on-Chip (NoC) architecture that exploits user-cooperated network coding (NC) concepts for improving system throughput. Our proposed architecture relies on a light-weighted subnet of cooperation unit routers (CUR) for multicast traffic. Coding network interface (CNI) performs encoding/decoding of NC symbols and shares the data flows among cooperation units(CUs). We endow our proposed NC-based NoC architecture with: (i) a corridor routing algorithm (CRA) for maximizing network throughput and (ii) an adaptive flit dropping (AFD) scheme to mitigate congestion, branch-blocking and deadlock at run-time. The experimental results demonstrate that our proposed platform offers up to 127X multicast throughput improvement over multiple-unicast and XY tree-based multicast under synthetic collective traffic scenario. We have evaluated the proposed platform with different realworld benchmarks under network sizes of 4x4 to 32x32. Simulation results show 21%--91% latency improvement and up to 25X runtime reduction over conventional mesh NoC performing genetic-algorithm based protein folding analysis. FPGA implementation results show minimal overhead.","User Cooperation Network Coding Approach for NoC Performance Improvement Yuankun Xue Paul Bogdan Ming Hsieh Depar tment of Electrical Engineering University of Southern California 3740 McClintock Ave., Los Angeles, CA 90089-2562 Ming Hsieh Depar tment of Electrical Engineering University of Southern California 3740 McClintock Ave., Los Angeles, CA 90089-2562 yuankunx@usc.edu pbogdan@usc.edu ABSTRACT The astonishing rate of sensing modalities and data generation poses a tremendous impact on computing platforms for providing real-time mining and prediction capabilities. We are capable of monitoring thousands of genes and their interactions, but we lack eﬃcient computing platforms for large-scale (exa-scale) data processing. Towards this end, we propose a novel hierarchical Network-on-Chip (NoC) architecture that exploits user-cooperated network coding (NC) concepts for improving system throughput. Our proposed architecture relies on a light-weighted subnet of cooperation unit routers (CUR) for multicast traﬃc. Coding network interface (CNI) performs encoding/decoding of NC symbols and shares the data ﬂows among cooperation units(CUs). We endow our proposed NC-based NoC architecture with: (i) a corridor routing algorithm (CRA) for maximizing network throughput and (ii) an adaptive ﬂit dropping (AFD) scheme to mitigate congestion, branch-blocking and deadlock at run-time. The experimental results demonstrate that our proposed platform oﬀers up to 127X multicast throughput improvement over multiple-unicast and XY tree-based multicast under synthetic collective traﬃc scenario. We have evaluated the proposed platform with diﬀerent realworld benchmarks under network sizes of 4x4 to 32x32. Simulation results show 21%(cid:0)91% latency improvement and up to 25X runtime reduction over conventional mesh NoC performing genetic-algorithm based protein folding analysis. FPGA implementation results show minimal overhead. 1. INTRODUCTION AND RELATED WORK The emergence of cyber physical system (CPS) [3][1] that seamlessly integrates the advanced biological sensing, computation and actuation reshapes the life sciences into a quantitative, data-rich scientiﬁc domain. The unprecedented amount of heterogenous data of high variability sensed from biological entities of diﬀerent forms (e.g., genome sequence data, protein and nucleotide sequence data, protein Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM ISBN 978-1-4503-3396-2/15/09 DOI: http://dx.doi.org/10.1145/2786572.2786575 ...$15.00. structures, protein-protein interactions) paired with novel data types and unanswered biological questions of increased complexity are challenging the well established computational paradigms at multiple dimensions [1]. The large accumulated data, the high dimensionality of target analysis, the ob jectives and constraints of traditional large scale computing clusters are contributing to a widening gap between raw experimental data and the therapeutic knowledge, which in turn leads to a lagged medical response to reverse lifethreatening diseases. To overcome these challenges, in this paper, we advocate for the design of data-center-on-chip (DCoC) that exploit the massive ﬁne-grained parallelism and sustain the inherent communication requirements of big data applications via networks-on-chip (NoC) paradigm. Moreover, motivated by the tremendously high traﬃc loads and patterns of big data applications, we propose a network coding approach to NoC architectures for supporting exa-scale collective communications. Network coding (NC) [10] exploits cooperation among the network nodes and uses encoding/decoding schemes for multicast communication throughput improvement. Knowing the multicast characteristics, nodes in the network can cooperate with a coding unit which combines the multiple packets into a new one. The workload is thus reduced. Upon receiving the encoded packets, the decoding operations need to be performed on the packet and retrieve the original multicast packets before ejecting them into the destinations. The collaborations between the NC encoding and decoding nodes signiﬁcantly improve the link utilization and the system throughput. There have been attempts to use it in NoC context [12][7][9] but these eﬀorts only focus on searching for an intermediate coding node at runtime to send coded symbols. In this way, two destinations d1, d2 could receive two ﬂits at the same time from two sources s1, s2. But this needs topology reconﬁguration before a multicast session; thus, it is computationally infeasible as the network size increases and multicast transaction becomes intense. Multicast traﬃc has attracted interests in NoC due to the following reasons: i) Many NoC-based multicores have a signiﬁcant portion of multicast traﬃc. In chip-multiprocessor (CMP) architectures [5], this is due to cache coherence packets (e.g., write update request) transferred across multiple memory locations. Many applications (e.g., the spiking neural networks [4]) in multiprocessor system-on-chips (MPSoCs) [5] exhibit multicast traﬃc patterns among processing elements (PEs). ii) Prior eﬀorts emphasize the importance of multicast traﬃc on overall system throughput [8]. This is Figure 1: Comparison of multicast approaches because a single multicast packet may be destined to multiple destinations. Multiple unicast communication (MUC) used in regular NoC shown in Fig.1(a) creates congestion by unnecessarily replicating the packet to distinct destinations. The multicast throughput of MUC is also poor as only one packet could be sent to one sink during each transmission. In addition to MUC, numerous research eﬀorts have addressed the muticast routing in NoC [6][8][11][13]. In [14][6], the multicast routing algorithms are reviewed based on two types, i.e., the path-based [6] routing and the multicast tree based [8][17] routing. For the path-based routing [6], a single multicast packet traverses the destination nodes following the order predeﬁned by the setup ﬂits. In many approaches, the setup ﬂits introduce additional latency. As shown in Fig.1(b), for the tree based implementations [8][17][11], the multicast packets are replicated at the intermediate nodes of the tree and each copy of the packet follows the branches of the tree to route to destinations. One limitation of the tree-based multicast routing is that the packet replication at intermediate nodes may increase the workload on these routers and reduce the overall throughput due to the created congestion [2] known as branch blocking. Another limitation is that even though multiple destinations could be reached during one transmission, each destination could obtain only one packet at a time due to the individual channel bandwidth constraint. Towards this end, we propose a new network coding NoC (NCNoC) consisting of cooperation units (CU), a corridor routing algorithm (CRA) to support the NC-based multicast and an adaptive ﬂit dropping (AFD) scheme to avoid network congestion and save power. Our main contributions are: (1) We propose a network-coding NoC architecture that overcomes the limitation of prior multicast NoC and improves the multicast throughput by allowing multiple packets to be delivered to several destinations at the same time. (2) We design a deadlock-free corridor routing algorithm (CRA) to increase the path diversity for the multicast transaction. (3) We develop an adaptive ﬂit dropping (AFD) scheme to dynamically mitigate the runtime traﬃc congestion and to avoid the blocking at the branching nodes of the multicast tree. We show that the AFD scheme is deadlock-free and signiﬁcantly increases the system throughput especially under heavy traﬃc load. 2. NC AND APPLYING NC ON NOC 2.1 Linear Network Coding en network N = G(V , E ), a s (cid:0) t cut is a node partition According to the max-ﬂow min-cut theorem, for a giv(S, T ) of V such that s is in S and t is in T . The maximum Figure 2: Multicast and user-cooperation amount of ﬂow (maxf low) passing from a source s 2 S to a sink t 2 T is equal to the minimum capacity of this s (cid:0) t cut (i.e., minimal capacity of links leaving S ) [10]. Fig.2(a) shows the minimal capacity of links leaving S for T is 3 thus the maxf low(S, T ) is also 3. Based on this theory, for any node vti 2 V as a sink or a set of sink nodes ϱtk , the upper bound of the data receiving rate is given by maxf low(vti ) and maxf low(ϱtk ), respectively. To achieve this bound, NC is proposed to encode destinations. Let < (cid:1) > denote the space that is linearly packets in the intermediate nodes and reconstruct them at spanned by a set of vectors and fe is the NC global encoding kernels (i.e, vectors of weights for linear combination of incoming edges to node vti and Vti =< fe : e 2 I n(vti ) > packets from incoming edges). I n(vti ) denotes the set of is the space linearly spanned by the global encoding kernels of a linear NC. For every non-source node vti with maxf low(vti ) (cid:21) ω , if we have Dimension(Vti ) = ω (1) By properly designing fe , all non-source nodes that satisfy eq. (1) are able to receive ω packets from source nodes. Thus NC helps improve the multicast traﬃc throughput. 2.2 A Network-coding Approach to NoC When applying NC directly on conventional mesh-based NoCs, the max-ﬂow bound of each sink is constrained by network topology and the routing protocol. For example, assuming all links have unit capacity 1 in a mesh NoC like Fig.2(b), the maxﬂow (or min-cut) of node A and B is 2 and 3, respectively. This upper-bound is determined by how the nodes are interconnected in mesh NoC. However, considering pair-wise communication, if packets are routed deterministically, there is actually only one path between any pair of nodes thus the maxﬂow from one node to another will be 1 which is much less than the theoretical bound (i.e., 4). This observation motivates us to consider the beneﬁts brought by the col lective behavior of a set of nodes sharing network resources. Speciﬁcally, suppose ϱtk denotes a collection of destinations. Let Vϱtk represent the space formed by the encoding kernels of set ϱtk (i.e., all vectors of weights for linear combination of packets from incoming edges to a set of nodes ). If we have, Dimension(Vϱtk ) = minfω , maxf low(ϱtk )g for any set of non-source nodes, eq. (2) suggests such set of nodes are able to receive ω messages at the same time if the maxﬂow of the set is greater than ω even if the maxﬂow of any individual node may not satisfy eq. (1). In this sense, the constraints to improve multicast throughput by applying (2) NC are much relaxed compared to those for an individual node. Alternatively stated, the cooperation among a set of nodes makes possible receiving multiple packets at the same time for any node within it. More precisely, when enforced in practice, the cooperation here means the sharing of inbound packets and injection bandwidth among a set of routers located closely through CU. Each CU, which will be detailed later, is a common network interface between the tiles and their corresponding routers. It manages all the injection ports within, and inbound packets from outside it. Since routers commonly use the injection bandwidth and incoming packets so it is also called as user cooperation. Fig.2(c) shows an example of user-cooperation network coding where nodes in the shaded area are assumed to be in the same CU. A source node is sending 4 packets fp0 p1 p2 p3 g to a set of nodes. These four packets are ﬂit-wise encoded into one packet before they are being sent out through the injection ports managed by this CU. The uncoded 4 packets are routed via 4 distinct paths under minimal XY and YX routing algorithm. In contrast, the coded packet is sent out through a subnet of long links between CUs (shown in curved lines) rather than the same regular network. In the destination CU, combined with locally received packets, the coded packet that enters this CU are accessible by all its member tiles and used to reconstruct all 4 packets for all tiles in the same CU. 3. NC-BASED NETWORK-ON-CHIP Figures 3(a)-(b) show an overview of the 3-step network coding procedure where a source node is multicasting 4 packets to 4 destination nodes in the same CU over a large scale NCNoC. In Step 1 (Symbol Encoding), a multicast transmission is initiated by a source Tile j . The source sends the consecutive 4 packets fP3P2P1P0 g through coding network interface (CNI) to both the encoder and adjacent routers. The 4 packets fP3P2P1P0 g are grouped into two pairs fP3P2 g and fP1P0 g. Then the two pair of packets are ﬂitwise encoded and combined into a set of transmission coded ﬂits (tCFs). For minimized hardware overhead, XOR is used as network encoding kernel. These tCFs are sent through a subnet of cooperation unit routers (CURs) connected by multi-hop links. The same 4 packets will also be sent through the network of regular routers. In Step 2 (Corridor Routing and adaptive (cid:13)it dropping), the uncoded packets are travelling through the regular network following the proposed corridor routing algorithm and adaptive ﬂit dropping algorithm. Meanwhile, the tCFs will try to reach the destinations following simple XY-tree routing. In Step 3 (Decoding and end-point synchronization), the coded and uncoded packets will be synchronized at destination and used to reconstruct the original packets if necessary. Next, we present in Figure 3(c)-(d) a walk-through example to show how the multicast communication works via NCNoC. 3.1 Ready to take-off: symbol encoding A multicast session starts when any one of source nodes needs to initiate a collective transmission of packets to multiple destinations. Before it starts, a multicast request is ﬁrst sent to the local arbiter (i.e., Larbiter shown in Figure 3(c)) for resolving the conﬂict requests within the same CU. Once a request is granted, packet pairs fP3P2 g and fP1P0 g are encoded through XOR kernel into two symbols. The two symbols are then combined together as a tCF. After mountFigure 4: Distributed dropable ﬂits ing the header and tail ﬂits to form a packet, tCFs then request for the access to the the corresponding CUR whose injection port is shared among CUs. After obtaining access from the global arbiter (i.e., Garbiter), tCFs are forwarded along the XY tree paths towards the CURs to which the uncoded packet pairs fP3P2 g and fP1P0 g are also injected multicast destination CUs are connected. Meanwhile, the to the regular routers via the available injection ports managed by the CU to which the source node belongs. They are then routed under CRA to their destinations. 3.2 In Flight: Corridor routing of the proposed CRA. Uncoded multicast packets fP3P2P1P0 g Figure 3(c) simpliﬁes the network to crystalize concepts are assigned with distinct destinations (e.g., P0 is heading for node 3 and P3 moves towards node 1 even though they are multicast packets). The packet pair fP3P2 g travels under minimal XY routing paths (i.e., X corridors or Xcor) while fP1P0 g pair follows Y-X routing paths (i.e., Y corridors or Ycor). Routers receiving packets belonging to the same pair are called conjugate routers (ConjRs). Otherwise, they are called cooperation routers (CoRs). For instance in Figure 3(c), routers 1 and 3 are CoRs to each other while routers 2 and 1 are mutually ConjRs. Upon arrival, CoRs and ConjRs exchange received packets for reconstructing all original packets as detailed later in section 3.4. Algorithm 1 summarizes the pseudo-code of the CRA. For regular messages, packets will be distributed among all available injection ports and injected to network using different corridor paths. For multicast packets, when a granted multicast request is activated within a CU, the corresponding CU address is computed ﬁrst for each destination. Then, a corridor path will be assigned. Of note, this path might not lead to its real destination(s) but some other node(s) that are located in the same CU(s). This is permitted since the packets are able to be shared in the same CU so the destination(s) might not be the real one(s). Actually, by building the CU and CNI to share information among CoR and ConjR, we could enrich the path diversity by distributing the traﬃc across all possible routing paths between two CUs. For example, there are 4 minimal routing paths (2 Xcors and 2 Ycors) that exist between two fP3P2P1P0 g to node 1. In contrast to MUC, the source does CUs shown in Figure 3(c). The source node wants to send not need to send all the packets through the paths between node 1 and itself. The packets could take any of the Xcors In the example shown in Figure 3(c), fP3P2P1P0 g are sent and Ycors. This helps alleviate the congestion at run time. to node 3, node 0, node 2 and node 1, respectively. 3.3 Turbulence : adaptive ﬂit dropping By applying ﬂit-wise encoding of multiple multicast packets, we could recover data with missing parts. For example, with coded packet C and two original packets A and B, we aﬀord to lose any one of two packets A or B and reconstruct Figure 3: NCNoC Overview: a) Multicast traﬃc through NCNoC requires 3 steps: Symbol Encoding, Corridor Routing and Adaptive Flit Dropping , Decoding and End-point Synchronization. b) A multicast example over an extended network. A source node intends to deliver multiple packets to several distantly located destinations in the same CU. Packets are encoded into tCFs that are sent via the subnet of CU routers to the target CU which contains the destination nodes. Uncoded packets travel through the regular network under CRA. c) A simpliﬁed transmission graph shows the ideas of CRA. Uncoded packets fP3P2P1P0 g are assigned with distinct destinations. Packets pair fP3P2 g travels under minimal XY routing paths(i.e., X corridors) while fP1P0 g pair follows Y-X routing paths(i.e., Y corridors). Routers receiving packets belonging to the same pair are called conjugate routers(ConjRs). Otherwise, they are called cooperation routers(CoRs). CoRs and ConjRs exchange received packets for reconstructing all origin packets. d) Detailed micro-architecture and encoding&decoding scheme. The source node sends 4 packets to node 0-3. It is shown how node 1 gets the reconstructed 4 packets at the same time. them according to the algebraical structure of encoding kernel employed. This suggests that it is safe to lose ﬂits in a multicast packet and we can still keep the integrity of communication data. This introduces several beneﬁts: 1) Congestion reduction: Competition for network resources like link bandwidth, virtual channels and crossbars could be mitigated if we drop some of ﬂits for intense conﬂicts at network ”hotspots”. 2) Branching blocking reduction: As shown in Figure 5(a), tree-based multicast is less favored mainly due to the branch blocking phenomenon when a ﬂit fails to traverse the switch given not all desirable outports are granted thus blocking the packets behind and creating conﬂicts over long time. By forbidding current ﬂit requesting certain outport(s), the chance this ﬂit leaves current router is increased thus reducing the blocking rates and congestion. 3) Deadlock avoidance: In the routing algorithm, if the turn model could form a circular loop, then this routing is not deadlock free. Figure 5(b) shows a possible deadlock situation when XY and YX routing are used at the same time. In this situation, if some of ﬂits could be dropped and make room for incoming ﬂits, the deadlock will be avoided. Of particular note, the deadlock will only happen in routers with presence of multicast packets that have to take turns. Of note, each multicast packet only takes no greater than one turn under XY/YX routing. Therefore, we only need to drop the ﬂit once in such routers to avoid deadlock. Based on these observations, we propose a simple adaptive ﬂit dropping scheme to address congestion, branch blocking and deadlock collectively. This scheme consists of 3 main ideas: A) we distribute the dropable ﬂits every other ﬂit in Figure 5: Adaptive Flit Dropping the packet shown in Figure 4 to maximize the chance that a dropable ﬂit will appear in above situations. B) We set the length of VC buﬀer as higher than half of the maximal length of a packet so that if a multicast ﬂit is in the buﬀer, either there are ﬂits that could be dropped freely or the multicast ﬂit could not occupy the entire buﬀer if all its dropable ﬂits are dropped already. C) We set M ax trSW times as threshold and keep tracking of how many times a multicast ﬂit fails to traverse the crossbar. If this threshold is reached, then this ﬂit, if dropable, will be dropped. Compared to other state-of-art deadlock recognition schemes such as looping back a detection signal, the threshold-base method, although simple, is easy to tune, eﬀective in practice and minimizes the hardware overhead to detect the deadlock. 3.4 Decoding and end-point synchronization For regular packets, synchronization is not needed upon arrival but we need to synchronize the coded packets with Algorithm 1 Corridor Routing algorithm Input: Current node cur; Current packet of interest, p; Destination node set p.dst; Current CU, Ccur ; Routing Function XY() and YX() Output: Outgoing port list P 1: if I sRegularP acket(p) == 1 then 2: if F ind C U ID(p.dst) == Ccur then 3: P.insert(Eject(p,p.dst)) 4: else 5: P.insert(XY(p.dst,cur)) 6: end if 7: else for all m 2 p.dst do 8: 9: if F ind C U ID(m) == Ccur then 10: P.insert(Eject(p,m)) 11: else 12: if p.route direction == 1 then 13: P.inser(XY(m,cur)); 14: else 15: P.inser(YX(m,cur)); 16: end if 17: end if 18: end for 19: end if 20: return P un-coded packets only when (cid:13)it-dropping happened for this packet such that data has to be recovered from the coded packet. Otherwise, it is either already synchronized when coded packet arrives earlier or does not need to be synchronized as all original packets have already arrived. In the special case where synchronization is needed, we keep track of arriving and expected ﬂits at end-point to synchronize the dataﬂow. Three trackers AFID, EFID and CFID are used to update the record at runtime. AFID is used to record the ﬂit ID (FID) and packet ID (PID) of incoming ﬂits from corridor paths. CFID is used to track FID and PID of received tCFs. EFID is used to indicate FID of the next expected ﬂits in order. At runtime, upon arrival of a multicast ﬂit, the current front coded ﬂit in queue is compared with ID of this ﬂit. If C F ID = AF ID , then the current coded ﬂit is dequed, decoded at CNI and ejected. If C F ID < AF ID = EF ID or the received tCF queue is empty, the data retrieval from the regular router is suspended C F ID = AF ID . If EF ID = C F ID < AF ID , this means these ﬂits have been dropped since ﬂits should come in strict order under deterministic routing. In this situation, data will be collected from conjugate router to recover the dropped ﬂit. 4. EXPERIMENT SETUP AND RESULTS 4.1 Simulation setup We evaluate the proposed NCNoC using a C++ cycleaccurate simulator. The router is customized to support both XY-tree based and proposed multicast routing. Wormhole switching is used and each port has four 16-ﬂit-depth virtual channels (VCs). We also implemented the minimal building subregion of 4x4 mesh+CUR as an example in Xilinx Virtex-6 LX760 65nm FPGA using synthesizable Verilog for area evaluation. Xilinx ISE 12.4 is used as the implementation tool. We build bigger network by replication of the 4x4 minimal building subregion so area overhead of larger networks could be pro jected. We ﬁrst evaluate the network throughput on an 8x8 mesh NoC with synthetic traﬃc with diﬀerent number of concurrent sources and destinations. Throughout the experiments, ﬂit width is set to 64 bits (8 bytes) and each packet consists of 32 ﬂits. In all multicast transactions, the message size is set to 32 packets. We conduct a set of experiments with synthetic traﬃc under 10% multiple current many-to-many multicast transactions mixed with regular uniform traﬃc. For realworld benchmarks, we employ several 16-node multithreaded commercial and scientic workloads from DBmbench and SPECweb99 and map them randomly to the proposed platform with 8x8 nodes. The traﬃc workload of these benchmarks consists of the memory request/response coherence traﬃc between PEs and caches. To evaluate the throughput improvement for a real application, we perform 3D-HPSC model-based protein folding analysis using genetic algorithm [15] funder network size from 4x4 to 32x32 and evaluate the runtime of 2500 generations over a population of 5000 chromosomes. A set of realworld protein sequences with diﬀerent lengths from 27 to 48 amino acids taken from [15] are used as our input benchmarks. 4.2 Analysis under synthetic trafﬁc We compare our proposed solution with MUC and XY Tree-based approaches. To show the beneﬁts of adaptive ﬂit dropping, we implement the proposed architecture with and without AFD scheme and run several simulations. We randomly choose diﬀerent number of sources from 4-16 in each phase with diﬀerent number of destinations (i.e. 16, 32 and 64). To study multicast performance, we measure the multicast throughput as number of messages delivered to all destined sink nodes within a unit time under diﬀerent injection rates. We normalize the results over multiple unicast scenario and report the improvement. Figures 6(g)-(i) show the improvement in network multicast throughput of our proposed CRA+AFD over MUC and XY-tree (the multicast throughput improvement for XYtree, CRA-only and CRA+AFD with diﬀerent number of multicast destinations are normalized to the MUC values). The multicast throughput is deﬁned as the average time to deliver all the multicast packets to all destined nodes given diﬀerent injection rates. From the simulation results, when the injection rate is low and network is still in free phase, the proposed CRA+AFD achieves a network throughput improvement up to 127X over the MUC and 5.3X over the XY tree approach with number of destination nodes equal to 63. This is because the overall packet delivery time cost increases linearly when using MUC while it is determined by the most distant node using XY-tree and CRA/CRA+AFD. The augmented maxﬂow by introducing user cooperation network coding in each CU and enriching diversity of routing paths contribute to higher throughput over XY-tree by 530%. When the injection rate increases towards saturation phase, the performance degrades due to increasingly congested traﬃc but the throughput improvement still remains 51X, 29X, 15X over MUC with destination number of 63 when the number of sources is 4, 8 and 16, respectively. Compared with XY-tree, the proposed CRA+AFD Figure 6: The multicast network throughput evaluation:(a)-(c), # of simultaneously activated sources=4 to 16 Oracle in the ﬁgure. Compared to Oracle, Ocean and Sparse have lowest traﬃc volume and Db2v ranked as second heaviest application followed by Apache. Mixed 1 and Mixed 2 are roughly the averaged results of sum of these 5 applications. Combined with Fig.7-(D), we can see the relation between the improvement in latency and traﬃc load. The heavier an application is, the more improvement in latency is obtained. For example, in Ocean and Sparse, the traﬃc volume is so small that we only obtain roughly 20% reduction in average latency over naive mesh and CRA+AFD works even worse than CRA. This is because the network is away from saturation region and extra control logic for adaptive ﬂit dropping may contribute to latency increase of some locally congested packets. AFD is less favorable when traﬃc is just locally congested in certain nodes and threshold time to drop ﬂit is close to waiting time in such locally congested nodes. In this case, extra time cost at the sink node to recover the entire packet is larger than the travelling time saved for this packet. However, AFD shows latency improvement when the accumulated waiting time of the packets in the routers is greater than the time needed to recover dropped ﬂits when there is heavy traﬃc load like in Oracle. In such case, CRA+AFD has achieved 53% and 91% improvement in Oracle compared to CRA and naive mesh. In terms of energy consumption evaluation, we feed the traﬃc trace in Modelsim to generate backward Switching Activity Interchange format (SAIF) ﬁle as reference for power analysis in Xilinx ISE and use Virtex-6 LX760 as target device. Energy consumption is normalized over naive mesh NoC. Fig.7-(B) shows 12% energy consumption reduction for both CRA and CRA+AFD approaches. The energy consumption improvement is limited due to extra router overhead and limited share of multicast traﬃc in each benchmark. Fig.7-(D) shows an average of 10% multicast in total traﬃc volume. Energy could be saved for multicast because the total hop counts is reduced compared to MUC. It is also saved using CRA/CRA+AFD even for regular traﬃc because by sharing the received packets, packets could bypass 1-2 routers thus saving switching energy. We calculate energy-delay product (EDP). Fig.7-(C) shows a 30%-92% EDP reduction. To better show how augmented throughput could contribute to runtime reduction for real applications, we apply genetic algorithm for 3D-HPSC protein folding analysis [15] over 3 realworld protein sequences Unger273d.1, Dill.5 and S48.1 using proposed NCNoC platform from 4x4 to 16x16. We measure the runtime for 2500 generations over a population of 5000 chromosomes (i.e., candidate solutions) Figure 8: Protein folding runtime comparison achieves throughput gain of 1.9X, 2.56X, 3.49X with 4, 8 and 16 sources launching packets at the same time, respectively. Compared to CRA, considering the AFD scheme brings an improvement up to 1.8X in network throughput under near-saturation injection rate. This improvement suggests the reduced average packet latency by dropping some ﬂits in the most congested routers. This latency reduction is because the time cost to synchronize and decode the dropped ﬂits is less than the time saved during the travel. 4.3 Analysis under realworld benchmarks In this section, we ﬁrst report the latency comparison of various realworld benchmarks for a 8x8 NoC. We consider 7 applications, namely, Apache, Db2v, Ocean, Oracle, Sparse and two random combinations of these 5 applications, Mixed1 and Mixed2. Simulation time of each benchmark is set to 25,000,000 cycles with 1 warm-up phase of 250,000 cycles. In Fig.7-(A), the packet latency comparison is shown. We compare XY-tree and proposed approaches with baseline naive mesh NoC of same size. The results are normalized by the packet latency from naive mesh NoC. It is shown the proposed user cooperation NCNoC using CRA+AFD reduces the latency by 21%-91%. CRA+AFD approach outperforms CRA in all cases by 5%-53% except in Ocean. It is interesting to interpret this result combined with Fig.7-(D). We have analysed the traﬃc load for each of 7 application in terms of total traﬃc volume, percentage of multicast traﬃc in overall traﬃc and average number of destined regions (CUs). In Fig.7-(D), the traﬃc volume is normalized by the heaviest traﬃc load from Oracle. To better show the results, we keep Figure 7: Benchmark comparison: Latency(A), Energy(B), EDP(C), Traﬃc load(D) The result is normalized to that of on XY tree under each network size. From Figure 8, the proposed platform shows good scalability in terms of reducing the runtime under diﬀerent network sizes by 10%-90%, 10%-93%, 10%-96% for 3 benchmarks. The improvement of runtime for XY-based approach as we increase network size is saturated due to limited throughput gain [16]. Compared to XY-tree based approach, the proposed CRA+AFD outperforms by 81%, 82% and 87% in runtime under larger network size of 32x32. 4.4 Area evaluation Figure 9: Pro jected hardware overhead To evaluate the hardware overhead for the proposed NCNoC, we ﬁrst develop a 4x4 mesh NoC with a shared CNI and one CUR using fully synthesizable Verilog. This is the minimal building block and we could easily replicate it repeatedly to construct large scale NCNoCs. ISE design suite 12.4 is used as the synthesis tool and the target device is set as Xilinx Virtex-6 LX760. To fairly compare the hardware overhead in terms of FPGA resouces utilization, we ﬁx the targeting operating frequency at 100MHz such that no extra overhead to achieve better timing performance is considered. Table I shows the results where a 4x4 NCNoC introduces 12.6% more registers and 10.9% extra LUTs over conventional NoC. To further evaluate the hardware scalability, we take the synthesis measurement from the 4x4 mesh NCNoC implementation and pro ject it to mesh networks with size ranging from 4x4 to 32x32. Results are normalized to a conventional 4x4 mesh NoC as shown in Figure 9. The dark blue line represents the overhead of a conventional mesh NoC under diﬀerent network sizes. The red line shows how the area of NCNoC grows as the number of nodes in the network increases assuming the extra area penalty introduced by NCNoC grows as linearly as they were under the 4x4 network. The orange line shows the actual overhead of NCNoC vs network size. From the ﬁgure, we could see the area cost of NCNoC grows slower than they do under a 4x4 network. This is because we do not always need more CURs and CNIs whenever there is new node added to the network as one CUR or CNI is shared between multiple nodes. Compared to conventional NoC, the hardware overhead penalty ratio ﬂuctuates between 8% and 11.7% at the beginning. As the number of nodes increases, the cost to enforce the NCNoC and network coding scheme converges to roughly 11.6%. It is a minimized price to pay in view of remarkably improved performance. Table 1: FPGA implementation@100MHz FPGA resource Number of Slice Registers Slice of LUTs LUT as Logic LUT as Mememory Regular 11120 29362 25904 3458 NCNoC 12531(∆12.7%) 32574(∆10.9%) 28782 3792 5. CONCLUSION We have presented an user cooperation network coding approach for NoC consisting of cooperation units to aggregate traﬃc from multiple neighboring nodes, a corridor routing algorithm and adaptive ﬂit dropping scheme to avoid network congestion. To validate the beneﬁts of our proposed architecture, experiments are performed through both synthetic traﬃc and realworld application benchmarks including multicore and bioinformatics applications. FPGA implementation of proposed architecture are performed. Based on the implementation results, we pro ject and evaluate the area overhead over of wide range of network sizes from 4x4 to 32x32. The hardware cost is minimal compared to the signiﬁcantly higher network throughput and reduced network latency. We show in this work that remarkable performance improvement is achievable by exploiting the collective phenomenon and network coding concepts on NoC-based architecture. 6. ACKNOWLEDGEMENT The authors are thankful to anonymous reviewers for their valuable feedback. We acknowledge the support by US National Science Foundation (NSF) under Grant 1331610 and Grant 1453860. 7. "
Accurate System-level TSV-to-TSV Capacitive Coupling Fault Model for 3D-NoC.,"TSV-based 3D-NoC has been introduced as a viable solution for integrating more cores on a chip, while imposing smaller footprint area and better timing performance as compared to 2D-NoC. However, TSV-to-TSV coupling is increasingly impacting the reliability of 3D-NoCs due to large size of TSVs. Addressing this issue, various resilient approaches have been recently proposed. But they have been evaluated by uniform random distributions fault modelling, which results in 26%-99% inaccuracy. We propose a system-level TSV-to-TSV coupling fault model that models the capacitive coupling effect, considering thermal impact, with circuit-level accuracy. This model can be plugged into any system-level TSV-based 3D-NoC simulator. It is also capable of identifying faulty TSV bundles and evaluating the efficiency of alternative resilient TSV-based 3D-NoC designs at the system-level.","Accurate System-level TSV-to-TSV Capacitive Coupling Fault Model for 3D-NoC Pooria M.Yaghini, Ashkan Eghbal, Siavash S.Yazdi, and Nader Bagherzadeh Depar tment of Electrical Engineering and Computer Science University of California, Irvine {pooriam, aeghbal, ssedighz, nader}@uci.edu ABSTRACT TSV-based 3D-NoC has been introduced as a viable solution for integrating more cores on a chip, while imposing smaller footprint area and better timing performance as compared to 2D-NoC. However, TSV-to-TSV coupling is increasingly impacting the reliability of 3D-NoCs due to large size of TSVs. Addressing this issue, various resilient approaches have been recently proposed. But they have been evaluated by uniform random distributions fault modelling, which results in 26%99% inaccuracy. We propose a system-level TSV-to-TSV coupling fault model that models the capacitive coupling effect, considering thermal impact, with circuit-level accuracy. This model can be plugged into any system-level TSV-based 3D-NoC simulator. It is also capable of identifying faulty TSV bundles and evaluating the eﬃciency of alternative resilient TSV-based 3D-NoC designs at the system-level. Categories and Subject Descriptors B.8 [Hardware]: Performance and Reliability General Terms Reliability, Measurement Keywords Fault modeling, TSV coupling, 3D NoC 1. INTRODUCTION Today’s process technology is expected to be scaled down to 7nm by 2020, while manufacturers will reach the fundamental physical limits of this trend. To keep technological progress in step with Moore’s Law, researchers have suggested applying lower frequency many-core chips rather than a single-core with higher operational frequency. Networkon-Chip (NoC) has been proposed as a scalable and eﬃcient on-chip interconnection among cores. In addition, employing Three-Dimensional (3D) integration instead of TwoDimensional (2D) integration is the other trend to keep the Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citati on on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redis tribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions fro m Permissions@acm.org. NOCS ’15, September 28 - 30, 2015, Vancouver, BC, Canada Copyright 2015 ACM 978-1-4503-3396-2/15/09 ...$15.00. DOI: http://dx.doi.org/10.1145/2786572.2786598. traditional expected performance improvements [1]. The combination of 3D integration and NoC technologies provides a new horizon for on-chip interconnect design. The 2D dies were initially connected by wire-bond, later by ﬂip-chip, and recently by Through-Silicon Via (TSV). TSV-based 3D-NoCs are currently the most promising approach to deal with the limitation of 2D architectures for next generation fabrication technologies [2]. They oﬀer higher bandwidth, smaller form factor, shorter wire length, lower power consumption, and better performance than traditional 2D-NoCs [3]. Although the impact of TSVs on Signal Integrity (SI) in 3D-NoCs has been investigated [4, 5], the reliability of TSVs is still an area of open research in the context of designing 3D stacked chip systems. TSV-to-TSV Capacitive Coupling (TTCC), which is the main focus of this article, is one of the ma jor challenges for designing 3D multiple stacked ICs. TTCC occurs because of unexpected parasitic signals in 3D designs related to physical characteristics of TSVs. TTCC is responsible for two undesirable eﬀects. First, it increases the path delay by slowing down transitions on signal-switching if neighbor TSVs perform opposite transitions. Second, the coupling noise may result in signal distortion by generating large glitches on a static signal when TSV’s aggressor neighbors transition. We present a fault model to quantify the impact of TTCCinduced faults at system-level with circuit-level accuracy. This model pinpoints fault-prone TSV links at runtime. This model is also able to report the eﬃciency of resilient TSVbased 3D-NoC designs for a given set of TSV characteristics, thermal impacts, and workloads. The presented model can be utilized for application-speciﬁc designs by addressing the susceptible to failure TSVs. With these results a designer is able to employ fault-tolerant methods only where they are needed. For general purpose architectures, the presented fault model is able to ﬁgure out the eﬀect of physical parameters of TSVs on timing requirement of the circuits. This model can be used to ﬁnd the suitable physical parameters for a TSV to have reliable TSV links. In more details the eﬀect of TTCC on timing requirements of the 3D design are captured at circuit-level, and they will be applied in system-level simulations at runtime. This model takes advantage of both system-level and circuit-level modeling which results in shorter simulation time and more accurate experimental reports. Our proposed fault model is potentially useful for evaluating the reliability of 3D manycore applications in which TTCC may lead to failure. 3D memory and 3D-NoCs are two examples of these applications. In 3D memory applications [6], TTCC can corrupt the data or/and address bus. In on-chip network routers, data ﬂit corruption may occur due to TTCC in which an Error-Correction Code (ECC) is needed for protection. The ma jor contributions of this article are: Flip  Flop ITSV Dri ver CTSV/2 LTSV CTS V/2 CTS V/2 CTS V/2 r o b h g e i S T r o b h g e i CTSV/2 LTSV Victim  TSV RTSV 2Csi Rsi/2 Silicon  Model CTSV/2 TSV Lumped Model Load Flip  Flop CTSV/2 • To elaborate TTCC eﬀects on timing requirement of a circuit in order to present circuit-level fault library, which is discussed in Section 3. The proposed fault library is utilized at run-time in order to identify the TTCC eﬀect automatically. • To provide a system-level TTCC fault modeling framework for TSV-based 3D-NoCs, which is presented in Section 4. It can be integrated into any simulator (working with actual data ﬂits) to detect and inject TTCC faults at runtime, and to evaluate resilient approaches. • To present a case study, characterizing faults at runtime in a 4 × 4 × 4 3D-NoC architecture, which is explained in Section 5. 2. RELATED WORK Based on an overview of the state-of-the-art fault-tolerant methods in the last decade [7], reliable NoCs have been proposed by presenting fault-tolerant routing algorithms [8, 9], reliable architecture [10], and error correction coding methods [11, 12]. Additionally, some research groups have suggested coding methods to alleviate parasitic capacitivenoises rather than removing them. Two coding approaches have been proposed to mitigate the undesirable eﬀects of Inductive and capacitive TSV-to-TSV coupling eﬀects [13, 14]. A power-eﬃcient fault-tolerant method has been proposed in which the routers are capable of switching between error detection and error correction modes at run time [15]. Furthermore, some researchers have addressed the reliability evaluation of NoCs [16]. A classiﬁcation of the potential physical faults in a baseline 3D NoC is discussed in [17]. This article also provides a reliability analysis for ma jor sources of faults separately based on their Mean Time to Failure (MTTF). In addition, an analytical model for the coupling capacitance between pairs of TSVs is presented in [4]. However, all of these approaches are evaluated through the experiments in which the time and location of fault occurrences are chosen with uniform random distributions. In addition, based on our experiments, the evaluation of TTCC eﬀects by injecting uniformly random faults is considered 26%-99% inaccurate in capturing time and locations of induced faults, as will be discussed in Section 5.2. In a similar work, a system-level process variation model has been proposed for 2D-NoC simulators [18], but it does not support TTCC eﬀect in 3D-NoCs. On the other hand, although several crosstalk minimization techniques have been proposed in 2D designs [10, 19], they cannot be directly applied in 3D designs. This is because of the fact that the physical characteristics of 2D wires and TSVs are diﬀerent. In addition 2D wires have at most two aggressors in the same layer of fabrication, while in 3D designs TSVs are surrounded by more aggressors [20]; making the crosstalk modeling and elimination more complicated for 3D-NoCs. 3. TTCC ELABORATION The term TSV-to-TSV coupling refers to capacitive and inductive couplings between each pair of TSVs. Electric 1 Dri ver Dri v er Dri v er Dri v er V V T S 2 1 N V N T V S N i i T A N r o r o RTSV N N S r o b r h o g b h e g e r o s r s o e s r s g e g r g g A A s s e r g g s s e r g g R T S V RTSV RTSV Load CTS V/2 CTS Load V/2 Load Load A Figure 1: The block diagram of the induced capacitive coupling on each TSV based on physical parameters ﬁeld results in capacitance coupling and magnetic ﬁeld is a source of inductive coupling. This article targets the capacitive coupling eﬀect that is more critical in lower range of operational frequencies (less than 5GHz) [21], which applies to NoC routers. In this section: ﬁrst, a circuit-level TSV model for TTCC elaboration is discussed, although any other model can be replaced; second, a TTCC classiﬁcation is presented; ﬁnally, the eﬀect of TTCC on timing requirement of NoC router transmitter circuit is illustrated using realistic benchmarks. 3.1 TTCC Circuit-level Modeling A framework consisting of multiple TSVs at circuit-level using Synopsys HSPICE is implemented in this experiment to study the sources of TTCC eﬀect. Developing TSV simulation framework allows extracting the realistic accurate TTCC eﬀect for diﬀerent parameters. The coupled TSV structure is modeled as a lumped RLC circuit. We have utilized the lumped RLC circuit circuit-level model of TSVs presented in [22–24]. Figure 1 shows the used circuit-level in this article, in which RT SV , LT SV , Rsi , Csi , and CT SV represent TSV resistance, TSV inductance, substrate resistance, substrate capacitance, and oxide capacitance, respectively. The value of the circuit elements are modeled using analytical equations based on the dimensions of the structure, such as oxide thickness, silicon substrate height, TSV radius, and TSV pitch and by material properties like dielectric constant and resistivity. These physical parameters are also extracted from ITRS reports [25]. The thermal impact is also considered in the TSV model using equations in [26]. Furthermore, since the parasitic capacitive eﬀect of a diagonal neighboring TSV is less than 1/5 of an adjacent TSV neighbor [13], only the eﬀect of adjacent TSV neighbors are examined in this experiment. However, our fault model can be expanded to support more TSVs as well. For our analysis, a TSV is connected to the output of an inverter (driver) on one side and to the input of another inverter on the other side (load). These inverters are needed to record the propagation delay and its dependency to parasitic capacitivenoises. Two ﬂip-ﬂops, one before the driver inverter and one after the load inverter are inserted to capture the parasitic capacitive eﬀects on timing requirements of the circuit. We compare the input data pattern with out                        0C 1C 2C 2C 0   1   0    1   0   1    0   0   0 Data i =  Data i-1 =  Current  = direction   0   0   0    0   1   1    0   1   0 TTCC  = factors   2   4   1    4   5   1    2   2   1 Figure 2: Current and TTCC matrices in a 3 × 3 mesh of TSVs put data pattern to catch the parasitic capacitive eﬀects. Predictive Technology Model (PTM) [27] FinFET transistor models are employed to implement inverters and ﬂipﬂops. Then a comprehensive set of simulations is performed on the developed TSV framework. The impact of operational frequency, temperature, technology, TSV radius, and TSV oxide thickness are investigated which is discussed in 3.2. SPICE model of TSVs are employed to examine the TTCC eﬀect among a victim and its aggressor TSVs. In this article we deﬁne path delay, as the propagation delay from the output of the driver inverter to the input of the load inverter after the rising edge of the clock. Nominal Path Delay (NPD) is the path delay when there is no TSV parasitic capacitive. Actual Path Delay (APD) may be longer than NPD due to the coupling eﬀects generated by aggressor TSVs. Assuming the system clock is adjusted for a critical path of NPD, circuit timing requirement is violated when the APD exceeds the NPD. Timing Violation (TV) is deﬁned as any additional delay over NPD (introduced by parasitic capacitive) normalized by clock period as presented in Equation 1: T V = AP D − N P D Tclk = fclk (AP D − N P D) (1) Running hundreds of simulations on the developed circuit model with diﬀerent input data patterns, diﬀerent TVs are reported; concluding that TTCC factors are data dependent. In other words, the TTCC eﬀect on circuit timing is predictable by monitoring the data bit patterns fed into the TSVs, which is discussed in the following subsection. 3.2 TTCC Analysis The TTCC classiﬁcation is presented in this section is based on the severity of their parasitic capacitive factors. The parasitic capacitive value is a function of the charging and discharging of the victim TSV and its neighbors. Since between any two dies, the TSV drivers are all in one die and the loads are in the other die, the direction of the current in each TSV can specify the charging or discharging state. On the other hand, the current direction is data0.5 1 1.5 2 2.5 3 3.5 4 0 10 20 30 40 50 60 70 80 90 100 T i m i g n V i a o l i t n o ( % ) Frequency (GHz) 1C 2C 3C 4C 5C 6C 7C 8C (a) 0.5 1 1.5 2 2.5 3 3.5 4 0 5 10 15 20 25 30 35 40 T i m i g n V i a o l i t n o ( % ) TSV radius (µm) 1C 2C 3C 4C 5C 6C 7C 8C (b) 20 16 14 10 7 0 10 20 30 40 50 60 T i m i g n V i a o l i t n o ( % ) Technology (nm) 1C 2C 3C 4C 5C 6C 7C 8C (c) 20 40 60 80 100 120 140 0 10 20 30 40 50 60 T i m i g n V i a o l i t n o ( % ) Temperature (°C) 1C 2C 3C 4C 5C 6C 7C 8C (d) 0.8 1 1.5 2 2.5 3 3.5 4 0 10 20 30 40 50 60 70 80 90 100 T i m i g n V i a o l i t n o ( % ) TSV oxide thickness (µm) 1C 2C 3C 4C 5C 6C 7C 8C (e) Figure 3: Characterizing TTCC against various parameters dependent. Therefore, TTCC depends on the data pattern. This explanation conﬁrms our previous observation in which TTCC factors are data dependent. However, both the previous (Datai−1 ) and current (Datai ) data bit value of a TSV’s driver are needed in order to identify the current direction of each TSV. According to current direction detection process of a TSV in [14], there are three possible current directions for TSVs: Upward (⊗), Downward (⊙), and No-current (#). In the rest of this article, a TSV with No-current is called an inactive TSV, while a TSV with Downward/Upward current is called an active TSV. With these assumptions, the parasitic capacitive between a pair of TSVs is represented by 0C (if they both have the same current direction), 1C (if one of them is inactive and the other is active), 2C (if they have reverse current direction). The total capacitive coupling voltage on the victim TSV is equal to the sum of voltages coupled by each aggressor on the victim TSV. If an upward current is represented with Table 1: TTCC factor categorization Types 0C ⊙ ⊙ ⊙ ⊙ ⊙ 3 0.01 1C ⊙ ⊙ ⊙ ⊙ 2C ⊙ ⊙ ⊙ ⊙ ⊗ 44 0.18 3C ⊙ ⊙ ⊙ # ⊗ 64 0.26 4C ⊙ ⊙ ⊙ ⊗ ⊗ 54 0.22 5C 6C ⊗ ⊙ ⊙ ⊗ ⊗ 20 0.08 7C ⊗ # ⊙ ⊗ ⊗ 8 0.03 8C ⊗ ⊗ ⊙ ⊗ ⊗ 2 0.01 Sample pattern # # ⊙ ⊙ ⊗ ⊗ 32 0.13 Occurrence frequency Occurrence probability 16 0.07                                         n o i t l a o i V g n i m i T f o y t i l i b a b o r P 80% synthesis frequency 90% synthesis frequency 97% synthesis frequency 100% synthesis frequency blackscholes bodytrack canneal facesim ferret fluidanimate raytraces vips X264 PARSEC benchmark workloads 0.5 0.4 0.3 0.2 0.1 0 Figure 4: Probability of TV in PARSEC benchmark workloads under diﬀerent conditions (Table 2) +1, a downward current with -1 and no-current with 0, total TTCC can be quantiﬁed by Equation 2: T T CCtot = N X i=1 |dvic − daggi | (2) where T T CCtot is the total parasitic capacitive factor for each TSV, N represents the number of adjacent aggressors for a victim TSV, and d is the current direction for the corresponding TSV. The T T CCtot factors are used for categorizing parasitic capacitive types in this article as shown in Table 1. Figure 2 shows an example of current matrix generation and consequently TTCC factors on the victim TSV (the middle one), caused by its adjacent neighbors in a mesh of 3 × 3 TSVs. The T T CCtot value on the victim TSV for the given example in Figure 2 is equal to 5C. There are 35 = 243 possible TSV arrangements for 5 TSVs, one victim and four adjacent TSVs, with 3 possible current directions. In each of these arrangements the T T CCtot factor will be in range of 0C to 8C as discussed in Equation 2. The frequency and probability of occurrence of each of the T T CCtot factors are summarized in Table 1. For further illustration, a sample pattern resulting in the corresponding parasitic capacitive type is also shown in this table. The maximum capacitive coupling voltage on a victim TSV in this representation is equal to 8C if the middle TSV has reverse current direction as compared to all of its neighbors, shown in the right most column of Table 1. In addition, these capacitive coupling factors may disrupt timing requirement of 3D-NoC depending on the operational frequency and TSV physical parameters. We have characterized the eﬀect of TTCC for each of parasitic capacitive types presented in Table 1 using our circuit-level model. This characterization for a range of operational frequency and diﬀerent TSV parameters is elaborated in Figure 3. In Figure 3a, increasing clock frequency does not have tangible eﬀect on the TTCC severity, but TV is increasing linearly for larger operational frequencies. This is because timing requirement gets tight in higher frequencies. For TSVs with larger radius and the same pitch value, Csi will increase and therefore more capacitive coupling is observed, as shown in Figure 3b. As the technology advances, the loading voltage of the ﬂipﬂop over the TSV decreases, resulting in larger coupled voltage on the TSV (shown in Figure 3c). The permittivity of the silicon rises as a weak linear function of temperature [26], which increases Csi and consequently the TV, as depicted in Figure 3d. Finally, as shown in Figure 3e, thicker oxide provides better isolation and reduces the value of CT SV , producing less capacitive coupling and consequently less TV. 3.3 TTCC Effect on TV Having analyzed and modeled the TTCC, we have evaluated its eﬀect on realistic data traﬃc using PARSEC benchmark. This realistic data benchmark is transferred through the circuit-level model of 64 TSVs for various conﬁgurations. The TV values on the receiver side of each TSV is recorded. A conﬁguration is a set of physical parameters including TSV radius, length, pitch, oxide thickness, and process technology, operating frequency, and temperature. The conﬁguration values are selected in a way to cover different TTCC eﬀects. Figure 4 shows the probability of TV for PARSEC benchmark workloads for three diﬀerent TSV conﬁgurations (presented in Table 2). Each group of three bars in this ﬁgure from left to right refer to conﬁgurations A, B, and C in Table 2. In addition, the TV probabilities are reported for diﬀerent percentage of maximum synthesis frequencies. The results show that, the percentage of TV for lower synthesis frequency drops down for all workloads, however, an average of 40% TV at 100% synthesis frequency still conﬁrms the importance of TTCC analysis for TSV-based 3D-NoC architectures. Furthermore, the result of Figure 4 shows how TTCC limits the maximum operational frequency of 3D NoCs. The reason is that the propagation delay of TSVs are extended as an eﬀect of TTCC. In other words, the circuit is able to handle more percentage of TV with lower operational frequency.       die (0-2) TR: Timing Requirement APD:Actual Path De lay CCT: Clock Cycle Time TSVs Data i  Data i -1  TTCC fault model System-level simulation Current  direction (CD) matrix generator  Parasitic  coupling (PC )  matrix generator  Data out  Fault  activation Fail Top view of a TSV Substrate Pitch TTCC fault  model TSV diameter TSV 2 Depletion Insulator (ox) TSV Body(cu) TSV 1 Oxide thickness TSV pitch TSV diameter Technology Freuency TSV arrangement 9 sample input data Circuit level TSVmodel Driver Driver Output of circuit (fault library ) HT +ST 20ps 10ps C TSV/2 LTSV RTSV LTSV RTSV CTSV/2 Frequency 750MHz 1000MHz 750MHz 1000MHz Temperature 25 50 75 100 25 50 75 100 Fail case if APD > TR 8C 7C 8C 8C 7C 6C CTSV/2 CTSV/2 Load Load (a) Fault model location in IC simulator (b) Fault model Figure 5: Fault Model usage demonstration in 3D-NoC Table 2: Diﬀerent conﬁguration of TSV arrays Conﬁguration radius µm length nm pitch µm Tox µm Technology nm Max Freq. GH z Temperature ◦C A 3 15 9 3 20 1 50 B 3 20 9 2.5 16 1 75 C 2 25 6 1 10 1 100 4. TSV COUPLING FAULT MODEL Circuit-level simulation takes much longer than systemlevel simulation. A fault model is proposed in this paper that that can accurately assess TTCC faults. This approach considers the eﬀects of circuit-level representation of TTCC for a system-level platform to reduce simulation time while maintaining accuracy. This operation is performed at runtime by monitoring the data signals that are being transmitted through TSVs in order to identify where and when potential faulty TSVs occurred. Next these candidate faulty TSVs are triggered with the observed eﬀect at the circuitlevel of TTCC fault. Figure 5 shows the 3D-NoC framework and the proposed TTCC fault model. The fault model is envisioned to be employed as an intermediate component among TSVs connecting routers in diﬀerent dies, as shown in Figure 5a. This fault model does not aﬀect the functionality of 3D-NoC; it only decides the time and location of fault activation through the TSVs based on data input patterns and the provided fault library at the circuit level. Figure 5b depicts the functionality of our proposed fault model in details. The input parameters of our circuit-level model are TSV arrangement conﬁguration (Number of rows and columns) connected to 3D-NoC, operating frequency, process technology, silicon oxide thickness, TSV-to-TSV pitch, TSV length, and TSV diameter. The output of this model is a table, which shows the corresponding parasitic capacitive factors violating the timing requirements for each conﬁguration. An example of the fault library table is shown in Figure 5b. This output is used as a fault library in our system-level simulation, in which the parasitic capacitive factors are extracted by comparing the transmitted (Datai−1 ) and ready to transmit (Datai ) data bits through TSVs. With this conﬁguration the TTCC fault model decides intelligently and accurately when and where a TTCC fault should be activated. The steps of this methodology are as follows: • Step.0 Conﬁguration and Setup: Prior to instantiating and utilizing the devised TTCC fault model, ﬁrst it needs to be conﬁgured and setup. In this phase, input parameters of the model such as the TSV length, TSV diameter, TSV pitch, oxide thickness of TSVs, process technology, frequency, and temperature are speciﬁed. Frequency and temperature parameters are deﬁned as a range with a speciﬁc granularity to support dynamic changes at runtime. The other inputs of the circuit-level model is all the possible data inputs resulting in 9 parasitic capacitive factors from 0C to 8C. • Step.1 Capturing transferred data: In this step, the data bits transferring through TSV links (Up/Down port) are captured as the input of fault model at run-time. These captured data bits are adjusted if the fault activation condition is met. • Step.2 Data analysis to determine the TSV current directions: At this step, the current directions of all TSVs are identiﬁed. The previous (Datai−1 ) and current (Datai ) data-bit values of a TSV’s driver are proﬁled and compared in order to recognize the current direction of each TSV. This process is done with the same approach as discussed in [14]. The output of this stage is stored as Current Direction (CD) matrix. • Step.3 Determine the induced capacitive coupling case for each TSV: Looking at the current direction of each TSV and its adjacent neighbors, in this step an appropriate capacitive case is assigned per TSV. Now the fault library generated at pre-runtime is used to look up the timing delay associated for the corresponding case and is recorded as Parasitic Coupling (PC) matrix. • Step.4 Map circuit-level faults to system level delay fault/failure for each TSV: Considering the timing requirement parameter of the destination receiver ﬂip-ﬂop Table 3: System conﬁguration parameters Parameter Value Topology 3D fully connected Mesh Network Size (4x4x4) 64 Routers Flit Size 32 bits Buﬀer Depth 8, 16-bit entries per port Switching Scheme Wormhole Routing Algorithm Dimension Ordered Routing Simulator THENoC [28] (input buﬀer of receiver router), at this point, using PC matrix, the decision for faulty TSVs is made and an appropriate fault is applied to the detected faulty TSVs. If the reported timing delay associated with the capacitive case violates the timing requirement of the receiver logic, then the data bit is assumed faulty. The fault type, depending on the speciﬁed delay tolerance for the circuit, can be either a ) % ( e a t r n o i t a o l i V g n i m i T 20 15 10 5 0 Configuration A Configuration B Configuration C bodytrack canneal vips ferret raytraces fluidanimate x264 PARSEC benchmark workloads Figure 7: Fault Model usage demonstration in 3D-NoC running PARSEC benchmark under diﬀerent conditions (Table 2) 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Layer 3 − Down port Layer 2 − Up port Layer 2 − Down port Layer 1 − Up port Layer 1 − Down port Layer 0 − Up port Figure 8: Fault Density Map and low TSV oxide thickness which exasperate the TTCC. As the conﬁguration parameter values get relaxed, the TV due to TTCC also decreases accordingly. TTCC fault density map for the 4 × 4 × 4 simulated network with Canneal workload traﬃc is depicted in Figure 8. This ﬁgure illustrates 4 × 4 NoC routers of a speciﬁc layer sending data to their lower/upper layer routers (Down port /Up port ). The values are normalized to the maximum number of TV in entire 3D-NoC. The layer 0 down port and layer 3 up port are not shown since they do not exist. With this map designers can have better knowledge of placing their resiliency methods for an speciﬁc application. It can be seen that the data transactions from layer 2 downward layer 1 cause a large number of TTCC faults. 5.4 TTCC Fault Characterization with Resilient Approach In order to show the advantage of our coupling fault model for fault-tolerant NoC designers, we model a simple inversion y c n e u q e r f . p a c c i t i s a r a p C 7 & C 8 3500 3000 2500 2000 1500 1000 500 0 32 Uncoded FA method 48 64 NoC router bandwidth (TSVs) 128 256 Figure 9: Number of 7C/8C for random data bit patterns in small mesh of TSVs technique to avoid the most aggressive capacitive coupling cases, 7C and 8C, in each NoC router. State-of-the-art research in 3D-NoC design has explored various TTCC fault mitigation approaches to protect fault-prone TSVs. The basic idea of this method is to modify the conﬁguration of sequential data bits feeding TSVs by a light encoding approach. The inversion operation is chosen as a simple but light and eﬃcient practical coding method in this experiment in order to keep the overhead low, while mitigating parasitic capacitive factors. This is a popular Fault Avoidance (FA) approach in order to mitigate both inductive and capacitive coupling eﬀects in 3D-NoC designs [14, 20]. In this method two consecutive data bit values which are transferred through a single TSV link are examined to report the generated parasitic capacitive factors in a mesh of TSVs of NoC router as discussed in Section 3.2. Each row of 2D array of TSVs including 8C or 7C parasitic capacitive factors is nominated for the data encoding process. By encoding the ready to transmit data bits, 8C parasitic capacitance will be 4C and 7C parasitic capacitance will be 1C or 2C. Figure 9 shows the number of 8C and 7C parasitic capacitance fault frequency before and after applying FA coding method between two vertically adjacent routers in a 3D NoC. We repeat the experiment for diﬀerent router port bandwidth, ranging from 32 to 256, using uniform random synthetic traﬃc. The observation results of our proposed TTCC fault model after applying FA technique, results in a considerable reduction in the number of coupling faults. 6. CONCLUSIONS A TSV-to-TSV capacitive coupling fault model was presented which can be easily deployed in system-level 3DNoC simulators to detect the TSV-to-TSV capacitive coupling fault at runtime as part of any dynamic fault injection process. Our model facilitates the exploration of resilient TSV-based 3D-NoCs and help researchers accurately evaluate their 3D systems when dealing with TSV capacitive coupling. The core of our fault model is implemented at the circuit-level to collect accurate timing violations for each of parasitic capacitive cases, although the interface is implemented at the system-level. This model is useful for both application-speciﬁc and general purpose designs. For application speciﬁc designs our fault models reports the susceptible to failure TSVs. For general purpose applications it can                     be applied to optimize the physical parameters of TSV to reduce the propagation delay of TSVs caused by TTCC. 7. "
On-Chip Decentralized Routers with Balanced Pipelines for Avoiding Interconnect Bottleneck.,"Technology scaling makes designers face difficulties dealing with wire delay of long global interconnects, especially for high-radix networks. In this context, we propose decentralization of on-chip packet routers. A decentralized router consists of submodules, each of which has particular functionality and they are scattered on a link, thereby long wires are segmented. Our starting point is from a conventional router architecture, and we illustrate four case studies to generalize our proposal. We also propose a new buffer design and how to balance pipelines of a router. A proof-of-concept is shown in 28-nm process technology. Our results demonstrate that the decentralization of an on-chip router enables Link Traversal (LT) stages to be eliminated, and the critical path delay is improved by up to 45% with the reduced area compared with a conventional router. As technology advances, the benefit of the decentralized routers become more substantial in the nano-scale era.","RC logic Arbiter VC Input channel Output channel Crossbar Switch TRC=max(Gﬁfowr , Grc ), TVSA=Garb , TST=Gﬁford + Gcb , TLT=Wlink , T G W T Trouter Trouter=max(TRC , TVSA , TST , TLT ). m n m n m n Submodule A RC logic State machine VC (Submodule C of prev. router) Segment c request / grant Submodule C Arbiter Submodule B State machine VC Output channel Segment a Segment b Crossbar Switch TRC=max(Gﬁfowr , Grc ) + Wsegmenta , TVSA=max(Gﬁfowr , Garb + 2Wsegmentb ), TST=Wsegmentb + Gﬁford + Gcb + Wsegmentc , Wsegment Wsegmenta +Wsegmentb +Wsegmentc = Wlink TVSA 2Wsegmentb n − 1 n n 1-bit Data     from prev. router 1 flit Back pressure from arbiter 1 2 3 4 5 Buffer delay(e.g. 2 cycles) Column number Gbuﬀer Tdata C T TVSA TST TRC=Grc + Wsegmenta , TVSA=Garb + Wsegmentb , TST=Gcb + Wsegmentc . Wsegmentb Wsegmentb Tdata≈Gbuﬀer + Wlink C . Tdata TRS=Grs + Wsegmentd . Wsegmentd (Submodule C of prev. router) Segment c Control path Submodule A RC logic State machine Segment a Submodule B State machine Segment b request Submodule C Arbiter back pressure Data path VC(1 flit) Input channel multiple request selected request Selection function grant Arbiter Output channel Crossbar Switch Grc Gﬁfowr Grs Garb Gﬁford Gcb Gbuﬀer selected request request Submodule B Submodule C Selection function is inserted here multiple request Submodule D Submodule A TRS=Grs + 2Wsegmentd + Wsegmentb . Grc Garb Gﬁfowd Gﬁford Gcb Gbuﬀer ] s n [ l y a e d e r i w d e t a e p e R  2  1.5  1  0.5  0  1  2 Manhattan distance  3 2n × 2n × × 2n − 1 TRC=max(Gﬁfowr , Grc ) = 0.34 ns, TVSA=Garb = 0.92 ns, TST=Gﬁford + Gcb = 0.62 ns, 0.63 ns (M = 1) 1.14 ns (M = 2) 1.67 ns (M = 3). TLT=⎧⎪⎨⎪⎩ M M TRC=0.27 ns + Wsegmenta , TVSA=0.92 ns + Wsegmentb , TST=0.44 ns + Wsegmentc , Tdata≈0.21 ns + 0.52 ns 0.78 ns 1.04 ns 2 (M = 1) (M = 2) (M = 3). Wlink =⎧⎪⎨⎪⎩ Wsegmenta Wsegmentb TST Wsegmentc TRC TVSA • • • • Wsegmenta Wlink TRC TST Wsegmenta = Wsegmenta Wlink Wsegmenta Wsegmentc Wlink (Wsegmenta +Wsegmentc ) Wsegmentc + Wlink − M = 1 M = 2 TRC≈0.27 ns + 0.653 ns = 0.923 ns, TVSA≈0.92 ns + 0.003 ns = 0.923 ns, TST≈0.44 ns + 0.483 ns = 0.923 ns. M = 3 TRC≈0.27 ns + 0.83 ns = 1.10 ns, TVSA≈0.92 ns + 0.18 ns = 1.10 ns, TST≈0.44 ns + 0.66 ns = 1.10 ns. TVSA TVSA=Garb = 1.45 ns. TRC≈⎧⎪⎨⎪⎩ 0.27 ns + 0.63 ns = 0.90 ns 0.27 ns + 1.14 ns = 1.41 ns 0.27 ns + 1.18 ns = 1.45 ns TVSA≈%1.45 ns + 0.00 ns = 1.45 ns TST≈&0.44 ns + 0.00 ns = 0.44 ns 0.44 ns + 0.49 ns = 0.93 ns TVSA M (M = 1) (M = 2) (M = 3), (M ≤ 3), (M ≤ 2) (M = 3). M       TRS=Grs = 0.38 ns. 0.92 ns TRC=0.27 ns + Wsegmenta , TRS=Grs = 0.38 ns + Wsegmentd , TVSA=0.92 ns + Wsegmentb , TST=0.44 ns + Wsegmentc , Tdata≈0.21 ns + 0.42 ns 0.59 ns 0.77 ns 3 (M = 1) (M = 2) (M = 3). Wlink =⎧⎪⎨⎪⎩ TRS Wsegmentd Wsegmentd TRS≈⎧⎪⎨⎪⎩ TRC≈&0.27 ns + 0.63 ns = 0.90 ns 0.27 ns + 0.65 ns = 0.92 ns 0.38 ns + 0.00 ns = 0.38 ns 0.38 ns + 0.49 ns = 0.87 ns 0.38 ns + 0.54 ns = 0.92 ns TVSA≈%0.92 ns + 0.00 ns = 0.92 ns TST≈&0.44 ns + 0.00 ns = 0.44 ns 0.44 ns + 0.48 ns = 0.92 ns 0.92 ns Wsegmentb M (M = 1) (M ≥ 2), (M = 1) (M = 2) (M = 3), (M ≤ 3), (M ≤ 2) (M = 3). ] % [ e a t r t n e m e v o r p m I  50  40  30  20  10  0 Simple Many VCs Partially adaptive Fully adaptive  1  2 Manhattan distance  3 TRS≈ 0.27 ns + 0.63 ns = 0.90 ns 0.27 ns + 0.65 ns = 0.92 ns 0.27 ns + 0.793 ns = 1.063 ns 0.70 ns + 2 × 0.00 ns + 0.00 ns = 0.70 ns 0.70 ns + 2 × 0.11 ns + 0.00 ns = 0.92 ns 0.70 ns + 2 × 0.11 ns + 0.14 ns = 1.06 ns TVSA≈&0.92 ns + 0.00 ns = 0.92 ns 0.92 ns + 0.143 ns = 1.063 ns 0.44 ns + 0.00 ns = 0.44 ns 0.44 ns + 0.38 ns = 0.82 ns 0.44 ns + 0.623 ns = 1.063 ns TRC≈⎧⎪⎨⎪⎩ ⎧⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎩ TST≈⎧⎪⎨⎪⎩ (M = 1) (M = 2) (M = 3), (M = 1) (M = 2) (M = 3), (M ≤ 2) (M = 3), (M = 1) (M = 2) (M = 3). M TRS=Grs = 0.70 ns. TRS TRS=0.70 ns + 2Wsegmentd + Wsegmentb . TRS Wsegmentd Wsegmentd • Wsegmentd GVSA Wsegmentd M     ) d e z i l a m r o N ( a e r A l a t o T  1.2  1  0.8  0.6  0.4  0.2  0 Input buffers Baseline Naive Proposed     "
Asymmetric NoC Architectures for GPU Systems.,"While both Chip MultiProcessors (CMPs) and Graphics Processing Units (GPUs) are many-core systems, they exhibit different memory access patterns. CMPs execute threads in parallel, where threads communicate and synchronize through the memory hierarchy (without any coalescing). GPUs on the other hand execute a large number of independent thread blocks and their accesses to memory are frequent and coalesced, resulting in a completely different access pattern.
NoC designs for GPUs have not been extensively explored. In this paper, we first evaluate several NoC designs for GPUs to determine the most power/performance efficient NoCs. To improve NoC energy efficiency, we explore an asymmetric NoC design tailored for a GPU's memory access pattern, providing one network for L1-to-L2 communication and a second for L2-to-L1 traffic. Our analysis shows that an asymmetric multi-network Cmesh provides the most energy-efficient communication fabric for our target GPU system.","Asymmetric NoC Architectures for GPU Systems Amir Kavyan Ziabari† , José L. Abellán ‡ , Yenai Ma to execute one independent block of threads (i.e., a workgroup) at a time. Work-groups consist of multiple wavefronts (consisting of 64 threads or work-items). Each CU can execute an entire wave-front in 4 cycles. Each wave-front can start execution on the SIMD pipelines of the compute unit. Execution begins as soon as data becomes available in the memory hierarchy. Each CU is equipped with a Load-Data-Share (LDS) unit as local memory. CUs are connected individually to the global memory hierarchy through two cache units; a L1 vector data cache (vL1) unit and a read-only L1 scalar data cache (sL1) unit. The global memory hierarchy also consists of L2 cache units. Each L2 cache unit is coupled with only one memory controller that can access a unique memory address range. This distribution of address ranges across the L2 banks reduces the load on any single memory controller, while exploiting spatial locality [3]. We explore the design space of a NoC that connects the scalar and vector L1 data cache units to L2 cache banks. There are two types of messages that is transmitted between the L1 and L2 cache units in the memory hierarchy. The ﬁrst type is an 8-byte control message. This control message contains information speciﬁc to cache requests (reads, writes, invalidation, etc.), and the address of the destination cache unit. The second type is a 72-byte message, which includes an 8-byte control message and a 64-byte cache line. For any channel with a bandwidth smaller than 72 bytes, the control message will be transferred in a separate cycle ﬁrst, and the cache line is packeted and transferred immediately in the following cycles. For example, if we use a 32-byte channel to transmit a 72-byte message, then we will use the ﬁrst cycle to transmit the 8-byte control message, and then the next 2 cycles to transmit the 64-byte cache line. 2.2 Evaluation Methodology To evaluate the NoC for a GPU system, we used the Multi2sim 4.2 simulation framework [22]. We evaluated the crossbar, mesh, concentrated mesh (Cmesh), butterﬂy, concentrated crossbar, and Clos topologies. Our NoC designs utilize state-of-the-art single-cycle routers, with the extra required lookahead signals embedded in the 8-byte control messages (see Section 2.1), which are transferred to the cache units [20]. The routers in the designs operate at 1 GH z frequency. Table 2 provides the set of applications used in our evaluation. These applications are taken from the AMD APP SDK [1]. The benchmarks represent a wide range of workload sizes, bandwidth demands, and memory intensities (URNG is a compute-intensive application, CONV and DCT have very large workloads and high memory intensity. FWT includes irregular access patterns). The power of the NoC is estimated using a detailed transistorTable 1: AMD Radeon HD 7970 GPU speciﬁcation. Processor Cores Memory System Fabrication process Clock Frequency Compute Units MSHR per Compute Unit SIMD Width Threads per Core Wavefront Size 28nm Size of L1 Vector Cache 925 Size of L1 Scalar Cache 32 L2 Caches/Mem. Cntrls. 16 Block Size 16 Size of L2 Cache 256 Memory Page Size 64 LDS Size 16K 16K 6 64B 128K 4K 64K Table 2: Workloads from the AMD APP SDK. Abbreviation Application CONV DCT DWTHAAR FWSHALL FWT HIST MATMUL MT RED RG SOBEL URNG Simple Convolution Discrete Cosine Transforms One-dimensional Haar Wavelet Transform Floyd-Warshall Shortest Path Calculation Fast Walsh Transfrom Histogram Matrix Multiplication Matrix Transpose Reduction Recursive Gaussian Filter Sobel Edge Detection Algorithm Uniform Random Noise Generator level circuit modeling, the physical layout, the ﬂow control mechanism and network traﬃc workloads. The wires in the crossbar, butterﬂy and clos topologies are designed to be implemented in the global metal layers using pipelining and repeater insertion in 28 nm Predictive Technology Models [2]. All of inter-router channels in all of the mesh-based topologies are implemented in the semi-global metal layers using standard repeater wires. The power dissipated in the SRAM array and crossbar of the routers is calculated by adapting the methodology described in [15] and [24], respectively. 3. SYMMETRIC NOC DESIGNS FOR GPUS In this section we explore the trade-oﬀs associated with various NoC topologies that can be used for interconnection between the cache units in the GPU memory hierarchy. We analyze a crossbar, a mesh, a concentrated mesh (Cmesh), a Butterﬂy, a concentrated crossbar, and a Clos network (see Figure 1), to cover the entire spectrum from high-diameter, low-radix networks, to low-diameter, high-radix networks at the other end. Table 3 includes the key architecture parameters of these NoC topologies. The bisectional bandwidth is matched across all topologies for a fair comparison of performance of network topologies. The ﬁrst topology considered is the well-known global crossbar. The global crossbar is generally considered to be the most eﬃcient network topology in terms of programmability. A 46 × 46 global crossbar is considered to provide all-toall connectivity between the 40 L1 (8 scalar and 32 vector) cache units and 6 L2 cache units. A crossbar provides nonblocking connectivity between each pair of nodes, but the crossbar design is very challenging to layout. Since a crossbar requires a large number of global buses across the length of the chip, this can lead to signiﬁcant power consumption in the wires. Crossbars also require global arbitration, which can add signiﬁcant latency and power dissipation. We place the arbiter in the center of the chip to minimize the arbitration overhead [18]. Figure 1(a) shows a 2D 8 × 5 mesh network. In Southern Island GPUs, each CU is connected to a single vector cache unit and a group of four CUs share a single scalar unit. The number of nodes along each dimension of the mesh is chosen based on this adjacency of the cache units. The diagonal placement [19] is considered for the L2 cache banks to minimize the average packet latency and request-response variance. The mesh design utilizes the X-Y routing and distributed ﬂow control [23]. The high hop count in the mesh, however, results in long latencies and high energy consumption in both routers and channels. The hop count of a mesh network could be reduced if Figure 1: Topologies of the NoCs evalutated for the 32-CU GPU: (a) a 2D 8x5 mesh, (b) a concentrated mesh (Cmesh) with 5x and 6x concentration, (c) a 6-ary, 3-stage, Clos network with 8 intermediate routers, (d) a concentrated tri-state global crossbar (C-crossbar), (e) a 6-ary 4-ﬂy butterﬂy. In all of our ﬁgures: dots = routers, triangles = tristate buﬀers. In (a) and (b) inter-dot lines = bi-direction channels. In (c), (d) and (e) inter-dot lines = uni-directional channels. In (c), (d) and (e) the source and destination nodes are separated for the clarity, otherwise the number of cache units are the same as (a) and (b). In (c) nodes are connected to the concentration switch by bi-directional channels. Table 3: Network Conﬁguration - Networks are sized to support two types of messages that create the GPU traﬃc. NC = number of channels, bC = bits/channel, NBC = number of bisection channels, NR = number of routers, H = number of hops along data path, TR = router latency, TGR = average latency of global connections (if used), TC = channel latency, TT C = latency from cache units to the concentration switch, TS = serialization latency, T0 = zero-load latency. Both types of messages are considered in the latency calculations. The latency values are separated by ”,”. Channels Topology Butterﬂy Clos C-crossbar Cmesh Crossbar Mesh NC 48 128 8 20 46 134 bC 32 × 8 8 × 8 32 × 8 72 × 8 8 × 8 32 × 8 Routers NBC NBC · bC NR Common Radix 2 × 2 8 2048 32 8 × 8 64 4096 24 8 × 8 8 2048 16 9 × 9 4 2304 8 46 × 46 46 2944 1 5 × 5 10 2560 40 Latency H 4 3 3 1 – 5 1 2 – 12 TR 1 1 1 1 n/a 1 TGR (avg) n/a 2 4 n/a 4 n/a TC 1 n/a n/a 1 n/a 1 TT C 1, 3 1, 9 1, 3 1 0 0 TS 0, 2 0, 8 0,2 0 0,8 0,2 T0 9, 19 8, 36 8, 15 3 – 11 5, 13 5 – 51 concentration is used to combine the traﬃc of multiple cache units at one router and reduce the diameter of the network [6]. This reduces load imbalance across the channels without increasing wiring complexity. Figure 1(b) illustrates a Cmesh for the GPU architecture. Here four neighboring CUs in the AMD Radeon 7970 HD GPU layout are concentrated on a single concentration switch [17]. Concentrated crossbars (C-crossbar) and Clos networks are intermediate points between the conventional high-radix, low-diameter, crossbar topology and the low-radix, highdiameter, mesh topology. Figure 1(c) and 1(d) illustrate the two topologies that utilize the concentration of the neighboring cache units to reduce the required wiring. However, this leads to high-radix routers. Both designs have lower hop counts in comparison to mesh topologies, but require longer point-to-point channels. The Clos network is reconﬁgurably non-blocking. Similar to the crossbar, for C-crossbar design, we pipelined point-to-point channels to improve throughput and placed the arbiter in the center of the chip. We also considered a conventional 6-ary 4-ﬂy butterﬂy in this study, as shown in Figure 1(e). A conventional butterﬂy has no path diversity (and therefore no load-balancing in the network) as compared to a ﬂattened butterﬂy [12], but requires low-radix routers. We favor the conventional butterﬂy over a ﬂattened butterﬂy, since one side of each communication is typically a L2 cache unit. Since the L2 cache units are partitioned the network load becomes balanced (see Section 4 for more details). Figure 2 presents a comparison of the various NoC designs for the targeted GPU architecture in terms of performance, power and energy-delay-product (EDP) metrics. We normalized the performance of the GPU with diﬀerent NoCs for each application using an ideal NoC with a ﬁxed 3-cycle latency. The 3-cycle latency is the lowest latency we can have in our design, which is the minimum zero-load latency of the Cmesh. As shown in Figure 2(a), the mesh, Cmesh and butterﬂy NoCs exhibit comparable performance across all the applications. The highest performance is achieved by a Cmesh network. On average, the performance of the Cmesh is 0.71% the ideal network, while the mesh and butterﬂy both achieve a performance (on average) equal to 0.69% of an ideal network. As mentioned in Section 2, wavefronts of a work-group that reside in a single CU can start their execution as soon as their data becomes available through the memory hierarchy. The latency associated with retrieving the required data will determine the start of execution of the wavefront. Since L2 caches in the GPU architecture are partitioned, the required is directly correlated with the ﬂit size, which in this case is 72 bytes. Clos has the lowest performance in comparison with other topologies (16% of an ideal network – Figure 2(a)), and hence it exhibits the lowest dynamic power consumption compared to all other topologies. While Clos uses routers with the same radix as a C-crossbar, it is designed with the lowest channel width (8 Bytes). Moreover, in a Clos layout, we placed all the middle-stage routers together in the center of the chip to provide shorter global channels, which in turn results in lower power consumption, as suggested in [10]. Figure 2(c) shows an overall comparison of all the topologies using the EDP metric, which jointly accounts for changes in performance and energy. We have normalized the EDP of each design based on the EDP of the Clos, which has the highest EDP among all the network topologies which we evaluated. As shown in the ﬁgure, a butterﬂy network achieves the lowest EDP across all the applications (0.10% of the EDP of the Clos, averaged across all the benchmarks). The mesh and Cmesh are the next best topologies that exhibit low EDP, 0.12% and 0.31% the EDP of the Clos, respectively. In the next section, we propose asymmetric NoC architectures (designed based on application analysis) and we use the butterﬂy, mesh and Cmesh networks topologies for evaluating the asymmetric NoCs. 4. ASYMMETRIC NOC DESIGN FOR GPU In the previous section we compared the use of diﬀerent NoC topologies for our target system while running a variety of the applications. In this section, we analyze the trends in OpenCL applications and optimize the NoC design based on the traﬃc pattern exhibited by these applications. As mentioned in Section 1, the OpenCL data parallel programming model achieves scalable performance through independent execution of work-groups. Applications written in OpenCL exhibit unique memory access patterns, and hence the NoC can be designed based on these expected memory access patterns to maximize the NoC energy eﬃciency. The amount of communication between cores (L1-to-L1) in a GPU is limited. This limited communication includes interaction due to false-sharing (where two cores share diﬀerent sub-blocks of the cache-lines), and limited cache coherency signals (if any), which are enforced by the AMD’s relaxed consistency model [3, 22]. At the same time, the latency of L1-to-L2 traﬃc is typically not critical, as the GPU programming model enforces that no other CU should be stalled awaiting completion of a write-back transfer. Moreover, GPU workloads exhibit lighter traﬃc for L1-to-L2 accesses due to architectural enhancements such as coalescing. Figure 3 breaks down the percentage of diﬀerent types of communication between the cache units (L1-to-L1, L1-to-L2, and L2-to-L1) for our selected applications. We consider the knowledge of the expected network traﬃc, and the results presented in Figure 3, to enhance our NoC design. As a ﬁrst step for shaping our proposed topologies, we consider two separate networks, one for each direction of the communication, i.e., L1 to L2 and L2 to L1. We consider this strategy for two reasons: 1) We can improve the performance of both networks in terms of latency by restricting the traﬃc to one direction 2) We can design asymmetric networks optimized for the direction with heavier load and higher delay sensitivity. As a second step, we eliminate the paths between the L1 cache units and replace any L1-to-L1 communication with a (a) Performance Comparison of various NoC designs (b) Power breakdown of various NoC design (c) Energy-per-Delay Product of various NoC Designs Figure 2: Evaluation of Performance and Power for a GPU with various NoC designs using AMD APP SDK benchmarks. The performance is normalized to an ideal network with 3-cycle latency. data for the wavefronts may reside in a number of L2 units (and not just a single). Any network that combines the traﬃc of L1s toward L2s (and vice versa) can hurt the performance of, not a single, but multiple CUs. Because the mesh, Cmesh, and butterﬂy NoCs provide diverse paths between L1s and individual L2s, they lead to higher utilization of the CU. On the other hand, the Crossbar, Clos and C-Crossbar, which at some point combine the traﬃc to/from the L2s, achieve lower performance. Figure 2(b) illustrates the power breakdown of the diﬀerent NoC topologies. Among these topologies, Cmesh has the highest static and dynamic power consumption. The highest static power can be attributed to the fact that Cmesh has the widest channel width (72 bytes) and it has high-radix routers. The power dissipated by the wires in the 72-byte links is the source of this high power dissipation. At the same time, the power consumed by the router’s crossbar is large since power Table 4: Bisection bandwidth for symmetric and asymmetric designs of target topologies, i.e., butterﬂy, mesh, and Cmesh. L1-to-L2 L2-to-L1 Topology bC ButterﬂyX2-sym 22 × 8 ButterﬂyX2-asym 16 × 8 22 × 8 MeshX2-sym 16 × 8 MeshX2-asym 32 × 8 CmeshX2-sym 22 × 8 CmeshX2-asym NBC 6 6 10 10 4 4 bC 22 × 8 22 × 8 22 × 8 22 × 8 32 × 8 32 × 8 NBC 6 6 6 6 4 4 Bisection Bandwidth NBC · bC 2112 1824 2816 2336 2048 1728 Based on these modiﬁcations, channel widths (see Table 4) are calculated using the bisection bandwidth criteria for the same network throughput as used in previous designs. For each baseline topology, two variations of the NoCs have been proposed; symmetric and asymmetric. The diﬀerence between these variations is in the channel width. In the symmetric designs, channel width of the L1-to-L2 and L2-to-L1 networks are the same. In the asymmetric designs, channels in the L1-to-L2 networks are chosen to be narrower since, as explained earlier, the L1-to-L2 communication latency has minimal eﬀect on the overall system performance. The traﬃc in the L1-to-L2 direction is also lighter, as shown in Figure 3. Overall we propose and analyze 6 diﬀerent networks for the GPUs; MeshX2-sym, MeshX2-asym, ButterﬂyX2-sym, ButterﬂyX2-asym, CmeshX2-sym, and CmeshX2-asym. All of our proposed designs for mesh and Cmesh (MeshX2-sym, MeshX2-asym, CmeshX2-sym and CmeshX2-asym) use X-Y Routing. In the MeshX2-sym and MeshX2-asym designs, the links in the ﬁrst and last row are unutilized because the L2 caches are placed diagonally in the center of the mesh. An example of the routing is shown in the Figure 4(b). As can be seen (and generalized), the messages from L2 never use the links in the last (and the ﬁrst) row of these mesh-based designs. By removing these links, we reduce both static power consumption in the NoC and the number of bisectional links. The Cmesh-based designs (CmeshX2sym and CmeshX2-asym) have the same logical organization as the baseline Cmesh (introduced in Section 3) for both directions, i.e. L1-to-L2 and L2-to-L1. The L1-to-L2 and L2to-L1 networks in a butterﬂy-based design (ButterﬂyX2-sym and ButterﬂyX2-asym) are slightly diﬀerent as compared to the baseline butterﬂy (introduced in Section 3). Since the number of L2s is 6, the last stage of the butterﬂy is modiﬁed (two routers are removed) to accommodate for this variation. Figure 5 presents the performance of the proposed topologies, normalized to the respective baseline designs, i.e., butterﬂy, mesh and Cmesh. In Figure 5(a), the performance of the ButterﬂyX2-sym and ButterﬂyX2-asym is compared with the baseline butterﬂy NoC, as shown in Section 3. Both the ButterﬂyX2-sym and ButterﬂyX2-asym designs provide similar relative performance (92% and 91% as compared to the Butterﬂy network, respectively). This is while the asymmetric design (ButterﬂyX2-asym) has a smaller number of bisectional wires in the layout (as shown in Table 4). Figure 5(b) compares the performance of our proposed MeshX2-sym and MeshX2-asym designs with a conventional mesh design. The MeshX2-sym and MeshX2-asym designs provide similar performance (93% and 92% relative to the baseline mesh, respectively) while the L1-to-L2 links are narrower in the MeshX2-asym. The main reason for this slight performance loss in both ButterﬂyX2 and MeshX2 designs (symmetric Figure 3: Breakdown of the diﬀerent types of communications between cache units. Figure 4: (a) The L1-to-L2 network for MeshX2, (b) The L2-to-L1 network for MeshX2. The use of X-Y routing leads to several unused links. These links were removed to reduce the static power consumption and switch radices, (c) The network for both direction in a ButterﬂyX2. Since the number of L2s is limited to 6, the design uses two less routers and wider bisection channels than the conventional butterﬂy. L1-to-L2 transfer followed by a L2-to-L1 transfer. While this slightly increases the traﬃc between the L1-to-L2 and the L2-to-L1, it allows us to reduce the power consumption in the network. This reduction in power is due to lowering of the number of physical links and router radix. For example, in the L1-to-L2 network in Cmesh, 5 L1s and one L2 (in 6 out of 8 routers) are connected to each concentration switch unidirectionally instead of bidirectionally, which leads to a reduction in the number of wires (32 × 8 wires are eliminated for each. Links also become unidirectional – 1280 wires per concentration switch). We also see a reduction in the router radix, from 10 × 10 (or 9 × 9) to 8 × 4 (or 7 × 4). Based on these considerations, we propose using parallel networks, one for L1-to-L2 communication and one for L2to-L1 communication. We eliminate the links that create paths between the L1 units. The new parallel designs for the mesh (MeshX2) and the butterﬂy (ButterﬂyX2) networks are shown in Figure 4. The CmeshX2 design uses two parallel Cmesh networks, similar to the design presented in Section 3, with the link and router radix reductions, as discussed above. (a) Speedup of asymmetric and symmetric ButterﬂyX2 against the baseline butterﬂy. (b) Speedup of asymmetric and symetric MeshX2 against Mesh (c) Speedup of asymmetric and symetric CmeshX2 against Cmesh Figure 5: Performance comparison of various parallel designs against baseline NoCs. and asymmetric) is due to the lower channel width, which results in more serialization delay for access to the cache. However, this performance degradation is compensated by the reduction in congestion (resulting from using two separate networks for the L1-to-L2 and the L2-to-L1 communication). We present the speedup achieved by CmeshX2-sym and CmeshX2-asym as compared to the baseline Cmesh network in Figure 5(c). In both of our proposed designs the performance is almost equal to the baseline Cmesh network (99% and 97% of baseline performance), while the channel width is half of the channel width of the baseline Cmesh. The main reasons why we can obtain similar performance is due to a reduction in arbitration latency (CmeshX2 networks have switches with lower radices, since the connection between concentration switch and injecting nodes are unidirectional), and routing the L1-to-L2 and L2-to-L1 traﬃc on two diﬀerent physical networks. Figure 6 shows a comparison of conventional, symmetric and asymmetric NoCs, in terms of power consumption. The ButterﬂyX2-sym and ButterﬂyX2-asym designs do not exhibit signiﬁcant power reduction in comparison to the baseline butterﬂy network (18% and 25% power reduction on average for symmetric and asymmetric design, respectively) because the reduction in power, due to reduction in channel width, has been mostly compensated by the increase in the Figure 6: Dynamic and Static power breakdown for various parallel symmetric and asymmetric designs. number of low-radix routers. The MeshX2-sym and MeshX2-asym designs dissipate 35% and 44% less static power than the baseline mesh, respectively. This is due to the narrower bandwidth and lower channel counts of our MeshX2 designs, versus the higher component count of the mesh. While the router count is doubled in the design, most of these routers have low radices. The total power savings achieved by the MeshX2-sym and MeshX2asym design are 30% and 37% on average in comparison to baseline mesh, respectively. The largest power savings are observed when using parallel asymmetric CmeshX2 (CmeshX2-asym) and symmetric CmeshX2 (CmeshX2-sym). The CmeshX2-asym dissipates 69% less power, in comparison to the baseline concentrated mesh, while the CmeshX2-asym dissipates 65% lower power. This signiﬁcant reduction in power is directly related to the narrowing of the channel width. The EDP for each application is calculated based on the execution time of the application and energy consumed by this NoC during execution. Even though the proposed NoC designs have slightly lower performance on average in comparison to the baseline designs, they exhibit larger power savings that result in lower EDP than the baseline topologies. As shown in Figure 7(a), The ButterﬂyX2-asym has 7% lower EDP on average (lowest EDP among the butterﬂy designs) as compared to baseline butterﬂy network In Figure 7(b), the EDP of the proposed MeshX2 designs (MeshX2-sym and MeshX2-asym) is compared with the EDP for the baseline mesh network. We see signiﬁcant power savings with the MeshX2-asym, while achieving comparable performance to the baseline mesh. This leads to a 72% reduction in EDP, as compared against the baseline. The signiﬁcant power savings and comparable performance provided by the CmeshX2-asym (a) EDP comparison of proposed ButterﬂyX2-sym and ButterﬂyX2-asym against the baseline butterﬂy. (b) EDP comparison of proposed MeshX2-sym and MeshX2-asym against baseline Mesh. (c) EDP comparison of proposed CmeshX2-sym and CmeshX2-asym against baseline Cmesh. Figure 7: Design comparison based on the Energy-Delay Product metric. versus the baseline Cmesh results in an 88% reduction in EDP (see Figure 7(c)). Figure 8 compares the range of topologies proposed in this section in terms of EDP. The EDP values are normalized to the topology with the highest EDP, i.e., Cmesh. Cmesh also had the highest performance among all topologies that we evaluated in Section 3. As can be seen, our proposed CmeshX2-asym design has the lowest EDP among all the topologies (88% reduction against Cmesh), while it provides comparable performance as Cmesh (97%). MeshX2-asym designs are a close second, with a 86% reduction in EDP. High performance and low power consumption in CmeshX2asym and MeshX2-asym designs make them suitable options for GPUs. 5. RELATED WORK A large amount of work has been done in the area of network-on-chip designs for many-core architectures, targeting energy-eﬃcient on-chip communication. A broad spectrum of network design topologies for on-chip communication in CMPs has been explored. The NoC designs for CMPs has matured to the extent that several commercial designs are now available [23, 25]). The area of on-chip networks on a GPU has not been widely explored. In [5], the authors evaluate GPU performance Figure 8: Overall comparison of baseline and proposed designs using the EDP metric. across diﬀerent micro-architecture and NoC design choices using diﬀerent benchmarks. Our baseline evaluations diﬀer from their work in the following aspects. In [5], the design layout is not considered, nor is power estimation. Also their hypothetical GPU assumed a smaller number of streaming multiprocessors and a higher number of memory controllers. This hides the eﬀect of path diversity and congestion in the network. The work in [4] exploits the many-to-few traﬃc patterns observable in manycore accelerators by alternating full routers in congested areas of a mesh with half routers that reduce cost. In [9] the authors propose a 3-D stacked GPU design using optical on-chip crossbar interconnects and explore the power consumption implications in throughput-oriented architectures. The work in [26] advocates using silicon-photonic link technology for on-chip communication in state-of-the-art commerical GPUs and presents an eﬃcient GPU-speciﬁc photonic NoC design. It also examines the scalability of the NoC design for forward-looking GPUs with 128 compute units. In the past, several research papers have suggested the use of parallel networks and channel slicing to improve the utilization of the NoC in CMPs [6, 14]. The main diﬀerence between these prior studies and our work is that our network is designed with two uni-directional asymmetric networks, tailored for the needs of a GPU. 6. CONCLUSION In this work, we evaluated a number of network-on-chip designs, comparing power and performance metrics, targeting the memory subsystem of a contemporary state-of-the-art GPU architecture. We ﬁrst analyzed the memory access patterns of GPU applications, and used this to motivate the design of a range of asymmetric NoCs that are speciﬁcally tailored for GPUs. These asymmetric NoC designs use two diﬀerent NoC architectures for L1-to-L2 and L2-to-L1 communications. This strategy reduces contention in the NoC, and in turn, improves application performance. We compared various asymmetric NoC designs based on performance, power and EDP metrics. Our analysis shows that CmeshX2-asym provides comparable performance to the best baseline design, Cmesh, but consumes 65% lower power. The MeshX2-asym topology also consumes 37% lower power than the baseline mesh while providing comparable performance to this topology. Based on these evaluations we conclude that the CmeshX2-asym and MeshX2-asym are the most suitable electrical NoC designs for GPU systems. For future work, we plan to consider adding a dedicated NoC for smaller messages (i.e., cache control messages) and applying run-time power saving techniques on the subnetworks of CmeshX2-asym to further reduce power consumption and improve energy eﬃciency of the NoC, and the system as a whole. 7. "
Unbiased Regional Congestion Aware Selection Function for NoCs.,Adaptive routing in Network-on-Chip (NoC) selects paths for packets according to network state to reduce packet latency and balance network load. Existing adaptive routing schemes can degrade network performance due to their dependency on either inadequate or outdated network information. We present an adaptive routing scheme in which a router is provided adequate and timely congestion information of the network. A low-complexity routing selection function that considers regional congestion status is proposed. The selection function is unbiased as it considers the same amount of congestion information on both admissible directions. Proposed selection function achieves 18% lower packet latency than local congestion aware selection under realistic workloads. It also reduces regional congestion aware selection logic area and power overhead by 73% and 35% on an 8×8 mesh network.,"Unbiased Regional Congestion Aware Selection Function for NoCs Wen Zong† , Michael Opoku Agyemen† , Xiaohang Wang‡ , Terrence Mak† ‡ †Depar tment of Computer Science and Engineering The Chinese University of Hong Kong ‡Guangzhou Institute of Advanced Technology Chinese Academy of Science ABSTRACT Adaptive routing in Network-on-Chip (NoC) selects paths for packets according to network state to reduce packet latency and balance network load. Existing adaptive routing schemes can degrade network performance due to their dependency on either inadequate or outdated network information. We present an adaptive routing scheme in which a router is provided adequate and timely congestion information of the network. A low-complexity routing selection function that considers regional congestion status is proposed. The selection function is unbiased as it considers the same amount of congestion information on both admissible directions. Proposed selection function achieves 18% lower packet latency than local congestion aware selection under realistic workloads. It also reduces regional congestion aware selection logic area and power overhead by 73% and 35% on an 8x8 mesh network. Categories and Subject Descriptors B.4.3 [Interconnections (Subsystems)]: Network-on-Chip General Terms Design 1. INTRODUCTION Network-on-Chip (NoC) provides scalable and ﬂexible communication infrastructure for chip-multiprocessor (CMP) [16]. In NoC based CMPs, the system relies on the network to access memory and transfer cache coherence data [11, 3]. In CMP, communication pattern varies signiﬁcantly with the running applications, moreover, even for one application, its communication dynamics has varied characteristics at diﬀerent running stages [10, 20]. NoC that incorporates deterministic and oblivious routing cannot well adapt to these trafﬁc patterns which leads to imbalanced link utilization and causes performance degradation in real applications [18]. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. NOCS ’15 September 28 - 30 2015, Vancouver, BC, Canada ACM 978-1-4503-2782-4/14/04 ...$15.00. DOI: http://dx.doi.org/10.1145/2786572.2786574. Adaptive routing selects paths for packets according network state to avoid congested areas. However, locally adaptive routing breaks the inherent global traﬃc balance of applications due to lack of adequate network status information [9]. Adaptive routing that takes non-local information into consideration can prevent the greedy local decisions and is able to improve network load balance and reduce packet latency [9]. Routing schemes such as Global Congestion Awareness (GCA) [18] and Destination Based Adaptive Routing (DBAR) [14] have demonstrated that regional congestion awareness is able improve network load balance and reduce average packet latency under various traﬃc patterns. However, existing approaches either have inadequate information of the network or contain much outdated information that can lead to incorrect view of the network status and cause ineﬃcient routing decisions. An eﬃcient and cost-eﬀective regional congestion aware NoC architecture is desired to have following four properties. a) adequate knowledge of network, a router needs adequate knowledge of the network to get a comprehensive view of the network load and make proper routing decisions; b) timely information, outdated information gives incorrect view of the network which leads to wrong path selections and increase average packet latency; c) unbiased selection, the selection function should not bias to any direction in order to balance network load; d) low-complexity, the selection function should be low-complexity due to the stringent latency, area and power constraint of NoCs. Existing regional congestion awareness NoCs cannot eﬀectively address the four requirements above. We propose an adaptive routing scheme with regional congestion awareness that oﬀers the four desired properties as an eﬃcient adaptive routing scheme. We make following contributions in this paper: • We collect congestion information of a region near a router and transfer the information to this router with low latency. Speciﬁcally, virtual-channel (VC) occupation status of a router’s output channels are monitored and propagated to other routers on its row and column through a lightweight low-latency network. • We propose a low-complexity congestion estimation method to evaluate an admissible direction based on the congestion information collected. Given an admissible output direction, a packet can have one or several paths within the congestion visible region before reaching its destination. The average cost of these paths within the congestion visible region is used to evaluate this output direction. • We implement an unbiased routing selection function. The selection logic always considers the same amount of congestion information on both admissible directions to ensure the congestion comparison unbiased. 1.1 Related work Many adaptive routing algorithms present poor worst-case performance due to the local nature of the algorithms [6]. Several adaptive routing algorithms that leverage both local and non-local information for NoCs were proposed in the past few years. Regional congestion aware NoC architectures can be classiﬁed into two types according to the broadness of congestion information available in each router. In some architectures, a router knows status of the whole network, while in other architectures, a router knows status of a region of the network. In all architectures, non-local congestion information needs to be propagated to a desired router through wires. Generally, it takes longer time to get non-local congestion information from further areas. In the ﬁrst type of NoC, each router has global knowledge of network status. Regional Congestion Awareness (RCA) [9] uses a lightweight network to aggregate and propagate congestion information. Other works which also collect global congestion information are presented in [15, 19, 18]. In these works, channel congestion status is modeled as the cost of edges of the network topology graph, and an optimal routing path is determined by a shortest path to the destination node on the graph. These work incorporate a more concrete model to utilize the congestion information other than the empirical aggregation method used in RCA. However, due to the propagation and computation/aggregation delay, large portion of the global congestion information in these architectures is outdated [18, 14]. Outdated information causes incorrect routing decisions and leads to poor performance. Global Congestion Awareness (GCA) [18] eliminates the aggregation delay on intermediate nodes to improve the timeliness of information. It embeds status information in packet headers to eliminate the need of a side-band network, which adds the router datapath latency to congestion status packets. In terms of route computation complexity, at each router, GCA needs to perform Dijkstra shortest-path computation for all nodes in the network. The other type of NoC architecture collects status of a few non-local nodes instead of all nodes of NoC (e.g., Neighboron-Path (NoP) [1] and Destination Based Adaptive Routing (DBAR) [14]). Though with limited knowledge of the network, the information is relatively timely in average in such type of NoC. NoP considers both current node’s buﬀer depth as well as a neighbor’s buﬀer depth that lies on a candidate path of the packet. In NoP, non-local congestion information is limited to one-hop away from current router. In DBAR, each router propagates its virtual-channel occupation status to other routers on its row and routers on its column through a lightweight network. The congestion propagation network in DBAR covers more number of nodes than that in NoP, and the congestion information experiences only single-cycle delay on each hop. DBAR only collects the virtual-channel occupation status of a single dimension on a row (or column). This 1-dimensional congestion information gives incomprehensive view of the network status and leads to inappropriate routing decisions. Moreover, for one admissible direction, DBAR may have more number of congestion values summed than the other admissible direction. The ] 2 1 [ l a c o L     ] [ 9 A C R     ] 8 1 [ A C G     ] [ 1 P o N     ] 4 1 [ R A B D     Scheme Adequate knowledge Timely information Unbiased selection Low complexity Table 1: Desirable properties achieved by existing work routing selection function is biased to direction that knows less amount of information and leads to poor performance in some traﬃc. We summarize existing work in terms of their achievements on the four desired properties in Table 1. This table shows that there’s not an existing architecture that can well achieve all the four desired properties. These works either have inadequate knowledge of the network, or do not have timely information of the network. In DBAR, the routing selection is likely to bias to direction with less knowledge of congestion. The complexity of GCA architecture is high due to the computation of shortest-path. 1.2 Motivation Existing regional congestion aware routing schemes either have inadequate knowledge of the network or contain large portion of outdated information [14, 18, 1, 15]. Ideally, increasing the coverage of the congestion propagation network provides better view of the network status, but it also inevitably introduces more outdated information which can mislead the routing decisions; moreover, it also requires more area overhead to store and process the congestion information. To make regional congestion aware routing more eﬃcient and cost-eﬀective, one needs to ﬁnd a good balance between the broadness and timeliness of congestion information. Here we brieﬂy analyze the trend of information timeliness, area overhead and routing eﬃciency over the increasing coverage of congestion propagation network. We measure the timeliness of congestion information by the reciprocal of its average delay (in cycles), and measure routing eﬃciency by network saturation point divided by area overhead of adaptive routing logic. Figure. 1 shows the trend. Covering only local congestion status provides non-optimal performance and leads to low routing eﬃciency. Congestion propagation network that covers the global network provides congestion information with poor timeliness. The performance gain is limited, and it requires large area and power overhead, which yields low routing eﬃciency. If the congestion propagation network covers a network region near a router, it oﬀers the router with timely regional congestion information. With proper processing, it is able to get better routing eﬃciency than the other two designs due to its high performance and moderate or low area overhead. This motivates us to propose a regional congestion aware routing scheme which well balances the broadness and timeliness of congestion information to achieve eﬃcient adaptive routing. gestion information for router src in DBAR and proposed architecture. The shaded area shows the visible-region for router src in two schemes. In proposed routing scheme, as in 2(b), src knows status of each output channel of routers that are on its row and column. Minimal routing is employed in this work for its energy eﬃciency and freeness of livelock [6]. So the VC occupation status of channel that leads the packet back to current node is not propagated. In DBAR, src only considers channels of a single direction on a row or column like the arrows in 2(a). Proposed routing scheme in Figure. 2(b) has a larger visible-region, and has a more detailed view of congestion status on the row and column. The congestion information not only includes congestion status the row/column, but also includes the congestion status of turning away from the row/column. We call it 2-dimensional congestion information as it provides congestion status of output channel orthogonal to the admissible routing direction. (a) Visible-region router src in DBAR of (b) Visible-region of router src in proposed routing scheme Figure 2: Visible-region for the router src in DBAR and proposed scheme. 2.2 Congestion propagation network We build a low-latency network to transfer the non-local virtual-channel occupation status to an upstream router on the row/column. Upon receiving a congestion data, the node buﬀers the congestion data then forwards to further upstream node immediately, forming a single-cycle delay per hop propagation network. Through this network, each router can share its VC occupation status with all upstream routers. Given an admissible direction, 3 set of wires are setup to collect VC occupation status of routers located aside that direction. Each set of wires is responsible for propagating the VC occupation status of channels of one direction, including the admissible direction and the two orthogonal directions as well. Figure. 3 shows an example of the congestion propagation network on a row of a 4x4 mesh NoC. In this example, current router is router 0, and the admissible output direction is E ast. The 3 set of wires collect the number of occupied VCs of E ast-directional, N orth-directional and S outh-directional output channels of router 1, 2 and 3. Encoding number of occupied VCs requires log2w bits per output channel where w is the number of virtual channels. The data width of the VCs occupation can be compressed to Figure 1: The area overhead, timeliness of congestion information and its routing eﬃciency over the increasing coverage of congestion propagation network. Collecting a moderate amount information of the network is possible to achieve the best routing eﬃciency. 2. UNBIASED REGIONAL CONGESTION AWARE SELECTION We present the proposed unbiased regional congestion aware (URCA) adaptive routing scheme in this section. In this work, a router receives the congestion status of non-local routers that are located on its row or column.The congestion information of a router is its virtual-channel occupation status of each physical output channel. We take advantage of the abundant wiring resources on chip to implement a lightweight and low-latency congestion propagation mechanism. Based on the congestion information of local and non-local routers, the router estimates the congestion of an admissible direction. The weight of channel congestion value are determined by its likelihood of being traversed by a packet. It then chooses a direction that leads to a leastcontention path in the congestion visible region. In cases where one admissible direction has more knowledge than the other admissible direction, only a subset of its information is used to estimate the congestion of this direction which makes the selection function unbiased. We ﬁrst introduce the congestion information that we use in this work and the network that propagates this information; then we describe the method to evaluate an admissible direction according to the collected congestion information, and lastly we show how to make this selection function unbiased. 2.1 2-dimensional congestion information Virtual-channel occupation status of an output channel measures the contention of going through that output channel [9, 14]. We absorb virtual-channel occupation status from a router’s virtual-channel allocator where it holds credit status from neighboring routers. With the VC occupation status of multiple successive routers, the decision-making routing is able to ﬁgure out the congestion of going on the path formed by these nodes. For each router, we collect the VC occupation status of routers located on its row and column. Thus, the congestion information is from at most N hops away in a square mesh, where N is the total number of network nodes. We refer the region formed by channels with known congestion status visible-region in this paper. Figure. 2 is an example which shows the available con√ Figure 3: Example of congestion propagation network in proposed routing scheme. 3 set of wires are required to collect the VC occupation status of downstream routers. (a) Available edge cost for selecting an output direction for dst (b) Utilized edge cost for selecting an output direction for dst less bits to reduce bandwidth and logic complexity. We use 1-bit data to represent VC occupation status, if the number of occupied VC is large than 1, the congestion value of that channel is set to 1 otherwise 0. Using 1-bit information causes negligible performance degradation compared with multiple-bits representation but reduces the router complexity eﬀectively [14]. 2.3 Evaluating an admissible output direction NoC topology can be modeled using graphs, where the nodes represent the routers and edges represent channels. The congestion value of a channel is modeled as edge cost of the graph. An optimal routing path for a packet corresponds to a shortest path on the graph [18, 15]. Without global congestion information, the routing decisions are made according to the regional information as that in NoP [1]. In this work, a router always selects an output channel which leads to paths that are less congested in its visible-region. A destination located in one of the four quadrants of current router has two admissible output directions using minimal routing. For one of the admissible output direction, inside the visible-region, there can be one or several possible paths that start with that output port. The router selects the output direction if its paths in average is less congested than that of the other admissible direction, The packet travels one or several hops along an admissible direction, and then it turns to an orthogonal channel and exit the visible-region. Taking a destination that is located at the N orth − E ast quadrant as an example, like the dst node in Figure. 4(a). For the E ast admissible direction, the packet will ﬁrst travel several hops along the E ast directional channels and then turn to a N orth directional channel. Cost of E ast directional channels are noted as m0 , m1 , ..., mK−1 , and cost of N orth directional channels are noted as n1 , n2 , ..., nK as that in Figure. 4(a). If the packet takes the turn at node which is t hops away on the admissible direction, the cost of this path is computed as Equation 1, ct = mi + nt (1) i=0 which essentially sums all the cost of channels that are on the path. Assume the destination is K hops away from current router on the admissible direction. The packet path can go t hops on the candidate direction and then turn to the channel of orthogonal direction, where 1 ≤ t ≤ K . So there is a total t−1(cid:88) K(cid:88) t=1 C = 1 K K−1(cid:88) K(cid:88) ct (2) Figure 4: Available edge cost and utilized edge cost for selecting an output direction for destination dst at router src of K possible paths in the visible-region on this admissible direction. We assume the probability for each path being taken is the same, i.e., 1/K ; so the average routing cost of all paths of this admissible direction in the visible-region is Replace ct with value from Equation 1 we get: C = 1 K ( (K − i)mi + i=0 j=1 nj ) (3) We use Equation 3 to evaluate the congestion in the visibleregion of an admissible direction. Equation 3 shows that the weight of channel cost of an admissible direction decreases linearly, and the weight of cost of the orthogonal channels are all 1/K . A channel that is included in more paths has higher weight, because it is more likely to be traversed by the packet. So the weight of the ﬁrst channel of the admissible direction is 1 since it is included in every possible path; an orthogonal channel has weight of 1/K since it is included in only one path. Now we apply this evaluation method to the example in Figure. 4(a). For E ast direction, the destination dst is 3 hops away from current router src, and hence K = 3. The average cost of paths starting from E ast output port is C = (3m0 + 2m1 + m2 + n1 + n2 + n3 )/3. Using the same rule for N orth admissible direction, we get its cost C = (2p0 + p1 + q1 + q2 )/2. 2.4 Unbiased regional congestion aware selection The output selection of a packet is implemented by comparing the average routing cost of the admissible directions which is deﬁned in Equation 3. However, we can see that the upper bound of Equation 3 is determined by the destination oﬀset K on that direction. Comparing the routing cost of two admissible direction directly is not fair for the direction with a larger K . It will push the packet the those boundary nodes which have only one path to the destination, and get poor performance according to ZigZag [2]. In Figure. 4(a), for E ast direction, cost of 6 channels are summed, while for N orth direction, cost of 4 channels are summed. If the network congestion status is the same at all channels, the selection function will choose N orth direction for this packet. However, this selection is not correct, instead it should randomly select one of the two directions. Our solution for this problem is, ﬁltering the extra information on one admissible direction, making the number of considered channels the same on both directions. Suppose the destination is K1 and K2 hops away from current router on the two candidate directions respectively; we set the K on both directions to be the smaller value of K1 and K2 before evaluating the direction according to Equation 3. Taking the example in Figure. 4(a), we set K on both directions to be 2, which prunes the considered channel status to that in Figure. 4(b). In Figure. 4(b), cost of 4 channels are considered for both directions. In an extreme case when K is 1, our method essentially turns to be NoP [1] selection that considers status of neighbors. Suppose the two admissible directions are D0 and D1 , and the oﬀset of destination on the two directions are K0 and K1 respectively. On D0 direction of visible-region, mi represents the cost a D0 directional channel, and nj represents the cost a D1 directional channel. On D1 direction of visibleregion, pi represents the cost a D1 directional channel, and qj represents the cost a D0 directional channel. The selection function works as follows: It ﬁrst set K to the smaller value of K0 and K1 , and then evaluates the two directions according to Equation 3. Since in both directions the average cost are divided by K , this division does not aﬀect the result of comparison, so the division is not performed. The router selects the direction which has smaller average routing cost. If the average routing cost are the same, it selects randomly from direction D0 and D1 . Figure. 5 describes this selection function using pseudo code. C0 = (cid:80)K−1 i=0 (K − i)mi + (cid:80)K 1: procedure selection(K0 , K1 , mi , nj , pi , qj ) 2: K = min (K0 , K1 ) C1 = (cid:80)K−1 i=0 (K − i)pi + (cid:80)K 3: 4: 5: if C0 < C1 then 6: return D0 7: else if C0 > C1 then 8: return D1 9: else 10: return random(D0 , D1 ) 11: end if 12: end procedure j=1 nj j=1 qj Figure 5: Unbiased regional congestion aware selection function Normalize the average routing cost according to the length of the visible region on a direction is another way to eliminate selection bias. However, we ﬁnd it does not perform as good as proposed solution in out experiments, moreover, it introduces large area overhead to do normalization. 2.5 Comparison with existing routing schemes We use an example to show the diﬀerences between proposed architecture and existing regional congestion aware architectures. In this comparison, we assume the coordinate of the destination is (k , k) and current router is (0, 0). In Table 2, we compare these routing schemes in terms of the congestion information coverage, information timeliness, and computational complexity of routing. Proposed routing scheme covers twice the number of channels compared to that in DBAR but still keep the same information delay. Compared with GCA the information timeliness is 6 times better, and computational complexity is k times lower. 3. ROUTER MICRO-ARCHITECTURE The state-of-the-art adaptive router is presented in [12] which includes 2 router pipeline stages and one link traversal stage. We use advance bundle signal [13, 14] which is sent to next router before the head ﬂit arrives the designated neighbor router. A router does Dimension Pre-selection (DP) according to advanced bundle signal to select the optimal output for a packet before the head ﬂit arrives, this hides the selection logic from the router critical path. Figure. 6 shows the router pipeline which is modiﬁed according to a state-of-the-art low-latency speculative adaptive NoC router [17, 12]. The shaded stages are used to hide the our routing selection logic from the router’s critical path. URCA selection computation is done independently of the router logic, and provides a bit-vector for the dimension preselection to use. We also call this bit-vector out dim register following the naming in DBAR. Figure. 7 shows the diagram of the propose router micro-architecture. The shaded modules are related to the unbiased regional congestion aware selection. The URCA selection unit is responsible for computing the optimal output direction for destinations of different oﬀsets. Its implementation details and cost analysis are described in Section 4.4. The result is stored and then utilized by dimension pre-selection unit. A dimension preselection unit selects the corresponding bit from the out dim register according the destination ID in bundle signal. When the head ﬂit arrives at a router, SA and VA can be performed directly according to the Pre-selection result. Figure 6: 2-stage router pipeline for proposed routing scheme. The acronyms are RC (Route Compute), SA (Switch Allocation), VA (Virtual-channel Allocation), ST (Switch Traversal) and LT (Link Traversal), DP (Dimension Pre-selection) 4. EVALUATION We modiﬁed NoC simulator Noxim [8] to support virtualchannels and congestion propagation mechanism. We use 6 diﬀerent synthetic traﬃc patterns from Noxim and use realistic workloads traces from many-core simulator Sniper [5]. In all simulations, same number of virtual-channels are used, and one of the virtual-channels works as the escape channel to prevent deadlock [7]. The network conﬁguration is summarized in Table 3. 4.1 Packet latency of synthetic trafﬁc Table 2: Coverage, timeliness of congestion information and routing computational complexity Local GCA [18] DBAR [14] Proposed Arrows compose the visible-region of router (0,0) Visible-region (# of channels) Mean information delay (Cycles) Computational complexity 2 0 O(1) 2k(k + 1) 3k O(k2 ) 2k k/2 O(k) 4k k/2 O(k) Table 3: Simulation setup for synthetic traﬃc Mesh size 8x8 Number of virtual-channels 4 Buﬀer length 6 ﬂits Packet length 2 - 7 ﬂits PIR (packets/cycle/core) 0.01 to 0.1 URCA congestion data 1 bit width DBAR congestion width GCA limitation window 7 hops data 1 bit Figure 7: The router micro-architecture with unbiased regional congestion aware selection In this evaluation, we compare the average packet latency and network saturation point of 5 diﬀerent routing algorithms, namely XY routing, locally adaptive routing, Destination Based Adaptive Routing (DBAR), Global Congestion Awareness (GCA) and the proposed Unbiased Regional Congestion Aware (URCA) routing. 6 traﬃc patterns from Noxim [8] are used: uniform random, hot-spot, shuﬄe, butterﬂy, transpose and bit-reversal traﬃc. The network size is set to be 8x8. Figure. 8 shows the average packet latency results in all traﬃc patterns with diﬀerent packet injection rate. In Figure 8(a), under uniform random traﬃc, XY routing has close saturation point with adaptive routing methods, and from Figure 8(b) to 8(f ), XY routing has much lower saturation point than adaptive routing algorithms. XY routing cannot distribute non-uniform communication ﬂows to the network and results in large packet delay. URCA effectively extends the network saturation point beyond local selection function under various traﬃc patterns. At moderate and high injection rate, URCA leads to lowest average packet latency under all traﬃc patterns except butterﬂy traﬃc. Compared with local adaptive selection strategy, URCA improves the saturation point by 5.8%, 6.0%, 9.5%, 24.3%, 21.1%, 11.8% in random, hot-spot, shuﬄe, butterﬂy, transpose and bit-reversal traﬃc respectively. In random and hot-spot traﬃc, GCA is slightly worse than DBAR, and in other traﬃc patterns, GCA leads to higher saturation point than DBAR. In butterﬂy traﬃc, the source node and destination node are in neighbor columns. URCA under this traﬃc pattern essentially degrades to NoP [1] as we prune congestion information to same amount on two directions. However, due to the special communication distribution, that DBAR pushes packet to destination column early happens to match the traﬃc and hence leads to higher throughput than URCA. The communication distance is short in butterﬂy traﬃc, which favors GCA as it mitigates the eﬀect of inaccurate knowledge of far nodes. 4.2 Link load variance We also record the link load (ﬂits/cycle) of each channel during simulation when packet injection rate is 0.055 packet/cycle/node. Adaptive routing improves the link load balance, so as the variance of link load in NoC. The variance of link load of diﬀerent adaptive routing under these traﬃc patterns are summarized in Table 4. Values in this table are normalized to the variance of link load of locally adaptive routing. It shows that URCA can reduce link load variance by 22.5% in average compared with local congestion aware adaptive routing. DBAR can also reduce link load variance under all traﬃc patterns, but due to its limited knowledge (a) Uniform random traﬃc (b) hotspot traﬃc (c) Shuﬄe traﬃc (d) Butterﬂy traﬃc (e) Transpose traﬃc (f ) Bit-reversal traﬃc Figure 8: Average packet latency of 6 traﬃc patterns Table 4: Variance of link load random hotshuﬄe transbutterspot pose ﬂy 0.86 0.97 0.85 0.95 1.40 1.33 0.80 0.76 0.73 0.98 1.28 0.81 DBAR 0.90 GCA 0.84 URCA 0.77 bitreversal 0.95 1.32 0.78 of network, the reduction is not as eﬀective as URCA. GCA pursuits shortest path for packets which drives packets to few less congested links and causes large link load variation. 4.3 Packet latency on realistic workloads In this part, we evaluate the routing performance on SPLASH2 [21] and NPB [4] workloads running a 64-core CMP. We extract the traﬃc traces from many-core simulator Sinper [5] with conﬁguration in Table 5. Average packet latency normalized to XY routing of evaluated workloads are plotted in Figure. 9. In low injection rate workloads like barnes and fmm, all routing schemes have similar packet latency. In high contention workloads like ocean, ft and mg, adaptive routing schemes have lower packet latency than XY routing. In cholesky, locally congestion aware selection and DBAR does not perform better than XY routing, while URCA can reduce packet latency by 42%. Across all workloads listed, URCA achieves 18% packet latency reduction in average, compared with and locally adaptive routing. 4.4 Implementation cost analysis We implement proposed routing selection logic using Verilog HDL for a 8x8 network. Since we use single bit data to encode channel cost, the multiplication in the selection function can be implemented with AND logic. The weight of each channel cost is determined by the oﬀset K . Congestion values are used as masks for corresponding weight, Table 5: Simulation setup for application benchmarks Frequency Core model L1 ICache L1 DCache L2 Cache Cache coherence Main memory latency Network size Concentration Flit size 1.0GHz Intel Nehalem 32KB, private, 4-way 32KB, private, 4-way 512KB, private, 8-way MOESI 80 cycles 8x4 2 128 bits Figure 9: Network packet latency normalized to XY routing and the average routing cost of the direction is a summation of the masked weights. The dimension pre-selection unit is essentially a decoder, its input is the destination ID and returns a bit from the out dim register updated by URCA selection unit. We use Synopsys Design Compiler to analyze the area and power overhead of proposed selection strategy on TSMC 65nm standard cell library with the clock frequency set to be 1GHz. Table 6 shows the area and power overhead of the selection logic in URCA and DBAR. DBAR requires one selection computation unit for each destination in a quadrant. The area overhead grows linear with number of nodes in the network. In URCA, the destinations in one quadrant can share the same selection computation unit as long as their oﬀset K in algorithm in Figure. 5 are the same. So the area overhead only grows linearly with the network dimension length. In square mesh network, DBAR requires O(N ) selection computation units, while URCA requires 2 N selection computation unit in each router. Table 6 shows that URCA reduces area and power overhead by 73% and 35% relative to DBAR. √ Table 6: Implementation overhead comparison Routing Scheme Area (NAND2 Power (mw) equivalent) 121590 31920 DBAR URCA 2.48 1.60 5. "
