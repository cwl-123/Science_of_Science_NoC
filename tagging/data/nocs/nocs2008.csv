title,abstract,full_text
Reducing the Interconnection Network Cost of Chip Multiprocessors.,"This paper introduces a cost-effective technique to deal with CMP coherence protocol requirements from the interconnection network point of view. A mechanism is presented to avoid the end-to-end deadlock that arises from the dependency chains created at the network interfaces between the different message types handled by coherence protocols. Our proposal is designed to guarantee a fraction of end-to-end bandwidth for the highest priority messages and makes it unnecessary to employ several virtual networks or complex mechanisms for dealing with the limited capacity of the endpoint buffers. The presented approach uses the Rotary Router as its starting point, extending the original mechanism for the routing-dependent deadlock to the message-dependent deadlock. We also propose a solution that guarantees point-to-point message ordering in this router, which is a common requirement in some coherence protocols. Results for synthetic and parallel applications show that the proposal improves the performance of previous solutions with a much lower hardware cost.","Reducing the Interconnection Network Cost of Chip Multiprocessors  Pablo Abad, Valentín Puente, José Ángel Gregorio  Universidad de Cantabria  {abadp, vpuente, monaster}@unican.es  Abstract  This paper introduces a cost-effective technique to  deal with CMP coherence protocol requirements from  the  interconnection network point of view. A  mechanism is presented to avoid the end-to-end  deadlock that arises from the dependency chains  created at the network interfaces between the different  message types handled by coherence protocols. Our  proposal is designed to guarantee a fraction of end-toend bandwidth for the highest priority messages and  makes  it unnecessary  to employ several virtual  networks or complex mechanisms for dealing with the  limited capacity of the endpoint buffers. The presented  approach uses the Rotary Router as its starting point,  extending the original mechanism for the routingdependent deadlock  to  the message-dependent  deadlock. We also propose a solution that guarantees  point-to-point message ordering in this router, which  is a common requirement  in some coherence  protocols. Results  for  synthetic and parallel  applications show that the proposal improves the  performance of previous solutions with a much lower  hardware cost.  1. Introduction  CMP systems usually assume the presence of some  cache coherency mechanism in order to guarantee the  communication between processors via  sharedmemory. The coherence protocol keeps caches  transparent to the software, guaranteeing the coherence  invariants at each cache block.   In order to ensure coherence invariants, each  memory controller must react to each coherence  transaction received from the processor or network, in  some situations sending new messages  to other  controllers in the system. In consequence, a hierarchy  of protocol messages must coexist in the network. The  reactive nature of these different types of messages and  the limited capacity of consumers can generate end-toend deadlock. When a particular class of messages  overflows the consumption queue in a node, the  progression of subsequent actions at the memory  controller cannot be guaranteed because the network  cannot guarantee  the delivery of  the associated  messages. The solutions for this problem vary from  routing each network-traffic class through different  virtual [14] [20] or physical networks [10]; extending  the end-point queues into a main memory buffer [3];  employing  some  deadlock  detection-recovery  technique or a combination of detection and avoidance  based on virtual networks[21][9]; or even, providing  enough buffer space in each node’s network interface  message queues to hold at least as many messages as  can be supplied, as in [22]. Today, the most common  technique for dealing with this problem in CMP  systems [19] or system level multiprocessors [14] is to  employ different virtual networks for each kind of  traffic. To be conscious of the cost of this technique,  let us focus our attention in the Alpha 21364 router  [14]. This router employs adaptive routing in a bidimensional  torus network, which requires  three  virtual channels per physical link in order to avoid  routing deadlock [7]. In addition, the coherence  protocol employed requires seven different classes of  messages, which makes it necessary to employ seven  different virtual networks. In the end, the router  employs 19 virtual channels per physical link. This  configuration requires separate buffering and signaling  for each channel, besides an  increment  in  the  arbitration cost even with a multiplexed crossbar. This  might not be a problem in system level multiprocessor  systems, such as the Alpha 21364, but it clearly is for a  CMP system. In a CMP, this approach requires an  extremely small buffer size if the implementation has  to be feasible in terms of silicon area.  In this paper, we propose an effective solution for  this problem, with an almost zero implementation cost.  Starting from the Rotary Router [1], the proposed idea  extends the originally designed to avoid routing  deadlock to avoid also message-dependent deadlock.  The idea is based on restricting the amount of                resources available per router for each kind of traffic.  The solution does not need to increase neither the  number of virtual networks nor buffering resources of  the original router, and it requires only some slight  modifications  in control  logic.  In contrast  to  conventional solutions, our idea allows a better buffer  utilization. Thus, the implementation cost is reduced  and the router performance could be improved.   Moreover, in some protocols, consecutive messages  between two different controllers must arrive at their  destination in the same order as they enter the network.  This requirement is referred to as in-order delivery or  point-to-point order. For example, in token coherence  protocol, persistent request deactivation must arrive at  destination after the activation [13]. In other situations,  maintenance traffic must follow a predefined path from  origin to destination [14][20]. The percentage of  messages that must follow that order is extremely low  and usually  this  is not a difficult problem.  Deterministic  routing  solves  this problem by  construction, as  the path between any origindestination pair is fixed. In the adaptive routing case,  the messages that require point-to-point ordering could  be tagged at origin and the use of adaptive resources  disallowed. Unfortunately, for the Rotary Router the  solution  is not so straightforward. The  inherent  buffering scheme makes it hard, at first sight, to  achieve point-to-point ordering. However, we have  found that it is possible to ensure that order with little  effort and with low performance impact by restricting  network resources availability combined with a portto-port bookkeeping system.  The rest of the paper is organized as follows:  Section 2 summarizes the operating mode of the  Rotary Router. Section 3 explains  the solution  proposed  to avoid message-dependent deadlock.  Section 4 shows how the Rotary Router is capable of  guaranteeing in-order delivery. Section 5 presents the  performance results and, finally, Section 6 states the  main conclusions of the paper.  2. Previous work  A router architecture able to deal with most of the  requirements of CMP interconnection networks was  proposed  in [1]. The Rotary Router completely  removes centralized structures, such as global arbiters  or crossbars, is fully adaptive, and avoids the Head Of  Line Blocking (HOLB). In addition, the Rotary Router  is able to deal with some important requirements  imposed by CMP environments, such as higher wire  availability [4] and power and area efficiency. The  capability to make such optimizations comes from the  way packets are moved  inside  the router. The  operation of the Rotary Router is based on two internal  rings where packets circulate in opposite directions,  looking for a suitable output port. This movement  simplifies output arbitration and reduces contention.  An outline of the Rotary Router can be seen in Figure  1. The router is built through the replication of three  different structures named Input Stage, Output Stage  and Buffering Segment Stage. Packets enter the router  through the Input Stage, where pre-routing decisions  are made. Additionally, the ring in which the packet  will circulate is chosen depending on both the path to  the closest profitable output port and  the ring  occupancy. After header update, packets start moving  towards their output port through the Buffering  Segment Stage. This stage is made up of Dual-ported  FIFO Buffers (DFB) interconnected forming two  independent rings and connected to each input and  output port. Once a packet reaches a buffer connected  to a profitable output port, there are two possible cases:  i) if the packet loses arbitration, it will keep on  circulating the ring until reaching another profitable  output port; ii) if arbitration is won, the packet will  move to that Output Stage of the router. This stage is  in charge of sharing the only physical link between the  packets coming from the two buffer rings.  Injector  Consumer  N  W  BUFFERING SEGMENT  STAGE  OUTPUT  STAGE  FIFO  Buffer  Multiplexer  E  FIFO  Buffer  Dual-Port  Fifo Buffer  S  Demultiplexer  INPUT  STAGE  Figure 1. Rotary Router Sketch  Rotary Router avoids deadlock for any network  topology, and performs adaptive routing without  virtual channels. Different flow controls are applied to  packets entering a buffer ring from a transit port or  from an injection port. Control applied to in-transit  packets limits the number of packets that can be in the  router  rings  simultaneously, avoiding deadlock  appearance inside the router. Control applied to                    injection ports guarantees the existence of enough  holes in the network to move packets between nodes,  which, added to the capacity of packets to do missrouting, makes the network deadlock free. A formal  proof of this claim can be found in [23].   The Rotary Router has proved to perform better  than more classic structures as part of a CMP  interconnection network. The performance advantage  and power efficiency of this router is clear. However,  for the performance study carried out in [1], for the  sake of simplicity, message dependent deadlocks were  solved by the network interface assuming unlimited  storage capacity at consumption queues. In-order  delivery was unnecessary in the evaluation framework  employed. These assumptions do not invalidate the  performance and energetic efficiency achieved, but for  a practical usage of Rotary Router, these issues must  be addressed.  3. Message-Dependent Deadlock  In a CMP cache coherence protocol, the messages  involved in a memory transaction depend one upon the  other, because the generation of some message types is  a consequence of the delivery of other types. For  example, when a cache controller sends a message  requesting a cache line, this causes at least the answer  from another cache controller providing that block.  Therefore, there is a second message subordinate to  the first one. This relationship is known as the message  dependency chain [21]. This dependency between  messages can cause the appearance of a deadlock other  than the routing deadlock. This new kind of deadlock,  known as message-dependent deadlock or end-to-end  deadlock,  appears  at  the  endpoints of  the  interconnection network because of  the  limited  capacity of the consumption queues. As a simple  example, consider an interconnection network with a  request-reply protocol. If an application exhausts  network resources with request messages due to  consumption queue overflow, reply messages will not  be able to make progress, stopping the processing of  pending requests at consumption queues and blocking  therefore traffic advance. This cyclic dependency  could lead to a message deadlock. Coherence protocols  will have deeper dependencies among messages  (longer dependency chains)  than a request-reply  communication protocol, because depending on the  state which a cache line is in, different operations will  be performed in order to read/write the data. As an  example, the communication protocol in [14] has a  dependency chain of seven messages, which means  that some operations need seven messages to complete.  Most of the previous methods used to avoid  message-dependent deadlocks are mainly based on the  replication of traffic paths via the inclusion of extra  hardware resources, such as extra virtual or physical  networks able  to break  resource and message  dependencies [6][9][14][20]. Different message types  travel through different hardware resources. This way,  different message1 traffics never can block each other.  The complete avoidance of message-dependent  deadlocks requires a number of replications equal to  the dependency chain length. The additional hardware  resources  increase network area and arbitration  complexity and obviously, this could have a significant  performance and cost impact. In fact, in some real  machines, like the SGI Origin 2000, with the aim of  reducing the number of necessary virtual networks  imposed by  the protocol, a detection-recovery  technique is employed to reduce the three virtual  networks imposed by the protocol to only two. In other  cases, like the solution adopted in the Alpha 21364  router where seven virtual networks are employed  solely for the purpose of eliminating this anomaly, the  importance of the problem can be clearly appreciated.  Fortunately,  the  special  Rotary  Router  characteristics, summarized in the previous Section,  provide the opportunity to deal with this problem  without requiring extra hardware resources. This  technique can only be applied if the buffering strategy  allows packet overtaking inside the router, as occurs in  the Rotary Router.  3.1 End-to-end Deadlock avoidance for Rotary  Router  The Rotary Router is free of Head of Line Blocking  because a blocked message cannot indefinitely delay  the access of other messages to an available output  port. The same property, adequately employed, will  allow us to avoid message-dependent deadlock without  hardware replication. This method, named as filling  control, is explained below.  It could seem that in order to reserve exclusive  buffering resources for each message type the Rotary  Router would need the inclusion of two additional  DBF rings per type. But it is not the case. To avoid  buffering replication, every message type is forced to  move through the same buffering space, and message  advance is guaranteed through the control of the  cumulative amount of resources used in all the  1 As we are employing cache coherent protocol, each message is  composed of just one packet (a command or a command plus a cache  block) and consequently we will indistinctly employ the terms  “message” or “packet”                                                                      buffering space. The filling control method does not  supervise the buffers used by a message type, but  rather the fraction of the whole buffering resources in  use. The amount of buffering used by each message  type will be limited, in accordance with the priority of  the traffic. Each subordinate message is able to occupy  a bigger portion of area than its predecessor. The top  class or terminating class of traffic will be able to  utilize all the buffering space in the network, with the  exception of the resources required to guarantee that  the network is routing-deadlock free. This way, every  time a message tries to access any buffer ring, the  number of messages which are already in both router  rings is checked. If this number is below the limit  imposed for a particular message type and router input  port, the message is allowed to enter the ring.  Otherwise, the message must wait until the necessary  amount of buffering resources becomes available.  Let us explain the method with an example. Assume  we have a protocol with four different message types,  m1, m2, m3 and m4, being m1 the first message type in  the dependency chain and m4 the terminating one.  Filling control will restrict the first message type m1,  only allowing it to fill up to 25% of a router’s  buffering resources. When a router exceeds this limit,  the situation is communicated to the injector and to the  neighboring routers, through specific stop protocol  lines. From that moment, no more m1 messages are  allowed to enter in the router from any input port  (injection or transit). m1 subordinate messages (m2)  should be able to advance even if m1 messages are  stalled due to an overflow of m1 at any consumption  queue. In a similar way, m2 should not be allowed to  occupy the whole buffering space, because there are  still two kinds of messages with higher priority. For  this reason, it is safe for m2 messages to make use of  up to 50% of ring buffering. The limit for the third  message  type will  rise 75%, and  finally,  the  terminating message type will be the only one allowed  to make use of 100% of buffering resources  (obviously, this 100% does not include the buffering  resources needed by the routing-deadlock avoidance  method). Terminating messages do not generate new  messages, therefore they will not block any other  message.   However, applying the same occupancy limits to  injection and in-transit ports could give rise to  deadlock situations. For instance, if every router in the  network reaches the limit to inject m1 messages  simultaneously, this class will not block subordinate  messages, but it will not be able to advance. To  circumvent this situation, a solution equivalent to the  one used in routing-deadlock avoidance mechanism  has been adopted. In order to reach a situation in which  every router in the network has reached its limit to  inject m1 messages, last messages must come from an  injection queue (in-transit queues move messages  between routers, but do not increase the total amount  of messages in the network). Applying a harder limit to  injection queues we ensure that we will never reach the  situation described before. This way, in a worst case  scenario at least one of the routers will have an  occupation level lower than the limit for m1 messages.  Notice that this limit difference must be applied to  each message type independently. For example, if we  had a network with two message types (m1 and m2) and  a router capacity of N messages, in-transit queue limits  will be N/2 for m1 messages and N for m2 , while  injection queue limits will be N/2-δ and N-δ. The δ  extra holes generated by the method avoid blocking  situations.   The filling control mechanism does not require  data-path replication to deal with message-dependent  deadlocks, but some control logic needs to be added.  This mechanism has to be applied both to the messages  in transit through the network and to the messages  injected from a coherence controller. For this reason,  this flow control has to be handled by a centralized  structure per router. This structure, made up of a  counter for each message type, will be in charge of  sending stop signals to the injector and to the  neighboring routers. Counters update is performed in  two phases; first, every new message entering the input  stage or at the injector will be checked and the  appropriate counter will be  incremented. This  operation is performed in parallel with the pre-routing  and ring selection process. In the second phase,  packets leaving the router rings are also checked, and  counters decremented. This operation is performed  when the message is in the output stage. Once every  counter has the proper value, flow control signals are  generated and sent to the injector and neighboring  routers. These control signals are processed by the  control logic of the DFBs in the neighboring router in  order to make the message advance inside the ring or  to the next router.   It should be noted that this approach requires a  modest amount of hardware: merely one counter per  class of traffic, some modification in the DFB control  and to increase the wiring between routers with a stop  signal per message type. In contrast, conventional  solutions need to multiply the virtual channels per link  by the number of messages types. This implies  additional buffers per physical channel and complexity  increment in crossbar arbitration. Besides, independent  inter-router protocol lines per traffic class are required.   Moreover, our approach tends to favor the advance  of high order messages type, being the traffic with the  biggest advantage  the  terminating  traffic. For a  coherence protocol, this behavior is the most desirable,  and in contrast to our router, conventional routers must  prioritize artificially the traffic at crossbar arbitration  [14], increasing its cost.  3.2 Correctness in Corner-case situations  To check the correctness of the proposal, specific  synthetic  traffic  tests have been developed for  emulating  the environment  in which messagedependent deadlocks are likely to occur.   Basically, a reactive traffic pattern is applied to the  network and after the steady state network consumers  will be enforced to stop accepting one of the message  types, emulating the behavior of a network interface  with finite resources. From that moment, no more  messages subordinated to the type stopped will be  generated. The filling control method must guarantee  the delivery as soon as possible of the subordinate  messages which are actually in transit or waiting at  injection queues.   The main network parameters will be the same for  every simulation. The topology considered will be a 2Dimensional torus with 64 nodes (8×8). For this  experiment, every message-type will have a fixed  length of 5 phits. The router buffering space will be  kept constant at a value of 60 packets per router.  Traffic analyzed will be reactive with uniform  destination pattern. The simulator generates the first  message type in the dependency chain at a rate of one  phit/cycle/router. The generation of  the rest of  subordinate messages is done automatically upon  completion of servicing messages at end nodes. Six  different protocols will be simulated, each of them  with a different dependency chain length, varying from  two to seven. Each protocol will be evaluated, stopping  the consumption of different message types at a fixed  simulation cycle. For every simulation, we will analyze  the throughput obtained for the last class of messages  in the dependency chain. To do so, the time the last  terminating message takes to reach its destination will  be measured. Simulations were repeated several times  with different seeds for traffic generation, and for  every simulation done, every terminating message  reached its destination. If a deadlock had happened,  some terminating messages would have never reached  their destination. The results of the experiment are  shown in Figure 2. The X-axis represents the message  type stopped for each simulation and the Y-axis  represents the throughput of terminating messages  remaining  in  the network, normalized  to each  protocol’s total throughput. Note that while for a 7type protocol we can stop 6 different message types,  for a 2-type there is only one message type that can be  stopped. As can be seen in the graph, terminating  messages throughput remains constant independently  of the message type stopped. As the protocol has a  higher number of message types, less buffering space  is assigned to each type and obviously terminating  traffic will have lower throughput, but every message  belonging to the highest priority type arrives at its  destination.  t u p h g u o r h T s e g a s s e m g n o i t a n i m r e T 0.5 0.4 0.3 0.2 0.1 0 0 2 MSG TYPES 3 MSG TYPES 4 MSG TYPES 5 MSG TYPES 6 MSG TYPES 7 MSG TYPES 1 2 3 4 5 6 7 Message type blocked Figure 2. Terminating messages throughput  when consumers of intermediate message  classes are artificially blocked  4. In-Order delivery support  Some memory coherence protocols or maintenance  tasks require in-order delivery support for a small  fraction of the network traffic. Fulfilling this requisite  is extremely simple for input buffered routers. A  specific routing algorithm can be applied to ordered  messages, forcing them to follow a fixed path to  destination. As the buffers in this type of routers do not  allow packet reordering inside each router, in-order  delivery will be guaranteed. The Rotary Router can  forward packets between different router buffering  elements, which  imply a chance of reordering.  Consequently, in the Rotary Router some special  actions need to be taken to ensure the correct order at  packet delivery.   The routing deadlock avoidance mechanism in the  Rotary Router is based on the ability of packets to be  miss-routed and on the injection restriction. In-order  messages cannot make use of that approach, so they  need a different methodology  to avoid routingdeadlock. As the Rotary Router does not divide  network resources into multiple virtual channels, the  routing algorithm chosen for in-order messages has to  be deadlock free when no virtual channels are  available. We could guarantee in-order delivery for  that traffic if the network resource availability is                IN TABLE  NODE  X-  Y+  Y-  0  0  0  0  X+  . X+  0  INPUT  IN TABLE  NODE  X-  Y+  Y-  0  0  0  1  IN TABLE  NODE  X-  Y+  Y-  0  0  0  2  BUFFERING  SEGMENT  STAGE  X+  1  X+  BUFFERING  SEGMENT  STAGE  X+  BUFFERING  SEGMENT  STAGE  INPUT  X+  0  INPUT  1  X+  P1 header  P2 header  OUTPUT   STAGE  OUT TABLE  NODE  X+  X-  Y+  0  0  0  0  Y-  (a)  OUT TABLE  NODE  X+  X-  Y+  0  0  0  0  (b)  OUTPUT   STAGE  Y-  OUT TABLE  NODE  X+  X-  Y+  0  1  0  0  (c)  OUTPUT   STAGE  X+  0  Y-  Figure 3. In-order routing, with two packets from the same traffic class. (a) Entering packet p1 exit  index is updated using input table value and X+ input port (b) Input table is updated, subsequent  packet p2 exit index is updated. Exit index of p1 is compared against output table value for packet  input port, (c) p1 is allowed to leave the router, next exit index in output table is updated for X+  inputs after the message leaves the ring.  restricted to a sub-topology. Although the Rotary  Router is topology agnostic, in this work we will  assume a suitable topology for CMP systems, such as  bi-dimensional torus. Under these circumstances, it is  enough that the in-order messages do not make use of  the wraparound links and that they must be routed  following a strict dimension order, to guarantee  deadlock freedom for in-order traffic. Although suboptimal, in general it is possible to keep the in-order  delivery implementation topology agnostic, employing  up/down* routing algorithm.  In an input buffered router, messages traveling in  opposite directions of  the same dimension use  independent resources. However, in the Rotary Router  every direction and dimension can share the buffering  space (originally, there is no restriction to using both  internal rings). This could produce a deadlock between  two neighboring routers if a router is full of in-order  traffic and all the messages try to advance towards a  neighbor where the same situation is happening. To  avoid this circumstance, the two buffer rings inside the  Rotary Router will be used for in-order traffic flowing  in opposite directions. The selection of the router ring  in which a packet will advance will be based on the  packet direction. Packets  traveling  in opposite  directions will make use of different rings, never  sharing the same buffering space. This way, this kind  of deadlock is avoided because no cyclic dependences  between buffers will occur.  Under the above conditions, it can be ensured that  packets with the same source and destination will  advance through the same path. But we still need to  ensure that packets do not change their order while  moving inside the buffer rings of the routers. A  mechanism based on table lookup is proposed for this  purpose. The operation of this mechanism is shown in  Figure 4. Each input stage will hold a small table with  the order value (named exit index) for each output of  the router. Once pre-routing is computed and it is  determined that the packet is tagged for in-order  delivery,  the  table value corresponding  to  the  profitable output port is copied to the header of the  packet, and the value in the table is incremented by one  unit. This value at the header of the packet indicates  the exit order. At every output stage, there will be a  complementary table with information about the exit  index expected for the next in-order packet that must  leave the router, coming from each input port. In this  way, when a packet is being arbitrated at a DFB, the  index at the header of the packet pi must coincide with  the value in the output stage table corresponding to the  input port where the packet came from. If both fields  match, the packet pi can leave the router ring, and the  corresponding output port table will be updated.  Otherwise, the other packet pj that entered the ring  before pi is still in the ring and consequently pi must be  kept on in the current router, and will be forwarded to  the next DFB of the ring, even when its profitable  output port is available.  Note that this ordering method does not order the  packets according to the pair source-destination, but to  their router input-output ports. This can introduce  unnecessary delay to some packets, because they have  to maintain the order with respect to packets from  different traffic flows. The main reason for applying  this method is to minimize implementation cost. If  packets are classified according to their source and  destination,  table sizes will be  increased  in an  unsustainable way with the network size. With this  method, tables size is proportional to the number of  input ports of the router. As an example, if we have a  router with five input ports and a buffering space of 60    packets in the rings, we will only need ten tables with  four rows each (it is not possible for an in-order packet  to leave the router through the entering port). The exit  index on each row does not need to grow indefinitely;  it is enough to let it reach a value equal to the buffering  space (in packets). Thus, for this example each row  would only need six bits to store a maximum value of  60. Therefore, each table needed would have a size of  24 bits (30 bytes per router).  The Rotary Router was not conceived to deal with  in-order packet routing, and therefore its performance  falls when this kind of traffic predominates. For these  packets, the output port accessibility is much more  challenging than in conventional traffic, and can  produce router performance degradation for in-order  traffic. This method is only useful when in-order  packets represent a small portion of the whole network  traffic. Under this condition, the method guarantees inorder delivery without using solutions with a higher  implementation cost. In-order packets are able to share  resources with the rest of the packets, only routing and  arbitration needs to be modified.   Note that the combination of this method with the  end-to-end deadlock avoidance mechanism is not  completely orthogonal. This means that if we have inorder traffic belonging to different classes of traffic,  we need to expand the size of the tables, maintaining  an exit  index per class (the cost  increment  is  proportional to the number of message classes that  could require  in-order delivery). Otherwise,  low  priority  in-order  traffic can block point-to-point  ordered packets with higher priority, which can  generate deadlock. Each class of traffic must be inorder only with packets belonging to its own class. In  most cases, the in-order traffic is restricted to only one  or a few message classes [13][14].  5. Performance Evaluation  The solutions presented for message-dependent  deadlock and in-order routing must be evaluated to see  how they affect performance. For this purpose, three  counterpart router architectures were compared against  the Rotary Router. The first one was the Adaptive  Bubble Router (BADA) [17]. This router will have  higher buffer requirements than the rest of the routers,  because it needs two virtual channels to avoid routingdeadlock. Adaptive Bubble Router has proved to be a  good off-chip proposal and in fact its deadlock  avoidance methodology is used in the interconnection  network of the BlueGene/L supercomputer [2]. The  second router evaluated was the Deterministic Bubble  Router (BDOR). This router shares the same flow  control as the one above, but does not perform  adaptive routing, making unnecessary the employment  of virtual channels to avoid deadlock. Finally, the last  router evaluated (LOW-LAT) makes use of speculative  arbitration and buffer bypass to achieve a base latency  of a single cycle, similar to the router presented in  [15]. This is a deterministic router, where packets  traveling in the same dimension have a latency of one  cycle, while injected, consumed or turning packets  have to go through the whole router pipeline. As link  traversal is also made in the same cycle, in order to  achieve a reasonable cycle time this last router is only  suitable for topologies with low link lengths, such as  mesh networks. Message-dependent deadlocks are  avoided in the three routers using different virtual  channels for each message type. In-order messages do  not need special actions in the second and third routers.  For the Adaptive Bubble Router, in-order messages  will not be routed through adaptive paths. To carry out  this evaluation, no implementation based on recovery  methods for message dependent deadlock, such as  [21], was employed because this method cannot  support the in-order delivery required by the real  system evaluation carried out in subsequent subsections.  5.1 Synthetic Scenario  In this first phase of the evaluation, we will show  the effect of synthetic traffic on network performance.  The  tool used for  this evaluation will be  the  interconnection network simulator SICOSYS [18].  Two different networks have been considered for the  experiment. The topology chosen for LOW-LAT  router is an 8x8 mesh, and 8x8 torus for the rest of the  routers.  As we are trying to emulate a memory coherency  protocol, we will simulate a workload in which data  transactions are started at every injector and measure  the time required to complete a fixed number of  transactions. This will provide more useful information  about how the network will behave when making a full  system evaluation. Data transactions will be generated  as follows; the simulator generates the first message  type  in  the dependency chain at a rate of 1  phit/router/cycle, and  subordinate messages are  generated automatically as messages arrive at their end  nodes. Messages are classified in classes and these are  numbered (starting from 1) according to their position  in the dependence chain. The packet size selected for  the experiment has a bimodal distribution, being 5  phits (128 bits links and 64+16 bytes messages) for  messages belonging to odd classes and 2 phits for  those belonging to even classes (128 bits links and 16          bytes messages). To mimic the reactive characteristic  of the traffic, destination of an odd-class message is  chosen according to the pattern traffic selected,  whereas those messages from even classes are sent  back to the sources from which the originating  messages were received.  ROTARY BADA BDOR LOW-LAT 5 4 3 2 1 0 RAND BIT-REV. MAT-TR PERM Figure 4. Normalized required time for  consuming 32,000 terminating messages.  The first experiment is designed to observe the raw  performance of all routers. Assuming only three  message classes, synthetic patterns Random, Transpose  Matrix, Perfect Shuffle and Bit Reversal [8] are  employed for the destination of class-1 and class-3  messages. Results have been obtained simulating the  traffic triggered by 32,000 messages (500 from each  router) belonging to the class 1 and similar buffer  capacity is assumed in each router. The BADA router  has 15 phits FIFO queues, BDOR and LOW-LAT  routers have 30 phits per FIFO. In the Rotary Router,  buffer capacity is 20 phits in DFB and 10 phits in each  one the input and output stages. In this way, the total  storage capacity per router is 320 phits in conventional  routers and 300 phits in the Rotary Router. The sizes  chosen are those where no significant improvements in  throughput were observed for larger sizes.  As can be seen in Figure 4, the Rotary Router  reduces  the  time required  to finish every data  transaction for almost all traffic pattern analyzed. Both  adaptive  routers obtain close  results,  the  two  deterministic ones employ up to four times more  execution time in the presence of non-uniform traffic  patterns. The differences between the BDOR and the  LOW-LAT router are mainly caused by the different  network topology chosen for each router. The small  link length restriction present in the LOW-LAT router  harms its performance.  The second experiment is designed to show how  each router performs when the number of message  classes vary form 2 to 4, keeping the router storage  capacity constant at 300/320 phits. In order to meet  this requirement, we must modify the phits per FIFO to  20 (2 classes) and 10 (4 classes) phits respectively in  BADA and 40 (2 classes) and 20 (4 classes) phits for  BDOR and LOW-LAT. No change is required in the  Rotary Router storage distribution. We are considering  no implementation cost increment in any of the routers,  which is true for the Rotary Router but false in the  conventional routers, harming our proposal in this  comparison. Anyway, even without taking into account  this important fact, the performance advantage of the  Rotary Router, as it can be seen in Figure 5, is clear.  For every traffic pattern and every protocol analyzed,  the Rotary Router obtains better throughput results. In  addition, the number of message types in the network  does not affect Rotary Router performance, and  maximum  throughput  remains nearly constant.  Deterministic routers also maintain their maximum  throughput levels constant, but at much lower levels.  The BADA router suffers important throughput losses  when moving from 3 to 4 message types. The reason  behind this behavior is the reduction of buffer size. As  buffering space was kept constant, buffers in the  BADA are extremely small (2 packets) for a 4-types  protocol, which reduces router throughput, being even  worse than the deterministic routers in some cases.  0.8  0.6  0.4  0.2  0  2 Types 3 Types 4 Types  2 Types 3 Types 4 Types                     (a)                                           (b)  0.8  0.6  0.4  0.2  0  ROTARY  BADA  BDOR  LOW -LAT  2 Types 3 Types 4 Types  2 Types 3 Types 4 Types                     (c)                                           (d)  Figure 5. Normalized Maximum Sustained  Throughput for different number of types  5.2 Real Scenario  In this section, we will show the effect of the  message dependent deadlock avoidance mechanism  and in-order packet routing under a realistic situation.  For this purpose, the complete system simulator Simics  [11] will be used, extended with the GEMS timing  infrastructure [12]. GEMS provides detailed models of  both  the memory system and a state-of-the-art  processor. SICOSYS has been integrated into the  simulator GEMS, replacing  its original network  simulator. The simulated system is a 16-processor                CMP with shared S-NUCA L2 based on [5]. The  protocol, based on Token Coherence [13], requires a  hierarchy of  five classes of messages  to be  implemented. In  this protocol, persistent request  activation and deactivations must be point-to-point  ordered. In this way, we will expose the advantages  and correctness of our proposal  in  terms of  performance, with a large number of message classes,  and correctness, requiring  in-order  traffic. Main  parameters of the simulated system are shown in Table  1.   Table 1. Main simulation parameters  Number of Cores  Window Size /  outstanding req. per CPU  Issue Width  L1 I/D cache  16  256 / 16  4  Private, 32KB, 2-way, 64Bytes  block, 1-cycle  Direct Branch Predictor  4KB YAGS  Indirect Branch Pred.  256 entries (cascaded)  L2 cache  L2 cache bank  Main Memory  Command size  Network Topology  SNUCA, token coherence protocol,  16x16 banks, 4 per router  128KB, 16-way, 3-cycles, Pseudo  LRU, 64 Bytes block  4GB, 260 cycles, 320 GB/s  16 bytes  8×8 torus  Network Link  128 bits / 1 cycle latency  The applications considered in this study are four  transactional and three scientific workloads. The server  workloads used are a Static Serving Web server  benchmark based on SURGE running on top of an  Apache web server (HTTP1) and Zeus web server  (HTTP2), SPECjbb2000  (Java), and an onlinetransactions processing TPC-C  like benchmark  (OLTP). The numerical workloads used are LU, FT  and IS from NAS Parallel Benchmark, using the  OpenMP  implementation, Version 3.3.  In all  applications, a variable number of runs are performed  with pseudo-random perturbation in access memory  times in order to estimate workload variability.  Figure 6 presents the results with expected average  execution time. The confidence interval is 95%. As can  be seen, the Rotary Router outperforms the rest of the  routers in all the applications simulated. The adaptive  and deterministic Bubble Routers obtain similar results  for every application. This means that each virtual  network is not stressed enough to take advantage of  adaptive routing. The LOW-LAT router exhibits a  very low latency under low traffic conditions. As can  be seen in some applications, especially server based  ones, it outperforms bubble routers, because of its  smaller low load pipeline length. Notwithstanding,  with other applications  this router has a poor  performance. This behavior is mainly due to the  topology employed (it is the only mesh topology) and  routing simplicity. Both factors will cause a low  maximum achievable throughput. It should be pointed  out here that in the experiments carried out, the LOWLAT router has an unfair advantage because we are  assuming the same cycle time for all the routers. For  example, according to [1], the Rotary Router cycle  time will be approximately 20FO4 whereas LOW-LAT  router  will  have  35FO4  [16].  ROTARY BADA BDOR LOW-LAT 200 150 100 50 0 IS LU FT OLTP Java HTTP1 HTTP2 Figure 6. Normalized execution time of real  workloads.  The reason behind the better results of the Rotary is  the lower latency of the protocol messages with  highest priority. Due to the special flow control of intransit messages in the Rotary Router, messages with  high priority advance faster, because they can occupy a  bigger portion of router buffering resources. In the  case of input buffered structures, an amount of  buffering space is fixed for each message type, so  latencies are not able to adapt to message priority. In  some cases, the advantage is close to 30% with respect  to the closest alternative.  6. Conclusions  In this work, we have presented efficient solutions  for well-known network problems. The mechanism  designed to alleviate the HOL blocking in the Rotary  Router has been extended to implement a mechanism  able  to deal with message-dependent deadlocks  without hardware replication. This proposal allows us  to keep router complexity constant, independently of  the number of message classes of the coherence  protocol and we consider this to be of great importance  for current and future CMP architectures. In addition, a  solution for point-to-point ordering was presented. An        efficient mechanism able  to deal with  in-order  messages with few control logic add-ons has been  developed. The idea allows ordered messages to use  the same resources as the rest of message types.  Performance results from a wide range of loads  demonstrate that the mechanism used for deadlock  avoidance presents advantages over conventional  approaches. The buffer utilization of our proposal is  more flexible, which implies a performance boost and  messages with a higher priority travel faster through  the network, thus accelerating application execution  times.  7.  Acknowledgements  This work has been supported by the Ministry of  Education and Science of Spain, under contracts  TIN2004-07440-C01-01 and TIN2007-68023-C02-01  and by the HiPEAC European Network of Excellence.  8. "
Dynamic Voltage and Frequency Scaling Architecture for Units Integration within a GALS NoC.,"In complex embedded applications, optimization and adaptation at run time of both dynamic and leakage power have become an issue at SoC coarse grain. For power reduction, voltage and frequency scaling techniques have been applied successfully to CPUs but never with a generic approach for all IPs within a SoC. Network-on-Chip architecture combined with a globally asynchronous locally synchronous paradigm is a natural enabler for easy IP unit integration. GALS NoC provides scalable communications and a clear split between timing domains. We propose in this paper a complete dynamic voltage and frequency scaling architecture for IP units integration within a GALS NOC. The proposed DVFS architecture is based on the association of local clock generator and VDD-hopping between two given voltages. No fine control software is required during any voltage and frequency re-programming. As a result, minimal latency cost is observed. The power efficiency of the proposed system has been evaluated close to 95%.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Dynamic Voltage and Frequency Scaling Architecture  for Units Integration within a GALS NoC   E. Beigné, F. Clermidy, S. Miermont, P.Vivet  CEA-LETI, MINATEC, 38054, Grenoble, FRANCE  {edith.beigne, fabien.clermidy, sylvain.miermont, pascal.vivet}@cea.fr  Abstract  In complex embedded applications, optimization and  adaptation at run time of both dynamic and leakage  power have become an issue at SoC coarse grain. For  power  reduction, voltage and  frequency  scaling  techniques have been applied successfully to CPUs but  never with a generic approach for all IPs within a SoC.   Network-on-Chip architecture combined with a Globally  Asynchronous Locally Synchronous paradigm is a natural  enabler for easy IP unit integration. GALS NoC provides  scalable communications and a clear split between timing  domains. We propose in this paper a complete Dynamic  Voltage and Frequency Scaling architecture for IP units  integration within a GALS NOC. The proposed DVFS  architecture is based on the association of Local clock  generator and VDD-Hopping between two given voltages.  No fine control software is required during any voltage  and frequency re-programming. As a result, minimal  latency cost is observed. The power efficiency of the  proposed system has been evaluated close to 95%.  1. Introduction  Power dissipation has emerged as a major design  constraint in today complex System-On-chip architectures,  limiting performance, battery life and reliability. A lot of  dynamic and static power saving techniques exists and  most of them are related to the VDD voltage supply level  control. Reducing the voltage affects power consumption  quadratically and linearly affects frequency. Processor  manufacturers offer technologies to reduce the power  consumption by means of Dynamic Voltage Scaling  (DVS)  [1]. Typically, the processor speed can be switched  between several frequencies depending on the detected  load of the system while the level of the supply voltage is  changed to match the new frequency. Regarding leakage  currents, a common global power gating scheme usually  partitions the system into several power domains  [2] to  reduce leakage currents but most of the time power  domains are gated at coarse grain.  For multimedia  or Software  defined Radio  applications [5], IP units are designed to respect the most  demanding configurations. We aim at the better power  savings when  the SoC  is  in  lower performance  configurations.  Each IP unit thus needs adapted power  modes. In SoC architecture, if only one global voltage is  controlled or scaled down, there is no real optimisation at  unit level and the whole system is constrained by the most  critical functional unit to meet its timing constraints. As  the number of IPs integrated in a SoC is increasing and  the power consumption is ever increasing, a fine-grain  power management is thus becoming essential.  Using both a NoC distributed communication scheme  and a GALS approach offers easy IP integration thanks to  local clock generation  [3]. Moreover, it can allow better  energy savings since each functional unit can easily have  its own independent clock and voltage. Hence, Networkon-Chip architecture combined with a multi powerdomains GALS system appear as natural enablers for  distributed power management system as well as for local  DVFS and local power gating.  In this paper, we propose, as an evolution of the  FAUST architecture [5], to optimize and control locally,  at IP block level, dynamic and static power consumption  of a complete GALS NoC architecture. The proposed  DVFS architecture is based on the association of a local  clock generator, its pausable clock system  [18] and a local  voltage supply unit. The supply unit is based on a VDD  hopping technique  [7] to control active power modes,   combined with a SCCMOS power switch  [10] to handle  stand-by low leakage mode. Unit voltage and frequency  are locally controlled to handle five power consumption  modes from high performance to absolutely no leakage.  An average voltage and frequency given value is obtained  thanks to an automatic hardware mechanism. The main  objective is to optimize, at fine grain, the power reduction  without any fine control software at system level  [4]  [23].  In section 2, we firstly present an overview of the  proposed NoC architecture for local DVFS. In section 3 is  explained IP unit architecture handling five power modes.  In section 4, we present the detailed design to encapsulate  a NoC unit within its local DVFS mechanism. In section 5  is presented the low-power execution strategy. Finally, we  present some analysis about estimated power gains and  the DVFS power efficiency of the complete system.  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.26 DOI 10.1109/NOCS.2008.26 129 129                 2. DVFS NoC architecture  2.2. Main principles  The proposed DVFS architecture is implemented  within a complex GALS NoC. The system architecture is  briefly described to focus on the unit architecture handling  the local power management scheme.  2.1. System Architecture  Each units of the dedicated SoC are arranged around a  fully asynchronous Network-on-Chip  [5] [6]. As shown  Figure 1, the NoC units are fully synchronous islands.  Synchronization between the communication router and  the units is done thanks to a pausable clock mechanism  called SAS (containing Synchronous-to-Asynchronous  and Asynchronous-to-Synchronous  interfaces). A  programmable Local Clock Generator (LCG), using a  delay line, is implemented within each unit to generate a  variable frequency in a predefined applicative range. The  power unit manages the local unit voltage, sharing a  power switch between a VDD hopping technique and an  ultra-cut-off block. The Power Unit uses two external  voltages : VHIGH and VLOW to be automatically switched  during DVS phases. The Network Interface (NI) is in  charge of communications with respect to NoC protocol  and is also in charge of local voltage and frequency  control for DVFS using a Low Power Manager.     VHIGH VLOW POWER UNIT POWER UNIT POWER UNIT Unit A Unit A Unit A Unit A NI NI NI NI S A S S A S LCG LCG LCG LCG Unit B Unit B Unit B Unit B NI NI NI NI S A S S A S Unit C Unit C Unit C Unit C N I N I N I N I S A S S A S LCG LCG LCG LCG LCG LCG LCG LCG POWER UNIT POWER UNIT POWER UNIT Unit D Unit D Unit D Unit D NI NI NI NI S A S S A S Unit E Unit E Unit E Unit E N I N I N I N I S A S S A S LCG LCG LCG LCG LCG LCG LCG LCG CPU CPU CPU CPU N I N I N I N I S A S S A S LCG LCG LCG LCG Units_off Units_rst Figure 1 : DVFS NoC architecture  The power management strategy is programmed by the  main CPU,  through NoC unit attached Network  Interface’s Low Power Managers, according to required  performance and power constraints. DVFS can be  executed during IP computation and communication  according to their own activity. The only global signals  are regarding units’ reset and off control. The main CPU  is required to directly disable/enable the units for power  off mode and the corresponding reset phase.  Main principles of the local control and power  regulation are described thereafter.  Each synchronous IP unit is defined as an independent  power domain (using its dedicated local voltage) and an  independent frequency domain (using its dedicated local  clock). The unit handles a set of user-defined power  modes (see section 3.2).  In order to perform efficient local DVS, the main  objective is to avoid as much as possible low-level  software control to ensure a minimal latency cost of DVS  during unit’s computing. Within the Power Unit, this leads  to implement a hardware controller to automatically  switch between VHIGH and VLOW.  By guarantying smooth  DVS transitions, the synchronous IP block can continue  its own operation. To obtain an average voltage value  between VHIGH and VLOW, the Low Power Manager  automatically switches between these two values using a  configurable duty-ratio.  Since the power domain and frequency domain of the  synchronous unit are identical, it is expected that the local  frequency  scales approximately  linearly with  the  associated voltage scaling. If  the frequency/voltage  scaling ratio is not exactly linear (see section 6.1), the  delay line must be re-programmed accordingly. The VLOW  delay value is adjusted by a correcting factor with respect  to the VHIGH delay value, since the delay line is supplied  on the same power domain.  Finally, using Pausable Clock technique, fast and  reliable delay line programming interface is obtained. As  a consequence, the synchronous IP unit locally continues  its own computations or NoC communications during any  DVFS phases.  3. NoC unit architecture  3.1. NoC unit integration for DVFS  In order to integrate a synchronous unit within the  proposed NOC DVFS  scheme  (Figure 2), each  synchronous IP core (“core” level) is encapsulated within:  -  Its own Network Interface (NI) and Low Power  Manager (LPM). The Network Interface provides  HW primitives for NoC packet generation &  reception, and task synchronization [5]. The LPM  implements the local power mode defined for that  given unit and controls respectively the Power  Supply unit and the Delay line. This is the “unit”  hierarchy level.  Its own NoC Test Wrapper (NTW) for handling  test-mode. For test, the NoC topology is used to  carry the test patterns which are used to feed the  synchronous scan chains through the NTW  [22].   This is the “test” hierarchy level.  -  130130               -  -  Its own Pausable Clock interface, which contains  the SAS  interface,  the  local pausable clock  generator and a delay line programming interface.  This is the “sas” hierarchy level.  Its own Power Supply Unit (PSU), which contains  Ultra-Cut-Off mechanism for leakage reduction,  and Hopping Unit for DVFS, generates the VCORE  voltage. Lastly, some isolation cells (for LOW and  OFF modes) are  inserted on  the external  asynchronous 4-phase/4-rail NoC link for proper  voltage conversion between the local unit and the  NoC topology. This is the “top” hierarchy level.  cut_off V-HIGH V-LOW xxx_top Synchronous NOC protocol ULTRA-CUT-OFF HOPPING UNIT POWER SUPPLY UNIT ANOC 4-phase / 4-rail link S L L E C N O I T A L O S I V-CORE POWER DOMAIN l h _ c w p g f c _ c w p xxx_sas xxx_test xxx_unit xxx_core T S E T C O N R E P P A R W LOW POWER MANAGER NETWORK INTERFACE SYNCHRONOUS IP  CORE g f c _ l d clk_ni idle clk_core GATED CLOCK E C A F R E T N I S A S clock pause  req/ack signa ls DELAY LINE PROG delay_ctrl clk_gene PAUSABLE CLOCK GENERATOR Pausable Clock Interface test_scan reset_n Figure 2 : NoC unit architecture  In the proposed scheme, the complete Synchronous IP  core, up to the “sas” hierarchy level, is clocked by the  locally generated clock, and supplied by the VCORE  voltage, locally generated by the PSU. The synchronous  unit has thus its own frequency and power domain.  3.2. Power mode definition  INIT INIT HIGH HIGH LOW LOW At reset, the unit is at VHIGH with no clock At reset, the unit is at VHIGH with no clock The unit is supplied by VHIGH voltage The unit is supplied by VHIGH voltage The unit is supplied by VLOW voltage The unit is supplied by VLOW voltage HOPPING HOPPING The unit is automatically switched between The unit is automatically switched between VHIGH and VLOW voltages,  for DVFS VHIGH and VLOW voltages,  for DVFS IDLE IDLE OFF OFF The unit is idle, with maintain of its current state  The unit is idle, with maintain of its current state  at VLOW voltage,  for reduced leakage power at VLOW voltage,  for reduced leakage power The unit is switched OFF, with no maintain of its The unit is switched OFF, with no maintain of its current state,  for minimal leakage power current state,  for minimal leakage power Figure 3 : Definition of Unit Power Modes  In the proposed architecture, each unit can be set in  one of the 6 available power modes (Figure 3) :  -  in INIT mode, supply voltage is VHIGH, and no  clock is sent to the core. This is the “post-reset”  mode.  131131 -  -  -  in HIGH mode, supply voltage is VHIGH and core  clock is on. This is the “nominal” working mode.  in LOW mode, core clock is still on, but supply is  switched to VLOW. Clock frequency is lower than  nominal, and energy per cycle decreases. This is  the “low power” mode.  in HOPPING mode, core clock is on and supply  voltage automatically hops between VHIGH and  VLOW. Frequency and duty-ratio of hopping  transitions is configurable. The obtained performance is an intermediate between VHIGH and VLOW  modes, depending on the given duty-ratio. This is  the “DVFS” mode.  in IDLE mode, core clock is off and leakage power  is reduced thanks to the VLOW supply voltage. This  is the “low-power dormant” mode.  in OFF mode, the unit is switched off by the Ultra  Cut-Off device (see section 4.2) to further reduce  the leakage power. Since the NI is inactive in this  mode, the OFF mode is enabled/disabled through  an external “cut_off” signal controlled by another  unit in the NoC (for instance the main host  processor). This is the “low-leakage” mode.  All power modes, beside the OFF mode, can be  selected per each unit through programming of the unit  Network Interface (see section 5).  -  -  4. NoC Unit design for DVFS  In this section is presented the design of the various  elements (from Figure 2) to encapsulate one synchronous  IP core within the proposed DVFS mechanism. We  describe respectively the Local Power Manager, the  Power Supply Unit and the Pausable Clock interface.  4.1. Local Power Manager  The Local Power manager  integrated  into  the  Network-Interface is in charge of handling the unit’s  power modes. This manager contains a set of  programmable registers, which can be programmed  through the NoC, to define the unit power mode, to  configure the programmable delay line, and to configure  and control the Power Supply Unit.  The Power Unit manager contains a “mode” register to  define  the unit power mode (INIT, HIGH, LOW,  HOPPING, IDLE, OFF, as defined in section 4.2). The  “dl_cfg” register defines the two delay lines values :  dl_cfg[15:8] for delay in HIGH mode, and dl_cfg[7:0] for  delay in LOW mode.  In INIT and IDLE mode, the Power Manager set an  idle signal in order to gate the clock of the core unit. The   PSU is then required to be in VHIGH supply in INIT mode  while in VLOW supply in IDLE mode.                                  In order to control the HOPPING mode, a Pulse Width  Modulation (PWM) is used. Two dedicated registers  define the “PWM frequency” and the “PWM duty-ratio”.  To get a low power PWM design, an 8-bits PWM counter  is used to set the VHIGH / VLOW duty-ratio while a 4-bits  16-stage clock prescaler is used to use core clock divided  by 21 to 216 as a PWM reference clock. As an illustration,  Figure 4 shows a sequence between the HIGH and LOW  states using the PWM.  PWM Frequency Clk Voltage 1 0 Fhigh Flow 0 1 0 Vh igh Vlow 0 Figure 4 : LPM control, hopping sequence example  Finally, the LPM also contains a set of registers to  precisely configure the Hopping-unit : the hopping-unit  clock through a dedicated programmable delay-line and  the transition slopes between VHIGH and VLOW.  4.2. Power Supply Unit  The Power Supply Unit (PSU) manages the unit  supply voltage Vcore according to the selected power  modes using two supply rails Vhigh and Vlow provided  by off-chip DC-DC converters. According to the 65nm  targeted technology, Vhigh is 1.2V, while Vlow is 0.8V  but Vlow could be any voltage between 0.6V and 1.2V.  during 'OFF' mode to reduce the unit leakage current. The  Vdd-Hopping unit ensures smooth transitions between  Vhigh and Vlow without stopping the unit clock and  computations.  • Hopping unit  The hopping unit  [7] is composed of a control FSM,  an unbuffered R-2R ladder DAC, a fast comparator, a  counter with thermometer-coded outputs called a “softswitch” and a clock generator independent from the unit  clock.   To hop between Vhigh and Vlow, while always  keeping functional the synchronous logic, there must be  no voltage undershoot (Vcore << Vlow) and the transition  must last at least few nanoseconds to avoid EMI and  dynamic IR-drop problems associated with high dV/dt.  Also, current must not flow directly from the Vhigh  source to the Vlow source to avoid destructive overcurrents and power losses.  By splitting the Thigh transistor in 24 parallel  transistors with independent gates, and controlling the  gates with the thermometer-coded counter we obtain an  adjustable-width transistor than can be used as a digitally  adjustable resistor. With the comparator and the DAC,  this makes a closed-loop control system, adjusting Vcore  to be equal to Vref. By proper DAC configuration, Vcore  can ramp smoothly from Vhigh to Vlow and vice-versa.  Vlow Vhigh 1 Vlow Vhigh 'HIGH '  state Vcore = Vhigh - ∆ V 2 Vhigh≥ Vref ≥Vlow Vcore = ramp f rom Vhigh to Vlow or  Vlow to Vhigh Vlow Vhigh 4 Vlow Vhigh 3 'LOW'  state Vcore = Vlow - ∆ V Vref =  Vlow Vcore ~ Vlow Figure 6 : Hopping transition principle  Figure 6 shows the followed steps to make a transition.  For a falling transition, Vcore is firstly supplied by Vhigh,  then the control loop is activated and Vref is rampeddown, Vcore follows and some power is lost in the Thigh  transistors. When Vref=Vcore=Vlow the Tlow transistor  is switched on with no short-circuit risks, the control loop  and Thigh transistors can then be switched off. For a  rising transition, the sequence is reversed. Finally, outside  transition phases, the hopping clock is switched off and  the dynamic power consumption is minimal.  Figure 5 : Power Supply Unit  The Power Supply Unit (Figure 5) is composed of  three main devices : the power switches (Thigh and Tlow  power transistors), the Ultra Cut-Off voltage generator  (UCO), and the Vdd-Hopping unit. The UCO is used  132132                   V-UCO  • Pausable Clock Interface architecture  • Ultra Cut-Off generator  To minimize power switches size and allow lowvoltage operation, low-Vt transistors are used for the  Thigh and Tlow power switches. This leads to high  leakage current when the unit is switched off.  DN  UP  Charge  pump  EN  VP  MA  UP  DN  Current sense  amplif ier  EN  CLK  MB  CUT-OFF  UCO-CLK   Figure 7 : Ultra Cut-Off architecture  [10]  The UCO generator (Figure 7) is a charge pump  creating a voltage slightly higher than Vhigh to polarize  PMOS power switches gates in order to reduce the drain  leakage. Since higher gate voltage increases gate leakage,  there is an optimal voltage that minimizes total leakage.  Due to process variations, this optimum strongly  depends on process, temperature and aging. The proposed  UCO generator architecture  [10] is fully auto-adaptive to  get automatically to the minimal leakage.  Compared to traditional MTCMOS power switches   [11], the obtained leakage current is 1 decades lower,  while offering a good compromise for Power Switch  efficiency for VLOW voltage.  4.3. Pausable clock interface  In this section is presented the pausable clock interface  which connects the synchronous unit to the asynchronous  NoC and generates the local clock using a programmable  delay line. A specific attention has been carried out reprogram dynamically and reliably the clock period during  DVFS phases.  •  Introduction  In order to resolve the problem of metastability  between the synchronous and asynchronous domains,  GALS and Pausable Clock mechanisms have been  introduced and studied by various research groups   [12] [13] [14] [15] [16] [17]. In   [18]  is given a recent  overview and classification of existing Pausable Clock  techniques. In order to avoid metastability and remove  synchronisation cost, the common idea is to pause  temporary the clock when a transfer is required between  both timing domains then resume the clock. The design  objective of such interface is obviously to offer reliability,  -  high throughput and low latency. The ETH solution   [16] [17] is adopted for the following reasons :   -  free running clock compatible with delay line,  -  various GALS ports (poll/demand, in/out, etc…),  -  asynchronous 4-phase handshaking compatible  with ANOC 4-phase protocol,  high throughput with one asynchronous transfer  per clock cycle thanks to a toggle signalling,  - Extended Burst Mode  formalism   [19],  efficient synthesis using the 3D tool  [20].  Starting from the above solution, we present in detail  in the following paragraph the dedicated Pausable Clock  interface which is compatible with ANOC protocol and  which allows DVFS by dynamic programming of the  Delay Line.  for  In Figure 8  is presented  the Pausable Clock  architecture for ANOC protocol. It is composed of:  - 2 GALS ports composing the “SAS interface” : the  A-S interface for transferring input packets from ANOC  to the synchronous unit, the S-A interface for transferring  output packets from the synchronous unit to ANOC. The  SAS interface converts the asynchronous QDI 4-phase/4rail ANOC protocol into the synchronous ANOC protocol  with proper handling of VC0/VC1 virtual channels  priority  [6].  - one “Delay Line Programming” interface : when  delay line must be dynamically re-programmed upon  demand of the Network-Interface or of the Power unit (see  section 4.1), the clock is paused in order to guarantee that  delay-line is cleared during its programming.  - one “Pausable Clock Generator” which generates  locally the clock thanks to a delay line, which can be  paused upon demand of A-S interface, S-A interface, or  DLP interface.  : k n i l C O N A e d o n C O N A o t / m o r f Edata[67:0] Edata_ack[16:0] Esend[1:0] Esend_ack Eaccept0/1 Eaccept0/1_ack Sdata[67:0] Sdata_ack[16:0] Ssend[1:0] Ssend_ack Saccept0/1 Saccept0/1_ack SAS A – S Interface S – A Interface n_data[33:0] n_send[1:0] u_accept[1:0] u_data[33:0] u_send[1:0] n_accept[1:0] d l_cfg[15:0] d l_cfg_ctrl pwc_hl test_scanhl Delay  Line Prog ri_as, ri_sa ai_as, ai_sa ri_dlp ai_dlp Delaycell[7:0] Figure 8 : Pausable Clock Interface  Connection from / to  Synchronous Unit Clk Pausable Clock Generator reset_n l o r t n o C t i n u r e w o P d n a I N 133133                                 • Pausable Clock Generator  The Pausable Clock Generator (Figure 9) can handle 3  concurrent requests : from either the A-S, S-A or DLP  interfaces. An asynchronous request is arbitrated using a  Mutex element which cause the clock to be momentarily  paused. Once the request is released, the clock can restart  again. If no asynchronous request is received, the clock  (half-) period is determined by the value programmed in  the delay line. The generated clock is then applied to the  synchronous unit through a classical clock-tree (generated  during place & route).  ri_as ai_as ri_sa ai_sa ri_dlp ai_dlp r1 r2 ME a1 a2 r1 r2 ME a1 a2 r1 r2 ME a1 a2 rclk_dclk Clock Tree clk_prebuf Clk dclk_b dclk_b dclk reset_n Programmable Delay Line rclk delay_cell[7:0], test_mode, reset_n Figure 9 : Pausable Clock Generator  In order to re-program dynamically the delay line  without any internal delay line glitches, the classical  scheme  [18] has been modified with an extra C-element  and AND-gate to guarantee that both input and output of  the delay line are cleared before reprogramming the delay  line : the ai_dlp output signal is raised only once the delay  line is cleared.  re-programmed through its Network Interface (dl_cfg_ctrl  is raised), or that the unit’s VDD-Hopping starts a  transition between High and Low voltages (pwc_hl is  switched) and that the delay value must be switched  between High delay value (dl_cfg[15:8]) and Low delay  value (dl_cfg[7:0]).  When such an event is detected, the  pen signal is toggled in order to fire the Asynchronous  Finite State Machine. The DLP AFSM specification using  XBM notation  [19] is defined below :  0  1  2  3  4  5   1  pen+  |   ri+   2  ai+   |   ri- dl_prog+   3  ai-   |   dl_prog-   4  pen-   5  ai+     0  ai-   |   ri+  |   ri- dl_prog+  |   dl_prog-  When pen is toggled, a clock pause request is raised  (ri+), once the clock is paused (ai+), the new delay value  is then sent to the programmable delay-line (dl_prog+).  The proposed delay-line programming mechanism is  reliable and cost only a few clock cycles to program backto-back the clock period during any VDD-hopping  transition between High and Low voltages, or to reprogram the unit clock period through the NoC and the  unit’s Network-Interface.  • Programmable Delay-Line   When designing a programmable delay line  [21], the  main difficulty is to obtain a precise, small and low-power  design, while using if possible only standard-cells.  • Delay-Line Programming interface  Delaycell_in rst_n rst_n d[i] rst_n rst_n d[i+1] d[i+1] Delaycell_out Within the pausable clock interface, the Delay-Line  Programming interface is responsible to program a new  delay-line value. The interface pauses the clock during  delay line programming to guarantee that the delay line is  cleared.  clk pwc_hl dl_cfg_ctrl test_scanhl Edge detection pen DLP AFSM dl_prog l p d _ a i Connection withClock generator l p d _ i test_scanhl test_mode r pwc_hl dl_cfg[15:8] dl_cfg[7:0] delaycell[7:0] e y Lin ela o D T Figure 10 : Delay-Line Programming Interface  The Delay-Line programming interface (Figure 10)  detects either that the unit must enter in test mode (testscan is raised), or that the unit’s clock period have been  134134 Ctrl[i] Ctr l[i+1] Ctr l[i+1] Test_mode Ctr l[i] rst_n ∆ (i) Ctr l[i+1] Ctr l[i+1] Test_mode rst_n rst_n ∆ (i+1) rst_n D(test) Figure 11 : Delay-Line architecture  In  the  targeted  technology  (STMicroelectronics  65nm), we have chosen to design the low-power structure  presented in Figure 11. The delay line is composed of  delay elements built with either available delay-cells or  inverter-cells (according to the required delays), and of  latches and muxes. The latches offer a good compromise  in terms of delay and energy, while filtering out all  unnecessary pulses within the delay line. Only one path  through the delay line is activated according to the  programmed binary value. In order to generate a longer  delay to obtain slow frequency in test-mode without  reducing the performance in normal mode, a unique long  path is added for test-mode. This structure is only                        implemented by standard-cells : the delay-line can be  placed-and-routed as a hard-macro and then reused for  various units. See section 7 for analysis of delay  variations.  • The SAS interface  The SAS interface contains both A-S and S-A  interfaces. The details of  implementation of  those  pausable clock interfaces are out-of-scope of this paper.  To ease the reader, we present below an overview of the  A-S interface (Figure 12). The A-S interface converts the  incoming flits from the 4-phase/4-rail ANOC protocol into  a binary synchronous flit. The ANOC Virtual Channel  priority policy is also respected within the SAS interface :  according to output availability, an incoming VC0 flit is  sent before a VC1 flit.  E_ACCEPT0_ack E_SEND[0] E_SEND_0 pen0 E_ACCEPT0, E_SEND_DATA_ack0 A – S  VC0 AFSM E_DATA [67:0] CT 0 set ta0 ri_as_0              ai_as_0  clk clk Next state Send/Accept Logic n_data[33:0] n_send[1:0] u_accept[1:0] E_SEND[1], E_ACCEPT1_ack 4R-BD as_data[33:0] Connection with Clock generator ri_as ai_as E_SEND_ack, E_DATA_ack[16:0] E_SEND_DATA_ack0 as_data[33:0] reg_data0 ri_as_1              ai_as_1  E_SEND_DATA_ack1  E_ACCEPT1,  E_SEND_1 A – S  VC1 AFSM set 0 clk ta1 pen1 reg_data0 reg_data1 reg_data1 E_SEND_DATA_ack1 Figure 12 : A-S interface  The A-S  interface  is composed of completion  detection to detect an incoming 4-rail flit, of some logic  for 4-rail to binary conversion, of two concurrent AFSMs  (one per ANOC virtual channel VC0 and VC1), of latches  to store the received asynchronous flits, and some  synchronous logic to handle the output send/accept virtual  channel protocol and to generate the pen0/pen1 toggle  signals which fire the 2 AFSMs. The AFSM behaviour is  similar to a Poll-input type port  [16]. The proposed SAS  interface handles an asynchronous flit transfer every  clock-cycle with a minimum clock pause ratio.  In terms of design, the AFSMs are synthesized using  the 3D-tool  [20] to obtain a glitch free two–level ANDOR logic. The SAS and pausable clock interface is written  as a mix of gate-level VHDL and RTL.   To conclude, the proposed Pausable Clock interface  allows to efficiently connect the synchronous unit to the  asynchronous NoC, to generate a local programmable  clock for DFS, and to re-program dynamically and  reliably the clock period during DVS phases with minimal  latency cost.  135135 5. DVFS execution at system level  Following the presentation of DVFS architecture and  design for a GALS NoC unit, we now present how this  architecture can be programmed and exploited for system  level power optimisation.  5.1. NoC units programming  Given the proposed power modes (INIT, HIGH,  LOW, HOPPING, IDLE, OFF), two execution cases are  foreseen at system level. According to power application  requirements, the software programmer can either use an  explicit way to program each IP unit using the HIGH,  LOW, IDLE, OFF modes ; or use an implicit way to  program each IP for a pre-determined average VCORE  value using the HOPPING mode. In the explicit way, the  software must configure at real time the appropriate mode  according to NoC units data flow, while in the implicit  way, the pre-programmed VCORE value is fully managed  by hardware.  At a first glance, we may consider that in the explicit  HIGH and OFF cases, the programmer will drive the  system according to strong applicative latency constraints,  while in the HOPPING, LOW and IDLE cases, the system  is driven according to stronger power budget constraints.  For the OFF mode targeting leakage reduction, special  care must be taken in software since the IP unit execution  must be completed or saved before switch-off. For switchon, the unit must be restarted by a dedicated signal and  reset.  A precise and optimised usage of the proposed power  modes obviously strongly depend on the relative power  values of the IP blocks in each mode (see section 6.2 for  some evaluations). The global power management  strategy is out of scope of this paper  [4]. For instance, the  units’ average performances can be determined thanks to  an off-line algorithm, while reducing the global energy  and respecting a global latency constraint  [4]. In the  following paragraph is presented a DVFS execution  example through simulation results.  5.2. DVFS execution example  As illustrated Figure 13, we present an example of  NoC units programming for DVFS and the corresponding  simulation results. At hard-reset, the NoC units are set in  an initial state obtained by a global reset signal. Then, the  steps are the following ones : (1) units implied in the  application are set in non-OFF mode by clearing a first  register to generate the units’ power_off signals; (2) the  corresponding units are set in INIT mode by writing a  second register to generate the units’ reset signals; (3) the  power modes and parameters of the units are programmed                    Figure 13 : Two NoC units DVFS execution example  through the NoC; (4) the configurations of the IP cores are  loaded and the execution is launched. In Figure 13  simulation example, the application implies the processing  of two NoC units. The first unit unit_1 is explicitly  controlled via NoC messages: it is firstly set in HIGH  mode, then in LOW mode after 5.7µs, and finally in IDLE  mode. On the other hand, the unit_2 unit is set in  HOPPING mode with a hopping period of 0.6µs to obtain  implicitly an average voltage value.   The presented mechanisms can be observed in this  simulation. When a new power mode is activated within  the LPM, the generated IP clocks are enabled. The  clk_pad signal (used for off-chip measurements in this  simulation), which is a divided copy of the local IP clock  clk_core,  is  started. During autonomous hopping  transitions of unit_2, we can observe that the Local Power  Manager generates the control_hop signal according to  the Hopping ratio between Vhigh and Vlow. When a  hopping transition starts, the Hopping unit is activated  (activity of its local clk_hop signal). We can observe that  the IP core clock frequency is reduced between Vhigh and  Vlow phases on the clock_pad signal. During the voltage  transitions, we can moreover observe that the unit_2 NoC  unit  still  continues  its  computations  and NoC  communications.  6. Power gain analysis  In this section, based on the ST 65nm technology, we  present some power analysis for the typical targeted  applications and the corresponding IP units  [5].  6.1. Delay line matching with unit logic  The programmable delay line and the core logic are on  the same power supply Vcore. The technology used is a  triple-Vt technology, meaning that different parts of the  circuit behave differently when the supply voltage is  lowered.  1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 LVT SVT HVT 0.8 1.0 1.2 Figure 14 : Delay Line matching wrt cells Vt  (relative frequency ratio wrt. voltage)  Figure 14 shows results of technological evaluation for  various types of logic cells. Since the delay line in the  clock generator uses mostly low-Vt cells, and the  synchronous unit critical paths also tend to be composed  of low-Vt cells, the frequency mismatch is expected to be  small. Anyway, thanks to the use of 2 registers to  configure differently the delay line when Vcore is equal to  Vhigh or Vlow (see section 3.2), any mismatch can be  compensated.  136136             550µ m 140µ m 35µ m Power-Switch                  Figure 15 : Power Supply Unit layout  Comparator D2A VDD-Hopping logic Ultra-Cut-Off 6.2. Unit power consumptions evaluation  • Total power efficiency  Lowering the supply voltage reduces both dynamic  and static power consumption. Synthesis results and spice  level simulations shows  that for Vhigh=1.2V and  Vlow=0.8V, clock speed is commonly reduced by 75%,  leakage power by 45%, and dynamic power by 88%. For a  typical synchronous unit where leakage would represent  20% of the total power, the energy per cycle is reduced  for that unit of 35% between LOW and HIGH modes.   In a multi-configuration application, when operating in  a low performance mode, the unit can be set in one of the  available power modes (IDLE, LOW or HOPPING)  chosen according to the performance constraints. For  example, an OFDM IP unit of about 300 kgates consumes  80mW@220MHz in HIGH mode, while consumes only  10mW@66MHz in LOW mode. If a reduced performance  is only required, HOPPING will save the corresponding  ratio: if 145Mhz fits the application requirements, a 50%  hopping ratio will save half the power.  6.3. Power supply efficiency  We now analyze the power efficiency of the Hopping  Unit and the complete system including external supplies.  • Hopping Unit efficiency  Outside transitions phases, losses in the hopping unit  are the sum of resistive losses in the power transistors and  leakage current in the device. Thanks to the use of a  triple-Vt technology, Power Switch leakage is less than  10 µW, which is negligible compared to unit power. The  power transistors Thigh and Tlow are sized so that the  resistive losses are less than 3 % of useful unit power.  During Hopping transitions, there are two sources of  losses [7]: the energy dissipated by the Thigh transistors  in linear mode and the dynamic consumption of the  hopping unit. Considering a linear ramp from Vhigh to  Vlow, losses in the Thigh power transistor during the  hopping transition is 18%. During transition time, hopping  unit dynamic power is about 1 mW. Given a ramp of 80ns,  a transition time of 300ns and a hopping every 2µs, the  power efficiency is raised to about 95%. There are  obvious  trade-offs: decreasing hopping  frequency  increases efficiency, and  increasing  ramp duration  decreases efficiency.  Because Vhigh and Vlow must be provided to the  circuit by external power converters, their efficiency must  also be taken into account to analyze the system total  efficiency.  State-of-the-art buck or boost DC/DC  inductive  converters  [24] using external inductors and capacitors  can provide a high-quality voltage source with an  efficiency superior to 95 % over one or two decades of  load current. For our system, that leads to a total  efficiency around 90 % over few decades. The obtained  power efficiency is then comparable to power efficiency  of recent integrated DC/DC converters  [8], but those  require external passives, which cannot be easily  integrated.  7. Power Supply Unit layout  The proposed architecture has been implemented in a  prototype called ALPIN in a 65nm STMicroelectronics  technology. Figure 15 shows the layout of the Power  Supply Unit (schematic in Figure 5) dedicated to one NoC  Unit: for instance, a 300 kgates OFDM including SRAMs.  The layout contains Thigh and Tlow Power Switches  sized to get a speed reduction less than 5%. The PSU  layout contains also analog blocks for UCO, Comparator,  Digital-to-Analog converter and Hopping Unit standard  cells. The hopping area is 140µm*35µm for a total area of  550µm*35µm. The PSU area is then only 5% of the NoC  Unit area.  8. Conclusion  In order to automatically control both dynamic and  leakage power at SoC coarse grain for embedded  applications, we have proposed a complete Dynamic  Voltage and Frequency Scaling architecture for IP unit  integration within a GALS NoC. In  the proposed  architecture, each synchronous unit is encapsulated with  its own local clock generator and local supply power unit  and can be programmed through a set of dedicated power  modes. No fine control software is required during voltage  and frequency programming and thus minimal latency cost  is observed. This DVFS architecture can be fully  integrated  in CMOS  techniques with an area cost  137137               affordable for coarse grain IP units. The power efficiency  of the complete system is evaluated close to 95%. Ongoing research works are related to system level power  modelling and optimisation strategy using this kind of  architecture.  9. Acknowledgments  This work was supported by the European Commission in  the framework of FP6 with the IST-CLEAN project (Controlling  Leakage Power in Nano CMOS SOC's) and with the Medea+  LOMOSA 2A708 project (Low-power expertise for Mobile and  multimedia system applications). Many thanks to F. Gurkaynak  (formally with ETH, now with EPFL) for valuable discussions  about pausable clock techniques and low power issues.  10. "
Statistical Approach to NoC Design.,"Chip multiprocessors (CMPs) combine increasingly many general-purpose processor cores on a single chip. These cores run several tasks with unpredictable communication needs, resulting in uncertain and often-changing traffic patterns. This unpredictability leads network-on-chip (NoC) designers to plan for the worst-case traffic patterns, and significantly over-provision link capacities. In this paper, we provide NoC designers with an alternative statistical approach. We first present the traffic-load distribution plots (T-plots), illustrating how much capacity over- provisioning is needed to service 90%, 99%, or 100% of all traffic patterns. We prove that in the general case, plotting T-plots is #P-complete, and therefore extremely complex. We then show how to determine the exact mean and variance of the traffic load on any edge, and use these to provide Gaussian-based models for the T-plots, as well as guaranteed performance bounds. Finally, we use T-plots to reduce the network power consumption by providing an efficient capacity allocation algorithm with predictable performance guarantees.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Statistical Approach to NoC Design Itamar Cohen, Ori Rottenstreich and Isaac Keslassy Department of Electrical Engineering Technion - Israel Institute of Technology {ofanan, ori.rot}@gmail.com, isaac@ee.technion.ac.il Haifa 32000, Israel Abstract Chip multiprocessors (CMPs) combine increasingly many general-purpose processor cores on a single chip. These cores run several tasks with unpredictable communication needs, resulting in uncertain and often-changing trafﬁc patterns. This unpredictability leads network-onchip (NoC) designers to plan for the worst-case trafﬁc patterns, and signiﬁcantly over-provision link capacities. In this paper, we provide NoC designers with an alternative statistical approach. We ﬁrst present the trafﬁc-load distribution plots (T-Plots), illustrating how much capacity overprovisioning is needed to service 90%, 99%, or 100% of all trafﬁc patterns. We prove that in the general case, plotting T-Plots is #P-complete, and therefore extremely complex. We then show how to determine the exact mean and variance of the trafﬁc load on any edge, and use these to provide Gaussian-based models for the T-Plots, as well as guaranteed performance bounds. Finally, we use T-Plots to reduce the network power consumption by providing an efﬁcient capacity allocation algorithm with predictable performance guarantees. 1 Introduction The multi-core era is here. Today, chip multiprocessors (CMPs) combine increasingly many general-purpose processor cores on a single chip [1–7]. As shown in Figure 1, these processor cores can be placed in regular and identical tiles, interconnected in a network-on-chip (NoC) using links and switches. Such a regular network-based design enables a lower design complexity, scalable and predictable layout properties, a high level of parallelism and modularity, and an efﬁcient statistical capacity sharing [8–13]. The processor cores in CMPs run many software processes belonging to a wide variety of possible applications, with unpredictable communication needs between the cores. As a result, the trafﬁc pattern in the NoC is une1_2  1  5  9  2 6 3  7  4  8  10 11  12  Figure 1. 3×4 NoC-based CMP architecture. certain and often-changing. The challenge is to allocate NoC link bandwidth capacities efﬁciently so as to service the many possible trafﬁc patterns, and at the same time not to use excessive link area and power — especially given that the NoC architecture consumes a signiﬁcant portion of CMP resources [1, 2, 14, 15]. Note that this capacity allocation problem is different from traditional applicationspeciﬁc systems-on-chip (ASSoCs), in which a limited set of applications is statically mapped onto the cores and generates a well-known trafﬁc pattern [16–19]. It also differs from traditional chip-to-chip multiprocessor interconnects, in which the link bandwidth capacities cannot be easily adjusted [20]. The link bandwidth capacity allocation algorithm needs to trade off the different bandwidth requirements of the many trafﬁc patterns, and the possible capacity overprovisioning. On the one hand, the usual method of sizing the network for some typical average trafﬁc pattern [13], such as a uniform trafﬁc pattern, can completely miss the widely different bandwidth demands of the other trafﬁc patterns, which appear when running different applications. On the other hand, planning for the worst case among all possible trafﬁc patterns [3, 21–23] can potentially necessitate signiﬁcant link bandwidth capacities that are rarely fully utilized and consume expensive power resources. In fact, such a scheme does not fully exploit the statistical mul978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.23 DOI 10.1109/NOCS.2008.23 171 171         tiplexing properties of the NoC, which are increasingly signiﬁcant as the number of cores increases. The main contribution of this paper is the introduction of a statistical approach to NoC design and capacity allocation. To do so, we introduce a novel method to represent and analyze the full spectrum that lies between the average and the worst-case trafﬁc patterns. Then, we argue that the NoC designer should consider the tradeoff between link capacity and performance guarantee, where the performance is measured by the fraction of trafﬁc patterns that can be fully served. For instance, the NoC designer should know that instead of some worst-case capacity allocation in which the NoC can guarantee service to 100% of trafﬁc patterns, some other statistical capacity allocation can guarantee service to 99.99% of trafﬁc patterns in exchange for a reduction in the total link capacity. It is then up to the NoC designer to determine whether the 0.01% of trafﬁc patterns are worth this additional capacity and the necessary additional power resources. To support our statistical approach, we introduce the TPlots, or Trafﬁc Load Distribution Plots — a class of plots illustrating the distribution of the load generated by the set of trafﬁc patterns, and providing a synthetic view of the network performance. For instance, Figure 2 illustrates such a T-Plot, showing the distribution of the normalized load on edge e6 7 . The T-Plot is generated using the set of all trafﬁc patterns in the CMP, and the graph is of course normalized so that the area below it sums up to 1 (other simulation details are in Section 9). As shown in the T-Plot, the average load generated on this link is 0.94. Further, the worst-case load can be found to be exactly 2 (with a negligible density), and the 99.99%-cutoff load is a bit below 1.59. In other words, this T-Plot shows that when the link capacity equals 21% less than the worst-case load, 99.99% of the trafﬁc patterns can already be serviced. Thus, using this T-Plot, a NoC designer can directly evaluate the performance of a capacity allocation scheme, and clearly see the tradeoff between performance guarantee and capacity overprovisioning. The NoC designer might decide, for instance, that the marginal beneﬁt of allocating more capacity beyond 1.59 is not worth the cost. Incidentally, note that this T-Plot can be closely modeled as Gaussian – the paper will later expand on this point. In this paper, we demonstrate that the exact computation of T-Plots is #P-complete, and therefore without known polynomial-time algorithms. We later show how to practically approximate T-Plots using random-walk-based methods, and how to analytically calculate the mean and the variance of the edge loads in a combinatorial way. We further show that knowing the mean and the variance is often sufﬁcient to approximate the whole distribution, as the edge T-Plots may be frequently closely modeled as Gaussian. We also suggest some simple bounds and models for the 2.5 2 1.5 F D P 1 0.5 0 0 Simulations Gaussian Model 0.5 Edge Congestion 1 1.5 Figure 2. Edge congestion PDF T-Plot on e6 7 global T-Plot, which models the performance of the whole network. Finally, we suggest a very simple, yet efﬁcient, capacity allocation algorithm with predictable performance guarantees. We would like to stress that in our view, a key aspect of this statistical approach is its potential for a wide range of applications, including in non-CMP NoC-based architectures. For instance, while not applicable to simple ASSoCs with a single trafﬁc pattern, the statistical approach can be highly useful for more complex ASSoCs with dozens of basic use-cases and potentially thousands of compound usecases [24, 25]. Likewise, the statistical approach can be used in NoC-based FPGAs to allocate the available bandwidth capacity of the higher-performance hard-wired nonprogrammable links, thus providing the designer with performance guarantees for a signiﬁcantly large number of trafﬁc patterns [26]. Finally, the statistical approach can be combined with other approaches to provide quality-ofservice (QoS) guarantees, for instance by using worst-case analysis for high-priority control and delay-sensitive trafﬁc, and statistical analysis for the remaining best-effort trafﬁc [13, 27]. This work is structured as follows. After formulating the T-Plot model in Section 2, we prove its #P-completeness in Section 3. Then, in Sections 4 and 5, we provide a Gaussian view of the edge T-Plots as well as strict performance guarantees, and generalize these results to global T-Plots in Section 6. Finally, in Sections 7 and 8, we introduce a simple capacity allocation scheme, which we evaluate, together with the other results, in Section 9. 2 T-Plot model Network – The NoC architecture is modeled as a directed graph G(V , E ) with n=|V | nodes (processor cores) and |E | edges (links). For instance, Figure 1 illustrates such a graph with 12 nodes (each corresponding to a processor core and its associated switch), and 34 edges between them. 172172     In this paper, we consider a normalized homogeneous CMP in which each processor core works at the same frequency and can send (receive) at most one data word every clock cycle, but we do not make any assumption on the destination (source) of its trafﬁc (see [3, 21–23] for more details on this standard model). Therefore, the possible set A of trafﬁc matrices in the NoC, called the T-Set A, is deﬁned as A = ⎩D|∀i : Dij ≤ 1, Dj i ≤ 1 (1) j j ⎧⎨ (cid:5) (cid:5) ⎫⎬ ⎭ (cid:11) (cid:9) (cid:10) D|∀i : (cid:10) j Dj i ≤ ri j Dij ≤ qi , For example, assuming a data width of 32 bits and a frequency of 200 MHz, we get a maximum input/output rate of 32 ∗ 200/8 = 800 MByte/s for each processor core of the network, and the T-Set A is the set of all the possible trafﬁc matrices that respect this maximum. We can generalize the results to different T-Sets. For instance, in a general heterogeneous NoC architecture, node i may send (receive) trafﬁc at any rate up to qi (ri ), and we will consider the T-Set H deﬁned as H = . Likewise, we will consider the set P of permutation trafﬁc matrices, in which each processor core transmits (receives) at maximum rate to (from) a unique processor core. Given a T-Set, we will assume that any trafﬁc matrix in a T-Set is always equally likely (though adding weights to speciﬁc subsets can of course easily be done if needed). We will also assume that each edge e is allocated a positive capacity c(e) > 0. An edge e is a strictly minimal edge if c(e(cid:2) ) > c(e) for each edge e’ different from e, and a bridge if removing e would increase the number of components in the graph. Routing – A routing is classically deﬁned as a set of (n2 |E |) variables {fij (e)}, where fij (e) denotes the fraction of the trafﬁc from node i to node j that is routed through edge e. In other words, the total ﬂow crossing e when routing the trafﬁc matrix D is (i, j )th element of matrix D . Such a routing is oblivious in the sense that the routing variables are independent of the current trafﬁc matrix. The routing is assumed to satisfy the classical linear ﬂow conservation constraints [28]. An example of routing scheme is dimension-ordered routing (DOR) [29], also called XY routing, a simple NoC mesh routing algorithm in which packets are routed along one dimension ﬁrst and then along the next dimension (we assumed an ”X then Y” routing). Further, when the T-Set is A, the most loaded edge is the edge e that maximizes Congestion – The edge congestion (or load) on edge e is equal to the total ﬂow crossing it divided by the edge i,j Dij fij (e), where Dij is the ij fij (e). (cid:10) (cid:10) capacity, i.e. EC (e, f , D) = (cid:10) i,j Dij fij (e) c(e) (2) When the edge congestion on e is at least 1, we will say that e is saturated. Further, a network is saturated if at least one edge in it is saturated. The global congestion of routing D using f will be obtained by maximizing the edge congestion over all the edges, that is: GC (f , D) = max e∈E {EC (e, f , D)} (3) For a saturated network, the throughput is deﬁned as the inverse of the global congestion, and is otherwise made not to exceed 100%: T P (f , D) = min{GC (f , D)−1 , 1} T-Plot – Edge (global) T-Plots show the distribution of the edge (global) congestion generated by trafﬁc matrices in the T-Set. T-Plots can be represented as plots of the cumulative distribution function (CDF) or the probability density function (PDF). For example, the value of the edge T-plot CDF at point L is the probability that the edge congestion imposed on that edge by a trafﬁc matrix selected from the T-Set T would be at most L: (4) EC T CDF (e, f , L) = Pr {EC (e, f , D) ≤ L|D ∈ T } (5) 3 T-Plots are #P-complete We will now prove that computing the T-Plots is #Pcomplete [30], which implies that it cannot be done using any known polynomial-time algorithm. Intuitively, #P-complete problems are hard counting problems without known polynomial-time solution, in the same way as NP-complete problems are hard decision problems without known polynomial-time solution. In fact, NP is a subset of #P, and therefore #P-complete problems are at least as hard as NP-complete problems: while a typical NP-complete problem is to decide whether there exists at least one solution, the related #P-complete problem is to count the number of solutions, which typically makes it quite harder. We will ﬁrst show the #P-completeness for edge T-Plots, and then as well for global T-Plots. We refer interested readers to [31] for more formal deﬁnitions and complete proofs of all the theorems in this paper. Theorem 1 When the T-Set is the set of permutations P , ﬁnding the edge T-Plot of a non-bridge edge e is #Pcomplete. Corollary 1 In the general case, ﬁnding the edge T-Plot is #P-complete. 173173 Theorem 2 When the T-Set is the set of permutations P , ﬁnding the global T-Plot of a graph that includes a strictly minimal edge is #P-complete. Corollary 2 In the general case, ﬁnding the global T-Plot is #P-complete. Since exact T-Plot computation proves elusive, we can only try to approximate or bound it. This will be a recurring theme in this paper. 4 Exact mean and variance of edge T-Plots We just proved that in the general case, computing edge T-Plots is #P-complete, and therefore extremely complex. Thus, we will strive to look for good approximations and bounds. We will now present a straightforward method to calculate the mean and variance of the edge congestions. This will enable us to obtain an overview of the network bottlenecks without running extensive simulations. Furthermore, we will later see that these values will be enough to provide both a Chebyshev-based deterministic bound (Section 5) and a Gaussian-based model (Section 7). Let’s illustrate the computation of the mean and variance of the edge congestion when the T-Set is the set of permutations P . In this case, the average-case edge congestion on edge e using routing f is: EC P ac (e, f ) = 1 n! EC (e, f , D) (cid:5) (cid:5) D∈P (cid:10) 1 n! D∈P 1 n!c(e) 1 (cid:5) (cid:5) ij nc(e) ij = = = ij Dij fij (e) c(e) (cid:5) D∈P fij (e) fij (e), Dij (6) where the last equality relies on the fact that a given ﬂow (i, j ) is only used in 1 th of the permutations. Likewise, the variance is calculated using the variance formula n V arD∈P [EC (e, f , D)] = E [EC 2 ] − E 2 [EC ], (7) with (cid:10) E [EC 2 ] = (cid:12)(cid:10) ijkl fij (e)fkl (e) n!c(e)2 D∈P Dij Dkl (cid:13) , (8) where the expectations are with respect to the random variable D ∈ P and the parameters of EC are implicit. Using 174174 basic combinatorial considerations, (cid:5) D∈P Dij Dkl = ⎧⎪⎪⎨ ⎪⎪⎩ (n − 1)! (n − 2)! 0 0 i = k ∧ j = l i (cid:7)= k ∧ j (cid:7)= l i = k ∧ j (cid:7)= l i (cid:7)= k ∧ j = l (9) The assumptions above can be relaxed and the computation of the mean and variance can be generalized to other T-Sets (see [31] for more details). In the next section, we will show how the mean and variance of the edge congestions can provide us with deterministic congestion guarantees. 5 Congestion guarantees for edge T-Plots We are interested in providing performance bounds that are guaranteed independently of the shape of the edge TPlot. We will now show that it is indeed possible to bound the probability that the congestion on some edge exceeds a given value. Let X denote the congestion imposed on a given edge e by a trafﬁc matrix D generated from the T-Set. Further, let μ and σ be the average and standard-deviation of the edge congestion on e . Then, by Chebyshev’s one-tailed inequality with k ≥ 0, P r(X ≥ μ + kσ) ≤ 1 (10) By deﬁnition, e is saturated iff X ≥ c(e). Therefore, the probability for e to be saturated is upper-bounded as follows: 1+k2 P r(X ≥ c(e)) ≤ (cid:15) 1 c(e)−μ σ (cid:16)2 1+ (11) Alternatively, given a desired congestion guarantee level G, it is possible to calculate a capacity c’(e) that guarantees that at least a fraction G of the allowable trafﬁc matrices would be served without saturating e. Transforming Equation (11), we get: (cid:17) c(cid:2) (e) = μ + σ G 1 − G (12) For instance, for G = 99%, we need c(cid:2) (e) = μ + 9.95σ ; i.e., with this edge capacity, we are guaranteed that at least 99% of the matrices can be served without saturating e. Example – Figure 3(a) provides an example of CDF T-Plot of an edge congestion. It is compared with the Chebyshev-based deterministic guarantee presented above, as well as a Gaussian-based model (as developed in Section 7). This plot was obtained on edge e6 7 in the 3 × 4 mesh of Figure 1, using DOR routing. It is a CDF plot, corresponding to the PDF plot of Figure 2. 1 0.8 F D C 0.6 0.4 0.2 0 Simulations Gaussian Model Chebyshev Lower Bound 0.5 1 Edge Congestion 1.5 (a) Edge congestion CDF 1 0.8 F D C C 0.6 0.4 0.2 0 0 Simulations Gaussian Model Chebyshev Lower Bound 0.2 0.4 0.6 Throughput 0.8 1 (b) Edge throughput CCDF Figure 3. Two views of the same T-Plot (edge e6 7 in the 3×4 mesh) As seen in Figure 3(a), the Chebyshev-based deterministic congestion guarantees are rather far below the simulated CDF. This is because the Chebyshev inequality is known to be a very loose bound. On the contrary, in this case, the Gaussian model does very well for this edge, to the point that the plots of the congestion and its Gaussian model can barely be distinguished. For instance, consider an edge congestion of 1.25 (on the x-axis): as shown by simulations, 96% of the matrices cause an edge congestion under this value. By contrast, the Chebyshev-based deterministic approach only guarantees that at least 76% of the matrices will be under this value. In the same way, the same T-Plot can also be represented as the CCDF (Complementary CDF) of the throughput, as seen in Figure 3(b). Again, a throughput of at least 1.25 = 80% is provided to 96% of the matrices on this edge, while the Chebyshev-based performance bound can only guarantee this for 76% of the matrices. 1 6 Model and bounds of global T-Plots So far, we have mainly dealt with edge congestions. We will now deal with global congestions. Of course, succeeding to well approximate the global T-Plots would mean obtaining a performance model for the whole network. We will ﬁrst provide a simple model assuming independence, and then an upper-bound. 6.1 Edge-independent and independentGaussian models Assuming that all edge congestions are independent, i.e. trafﬁc matrices cause congestion at different links in an independent manner, provides the following edgeindependent model: 175175 GCCDF (f , L) = Pr (cid:18) (cid:20) (cid:20) e∈E e∈E ≈ = e∈E max [EC (e, f , D)] ≤ L Pr (EC (e, f , D) ≤ L) ECCDF (e, f , L) (cid:19) (13) This edge-independent model is not always a good approximation, because matrices often cause loads in a positively correlated way. However, it plays the role of an intuitive lower bound (though it can be shown that it is not always a lower bound). Further, this model can be extended to an even simpler independent-Gaussian model, in which the distributions of all edge congestions are assumed to be Gaussian. In Section 4, we determined their exact average and standarddeviation at each edge e, denoted μ(e) and σ(e). Therefore, this model is fully and exactly determined: (cid:18) (cid:20) e∈E Φ (cid:19) L − μ(e) σ(e) , (14) GCCDF (f , L) ≈ where Φ denotes the normalized Gaussian CDF. In the simulations section, we will show that the independentGaussian model performed surprisingly well. 6.2 Global upper bound Let’s now look for an upper bound on the CDF T-Plot of the global congestion. The global congestion is the maximum edge congestion across all edges, and therefore it is at least as large as the congestion of the most loaded edge in the network. Thus, we get the following upper bound on the probability of not being congested: GCCDF (f , L) ≤ min {ECCDF (e, f , L)}. (15) e∈E         Further, if e1 and e2 are two edges (e.g. the two most loaded edges in the network, which could be the two different directions of the same link), then: P r(GC > x) ≥ P r(EC (e1 ) > x ∨ EC (e2 ) > x) = P r(EC (e1 ) > x) + P r(EC (e2 ) > x) − P r(EC (e1 ) > x ∧ EC (e2 ) > x) ≥ P r(EC (e1 ) > x) + P r(EC (e2 ) > x) − P r(EC (e1 ) + EC (e2 ) > 2x), (16) where P r(EC (e1 ) + EC (e2 ) > 2x) is equal to 1 − ECCDF (ˆe, 2x), using a dummy edge ˆe for which f (ˆe) = f (e1) + f (e2 ). Using ˆe, a similar upper bound can be obtained as follows: P r(GC ≤ x) ≤ P r(EC (e1 ) ≤ x ∧ EC (e2 ) ≤ x) ≤ ECCDF (ˆe, 2x) (17) A stricter global upper bound may ﬁnally be deﬁned as the minimum of the three bounds (15), (16) and (17). 7 Capacity allocation for edge T-Plots Our goal is now to propose a simple, yet efﬁcient, statistical capacity allocation algorithm, which would enable signiﬁcant savings in the total capacity, yet achieve full service for the vast majority of the trafﬁc patterns in the CMP. We ﬁrst explain in this section how our statistical approach enables to dramatically decrease the capacity of a given edge with only a negligible effect on the throughput on that edge. In the next section, we show that our global capacity allocation scheme is optimal in CMP architectures that obey some simplifying assumptions. Finally, the simulations in Section 9 suggest that the capacity allocation scheme is close to optimal in reference CMP architectures as well. 7.1 Gaussian model We will now prove that when scaling a speciﬁc CMP mesh-based architecture, a statistical design allows cutting the edge capacity by almost 50%, while still guaranteeing full service with probability arbitrarily close to 1. To do so, we will ﬁrst show that the normalized edge T-Plot is asymptotically Gaussian. Consider an m × m mesh with DOR routing. Assume that the T-Set T is deﬁned such that the processes of core i send trafﬁc to any of the other m2 − 1 cores j according to some uniform i.i.d. distribution. The uniform distribution is taken so that any core does not exceed its normalized maximum input/output rate of 1 word per clock-cycle: for D ∈ T , (cid:18)(cid:21) (cid:22)(cid:19) ∀i (cid:7)= j, Dij ∼ U nif orm 0, 1 m2 − 1 . (18) 176176 Consider some edge e in the mesh. Let’s denote by s the number of (source, destination) ﬂows crossing e using DOR routing, and further denote the average, standard-deviation and maximum of the ﬂow on edge e by μ, σ and w. By Equation (18), it is clear that the maximum ﬂow generated by each (source, destination) pair is m2−1 , and therefore m2−1 . Likewise, using independence and summation rules of the expectation and variance, μ = w 2 and w = s 1 √ σ = √ s 12(m2−1) . A worst-case deterministic approach would allocate a capacity equal to the maximum possible edge ﬂow: c(e) = w. We will now show that as we scale the CMP, the edge ﬂow distribution becomes extremely concentrated around its average μ = w 2 . Therefore, by following a statistical design and allocating a capacity just above this average, we can gain nearly 50% capacity with a loss probability going to zero. To prove this, we will ﬁrst demonstrate that modeling the edge T-Plot as Gaussian is asymptotically correct in this CMP architecture. While this model is not necessarily correct in all architectures, we will later use it to analyze capacity allocation schemes. We remind that interested readers can refer to [31] for the complete proofs of all the theorems in this paper. Theorem 3 As m grows and we scale the CMP architecture, the normalized edge T-Plot of any edge e converges to the normalized Gaussian distribution N (0, 1). 7.2 Statistical capacity allocation σ k(m) = c(e)−μ Denote by Φ(x) the normalized Gaussian CDF, and let . Then a consequence of Theorem 3 is that the percentage of trafﬁc matrices that do not saturate edge e (i.e. such that the ﬂow on e is at most c(e)) converges to Φ(k(m)) = Φ((c(e) − μ)/σ) as m increases. For instance, of the matrices do not saturate e. Since Φ−1 (0.99) = 2.33, suppose that we would like to guarantee that at least 99% it sufﬁces to allocate capacity c(e) = μ + 2.33σ , rather than allocating the worst-case capacity c(e) = w = 2μ. Asymptotically, we can gain up to 50% capacity if σ/μ goes to zero when m goes to inﬁnity. In fact, the theorem below shows that having a capacity allocation barely above 50% of the worst-case capacity is enough to guarantee any level of performance guarantee on edge e as we scale m. ( 1 Theorem 4 For any small  > 0, any edge e, and any guaranteed probability G < 1, having an edge capacity of 2 + ) of the worst-case link capacity and m large enough is sufﬁcient to guarantee full service on edge e for a fraction G of all trafﬁc matrices. 8 Capacity allocation for global T-Plots 9.2 Global T-Plot Let’s denote by ci the capacity of edge i, and by μi , σi the mean and standard deviation of the load on edge i, respectively. We now suggest to allocate to edge i a capacity of ci = μi + kσi , where we use the same value of k for all edges. Therefore, the total capacity C required as a function of k is: |E |(cid:5) |E |(cid:5) |E |(cid:5) C = ci = μi + k σi , (19) i=1 i=1 i=1 or, equivalently, for a given total capacity C , we need to use k = C − (cid:10)|E | (cid:10)|E | i=1 μi i=1 σi . (20) Note that when the total capacity is constrained to be smaller than the sum of the average-case edge congestions, k is negative. The following theorem demonstrates that this capacity allocation minimizes the probability that the network is saturated, in any NoC with any topology and any routing, as long as two approximation assumptions hold: ﬁrst, the loads on different edges are independent; and second, the edge T-Plots obey a Gaussian model with the same standarddeviation. Theorem 5 Assume that the T-Plots of all edges i are independent and Gaussian of mean μi and same standarddeviation σ . Then allocating to each edge i a capacity ci = μi + kσ , where k is a real constant, minimizes the probability that the network is saturated. In the simulations, we will evaluate the performance of this capacity allocation algorithm in NoC architectures. 9 Simulations 9.1 T-Set representation To perform simulations, we need the ability to represent the T-Set. We proved above that this is intrinsically hard (Theorem 1). Therefore, we want to pick trafﬁc matrices uniformly at random from the T-Set in order to approximate their full representation – and to do so, we use random-walk sampling. In the simulations below, sampling is always done using one million samples, unless mentioned otherwise. It is also assumed that nodes don’t send trafﬁc to themselves. Interested readers can refer to [31] for a full description of the random walk procedure, as well as to why it should intuitively converge towards the T-Plot. 177177 We already saw simulation results of edge congestion TPlots in Figures 2 and 3. Let’s now look at global congestion T-Plots, which show the distribution of the maximum load across all edges. In Figures 4(a), 4(b), and 4(c), we analyze several parameters of the global congestion T-Plots for the 3x4 mesh. First, Figure 4(a) shows the PDF of the global congestion, with the routing algorithm being either DOR or O1TURN [32]. The graph shows that O1Turn does a much better job than DOR in load-balancing the load across different links, and thus has less chances of reaching high link loads (for instance, the area under the PDF to the right of 1.4 is much smaller in O1TURN). Additionally, both graphs are well ﬁtted to Gaussians. Note that here, contrarily to all other places, we ﬁtted the Gaussian distribution without using a-priori models, as we don’t have an analytical model for the mean and variance of the global congestion. In addition, note that the maximum of many i.i.d. Gaussian random variables does not behave as a Gaussian random variable (it follows a Gumbel distribution [33]), and thus one must be careful with the conclusions taken from this plot. Figure 4(b) shows the CDF of the global congestion in the same network, using DOR routing. The independentGaussian model and the upper bound are presented in Section 6. We can see that the independent-Gaussian model assuming independent edge congestions with Gaussian distributions is rather close to the exact results. The upper bound, however, is rather loose, which is explained by the fact that it is based on the two most loaded edges in the network, while our network contains many other highlyloaded edges, which may raise the global congestion. Other simulations (not shown here) show that this upper bound is stricter in networks in which there exist only very few highly-loaded edges. Figure 4(b) can be used to determine the required capacity overprovisioning: for instance, the CDF for a global congestion of 1 is 0.053. Therefore, without overprovisioning, only 5.3% of the trafﬁc matrices in the T-Set would be fully served. Since the CDF for a global congestion of 1.2 is 0.604, an overprovisioning of 20% would guarantee that 60.4% of the trafﬁc matrices would be fully served. 9.3 Capacity allocation algorithms Until now, all of our T-Plots were realized without doing any optimization, by simply measuring the distribution of the link load. We will now show that our statistical approach using T-Plots can do more than just measure: it can also help optimize. pacity allocation (CA) algorithms on the 3×4 mesh network Figure 4(c) illustrates the performance of different caF D P 4 3 2 1 0 0 DOR Simulations DOR Fitted Gaussian O1TURN Simulations O1TURN Fitted Gaussian 1 0.8 F D C 0.6 0.4 1.5 0.2 0 0.5 0.5 1 Global Congestion 1 0.8 0.6 0.4 0.2 F D C 2 0 20 30 Homogeneous CA Suggested CA Optimized CA 40 50 Total Capacity 60 Simulations Independent−Gaussian Model (Intuitive Lower Bound) Upper Bound 1 1.5 Global Congestion (a) Global congestion PDF: DOR vs O1TURN (b) Global congestion CDF: model and bound (c) Global congestion CDF: CA schemes Figure 4. Global congestion T-Plots for the 3x4 mesh with 34 edges (presented in Figure 1). For each total capacity, it shows the fraction of matrices that would be served under a given CA algorithm. It compares three CA algorithms: the homogeneous CA assumed above, the simple CA based on means and variances suggested in Section 8, and an optimized CA explained below. For instance, assume that the average capacity per edge is 1.2, i.e. the total capacity is 1.2 · 34 = 40.8. The homogeneous CA algorithm would allocate a capacity of exactly 1.2 to each edge. It would only be able to service 60.4% of the matrices (as seen above as well with Figure 4(b)). On the contrary, our simple CA scheme suggested in Section 8 would distribute the total capacity differently among the edges, according to their congestion average and variance. With this total capacity of 40.8, it would be able to service 96.4% of the matrices, hence improving noticeably on the homogeneous scheme. Finally, to examine the quality of our simple capacity allocation scheme, we compare it to an optimized CA, which was obtained after extensive brute-force simulations. Using this optimized CA, we can service 99.2% of the matrices, hence slightly improving on our simple suggested CA. In fact, the plot suggests that out simple suggested heuristic CA is not too far from optimum. Note that to obtain this optimized CA, we ran 10,000 iterations for each total capacity value. At each iteration, a new CA is taken at the neighborhood of the old one using a Gaussian ball-walk algorithm, and is only accepted if it fares better [31]. The optimization was done using 200,000 sample matrices from A, and the results were computed on 200,000 different matrices. We also checked that starting from different points yields the same end result. 9.4 Capacity allocation and throughput guarantee We will now exemplify how our statistical approach enables a drastic capacity saving with only negligible deterioration in performance. y t i c a p a C l a t o T 60 50 40 30 20 10 0 100% 99.99% 99.9% 99% 90% CA Performance Target Figure 5. Total capacity required for various CA targets Figure 5 compares the total capacities needed by the opin the 3 × 4 mesh. The ﬁrst bar represents a worst-case aptimized CA algorithm with 5 different performance targets, proach, in which each edge is allocated a capacity according to the worst-case ﬂow on this edge, thus guaranteeing that 100% of trafﬁc matrices will be fully served. It is loosely based on the worst-case approach adopted in [3, 21, 22]. On the contrary, the other bars represent the statistical approach, with increasingly loose levels of statistical-based capacity allocation schemes. Their values can be retrieved from Figure 4(c). For instance, for G = 99.9%, the amount of provisioning needed is CDF −1 (0.999) = 43.8. Figure 5 shows that switching from a worst-case to a statistical CA approach may save up to 37% of the total required capacity in this network, for a capacity guarantee at a 90% level. Likewise, planning for a very stringent 99.99% cutoff decreases the amount of total capacity used by 21%. As an aside, note that we didn’t even compare with the naive homogeneous worst-case approach – such a comparison would have yielded even greater savings! 178178               1 0.8 0.6 F D C 0.4 0.2 0 0 Homogeneous CA Suggested CA  Optimized CA 20 40 Total Capacity y t i c a p a C l t a o T 90 80 70 60 50 40 30 20 10 0 60 100% 99.99% 99.9% 99% CA Performance Target 90% (b) Global congestion CDF: CA schemes (c) Total capacity required for various CA targets Figure 7. NUCA network: topology and performance Homogeneous CA 1.2. As expected, our CA scheme has signiﬁcantly less trafﬁc matrices with inﬁnite average ﬂow delay; in addition, on the remaining matrices, the average ﬂow delay also tends to be lower. Thus, this plot conﬁrms that our simple CA tends to signiﬁcantly outperform the homogeneous CA. 0−10 10−20 20−3030−40 40−50 50−6060−70 70−80 >80 Infinite Delay Suggested CA 9.6 NUCA network  P0   P1   P2   P3   P4   P5   P6   P7   P8   P9  P10  P11  P12  P13  P14  P15  (a) NUCA architecture (based on [34] with sharing degree 4) y t i l i b a b o r P y t i l i b a b o r P 0.6 0.4 0.2 0 0.6 0.4 0.2 0 0−10 10−20 20−3030−40 40−50 50−6060−70 70−80 >80 Infinite Delay Average Flow Delay Figure 6. Average ﬂow delay distribution over all trafﬁc matrices, for two different CA schemes 9.5 Delay distribution Our objective is to obtain some intuition on the different distributions of the expected ﬂow delays using different CA algorithms. In order to do so, we model the delay at each edge with the simple M/M/1 model, using an arrival rate equal to the edge ﬂow and a service rate equal to the edge capacity. (Of course, this is just a toy model: the deterministic nature of the services would probably decrease the average delays, and the wormhole scheduling [20] would increase them.) The average delay of a ﬂow is the sum of its average edge delays. Finally, for each given trafﬁc matrix, we compute the average ﬂow delay across all ﬂows. Note that a saturated edge results in an inﬁnite edge delay, and therefore an inﬁnite average ﬂow delay. Figure 6 compares the distributions of the average ﬂow delays for both the homogeneous CA and our simple suggested CA, for the 3 × 4 mesh with average edge capacity 179179 Finally, we considered a different CMP architecture model based on a NUCA (non-uniform cache architecture) network. As shown in Figure 7(a) (based on [34] with sharing degree 4), the network contains 4 sub-networks, each with 4 processor cores and 16 caches, hence with a total number of 80 nodes and 224 edges. Each core may only send (receive) trafﬁc to (from) caches in its sub-network, and each cache may only send (receive) trafﬁc to cores in its sub-network, with a maximum node transmission (reception) rate of 1. Figure 7(b) compares the different CA schemes on this NUCA network (simulated using 100,000 samples). For example, with a total capacity of 50, using our suggested CA dramatically increases the probability that the NUCA network is not saturated from less than 1% to 98%. Again, it is very close to the optimized envelope. Likewise, Figure 7(c) shows that the total capacity required to fully serve 99.99% of the matrices is lower than the total capacity in the worst-case approach by 24%, and in the 90% cutoff case by 48%. Thus, this conﬁrms the intuition that as networks grow in size, the gains in the statistical approach tend to grow as well - intuitively conﬁrming Theorem 4 as well. 10 Conclusion In this paper, we introduced the T-Plots, which can provide a common foundation to quantify, design, optimize                                                           and compare NoCs architectures and routing algorithms. We showed that an accurate computation of T-Plots is #Pcomplete, but that they can sometimes be modeled as Gaussian, providing a full link load distribution model using only two variables. Further, we provided bounds that can be the basis of strict throughput performance guarantees. We ﬁnally showed how T-Plots can be used to develop a simple, yet efﬁcient, capacity allocation scheme. We believe and hope that this work will contribute to lay the ground to a common basis in future NoC design research. "
SEU-Hardened Energy Recovery Pipelined Interconnects for On-Chip Networks.,"Pipelined on-chip interconnects are used in on-chip networks to increase the throughput of interconnects and to achieve freedom in choosing arbitrary network topologies. Since reliability and energy consumption are prominent issues in on-chip networks, they should be carefully considered in the design of pipelined interconnects. In this paper, we propose the use of energy recovery techniques to construct low energy and reliable pipelined on-chip interconnects. The proposed designs have been evaluated using detailed SPICE simulations. In the reliability analysis, the SEU fault model is considered as it is a major reliability concern in the sequential circuits (pipelining memory elements) implemented in DSM technologies. The experimental studies show that the proposed energy recovery designs can be used to reduce the energy consumption by about 30% while provide a better reliability (comparable to what is achievable from fault tolerance techniques) as compared to conventional pipelined interconnects.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip SEU-Hardened Energy Recovery Pipelined Interconnects for On-Chip Networks  Alireza Ejlali  Department of Computer Engineering  Sharif University of Technology,  Azadi Ave., Tehran, Iran  ejlali@sharif.edu  Bashir M. Al-Hashimi  School of Electronics and Computer Science  University of Southampton,  Southampton, SO17 1BJ, UK   bmah@ecs.soton.ac.uk  Abstract  Pipelined on-chip interconnects are used in on-chip  networks to increase the throughput of interconnects  and to achieve freedom in choosing arbitrary network  topologies. Since reliability and energy consumption are  prominent issues in on-chip networks, they should be  carefully considered in the design of pipelined  interconnects. In this paper, we propose the use of  energy recovery techniques to construct low energy and  reliable pipelined on-chip interconnects. The proposed  designs have been evaluated using detailed SPICE  simulations. In the reliability analysis, the SEU fault  model is considered as it is a major reliability concern  in the sequential circuits (pipelining memory elements)  implemented in DSM technologies. The experimental  studies show that the proposed energy recovery designs  can be used to reduce the energy consumption by about  30% while provide a better reliability (comparable to  what is achievable from fault tolerance techniques) as  compared to conventional pipelined interconnects.  1. Introduction  On-chip networks have emerged to deal with the  increasing complexity and communication requirements  of SoCs [1]. In on-chip networks, it is common to  pipeline interconnects by inserting pipelining flip-flops  that partition each interconnect into consecutive stages  [2,3]. The use of pipelining decouples the throughput of  on-chip interconnects from their length, thereby giving  more freedom to designers to choose arbitrary  topologies for their on-chip networks [2]. However, we  believe that pipelining has a negative impact on the  reliability of on-chip interconnects. The reliability of onchip interconnects (without considering pipelining) is  one of the major concerns in today's deep sub-micron  (DSM) technologies [8], and the use of pipelining flipflops can aggravate the reliability problem, because it  has been observed that in DSM technologies the flipflops are very susceptible to single event upsets (SEUs)  (bit-flips due to the impact of particles on flip-flops) [9].  Some attempts have been made to address the reliability  problem of on-chip interconnects (e.g., [5,6,7,8]).  However, most of these works have not considered the  reliability of pipelining flip-flops.  The energy consumption of on-chip interconnects is  another prominent issue in on-chip networks, as up to  50% of the total on-chip energy may be consumed by  on-chip interconnects [10]. It has been observed that the  techniques that are used to improve the reliability of onchip interconnects have negative impacts on the energy  consumption. Conversely, the techniques that are used  to reduce the energy consumption of on-chip  interconnects have negative impacts on the reliability  [7,8,11]. In this paper, we present specialized energy  recovery designs which can be used in pipelined on-chip  interconnects to achieve both low energy consumption  and reliability against SEUs at the same time.  Traditional energy recovery logic styles [12,13,14] have  been used to reduce switching energy. Due to the trends  in DSM technologies, the contribution of the switching  energy to the total energy consumption of processing  blocks (IP-cores) is decreasing as compared to the static  energy [15]. However, the switching energy of on-chip  interconnects is becoming a considerable issue in onchip networks [10], therefore the use of energy recovery  techniques can be very useful for on-chip interconnects.  The use of energy recovery techniques for long wires  has been proposed in [16,17]. However, these works  have considered neither the reliability issues nor  pipelined interconnects in on-chip networks. We will  also discuss in Section 5 that traditional energy recovery  logic styles [12,13,14] are not suitable to be used for  pipelined on-chip interconnects and our proposed energy  recovery designs are more suitable. To analyze the  reliability and energy consumption of the proposed  techniques, detailed SPICE simulations and faultinjection experiments were done. The experiments show  that the proposed energy recovery designs can be used to  achieve up to 30% energy saving (compared to  conventional pipelined interconnects) and at the same  time achieve reliability comparable to sophisticated fault  tolerance techniques like those proposed in [18]. While  these fault tolerance techniques [18] are very effective in  improving the reliability, it has been shown that they  have considerable negative impacts on the energy  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.15 DOI 10.1109/NOCS.2008.15 67 67             consumption [4]. The experimental and analytical  studies also show that the energy saving of our proposed  technique can be improved by increasing the depth of  pipelining (number of pipeline stages).  To the best of our knowledge this paper is the first  attempt to show that energy recovery designs can be  used in pipelined on-chip interconnects to achieve both  low energy consumption and reliability against SEUs at  the same time.  The rest of the paper is organized as follows. Section  2 provides a brief overview of the principle of energy  recovery. Section 3 discusses the basic concept of  energy recovery pipelined interconnects, and explains  why the use of energy recovery techniques can be useful  for pipelined on-chip interconnects. In Section 4, we  explain our proposed energy recovery designs for  pipelined on-chip interconnects. In Section 5, we present  the experimental results and compare the proposed  pipelined on-chip interconnects with the conventional  pipelined on-chip interconnects. Finally, Section 6  concludes the paper.  2. Principle of energy recovery  Conv VC 2 DDL E =                   (1)  In a conventional CMOS logic gate a load capacitance  CL is charged to VDD via a PMOS network and  discharged to GND via an NMOS network. During the  charging process the energy ECh=½CLVDD 2 is consumed  by the PMOS network and the energy ECL=½CLVDD 2 is  stored in the load capacitance. The stored energy ECL  will be consumed by the NMOS network during the  subsequent discharging of CL. Therefore the switching  energy of a conventional CMOS logic gate is [12]:  1 2 Although the supply voltage of a conventional CMOS  logic gate is constant, the current by which the load  capacitance is charged (or discharged) is not constant at  all. However, it has been proved that the switching  energy can be reduced if the load capacitance is charged  and discharged by a constant current rather than by a  constant voltage [12]. For example, consider Fig. 1a  where the load capacitance CL is charged from 0 to VDD  by a constant current source. It can be shown [12] that  during the process of constant current charging, the  energy ECh=(RCL/TR)CLVDD 2 is consumed by the resistor  R (TR is the charging time, i.e., the time it takes to  charge CL from 0 to VDD). Also, after the process of  2 is  constant current charging, the energy ECL=½CLVDD stored in the load capacitance. Unlike in conventional  CMOS logic gates, during the process of constant  current discharging (Fig. 1b), the stored energy ECL is  6868 EDis-Ch=(RCL/TF)CLVDD not consumed completely, rather the energy  2 is consumed by the resistor R  (TF is the discharging time). This is why the circuits that  use constant current charging and discharging are called  energy recovery circuits. In short, the switching energy  of an energy recovery gate (Fig. 1) is:  RC T where TRF is the charging/discharging time.  ECons-Cur can be lower than EConv, if TRF is long enough.  Also, a lower path resistance R brings lower energy  consumption in the energy recovery gate. This result is  in contrast to the conventional CMOS case as the  expression for EConv does not contain R.  ) VC 2 DDL Cons Cur  (2)  E = ( L RF R Q R Q I CL I CL (a ) (b)(c ) Vin VA CLVin VDD GND Clock Period Charge TR Discharge TF (d ) Figure 1. a) Constant-current charging, b) Constantcurrent discharging, c) An energy recovery circuit [12],   d) Trapezoidal voltage source  It has been proved that a time-dependent voltage  source that generates periodic positive- and negativegoing linear voltage ramps (i.e., a trapezoidal voltage  source like what is shown in Fig. 1d) will create current  waveforms similar to those generated by constant  current sources [12,14]. In fact, all energy recovery  circuits presented to date use trapezoidal voltage sources  rather than current sources [12]. To make this point  more clear, Fig. 1c shows a simple energy recovery  CMOS circuit [12]. When Vin=0, the transmission gate is  'on' and hence the trapezoidal voltage source can charge  and discharge the load capacitance CL. During the  charging process, when the trapezoidal voltage source  generates a positive-going voltage ramp, the simple  energy recovery circuit of Fig. 1c behaves the same way  as the circuit of Fig. 1a. Similarly, during the  discharging process, when the trapezoidal voltage source  generates a negative-going voltage ramp, the simple  energy recovery circuit of Fig. 1c behaves the same way  as the circuit of Fig. 1b. For the simple energy recovery  circuit of Fig. 1c, the parameter R of Eq. 2 is almost                                                                               equal to the resistance of the turned-on transmission  gate, and the parameter TRF of Eq. 2 is the rise/fall time  of the trapezoidal voltage source (Fig. 1d).  It should be noted that the circuit of Fig.1c is only  used to provide a simple illustration of the principle of  energy recovery, and the complexities of energy  recovery circuits are not shown in Fig. 1. Some of the  most important characteristics of energy recovery  circuits are as follows:  1- In addition to the operating power, the trapezoidal  signals naturally provide timing information to energy  recovery circuits, and, therefore, are sometimes referred  to as power-clocks [12].  2- All energy recovery circuits are essentially  pipelined sequential circuits [12,13,14]. This may cause  problems (e.g., increased latencies) if one wants to use  energy recovery circuits to implement processing  elements. However, in the case of on-chip interconnects,  this feature is desirable.  3- All energy recovery circuits require multiphase  trapezoidal power-clock signals [12,13,14]. Various  techniques have been developed for generating  trapezoidal power-clock signals [12,19].   4- All pipeline stages in an energy recovery circuit  should implement reversible logic functions [12].  Therefore, energy recovery circuits usually require  additional hardware to make the logic functions  reversible. However, in the case of on-chip  interconnects, the reversibility problem is not a concern  as the operation of on-chip interconnects (data  transferring) is inherently reversible.    For more information on energy recovery circuits  please refer to [12,13,14].  3. Energy recovery pipelined interconnects  Fig. 2 shows the basic idea of energy recovery  pipelined interconnects. As shown in this figure, the  capacitance of an on-chip interconnect is divided into  smaller capacitances by inserting energy recovery buffer  gates. As mentioned in Section 2, energy recovery  circuits are essentially pipelined sequential circuits,  therefore a chain of cascaded energy recovery buffers  (Fig. 2a) always behaves like a shift register. Let TP and  TRF be the period and the rise/fall time of the powerclock signals respectively. TP is usually an integer  multiple of TRF, i.e., TP=KTRF, where K is usually equal  to the number of power-clock signals [12,13,14]. The  period TP determines the throughput of energy recovery  pipelined circuits, since during each period only one  data item is shifted into the pipeline and also only one  data item is shifted out from the pipeline (i.e., the  throughput is one initiation per period) [14]. In Fig. 2, a  4-phase energy recovery circuit is used to implement a  pipelined interconnect. Therefore, 4 trapezoidal powerclock signals are required and hence TP=4TRF and the  throughput is 1/(4TRF).  P0 P1 P2 P3 P0 P 1 (a) TRF (b) P0 P1 P2 P3 Figure 2. a) An energy recovery pipelined interconnect,  b) Trapezoidal power-clock signals  Time Pj-1 Pj-1 Pj Pj Ai-1 Ai-1 ER Buffer Ai+ 1 Ai+ 1 Ai Ai Ai+1 Ai Ai-1 Ai Ai VDD Pj Ai Pj Ai-1 Ai-1 Ai-1 Ai Ai+ 1 Ai-1 Ai Ai-1 Ai Pj-1 Pj-1 Figure 3. CMOS circuit of an ER buffer gate  When n energy recovery buffers are used to pipeline  an interconnect (with the capacitance  CL), the  interconnect is divided into n+1 stages each with a  capacitance of CStage=CL/(n+1). Assuming that the  parasitic capacitances of the buffers can be neglected  compared to the interconnect capacitances, we can  obtain from Eq. 2 that the switching energy of each  stage is (RCStage/TRF)CStageVDD 2, where R is the resistance  of the path through which the load capacitance CStage is  charged and discharged. Therefore the switching energy  of the whole pipelined interconnect is:     (3)  L VC 2 DDL RC T RF Stage RC T RF VC Stage 2 DD = 1 n + 1 (cid:215) nnE )( = ( + pipeline )1 6969                 In conventional pipelined interconnects, the throughput  can be improved by increasing the depth of pipelining  [3]. However, Eq. 3 indicates that in energy recovery  pipelined interconnects, when we do not need to  improve the throughput ( TRF remains unchanged), the  switching energy consumption decreases as the depth of  pipelining increases.   4. Proposed energy recovery designs  In this section we present two designs for energy  recovery pipelined on-chip interconnects, called ER  (Energy Recovery) and SHER (SEU-Hardened and  Energy Recovery).   4.1. ER pipelined interconnects  Fig. 3 shows the CMOS circuit of an ER buffer gate  and Fig. 4 shows an ER pipelined interconnect. As it can  be seen from Figs. 3 and 4, ER pipelined interconnects  use a dual-rail logic, so that for each data bit, both the  true and inverse values are transmitted. The use of dualrail logic is necessary for the proper operation of  transmission gates, as they require dual-rail control  signals. It should be noted that it is not admissible to  introduce a conventional inverter to derive one of these  control signals from the other. A conventional inverter  does not operate according to the principle of energy  recovery and if we use it in an energy recovery circuit, a  considerable amount of energy will be wasted [12]. ER  pipelined interconnects require 4 power-clock signals  which are denoted in Fig. 4 by P 0, P1, P2, and P 3. It  should be noted that P 0=P¯2 and P1= P¯3 (Fig. 5), therefore  in Figs. 3 and 4, the power-clock signals P¯0, P¯1, P¯2, and  P¯3 can be replaced with P 2, P3, P0, and P 1 respectively.  However, the signals P¯0, P¯1, P¯2, and P¯3 are used to make  the diagrams more intelligible.  To see how an ER pipelined interconnect operates,  suppose we want to transmit the bit-string 10110 on the  ER pipelined interconnect of Fig 4. Fig. 5 shows the  waveforms at various nodes in the interconnect of Fig. 4.  For the sake of simplicity, the waveforms of the nodes  A¯ 2, A¯ 3, A¯ 4, and A¯ 5 are not shown in Fig. 5. In Fig. 5, the  time axis is divided into time units (TU) equal to the  rise/fall time of the power-clock signals. The period of  the power-clock signals is 4TU (Section 3), hence the  throughput is 1/(4TU). As it can be seen from Fig. 5,  each node in an ER pipelined interconnect is  synchronous with one of the power-clock signals. When  a node A is synchronous with a power-clock signal P,  the value of the node A can change from 0 to 1 only in  the TUs where the power-clock signal P has positivegoing ramps and can change from 1 to 0 only in the TUs  where P has negative-going ramps. During each clock  period (TP=4TU), only one bit of information is applied  to each node. Fig. 6 shows how a bit of information is  applied to a node. When a '0' is applied to the node A,  the value of the node remains '0' during the whole clockperiod. However, when a '1' is applied to the node A, the  A2 A1 IN VDD P12 P1 P11 T14 IN A1 T13 P0 P13 P0 P1 T12 A1 IN A1 A2 IN A1 T11 N11 N12 N13 A1 A1 ER Buffer #1 A1 IN IN A4 A3 A2 VDD A2 A3 T33 P3 T34 P2 P31 P32 P33 P2 P3 T32 A3 A2 A3 A4 A2 A3 T31 N31 N32 N33 A3 A3 ER Buffer #3 A3 A3 A2 A1 VDD A1 A2 T23 P2 T24 P1 P21 P22 P23 P1 P2 T22 A2 A1 A2 A3 A1 A2 T21 N21 N22 N23 A2 A2 ER Buffer #2 A2 A6 A5 A4 VDD P52 P1 P51 T54 A4 A5 T53 P0 P53 P0 P1 T52 A5 A4 A5 A6 A4 A5 T51 N51 N52 N53 A5 A5 ER Buffer #5 A5 A5 A4 A3 VDD P42 P0 P41 T44 A3 A4 T43 P3 P43 P3 P0 T42 A4 A3 A4 A5 A3 A4 T41 N41 N42 N43 A4 A4 ER Buffer #4 A4 (a) (b) ER Buffer A1 A1 A3 A3 P1 P1 P2 P2 ER Buffer A2 A2 A4 A4 P2 P2 P3 P3 ER Buffer A3 A3 A5 A5 P3 P3 P0 P0 ER Buffer IN IN A2 A2 P0 P0 P1 P1 ER Buffer A4 A4 A6 A6 P0 P0 P1 P1 A5 A5 Figure 4. An ER pipelined interconnect: a) Schematic diagram, b) Circuit-level details  7070             node value does not remain constant during the clock  period. In this case, during the 1st TU of the clock  period, A is 0, during the 2nd TU of the clock period, A  changes from 0 to 1, during the 3rd TU of the period, A  is 1, and finally during the 4th TU of the clock period A  changes from 1 to 0.  P0 P1 P2 P3 IN IN A1 A1 A2 A3 A4 A5 12 345 67891011121314151617181920212223 Tim e Figure 5: Waveforms for the interconnect of Fig. 4   Clock Period P P A A (a)(b)(c) Figure 6. Node A is synchronous with the power-clock  signal  P, a) a '1' is applied to A, b) a '0' is applied to A,   c) a '1' is applied to A  Since we want to transmit the bit string 10110, this bit  string is applied to IN (and its inverse is applied to I ¯N¯).  The node IN is synchronous with the power-clock signal  P0, hence during the TUs #1 through #4 a '1' is applied  to the node IN, during the TUs #5 through #8 a '0' is  applied to the node IN, and so forth. As it can be seen  from Fig. 5, when a signal passes through an ER buffer  it is delayed by one TU. For example, the waveform of  A2 is the 1TU delayed copy of the waveform of A 1.  Since the delay of each ER buffer is one TU, and  consecutive data bits are applied to the pipeline input  every 4TUs, any four cascaded ER buffers behave like a  1-bit memory-element. To see how ER buffers operate,  consider the TUs #4 through #7 when the first bit of the  bit-string passes through the ER buffer #2 from the node  A1 to the node A 2. During the TU #4, A 1 is 1 (and A¯ 1 is  7171 0) hence the transmission gate T22 is 'on', and P 2 is  connected to the node A 2. Therefore, since P 2 has a  positive-going ramp during the TU #4, the value of the  node A2 changes from 0 to 1. During the TU #5, A2 is 1,  hence the transmission gate T21 is 'on' and P 1 is  connected to the node A 1. Therefore, since P 1 has a  negative-going ramp during the TU #5, the value of the  node A1 changes from 1 to 0. It should be noted that  what goes on in the ER buffer #2 during the TU #4 is  the same as what goes on in the ER buffer #3 during the  TU #5, i.e., during the TU #5, the node A 3 charges from  0 to 1 as it is connected to the power-clock signal P 3.  Although during the TU #5, the transmission gate T22  gradually turns 'off' (as A 1 changes from 1 to 0), the  transmission gate T31 gradually turns 'on' (as A 3  changes from 0 to 1). Therefore, the node A 2 remains  connected to P2 and remains '1'. During the TU #6, A 3 is  1 (in the same manner that A 2 is 1 during the TU #5),  hence the transmission gate T31 is 'on' and P 2 is  connected to the node A 2. Therefore, since P 2 has a  negative-going ramp during the TU #6, the value of the  node A2 changes from 1 to 0. During the TU #7, A 2  remains 0 regardless of whether the transmission gates  T22 and T31 are 'on' or 'off', because the power-clock P2  is 0. It can be seen from Fig. 4b that in addition to the  transmission gates T22 and T31, a stack of three NMOS  transistors (N21, N22, and N23) is connected to the  node A2. Unlike the transmission gates T22 and T31,  this transistor stack is not used to control the value of  the node A2, rather the transistor stack is used to clamp  the node A 2 to GND after the node capacitance  discharges to 0 through the transmission gates T22 and  T31. For example, during the TU #4, the transistor N21  is 'off' as A1 is 1, during the TU #5, the transistor N22 is  'off' as A2 is 1, and during the TU #6, the transistor N23  is 'off' as A 3 is 1. Therefore, during the TUs #4, #5, and  #6, the transistor stack has no impact on the value of A 2  (this is why we did not consider the transistor stack  when explaining how the ER buffer #2 operates during  the TUs #4, #5, and #6). However, during the TU #7,  when the value of the node A 2 is 0 the transistor stack  starts clamping the node A2 to GND (as A 1 and A2 are 0  and A3 gradually changes to 0). In fact, as it can be seen  from Fig. 5, whenever the node A 2 has a non-zero value  the transistor stack does not clamp it to GND.  Conversely, whenever the node A 2 is 0, the transistor  stack clamps (or starts clamping) it to GND. Although,  the clamp transistor stacks never charge or discharge the  nodes, they are necessary for the proper operation of the  whole circuit. Without the clamp transistor stacks, the  nodes may be left floating. As discussed in Section 5,  the floating nodes can cause serious problems in energy  recovery circuits.            Despite the fact that in pipelined on-chip  interconnects, the whole capacitance of an interconnect  is divided into smaller capacitances, pipelining can  increase the total capacitance of an interconnect. As it  can be seen from Fig. 4, in an ER pipelined interconnect,  each buffer receives the two outputs of its previous  buffer and the two outputs of its next buffer. Therefore,  the use of ER pipelined interconnects can increases the  total load capacitance by a factor of 4. However, as we  will see in Section 5, thanks to the principle of energy  recovery, ER pipelined interconnects achieve a  considerable energy saving (up to 50%) as compared to  conventional pipelined interconnects.  Clock Period #1 #2 #3 #4 #5 P P A A ~A Figure 7. A¯ = voltage inverse of A, ~A=logical inverse of A  4.2. SHER pipelined interconnects  As discussed in Section 5, while ER pipelined  interconnects consume less energy than conventional  pipelined interconnects, the reliability of ER pipelined  interconnects (against SEUs) is comparable to the  reliability of conventional pipelined interconnects. In  this section, we present another design for energy  recovery pipelined interconnects, called SHER. As  shown in Section 5, SHER pipelined interconnects  consume more energy than ER pipelined interconnects.  However SHER pipelined interconnects provide a  considerable reliability against SEUs, while they  consume less energy than conventional pipelined  interconnects.  Before explaining SHER pipelined interconnects, we  need to present the following definitions.  Voltage  inverse: the values of the two nodes A and B are the  voltage inverse of each other iff VA(t)+VB(t)=VDD, where  VA(t) and VB(t) are the voltage values of the nodes A and  B at the time instant t respectively. Logical inverse: the  values of the two nodes A and B are the logical inverse  of each other iff during each clock period, if a 1 is  applied to the node A, a 0 is applied to the node B and  vice versa. Throughout this paper we have used the  notations A¯ and ~A to show the voltage inverse and  logical inverse of A respectively. As an example, Fig. 7  7272 shows the logical inverse and the voltage inverse of the  value of a node A.  It can be seen from this figure that  while both the nodes A and ~A are synchronous with the  power-clock signal P, the node A¯ is synchronous with  the power-clock signal P¯.   Pj-1 Pj-1 Pj Pj SHER Buffer ~Ai ~Ai Ai Ai ~Ai-1 ~Ai-1 Ai-1 Ai-1 VDD Pj ~Ai-1 VDD Pj-1 ~Ai Pj ~Ai-1 Ai Pj-1 Pj Ai Pj Ai-1 Ai-1 Pj-1 ~Ai Pj-1 Ai ~Ai ~Ai ~Ai Ai Ai Ai-1  -1 ~Ai ~Ai-1 ~Ai Ai-1 Ai Ai-1 Ai Figure 8. The CMOS circuit of an SHER buffer gate  Fig. 8 shows the CMOS circuit of an SHER buffer  and Fig. 9 shows an SHER pipelined interconnect. As it  can be seen from Figs. 8 and 9, SHER pipelined  interconnects use a 4-rail logic, so that for each data bit,  in addition to the true value, the voltage inverse value A¯,  the logical inverses value ~A, and the voltage inverse of  the logical inverse value ~¯¯A   are transmitted. Just like in  ER pipelined interconnects, SHER pipelined  interconnects require 4 power-clock signals. To see how  an SHER pipelined interconnect operates, suppose we  want to transmit the bit-string 10110 on the SHER  pipelined interconnect of Fig 9. Fig. 10 shows the  waveforms at various nodes in the interconnect of Fig. 9.  Since we want to transmit the bit string 10110, this bit  string is applied to IN (and its voltage inverse is applied  to I¯N¯). Also, the logical inverse of the bit string 10110,  which is 01001, is applied to ~IN (and its voltage  inverse is applied to ~¯I¯N¯). The nodes IN and ~IN are  synchronous with the power-clock signal P 0, hence  during the TUs #1 thourgh #4 a 1 is applied to the node  IN and a 0 is applied to the node ~IN, during the TUs #5  through #8 a 0 is applied to IN and a 1 is applied to ~IN,  and so forth. In fact, the pass transistors of a SHER  buffer play the same role as the pass transistors of an ER  buffer, so that for example what goes on in the pass  transistors T21 and T22 in the SHER buffer #2 during              the TUs #4 through #7 is the same as what goes on in  the pass transistors T21 and T22 in the ER buffer #2 of  Fig. 4 during the TUs #4 through #7. The main  difference is in the way that nodes are clamped to GND  (or VDD). For example consider the NMOS transistor  N21 in Fig. 9b which is connected to the node A 2. This  NMOS transistor is used to clamp the node A 2 to GND  after the node capacitance discharges to 0 through the  transmission gates T22 and T31. For example, during  the TUs #4, #5, #6, and #7, when a 1 is applied to the  node A2, the transistors N21 is 'off' as ~A 1 is 0.  Therefore, during the TUs #4, #5, #6, and #7 the  transistor N21 has no impact on the value of A 2 and the  value of A2 is only controlled by the transmission gates  T22 and T31. However, during the TUs #8, #9, and #10  when the value of the node A 2 is 0, the transistor N21  clamps the node A 2 to GND (as a 1 is applied to ~A 2  during the TUs #8, #9, and #10). It should be noted that  during the TUs #8, #9, and #10, the transmission gates  T22 and T31 are both 'off' as A 1 and A 3 are both 0.  Therefore, during the TUs #8, #9, and #10, the transistor  N21 clamps the node A2 to GND. As it can be seen from  Figs. 9 and 10, whenever a 1 is applied to the node A 2  the transistor N21 does not clamp the node A 2 to GND  as the transistor is controlled by ~A 2 and a 0 is applied  to ~A2. Conversely, whenever a 0 is applied to the node  A2, the transistor N21 clamps (or starts clamping) the  node A2 to GND as the transistor is controlled by ~A 2  and a 1 is applied to ~A2.  As it can be seen from Fig. 9, in an SHER pipelined  interconnect, each buffer receives the four outputs of its  previous buffer. Therefore, like in ER pipelines, the use  of SHER pipelined interconnects can increases the total  load capacitance by a factor of 4. However, as we will  ~IN ~A1 T17 P1 T18 P0 P12 P0 P1 T16 ~A1 T15 N12 ~A1 ~IN ~A2 ~A3 T37 P3 T38 P2 P32 P2 P3 ~A2 T36 ~A3 A3 ~A3 T35 N32 ~A3 ~A3 ~A3 ~A1 ~A2 T27 P2 T28 P1 P22 P1 P2 ~A1 T26 ~A2 A2 ~A2 T25 N22 ~A2 ~A2 ~A2 ~A4 ~A5 T57 P1 T58 P0 P52 P0 P1 ~A4 T56 ~A5 A5 ~A5 T55 N52 ~A5 ~A5 ~A5 ~A3 ~A4 T47 P0 T48 P3 P42 P3 P0 ~A3 T46 ~A4 A4 ~A4 T45 N42 ~A4 ~A4 ~A4 VDD A1 VDD A2 VDD A3 VDD A4 VDD A5 SHER Buffer ~A1 ~A1 A1 A1 P1 P1 P2 P2 SHER Buffer ~A2 A2 A2 P2 P2 P3 P3 SHER Buffer ~A3 A3 A3 P3 P3 P0 P0 SHER Buffer IN IN P0 P0 P1 P1 SHER Buffer ~A4 A4 A4 P0 P0 P1 P1 ~A5 ~A5 A5 A5 ~IN ~IN ~A2 ~A3 ~A4 (a) (b) SHER Buffer #1SHER Buffer #3 SHER Buffer #2SHER Buffer #5 SHER Buffer #4 IN A1 T13 P1 T14 P0 P11 P0 IN A1 P1 T12 A1 ~A1 T11 N11 A1 A1 A1 IN IN A2 A3 T33 P3 T34 P2 P31 P2 A2 A3 P3 T32 A3 ~A3 T31 N31 A3 A3 A3 A1 A2 T23 P2 T24 P1 P21 P1 A1 A2 P2 T22 A2 ~A2 T21 N21 A2 A2 A2 A4 A5 T53 P1 T54 P0 P51 P0 A4 A5 P1 T52 A5 ~A5 T51 N51 A5 A5 A5 A3 A4 T43 P0 T44 P3 P41 P3 A3 A4 P0 T42 A4 ~A4 T41 N41 A4 A4 A4 VDD ~A1 VDD ~A2 VDD ~A3 VDD ~A4 VDD ~A5 ~A1 ~IN ~A1 ~A1 A1 ~IN Figure 9. SHER pipelined interconnect: a) Schematic diagram, b) Circuit-level details  7373        see in Section 5, SHER pipelined interconnects still  achieve a considerable energy saving (up to 30%) as  compared to conventional pipelined interconnects.  P0 P1 P2 P3 IN IN ~IN ~IN A1 ~A1 A2 ~A2 A3 ~A3 123 456 7 891011121314151617181920212223 Time Figure 10: Waveforms for the interconnect of Fig. 9  It should be noted that the hardware overhead of  SHER pipelines is acceptable as compared to  conventional fault tolerance and low energy techniques.  For example, the techniques that are used to tolerate  SEUs can easily lead to a hardware overhead of 300%  [18]. Also, the use of energy recovery techniques can  easily lead to a hardware overhead of 2000% [14].  While the overhead of SHER pipelines is about 400%  they reduce the energy consumption by about 30% and  at the same time improve the reliability considerably  (Section 5).  5. Evaluation of pipelined interconnects  In this section, we evaluate the energy consumption  and reliability of our proposed energy recovery  interconnects and compare them with conventional  pipelined interconnects. To analyze the pipelined  interconnects, SPICE simulations were carried out using  45nm PTM technology [20,21] ( VDD=0.5V). Since  pipelined interconnects are simply a cascade connection  of similar buffers (or flip-flops), they can be easily  synthesized and the synthesis flow can be automated. In  the experiments, an on-chip interconnect with the  capacitance CL=1pF (a few millimeters long wire in  45nm technology [22]) was considered, and the different  pipelining methods were applied to this interconnect. It  was assumed that the required throughput for the  7474 pipelined interconnects is 0.1 Gbps. Fig. 11 shows a  conventional pipelined interconnect which is constructed  using conventional CMOS edge-triggered flip-flops (the  transistor-level design is provided in [24]). Such a  conventional pipelined interconnect was used in the  SPICE experiments.  VDD CLK VDD VDD CLK VDD D CLK CLK Q CLK VDD CLK VDD (b) CLK CLK CLK CLK IN ET DFF ET DFF A1 CLK CLK ET DFF ET DFF A3 A4 CLK CLK A 2 (a) Figure 11. a) Conventional pipelined interconnect made  up of edge-triggered FFs, b) Transistor-level  implementation of the edge-triggered FF [24]  5.1. Estimating energy consumption  To analyze the energy consumption of the pipelined  interconnects a bit string consisting of 120 bits was  randomly generated. The bit string was generated only  once and the same bit string was used in all the SPICE  simulations. For each pipelined interconnect three  different pipelining depth were considered, however, as  mentioned previously, the throughput was supposed to  be constant and equal to 0.1 Gbps. The constant  throughput is considered, as we want to analyze the  impact of pipelining depth on the energy consumption  when the throughput is constant (Section 3). Table 1  shows the energy consumption of the pipelined  interconnects. It can be seen from Table 1 that in a  conventional pipelined interconnect, as the pipelining  depth increases, the energy consumption increases.  However, in an energy recovery pipelined interconnect  as the pipelining depth increases, the energy  consumption decreases. This observation is in line with  the analytical study of Section 3. Table 1 shows that the  ER pipelined interconnect with 20 ER buffers provides  53.29% energy saving as compared to the conventional  pipelined interconnect with 3 flip-flops. Also, the SHER  pipelined interconnect with 20 SHER buffers provides  29.34% energy saving as compared to the conventional  pipelined interconnect with 3 flip-flops.                    5.2. Estimating reliability against SEUs  To analyze the reliability (against SEUs) of the  pipelined interconnects, we used SPICE-based fault  injection experiments. Faults were injected using the  current sources, which can accurately represent the  electrical impact of the particle strikes [4]. The injected  current caused by a particle strike is [9]:  tI )( Inj = 2 p (cid:215) Q (cid:215) T t T t -(cid:215) e T  (4)  where Q is the charge deposed as a result of the particle  strike, and T is a time constant. These parameters  depend on particles energy and process-related factors  [23]. In the fault injection experiments, it was assumed  that particle strikes have equiprobable occurrence during  a clock cycle. Also, faults were injected with different  values for Q (Eq. 4), ranging from -0.2pC to +0.2pC,  and different values for T (Eq. 4) ranging from 0.1ns to  0.5ns (realistic values based on [4,23]). 4096 faults  where injected into each pipelined interconnect. Table 2  shows the results obtained from the fault injection  experiments. As it can be seen from Table 2, in the  conventional pipelined interconnect with 3 FFs, 377  faults (simulated particle strikes) out of 4096 injected  faults caused SEUs, and the rest of the injected faults did  not result in SEUs. However, as the pipelining depth  increases, the SEU-hardness of the conventional  pipelined interconnect decreases, so that the number of  SEUs increases from 377 to 792 as the number of stages  increases from 3 to 5 (The same is true of ER and SHER  pipelined interconnects). This is because, as the  pipelining depth increases the load capacitances of the  pipelining stages decrease and it has been shown that the  SEU-susceptibility of circuits increases as load  capacitances decrease [4]. While ER pipelined  interconnects are slightly less reliable than conventional  pipelined interconnects, SHER pipelined interconnects  are considerably hardened against SEUs. In fact, the  SHER pipelined interconnects could tolerate almost all  the injected faults and hence their reliability is  comparable to the reliability achieved from sophisticated  fault tolerance techniques like those proposed in [18].  In ER pipelined interconnects, our study shows that  when a node is clamped to GND (or VDD), the node is  very sensitive to undesirable currents. Conversely, when  a node is connected to one of the power-clock signals  through transmission gates it is very hardened against  undesirable currents. For example, in Figs. 4 and 5,  when the node A 2 is clamped to GND, if an undesirable  current can only increase the voltage of A 2 from 0 to Vtn  (threshold voltage of NMOS transistors) an SEU will  occur. However, when the node A 2 is connected to P 2  through the transmission gates T22 and T31, our  7575 experiment shows even if an undesirable current can  decrease the voltage of A 2 from VDD to a voltage lower  than 0, the node voltage might be recovered.  Conventional  Table 1. Energy consumption of pipelined interconnects  Pipelining  # of FFs or  Average Power  Energy  Scheme  # of Buffers  (uW)  consumption (pJ)  3 FFs 11.90 14.28  4 FFs 12.14 14.57  5 FFs 12.42 14.91  12 BUFs 7.42 8.90  16 BUFs 6.36 7.63  20 BUFs 5.56 6.67  12 BUFs 11.22 13.47  16 BUFs 9.62 11.54  20 BUFs 8.41 10.09  SHER  ER  *   Conventional  Pipelining  Scheme  Table 2. Fault injection results  # of FFs or  # of SEUs % of SEUs # of Buffers  3 FFs 377 9.2  4 FFs 618 15.08  5 FFs 792 19.33  12 BUFs 502 12.26  16 BUFs 816 19.92  20 BUFs 844 20.61  12 BUFs 0 0  16 BUFs 0 0  20 BUFs 2 0.05  * 4096 faults (simulated particle strikes) were totally injected  SHER  ER  In SHER pipelined interconnects, when a node A is  clamped to GND (or VDD), the logical inverse of A,  i.e., ~A is connected to a power-clock signal through  transmission gates. In this case, the node A is more  sensitive to undesirable currents than the node ~A.  However, if an undesirable current affects the node A,  since ~A controls the clamp transistor of A, the node ~A  will help the node A to remain clamped to GND (or  VDD) and recover its original voltage.  In short, in  SHER pipelined interconnects, always one node in a  logical inverse pair is hardened against undesirable  currents and the other one is sensitive to them. If an  undesirable current affects the sensitive one, the  hardened one will help the sensitive one to recover from  the transient undesirable current. It should be noted the  same property does not hold for voltage inverse pairs.  When a node in a voltage inverse pair is clamped to  GND (or VDD) the other one is clamped to VDD (or  GND), therefore both of them are sensitive to  undesirable currents. This is why ER pipelined  interconnects (that do not use logical inverse pairs) are  not as SEU-hardened as SHER pipelined interconnects.  5.3. Traditional energy recovery logic styles  It is possible to use traditional energy recovery logic  styles, such as 8-phase dual-rail logic [12,13,14], and  2LAL [19] to implement pipelined interconnects.                                                             However, the use of traditional logic styles causes the  following problems.  The 8-phase dual-rail logic style has the following  drawbacks: 1) They require 8 power-clock signals while  our proposed energy recovery techniques require 4  power-clock signals, 2) The period of the power-clock  signals is eight times longer than the rise/fall-time of the  signals, i.e.,  TP=8TRF. However, in 4-phase energy  recovery circuits we have TP2=4TRF2. According to Eq.  2, assuming that CL and R are the same in both the 8phase and 4-phase logic styles, to achieve the same  energy consumption we have TRF2= TRF, however in this  case the throughput of the 8-phase energy recovery  circuit is half of the throughput of the 4-phase energy  recovery circuit.  The 2LAL logic style requires 4 power-clock signals.  Therefore, it does not have the drawbacks of the 8-phase  dual-rail logic. However, our study shows that in the  2LAL logic style the nodes may become floating. The  considerable sub-threshold leakage current of DSM  transistors can disturb the values of floating nodes, so  that our SPICE simulations show that the 2LAL logic  family does not operate correctly when used in 45nm  Technology.    6. Conclusions   In this paper, we have presented two energy recovery  designs, called ER and SHER, to implement low energy  pipelined on-chip interconnects. It has been shown via  SPICE simulations that ER pipelined interconnects can  achieve up to 50% energy saving as compared to  conventional pipelined interconnects. However, ER  pipelined interconnect are slightly less reliable than the  conventional pipelined interconnects. It has been also  shown via SPICE simulations that SHER pipelined  interconnects can achieve up to 30% energy saving (less  than what is achievable from ER pipelined  interconnects), and they are considerably hardened  against SEUs.   7. Acknowledgements  B.M. Al-Hashimi, and A. Ejlali acknowledge the  Engineering and Physical Sciences Research Council  (EPSRC UK) for funding this work under grants no.  EP/C512804/1 and EP/035965/1. Also, A. Ejlali  acknowledges Research Vice-Presidency of Sharif  University of Technology for partially funding this  work.  8. "
An Efficient Implementation of Distributed Routing Algorithms for NoCs.,"The design of NoCs for multi-core chips introduces new design constraints like power consumption, area, and ultra low latencies. Although 2D meshes are preferred, heterogeneous blocks, fabrication faults, reliability issues, and chip virtualization may lead to the need of irregular topologies or regions. In this situation, efficient routing becomes a challenge. Although the use of routing tables at switches is flexible, it does not scale in terms of latency and area due to its memory requirements. LBDR (logic-based distributed routing) is proposed as a new routing method that removes the need of using routing tables at all. LBDR enables the implementation of many routing algorithms on most of the practical topologies we might find in the near future in a multi-core system. From an initial topology and routing algorithm, a set of three bits per switch/output port is computed. Evaluation results show that, by using a small logic, LBDR mimics the performance of routing algorithms when implemented with routing tables, both in regular and irregular topologies.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip An Efﬁcient Implementation of Distributed Routing Algorithms for NoCs ∗ J. Flich, S. Rodrigo, and J. Duato Parallel Architectures Group Technical University of Valencia, Spain email {jﬂich, srodrigo, jduato}@disca.upv.es Abstract The design of NoCs for multi-core chips introduces new design constraints like power consumption, area, and ultra low latencies. Although 2D meshes are preferred, heterogeneous blocks, fabrication faults, reliability issues, and chip virtualization may lead to the need of irregular topologies or regions. In this situation, efﬁcient routing becomes a challenge. Although the use of routing tables at switches is ﬂexible, it does not scale in terms of latency and area due to its memory requirements. LBDR (Logic-Based Distributed Routing) is proposed as a new routing method that removes the need of using routing tables at all. LBDR enables the implementation of many routing algorithms on most of the practical topologies we might ﬁnd in the near future in a multi-core system. From an initial topology and routing algorithm, a set of three bits per switch/output port is computed. Evaluation results show that, by using a small logic, LBDR mimics the performance of routing algorithms when implemented with routing tables, both in regular and irregular topologies. 1 Introduction Multi-core architectures are becoming mainstream for designing high performance processors. As power limits the performance for single-core solutions, designers are shifting to the multi-core domain where simpler processor cores are integrated into the same chip. Although the number of cores in current processing devices is rather small (i.e. two to eight cores per chip), this trend is expected to change. As an example, the TeraScale chip has been recently announced with 80 cores [1]. Such a large number of cores requires a highperformance on-chip interconnect (NoC) to efﬁciently communicate cores among them and with cache blocks and/or memory controllers. Current chip implementations use sim∗ This work was supported by CONSOLIDER-INGENIO 2010 under Grant CSD2006-00046, by CICYT under Grant TIN2006-15516-C04-01, by Junta de Comunidades de Castilla-La Mancha under Grant PCC080078. ple network structures such as buses or rings [2]. However, as the number of cores increases such networks become the bottleneck of the system, thus bus and ring topologies become unpractical. For chips with a larger number of cores the 2D mesh topology is usually preferred due to its layout on a planar surface in the chip. This is the case of the TeraScale chip. For routing purposes, logic-based routing (e.g. Dimmension Order Routing; DOR) is preferred to reduce latency, power, and area requirements for the NoC. The high integration scale, however, pushes a number of communication reliability issues. Crosstalk, power supply noise, electromagnetic and inter-symbol interference are some of these issues. Moreover, fabrication faults may appear, in the form of defective core nodes, wires or switches. In these cases, while some regions of the chip are defective, the remaining chip area may be fully functional. From the NoC point of view, in presence of such fabrication defects, the initial regular topology has become an irregular one. This is the case for topologies shown in Figure 1. Additionally, in order to exploit the increasing number of cores, and due to the fact that applications are not getting enough parallelism, virtualization of the chip is becoming a necessity. In a virtualized system resources are distributed among different tasks or applications. The network must guarantee trafﬁc isolation within regions, thus, leading to irregular sub-networks within the original 2D mesh. Figure 1.h shows an example where three regions are used. Routing can be implemented as source routing or distributed routing. In source routing, the source end node computes the path and stores it in the packet header. Since the header itself must be transmitted through the network, it consumes network bandwidth. The TeraScale chip uses source routing. In distributed routing, however, each switch computes the next link that will be used while the packet travels across the network. The packet header only contains the destination ID. Distributed routing can be implemented in different ways. The approach followed in regular topologies is the so called algorithmic routing, which relies on a combinational logic circuit that computes the output port to be used as a function of the current and destination nodes and the status 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.28 DOI 10.1109/NOCS.2008.28 87 87 Figure 1. Examples of topologies (a-f and h) supported and (g) not supported by LBDR. (a) XY in 2D mesh (b) SRh in 2D mesh (c) SRv in 2D mesh (d) UD in 2D mesh SOME PAIRS CANNOT COMMUNICATE (e) XY in p topology (f) SRh in p topology (g) SRv in p topology (h) UD in p topology Figure 2. Examples of routing algorithms (by their routing restrictions) in 2D mesh and p topology. of the output ports. The implementation is very efﬁcient in terms of both area and speed, but the algorithm is speciﬁc to the topology and to the routing strategy used on that topology. To deal with non-regular topologies, switches based on forwarding tables were proposed. In this case, there is a table at each switch that stores, for each destination end-node, the output port that must be used. This scheme can be easily extended to support adaptive routing by storing several outputs in each table entry. The main advantage of table-based routing is that any topology and any routing algorithm can be used, including fault-tolerant routing algorithms. However, memories, do not scale in terms of latency, power consumption, and area, thus being impractical for NoCs. Possibly, the size of the routing table can be reduced in some environments. This is the case of application-speciﬁc systems where the communication pattern may be known in advance. However, is not the case for generic purpose multi-core chips. It would be interesting to ﬁnd an implementation, for irregular topologies (partial 2D meshes), that allows the use of any distributed routing algorithm without the need of using routing tables nor source-based routing. In this paper we take on such a challenge. We propose a very simple mechanism that removes the routing tables at every switch, thus enabling the distributed implementation of any routing algorithm on irregular topologies. The mechanism, referred to as logic-based distributed routing (LBDR), relies on three bits per output port at every switch and a small logic of several gates. The rest of the paper is organized as follows. In Section 2 related work is presented. Then, in Section 3 the system environment of LBDR is shown. In Section 4 the mechanism is presented and in Section 5 its deadlock-freedom and connectivity properties are demonstrated. In Section 6 some evaluation results are presented and the main beneﬁts of LBDR are exposed in Section 7. The paper is concluded with Section 8. 8888 2 Related Work Some work on the reduction of memory requirements for routing in NoCs already exists. One solution is Interval Routing [3]. With interval routing, sets of destinations requesting the same output ports are grouped. This method is speciﬁc for regular topologies. The FIR method [4] is an extension of interval routing for allowing different routing algorithms in meshes and tori networks. However, FIR is not applicable to irregular networks. Another solution is named street-sign routing [12]. In this method, only the router name of the next turn and the direction of the turn are included in the packet header. Recently, two solutions for irregular topologies have been proposed [5], [6]. In both cases, the destinations are grouped into regions and regions are coded into switches. A region is coded by the top left-most switch and the bottom right-most switch. Although the number of regions grows logarithmically with the number of failures, the number is unbounded and each region implies a logic. Another solution for routing table minimization is presented in [8]. In this case logic is used for the regular case and a deviation routing table is used for routing deviations. Although different solutions exist, none of them allows the implementation of distributed routing algorithms in irregular topologies with no routing tables and minimum logic. 3 System Environment For the sake of simplicity we focus on networks with no virtual channel requirements, and assume wormhole switching (although the proposed method also works for virtual cut-through switching as well). Messages (or packets in virtual cut-through) are routed with X and Y offsets assuming the X and Y coordinates of the ﬁnal destination are included in the message header (Xdst and Ydst ), and each switch knows its X and Y coordinates (through the Xcurr and Ycurr registers at each switch). LBDR can be applied to a combination of topologies and routing algorithms with some particular characteristics. The following paragraphs describe the conditions topologies and routing algorithms must meet. The typical topology of choice for NoCs is the 2D mesh network. However, with the advances of technology, other topologies may be suitable for NoCs. As the number of nodes increases some NoC components may fail. Therefore, topologies derived from an initial 2D mesh, but with some manufacturing defects or failures may come up. For instance, Figure 1 shows different topologies. Due to manufacturing defects some parts of the topology have been disabled for normal operation. This is the case for topology in Figure 1.c (p topology). In this case some nodes and links have been disabled. Equivalent topologies are the ones shown in Figures 1.d (q topology), 1.e (d topology), and 1.f (b topology). Obviously, there are other topologies with the same shape (p, q , d, or b) but with different number of nodes and links. Additionally, other circumstances may lead to the need for using irregular topologies. Examples are application-speciﬁc systems and chip/server virtualization (an example is shown in Figure 1.h). It should be noted that all the described topologies share the same property: all the end-nodes (assuming at least one end-node attached to each switch) can communicate with the rest of nodes through any minimal path deﬁned in the original mesh topology (the topology pictured in Figure 1.a). LBDR can be applied to all the topologies that fulﬁll this property. LBDR is, however, not applicable to topologies where some pairs of end-nodes cannot communicate through a minimal path deﬁned in the original 2-D mesh topology. Figure 1.g shows an example. Note that topologies with several disabled regions are suitable for LBDR. One example is shown in Figure 1.b. Notice that in this case all the end-nodes can communicate through minimal paths deﬁned in the original 2-D mesh topology. A deterministic (or partially adaptive) routing algorithm without cyclic dependencies among links or buffers can be represented by the set of routing restrictions it imposes. As an example, Figure 2 shows the routing restrictions deﬁned by X Y , SRh [6], SRv [6], and U D (up*/down*) [7] routing algorithms on a 2-D mesh topology and a p topology. Each arrow indicates a routing restriction. Basically, a routing restriction forbids any packet to use two consecutive channels. So, the ﬁnal paths for each pair of communicating end-nodes will not pass through any routing restriction. In this paper we deﬁne a routing restriction as the pair of channels that can not be used in sequence by any packet. For instance, at the ﬁrst (top left-most) switch in Figure 2.a there is a SE restriction 1 . As can be seen in the Figure, the X Y routing algorithm is designed only for the 2D mesh topology and it is unsuitable for non-regular topologies. Topology-agnostic routing algorithms like SRh , SRv , and U D can, however, be applied to any topology. LBDR is applicable to any routing algorithm that complies with the following condition: deﬁning the following two sets of channels {N,S} and {E,W}, all the routing restrictions are formed by two channels, each one from a different set. Thus, for instance, restriction EW is not allowed. In other words, routing restrictions forbid only some changes in the direction. Notice that this makes sense since it allows for minimal routing (restrictions like W E , EW , N S , SN , SS , N N . . . always force the need for nonminimal paths). Notice that all the routing algorithms pictured at Figure 2 comply with this requirement, since all the restrictions are: N E , N W , SE , SW (in the case of X Y ), W N , N W , N E , EN (in the case of SRh ), W N , N W , W S , SW (in the case of SRv ), and W N , N W (in the case 1Channels are labeled as N (North), E (East), W (West), and S (South). 8989 Figure 3. The LBDR method. of U D). Other routing algorithms like FX [9] and Turn Model [10] also adhere to these conditions, thus they can be implemented with LBDR. 4 LBDR Description Figure 3 shows the details of LBDR. It relies on the use of only three bits per switch output port. Therefore, 12 bits in total per switch. The value of these bits depends on the topology and the routing algorithm being implemented, and are computed and uploaded to the switches before normal operation (at system boot). Bits are grouped in two sets: routing bits and connectivity bits. Routing bits indicate which routing options can be taken, whereas connectivity bits indicate whether a switch is connected with its neighbors. Regarding the routing bits, the bits for the E output port are labeled Ren and Res . They indicate whether packets routed through the E output port may take the N port or S port at the next switch, respectively. In other words, these bits indicate whether packets are allowed to change direction at the next switch. For output port N the bits are accordingly labeled Rne and Rnw , for output port W Rwn and Rws , and for output port S Rse and Rsw . Regarding the connectivity bits, each output port has a bit, referred to as Cx indicating whether a switch is connected through the x port. Thus, connectivity bits are Cn , Ce , Cw , and Cs . Figure 4 shows two examples of all the bits at every switch for an irregular topology when using two different routing algorithms: SRh and U D . Routing logic of LBDR is divided in two parts (see Figure 3). The ﬁrst part computes the relative position of the packet’s destination. For this, two comparators are used and Xcurr and Ycurr are compared with Xdst and Ydst . At the the packet is in the N W quadrant then N (cid:1) output of this logic one or two signals may be active (e.g. if and W (cid:1) signals are active). Note also that packets forwarded to the local port are excluded from the routing logic. Once the N (cid:1) , E (cid:1) , W (cid:1) , and S (cid:1) signals are computed, the second part of the logic comes into play. It consists of four logic units, one for each output port. Each one can be implemented with only two inverters, four AND gates and one OR gate. As all of them are similar we describe here only the logic associated with the N output port. The N output port is considered for routing the incoming packet when either one of the following three conditions is met. If none of the conditions is met, then the N port can not be considered for routing the packet (additionally, the connectivity bit Cn is inspected in order to ﬁlter the N port): • The packet’s destination is on the same column (N (cid:1) × E (cid:1) × W (cid:1) ). • The packet’s destination is on the N E quadrant and the packet can take the E port at the next switch through the N port (N (cid:1) × E (cid:1) × Rne ). • The packet’s destination is on the N W quadrant and the packet can take the W port at the next switch through the N port (N (cid:1) × W (cid:1) × Rnw ). 9090 h c t i w S 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 (a) SRh routing w e n n R R n s e e R R n s w w R R w e s s R R 11 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 11 1 1 1 0 n e w C C C C s 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 2 6 3 7 path 0 4 8 1 5 9 12 13 1 1 1 1 0 1 1 1 1 1 1 1 1 1 11 1 1 0 0 1 0 1 0 (b) U D routing Figure 4. Example of LBDR for an irregular (p) topology. Notice that, for example, N and E signals could be active at the same time. In this case, the switch has to choose among them in the arbiter unit, according whether adaptiveness is allowed or the routing algorithm is deterministic. LBDR will mimic performance in most of the routing algorithms. This is the case for the X Y and U D routing algorithms. In these algorithms, the routing restrictions are located in the same relative position through all the rows and columns. As an example, Figure 4.b shows all the bits for the U D routing algorithm in a p topology. Imagine the path from source 1 to destination 8 as it is shown in Figure 4.b. Notice that output port S is not taken at switch 1 because there is a N W routing restriction at switch 5 (bit Rsw is zero at switch 1). This decision does not impact performance, as the S output port cannot be taken to forward properly the packet (packet would never be able to turn to W in the column). This is a very interesting observation as it allows LBDR to achieve the maximum performance of the routing algorithm with very low logic/area requirements (the same applies for X Y routing in a 2D mesh topology). However, there are situations (e.g. more advanced routing algorithms like SR) where LBDR induces some inefﬁciencies. An example can be seen in Figure 4.a. In this case, like before, switch 1 decides to discard output port S because its Rsw bit is not active (there is a N W restriction at the next switch through the S port). However, in this case, a valid path would be 1-5-9-8. Therefore, LBDR reduces adaptiveness. Although LBDR is still working (it always provides a valid set of paths) the performance degradation could be unacceptable (see Section 6). In order to ﬁx this, we extend in the next section the mechanism to overcome this problem. However, bear in mind that if we change the routing algorithm to UD, the problem disappears. It is important to note that only the bits referring to a routing restriction are set to zero and the remaining ones are set to one, even those that refer to switches not existing in the topology (for instance bit Rnw at switch 0). However, they must be set to one in order the mechanism to work properly. This can be better seen through an example. Imagine the path at Figure 4.a from switch 13 to switch 7. At switch 13 the signals N’ and W’ are active. Also, signals N (cid:1)(cid:1) and W (cid:1)(cid:1) are active. In particular, N (cid:1)(cid:1) is activated as Rne at switch 13 is set to one, although it does not make sense for routing purposes. However, this allows the packet to being forwarded north, until it reaches switch 5, where it can take the east direction. Notice that output port E will never be taken at switches 13 and 9 due to the connectivity bit Ce . Deadlock freedom is guaranteed by the underlying routing algorithm. If packets do not cross any routing restriction then no cycle can be formed. Notice that a packet is forwarded by LBDR by using the Rxy routing bits, thus, ensuring no routing restriction is crossed. Connectivity is also guaranteed since LBDR uses all the possible minimal paths provided by the underlying routing algorithm. Formal demonstrations can be found on Section 5. 4.1 LBDRe Figure 5 describes the extended LBDR method. We refer to is as LBDRe. As can be seen, the routing and connectivity bits (3 bits per output port) are still maintained, and they are computed in the same way. Four new bits per switch output port are, however, added. The bits labeled R2xy indicate whether the y direction can be taken two hops away from the current switch through the x direction. For example, R2ne indicates whether a packet is allowed to change direction to E at the switch 9191 Figure 5. The LBDRe method. located two hops in the N direction. Notice that this set of bits have similar meaning with the ones used in LBDR. In some sense, these bits provide visibility to the switch of the routing possibilities two hops away. However, it must be stated that these bits must be not active if they refer to a non-existing switch. For instance, in Figure 6 the R2nw bit at switch 4 is not active. The bits labeled RRxy indicate whether there is a routing restriction between x and y channels at the current switch. These bits are needed in order to avoid the formation of cycles, which is described in the example below. To sum up, LBDRe requires 24 routing bits grouped by 6 bits per output port. Figure 6 shows an example of the LBDRe bits for a p topology. Additionally, the switch needs ﬁve internal signals ipN , ipE , ipW , ipS and ipL to indicate the incoming port of the packet being routed. The ﬁrst part of the routing logic is slightly augmented compared to LBDR. In particular, based on the X and Y coordinates of the current switch and the packet’s destination, the logic computes the relative directions N (cid:1) , E (cid:1) , W (cid:1) , and . Additionally, four extra signals N 2, E 2, W 2 and S 2 are computed. These signals are active if the packet’s destination is at least two hops away in the corresponding direction (if N 2 is active, then at least two hops must be done in the N direction to get closer to packet’s destination). Notice that these signals can be easily computed with additional comparators with the Xcurr and Ycurr coordinates shifted in one position. S (cid:1) 9292 , E (cid:1)(cid:1) , S (cid:1)(cid:1) , W (cid:1)(cid:1) The ﬁrst part of the logic is also in charge of inhibiting the possible output ports that would lead crossing a routing restriction. For this, the RR (routing restriction) ﬁlter logic is used. This logic requires two inverters, three AND gates and one OR gate per output port. The resulting signals are labeled as N (cid:1)(cid:1) . They feed the ﬁnal part of the logic. The second part evaluates the routing options at the onehop and two-hops neighbors. For this, the previous logic functions for LBDR have been extended. For instance, for the output port N , the port will be selected if any one of the following conditions are met: • The packet’s destination is on the same column (N (cid:1) × E (cid:1) × W (cid:1) ). • The packet’s destination is on the N E quadrant and the the N port (N (cid:1) × E (cid:1) × Rne ). packet can take the E port at the next switch through • The packet’s destination is on the N W quadrant and the packet can take the W port at the next switch through the N port (N (cid:1) × W (cid:1) × Rnw ). • The packet’s destination is on the N E quadrant, the packet’s destination is at least two hops away through the N port, and the packet can take the E port at the two-hops neighbor switch through the N port (N 2 × E (cid:1) × R2ne ). 1 1 1 1 1 1 11 0 1 0 1 0 1 11 1 1 11 1 1 1 0 1 0 1 0 0 1 1 1 11 11 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 00 0 0 0 0 0 1 0 0 0 0 10 0 0 00 0 0 0 0 00 0 0 0 0 R R e s s w R R 2 2 e s s w 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 11 11 11 11 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 11 1 1 1 1 1 1 11 10 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 path 4 0 1 2 3 7 6 5 8 9 12 13 path 10 0 1 0 111 0 1 1 1 0 0 11 1 1 0 1 1111 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 S w t i h c R R e n n 2 2 w R R e n n w R R n s e e R R n s e e 2 2 w w R R n s R R 2 2 w w n s R R R R e n n w w w R R R R R R R R R R R R n s e e n s e s s w w C C C C n e s Figure 6. Example of LBDRe for an irregular (p) topology and SRh routing algorithm. • The packet’s destination is on the N W quadrant, the packet’s destination is at least two hops away through the N port, and the packet can take the W port at the two-hops neighbor switch through the N port (N 2 × W (cid:1) × R2nw ). Finally, the connectivity bit Cn and the routingrestriction ﬁlter (N (cid:1)(cid:1) ) are used to ﬁlter the output port. For the remaining ports, similar deductions are considered. Notice that the LBDRe mechanism solves the problem found with LBDR. Figure 6 shows two possible paths from source 1 to destination 8. At switch 1, the S output port can now be taken because the R2sw bit is active and the internal S 2 signal will be activated. Note also that switch 5 has its RRnw bit active, thus avoiding taking the W output port at the current switch, which would lead to an invalid path. With LBDRe, the SRh routing algorithm can be applied with no performance degradation. We will demonstrate this afﬁrmation in Section 6. 5 Deadlock-freedom and Connectivity In this Section we demonstrate that LBDR is deadlockfree and provides connectivity among all the end-nodes. It must be noted that this can also be applied to LBDRe. As it has been shown before, LBDRe embeds LBDR and therefore it inherits all of its properties. 5.1 Deadlock-freedom LBDR is not restricted to any particular routing algorithm. Instead, it can support any routing algorithm that provides minimal paths for every pair of end-nodes (as we see in Figure 2.e XY is a bad choice as it does not provide connectivity in an irregular topology). However, the applied routing algorithm must ensure deadlock-freedom and LBDR has to maintain such property. LBDR computes the routing bits from the routing restrictions deﬁned by the routing algorithm. The algorithm is deadlock free if no packet crosses a forbidden routing restriction. Therefore, LBDR must ensure that no packet crosses any routing restriction deﬁned by the routing algorithm. Imagine there is a deadlock in the network induced by a set of packets that are requesting buffers in a cyclic manner. In that situation a packet in a switch sw along the cycle is mapped at a buffer in an input port i and is requesting an output port o for which a routing restriction is deﬁned between i and o. Without lose of generality, consider the input port is S and the output port being requested is W . Hence, a SW routing restriction is deﬁned at switch sw . As routing restrictions are assigned only to links between switches (links connecting end-nodes are excluded), the given packet has previously been forwarded from a previous switch (swp ). The output port used to forward the packet at swp is N . At this switch the routing bit Rnw is set to zero (since there is a SW routing restriction at switch sw). Additionally when routing the packet at switch swp the signals N’ and W’ were active as the packet is now requesting output port W at switch sw . Looking at the LBDR logic for output port N , at switch swp the N port can not be selected since none of the outputs of the AND gates will be active (x1=x2=x3=0, see Figure 3). Indeed, the packet is in the N W direction and the Rnw bit is not active. Therefore, this situation can not be induced and thus LBDR is deadlock-free. Similar conclusions can be obtained when assuming different sets of forbidden routing restrictions (N E , SE and SW ). 9393 switch 13 has its destination at the N E quadrant. Switch 13, however, is at the boundaries of the topology. In this case, switch 13 has its Ren and Rne bits active. However, its connectivity bit Ce is not active. In this situation the N port is eligible. Notice that the packet will go north until it reaches switch 5 where it will take either N or E . Figure 7. Path taken on boundaries at (p) topology . 6 Performance Evaluation 5.2 Connectivity To demonstrate that the mechanism provides connectivity we must ﬁrst highlight that the routing algorithm implemented by LBDR provides minimal paths and connectivity among all the pairs of end-nodes. Notice that on each hop a packet performs in the network it gets closer to its destination. From the LBDR logic we can also deduce that non-minimal paths are avoided. Each output port is candidate for being selected only if the destination’s distance is reduced along that port. For instance, the N port is eligible only if the packet is in the north direction or in the N W or N E quadrants (the signal N’ is active). Consider the case that a pair of end-nodes can not communicate when using LBDR. In this case, although the routing algorithm provides at least one minimal path to reach the destination end-node the LBDR mechanism fails to provide such path. In that situation, there is a point in the network where either LBDR logic provides a non-minimal path or any of the minimal paths are not eligible. As an example, consider Figure 7 and the routing unit at switch 8. The packet’s destination is switch 3, thus is in the N E quadrant. In that situation the W and S ports are not considered by LBDR since the W’ and S’ signals are not active. In other words, the packet’s destination is neither in the W’ nor S’ directions. Thus, LBDR avoids non-minimal paths. Therefore, only the N and E directions may be considered. In this case N’ and E’ signals are activated. In that situation, notice that the N port is eligible only if the Rne bit is active and the E port is eligible only if the Ren bit is active. Notice that both bits can not be zero at the same time. In that case there would be no connectivity between switches 8 and 5 and thus, the routing algorithm implemented would not guarantee connectivity. As this situation is not assumed by the routing algorithm, it can not happen, and therefore LBDR guarantees connectivity. Therefore, at least one output port (N or E ) will be eligible for routing the packet, getting closer to its destination. However, a subtle case arises in the boundaries of the topology. Figure 7 shows a p topology and the packet at 9494 In this Section we evaluate LBDR and LBDRe. Our goal is to evaluate the performance when applied to different topologies/routing algorithms compared with the performance achieved by those routing algorithms when implemented with routing tables. We check if LBDR and LBDRe mimic the performance of routing tables and by how much (and in which circumstances) they lose performance. We have used noxim [11] to evaluate LBDR and LBDRe. In all simulations wormhole switching is assumed, input port buffers are 4-ﬂit deep, and packets are 32-ﬂit long. Flit size is set to one byte. For the transient state, 40K messages are assumed and results are collected after 40K messages are received. X Y , U D , and SRh routing algorithms have been evaluated in an 8 × 8 mesh and different irregular topologies: p, q , d, and b topologies (an 8 × 8 mesh without an 4 × 4 sub-mesh). Uniform and transpose trafﬁc has been used. Figure 8 shows the performance (delivered throughput) for some of the analyzed cases. In all the situations the same basic conclusions can be extracted. First, it can be seen that for X Y (in 2D mesh) and U D (in 2D mesh and p topology) LBDR mimics the performance achieved with traditional implementation (routing tables). This is achieved because in both cases all the routing restrictions are aligned through the same columns and rows and this permits LBDR to achieve maximum performance. Second, it can be seen that for SRh , LBDR achieves different performance numbers. The loss in performance is 15% in transpose trafﬁc and negligible in random trafﬁc. Finally, Figures 9 and 10 show some interesting performance numbers for SRh and U D in two different irregular topologies. We can see, that when we apply LBDRe method, as we explained before, for a more complex routing algorithm like SRh , it performs better than its counterpart on LBDR, even better than U D routing algorithm at low loads, as shown in Figure 9. Both topologies (d and b) have the same shape once they are rotated accordingly, however, we can see that the impact of the routing algorithm can be signiﬁcant. Indeed, for b topology the achieved performance is higher than in d topology. This yields for interesting future research on ﬁnding the best practices in partitioning a NoC.  0  0.05  0.1  0.15  0.2  0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 Injected traffic (flits/IP) A p e c c t d e r t a i f f c t i l f ( s I / P ) UD (table, LBDR, LBDRe) XY (logic, LBDR, LBDRe) SRh (table, LBDRe) SRh (LBDR) (a) transpose, 2D mesh  0  0.05  0.1  0.15  0.2  0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 (flits/IP) D U t ( b a l e , R D B L , R D B L e ) XY (logic, LBDR, LBDRe) SRh (table, LBDRe) SRh (LBDR) (b) random, 2D mesh  0  0.05  0.1  0.15  0.2  0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 Injected traffic (flits/IP) A p e c c t d e r t a i f f c t i l f ( s I / P ) UD (table, LBDR, LBDRe) SRh (table, LBDRe) SRh (LBDR) (c) random, p topology Figure 8. Performance achieved for different routing algorithms, different topologies, and different trafﬁc patterns.  0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0  0.02  0.04  0.06  0.08  0.1  0.12 Injected traffic (flits/IP)  0.14  0.16  0.18 A p e c c t d e r t a i f f c t i l f ( s I / P ) LBDR and LBDRe Up*/Down* LBDR SRh LBDRe SRh Figure 9. Performance achieved for different routing algorithms and a d topology for both methods. Random trafﬁc. 7 Beneﬁts of LBDR The beneﬁts of LBDR are important (with no performance degradation at all). With alternative implementations the routing information needs to be stored either at source nodes (with source routing) or at switches (with distributed routing). In both cases routing tables are used. Each table needs as many entries as potential destinations can be addressed from the source or the switch. As the communication pattern in a multi-core is not known in advance the worst case must be assumed. Thus, for a N × N system up to N 2 entries are needed. Thus, the memory (and area) requirements for alternative implementations grow with system size. With LBDR, however, the requirements are the same regardless of system size. Only three bits for LBDR (7 bits for LBDRe) and a few gates are required per output port. In the same sense power saving can be signiﬁcant as all the power required by each routing memory is saved.  0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0  0.02  0.04  0.06  0.08  0.1  0.12 Injected traffic (flits/IP)  0.14  0.16  0.18 A p e c c t d e r t a i f f c t i l f ( s I / P ) LBDR and LBDRe Up*/Down* LBDR SRh LBDRe SRh Figure 10. Performance achieved for different routing algorithms and a b topology for both methods. Random trafﬁc. Moreover, the latency of LBDR could be smaller than the one expected by a table-based implementation. The routing delay of LBDR is given by the time required to compute the relative position of the destination (two comparators in parallel) and the logic associated to each output port (four levels of logic gates). This hardware has an approximate delay of 10 logic gates and very similar to the delay of an X Y implementation. As a rough comparison, based on the model proposed in [13, 14] for caches, an access to a routing table should have a delay similar to accessing the data array of a cache. According to [13], for a 0.13 µ m CMOS technology, this value ranges from 0.8 ns for a 4 K cache to more than 2.9 ns for 1 M cache. In the same model a single logic gate has a delay of about 67 ps. Hence, LBDR has a delay of about 0.67 ns. For 90nm technology, gate delays of 9.5ps are available [15], thus the LBDR delay will be 95 ps (not considering wiring delays). 9595                       Routing in Mesh Topology NoC Architecture,” in International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS), 2006. [6] J. Flich, A. Mej´ıa, P. L ´opez, and J. Duato, ”RegionBased Routing: An Efﬁcient Routing Mechanism to Tackle Unreliable Hardware in Networks on Chip”, in First International Symposium on Networks on Chip (ISNOC), 2007. [7] D. Gelernter, ”A DAG-based algorithm for prevention of store-and-forward deadlock in packet networks,” in IEEE Transactions on Computers, 30(10):709-715, Oct. 1981. [8] E. Bolotin, I. Cidon, R. Ginosar, and A. Kolodny, ”Routing Table Minimization for Irregular Mesh NoCs”, in International Conference on Design, Automation and Test in Europe (DATE), 2007. [9] J.C. Sancho, A. Robles, and J. Duato, ”A Flexible Routing Schemes for Networks of Workstations”, Third International Symposium on High Performance Computing (ISHPC), 2000. [10] C. Glass and L. Ni, ”The Turn Model for Adaptive Routing,” in International Conference on Computer Architecture (ISCA), 1992. [11] Noxim: Network-on-Chip simulator, available at http://noxim.sourceforge.net. [12] S. Borkar et. al, ”iWarp: An Integrated Solution to High-Speed Parallel Computing,” in Supercomputing Conference, 1988. [13] J.E. Wilton, N.P. Jouppi, ”An enhanced access and cycle time model for on-chip caches”, Technical Report 93/5, Western Research Laboratory, 1993. [14] P. Shivakumar, N. Jouppi, ”CACTI 3.0: An integrated cache timing, power and area model”, Technical Report 2001/2, Western Research Laboratoy, 2001. [15] Toshiba, product guide 2003, available at http: //www.toshiba.com/taec/components/ Generic/cmosasic tc300prodbroch.pdf 8 Conclusions In this paper we have presented the LBDR mechanism and its extension, LBDRe. They allow for efﬁcient implementation of most of the existing distributed routing algorithms in suitable topologies for NoCs. For LBDR only two routing bits and one connectivity bit are required along with a small logic per output port. For LBDRe four more bits are required along with the bits existing in LBDR. A bit complex logic than in LBDR method is required but it ensures better performance. LBDR mimics the performance achieved by X Y and U D routing algorithms when implemented using routing tables. For more sophisticated routing algorithms, like SRh , the LBDRe method may be used. Although not evaluated we have analyzed the extension of LBDR with additional visibility routing bits and obtained no performance gains with any routing algorithm. Therefore, LBDRe, provides enough visibility to extract the full potential of any routing algorithm on an irregular topology. Also, we would like to point that although LBDR loses some performance with some routing algorithms it is much more attractive than LBDRe, due to its simplicity. Also, with a proper routing algorithm (XY and/or UD) the performance penalty is eliminated. As future work, the applicability of LBDR and LBDRe for chip/system virtualization is meant to be deeply analyzed. Some example of this analysis could be NoC partitioning (we want to assure coherency and isolation for every part, e.g. different running applications) or dealing with failures. Further studies of area, power and delay reductions (with much more detail) are also on their way. We are currently working on designing and synthetizing the LBDR solution to compare it with a table-based solution. "
A Network of Time-Division Multiplexed Wiring for FPGAs.,Our investigation into networks-on-chip for field- programmable gate arrays (FPGAs) indicates that fine-grain time-division multiplexing over configurable wires can significantly reduce the number of interconnects needed and therefore reduce chip area. We have investigated the impact of using different proportions of time-multiplexed shared wiring and conventional wiring on the number of wires needed per channel. To do this we have written a scheduler to map benchmarks to the wire sharing architecture. The algorithm developed allows us to trade off between wire count and latency. This is the first time that the statically configured FPGA wiring has been entirely replaced by time-multiplexed wiring. Our results indicate that time-multiplexed wiring could be an effective way of making better use of the on-chip resources and enable the use of on-chip networks with low overheads.,"Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip A Network of Time-Division Multiplexed Wiring for FPGAs Rosemary Francis, Simon Moore, Robert Mullins Computer Lab University of Cambridge {Rosemary.Francis, Simon.Moore, Robert.Mullins}@cl.cam.ac.uk Abstract Our investigation into Networks-on-Chip for FieldProgrammable Gate Arrays (FPGAs) indicates that ﬁnegrain time-division multiplexing over conﬁgurable wires can signiﬁcantly reduce the number of interconnects needed and therefore reduce chip area. We have investigated the impact of using different proportions of time-multiplexed shared wiring and conventional wiring on the number of wires needed per channel. To do this we have written a scheduler to map benchmarks to the wire sharing architecture. The algorithm developed allows us to trade off between wire count and latency. This is the ﬁrst time that the statically conﬁgured FPGA wiring has been entirely replaced by time-multiplexed wiring. Our results indicate that time-multiplexed wiring could be an effective way of making better use of the on-chip resources and enable the use of on-chip networks with low overheads. 1 Introduction Increase in FPGA capacity combined with CMOS technology scaling has resulted in increased demands on the conﬁgurable wiring architecture. While the silicon area given over to conﬁgurable wiring has remained at around 50% for the last few generations, the way we use FPGAs is changing. Multi-cycle communication across chip will lead to latency tolerant design. In order to maintain clock speeds, communications will need to be pipelined; it is a small step to then send the data over a network. Separately, migrating commonly used structures such as processor cores and digital signal processing modules to hard blocks is a technique employed by most FPGA manufacturers. This serves not only to cut down on power consumption, but also makes more effective use of the chip area. While hard blocks go a long way to accelerate the performance of mapped systems, the reconﬁgurable FPGA fabric still lags behind in timing, power and area. The increasing fault rates of new technologies, as well as other issues, are pushing up the cost of ASIC production. The market for FPGAs is only going to expand as it becomes less economically feasible to produce a hard-core custom solution. FPGAs need to adapt to meet this demand while maintaining the levels of abstraction needed for platform independence and ease of programming. We propose the development of an FPGA architecture with a hierarchy of networks to meet the demand of future applications (see Figure 1). To cope with increasingly partitioned systems-on-chip with heterogeneous hard blocks within the FPGA, an adaptable, intelligent Networkon-Chip (NoC) will need to be available. High network bandwidth combined with low latency and low resource usage will be the goal. As technology scaling favours transistors over wires [16] we have been looking at a more effective way of bridging the gap between local static routing and coarse grain NoC. To reduce the amount of wiring on the FPGA, we have been working on sharing the wires effectively without requiring signiﬁcantly more conﬁguration logic or signiﬁcantly extending the critical path. We have developed a scheme whereby conﬁgurable interconnect wires are shared by Time-Division Multiplexing (TDM) signals in a prescheduled network. In this paper we present the results of a scheduling algorithm that maps designs to TDM wiring architectures. In doing so we demonstrate that TDM can be used to reduce the amount of wiring within the FPGA. We then discuss the impact the wiring could have on the logic density and on the implementation of scalable coarse-grain routing networks. 1.1 Time-Division Multiplexing Time-Division Multiplexing (TDM) has been used to improve resource usage on FPGAs in areas of research such as multi-context FPGAs [13], but we aim to adapt the FPGA architecture to allow time-division multiplexing over individual wire segments within the FPGA. We have developed a scheme whereby wires are used by multiple sig978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.21 DOI 10.1109/NOCS.2008.21 35 35 Figure 1. A hierarchy of static, timemultiplexed and packet-switched routing nals within a design clock cycle. We pipeline previously static paths over TDM wiring to achieve high data rates using fewer wires. The interconnect latches are clocked at a much higher rate than the design latches. Signals are serially scheduled at compile time onto shared wires by allocating them in time as well as space. Similar architecture have been patented recently [15, 14] and outline additional components that must be incorporated into programmable logic devices to implement TDM wiring. Both describe TDM wiring that runs alongside the conventional static wiring. As with our architecture, they intend to use this wiring for low priority signalling. However, they do not consider the feasibility of designing or using such an architecture. In order to evaluate the potential of this shared wiring we have written a scheduler to map designs from modern conventional FPGAs onto new shared wiring FPGAs. Conﬂicts arise when more than one signal requires the same wire in a given time slot. In this case one of the wires needs to be moved onto non-shared wiring or buffered on previous wires. The scheduler makes these decisions in order to minimise the amount of wiring and conﬁguration SRAM required. We will use the higher data rate enabled by the TDM architecture to design an effective global NoC infrastructure. Much of the arbitration can be performed at compile time thus reducing logic block utilisation. Network routers can be placed to make full use of the wire sharing capability. We will be able to implement a global interconnect network with the ﬂexibility of a conﬁgurable interconnect network, but with a clock frequency comparable to a VLSI network. Figure 2. Stratix FPGA Architecture with static wiring Figure 3. FPGA Architecture with TimeDivision Multiplexed Wiring 1.2 FPGA Architecture In order for our results to be widely applicable, we have chosen the Stratix [8] architecture as a starting point for our research. The logic elements (LEs) contain 4-input lookup tables (LUTs) and a synchronous latch. The LEs are grouped into clusters with local interconnect and local carry chains. The local interconnect can be used to drive LEs within the cluster neighbouring local interconnect or global interconnect. Each logic block cluster is associated with a switch box containing conﬁguration for the global interconnect (see Figure 2). The global interconnect consists of horizontal and vertical wire segments running in a mesh of channels between the logic clusters. The segments are staggered to produce a homogeneous architecture. They can drive other wires via the switch boxes at either end of the segments and at selected intermediate switch boxes. Their length is deﬁned by the number of switch boxes they span. Stratix wire segments are of length 4, 8, 16 (column only) and 24 (row only). It is the global routing segments that have been the focus for our study of time division multiplexing. Wires are iden3636 tiﬁed by their length, orientation and the switch box connected to their lower leftmost end. Channel width refers to the number of wires between any two switch boxes. This can be calculated from the number of wires at each coordinate by multiplying the wire frequency by the length of each wire. For example, ﬁve R4 wires at each switch box gives a channel width of 20 because each wire spans four CLBs, so we must count the wires located at the four switch boxes to the left in the channel count. Modern FPGAs with static routing use single driver routing for timing and area efﬁciency. This means that in a homogeneous architecture the number of wires driven per switch box will be half the number of wires terminating at that location. We can therefore characterise the architecture by how many wires have their lower left-most end at each switch box. We refer to this value as the number of wires per switch box from now on. In this paper we refer to hard and soft IP blocks. IP blocks are units of a System-on-Chip that can be implemented in the conﬁgurable logic (soft-core) or in silicon alongside the FPGA (hard-core). The Stratix contains hardcore memory blocks and DSP blocks as well as conﬁgurable routing. Other FPGAs contain hard-core processors. The value and impact of these blocks is a subject of discussion [3]. We have developed a model of an FPGA architecture with time-division multiplexed wiring based on the Stratix. We have used this model to test a scheduling algorithm which maps circuits to our new architecture. We now describe the architecture, the scheduling algorithm and the experiments we carried out with a selection of benchmarks. 2 Time-Division Multiplexed Wiring Architecture To implement time-division multiplexing over global interconnect wiring, interconnect latches are added to each global wire segment and extra conﬁguration bits are added to the switch boxes. The latches are clocked at a higher rate than the design clock to allow data to pass between logic block registers in one design clock cycle. The TDM wiring is used by dividing each design clock cycle into a series of time slots, representing the cycles of the interconnect clock. There is a conﬁguration bit for each time slot. Wires are shared by scheduling signals with different time slots onto the same wire. We developed a scheduling algorithm to investigate how far the wire count can be reduced. Each interconnect latch may have to hold its data for many time slots because the delay to the destination latches can vary between conﬁgurations. If the interconnect clock is n times faster than the design clock then each conﬁguration bit driving a shareable global wire connection must be replaced by n bits. The conﬁguration bit is selected by a log2n bit counter. Figure 3 shows the additional conﬁguration SRAM and the extra latch that needs to be added in comparison with Figure 2, which represents a conventional FPGA architecture. Although extra conﬁguration logic is added to each wire driver in the switch box, the reduction in the amount of wiring reduces the number of drivers. We believe that this will lead to an overall reduction in chip area when coupled with the reduction in wire buffering area. In addition to changes made in the switch box, the inputs to the LUTs must also be latched. This is to allow the local interconnect within a logic block cluster to be driven by one global interconnect wire. We have allowed the TDM wires to be bidirectional. While this moves away from single driver routing, early work on the beneﬁts of single driver wiring [7] showed that with good routing algorithms there was very little difference between single driver and bidirectional wiring in terms of channel width. Our scheduling algorithm is not able to reroute signals between channels and so we allowed bidirectional wires to compensate. 3 Scheduling Algorithm The scheduler takes a graph of each benchmark, as mapped to a conventional FPGA, and re-maps it onto a TDM FPGA. This is achieved by assigning the time slots of each wire to the edges in the graph representing global interconnect. The benchmark graph is constructed from a custom timing and routing ﬁle generated by a TCL script. The TCL script calls Quartus executables to place and route the design, perform timing analysis and then output tables of placement, routing and timing information for every wire mapped onto the FPGA. The scheduler is architecture independent and can be conﬁgured to investigate any homogeneous FPGA architecture. In the ﬁrst scheduling stage it is assumed that there are an inﬁnite number of wires and that each wire in the graph will be assigned to a physical wire on the FPGA for its required time slots. Signals are scheduled by assigning a ﬁrst and last time slot to each of their wires. This determines the duration for which the signals must be assigned to physical resources. Each signal must remain assigned to an interconnect latch until all destination latches in the signal fanout have receive the data. This may take multiple time slots. This also will vary between signals as they take different paths though non-TDM wiring. It is this variable delay requirement between interconnect latches that forces us to use ﬁne-grain 3737 time slots to share wires effectively. The second scheduling stage maps the signals in the graph onto physical wires on the device. To do this the scheduler resolves conﬂicts caused by too many signals requesting the same time slots in the same channel. Conﬂicts occur when more wires need to be mapped to a given location with the same time slot than there are wires on the device. Conﬂicts can be resolved in either of two ways: 1. Wires can be descheduled. This means that they can be mapped to conventional, non-shared wiring if necessary thus removing the conﬂict from the shared wiring, but possibly causing the wire count to increase. 2. Conﬂicts can also be removed by delaying signals until a free slot is available. Earlier schedules can be extended to allow the signal to take more time to propagate. This keeps the number of wires required low, but at the expense of delaying signals and possibly causing additional conﬂicts elsewhere. Decisions are made depending on the cost of rescheduling. Some wires can be rescheduled without affecting wires later in the path because there is slack in the timing. Those which do not effect the critical path and do not cause further conﬂicts are selected for rescheduling over those with higher cost. If the wire selected for rescheduling will cause the critical path to extend beyond the maximum time slot then that wire is descheduled and mapped to non-shared wiring. Wires are not descheduled under any other circumstances. After a conﬂict is removed the surrounding schedules are updated. Once all conﬂicts have been resolved, the schedule is analysed. Not all the shared wiring has to be pipelined on the wire so non-scheduled wires can sometimes be mapped to shared wiring. This is performed prior to analysis. Nonscheduled wires with short scheduling demands are given priority over those that need wire resources for a long time. 3.1 Algorithm Performance The scheduling algorithm was developed to demonstrate the potential of TDM wiring. It is not optimised for performance. Ideally one would start from the design source a the RTL level and rewrite the CAD tool chain to make full use of the shared wiring. The scheduler has been developed to demonstrate that designs can be mapped to FPGAs with TDM wiring and that this leads to a reduction in the number of wires. Therefore, when looking at the results section it is necessary to bear in mind that the reduction in the number of wires required is itself sub-optimal. 3.2 Architectural parameters When using the scheduler we are able to vary the following parameters: Number of Time Slots This is the ratio of design clock frequency to interconnect clock frequency and is determined by the number of conﬁguration bits at each conﬁgurable switch. A time slot represents a single interconnect clock cycle and therefore the number of time slots is the same as the number of conﬁguration bits. Length of Time Slot Combined with the number of time slots, this determines the latency of the design. The length of the time slot can be varied from design to design. The minimum is determined by the maximum frequency of the interconnect clock. We have assumed that the interconnect clock can support up to 2 GHz, which limits the time slot length to 500ps. Many designs perform better with longer time slots. Number of Shared Wires per Switch Box The shared wires are differentiated by their orientation, row (R) or column, (C) and by the number of logic clusters they span. The Stratix has six global wire types with many in each channel so we must have a minimum of six shared wires at each switch box (on the north and east sides). The scheduler is unable to move signals between channels or wire types. Therefore the ratio of wire types is heavily inﬂuenced by the Stratix architecture and the Quartus placement and routing tool. This does not detract from the value of our results because we are presenting the impact of TDM wiring, not a fully developed architecture. 4 Experimental Results We present the trade-offs between the number of wires per switch box, amount of conﬁguration SRAM per wire and latency of the critical path for each benchmark. At this stage we are performing implementation independent investigations. We therefore do not take into account the delay overhead of the interconnect latches, only the scheduling penalty. 4.1 Benchmarks The benchmarks were taken from the QuartusII University Interface Program. We selected the largest designs and mapped them to the smallest Stratix device possible. Table 1 lists the benchmarks along with the number of lookup tables (LUTs) used and the number of wires in the most contested switch box. 3838 Table 1. QuartusII University Interface Program Benchmarks Benchmark LUTs A barrel64 B aes core C ata ocidec1 D des3area E ata ocidec3 F mem ctrl G hdlc H ata ocidec2 I vga lcd J video huff enc K blowﬁsh L mux32 16bit M des perf opt N des area opt O pci P aes core inv Q cfft 1024x12 R mux64 16bit S wb dma 882 1680 540 1135 1045 3972 640 588 2207 613 1527 853 5336 691 2439 1947 1655 1702 3479 IO Mem Wires per switch box 39 41 16 27 30 49 37 23 47 35 50 39 46 17 57 50 49 60 66 0 32768 0 0 224 0 0 0 32640 0 67168 0 0 0 1720 34176 24576 0 0 136 388 125 304 130 267 82 125 585 23 585 54 185 189 367 389 68 87 444 The benchmarks were chosen to represent individual cores in a modern system. The motivation for the research was to investigate the performance of isolated IP cores within a time-division multiplexed (TDM) architecture. As systems increase in complexity, design reuse has never been more crucial. With good performance from the cores we can then go on to design a high performance interconnect architecture tailored to make full use of the TDM wiring. 4.2 Number of Wires per Switchbox Figure 4 presents the total number of wires (TDM + static) needed to route the benchmarks given different conﬁgurations of TDM wiring. The wire conﬁgurations are shown on the x-axis. The benchmarks were allowed to use up to 64 time slots of 500ps. We increased the amount of TDM wiring linearly whilst maintaining similar ratios to the Stratix and noted how much conventional wiring was still required to route the design. These results give us a clear indication of the lower limit of wire reduction. It was necessary to gather these limits so that we could make a quantitative evaluation of the results with limited latency and conﬁguration SRAM. Figure 4 demonstrates that only a few shared (TDM) wires makes a very large difference to the total number of wires per switch box. The majority of the benchmarks map entirely to shared wiring with very few wires. This supports 3939 Figure 4. Total number of wires per switchbox with maximum utilisation, given up to 64 time slots Table 2. Distribution of TDM wires R4 C4 R8 C8 R24 C16 Wire type TDM wires per switchbox 2 2 1 1 1 1 our hypothesis that the area gains in reducing the amount of wiring outweigh the possible costs of TDM. It is also interesting to note the range of results in Figure 4. A 500ps time slot will be suboptimal for many designs and the scheduling algorithm may not make the best decisions for others, however the range of results is very low. TDM wiring signiﬁcantly beneﬁts all the benchmarks investigated. 4.3 Number of Time Slots The number of time slots determines the amount of conﬁguration SRAM needed at each switch. It therefore dominates the cost of replacing a conventional wire segment with a TDM wire. Figure 5 shows the amount of wiring per switch box needed to map the benchmarks, with a selection of different numbers of time slots. Each switch box can drive eight TDM wires in the conﬁguration shown in Table 2. The algorithm then determines the minimum number of non-shared wires. The length of the time slots was increases from 500ps for each benchmark until no more beneﬁt was seen. The results are therefore optimised for the number of wires, not for latency. With as few as 8 time slots the number of wires increases for many benchmarks. This is because in many switch boxes the TDM wiring is not usable. It is not until 20 to 24 time slots that we see signiﬁcant reduction in the amount of wiring needed. The data points with one time slot represent a conventional FPGA architecture. In a conventional architecture Figure 5. Maximum number of wires per switchbox Figure 6. Latency of critical path normalised to the unscheduled case more than 60 wires would be needed in each switch box to map the benchmarks we have chosen. The large number of wires connecting to each switch box means that wires have to be divided into subsets to reduce the number of switches. While this does reduce the complexity of the switch boxes, it also increases the number of wires needed to effectively map the design. We have only included the number of wires used and so the number of wires needed is likely to be more in the conventional architecture than shown. With so few TDM wires, the TDM FPGAs will be able to afford totally populated switch boxes. The number of wires presented is the actual number of wires needed. Therefore the results presented in Figure 5 indicate that for reasonably low numbers of time slots and sensible interconnect clock speeds the amount of interconnect could be reduced by up to 83%. It is also reasonable to expect that the few benchmarks that require more than 24 time slots to reach the minimum amount of wiring or are not able to achieve complete mapping to TDM wiring are suffering from the inefﬁciency of our prototype CAD chain. Optimisation for this architecture at every point may well lead to even better results as wires with similar timing requirements can be mapped to different channels. Our algorithm suffers from not being able to spatially reroute the wiring. Figure 7. Amount of wiring needed in architectures with 24 time slots plications will not perform well on the TDM architecture. This does not however exclude the high speed digital signal processing applications because the IO can be run faster than the rest of the design and can drive replicated circuitry many times faster than the design can process it. For prototyping applications, TDM wired FPGAs will still be an order of magnitude faster than simulation. By reusing the on chip resources many times per clock cycle it is reasonable to expect that larger applications could be ﬁtted onto a TDM FPGA than a conventional one. 4.4 Latency Costs 4.5 Selecting a Wiring Architecture The TDM wiring does not only incur cost in wire segment complexity; There are latency considerations also. While we hope to alleviate some of these problems in later work, it is not something that we can ignore. Figure 6 shows that the majority of benchmarks were between two and three times slower than with static wiring. Some were as much as four times as slow. Until we show that TDM wiring can speed up designs by wire redesign and improved mapping algorithms, highly latency intolerant apIn order for TDM wires to be practical, all benchmarks will need to be mapped to the same architecture with good performance. Having established good values for the length of each time slot and the number of time slots we reran the experiments looking at different arrangements of TDM wiring. We constrained the benchmarks to use 24 time slots at most. The results are shown in Figure 7. The results achieved with constrained conﬁguration resources are largely similar to those with more ﬂexible re4040 sources. The majority of the benchmarks were able to achieve close to optimum routing with only eight wires in the conﬁguration shown in Table 2. A fully optimised CAD chain would be needed to make full use of the TDM wiring and demonstrate that all benchmarks can be mapped to so few wires. Currently we cannot guarantee that all nonshared wiring can be eliminated, but it is clear that they can be dramatically reduced. At worst, eight shared wires allow a reduction in the total number of wires needed to map all the benchmarks by 61%. All but two of the benchmarks map to 13 (or fewer) wires per switch box which is a reduction of 80% from the 66 static wires needed to map the benchmarks originally. Considering each benchmark individually we see the reduction in the amount of wiring per switch box ranges from 33% to 83%. The average reduction in the amount of wiring is 72%. 4.6 Spatial re-routing The two benchmarks, barrel64 and mem ctrl, that do not perform as well on the selected architecture show great potential for optimisation though spatial re-routing. Figure 8 shows the distribution of the number of non-shared wires across the used switch boxes for these two benchmarks. We have omitted the unused switch boxes because we are only interested in the area of the FPGA containing the benchmark. The majority of the switch boxes have no static wiring requirement. The additional wiring is needed in a very small area of the design. Currently our scheduler can only reroute wires in time. These distribution results demonstrate that there is deﬁnitely scope for alleviating problems with spatial routing, as it is highly likely that congested channels are near to empty ones. A fully optimised CAD chain would take advantage of the ﬂexibility in space as well as time. 5 Performance Many FPGA engineers equate clock speed with performance. While we seek to reduce the critical path delay, we also wish to distinguish between other factors that must be considered in evaluating system performance. With the model we have used there in an inevitable latency penalty caused by pipelining the interconnect over TDM wiring. Without the resources to design a CAD chain from scratch we have been constrained to the Stratix architecture in terms of wire placement and delay. We believe that reducing the amount of wiring in FPGAs will allow the complete redesign of the interconnect and will be able to reduce latency and area in a number of different ways. Figure 8. Proportion of non-shared, static wiring in the used switch boxes 5.1 Area and Latency Reducing the area used by the wiring has many beneﬁts. More area can be given over to the logic elements and wires can be made shorter and therefore faster. Reducing the number of wires also decreases the complexity of the switch boxes because there needs to be fewer switches between wire segments. This will not only help to reduce the cost of adding conﬁguration logic to each switch, but will also reduce the capacitance of each wire. In reducing the number of wires it is possible to decrease the latency of each wire. This could be done by using the extra channel space to decrease coupling capacitance, decreasing the RC delay by widening the tracks or increasing the logic density and therefore reducing chip area and shortening the wires. It does not necessarily follow that TDM wiring only increases the latency and decreases the area. It is still possible to trade one for the other. 5.2 Increasing the fmax As well as increasing the fmax (maximum frequency) of the wiring we can pipeline the hard IP blocks and IO to run at a higher frequency that the design as a whole. This lets us increase the throughput of hard IP blocks and effectively use them multiple times within a design clock cycle. The same can also be applied to the lookup tables. Those with identical conﬁguration can be chained in time as well as in space at no extra cost to the latency or architecture. 4141 All the benchmarks use the second wire in one to two thirds of the used switch boxes. We have not performed any analysis to see if this is a uniform distribution or not, but regardless of the use pattern, there is clearly scope for reducing the number of wires in some areas or reducing the power consumption though selective clock gating. Channel widths could be grouped locally or in distributed groups to allow sections of the FPGA to be taken off-line in order to save power. This is currently an area of continued research for us. 6 Routing Capacity of TDM Wiring Here we extrapolate our results to give an indication of the impact TDM wiring would have on the channel data rate compared to commercial FPGAs. The data rate of a channel is deﬁned as the number of signals per channel per average design clock cycle, where the design clock cycle is taken to be that of the benchmark mapped to static wiring. We have compared the data rate of three different TDM architectures with that of the Stratix. The Stratix has 72 wires per switch box. The wire types are arranged such that it has 232 wires per horizontal channel and 128 wires per vertical channel. The three conﬁgurations of TDM wiring have been chosen to span a range of realistic values based on our scheduling results. The distribution of wire types was chosen to mirror the Stratix and are shown in Table 4. • TDM(a) uses 13 wires as the majority of our benchmarks did. • TDM(b) used 16 wires because designers typically increase the amount of wiring by 20% for fabrication. • TDM(c) uses 20 wires because the average wiring reduction was 72% allowing us to reduce 72 wires to 20. The channel width and data rate ﬁgures are summarised in Table 3. We normalised the data rates by assuming that benchmarks mapped to TDM wiring 24 time slots will be on average 3.61 times as slow. This is a conservative estimate and is based on the results shown in Figure 6. The number of signals per channel is taken to be the maximum number of signals that can pas though a channel segment per un-normalised design clock cycle. This is then used to calculate the data rate by normalising to the static-wiring design clock cycle. The overall data rate increases are smaller when latency of the TDM critical path is taken into account, but again we reiterate that the results we have presented represent the worst case. With more intelligent design partitioning and re-optimisation of the wiring delay it is reasonable to expect the difference to become more pronounced. It is also clear Figure 9. Ratio of one and two R4 wire usage across benchmarks using 24 time slots and [2,2,1,1,1,1] TDM wiring conﬁguration Designs could be mapped to smaller areas on the FPGA by using the TDM wiring to reuse resources. 5.3 Clock architecture The TDM wiring will need a high performance clock network. In this paper we have limited the interconnect clock frequency to 2 GHz, but have done nothing else to ensure that it can be implemented efﬁciently. The advantage of this architecture is that the interconnect only has to be locally synchronous and can be divided into sections in the same way design clock networks are in modern FPGAs [5]. The local routing structure of the FPGA ensures that two interconnect latches will not be connected over long distances. Therefore there is scope for self-synchronising clock architectures such as the Distributed Clock Generator [6]. 5.4 Power Power is an important performance consideration. Additional clock networks and faster components need to be traded against fewer components to balance the power budget. Until now we have only considered a ﬁne grain homogeneous architecture with granularity at the logic cluster level. Figure 9 shows the ratio of switch boxes that drive one R4 wire to the number of switch boxes driving both R4 wires. R4 wires are placed horizontally (in rows) on the FPGA and span four logic block clusters. They are by far the most commonly used wire type on the Stratix FPGA. The benchmarks were allowed up to 24 time slots, up to 2 GHz interconnect clock and TDM wires in the conﬁguration show in Table 2, as before. 4242 Table 3. Horizontal (row) and vertical (column) channel data rates (normalized to signals per static critical path) Stratix Wires per Switch box H 47 V 25 TDM(a) H 8 V 5 TDM(b) H 10 V 6 TDM(c) H 13 V 7 Wires per channel Signals per channel 232 160 56 36 64 40 80 44 232 160 1334 864 1535 960 1920 1056 Data rate 232 160 372 239 425 266 532 292 Table 4. Distribution of wire types Wire type R4 C4 R8 C8 R24 C16 Total Stratix 40 20 6 4 1 1 72 TDM(a) 6 3 1 1 1 1 13 TDM(b) 8 4 1 1 1 1 16 TDM(c) 10 5 2 1 1 1 20 to see how much the data rate can be increased with small increments to the amount of wiring. With wiring reductions of 72-82% we have channel data rate increases of 50-130%. It is this data rate that we seek to exploit in the design of a high performance network-on-chip. 7 Logic Density Similar extrapolation can be applied to the conﬁgurable logic resources. Logic elements can be used multiple times in a clock cycle by mapping gates at different location in time rather than space. Redundancy and regularity in the logic block conﬁguration has been exploited in multicontext FPGAs [1]. It is reasonable to suppose that with good placement algorithms the logic could be shared using TDM wiring to signiﬁcantly increase the logic density. 8 Coarse Grain Network-on-chip One of the motivations of this work was to adapt FPGA architecture to allow the implementation of efﬁcient system-wide interconnect networks. Without a scalable system-wide interconnect solution FPGA designers will ﬁnd it increasingly difﬁcult to meet the demands of future applications. Here we consider how architectures with time-division multiplexed wiring can facilitate the implementation of both hard- and soft-core NoCs. A packet-switched mesh NoC [2] is a highly adaptive communication infrastructure that can handle both bursty and stream-based trafﬁc. Low latency routers can be implemented efﬁciently while still achieving high performance [10]. While NoCs can be effective ASIC interconnect solutions, FPGAs place different demands on a scalable routing solution. For example, FPGA hard blocks run at speeds of around 400 MHz, while surveys suggest that modern softcore IP blocks rarely achieve half that [12] and distribute the data bits over a wider area. FPGAs were originally designed to implement glue logic, but have long since become home to complex computational cores and, more recently, contain entire Systemson-Chip of widely varying architectures. The on-chip interconnect now forms an integral part of the design process. Some attempts [4] have been made to implement softcore networks on FPGAs. While these maintain the ﬂexibility of reconﬁgurable designs, the reconﬁgurable resources needed to implement the network cannot be justiﬁed. Even the simplest routers are comparable in size to many of the soft-core modules they endeavour to serve. Simpler approaches have focused on an alternative solution using more wires and less logic [11]. Many topologies have been shown to map to modern FPGAs, but they are still extremely resource hungry and can only achieve very low data rates. Although these approaches imply that current FPGAs contain the resources for highly connected system level interconnect, the studies have not looked into the rate of data transfer over the wiring or its scalability. The ease of mapping simple, resource-hungry topologies suggests that the wiring resources on the FPGA could be greatly reduced with more intelligent wire usage. We have been looking into a new FPGA architecture which will allow the design of a ﬂexible soft-core NoC that is neither wiring nor logic hungry. 8.1 Hard-core NoC Hard NoCs can arbitrate between packets without using expensive conﬁgurable logic resources and can make interchip communication trivial. This would signiﬁcantly reduce the design costs of multi-chip projects. However, without TDM wiring, soft-core IP blocks are unable to make use of the high performance of the NoC. By using TDM wiring, it will be possible to design high frequency NoCs that can interact with the soft-core interconnect at speeds comparable to ASIC designs. Whilst the soft-core IP will still be an order of magnitude slower, the TDM wiring enables many cores to use a single NoC router by making full use of the higher bandwidth per channel. 4343 8.2 Soft-core NoC "
Network Simplicity for Latency Insensitive Cores.,"In this paper we examine a latency insensitive network composed of very fast and simple circuits that connects SoC cores that are also latency insensitive, desynchronized, or asynchronous. These types of cores provide native flow control that is compatible with this network, thus reducing adapter overhead and buffering needs by applying backpressure directly to the sending core. We show that under realistic traffic patterns our sample network meets performance requirements and uses less power compared to a similar design. This concept of a simplified network, along with latency insensitive cores lends itself well to meeting the needs of low-power interconnect components in future design processes.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Network Simplicity for Latency Insensitive Cores Daniel Gebhardt, JunBok You, W. Scott Lee, Kenneth S. Stevens University of Utah, Salt Lake City, UT 84112, U.S.A. gebhardt@cs.utah.edu, {jyou,wlee,kstevens}@ece.utah.edu Abstract In this paper we examine a latency insensitive network composed of very fast and simple circuits that connects SoC cores that are also latency insensitive, de-synchronized, or asynchronous. These types of cores provide native ﬂow control that is compatible with this network, thus reducing adapter overhead and buffering needs by applying backpressure directly to the sending core. We show that under realistic trafﬁc patterns our sample network meets performance requirements and uses less power compared to a similar design. This concept of a simpliﬁed network, along with latency insensitive cores lends itself well to meeting the needs of low-power interconnect components in future design processes. Trafﬁc patterns of some system-on-chips (SoCs) are known at design time. In these cases, a custom generated network topology and physical placement of components yields improved performance and power than a regular-pattern network [1]. In many embedded applications, absolute performance is not the most important trait to optimize. Power, energy, or cost are often more important so long as the system meets the minimum performance. Latency insensitive (LI), or elastic design, is an area of research typically orthogonal to NoC protocols. LI protocols combine asynchronous design concepts with a standard clocked environment, and provide tolerance to variation in communication channel latency. When applied to a core’s design, LI can yield power savings and other advantages [2], and may soon become a more common design style. We have developed a LI protocol (pSELF) to allow operation with both synchronous and asynchronous circuits [3]. Our network circuits can interface directly with cores that operate with a phased elastic protocol [3]. With this scheme, the core and network interfaces of a network adapter (NA) follow compatible protocols. This simpliﬁcation eliminates the extra size and power requirements of interfacing with a standardized core protocol. One study indicates an OCP NA implementation can add up to 50% latency over a native interface [4]. The network fabric is implemented using two components: a phase elastic half buffer (pEHB) and a binary-tree router. A pEHB contains a data latch, and associated gates and control latches implementing the phase synchronous elastic ﬂow (pSELF) protocol. pEHBs may be added along long links in order to pipeline them for higher clock rates. A router consists of three bi-directional ports, control logic, and output buffers. It simultaneously routes a packet on each input port to one of its two possible output ports, and arbitrates if there is output contention. Packets contain source-routing bits and are, in this case, a single ﬂit long. We ﬁrst evaluated this network topology and protocol using a custom simulator and a 16-core binary tree network to measure throughput under trafﬁc distributions of uniform random and Gaussian. The uniform random trafﬁc simulates highly global communication, and because of this network’s low bisection bandwidth, the throughput saturates at only 0.22 packets/cycle per core. The Gaussian trafﬁc simulates more localized communication when a core will more frequently communicate to topologically close cores than to distant ones. We set σ in the distribution such that the nearest one-quarter of the network nodes fall within two σ from a given node. The maximum throughput in this case is much better at 0.45 packets/cycle. With this Gaussian trafﬁc at a 30% offered load, on average one out of ﬁve packet send attempts is blocked at the sending core by congestion, compared with two out of 5 attempts for uniform trafﬁc. These results conﬁrm that this network would be a poor choice for connecting many cores needing high bandwidth but communicating in an unknown pattern. However, it also indicates reasonable performance for more localized trafﬁc, while allowing efﬁcient global communication that occurs infrequently. 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.27 DOI 10.1109/NOCS.2008.27 209 209 We also evaluated our network on two realistic trafﬁc models. These have been used in previous work to evaluate application-speciﬁc NoC generation techniques [5]. The expected trafﬁc is represented as a communication trace graph (CTG) showing the bandwidth requirement between various cores in the SoC. The ﬁrst, a Multi-Window Displayer (MWD), has mostly one or two connections per core, all with relatively similar (and low) bandwidth requirements. The second model is a MPEG4 decoder (MPEG4). This CTG is quite different, and requires a number of high bandwidth connections to a few shared memories. We construct a tree topology by pairing cores, or groups of cores and their routers, that have the highest edge-weight between them in the core graph [6]. This topology generation is important to minimize network hops on paths needing a high bandwidth (or low latency, as the need may be). The generated topology for the MPEG4 design is shown in Figure 1. We simulated these topologies using the CTG information to determine if our network could support such applications successfully. In both cases, even for the more “difﬁcult” MPEG4 application, the topology and network maintained the average asked bandwidth for various message sizes. Assuming our network is using 4-byte wide ﬂits, and running at 1.3 GHz (in 130nm technology), the link bandwidth is 5.2 GB/s, fast enough to provide headroom for instantaneous bandwidth needs on the combined average 1.8 GB/s path to the sdram in the MPEG4 application. rast sram 1 upsp sd ram mcpu idct au vu risc sram 2 bab adsp Figure 1. Automatically generated topology for MPEG-4 trafﬁc simulation. We evaluated the power consumption of our pSELFbased routers against a Xpipes Lite [5] 4x4 router. We used Synopsys Design Compiler and Power Compiler to estimate our router’s power at the technology of our fabricated test-chip (0.5 micron), and scaled the values down for a 130 nm process using constantﬁeld scaling theory. The power of a Xpipes 4x4 router with 32-bit ﬂit widths and four output buffer stages is given as 55.5 mW when running at its maximum of 1 GHz. We constructed a functionally similar “4x4” router from two of our binary-tree routers and pEHBs. We estimated the FIFO buffers’ power of the Xpipes router, and added that to our 4x4 router construct for fair comparison. The power for this arrangement running at 1.3 GHz is 28.9 mW, 48% less than that of the Xpipes router. It is likely that additional internal network buffering, virtual channels, and other features could show performance improvements for certain applications. However, a simpliﬁed network concept can still offer the performance required for many designs while giving a signiﬁcant power advantage. A network compatible with elastic protocols yields very efﬁcient circuits and there is no need for extra ﬂow-control logic in the core’s network adapter, nor extra NACK control messages. If a core is desynchronized [7] there is an additional opportunity for greater power savings, and pSELF is directly compatible with the handshaking used in the desynchronization process, requiring only a minimal conversion circuit. "
Exploring High-Dimensional Topologies for NoC Design Through an Integrated Analysis and Synthesis Framework.,"Networks-on-chip (NoCs) address the challenge to provide scalable communication bandwidth to tiled architectures in a power-efficient fashion. The 2-D mesh is currently the most popular regular topology used for on-chip networks in tile-based architectures, because it perfectly matches the 2-D silicon surface and is easy to implement. However, a number of limitations have been proved in the open literature, especially for long distance traffic. Two relevant variants of 2-D meshes are explored in this paper: high-dimensional and concentrated topologies. The novelty of our exploration framework includes the use of fast and accurate transaction level simulation to provide constraints to the physical synthesis flow, which is integrated with standard industrial toolchains for accurate physical implementation. Interestingly, this work illustrates how effectively the compared topologies can handle synchronization-intensive traffic patterns and accounts for chip I/O interfaces.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Exploring High-Dimensional Topologies for NoC Design Through an Integrated Analysis and Synthesis Framework ∗ ‡ F. Gilabert † † † † ‡ ‡ , S. Medardoni , D. Bertozzi , L. Benini , M.E. Gomez , P. Lopez † ENDIF, University of Ferrara, 44100 Ferrara, Italy. † † DEIS, University of Bologna, 40136 Bologna, Italy. Dept. of Computer Engineering, Universidad Politecnica de Valencia, Spain. ‡ and J. Duato ‡ Abstract Networks-on-chip (NoCs) address the challenge to provide scalable communication bandwidth to tiled architectures in a power-efﬁcient fashion. The 2-D mesh is currently the most popular regular topology used for on-chip networks in tile-based architectures, because it perfectly matches the 2-D silicon surface and is easy to implement. However, a number of limitations have been proved in the open literature, especially for long distance trafﬁc. Two relevant variants of 2-D meshes are explored in this paper: high-dimensional and concentrated topologies. The novelty of our exploration framework includes the use of fast and accurate transaction level simulation to provide constraints to the physical synthesis ﬂow, which is integrated with standard industrial toolchains for accurate physical implementation. Interestingly, this work illustrates how effectively the compared topologies can handle synchronization-intensive trafﬁc patterns and accounts for chip I/O interfaces. 1. Introduction A general guideline driving network-on-chip (NoC) design under severe technology constraints consists of siliconaware decision-making at each hierarchical level [48]. This is likely to result in less design re-spins and in faster timing closure. In this direction, new tools are emerging that guide designers towards a subset of most suitable candidates for on-chip network designs while considering the complex tradeoffs between applications, architectures and technologies [8, 9, 10]. Topology exploration is a typical task performed by these tools [7]. NoC architectures can be designed with both regular and custom topologies. The primary advantage of a regular NoC architecture is topology reuse and reduced design time. From a physical design viewpoint, it enables a better control of electrical characteristics. Regular topologies are suitable for general purpose architectures consisting of homogeneous processing tiles (e.g., [5]) and are the focus of this paper. The 2-D mesh is currently the most popular regular topology used for on-chip networks in tile-based architec∗ This work was supported by CONSOLIDER-INGENIO 2010 under Grant CSD2006-00046 and the European Commission in the context of the HiPEAC network of excellence (project 004408 and 217068), under the Interconnects research cluster. tures, because it perfectly matches the 2-D silicon surface. However, this topology shows poor scalability. Some more complicated topologies have been used by or proposed for other interconnection networks, such as high-dimensional meshes/tori, hypercubes, hierarchical meshes/tori [12], express cubes [11] and fat-trees [13]. Topologies with more than 2 dimensions are attractive for a number of reasons. First, increasing the number of dimensions in a mesh results in higher bandwidth and reduced latency. Second, wiring on a chip comes at a lower cost with respect to off-chip interconnections. However, wiring is also the weakpoint of these topologies, since their mapping on a bidimensional plane involves the existence of wires with different lengths. From a layout viewpoint, this translates into links with different latencies and into the use of more metal layers. Moreover, other layout effects might impact feasibility of these topologies, such as the routability of wires over computation tiles and the routing constraints posed to other on-chip interconnects. These issues however require low-level analysis tools to be properly tackled. Backend synthesis toolchains are used to accurately assess NoC implementation alternatives. Such toolchains need to be used in combination with more abstract exploration tools, since their utilization to prune the design space would be overly time consuming. An even more important consideration is that the physical implementation of a selected design point is not unique in nanoscale technologies. A single technology library no longer exists for standard cell design. In fact, manufacturing technologies are spreading across a variety of libraries optimized for speciﬁc uses, such as low power or high performance, with several intermediate levels featuring for example different threshold voltages. Using different libraries at the same node generates large differences in synthesis results, and their spread is increasing as technology scales down [3]. Therefore, it is of utmost importance to have high level exploration tools providing feedback to the backend ﬂow to guide the synthesis process to the most suitable candidates in the implementation space [14]. High-level pruning of NoC design points is usually carried out by means of pencil-and-paper ﬂoorplan considerations [6]. These latter move from pre-existing lowlevel models [15, 16] or from technology projections [17]. Even assuming the correctness of reference models, these approaches can just indicate a trend or provide a general guideline. The gap between architectural and physical design phases can be partially bridged by performing a ﬂoorplan-aware topology synthesis process [14]. This 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.14 DOI 10.1109/NOCS.2008.14 107 107 allows to more accurately derive area and wire lengths. Unfortunately, most of these approaches lack of a fast but accurate simulation tool for early performance validation. Performance at this level is usually estimated through high level techniques based on the number of hops and on link bandwidth. More accurate indications will be available when the RTL description of selected topologies will be generated and cycle-true simulation will be accessible. Even in this case, tractable simulations will have to be limited to low-complexity (sub-)systems. This paper proposes to explore the feasibility and the efﬁciency of multi-dimensional topologies with respect to 2D-meshes by means of a 2 step methodology. At ﬁrst, we capitalize on the concept of transaction level modelling (TLM) to come up with a fast and accurate simulation environment which abstracts all relevant NoC architecture-level mechanisms while maintaining execution time accuracy of RTL simulation. Modelling and its accuracy are extended to injection and ejection interfaces. Simulation performance turns out to be orders of magnitude better. We use this simulation environment to explore the implementation space, i.e. we identify the range of network operating frequencies and link latencies over which performance of one topology is consistently better than another one. The results of the implementation space exploration are then changed into directives for the backend synthesis ﬂow. The degrees of freedom in the synthesis ﬂow (e.g., mix of technology libraries, ﬂoorplanning decisions, pipelined link insertion) should then be exploited to meet those constraints. In this way, we explicitely derive the physical constraints that, if met, would allow not to waste the better theoretical properties of multi-dimensional topologies as a result of physical implementation. As a case study, for the same number of communicating cores we compare the performance of a 2D-mesh with that of an equivalent hypercube and of a concentrated topology (i.e., more cores per switch). The work is structured as follows. After describing previous work in Section 2, we describe the reference NoC architecture in Section 3, and its transaction level models in Sections 4, 5 and 6. Topology analysis is performed in Section 7, while their physical design issues are investigated in Section 8. Finally, conclusions are drawn. 2. Previous work Several papers explore regular topologies for on-chip networks with different methodologies depending on the objective of the exploration. Two milestone works will be described next, since they allow to capture the distinctive contribution of this paper. The work in [10] proposes Polaris, a system-level roadmap for on-chip interconnection networks that guides designers towards the most suitable network design(s) tailored to their performance needs and power/silicon area constraints. Although this roadmapping toolchain is very useful in the early design stages, its power/area/delay estimations are necessarily based on ITRS projections, architecture-level power models [15], pipeline delay models [4], rough ﬂoorplan assumptions and are referred to a generic NoC architecture. Polaris is not the right toolchain for more detailed analysis of NoC design alternatives, since application, architecture as well as layout effects of the speciﬁc design at hand need to be considered. Other works illustrate system-level roadmapping research. High level models of key system parameters are proposed in [18, 19]. ARB ARB ARB ARB M U X E S IN0 IN1 IN2 IN3 LATCH LATCH LATCH LATCH FLOW CONTROL MANAGEMENT PATH SHIFT BUFFER OUT0 PATH SHIFT PATH SHIFT PATH SHIFT BUFFER BUFFER BUFFER OUT1 OUT2 OUT3 Figure 1. High level switch schematic. The work by Wang et al.[20] proposes an analytical designspace exploration tool for projecting NoC topologies at future technologies from a power perspective. Power modelling of NoC components is also a fruitful research area [15, 21, 22]. A complementary NoC synthesis toolchain that takes care of NoC selection and generation consists of the SUNMAP tool [8] and the xpipescompiler tool [9]. Early power/area/delay and trafﬁc bandwidth estimates are then calculated for each application-mapped NoC topology. The gap between the architectural and physical design phases is closed by performing a ﬂoorplan-aware topology synthesis process. Then topology selection takes place based on user requirements. Finally, backend tools are used to instantiate, simulate, verify and synthesize the chosen NoC description, resulting in the ﬁnal layout. This ﬂow lacks of a tool for fast and accurate NoC simulation. Therefore, the accurate simulation of large systems with functional trafﬁc becomes intractable. Similar trade-offs also appear in other synthesis toolchains [23, 24] The methodology and the tool proposed in this paper complement the previous approaches. Our starting point is a subset of topologies. Therefore, Polaris can be considered as a pre-processing tool for our methodology. Then, we extend the capability of synthesis ﬂows like the one in [8, 9] in many senses. First, we propose transaction-level models abstracting with excellent accuracy the behavior of the main NoC architectural functional units. Therefore, accurate performance analysis of even large systems can be performed in negligible time with respect to cycle-true SystemC simulation. Second, this modelling infrastructure allows to explore architectural parameters that can be set only as a result of physical synthesis, such as clock frequency ratio between synchronous domains, latency of layout-critical links or the clock cycle period. In other words, the tool can explore the implementation space of NoC topologies. We can therefore indicate the range of physical parameters over which one topology provides better performance than another one, and capture the trade-off between theoretical properties of a topology and the degradation of such properties as an effect of its physical synthesis. This information can be provided to physical designers as constraints to be met not to vanish performance beneﬁts of a given topology. This paper proves the viability of this methodology by comparing traditional 2D-meshes with some alternative topologies chosen among regular ones, namely multidimensional topologies and concentrated ones. In the past, 108108 network topologies have been extensively studied for either performance or hardware efﬁciency [11, 12, 13]. Topology optimization for power efﬁciency is also a popular research domain [31, 32]. [32] claims that from an energy standpoint, high-dimensional tori should never be selected over hierarchical or express cubes. However, the uncertainty on actual physical parameters prevents to accurately quantify the beneﬁts. Different optimal topologies have also been indicated for different trafﬁc patterns. The analysis carried out by [44] shows that fat-tree topology is a strong candidate to fulﬁll the latency constraints for many applications. Unfortunately, wiring for fat-trees is very challenging. Ring, spidergon, crossbar and 2D-mesh topologies are compared in [33, 34], pointing out the nice properties of spidergon. Again, the work does not dwelve into physical issues and the feasibility concerns for spidergon are not addressed. Mesh and torus topologies are compared in [35] under different routing algorithms and trafﬁc models. Gilabert et al. propose in [36] to route long links of multi-dimensional topologies on different metal planes, thus compensating delay differences. This is however hardly controllable with industrial synthesis tools. Since bandwidth is usually exceedingly available in onchip networks, a growing number of works propose to trade-off bandwidth with reduced latency. An interesting node:router mapping of N:M is proposed in [37], instead of traditional 1:1 (k-ary n-cube) or N:1 (clustered topologies). The work in [6] proves the limitation of 2D-meshes as processor counts increase. It also proposes a concentrated mesh architecture with replicated subnetworks and express channels. However, assumed ﬂoorplans envision over-the-cell routing which might not always be the case in tiled architectures. The work in [36] trades-off the number of dimensions with the number of cores per router, but lacks of physical insights. Finally, exotic topology solutions for 3D on-chip networks are investigated in [38]. 3 NoC architecture Our abstract modelling framework takes its steps from the synthesizable model of a packet-switched NoC architecture. The reference architecture is a variant of the XpipesLite NoC architecture, derived from [43]. The reference switch and network interface components are illustrated in Fig.1 and Fig.2. The switching fabric implements a 2-cycle-latency (one for switch operation and one for traversing the ouput link), output-queued wormhole-switched router supporting round-robin arbitration on the output ports. Allocation of inputs towards speciﬁc output ports is handled by an allocator module for each output port. The input ports are latched to break the timing path. Arbitration is subsequently performed upon receipt of a header ﬂit which also carries desired output port information (source-based static routing). After a packet wins the arbitration, routing information pertaining the current switch is rotated away in the head ﬂit. This allows positioning of the per-hop routing bits at a ﬁxed offset within the ﬂits, thus simplifying switch implementation. Access to output ports is granted until a tail ﬂit arrives. The implemented ﬂow-control scheme is stall/go [25]. It is a simple realization of an on/off ﬂow control protocol, requiring just two control wires: one going forward and ﬂagging data availability, and one going backward and signaling either a condition of buffer ﬁlled (“stall”) or of buffer req_tx_flit_from_FSM Busy_buffer fast_clk Clock Counter DATAPATH req_tx_flit req_tx_flit Register clk_counter sel_out tx_done Register tx_done (to FSM) MByteEn MData MBurstLength Clock MBurstSeq MBurstPrecise MCmd MAddr Payload Register payloadreg Payload Shifter payloadreg_to_flit_reg sel_out hload pload headerreg_to_flit_reg Flit Register Flit Header Register headerreg Header Shifter PATH register Flit_type Flit Type Register Flit_type_from_FSM CONTROL PATH FINITE STATE MACHINE Figure 2. Schematic representation of network interface initiator architecture. free (“go”). For this protocol, recovery from congestion is instantaneous. The switch is parameterizable in the number of its inputs and outputs, its link width, as well as in the size of the buffering at the outputs. For this work, 6-ﬂit buffers are assumed and the link (and ﬂit) width is set to 32 bits. The network interface (NI) is designed as a bridge between an OCP 1 interface and the NoC switching fabric. Its purposes are the synchronization between OCP and network timing, (de-)packetization, the computation of routing information (stored in a Look-Up Table, LUT) and ﬂit buffering to improve performance. For any given OCP transaction, some ﬁelds can be transmitted once, while other ﬁelds need to be transmitted repeatedly. Initiator and target NIs are attached to communication initiators and targets respectively. Each NI is split in two sub-modules: one for the request and one for the response channel. These sub-modules are loosely coupled: whenever a transaction requiring a response is processed by the request channel, the response channel is notiﬁed; whenever the response is received, the request channel is unblocked. The NI is built around two registers: one holds the transaction header (1 refresh per OCP transaction), while the second one holds the payload (refreshed at each OCP burst beat). A set of ﬂits encodes the header register, followed by multiple sets of ﬂits encoding a snapshot of the payload register subsequent to a new burst beat. Header and payload content is never allowed to mix, and padding is eventually used. Routing information is attached to the header ﬂit of a packet by checking the transaction address against an LUT. The length of this ﬁeld depends on maximum switch radix and maximum number of hops in the speciﬁc network in1Open Core Protocol – standard end-to-end communication protocol used in this work between processor/memory cores and network interfaces 109109 Injection interface Switch Input port Output port STALL flag STALL flag STALL flag Procesor Ejection interface STALL flag Memory Figure 3. TL modeling of the switch architecture. stance at hand. The SystemC simulation environment consists of the RTL-equivalent SystemC models of the reference architecture, of OCP trafﬁc generators and OCP memories. Next section describes how we abstracted the behavior of network building blocks while retaining accuracy. 4 NoC behavior abstraction In order to develop transaction level models of our network, we started from the modeling and simulation framework used in [26], which is based on the MODULA-2 language. However, that simulator just models a concept architecture, does not carry any information about implementation and models network interfaces only approximately. We made deep modiﬁcations of the native simulator in order to abstract the behavior of the speciﬁc architecture addressed in this work, to include network interface abstractions and to provide insights into the implementation space. We found a quite simple way of abstracting the RTL structure of the switch. The buffers are abstracted as counters (see Fig. 3), and the switch behavior is deﬁned as a set of complex logical functions. For instance, we have a logical function for performing round robin arbitration, one for raising and falling the stall signal, and others that model network connectivity. The simulator is event driven, so every time something changes in the network an event is scheduled. Each event contains the relevant data to that event, and executes the logical functions needed to handle the new network status. Also, events are processed in time order, and they can generate as much events as needed (i.e, the reception of a head ﬂit at an input port of the switch generates the event to route it). The ﬂow-control mechanism of the baseline simulator was updated to model stall/go semantics. Each ﬂow control stage is modeled by a counter which controls the number of ﬂits stored in the stage buffers and a ﬂag that represents the value of the stall signal in that stage. The behavior of the stall signal is represented by two events, one for raising, and other one for falling the signal. Also, a ﬂag that represents the actual value of the signal is associated to each port (see Fig. 3). The propagation delay of the signal is considered in the timing of the events. As an example, if the ejection interface of the memory represented in Fig. 3 raises the stall signal in cycle 0, it will generate a stall event for the output port of the switch at cycle 1. When the simulator engine starts to simulate cycle 1, it will process the stall event of the output port, and if the signal must be propagated to the input port of the switch, it will program a stall event at cycle 2 for the input port, and so forth. Most of the effort for NoC behavior abstraction was devoted to modeling the interfaces of the network. As it can be seen from Fig. 3, the interfaces are modeled with two buffers and a ﬂag. They have a single counter (i.e., a single slot buffer) that represents the buffer that connects with the elements outside of the network (processor and memory), and there is also another counter that represents the buffer that connects with the network. They also have a ﬂag that represents the value of the stall signal in the network interface. In order to support the different clock domains a system may be structured into, the simulator is able to cope with clock domain crossing at NoC boundary. But the most important part of the injection/ejection modeling is the set of logic functions that deﬁne the behavior of the interfaces. That set of functions manages the OCP-to-network protocol conversion (and viceversa), the (de-)packetization process, the synchronization between clock domains, the behavior of initiator and target cores and the update of the stall signal when required. 5. Network trafﬁc generation 5.1 OCP transactions In a relatively immature ﬁeld such as NoCs, realistically capturing trafﬁc behavior is a challenging task. Our approach to this problem is twofold. On one hand, we set up a trafﬁc injection mechanism for the purpose of validating TL simulator behavior with respect to the RTL-equivalent SystemC simulator. Individual OCP read and write transactions need to be validated in both simulation environments. We devised an injection mechanism such that the same input trafﬁc speciﬁcation can be reused for both RTL and TL simulation. In SystemC, OCP transactions are generated by means of parameterizable trafﬁc generators. Main parameters include the OCP burst length and the interburst idle time, in addition to OCP parameters for each transaction. A parser was designed in order to feed the TL simulator with the same trafﬁc speciﬁcations. 5.2 Communication protocol Our work also aims at comparing performance of different network topologies in presence of realistic trafﬁc conditions. Unfortunately, very often the representative set of test applications may not yet be exercised with real benchmark applications. Moreover, the trafﬁc pattern depends not only on the amount of communication data between the multiple tasks of an application, but also on the features of the communication library. This latter usually spans a large design space: topology, notiﬁcation mechanisms, synchronization, allocation of messages and interaction paradigm of communicating cores [39]. The library implementation is then optimized for speciﬁc communication infrastructures [41]. Our approach is to project network trafﬁc based on the latest advances in communication middleware for MPSoCs and to assess its performance with an on-chip network as the communication backbone. We derive from the queuebased library in [41] the guidelines for producer-consumer interaction. That library is suitable for a number of MPSoC architectures, including distributed architectures with local and tightly coupled memories for each processor core. This matches the tiled CMP scenario addressed in this paper. We therefore build an abstraction layer on top of our TL simulator, which models the behavior of a processor tile and of its HW/SW communication support. While read and write transactions to the network are modelled with almost 110110 Producer tile Processor Core local polling Memory Core Network IF Initiator Network IF Target Producer tile Consumer tile Local polling notify message availability Local polling 1 Request for data 2 3 2 Write message data transfer Read operation 3 4 notify transfer completion Reset semaph. (b) N E T W O R K 1 4 Network IF Initiator Network IF Target Processor Core local polling Memory Core Consumer tile (a) Figure 4. Tile abstraction and mapping of producer-consumer communication handshake on network transactions. cycle-true accuracy (see Section 6), timings for communication control and for computation in the tile were estimated based on past experience [40]. In essence, the tile architecture consists of a processor core and a local memory core, as illustrated in Fig.4(a). Both cores are connected to the network through a network interface initiator and target respectively. We assume that the two network interfaces can be used in parallel. While the processor is reading/writing from/to other tiles, the processor core of other tiles can read/write from/to the tile local memory. This can be achieved through a dual-port memory and a proper tile architecture, which however falls outside the scope of this paper. We assume producer-consumer communication between tiles based on the handshake in Fig.4(b). The producer checks local semaphores indicating whether there are previous pending messages for the target destination. If not, it writes communication data to the local tile memory and notiﬁes data availability to the consumer by unblocking a remote semaphore. The consumer was meanwhile performing local polling on that semaphore. The producer is then free to carry out other computation or communication activities to other consumer tiles. The consumer then reads computation data from the producer tile, and sends a notiﬁcation upon completion. This allows the producer to send another message to this speciﬁc consumer. The implementation of this communication protocol involves 4 network transactions: notiﬁcation of data availability, read request, actual data transfer and notiﬁcation of transfer completion. The producer local polling to check pending messages for the target consumer is performed in order to avoid congesting the network in case the consumer is slow in absorbing its input messages. This behavior may result in low network bandwidth utilization, thus making global performance mainly sensitive to network latency. The consumer local polling for incoming messages allows the consumer to synchronize data transfer operations from multiple producers. This avoids the collision of multiple packets in the network from the producers to the same consumer, since this latter operates all transfers once at a time. Under these working conditions, concentrated architectures trading bandwidth for latency become attractive. However, physical implementation effects might put this picture in discussion. 6 Validation of TL simulator accuracy We prove through experimental evidence that our abstract models accurately describe NoC behavior. They were compared with the results of SystemC-based functional simulation,which is RTL equivalent and therefore cycle and network signal accurate, thus much slower. The ﬁrst series of tests aims at capturing the accuracy with which the injection and ejection interfaces were modeled, as well as the congestion resolution mechanisms inside the switches. The ﬁrst experimental setup is composed of a single switch to which 4 processor cores are attached via their network interfaces. Packets from the cores are directed to a single shared OCP memory connected to one output port of the switch via its network interface. The operating frequency of the cores was assumed to reﬂect the trend for the speed of industrial ARM cores. 470 MHz is a worst case operating frequency for an ARM926EJ-S in 90 nm [45], while CPUs in the ARM11 MPCore can be operated up to 620 MHz in the worst case [46]. We ﬁnd 500 MHz to be a reasonable assumption for core speed in the near-future, while the network is assumed to work at 1GHz. The second series of experiments assesses the accuracy with which the clock domain crossing mechanism is abstracted when the ratio between OCP and network clock is varied. Finally, the third series of tests evaluates the acrossswitch communication model. This involves accurate abstraction of the switching and of the ﬂow control mechanisms, as well as of buffer control and congestion resolution mechanisms. For this purpose, the number of switches of the previous experimental setting was increased to 5. In all these tests, the accuracy was excellent (always within 0.03%), and the simulation speedup varied from 20x to 100x. The speeup factor heavily depends on the number of idle cycles in the simulation. The TL simulator only takes into account those cycles in which some event is scheduled and the signals and components that are affected by that event. While the SystemC simulator re-evaluates every signal at every cycle. Finally, we tested a more complex topology. This topology is a 4-ary 2-mesh, with one processor attached to every switch. Only one switch located in the middle has attached 111111 L M Total Bursts Speed-Up Factor Accuracy 8 100 8 4 8 4 1764 1764 4900 100x 85x 114x 99.99% 100% 100% Table 1. Simulation accuracy for a 4-ary 2mesh. I/O DEVICES P W W W P W W W C W W W C W W W Figure 5. System organization and workload distribution. a shared memory instead of a processor core. OCP trafﬁc generators generates bursts of given length L (no of beats) with inter-burst idle wait M (represented as L M pairs in Table 1). We simulate a heavy contention trafﬁc scenario, where each processor performs write accesses to the centralized shared memory. As it can be observed from Table 1, the results show that the model is still very accurate. Also, if we focus on the tests with 1764 total bursts, we can observe how the speedup factor achieved in 8 100 is higher than the one achieved in 8 4; the reason for this is that the 8 100 case has a larger number of idle cycles. 7. Assessing performance of topologies We combined the TL simulator of the network with the computation tile simulation model described in subsection 5.2 in order to explore regular NoC topologies. At ﬁrst, we derived performance of topologies from TL simulation in terms of clock cycles, and then explored the possible variants in the implementation space (clock frequency, link latency). 7.1 Workload distribution In order to simplify the analysis, we assumed a workload distribution between the tiles which de-emphasizes the role of the topology mapping algorithm with respect to overall performance. In fact, we consider a parallel benchmark consisting of one or more producer tasks, a scalable number of worker tasks and 1 or more consumer tasks (see Fig.5). Every task is assumed to be mapped on a different computation tile. 16 computation tiles are available in the system. The producer task(s) reads in data units from the I/O interface of the chip and distributes it to the worker tasks. There are no constraints on which worker tile has to process a given data unit. The higher the number of worker tiles, the higher the data processing rate provided the I/O interfaces can keep up with it. Output data from each worker tile is then collected by a consumer tile, which writes them back to the I/O interface. The following assumptions were made on such interface. We model input (output) data streams that are read from (written to) I/O devices, which are accessed through read/write operations like in SDRAM accesses. We assume that input and output streams do not interfere with each other, but are handled through different I/O ports. A maximum of 5 I/O ports is assumed, that can be used for input or for ouput. Such ports are accessed through sidewall tiles. The mapping of producer(s) and consumer(s) tasks is therefore constrained to these tiles. This I/O architecture is compliant with that of commercial network-based embedded multicore products, such as [42]. The only restrictive assumption we make is that the I/O tiles are located on the same side of the chip, due for instance to ﬂoorplanning constraints, thus generating collisions between input and output streams. The case where input and output tiles are located on opposite sides of the chip did not show signiﬁcant performance differentiation between alternative topologies. 7.2 Topologies under test Meshes can be referred as a k-ary n-mesh. In that nomenclature, the topology has kn routers in a regular n-dimensional grid with k switches in each dimension and links between nearest neighbors. Moreover, the nhypercube topology is a particular case of a mesh where k is always 2. In a mesh, for a given number of switches in the network, as the number of dimensions (n) is increased, the value of k is decreased. In this case, switches with a higher radix are required, but network bisection bandwidth increases, and network latency decreases. Also, each switch can have one or more tiles attached. For a given number of tiles, as we increase the number of tiles per switch, we decrease the total number of switches, thus we reduce the bisection bandwidth of the topology but we also decrease the maximum number of hops (i.e., latency). When placing a mesh with more than two dimensions the links used to connect the dimensions greater than two (express links from now on) are longer. In theory, the length of a link of the dimension t is: k(d−2)/2 , where d is equal to t if t is an even number and d is equal to t + 1 if it is an odd number, but that length may change according to the placement constraints (this is actually the case in this paper). In this paper we focus on four topologies of 16 tiles: a 4-ary 2-mesh (referred to as 2D-mesh from now on) with one tile per switch, a 2-ary 4-mesh (4-hypercube) with one tile per switch, a 2-ary 3-mesh with 2 tiles per switch, and a 2-ary 2-mesh with 4 tiles per switch. We denote these two latter solutions as the concentrated topologies. Table 2 shows some representative data of the four studied topologies. Please note that even with 1 tile per switch, 2 switch input and 2 switch output ports are required, since the tile includes an initiator and a target NI, each with one input and output port to the switch for receiving/sending data. 7.3 Topology performance results Our TL simulator needs to know the ratio between network and external world clock cycles, which is constrained 112112 Topology 4-ary 2-mesh 6 1 16 6 1 2-ary 4-mesh 6 1,2 16 4 1 2-ary 3-mesh 7 1,2 8 3 2 2-ary 2-mesh 10 1 4 2 4 Arity Link Length Switches Max. Hops Tiles per Switch Table 2. Topologies under test. (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:1)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:12)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:13)(cid:14) (cid:13)(cid:6)(cid:15)(cid:16) (cid:13)(cid:16) (cid:13)(cid:17)(cid:15)(cid:16) (cid:18)(cid:14)(cid:14) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:3) (cid:6) (cid:5) (cid:3) (cid:8) (cid:5) (cid:7) (cid:9) (cid:5) (cid:11) (cid:10) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:1)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:12)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:13)(cid:14) (cid:13)(cid:6)(cid:15)(cid:16) (cid:13)(cid:16) (cid:13)(cid:17)(cid:15)(cid:16) (cid:18)(cid:14)(cid:14) (cid:12)(cid:2)(cid:8)(cid:13)(cid:14)(cid:15)(cid:5)(cid:3) (cid:6) (cid:5) (cid:3) (cid:8) (cid:5) (cid:7) (cid:9) (cid:5) (cid:11) (cid:10) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:1)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:12)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:13)(cid:14) (cid:13)(cid:6)(cid:15)(cid:16) (cid:13)(cid:16) (cid:13)(cid:17)(cid:15)(cid:16) (cid:18)(cid:14)(cid:14) (cid:6)(cid:3)(cid:2)(cid:16)(cid:14)(cid:7)(cid:5)(cid:3) (cid:6) (cid:5) (cid:3) (cid:8) (cid:5) (cid:7) (cid:9) (cid:5) (cid:11) (cid:10) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:1)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:12)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:6)(cid:2)(cid:3)(cid:4)(cid:5)(cid:11)(cid:6)(cid:2) (cid:7)(cid:8)(cid:9)(cid:10) (cid:13)(cid:14) (cid:13)(cid:6)(cid:15)(cid:16) (cid:13)(cid:16) (cid:13)(cid:17)(cid:15)(cid:16) (cid:18)(cid:14)(cid:14) (cid:17)(cid:10)(cid:18)(cid:10)(cid:8)(cid:7)(cid:5)(cid:16) (cid:6) (cid:5) (cid:3) (cid:8) (cid:5) (cid:7) (cid:9) (cid:5) (cid:11) (cid:10) Figure 6. Performance comparison (in execution cycles) of topologies in 4 different scenarios. Values normalized to the performance of the 2D-mesh. to be an integer divider in our architecture. Our past experience suggests that for the system under test, a target clock frequency of 1 GHz is to be expected for the network, while a reasonable frequency for computation tiles and I/O devices is 500 MHz. As a consequence, we set a ratio of 1:2 for all clock domain crossings. Should such network frequencies prove infeasible, we assess the implications in subsection 7.4 during implementation space exploration. An initial latency of 20 cycles for external I/O device access was set. By varying the number of producer and consumer (I/O) tiles and the computation time of the worker tiles for each data unit, we got 4 different performance scenarios, as illustrated in Fig.6. A. Bottleneck in the workers. In this scenario, the I/O interfaces are fast enough to feed workers with computation data and to absorb output data from them. As a consequence, producer and consumer tiles experience idleness, since they are waiting for workers to complete. In this case, performance is not very topology-sensitive, since the network is not the bottleneck and even though some topologies provide lower latency, the time a worker takes to read input/write output data is masked by other workers processing their data in parallel. Overall, the performance advantage of concentrated topologies is almost negligible in this scenario. Interestingly, topology selection is just a physical issue here, since the concentrated solutions certainly involve less resources and probably less power, but are likely to run (cid:1) (cid:2) (cid:3) (cid:4) (cid:5) (cid:6) (cid:7) (cid:3)(cid:8)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:8)(cid:3)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:8)(cid:5)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:8)(cid:7)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:8)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:9)(cid:3)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:9)(cid:5)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:9)(cid:7)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:9)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1) (cid:3)(cid:10)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1) (cid:5)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:3)(cid:11)(cid:16)(cid:17)(cid:18)(cid:19) (cid:3)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:5)(cid:11)(cid:16)(cid:17)(cid:18)(cid:19) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:6)(cid:7)(cid:8)(cid:12)(cid:13)(cid:5)(cid:10)(cid:14)(cid:15) (cid:16) (cid:9) (cid:17) (cid:5) (cid:18) (cid:7) (cid:6) (cid:10) (cid:19) Figure 7. Execution time for 2D-mesh and 4hypercube as a function of the latency in the express links. frequency is 1 GHz for both networks. at lower frequencies. B. Bottleneck in the consumer. This scenario provides the largest performance differentiation. The chip input interface is fast enough to minimize worker idle waits for computation data. On the contrary, each worker waits almost 50% of its execution time in our simulation to forward its output data to the consumer tile, which cannot keep up with the needed consumption rate. In this case, the shorter the data transfer time to the consumer (impacted by network latency), the sooner a new data frame can be processed. This is in essence a network latency-sensitive scenario, where concentrated topologies outperform the others. We will see in section 7.4 how implementation-related effects might put this picture in discussion. C. Bottleneck in the producer. This is the case where a shorter network transaction latency does not help. In fact, the producer tile is not able to keep up with data requirements from the workers. The use of low-latency topologies allows these latter to read input data more rapidly, but then, once the computation of those data completes, the worker becomes idle again waiting for new data to process. A longer completion time would not have impacted performance, so all topologies perform the same in this scenario. Again, the choice among topologies will be based on physical implementation considerations (e.g., power vs performance trade-off). D. Balanced scenario. In this scenario, the idle time of all tiles in the system (producer, consumer and worker) for mutual synchronization was minimized. This system conﬁguration puts the highest bandwidth pressure to the network. This explains the performance results in Fig.6. The 4hypercube provides more bandwidth and therefore achieves shorter execution times. In contrast, concentrated topologies trade bandwidth for low latency, and therefore provide worst performance than the 4-hypercube in this bandwidthsensitive scenario, but still outperform the 2D-mesh. Please notice that for larger systems we expect the gap between 2D-mesh and 4-hypercube to increase. 7.4 Implementation space exploration We selected two relevant scenarios from the previous analysis framework and explored how performance ratios between alternative topologies are impacted by possible implementation degradation effects. These considerations will 113113 2-ary 2-mesh 4-ary 2-mesh 2-ary 2-mesh 4-ary 2-mesh Time (ns)  1.4e+07  1.3e+07  1.2e+07  1.1e+07  1e+07  9e+06  8e+06  7e+06  6e+06 Time (ns)  1.3e+07  1.2e+07  1.1e+07  1e+07  9e+06  8e+06  7e+06  6e+06  0  1  2 Latency  3  0.9  1  4  0.5  0.6  0.7  0.8 Frequency (Ghz)  0  1  2 Latency  3  0.9  1  4  0.5  0.6  0.7  0.8 Frequency (Ghz) Figure 8. Implementation space of 2D-mesh vs concentrated 2-ary 2-mesh with latency in the injection links. Figure 9. Implementation space of 2D-mesh vs concentrated 2-ary 2-mesh with latency in the switch-to-switch links. drive the synthesis process by posing optimization directives to speciﬁc logic modules and/or links in order to preserve theoretical performance beneﬁts. In particular, scenarios B and D were selected. B is a latency-sensitive scenario, while D is a bandwidth-sensitive one. In D , we restrict the implementation space exploration to the 2D-mesh (reference architecture for many NoC designers) and to the promising 4-hypercube solution. When the designer starts reasoning about the physical synthesis, he realizes that both 2D-mesh and 4-hypercube topologies require the same switch arity. This is because the 2-ary 4mesh increases the number of dimensions while limiting the number of switches in each dimension to 2. Therefore, the operating frequencies for the two topologies might differ only as an effect of the different wiring patterns and of the critical path being in the wires. Since all NoC modules in our architecture feature input and output latching, we assume that the critical path will be determined by the switch or the network interface. If link delay exceeds this maximum delay, we assume that such critical links will be broken via retiming and ﬂow control stages, following the link pipelining technique in [25]. While links of the ﬁrst and the second dimension in the 2D-mesh and in the 4-hypercube can be retained of comparable length in many ﬂoorplan variants, the express links in the 4-hypercube are the most likely candidates for retiming. The relative performance ratio between the alternative topologies as a function of the latency on the express links of the 4-hypercube is reported in Fig.7. It can be clearly observed that the breakeven point occurs with 5 cycles latency on the express links, which leaves ample margin to the physical synthesis tool to infer such links given the small size of the system as a whole. When it comes to scenario B , the implementation space complexity increases due to another physical parameter that our analyis has to account for: the maximum achievable frequency. In this scenario, we compare the 2D-mesh with the 2-ary 2-mesh concentrated topology. This latter requires a switch radix of 10 (it is 6 in the 2D-mesh), which might lead to severe cycle time degradations. Moreover, a concentrated topology poses ﬂoorplanning concerns. In fact, a large number of cores (4 in this case) need to be placed close to the same switch where they are attached to. This might be achieved in many ways posing different layout constraints. As an example, we might think of a ﬂoorplan wherein 4 cores are placed all around the switch, and the switch-toswitch connections might be as long as the side of two tiles in the best case. Such links might be candidate for retiming stage insertion. Alternatively, the ﬂoorplan might consist of a central network around which all cores are placed. In this variant, the critical links are those connecting the network interfaces (attached to the tiles) to the switches, which we call injection links. In the two ﬂoorplan variants the latency incurred by different links might impact performance in a radically different way, since different communication ﬂows are affected. We kept the 2D-mesh topology at the reference frequency of 1 GHz, while scaling clock frequency of the concentrated topology and the latency in its switch-to-switch or injection links. Execution time results are illustrated in Figg.8 and 9. As we scaled network frequencies, we had to scale computation tile and external I/O device frequencies accordingly, since our architecture forces an integer divider between the frequencies in the two clock domains. So, as network frequency scales down from 1 GHz to 600 MHz, tiles and I/O devices were forced to work from 500 MHz (their assumed maximum speed) to 300 MHz, keeping a frequency divider of 2. Had we considered the 500 MHz case for the network, we should have changed the divider to 1 instead of further scaling down I/O frequency, but this would have led to a different performance scenario than B . The horizontal plane in Figg.8 and 9 represents 2D-mesh performance. Fig.8 indicates that as soon as the frequency of the concentrated topology falls below 900 MHz, the performance improvements derived from the analysis in subsection 7.3 are at ﬁrst balanced and then progressively vanish. If the physical synthesis is able to limit operating frequency degradation (higher radix switch by 4 I/O ports) to 100 MHz, then such performance beneﬁts can be retained even placing up to 2 retiming stages in the injection links. In contrast, Fig.9 indicates that performance of the concentrated topology is much less sensitive to latency in the switch-to-switch links. In fact, not all communication ﬂows are affected, since inter-cluster communications do not go 114114 (a) Figure 10. (a) Floorplan directives for the 2Dmesh and (b) for the 4-hypercube. (b) through the long links. When latency of the injection links is increased, each communication ﬂow incurs always 2 extra cycles latency, in the injection and ejection links, respectively. 8. Topology physical design By leveraging the results of the implementation space exploration in the previous section, we went through the synthesis process of the 2D-mesh and the 4-hypercube topologies. In a balanced system (scenario D , subsection 7.3), we proved a 3.5% performance margin of the 4hypercube over the 2D-mesh, that can be retained provided the implementation of the express links does not give rise to more than 4 cycles latency. We used industrial tools for placement-aware logic synthesis and for place-and-route on an STMicroelectronics 65nm technology. Since computation tiles were assumed to include at least a processor and a memory core, we consider a physical size of such tiles of 1mm x 2mm. Although the system is globally regular and homogeneous, the asymmetric tile size makes the traditional assumptions on mesh and hypercube wiring questionable. Based on the theory in [1], the 4-hypercube we are considering should require two times the wiring resources of the 2D-mesh. We will see that this is not actually the case for this ﬂoorplan. Hard IP blocks representing computation tiles are deﬁned with a Library Exchange Format ﬁle and a Verilog Interface Logical Model, and rendered as black-boxes obstructing an area of 2 mm2 . First, a manual ﬂoorplanning phase is performed, where the hard black boxes are placed on the ﬂoorplan. Fences are deﬁned to limit the area where the cells of each module of the interconnect can be placed. Subsequently, the tool automatically places cells and ﬁnally the wire routing steps are performed. To account for the worst case, we prevented over-the-cell routing for the hard IP obstructions, thus posing more constraints on network link synthesis. Since position of network interfaces and switches on the ﬂoorplan needs to be manually deﬁned, while the routing is performed automatically, we came up with the optimized Figure 11. Automatic routing of hypercube topology. the 4Total W ire Lenght 2D MESH 4-HYPERCUBE 1,4 1,2 1 0,8 0,6 0,4 0,2 0 Figure 12. Total wire length for automatic topology routing. ﬂoorplan directives for the tool reported in Fig.10(a) for the 2D-mesh and in Fig.10(b) for the 4-hypercube. As can be observed, the asymmetric tile size plays in favour of hypercube wiring, since the length of the horizontal and of the vertical express links turns out to be similar and comparable to the length of horizontal wires in the 2D-mesh. This latter topology also features horizontal and vertical links of unequal length. The routing for the 2D-mesh was performed automatically by the tool. The critical path in the network interfaces was found to be 0.65ns, while the switch maximum delay amounts to 0.84ns. So, logic modules of the network can sustain the target 1GHz operating frequency. The maximum delay in network links was found to be 0.45ns: it includes not only wire delay, but also the delay of some ﬂow control cells and buffers. By performing the routing for the 4hypercube (see Fig.11), we found the delay in logic blocks almost unchanged, while maximum network link delay increased to 0.91ns. This indicates that the 4-hypercube under test can be mapped on silicon without any pipelining in the express links, therefore theoretical performance beneﬁts of this topology can be retained in the ﬁnal implementation. Moreover, since routing channels were reserved in excess for horizontal and vertical routing, we might restrict them at the eventual cost of 1 repeater stage in the hypercube express links, as far as performance is concerned. Exploring layout trade-offs like this however falls outside the scope of this paper and is left for future work. Finally, we report in Fig.12 total wire length statistics about the 2D-mesh and the 4-hypercube automatic routing. The total wire length increases in the 4-hypercube only by 25%. This is much less than expected, and this is due to the limited size of the system and to the asymmetric physical size of computation tiles. Therefore, the link delay overhead 115115 detected above for the 4-hypercube is mainly due to logic gates along the link (buffers, ﬂow control cells) and not to longer wirelengths. 9. Conclusions This work proposes an analysis framework for NoC topologies that leverages fast and accurate TL simulation to explore the implementation space and to drive the synthesis process. The methodology allows to quantify maximum theoretical performance beneﬁts that speciﬁc topologies provide with respect to alternative ones, and to assess the degradation margins that physical synthesis can afford without impacting speedup margins. We apply this methodology to the analysis of several topologies for a 16 core system. In spite of the limited system scale, performance differentiation is already visible in speciﬁc trafﬁc scenarios. Moreover, we prove that automatic routing of these topologies might provide surprising results, in light of the speciﬁc layout constraints of the design at hand. In future work, we will extend this analysis framework to highly integrated MPSoC platforms with a few hundreds of nodes. "
Hardwired Networks on Chip in FPGAs to Unify Functional and Con?guration Interconnects.,"We propose that networks on chip (NOC) are hardwired in Field-Programmable Gate Arrays (FPGA).??Although some area of the FPGA then has a fixed function, this loss of flexibility is outweighed by the following benefits.??First, implementation cost is much reduced. Second, a hardwired NOC solves physical problems such as timing closure and high cost of global wiring.??Third, dynamic partial reconfiguration can be better exploited.??Compared to current soft or firm interconnects, a hardwired NOC poses fewer restrictions on the(re)placement of IP blocks in the FPGA.??Finally, we also propose that the hardwired NOC is used for both the functional interconnect between the IP blocks and the configuration interconnect that transports the bitstreams.??We give a detailed overview of our NOC architecture, and its configuration and programming.??The proposed scheme enhances the on-line generation of bitstreams and the on-line verification of loaded bitstreams to detect tampering with the device.??In our experiment, a hardwired NOC has acceptable (≤ 10%) overhead for IP sizes with approximately 1400 lookup tables (LUT), enabling a fine-grained combined functional and configuration interconnect. A hardwired NOC offers significantly better functional performance than a soft NOC. Moreover, the configuration and programming of the hard NoC is much faster than when using a soft NOC.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Hardwired Networks on Chip in FPGAs to Unify Functional and Conﬁguration Interconnects Kees Goossens1,2 , Martijn Bennebroek3 , Jae Young Hur2 , and Muhammad Aqeel Wahlah2 1 Research, NXP Semiconductors, Eindhoven, The Netherlands, kees.goossens@nxp.com 2 Computer Engineering Laboratory, Delft University of Technology, Delft, The Netherlands 3 Research, Philips, Eindhoven, The Netherlands Abstract We propose that networks on chip (NOC) are hardwired in Field-Programmable Gate Arrays (FPGA). Although some area of the FPGA then has a ﬁxed function, this loss of ﬂexibility is outweighed by the following beneﬁts. First, implementation cost is much reduced. Second, a hardwired NOC solves physical problems such as timing closure and high cost of global wiring. Third, dynamic partial reconﬁguration can be better exploited. Compared to current soft or ﬁrm interconnects, a hardwired NOC poses fewer restrictions on the (re)placement of IP blocks in the FPGA. Finally, we also propose that the hardwired NOC is used for both the functional interconnect between the IP blocks and the conﬁguration interconnect that transports the bitstreams. We give a detailed overview of our NOC architecture, and its conﬁguration and programming. The proposed scheme enhances the on-line generation of bitstreams and the on-line veriﬁcation of loaded bitstreams to detect tampering with the device. In our experiment, a hardwired NOC has acceptable (≤ 10%) overhead for IP sizes with approximately 1400 lookup tables (LUT), enabling a ﬁne-grained combined functional and conﬁguration interconnect. A hardwired NOC offers signiﬁcantly better functional performance than a soft NOC. Moreover, the conﬁguration and programming of the hard NoC is much faster than when using a soft NOC. 1. Introduction Field-programmable gate arrays (FPGA) are highlyprogrammable chips at the forefront of silicon technology scaling. Current FPGAs are divided in orthogonal conﬁguration and functional regions, each with their own interconnect. In this paper we propose, ﬁrst, to use a hardwired (or just: hard) network on chip (NOC) for the functional interconnect. Second, we advocate to use the same hard NOC as the conﬁguration interconnect. In the remainder of the introduction we deﬁne some terminology, list the advantages of our approach, and give the outline of the rest of the paper. 1) Terminology: We call an intellectual property (IP) block soft, when after synthesis it is mapped on basic FPGA elements such as LUTs, before being placed and routed. A soft IP is independent of the device it is synthesised on. A ﬁrm IP is a soft IP that has optimised mapping, placement, and routing, taking into account the particular FPGA device implementation. An IP is hard when it is directly implemented in silicon. Existing examples are embedded multipliers, microprocessors, RAMs, and high-speed IO interfaces [37]. We deﬁne (re)conﬁguration as the installation of new functionality (IPs) in the FPGA by loading reconﬁguration regions with bitstreams. Dynamic partial reconﬁguration means that only part of the FPGA is reconﬁgured and that this happens while part of its functionality remains operational. Only soft and ﬁrm IPs need to be conﬁgured. An IP is programmed after it is conﬁgured, if necessary, which entails changing the state of its registers when it is in functional mode. These registers are usually memory-mapped so that they can be accessed through the functional interconnect, such as a bus or a NOC. Note that in our case the NOC uniﬁes the conﬁguration interconnect used to transport bitstreams, the functional control interconnect through which IPs are programmed, and the functional data interconnect to transport data between IPs. The ﬁrst is used when the system is (partially) reconﬁgured, and the latter two are used when the system is (partially) in functional mode. In the remainder, we will not further distinguish the control and data interconnects, calling them functional interconnect. 2) Advantages of Hard NOCs: Hard interconnects use the native silicon technology rather than conﬁgurable elements of the FPGA. They are reported to occupy 35 times less area, operate 3.5 times faster, and also use less energy [21]. However, the FPGA is less ﬂexible because some silicon area is committed to a ﬁxed function [37]. We argue that the cost:performance gain far outweighs the loss of ﬂexibility. Modern FPGAs are complex embedded systems on chip that are not monolithic functions, but composed of many reconﬁgurable blocks. The IPs communicate using standard communication protocols, e.g. AXI [3], OCP [25], 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.33 DOI 10.1109/NOCS.2008.33 45 45 and DTL [27] implemented by a functional interconnect, such as busses, switches, and NOCs. Hence, a functional interconnect is required, whether it is soft, ﬁrm, or hard. A hard interconnect must be dimensioned for the worst-case, whereas a soft interconnect can be tailored to the running application. However, the performance:cost ratio of the hard interconnect is much better than of the soft interconnect. Thus the hard interconnect can be “over-dimensioned” signiﬁcantly before we lose ﬂexibility. Also, in contrast to soft interconnects, hard interconnects are not conﬁgured, which saves conﬁguration footprint (bits) as well as conﬁguration time. We refer to Section 4 for the entire analysis. When a system is dynamically partially reconﬁgured, the functional interconnect must be updated, i.e. reconﬁgured and/or reprogrammed. This requires that IPs and interconnect are decoupled in several senses: physically (e.g. to avoid glitches), in placement (reconﬁguration and functional regions of IP and interconnect must be disjoint), and logically (there should be no communication to/from IPs that are reconﬁgured, and communication between other IPs should not be affected). Hard interconnects are per deﬁnition disjoint from soft IPs and reduce layout restrictions. Programmable interconnects such as busses and NOCs only require reprogramming. Hence, communications between IPs that are not reconﬁgured are not disturbed during partial reconﬁguration from a physical and placement point of view, and from a logical point of view too, if the interconnect offers guaranteed communication services. Moreover, programming is faster than reconﬁguration, which is required by e.g. dedicated through-routed point-to-point wires. By virtue of their better performance, hard busses and NOCs are also reprogrammed quicker than the soft counterparts (see Section 4.3). Busses and switches are single-hop interconnects, i.e. their arbitration does not scale with the number of attached IPs, unlike NOCs. Moreover, interconnects are physically distributed over the chip and deep-submicron problems related to long wires (such as low speed, signal degradation, etc.) complicate timing closure between IPs. NOCs can address these issues by a globally-asynchronous locallysynchronous design style and by replacing long global wires with optimised segmented wires between routers [31]. This is only possible when the NOC is hard (and to a lesser extent when ﬁrm). Finally, multi-hop interconnects, such as NOCs, are mandatory to offer transparent multi-chip or multi-board communication. 3) Uniﬁed Interconnects: We advocate merging conﬁguration and functional interconnects because the conﬁguration interconnect can beneﬁt from the higher performance of the hard NOC. However, the NOC should support real-time streaming of bitstreams, i.e. avoid interference from other (functional) trafﬁc. Unifying the conﬁguration and functional NOCs allows conﬁguration bitstreams to be treated like normal data. This allows many new applications. For example, bitstreams can be generated at run-time, e.g. for run-time tuning of IP conﬁguration. Bitstreams can also be encrypted, decrypted, and check-summed to detect bitstream tampering. In addition, IP can be relocated from one part of the FPGA to another, rather than reloading from the conﬁguration memory (ﬂash). For example, we can load and relocate embedded built-in-self-test (BIST) engines to structurally test the FPGA, by generating test patterns on the FPGA itself and by using the hard functional NOC as a test-access mechanism (TAM) [2][1]. The remainder of this paper is structured as follows. The contributions of this paper are described when we review related work. In Section 3, we explain our NOC architecture. After describing how a system is conﬁgured and programmed, we combine all elements in a complete system. Various possible extensions and new applications of the hard NOC are then discussed. In Section 4, we compare a soft, ﬁrm, and hard implementation of the Æthereal NOC [12]. Finally, conclusions are drawn in Section 5. 2. Related Work Scores of soft interconnects ranging from pointto-point [19], busses [5][30], cross-bars [24][34], to NOCs [22][20][28] have been presented in the literature. They implement different cost:performance trade-offs. Larger and faster FPGAs can contain many IPs and multihop network solutions are sure to gain popularity. Fewer ﬁrm interconnects have been presented [5][18][6], where the interconnect is implemented using native on-chip resources. This increases the performance and lowers the cost of the interconnect compared to soft interconnects, but their implementations are dedicated to particular FPGA architectures. [5] presents four communication schemes, including bus macros, shared memories, linear array multiple bus, and external crossbars that used for different communication modes. In [18], a reprogrammable interconnect is implemented based on a LUT-based bus macro and is used to dynamically reconﬁgure the attached IPs. In [6], a large (928 × 928 bits) crossbar using native programmable interconnects and LUTs is presented. However, standard IP communication protocols such as AXI [3] contain several hundred of wires per IP. Few IPs can therefore be connected to a single switch. For dynamic partial reconﬁguration of IPs, the functional interconnect and IPs must be disjoint, otherwise they must be reconﬁgured simultaneously. By reprogramming the functional interconnect, IPs can be dynamically added and removed through partial reconﬁguration, e.g. [5][30][22][18]. Only few works reconﬁgure the soft interconnect itself. [19] dynamically reconﬁgures a pointto-point soft interconnect and [28] shows how a soft NOC 4646 can be partially reconﬁgured by adding or removing router modules at run time. A hard NOC is only (re)programmed. The cost of the hard interconnect is much lower than a soft functional interconnect, lowering the need for dynamically changing the topology. Moreover, because the hard NOC is per deﬁnition disjoint from soft IP, eliminating any interference during programming and/or reconﬁguration. Only two groups have reported on hard NOCs in FPGAs [17][16][8][11]. In [17][16], a system model is explored with SystemC simulation, and no hardware architecture is presented. In addition, the conﬁguration and programming of the NOC are not deﬁned in [17][16]. The work of [8][11] proposes to use a hard NOC as the functional interconnect. Although the basic idea of a hard NOC is introduced, no architecture details are provided. Our work differs from [8][11] in the following. Foremost, we combine the conﬁguration and data interconnects in the hard NOC, which has not been proposed by any prior work. Furthermore, our partitioning of the network interface (NI) in hard and soft regions draws the distinction more clearly at the network versus transport layer (see Section 3.2). For example, we ﬁrmly place routing in the hard NI kernel domain. Moreover, in [16] the architecture is based on tiles (functional regions), which can communicate only through the NOC. As explained in Section 3.3, we do not partition the FPGA in distinct functional regions and also keep them orthogonal to the conﬁguration regions. Next, we deﬁne the (re)conﬁguration and (re)programming steps required to boot a system. The requirement for guaranteed communication services (GS) to support real-time streaming of bitstreams is not met by their NOC. Also, we support arbitrary topologies without inducing any extra (routing) complexity [15], which is useful, as shown in Section 3.4. Finally, we present a comprehensive analysis of cost, performance, and programming footprint, based on experimental results on a Xilinx Virtex-4, which is lacking in [17][11]. NOCs are also (naturally) emerging to deal with interchip communication due to their intrinsic multi-hop nature [32][26][7]. [32] motivates extending the functionality of an ASIC by connecting the (hard) NOC on the ASIC to a soft NOC on an FPGA companion chip. [26] goes one step further and introduces a three-level hierarchical network. Intra-FPGA point-to-point links are implemented with Fast Simplex Links, inter-FPGA communication uses Rocket IO, and an ethernet switch implements inter-board communication. The Berkeley Emulation Engine [7] employs a parallel bus for the inter-FPGA communications. They use three types of global communication networks, a low-latency global communication tree, a highbandwidth nonblocking crossbar, and a 10/100 Base-T Ethernet. Multi-gigabit transceivers (MGTs) also were used for 2D-mesh inter-FPGA communications. Inter-chip and inter-board NOC are extensions of the work presented here, as discussed in Section 3.4. 3. Hard NOC Architecture 3.1. Overview Figure 1 shows the differences between the FPGA architectures with conventional (a) and new (b) interconnects in a system context. Figure 1(a) illustrates a conventional FPGA with orthogonal conﬁguration (thin lines, dark grey blocks) and functional (fat lines, light grey blocks) interconnects. The minimum coherent reconﬁguration region is the minimum number of reconﬁguration and functional regions that coincide. For example, in the case of Virtex4, it is equal to 22 frames, which cover 16 CLBs [36]. Figure 1(b) shows Figure 1. (a) Conventional and (b) new conﬁguration and programming. an example instance of the proposed architecture, where the conﬁguration and functional IO are connected to the same hard NOC, which now has two shades of grey. For simplicity, the conﬁguration and functional regions (frames and CLBs) have been drawn together as a CFR (conﬁguration and functional region). However, just as in the conventional FPGA, they can be orthogonal. The local conﬁguration interconnect/region (drawn as a chain of conﬁguration registers) connects to the NOC to receive bitstreams. CLBs are connected to their neighbouring CLBs in the same or different functional regions, as usual, but a functional region (containing a number of CLBs, BRAMs, etc.) is also connected to the NOC. The conﬁguration IO, usually connected to external ﬂash memory, is shown at the bottom right. The boot module (Section 3.3) bootstraps the system by conﬁguring and programming it through the uniﬁed interconnect. We describe NOCs generally, before detailing network 4747 interfaces (Section 3.2), and their essential role in system conﬁguration and programming (Section 3.3). Section 3.4 combines all these elements in our proposed uniﬁed hard conﬁguration and data interconnect. NOCs contain two kinds of components: routers that move data around (usually packets), and network interfaces (NI) that convert the NOC-internal data format (e.g. packets) to the protocol required by the NOC clients (e.g. AXI, OCP, DTL). Direct mesh topologies, where every router is connected to a NI, are popular. However, it makes sense to adapt the NOC topology to the resources of the particular platform FPGA to provide ample bandwidth to high-speed offchip IO links, conﬁguration IO, external memory interfaces, or large shared on-chip memories. As illustrated in Figure 1(b), NI kernels and shells can be hard or soft. One or more NIs may be attached to one IP, such as functional IO. Real-time applications often require communication with a guaranteed minimum bandwidth, and maximum or even ﬁxed latency. A number of NOCs offer these guaranteed communication services (GS, often also called quality of service) [12][23][4], and almost all NOCs offer basic lossless communication but without real-time guarantees (best effort, or BE). Most NOCs implement transactionbased protocols, such as AXI and OCP, and some also implement streaming data protocols, such as DTL’s peerto-peer streaming data (PPSD) [27]. The former uses a distributed-shared-memory communication model requiring read/write commands, data, and address, each of which uses a valid/ready handshake. The latter is a much simpler basic data pipe, containing only the write data group, usually with a valid/ready handshake. This has consequences for which part of a NI is hard or soft (see Section 3.4). Bitstreams are delivered to the region being reconﬁgured as a continuous data stream that should not be interrupted. However, during a dynamic partial reconﬁguration the NOC may be in use by an application which may interfere with the bitstream’s timing. Hence, the FPGA reconﬁguration interconnect should offer a GS (ﬁxed latency) communication between the bitstream source (e.g. off-chip ﬂash) and the reconﬁgured region. Similarly, NOCs with GS have been proposed to replace SOC test access mechanisms (TAM) that transport test patterns and responses to test the IP for errors for manufacturing test or for ﬁeld testing [1]. The alternative, stalling the test or conﬁguration bitstream when the BE communication is interrupted, requires expensive holdable state elements. 3.2. Network Interface Architecture The details of router architectures are not relevant here, details can be found in e.g. [4][12]. NIs are often split in two parts, see Figure 2: the kernel (performing network layer functions) and the shell (for transport layer functions) [29]. NOCs with GS communication require resource reservaThe IP shown in Figure 2 has a master data port, on which it sends read/write requests to a slave somewhere on the NOC, and a slave MMIO programming port, like the NI kernel, over which read/write requests are received. The slave conﬁguration port is a new addition proposed in this paper. Because conﬁguration data is streaming data and not shared memory communication, the IP conﬁguration port is connected directly to the NI kernel. From the NOC perspective, it is just another port, over which data is communicated with ﬁxed latency. This is achieved by programming sufﬁcient bandwidth allocation in the kernel’s TDMA slot table and by sizing the buffers in the NI kernel/shell to absorb any jitter from unevenly-spaced TDMA slots [9]. programmable processor. The boot module shown in Figure 1(b) is attached to the hard NI shown in Figure 3. The functional IO is connected to a hard NI kernel because it produces and/or consumes streaming data. This is not the case for all hard functional blocks. For example, the embedded memories, memory controllers, and hard processors (not shown) connect to a hard NI kernel and shell because they use distributed-shared-memory transactions. The local conﬁguration interconnect/region (drawn as a chain of conﬁguration registers) connects to a hard NI kernel to receive bitstreams. CLBs are, as usual, connected to their neighbouring CLBs in the same or different functional regions; but a functional region (containing a number of CLBs, BRAMs, etc.) is also connected to the NOC with a hard NI kernel. The NI shell is soft and will be implemented in the functional region. The two CFRs illustrate that conﬁguration and functional regions may share the same NI kernel, and that the number of NIs and their number of ports may vary. The sizes of conﬁguration and functional regions are discussed in Section 4. 1) Hard versus Soft: In Figure 1(b), we discuss which parts of the NOC can be hard, soft or ﬁrm. Routers are best implemented hard. NI kernels (cf. Figures 2 and 3) have ﬁxed hardware, such as (de)packetisation hardware. Channel FIFOs, per-channel administration (paths, credit counters, etc.), and TDMA slot tables can all be implemented soft. This makes no sense for FIFOs because the cost of LUT-based FIFOs is prohibitive, compared to BRAM-based FIFOs. Given that a number of hard FIFOs within reasonable distance of the hard (de)packetisation will be ﬁxed, it is best to dimension the TDMA and channel administration tables for this worst case, to hardwire the entire NI kernel. The NI shell, however, is soft for the following reasons. First, the port protocol depends on the IP and a single system often contains a number of different port protocols. Second, the depth of a channel FIFO depends on the required bandwidth and latency (e.g. it must hide jitter due to the distribution of TDMA slots and the round-trip latency of end-to-end ﬂow control), which depends on the application. The channel FIFO is for a small part in the NI kernel, where it has a ﬁxed size, and for the remainder in the NI shell. The only NI shells that are hard are the following. First, those connected to the NI kernel’s MMIO programming port, because it is always required and uses a ﬁxed protocol. Those NI shells that connect to hard IPs that use shared-memory protocols, such as the boot module, embedded memories, memory controllers, hard embedded processors, etc. 2) Hard NOC Extensions: The ﬁrst extension is to allow the hard NOC to be expanded by soft routers and NIs. This is useful when functional regions are large and more NI kernel ports are required than are present on the hard NI kernels near the region. This is implemented by the fat dashed line from the hard router network to the lower CFR in FigFigure 4. Current conﬁguration & programming. Figure 5. New conﬁguration & programming. receive new bitstreams and are reset on their MMIO ports. The NOC may be reprogrammed with the new application mode as well. Recall that bitstreams are streaming data and are usually not interruptable during their transport from bitstream memory to the IP (reconﬁguration region). The ﬁxed-latency GS communication service of the NOC is essential to avoid any (temporal) interference, because during the partial reconﬁguration other IPs continue to operate and communicate using the NOC. Thus, our hard NOC offers two essential qualities: reprogramming instead of reconﬁguration and guaranteed (ﬁxed-latency) communication. The conﬁguration interconnect is now split in two parts. First, the single link between conﬁguration IO and the boot module (Figure 3 and arrow 3a in Figure 5). The boot module connects to the hard NOC. Second, once the bitstream arrives on the other side of the NI (e.g. the CFR of Figure 2) it enters the local conventional conﬁguration interconnect, to conﬁgure the conﬁguration region (e.g. one or more frames) connected to the NI port (arrow 3b in Figure 5).1 The FPGA is divided in conﬁguration regions, each of which is reachable only via a single NI kernel of the hard NOC. But our functional regions are connected to each other, like CLBs are, and are also connected to the NOC’s hard NI kernels. We do not divide the FPGA in functional regions (also called tiles) that can communicate only via the NOC, as advocated by [5][16][11]. This unnecessarily causes problems, such as optimally packing multiple IP in multiple regions, or restricting the IP size to that of a region. 3.4. Proposed FPGA Overview In this section, we discuss Figure 1(b) in more detail. The conﬁguration IO is connected to the boot module, which may be a simple hardwired DMA and/or secure 1 In a ﬁrst instance we only upload bitstreams from boot processor to IPs, and the response channels are then absent. i.e. we omit the dashed channels at the boot module’s NI (Figure 3), and the slave IP NI (Figure 2). We re-introduce the response channel and alternative 3a’ in Section 3.4. 5050 ure 1(b). However, because the hard NOC will be running at higher frequencies than can be achieved with a soft NOC, it passes through the bridge marked “B,” which implements a clock domain crossing between hard NOC and the functional region. The bridge must be hardwired. When the soft extension is not used, the link from the functional region to the bridge can easily be “tied off ” by setting the packet-type side-band signal to “empty” [29]. In the opposite direction, towards the functional region, no connection will be programmed along the unused link. A related extension is the use of the functional IO to connect the NOCs on multiple FPGAs, to create a multi-FPGA NOC [32][26][7]. The NI kernel on one NOC converts packets to streaming data which is transported over the functional IO to the other FPGA, where it is repacketised by the NI kernel on the other NOC, which can be soft, ﬁrm, hard. 3) Dynamic Bitstreams: The proposed architecture already allows dynamic embedded bitstream generation, in the sense that any IP can functionally generate a bitstream at run time. Modern FPGAs support the on-line partial conﬁguration, for example using Xilinx ICAP(internal reconﬁguration access port). However, these conventional conﬁguration interconnects constitute dedicated physical point-topoint networks, which suffer from scalability problems and increased wire delays. To upload the bitstream to a conﬁguration region, the boot module must program the NOC to connect the data port of the IP to the conﬁguration port of the conﬁguration region. (As brieﬂy discussed in Sections 3.2 and 3.3; cf. arrow 3a’ in Figure 5.) We envisage computing or modifying a hardware accelerator. For example, optimising a FIR ﬁlter by conﬁguring multipliers optimised for the coefﬁcients instead of generic (larger, slower) multipliers and programming the coefﬁcients via MMIO. In fact, bitstreams are normal data and can, for example, be loaded in encrypted form from the conﬁguration IO, be sent to a (hard) decryption engine on the NOC, before being sent to a conﬁguration region. The proposed extension goes one step further, by allowing bitstreams to be read or downloaded from as well as uploaded to conﬁguration regions. This is implemented by the dashed arrows from the reconﬁguration regions to the NOC in Figures 2, 3, and 1(b). Apart from speculative applications, such as embedded genetic algorithms operating on bitstreams [33], it allows dynamic relocation of IPs by moving the bitstreams, in conjunction with techniques like those of [22] where bitstreams are reloaded rather than moved. As an example, we can load and relocate embedded builtin-self-test (BIST) engines that generate test patterns on the FPGA that are distributed to functional regions (e.g. using multicast). We use the hard NOC as a test access mechanism (TAM), which requires adaptations to the normal test shells, described in [1]. In Figure 2 this would entail adding a streaming data port on the CFR for test data. The BIST engines check the test responses that are streamed back over the hard NOC. In this way, the costly test time is reduced by testing at higher (functional) speed, and by reducing the amount of data that must be streamed to and from the automated test equipment (ATE) over limited IO [2]. Functionally operating on bitstreams also can be used to check if IP conﬁgurations have been tampered with since they were installed. This can be achieved by streaming the bitstream to a (hard) encryption or CRC IP and comparing the output with the original encrypted bitstream or a smaller checksum. The use of a functional interconnect for decrypted bitstreams is in general not safe, because it allows a malicious IP to capture secret information. However, ﬁrst note that a NOC is a (virtual) point-to-point and not a broadcast interconnect. Second, all channels are either hardwired (i.e. the path between source-destination pair is ﬁxed), in which case only the source and destination IP have access to the data. Or, the channel is programmed at run time. By bootstrapping from a (single) secure boot module, no IP can communicate (send or listen) until the boot module creates a channel to another IP [10]. Moreover, NOCs with guaranteed communication services also decouple the temporal behaviours of communicating IP. This removes the possibility to obtain secret information either from the timing of communication (events), or from a malfunctioning system after injecting spurious data. 4. Results We now compare various implementations of Æthereal NOC instances in terms of area, functional speed, footprint size, conﬁguration throughput, programming speed, and general ﬂexibility. The automated Æthereal design ﬂow generates application-speciﬁc NOCs, based on the speciﬁed communication requirements of multi-mode applications [13]. The topology, TDMA table size, and FIFO sizes are all tailored to the application. The ﬂow output includes the technology-independent RTL VHDL of the NOC, test bench, trafﬁc generators, embedded C code to program the NOC, scripts for gate-level synthesis, and scripts for scanchain insertion. It is also possible to specify a topology and generate the NOC programming code at a later stage, which is required for our purposes. We speciﬁed a simple system, consisting of two masters and three slaves, where each master can communicate to all slaves simultaneously. One master is the boot module. The NOC contains one router and ﬁve NIs, where the NI kernels/shells are shown in Figures 2 and 3. Each IP has its own NI and the single router has ﬁve bidirectional links. The NOC components use optimised hardware FIFOs [35] for high speed and small area. NI and router FIFOs contain 16, resp. 24 words. 4.1. Area Several router and NI instances have been implemented to timing back-annotated layout [12]. Based on these lay5151 out instances, our design ﬂow accurately estimates the area of any generated NOC instance in 130nm CMOS technology. The area results for the router and NI instances are shown in “hard” rows of Table 1. We also synthesised, placed, and routed (to the pads) the NOC onto a Virtex-4 XC4VLX200ff1513-11, for which we used Xilinx ISE 8.2. The Virtex-4 contains 178176 LUTs in total. The Virtex4 is fabricated in CMOS technology with a 90nm Copper CMOS process [36]. We used two versions of the NOC: one uses LUTs for all FIFOs and the other uses BRAMs. These are referred to as “soft” and “ﬁrm” in Table 1. We mapped a whole NOC and extracted the number of LUTs for a single router-NI pair, to take into account routing overhead, etc. Table 1. Area of NOC Components. Note the area of ﬁrm components does not include BRAMs. hard soft router NI router NI kernel NI shell ﬁrm router NI kernel NI shell # LUTs mm 2 2 mm 2 mm 130nm 90nm 90nm 2658 3470 2171 1988 1524 1501 0.13 0.33 0.065 0.167 2.28 3.58 2.24 1.70 1.57 1.55 5.48 7.16 4.48 4.10 3.15 3.09 In Table 1, the bold numbers are used to derive the remaining data in the following manner. We derived the 90nm-equivalent area of the 130nm hard NOC components by dividing by two. For the ﬁfth column, the area of soft router was computed by multiplying the area of the hard router by a factor 35, reported to be the cost ratio between ASIC and FPGA in [21]. The hard NI area is similarly scaled and divided over the soft NI kernel and shell in the ratio of their number of LUTs. The same holds for the ﬁrm router and NI, except that the BRAM area (used for the FIFOs) is omitted. Moreover, the RTL has not been optimised to minimise the LUT area. Hence we underestimate the area of the ﬁrm components. We ensured that all calculations, here and below, are conservative, i.e. underestimate cost of the soft and ﬁrm NOCs, and overestimate cost of hard NOCs. As an example, an alternative calculation of soft / ﬁrm router and NI area, shown in italics in the right-most column of Table 1, uses the area per LUT. The area is computed by dividing the number of required LUTs by the die size of the Virtex-4 device (735mm2 , estimated from www.fpga-faq.org). We divide the die size by 2, considering that the device contains embedded blocks (such as I/O pins, DSP, memories). In this case, the area ratio of soft:hard is above 70. Our analyses remain within the same order of magnitude. Note that the area for the soft/ﬁrm NOC does not include the area of the conﬁguration interconnect, which the hard NOC also implements. Our estimates are therefore conservative. 5252 10000% 1000% 100% 10% 1% 0% e z i s R F C f o % s a t s o c C O N soft firm hard 100 5100 10100 15100 20100 CFR s ize (number of LUTs ) (a) Percentage overhead for varying CFR sizes. I N + R + R F C f o r e b m u n . x a m 1000 100 10 1 100 soft firm hard 2100 4100 6100 8100 CFR s ize (numbe r of LUTs ) 10100 (b) Number of IPs on a Virtex-4 for varying CFR sizes. Figure 6. NOC cost for varying CFR sizes. In Figure 6(a), the cost of a router and NI is plotted against the size of the CFR. As an example, for soft, ﬁrm, and hard NOCs, the overhead reaches 830%, 500%, and 14% for a CFR size of 1000 LUTs, respectively. This means that the area overhead of hard NOC is acceptable for typical IP size, while the area overhead of soft/ﬁrm NOC is unacceptably large. Figure 6(b) depicts the number of (equalsized) IPs that can be mapped on a Virtex-4. As an example, for soft, ﬁrm, and hard NOCs, the maximum number of IPs are 19, 30, and 144 for a CFR size of 1000 LUTs, respectively. This means that sufﬁciently many IPs can be mapped when the hard NOC is accommodated, while only small number of IPs can be mapped when the soft/ﬁrm NOC is utilized. Hence a soft NOC has less than 10% area cost only for a small number of large (≈ 80, 000 LUTs) CFR, for which a NOC is not attractive to use. A hard NOC is already attractive for small CFRs (≥ 1400 LUTs), allowing over a hundred of CFRs on a Virtex-4. Firm NOCs score in between, but it is difﬁcult to state when they are attractive, given the current data. 4.2 Functional Performance In this section, we compare the speed of the NOCs. The hard implementation of Æthereal operates at (worstcase) 500MHz in 130nm [12]. The soft NOC operates at 118MHz (the NI) and 124MHz (the router) in the 90nm Virtex-4 device. Although the speed of the soft NOC can undoubtedly be improved, a speed improvement of a factor 5, which ignores the speed increase from ASIC 130nm to FPGA 90nm, is a conservative estimate. For a fair bench                  2 (bit /sec /mm mark of soft and hard NOCs, the performance:cost ratio ) should be compared. With equal topologies and architectures, we need to only compare the raw link bandwidths (32 bits × operating frequency) per area: soft 32bits × 118MHz /8.10mm2 = 466 ﬁrm 32bits × 122MHz /4.83mm2 = 808 hard 32bits × 500MHz /0.23mm2 = 69565 149 1 1.7 Thus, the performance of ﬁrm NOC is 1.7 times better than a soft NOC and a hard NOC is 149 times better. 4.3. Conﬁguration and Programming In this section, we quantitatively compare the number of bits and the required time for conﬁguration & programming. 1) Conventional Conﬁguration: The conﬁguration unit of a Virtex-4 device is a frame, containing 41 32-bit conﬁguration words [36]. SelectMAP provides conﬁguration at a rate of 1.9Gb/s (32-bit interface at 60MHz [36]). Therefore, a frame can ideally be conﬁgured in 41word × 32bit /1.9Gbit /sec = 0.7µs. A CLB column is the smallest coherent reconﬁguration unit, which, containing 22 frames, takes 0.7 × 22 = 15µs to conﬁgure. 2) NOC Programming: A NOC, whether soft or hard, must be programmed as described in Section 3.3. Each connection (a pair of request-response channels) in Æthereal has between 832 and 2096 state bits [14]. This requires 2.5µs to program in a hard NOC [14]. An ARM processor is used as the boot module, and it uses optimised MMIO read and write transactions to conﬁgure the NIs. (Routers are not programmed.) The boot time of the ARM processor is not taken into account here. 3) Soft NOC: We consider a conventional conﬁguration interconnect with a soft NOC. The soft NOC requires 8300 LUTs per router-NI pair (Table 1). Therefore, at least 8300 LUTs × 22 frames per column 8 LUTs per CLB × 16 CLBs per column = 1427 frames are 1.8Mb . required to conﬁgure a single router-NI pair. This is equivalent to a bitstream of 1427 frames × 41 words × 32b = It takes at least 1427 frames × 0.7µs = 998µs conﬁgure the router-NI pair. However, the soft NOC is distributed over the FPGA and is likely to occupy more frames. Moreover, the soft NOC frames must be disjoint from CFR frames, otherwise they cannot be reconﬁgured independently. Both increase the NOC conﬁguration time. Therefore, both the conﬁguration time and bitstream size are optimistic estimates. The time to program a connection in the soft NOC for the functional data communication can be derived by 2.5µs × 500/118 = 10.6µs (converting the hard NOC frequency to the slower soft NOC speed). 4) Hard NOC: The second scenario uses a hard NOC to conﬁgure the FPGA. First, the hard NOC must be programmed. For each NI, two connections must be programmed (one to program the NI, and one to conﬁgure the 5353 Table 2. Conﬁguration and Programming phase conf. NOC prog. conf. interc. conf. CFRs prog. NOC & CFR soft NOC hard NOC conﬁguration mode 998µs/NI 5µs/NI 1.9Gb/s 8Gb/s functional mode 10.6µs/conn. 2.5µs/conn. Fig.4 Fig.5 1 1 2-3 2 3 4 CFR), or 2 × 2.5 = 5µs per NI. Second, the bitstreams must be loaded in the CFRs. The NOC transports the conﬁguration data at, say, 8Gb/s (conservative conversion from 16Gb/s raw bandwidth to nett bandwidth), and is then a factor four faster than the conventional FPGA at 1.9Gb/s. 5) Overall: Recall Figures 4 and 5 where the phases of booting a system were depicted. For each of the soft and hard NOC Table 2 the time spent on the following phases: programming the conﬁguration interconnect, conﬁguring the functional interconnect, programming the functional interconnect, and conﬁguring the CFRs. A hard NOC requires programming per NI, whereas the soft NOC requires conﬁguration per router-NI. Since programming requires fewer bits and is faster too, a system with a hard NOC is ready for functional operation 998µs/5µs = 200 times faster. The gain of (10.6 − 2.5)µs to program each functional connection does not signiﬁcantly improve this number. The conﬁguration footprint of the hard NOC is also smaller. The footprint size for a single soft router-NI pair is 1.8M b, whereas only 8.4K b is required for the hard NI with 4 connections (routers are not programmed) [14]. For conﬁguration regions equal to those of a current Virtex-4 device (16 CLB columns of 128 LUTs each, i.e. 2048 LUTs), a hard NOC has a 7% area overhead versus 405% for a soft NOC. Note that our analyses are independent from the particular NOC because they essentially depend on three factors: the ASIC:FPGA area ratio, the ASIC:FPGA operating frequency ratio, and the conﬁguration:programming footprint (bitstream versus number of MMIO bits) ratio. For example, using a GS-only instead of BE+GS router [12] reduces the area cost of both soft and hard NOC by a factor four and increases their speed by a factor two, but the ASIC:FPGA area and speed ratios remain the same. 5. Conclusions We proposed to replace the current FPGA conﬁguration interconnect by a hard network on chip (NOC) and to use it also as the functional interconnect. The conﬁguration and functional regions (CFR) are independent, as in current interconnects, but both connect to the hard NOC. The proposed architecture reduces timing closure problems in the functional interconnect because it is hardwired and preveriﬁed. A hard NOC is disjoint from soft IPs, eliminating an interference during dynamic partial reconﬁguration. For example, this reduces the placement and layout of restrictions of soft IPs, which otherwise have to be e.g. in separate CLBs from a soft NOC. A number of novel applications are possible in the new architecture. First, the hard NOC can be extended with soft network components (routers, NIs) implemented in the functional regions, by adding a simple bridge. This allows dynamic addition of soft routers and NIs. Second, bitstreams can be generated and/or modiﬁed at run time by IPs. For example, they can be optimised at run time, encrypted, etc. Bitstreams can also be moved from one conﬁguration region to another, allowing, for example, dynamic relocation of IPs and embedded built-in self test. We compared a conventional FPGA and soft NOC with our proposed architecture on area, functional speed, conﬁguration footprint and speed, and general ﬂexibility. 10% area cost is achieved by a soft NOC only for large CFRs (80, 000 LUTs), but already for small CFRs (≥ 1400 LUTs), allowing a maximum of 109 such CFRs on a Virtex4. The hard NOC has a bandwidth:area performance advantage of a factor 150 or more over a soft NOC. Because a hard NOC operates at a higher speed, and is programmed rather than conﬁgured like a soft NOC, the conﬁguration of the FPGA is 200 times faster when using a hard NOC, and its conﬁguration footprint of the hard NOC is also smaller than that of a soft NOC. This suggests that our uniﬁed hard NOC outperforms the conventional conﬁguration interconnect and soft NOC, at acceptable cost. "
Applying Dataflow Analysis to Dimension Buffers for Guaranteed Performance in Networks on Chip.,"A network on chip (NoC) with end-to-end flow control is modelled by a cyclo-static dataflow graph. Using the proposed model together with state-of-the-art dataflow analysis algorithms, we size the buffers in the network interfaces. We show, for a range of NoC designs, that buffer sizes are determined with a run time comparable to existing analytical methods, and results comparable to exhaustive simulation.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Applying Dataﬂow Analysis to Dimension Buffers for Guaranteed Performance in Networks on Chip Andreas Hansson1 , Maarten Wiggers2 , Arno Moonen1 , Kees Goossens3,4 and Marco Bekooij4 1Eindhoven University of Technology, Eindhoven, The Netherlands 2Twente University of Technology, Enschede, The Netherlands 3Delft University of Technology, Delft, The Netherlands 4Research, NXP Semiconductors, Eindhoven, The Netherlands m.a.hansson@tue.nl Abstract A Network on Chip (NoC) with end-to-end ﬂow control is modelled by a cyclo-static dataﬂow graph. Using the proposed model together with state-of-the-art dataﬂow analysis algorithms, we size the buffers in the network interfaces. We show, for a range of NoC designs, that buffer sizes are determined with a run time comparable to existing analytical methods, and results comparable to exhaustive simulation. As the main contributions of this paper, we: 1) show how to construct a dataﬂow graph for a NoC communication channel, 2) use this model with state-of-the-art dataﬂow analysis techniques [10] to dimension the NI buffers. The run time is comparable to existing analytical methods, and the results are comparable to exhaustive simulation. Section 2 describes the proposed channel model. In Section 3, we apply dataﬂow analysis [4, 10] to determine conservative bounds on the NI buffer sizes. Finally, conclusions are drawn in Section 4. More details are found in [7]. 1 Introduction 2 Channel model A growing number of applications, often with real-time requirements, are integrated on the same System on Chip (SoC), in the form of hardware and software Intellectual Property (IP). Applications are split into tasks, and it is the onus of the interconnect to facilitate the real-time requirements of the inter- and intra-task communication. Networks on Chip (NoC) offer latency and throughput guarantees [6, 8]. The guarantees depend on the arbitration in the routers and Network Interfaces (NI), but also on the NI buffers. These decoupling buffers absorb differences in speed and burstiness between the IP and the NoC [5], and thereby hide network internals, such as packetisation, arbitration, and end-to-end ﬂow control [2, 9]. If the NI buffers are not sufﬁciently large, the guarantees are violated. The size must, however, be minimised, as the buffers are a major contributor to NoC power and silicon area [3]. Existing approaches to dimension NI buffers [3, 5] are based on linear bounds [5], resulting in a low run time but large buffers, or exhaustive simulation [3], with smaller buffers but a run time of several days for larger SoC designs. In this work, we model the NoC and the IP using a dataﬂow graph. In contrast to [3, 5], that are based on network calculus, dataﬂow analysis cannot only dimension the buffers given the temporal requirements, but also determine the temporal behaviour of the SoC for given buffer sizes, e.g. to analyse if new applications ﬁt on an existing NoC. We use Cyclo-Static Dataﬂow (CSDF) [1] models to compute buffer sizes. A CSDF graph is a directed graph, consisting of actors connected by edges. An actor has distinct phases of execution, and synchronises by communicating tokens over edges. An actor is enabled to ﬁre when tokens are available on all its input edges and transitions from phase to phase in a cyclic fashion. The proposed channel model is shown in Figure 1. In the ﬁgure, n × 1 denotes a vector of ones of length n, and the italic symbol 1 denotes a vector of ones of appropriate length. The Response Times (RT) [1] of the individual actors appear above and below the actors. Similar to [3, 5], the model is based on the notion of a producer and consumer, connected by a forward channel that carries data and a reverse channel that carries end-to-end ﬂow-control credits. The buffers of the channel are represented by βp and βc . Our method allows any CSDF model of the IP, but to enable a comparison with existing models, the IP behaviour is described by a period of pp and pc cycles, and a burst size of bp and bc words, for producer and consumer, respectively. The model reﬂects that only one word can be produced per cycle, thereby reducing the resulting buffer sizes. In this work, we model the Æthereal NoC [6] that uses time-division multiplexing (TDM) to provide latency and throughput guarantees. The model has ﬁve parameters, the period of the TDM wheel pn , and four parameters related 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.17 DOI 10.1109/NOCS.2008.17 213 211 RT=hpp − bp , bp × 1i RT=θd (tf ) RT=pn RT=θp (φf ) 1 hbp × 1, 0i 1 1 1 1 IPp,θ IPp,ρ h0, bp × 1i 1 NIp,θ 1 RT=hbp × 1, pp − bp i βp 1 1 βc 1 NIp,ρ 1 1 ρ−1 d (tf ) 1 1 1 Rf 1 Rr 1 1 NIc,ρ 1 1 ρ−1 h (tr ) 1 1 NIc,θ 1 h0, bc × 1i IPc,ρ 1 1 1 RT=hbc × 1, pc − bc i hbc × 1, 0i 1 1 IPc,θ Producer IP and NI shell NI kernel Router network NI kernel Consumer IP and NI shell RT=θp (φr ) RT=pn RT=θh (tr ) RT=hpc − bc , bc × 1i Figure 1. Data travelling in the forward direction (solid) and credits in the reverse direction (dashed). Table 1. Buffer sizes for mobile phone system Algorithm Analytical [5] Simulated [3] Dataﬂow approx. [10] Dataﬂow exact [4] Run time (s) Tot. buf. (words) Impr. (%) 0.05 1025 ref 6845 799 12 0.78 721 30 547 680 34 ρ−1 to the allocated resources: the forward and reverse path, φf and φr , plus the time-slot allocation in the two directions, denoted tf and tr . The throughput and latency of the NI is determined by tf and tr . The functions θd , ρ−1 d , θh and h conservatively bound the latency and rate for data and credits respectively. The router network is modelled as a latency only, given by the path and the function θp . The aforementioned bounding functions are determined by the NoC architecture, and include e.g. packetisation overhead, pipelining delay and arbitration. While the parameters and functions used in Figure 1 are speciﬁc for the Æthereal NoC, the model is applicable as long as the arbiters that are applied in the NIs and routers can be characterised as latency-rate servers [11], e.g. [2] and [8]. 3 Experimental results We compare the run time and buffer sizes derived using our approach with those of [3, 5]. Averaging over a set of 1000 randomly generated use-cases, each with 100 connections, we see a buffer-size reduction of 36% [10], 41% [3] and 44% [4] compared to [5]. The run time, using [10], is consistently below a second for all the different use-cases. A phone SoC with telecom, multi-media and gaming constitutes our design example. The results are shown in Table 1. The dataﬂow-based methods result in improvements of more than 30% while the simulation only reduces the buffers by 12%. In addition, the run time of the dataﬂow approximation algorithm is four orders of magnitude lower. 4 Conclusions The latency and throughput guarantees of Networks on Chip (NoC) depends on appropriately sized decoupling buffers in the network interfaces, situated between the Intellectual Property (IP) modules and the router network. Existing buffer-sizing methods are based on network calculus and rely on coarse linear bounds or exhaustive simulation, resulting in either large buffers or impractically long run times. In this work, we propose to capture the behaviour of the NoC and the IPs using a dataﬂow model. The presented model is an important step in enabling the use of dataﬂow analysis for NoC resource allocation. The proposed method is evaluated by comparing with existing buffer-sizing approaches on a range of SoC designs. Buffer sizes are determined with a run time comparable to existing analytical methods, and results comparable to exhaustive simulation. For larger SoC designs, where the simulation-based approach is not practical, our approach ﬁnishes in seconds. "
Low Power and Reliable Interconnection with Self-Corrected Green Coding Scheme for Network-on-Chip.,"In this paper, a low power joint bus and error correction coding is proposed to provide reliable and energy- efficient interconnection for network-on-chip (NoC) in nano- scale technology. The proposed self-corrected "";green""; (low power) coding scheme is constructed by two stages, which are triplication error correction coding (ECC) stage and green bus coding stage. Triplication ECC provides a more reliable mechanism to advanced technologies. Moreover, in view of lower latency of decoder, it has rapid correction ability to reduce the physical transfer unit size of switch fabrics by self- corrected technique in bit level. The green bus coding employs more energy reduction by a joint triplication bus power model for crosstalk avoidance. In addition, the circuitry of green bus coding is more simple and effective. Based on UMC 90 nm CMOS technology, the simulation results show self-corrected green coding can achieve 34.4% energy reduction with small codec overhead. This approach not only makes the NoC applications tolerant against transient malfunctions, but also realizes energy efficiency.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Low Power and Reliable Interconnection with SelfCorrected Green Coding Scheme for Network-on-Chip  Po-Tsang Huang, Wei-Li Fang, Yin-Ling Wang and Wei Hwang  Department of Electronics Engineering & Institute of electronics, and   Microelectronics and Information Systems Research Center,  National Chiao-Tung University, HsinChu 300, Taiwan  {Bug.ee91g, willy911.ee91}@nctu.edu.tw, grace1121@gmail.com, Hwang@mail.nctu.edu.tw   Abstract—In this paper, a low power joint bus and error  correction coding is proposed to provide reliable and energyefficient interconnection for network-on-chip (NoC) in nanoscale technology. The proposed self-corrected “green” (low  power) coding scheme is constructed by two stages, which are  triplication error correction coding (ECC) stage and green bus  coding stage. Triplication ECC provides a more reliable  mechanism to advanced technologies. Moreover, in view of  lower latency of decoder, it has rapid correction ability to  reduce the physical transfer unit size of switch fabrics by selfcorrected technique in bit level. The green bus coding employs  more energy reduction by a joint triplication bus power model  for crosstalk avoidance. In addition, the circuitry of green bus  coding is more simple and effective. Based on UMC 90nm  CMOS technology, the simulation results show self-corrected  green coding can achieve 34.4% energy reduction with small  codec overhead. This approach not only makes the NoC  applications tolerant against transient malfunctions, but also  realizes energy efficiency.  INTRODUCTION   I.  Network-on-chip (NoC) design has been considered an  effective solution to integrate multi-core system and a  process independent interconnection architecture [1]. As to  the shrinking of processing technology, the ratio between the  interconnection delay and the gate delay will increase in  advanced technologies. According to ITRS prediction as  shown in Fig.1, the ratio will increase to 9:1 with 65nm  technology  [2].  It  indicates on-chip  interconnection  architectures, such as NoC, will dominate the performance in  future system-on-chip (SoC) design. In addition to today’s  multi-core SoC design, power consumption is the major  challenge with advanced technologies.  Some physical effects  in nano-scale  technology,  unfortunately, will degrade the performance of NoC. In order  to obtain  low  latency, reliable and “green” on-chip  communication, power consumption becomes the critical  challenge in today’s multi-core SoC design with nano-scale  effects. First, coupling capacitance increases in nano-scale  technology significantly. Second, decreasing of operation  voltage will make the interconnection more susceptible to  noise. Due to crosstalk noises, it not only aggravates the  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.29 DOI 10.1109/NOCS.2008.29 77 77 100 y a e l D e v i t a e l R 10 1 0.1 250 Gate Delay (Fan Out 4) Local (Scaled) Global with Repeaters Global w/o Repeaters 180 Process Technology Node (nm) 130 90 65 45 32 Figure 1. Interconnect delay and gate delay under different technology  power-delay metrics but also deteriorates the signal integrity.  Many techniques were proposed to reduce the coupling  capacitance effect. The first option is to widen the pitch  between bus lines. The second option is using P&R (place &  route) tools to avoid routing of the bus lines side by side. In  SoC, however, the interconnect complexity and the routing  time do not allow us trying it to minimize the coupling  capacitances. The third option is to change the geometrical  shape of bus lines. But the disadvantage of this method is  that the blank area will increase since the cross-sectional area  of a bus line is fixed. The fourth option is to add a shielding  line (VDD/Ground) between two adjacent signal lines.  However, these methods are impractical and some will even  increasing interconnect area significantly. Bus encoding will  be an elegant and effective technique to solve the crosstalk  effect, and further provides a reliability bound for on-chip  interconnect.   For on-chip interconnection, three critical issues such as  delay, power and reliability have to address. For the delay  issue, the propagation delay will be deteriorated by the  coupling capacitances. Especially for long global lines, it  takes long time to charge/discharge large capacitances. For  the power issue, the power dissipation will increase due to  both parasitic and coupling capacitances. Finally,  the  reliability issue of on-chip interconnection will degrade due  to noises.  In advanced  technologies, circuits and  interconnects become even more degraded to noises as well  as lower operation voltage. Furthermore, the increasing    k Crosstalk Avoidance Code(CAC) l m Error Control  Code (ECC) Linear Crosstalk  Code(LXC) mc Figure 2. A unified framework for joint crosstalk avoidance and error                   correction  e c a Bus Encoder Serializer ECC  encoder Switch Fabric r e C d C o E c e d r t o n s e s e c e o m l r E P r t o n s e s e c e o m l r E P f r e n t i e c a f r e n t i Joint  bus and error correction  coding with serializer/deserializer Channels through  Multi switch fabrics ECC encoder ECC decoder Bus Decoder Deserializer ECC  decoder r e C d C o E c n e Figure  3. A joint bus and error correction coding scheme with   serializers/deserializer in network-on-chip  coupling noise, soft-error rate, bouncing noise decrease the  reliability also. In view of these, self-calibration circuitry  will become essential in today’s SoC design. Therefore, a  joint error correction coding and bus coding scheme is an  effective solution to deal with the three challenges. Joint bus  and error correction coding has been an elegant and effective  technique to solve the crosstalk effect and further provides a  reliability bound for on-chip interconnection. In this paper,  we proposed a novel joint bus and error correction coding  scheme, which is called self-corrected green coding scheme.  Depending on joint triplication bus power model, it provides  NoC platforms with  energy-efficient  and  reliable  interconnection.   The rest of this paper is organized as follow. Section II  will analyze the related works of reliable coding schemes.  The concept of joint bus coding and error correction coding  is presented in section III. Section IV will describe the  proposed self-corrected green coding scheme in network-onchip. In addition, the corresponding power model will be  presented in Section IV also. Section V will show simulation  results. Finally, we will conclude the paper in Section VI.  II. RELATED WORKS OF RELIABLE CODING SCHEMES  In recent years, many approaches made a lot of efforts on  crosstalk avoidance coding and error correction coding in  SoC paradigm. A unified framework of coding for systemon-chip with crosstalk avoidance codes (CAC) and error  control codes (ECC) was proposed in [4,6]. It provides  practical codes to solve delay, power, and reliability  problems jointly as Fig. 2. Crosstalk avoidance codes, one  kind of bus coding scheme, avoid specific code patterns or  code transitions to reduce delay and power consumption  produced by crosstalk effect. Error control codes are able to  7878 Figure 4. (a) Average power versus different ratio of serializer and  frequency in high loading (b) Average power versus different ratio of  serializer and frequency in low loading  detect and correct the error bits. Other approaches are based  on the unified framework to improve the ability of error  correction and to address signal integrity in NoC [6-7].   Joint coding schemes based on the unified framework  provide better communication performance. However, these  schemes just combine different kinds of codes directly, since  the intrinsic qualities of crosstalk avoiding coding and error  correction coding are mutually exclusive, except for  duplicate-add-parity (DAP). In DAP coding, nevertheless,  the critical path of the priority bit is much longer than others.  Moreover, crosstalk avoidance code must be a code that does  not modify the parity bits in any way as decoding of ECC  has to occur before any other decoding in the receiver. In  order to reduce the coupling effect of the parity bits, the  linear crosstalk code could be applied without destroying the  parity bits.  JOINT BUS CODING AND ECC IN NETWORK-ON-CHIP  III.  Both bus coding and error correction coding enlarge the  physical transfer unit in network-on-chip. The physical  transfer unit is a unit into which a packet is divided and  transmitted through micro-network. Simply speaking, the  physical transfer unit size is the bit-width of the link wire,  I/O and switch size. Large physical transfer unit size  increases network area and energy consumption, especially  for switching circuit and buffering units in switch fabrics.  Some approaches address signal integrity to protect the NoC  interconnection infrastructures against different transient  malfunctions [6-7]. However, these approaches can not  decode the codes in the switch fabrics because of significant  delay. The critical depth, moreover, will increase rapidly as  well as the bit-width increases. Therefore, the un-decoded  code will induce great amount of area and energy dissipation  in switch fabrics, especially in switching circuits and buffers.  For the disadvantages based on previous discussion, we  propose a joint bus and error correction coding scheme with  4:1 serializers and deserializer as Fig. 3. The serializer and  deserializer reduce the physical transfer unit size and further  reduce the area and energy consumption of the switch fabrics.  However, in order to achieve the same throughput, the  serialization technique will increase the operation frequency  of  interconnection  network. On-chip  serialization,  nevertheless, is a crucial technique for NoC implementation.      It reduces overall network area and optimizes power  consumption which  is well-explained  in  [8,9]. We  implemented the serializer and deserializer with all-digital  self-calibrated multi-phase delay-locked loop in [10]. Fig. 4  shows the average power dissipation of wiring under  different ratios of seializer and different frequencies. Fig. 4(a)  and 4(b) are simulated under high loading and low loading of  wires,  respectively. Despite of  loading,  the power  consumption decreases with the increasing ratio of serializer  under low operation frequency. Unfortunately, with he  increasing  ratio of serializer under higher operation  frequency, the power consumption increases because of large  driver to provide high driving ability. From [9] and the  simulation results, 4:1 serializer is an optimized ratio to  achieve energy saving.   IV. SELF-CORRECTED GREEN CODING SCHEME  We proposed a novel joint bus and error correction  coding scheme, called self-corrected green coding scheme, to  provide a low energy and reliable interconnection in  advanced technologies. Self-corrected green coding scheme  is constructed by two stages, which are green bus coding  stage and triplication ECC stage. The green bus coding is  developed by the joint triplication bus power model to  achieve more energy reduction for the triplication ECC. The  proposed self-corrected green coding scheme has  the  advantages of shorter delay for ECC, more energy reduction  and smaller area.  A. Triplication Error Correction Coding Stage  The triplication error correction coding scheme shown in  Fig. 5 is a single error correcting code by triplicating each bit.  From the information theory, it is well-known that a code set  with hamming distance of h has h-1 error-detect ability and  [(h-1)/2] error-correct ability. For the triplication error  correction coding, the hamming distance of each bit is equal  to 3. Therefore, each bit can be corrected by itself if there are  no more than two error bits in the three triplicated bits. The  error bit can be corrected by a majority gate, and the function  of the majority gate is shown in Fig. 5. Compared to other  error correction mechanisms, the critical delay of the decoder  is a constant delay of a majority gate and much smaller than  others. In other words, it has rapid correction ability by selfcorrected mechanism in bit level. Therefore, triplication error  correction coding is more suitable in network-on-chip  because the data could be decoded and encoded in each  switch fabrics by smaller delay of triplication correction  coding.  In addition, one of the advantages of incorporating error  correction mechanisms in the NoC data stream is that the  supply voltage of channels can be reduced without  compromising the reliability of system. Reducing the supply  voltage Vdd will increase the bit error probability. To  simplify the error sources, we assume the bit error  probability ε is as Eq. (1) when a Gaussian distributed noise  voltage VN with variance σN 2 is added to the signal waveform.  VQε 2 dd n σ ⎛ = ⎜ ⎝ ⎞ ⎟ ⎠ Where Q(x) is given as   ( ) 2 y 2 1 2 x Q x e dy π ∞ − = ∫ Each triplication sets can be error-free if and only if no error  transmission or just 1-bit error transmission. For each  triplication sets, therefore, P1-bit correct is given as  3 1 ( ) ( ) 3 2 1 1 1 bit correct P ε ε ε − − ⎛ ⎞ ⎜ ⎟ ⎝ ⎠ = − + For k-bits data, transmission is error-free if and only if all k  triplication sets are correct. Pk bits correct  is given by  ( ) 2 3 s 1 1 3 2 k k k bit correct i bit correct i P P ε ε + − = = = − ∏ Hence, the word-error probability will be  ( ) 2 3 triplication 1 1 3 2 k P ε ε + = − − For small probability of bit error ε, Eq. (5) simplifies to  2 3 triplication 3 k kε 2 P ε ≈ − By contrast, the word-error probability is much smaller than  hamming code and DAP which are direct to k2ε2. The  triplication error correction coding, moreover, can avoid  forbidden overlap condition (FOC) and forbidden pattern  condition (FPC) which will induce large energy dissipation  by coupling effect.  The FOC can be defined that bit pattern  (y2,y1,y0) does not have transition from 010 to 101, and  FPC can be satisfied that avoiding bit pattern 010 and 101 in  (y2,y1,y0).  B. Joint Triplication Bus Power Model  Although triplication error correction coding can avoid  some forbidden conditions, some power-hungry transition  patterns can not be avoided completely. These patterns are  mainly constructed by forbidden transition condition (FTC)  and self switching activity. The FTC can be satisfied that bit  pattern (y1,y0) does not have transition from 01 to 10 or  x0 x1 xk-1 x0 x1 xk-1 Triplication Channels Majority Gate :  a b c FM FM = ab + bc + ca  Decoder Figure  5. Triplication error correction coding scheme  7979                                                                                                              from 10 to 01. Therefore, we presented a joint triplication  bus model to implement the bus coding stage for achieving  more energy reduction. For 4-bit triplication bus, the  capacitance matrix Ct can be expressed as follow:   3 0 0 0 3 2 , 0 0 3 2 0 3 X L L C C tC C + λ λ − ⎤ − λ + λ λ − ⎥ ⎥ − λ + λ λ − ⎥ ⎥ − λ + λ ⎦ λ = ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ = (7)  The parameter λ is defined as the ratio of coupling  capacitance Cx to loading capacitance CL. The capacitance  matrix is modified from [4] and the coefficient of loading  capacitances is 3 for triplicated bits. Therefore, the power  consumption formula is shown in Eq. (8). E and P represent  energy and power density respectively. Then, f and V (VDD)  are frequency and voltage (voltage supply). Bi means the  current transition state (1 or 0) for the line i, and Bi -1 shows  the previous state for the line i.  The power density P can be transferred to Eq. (9).  ( ) ( ) ( ( ) ) ( ) ( ) ( ( ) ) ( ( ) ) 2 2 2 − 1 1 − 1 2 1 1 2 3 − 3 2 21 − 4 − 1 1 1 4 1 2 − 2 2 DD 2 − 1 2 − 1 3 2 3 2 − 1 3 − 1 4 3 4 3 3 3 3 L B B B B B B B B B B B B P f C V B B B B B B B B λ ⎡ ⎣ + λ ⎡ ⎣ + λ ⎡ ⎣ ⎧ ⎪ ⎪ ⎪ ⎪ ∗ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ ⎫ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎭ − + − + − ⎤ ⎦ + − + − − − = ∗ ∗ ⎤ ⎦ ⎤ ⎦ − − − − − − The items of Eq. (9) are defined and identified as follow:  − 1 2 − 1 − 1 − 1 2 − 1 − 1 1 − 1 ( B B B B [( where d ) ) B B B B ( )] B B B B r 4 B B B B i i i i i i i j j i j ij ij i i j j i i j j r r ∪ d − − − = ⊕ − − = = = ⊕ + × (10) What the ri means is that there is a switch of line i. It does  not concern about the direction of the change and the  adjacent lines. This item is only considering about the  loading capacitances. The meaning of ri ⊕ rj is that only one  line is changing between two lines of i and j. For the term of  dij, it is about the two lines change in the opposite direction.  Moreover, comparing with the other two definitions, ri and  ri ⊕ rj, the voltage difference across the coupling capacitance  is double and when squared it results in power 4 times. This  explains the factor 4 for dij. And using equation (10), we can  get the power formula as equation (11) with the parameter of  λ. The term α is the coefficient about coupling effects and  switching activities.   2 DD 1 2 3 4 1 2 2 3 3 4 12 23 34 f C 3( r r 4 ( d d ) ) ( ) L P V r r r r r r r r d α λ = α = + λ × × + + + + + × + ⊕ + ⊕ + ⊕ C. Green Bus Coding Stage for Crosstalk Avoidance  The purpose of green bus coding is to minimize the value  of α in Eq. (11) by encoding the signals when λ>2. Therefore,  we establish a 32x32 transition state table by calculating α,  and select 16 transition patterns with minimal values of α as  the codeword by avoiding crosstalk. The correspondences  between 4-bit data-word and 5-bit codeword are shown in  Fig. 6. According to the correspondences, the data-word can  be grouped into two set, original set and converted set as.  When the transmitted data is in the converted set, the green  bus coding will convert the data to the original set by oneon-one mapping as Fig. 6. Meanwhile, the converted bit, c4,  will be asserted, and c0 and c2 will be inverted and mapped  to the original set. X1 and X2 will not be modified all the  time. The circuit implementation of green bus coding is also  shown in Fig. 7, including encoder and decoder. The  circuitry of green bus coding is more simple and effective  than other approaches by the joint triplication bus model.  Between two adjacent 5-bit codeword, it’s unnecessary to  add an extra shielding line to reduce the coupling effect. This  is because the boundary data of the 5-bit codeword are set as  0 almost. Certainly, it can achieve more energy saving by  inserting a grounded shielding line. It’s a trade-off between  wiring area and energy consumption.  The proposed green bus coding has following properties:  Dataword Codeword x3~x0 c4~c0 0  0  0  0 0  0  0  1 0  0  1  0 0  0  1  1 0  1  0  0 0  1  0  1 0  1  1  0 0  1  1  1 1  0  0  0 1  0  0  1 1  0  1  0 1  0  1  1 1  1  0  0 1  1  0  1 1  1  1  0 1  1  1  1 0  0  0  0  0 0  0  0  0  1 0  0  0  1  0 0  0  0  1  1 0  0  1  0  0 1  0  0  0  0 0  0  1  1  0 0  0  1  1  1 0  1  0  0  0 1  1  1  0  0 1  1  1  1  1 1  1  1  1  0 0  1  1  0  0 1  1  0  0  0 0  1  1  1  0 0  1  1  1  1 0000 1000 1100 1110 1111 0001 0010 0011 0100 0110 0111 0101 1101 1001 1011 1010 Orignial Set Converted Set c4 = x2x1'x0       + x3x2'x0         + x3x2'x1 if (c4) then  c0 = x0' , c2= x2' else  c0 = x0 , c2= x2 Figure  6. Codeword, signal mapping and Boolean expression for                     green bus coding scheme  Figure  7. Encoder and decoder for green bus coding scheme  x0 x1 x2 x3 c0 c1 c2 c3 c4 Encoder Decoder x0 x1 x2 x3 c0 c1 c2 c3 c4 ( ) ( ) { } 2 D D 1 1 t i i j j i j P f V C B B B B − − = ∗ ∗ − ∗ − ∑ ∑ (8) ) VC ( ) ( V i f t Tf V E − = 8080                                       (1) Using y4 as detection bit to decide y0 and y2. It can  simplify  the circuitries of encoder and decoder,  especially for the decoder.  (2) The encode bit is always equal to the data bit at certain  bit positions, which y1 = x1 and y3 = x3.  (3) Focus on the joint bus and error correction coding  scheme, the self-corrected green coding scheme can   avoid forbidden overlap condition (FOC) and forbidden  pattern condition (FPC) and reduce forbidden transition  condition (FTC) to achieve more power saving.  (4) It’s unnecessary to add extra shielding lines to reduce  the coupling effect between two adjacent codeword  with increasing coding bits.   V. SIMULATION RESULTS AND ANALYSIS  In  this section, we present simulation results  to  demonstrate the improvement in energy and reliability by  employing self-corrected green bus coding scheme. All the  simulation results are based on UMC 90um CMOS  technology at 1.2 V. For a 32-bit packet size, the 4:1  serialization technique transfers the physical transfer unit  size from 32 bits to 8 bits. In addition, the length of wires is  set as 0.8mm of metal-4 with minimum width and spacing of  0.2um. Fig. 8 shows the energy reduction to uncoded code  under different values of λ. Compared to other approaches,  such as Hamming Code (HC), FTC+HC, FOC+HC and  Boundary Shift Code (BSC) in [4], One Lumbda Code  (OLC)+HC and DAP+shielding (DSAP) in [5], CADEC in  [7], the proposed self-corrected green bus coding (S-C green)  can achieve the most energy reduction no matter which value  of λ is.  Because error correction coding increases the reliability  of on-chip interconnections, the designers can tradeoff  between the power consumption and reliability through  reducing the operation voltage. Simplifying the cumulative  effect of noise sources, the model assumes that a Gaussian  distributed noise with voltage VN with variance σN 2 is added  to the signal. The bit error probability is given as Eq. (1) and  Eq. (2), where Vdd is the voltage swing of signal. Given the  same σN 2, the bit error probability is increasing by decreasing  the voltage swing of signals. However, some specific error  control/correct coding schemes allows us to decrease the  voltage swing of signal, and guarantee the reliability at the  same time. If and only if satisfy the equation as follow:  ( ) ( )ˆ uncode ecc P Pε ε ≥ (12)  Where ε is the bit error probability with full swing voltage  (1.2 V), ˆε is the bit error probability with lower swing  voltage. In order to obtain the lowest supply voltage for  specific error correction coding under the same level  reliability of un-coded code, the supply voltage can be  revised as:  2 4 6 8 10 12 -80 -60 -40 -20 0 20 40 60 Ratio of coupling Capacitance to Loading Capacitance  E e n r y g R c u d e i t n o t d e d o c n u o u b s ( % ) This work Hamm ing FTC+HC FOC+HC OLC+HC BSC DSAP CADEC S-C Green Figure 8. Energy reduction to un-coded code under different values of  λ  k=8 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0.65 0.70 0.75 0.80 0.85 0.90 0.95 S-C Green Dap Hamming CADEC k=32 -22 -20 -18 -16 -14 -12 -10 -8 -6 -4 -2 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05 S-C Green Dap Hamming CADEC (a) (b) V o t l e g a ( V ) V o t l e g a ( V ) Uncode_Word-error-rate(       ) log10 Uncode_Word-error-rate(       ) log10 Figure  9. Voltage of  specific error correction coding versus different  uncoded word-error- rate with (a) k = 8 (b) k = 32  8181                                                V ˆ dd = V dd − 1 − 1 Q Q ( ( ˆ ε ε ) ) P uncode ( Pε = ) ecc ( )ˆ ε Inverse function of Gaussian distributed function also called  probit function ( )xΦ . Probit function has been proved that  the function doesn’t have primary primitive. To solve the  problems, we first approximate the value of bit error  probability by varying  the voltage swing of signal.  Integrating from -100 ~ Vdd/2, we divide the integral range  on x-axis into 0.0001(v) segment, and each segment can  produce a trapezoid .To sum up the area of all trapezoids and  the results represent  the approximation of bit error  probability. Therefore, the lowest voltage swing for specific  error correction coding which satisfied the Eq. (13) could be  obtained.   When un-coded code is operated at full swing supply  voltage (1.2v), the different level of bit error probability ε  can be obtained by varying variance of Gaussian distributed  function. Fig. 9(a) and 9(b) show the voltages of  specific  error correction coding versus different uncoded word-error-  rate with k = 8 and k = 32, respectively. From Fig. 9(a),  assume the bit error probability of un-code word ε equals to  10-20, the specific voltage of Hamming code, DuplicationAdd-Parity code, CADEC code and the proposed selfcorrected green code are 0.845V, 0.850V, 0.695V, and  0.836V, respectively. From Fig 9.(b), all ECC code’s lowest  supply voltages increase with the increasing un-code worderror-rate. Compared to other ECC codes in Fig 9.(a),  however, the proposed S-C Green code has the better  characteristic that the lowest supply voltage decreases when  the un-code word-error-rate increases. When both k and uncode word-error-rate increase, the proposed self-corrected  green code can obtain the lower operation voltage than  CADEC.  Table 1 lists the summaries of codec in different  approaches, including the corresponding codec area, power  and latency. In addition, the summaries of different joint  coding schemes are shown as Table 2, which consist of the  energy saving of channels under normal operation voltage  and lowest supply voltage, the physical transfer unit size in  channels and in routers. The CADEC uses double error  correction coding to enhance the ability of error correction.  However, the codec overhead and energy dissipation are  much worse than others. Although it can reduce the supply  voltage to the lowest point at the same bit-error probability,  it is hard to be implemented in real cases. Furthermore, the  lowest voltage of CADEC will increase rapidly with the  increasing of bit error rate. Except for self-corrected green  coding, DAP and DSAP, the critical delay of codec depends  on the decoder, and consequently it’s not appropriate for  integrating into switch fabrics. Therefore, the physical  transfer unit sizes are bigger than proposed coding scheme  and thus increases network area and energy consumption.  The proposed self-corrected green coding scheme has the  smallest overhead of codec.  Table 1. Summaries of different Joint Coding Codec  Coding  Scheme  Uncoded  Hamming[4] FTC-HC[4] FOC-HC[4] OLC-HC[5] BSC[4,6]  DAP[5]  DSAP[5]  CADEC[7] S-C Green  Area (μm2) 0  102  190  161  394  274  54  57  130  122  Encoder  Average  Power  0  46.01  84.63  83.30  222.04  115.33  21.24  21.24  64.21  47.29  Delay  (ns)  0  0.43  0.38  0.38  0.65  1.16  0.42  0.42  0.56  0.29  Area  (μm2)  0  318  392  371  808  339  136  136  481  226  Decoder  Average  Power  0  198.72  240.00  237.31  194.51  150.90  67.10  67.19  328.03  137.96  Delay (ns)  0  1.37 2.67 1.59 1.65 1.83 0.92 1.12 2.93 0.69 Table 2. Summaries of different Joint Coding Schemes (λ= 4)  Coding  Scheme  Uncoded Hamming FTC-HC FOC-HC OLC-HC BSC  DAP  DSAP  CADEC S-C Green Energy  saving  (1.2v)  0  -51.08% -22.01% -33.17% +2.12%  +12.78% +11.92% +13.86% -24.05% +34.34% ( 10ε − ≅ )20 Lowest  supply  voltage  1.2 v  0.845 v  0.845 v  0.845 v  0.845 v  0.850 v  0.850 v  0.850 v  0.695 v  0.836 v  Energy  saving  (Lower  Voltage)  0  +26.38%  +40.07%  +34.82%  +51.46%  +55.95%  +55.54%  +56.46%  +58.84%  +67.29%  Physical  transfer  unit size  (wire)  8  12  21  16  34  17  17  25  25  30  Physical  transfer  unit size  (Router) 8  12  21  16  34  17  8  17  25  10  VI. CONCLUSIONS  Some physical effects in nano-scale, unfortunately, will  degrade the performance of NoC. In order to obtain low  latency, reliable and low power on-chip communication,  power consumption becomes the biggest challenge in today’s  multi-core SoC design with nano-scale effects. In this paper,  a joint bus and error correction coding, self-corrected green  coding scheme, is presented to construct reliable and green  interconnection for NoC. Self-corrected green coding  scheme  is divided  into  two stages,  triplication error  correction coding (ECC) stage and green bus coding stage.  Triplication ECC not only provides a more reliable  mechanism but possesses rapid correction ability to reduce  the physical transfer unit size of switch fabrics by selfcorrected in bit level. The green bus coding employs more  energy reduction by a joint triplication bus power model to  avoid crosstalk effect. It avoids forbidden overlap condition  (FOC) and forbidden pattern condition (FPC) and reduces  forbidden transition condition (FTC) to achieve more power  saving. In addition, the circuitry of green bus coding is more  simple and effective. The simulation results show selfcorrected green coding can achieve 34.4% energy saving in  UMC 90um CMOS technology.   ACKNOWLEDGEMENTS  This research is supported by National Science Council,  R.O.C., under project NSC 96-2220-E-009-026, NSC 962220-E-009-027.  This work also supported by Ministry of  8282         Economic Affairs, R.O.C., under the project MOEA 96-EC17-A-01-S1-034.  The authors would like to thank ITRI, and  TSMC for their support.  "
Circuit-Switched Coherence.,"Our characterization of a suite of commercial and scientific workloads on a 16-core cache-coherent chip multiprocessor (CMP) shows that overall system performance is sensitive to on-chip communication latency, and can degrade by 20% or more due to long interconnect latencies. On the other hand, communication bandwidth demand is low. These results prompt us to explore circuit-switched networks. Circuit-switched networks can significantly lower the communication latency between processor cores, when compared to packet-switched networks, since once circuits are set up, communication latency approaches pure interconnect delay. However, if circuits are not frequently reused, the long setup time can hurt overall performance, as is demonstrated by the poor performance of traditional circuit-switched networks - all applications saw a slowdown rather than a speedup with a traditional circuit-switched network. To combat this problem, we propose hybrid circuit switching (HCS), a network design which removes the circuit setup time overhead by intermingling packet-switched flits with circuit-switched flits. Additionally, we co-design a prediction-based coherence protocol that leverages the existence of circuits to optimize pair-wise sharing between cores. The protocol allows pair-wise sharers to communicate directly with each other via circuits and drives up circuit reuse. Circuit-switched coherence provides up to 23% savings in network latency which leads to an overall system performance improvement of up to 15%. In short, we show HCS delivering the latency benefits of circuit switching, while sustaining the throughput benefits of packet switching, in a design realizable with low area and power overhead.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Circuit-Switched Coherence ‡Natalie Enright Jerger, ?Li-Shiuan Peh, and ‡Mikko Lipasti ‡Electrical and Computer Engineering Department, University of Wisconsin-Madison ?Department of Electrical Engineering, Princeton University Abstract— Our characterization of a suite of commercial and scientiﬁc workloads on a 16-core cache-coherent chip multiprocessor (CMP) shows that overall system performance is sensitive to on-chip communication latency, and can degrade by 20% or more due to long interconnect latencies. On the other hand, communication bandwidth demand is low. These results prompt us to explore circuitswitched networks. Circuit-switched networks can signiﬁcantly lower the communication latency between processor cores, when compared to packet-switched networks, since once circuits are set up, communication latency approaches pure interconnect delay. However, if circuits are not frequently reused, the long setup time can hurt overall performance, as is demonstrated by the poor performance of traditional circuit-switched networks – all applications saw a slowdown rather than a speedup with a traditional circuitswitched network. To combat this problem, we propose hybrid circuit switching (HCS), a network design which removes the circuit setup time overhead by intermingling packet-switched ﬂits with circuit-switched ﬂits. Additionally, we co-design a prediction-based coherence protocol that leverages the existence of circuits to optimize pair-wise sharing between cores. The protocol allows pair-wise sharers to communicate directly with each other via circuits and drives up circuit reuse. Circuit-switched coherence provides up to 23% savings in network latency which leads to an overall system performance improvement of up to 15%. In short, we show HCS delivering the latency beneﬁts of circuit switching, while sustaining the throughput beneﬁts of packet switching, in a design realizable with low area and power overhead. I. Introduction As per-chip device counts continue to increase, many-core chip multiprocessors are becoming a reality. Shared buses and simple rings do not provide the scalability needed to meet the communication demands of these future manycore architectures, while full crossbars are impractical. To date, designers have assumed packet-switched on-chip networks as the communication fabric for many-core chips [11, 23]. While packet switching provides eﬃcient use of link bandwidth by interleaving packets on a single link, it adds higher router latency overhead. Alternatively, circuitswitching trades oﬀ poorer link utilization with much lower latency, as data need not go through routing and arbitration once circuits are set up. For the suite of commercial and scientiﬁc workloads evaluated, the network latency of a 4x4 multi-core design can have a high impact on performance (Figure 1) while the bandwidth demands placed on the network are relatively low (Workload details can be found in Table V). Figure 1 illustrates the change in overall system performance as the per-hop delay1 is increased from 1 to 11 processor cycles. When a new packet is placed on a link, the number of concurrent packets traversing that link is measured (including the new packet)2 . The average is very close to 1, illustratThis research was supported in part by the National Science Foundation under grants CCR-0133437, CCF-0429854, CCF-0702272, CNS-0509402, the MARCO Gigascale Systems Research Center, an IBM PhD Fellowship, as well as grants and equipment donations from IBM and Intel. 1This comprises router pipeline delay and contention. 2This measurement corresponds to a frequently-used metric for evaluating topologies, channel load [6]. Fig. 1. Eﬀect of interconnect Latency ing very low link contention given our simulation conﬁguration (See Table IV). Wide on-chip network channels are signiﬁcantly underutilized for these workloads while overall system performance is sensitive to interconnect latency. An uncontended 5-cycle per-hop router delay in a packetswitched network can lead to 10% degradation in overall system performance. As the per-hop delay increases, either due to deeper router pipelines or network contention, overall system performance can degrade by 20% or more. Looking forward, as applications exhibit more ﬁne grained parallelism and more true sharing, this sensitivity to interconnect latency will become even more pronounced. This latency sensitivity coupled with low link utilization motivates our exploration of circuit-switched fabrics for CMPs. Our investigations show that traditional circuit-switched networks do not perform well, as circuits are not reused suﬃciently to amortize circuit setup delay. As seen in Figure 2, every application saw a slowdown when using traditional circuit-switched networks versus an optimized packet-switched interconnect for a 16 in-order core CMP (for machine conﬁguration details see Table IV). Fig. 2. Performance of Traditional Circuit Switching This observation motivates a network with a hybrid router design that supports both circuit and packet switching with very fast circuit reconﬁguration (setup/teardown). Our results show our hybrid circuit-switched network with up to 23% reduction in network latency over an aggressive packet-switched fabric, leading to up to 7% improvement in overall system performance due solely to interconnect 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.22 DOI 10.1109/NOCS.2008.22 193 193 design. In Section IV, we will demonstrate that while our initial exploration of circuit-switching has been predicated on the low network loads in our applications, our ﬁnal design works well for high traﬃc loads as well, demonstrating the eﬀectiveness of our design where packet-switched ﬂits can steal bandwidth when circuits are unused. As systems become more tightly coupled in multi-core architectures, co-design of system components becomes increasingly important. In particular, coupling the design of the on-chip network with the design of the coherence protocol can result in a symbiotic relationship providing superior performance. Our workloads exhibit frequent pair-wise sharing between cores. Prior work has also shown that processor sharing exhibits temporal locality and is often limited to a small subset of processors (e.g. [3, 7]). Designing a router architecture to take advantage of such sharing patterns can out-perform even a highly optimized packetswitched router. Figure 3 illustrates the percentage of on-chip misses that can be satisﬁed by cores that recently shared data with the requester. The numbers on the x-axis indicate the number of sharers maintained in a most recently shared list and the corresponding percentage of on-chip misses that can be captured. For example, with the commercial workloads, the two most recent sharers have a cumulative 65% chance of sourcing data for the next miss. Such application behavior inspires a prediction-based coherence protocol that further drives up the reuse of circuits in our hybrid network and improves overall performance. The protocol predicts the likely sharer for each memory request so the requester can go straight to the sharer for data, via a fast-path circuit, rather than experiencing an indirection to the home directory node. Our simulations show this improves overall system performance by up to 15%. Fig. 3. On-chip misses satisﬁed by recent sharer(s) The key contributions of this work are • Characterizing real-world scientiﬁc and commercial workloads on a CMP and showing that on-chip network latency in our conﬁguration is more critical to overall system performance than network bandwidth. • Proposing a novel router architecture that removes circuit setup delay by interleaving circuit-switched and packetswitched ﬂits on the same physical channels (Section II). • Co-designing the coherence protocol with the network to further take advantage of low latency circuit-switched paths (Section III). II. Hybrid Circuit-Switched Network The key design goal of our hybrid circuit-switched network is to avoid the circuit setup delay of traditional circuitswitching. As shown in Figure 4, our design consists of two separate mesh networks: the main data network and a tiny setup network. The main data network supports two types of traﬃc: circuit-switched (CS) and packet-switched (PS). In the data network, there are C separate physical channels, one for each circuit. To allow for a fair comparison, each of these C channels have 1/C the bandwidth of the baseline packetswitched network in our evaluations. A baseline packetswitched network has a channel width of D data bits along with a logV virtual channel ID. Flits on the data network of our hybrid circuit-switched network are D/C wide, plus the virtual channel ID for the packet-switched ﬂits (logV ) and an additional bit to designate ﬂit type (circuit- or packetswitched). A single setup network is shared by all C circuits. We compare our design against a baseline packetswitched router shown in Figure 5a and b. Under low loads, the router pipeline is a single cycle (Figure 5a), achieved through aggressive speculation and bypassing. If the input queue is empty and no other virtual channels are requesting the same output channel, the incoming ﬂit can bypass the ﬁrst two stages and proceed directly to switch traversal. This optimization eﬀectively reduces the pipeline latency to a single stage but only for very low loads (for additional detail see [16]). With the presence of contention due to higher loads, the packet-switched baseline degrades to a three cycle pipeline (Figure 5b). To lower delay, we assume lookahead routing, thus removing the routing computation from the critical path; lookahead routing occurs in the ﬁrst stage with the buﬀer write (BW). In the second stage, speculative virtual channel and switch allocation is performed; if speculation fails, virtual channel or switch allocation will be performed again in the next cycle. This single-cycle pipeline is based on an Intel design of a 4-stage pipeline [17], which found it not possible to ﬁt the BW into the VA/SA stage and still maintain an aggressive clock of 16FO4s. Each input contains 4 virtual channels with 4 packet buﬀers each. A. Setup Network Similar to a traditional circuit-switched network, the setup network handles the construction and reconﬁguration of circuits and stores the switch conﬁguration for active circuits. However, a packet in our hybrid network does not wait for an acknowledgment that a circuit has been successfully constructed; therefore, data can be piggy-backed immediately behind the circuit setup request. At the injection port, one of the C circuit planes is chosen for the circuit under construction; if there are no unused circuit planes, the LRU circuit will be reconﬁgured as packet-switched whilst the new circuit request will take over the old circuit. Incoming circuit-switched (CS) ﬂits intended for the old (reconﬁgured) circuit will henceforth be tagged as packet-switched ﬂits and will remain packet-switched until their destination. A control ﬂit on the setup network will signal the source of the old circuit, that it must either stop sending CS ﬂits or must re-establish the circuit to prevent buﬀer overﬂow caused by too many CS ﬂits arriving at a reconﬁgured node. 194194 B. Circuit-switched pipeline on data network The circuit-switched pipeline in our network is depicted in Figure 5c. To allow circuit- and packet-switched ﬂits to intermingle throughout the network, we add an extra bit ﬁeld to each ﬂit indicating if this ﬂit is a circuit- or packetswitched ﬂit. When a ﬂit enters the router pipeline, the circuit ﬁeld is checked (CFC). If the ﬁeld is non-zero, this is a CS ﬂit and will proceed through the pipeline in Figure 5c, bypassing directly to ST, which was already conﬁgured to the appropriate output port when this circuit was originally established. When enabled, the tagging (T) stage ﬂips the circuit bit for incoming data so that ﬂits originally intended for a circuit will now go into the packet buﬀers. The tagging stage is enabled only when a reconﬁguration is needed at that router; this way, in future hops, since the tagging stage is not enabled, the original CS ﬂits will stay packet-switched until they arrive at the destination. This circuit-switched pipeline is nearly identical to the highly optimized single-cycle packet-switched router in Figure 5a. Note, however, that circuit-switching is able to achieve better performance than a single-cycle packetswitched router under certain sharing characteristics: in the packet-switched baseline, multiple incoming ﬂits prevent bypassing; with circuit-switching, these ﬂits can occupy diﬀerent circuit planes and proceed simultaneously through the router in a single cycle. The router architecture with 2 circuit planes is depicted in Figure 4. If the circuit ﬁeld is set to circuit-switched and the reconﬁguration signal has not been asserted from the setup network, than the ﬂit will take the direct path to the crossbar. If the circuit ﬁeld is set to packet-switched or the circuit has been reconﬁgured, the ﬂit will take the packetswitched path and will be written into a buﬀer. Pseudocode for the operation of the hybrid router design can be found in Table I. C. Packet-switched pipeline on data network If the circuit ﬁeld is zero, this is a packet-switched ﬂit and will be buﬀered, proceeding through the packet-switched pipeline shown in Figure 5d. The allocator of the packetswitched pipeline is designed to enable packet-switched ﬂits to steal bandwidth from CS ﬂits. The packet-switched ﬂit will perform speculative Virtual Channel Allocation and Switch Allocation each subsequent cycle until it is able to steal bandwidth through the switch. It receives a signal from the input ports indicating the presence or absence of incoming ﬂits for the physical circuit C that the packetswitched ﬂit has been assigned to and is being stolen. If there are no incoming ﬂits for that circuit, the packetswitched ﬂit arbitrates for the switch. Once a packetswitched ﬂit wins passage through the crossbar, it then traverses the output port and goes to the next hop. The circuit ﬁeld remains set to zero, so that this ﬂit will continue to be interpreted as a packet-switched ﬂit and buﬀered appropriately at the next hop. If a CS ﬂit enters the router while the packet-switched ﬂit is traversing the switch, the CS request will have to be latched until it can proceed along its circuit at the next cycle. Only a latch is needed on the circuit-switched path as a CS ﬂit can be stalled at most one cycle by a packet-switched ﬂit traversing the crossbar. To prevent the unlikely scenario where PS ﬂits are starved, a timeout is used to trigger the reconﬁguration of the starved Fig. 4. Proposed router micro-architecture Fig. 5. Router Pipeline [BW: Buﬀer Write, VA: Virtual Channel Allocation, SA: Switch Allocation, ST: Switch Traversal, LT: Link Traversal, CFC: Circuit Field Check, T: Tagging] The routers in the setup network have three pipeline stages, similar to that of our baseline packet-switched router, except that there is no speculation or virtual channel allocation (VA). Virtual channels are unnecessary since traﬃc on the setup network is low and wormhole is suﬃcient with lower overhead. When a setup ﬂit arrives, consisting of the destination ﬁeld (log N, where N is the number of nodes) and the circuit number (log C, where C is the number of physical circuits), it will ﬁrst be written to an input buﬀer (BW). Next, it will go through switch arbitration (SA), with each port having a C:1 allocator. This is followed by a circuit reservation on the data network which sets up the data network switch at that hop to route incoming CS ﬂits correctly; successful switch arbitration determines the ordering of two setup requests for the same circuit resources. The setup ﬂit then traverses the crossbar (ST) and the link (LT) towards the next router in the setup network. In the current design, this network is only six bits wide. The physical circuit plane is selected at the injection router based on LRU information and the circuit number (log C bits) is stored there for future CS ﬂits injected at that router. A circuit must remain in the same physical circuit plane from source to destination so a log C identiﬁer is suﬃcient. 195195 TABLE I Pseudo-code for Hybrid Router Design Buﬀer Write Stage if Virtual Channels are not empty then PS ﬂits are waiting to steal link Proceed to Speculative Virtual Channel & Switch Allocation Stage if Input port not idle then Incoming ﬂit if ﬂit type == Packet-Switched then Write ﬂit to input VC else if ﬂit type == Circuit-Switched then if Reconﬁgured Signal Asserted then Write to Input VC Flip Circuit ﬁeld to zero (this ﬂit is now a Packet-Switched Flit) else Proceed directory to switch traversal VA/SA Stage if Input Virtual Channels are not empty then Perform Speculative Virtual Channel Allocation And Switch Allocation Switch Traversal Stage if Input Idle then if Waiting PS ﬂit with successful VA/SA then Conﬁgure Switch for Stealing Traverse Switch Restore Circuit Conﬁguration to Switch plane from circuit-switched to packet-switched so starved PS ﬂits can make progress. D. Discussion D.1 Circuit Thrashing If two diﬀerent source/destination pairs try to establish a circuit at the same time sharing a common link, these requests will be serialized in the setup network. Eﬀectively, the ﬁrst request through the setup router will only hold the circuit for a single cycle making reuse impossible. The following cycle, the second request will reconﬁgure the link and hold that circuit until a subsequent request wishes to claim the link. In the event that these two source/destination pairs continue thrashing by trying to establish a circuit over the same link, their latency will degrade to the baseline packet-switched latency. Circuit thrashing is less likely with more available circuit planes. D.2 Circuit Fragments due to Reconﬁguration Our reconﬁguration mechanism only reclaims the contentious links for a new circuit. The remaining fragments of the old circuit are left intact, thus leaving partial circuits in the network. In the scenario where a link in a circuit has been reconﬁgured at a hop other the ﬁrst hop, the source of that circuit is unaware of the reconﬁguration and will keep sending circuit-switched ﬂits on the circuit fragment. These circuit-switched ﬂits will be converted to packet-switched ﬂits at the reconﬁguration site; this can potentially cause a buﬀer back-pressure situation back to the source node if there is not enough bandwidth available for the packet-switched ﬂits to steal and continue on to their destination. As such, upon reconﬁguration, we send a notiﬁcation ﬂit on the setup network back to the source of the circuit. The source of the circuit can then choose to re-establish the circuit or send packet-switched ﬂits. If the policy is to always establish a circuit, the source will re-establish its circuit; however, if the policy is to only establish circuits for a limited class of messages, the source will send packet-switched ﬂits until an appropriate message triggers a setup. The trade-oﬀs between these two policies will be explored in Section IV-B. D.3 Scalability Given the same traﬃc load on a larger network, there can potentially be higher circuit contention requiring more circuits. Additional circuits will lead to higher serialization delay. In large systems, circuit switching has the potential for greater latency savings. As the hop count increases from source to destination, the number of cycles saved will also increase. To scale our proposed hybrid circuit-switched network to very large networks, we suggest moving to a more scalable topology. Enriched connectivity will not only lower circuit contention and thrashing, but can potentially reduce global cross-chip latency to just pure wire delay, as circuits can be formed with mostly express links. Future many-core workloads such as server consolidation are unlikely to require global communication [9]. This limited sharing will reduce the need for large numbers of circuits and allow our design to scale further. Unfortunately, our full system simulation infrastructure is currently limited to 16 cores, so we cannot explore this aspect quantitatively. E. Power and Area Overhead Power and area are a ﬁrst order design constraint when dealing with on-chip networks. Using Orion and a 70nm technology [25], a setup network router (including conﬁguration memory) consumes less than 2% of the overall router power. An activity factor of 1 was used to provide a worst case analysis. The conﬁguration memory in the setup network consists of 25 bits for each of the C circuits. For each input port, 5 bits drive the select signal of the crossbar to activate the correct output port. On the data network, components of our router that increase power consumption and area are C D/C -wide multiplexers that select from either the circuit or the buﬀers, and tagging hardware to reset the circuit bit in each ﬂit.To reduce the area and power consumed by the C D/C multiplexers, we add an additional input to the 4:1 multiplexers in the baseline router that select between the VCs. Replacing 4:1 multiplexers with 5:1 multiplexers increases the power consumption of the router less than 1%. Power can potentially be lowered further by reducing the buﬀers and VCs in the hybrid router; however we chose to stick with the same conﬁguration as the packet-switched baseline for a consistent comparison. The C D/C -wide crossbars in the hybrid router will occupy less area than the D-wide crossbar of the PS router since the area grows quadratically with the width of the crossbar ports (each crossbar has the same number of ports as the baseline, i.e. 5). The setup network also consumes additional area due to the addition of buﬀers, switch allocator, and wiring. However, as the setup network is very narrow, we do not expect signiﬁcant area overhead. In the data network, the buﬀers are distributed evenly among the multiple circuit planes with the same total buﬀer capacity the packet-switched baseline. Since the crossbar ports are 1/2 and 1/4 as wide for 2 and 4 circuit planes respectively, the area of each crossbar is reduced quadrati196196 cally, giving our design extra area for the switch conﬁguration memory. The setup network, including conﬁguration memory and 4 buﬀers per input port consumes only 0.2% of the baseline packet-switched router area. In short, we do not impose any additional overhead over the baseline packet-switched router and less than 3% increase in router power. III. Coherence Protocol We couple our hybrid network with a directory coherence protocol based on the Origin 2000 [18], but augmented with a distributed directory cache that is stored along-side the shared last level (L3) cache bank at each node. While directory-based protocols are more scalable than broadcast-based ones, a key performance disadvantage of directory protocols is the indirection through the directory that is required to request data from another processor. Our protocol extensions streamline this process for load and instruction misses by predicting pairs of processors that frequently share data, and directly requesting data from one cache to another, via a circuit-switched link, without ﬁrst consulting the directory. Sequential consistency is maintained by ordering all coherence events at the directory, but latency is improved by overlapping the circuit-switched data transfer with the directory access. Other proposals that look at using prediction to accelerate the coherence protocol are discussed in Section V. A. Protocol modiﬁcations To allow directory indirections to be streamlined, we modiﬁed the directory protocol as follows: • Allow a cache to send a request directly to another cache. • Notify the directory that a sharer has been added without having the directory forward the request to the owning cache or initiate a memory request. • Retry the request to the directory if the direct request fails due to an incorrect prediction or a race condition. The directory does not need to be aware of which circuitswitched paths are active as long as it is notiﬁed to add a new sharer to the sharing list for each cache line. The protocol implementation is decoupled from changes to the interconnection network. The above modiﬁcations coupled with the fast circuit-switched paths for sharers create new race conditions which have been identiﬁed and dealt with in our simulation infrastructure (see Section III-C). B. Sharing Prediction Circuit-switched paths are set up on demand via a prediction mechanism that predicts the frequency of sharing between two processors. We implement an address-regionbased prediction mechanism. Each processor stores information about sharers of an address region alongside its last level cache. When data is sourced from another processor, the predictor stores the identity of the sourcing processor for the address region of the data. The next time a cache access misses to an address in that region, we predict that same processor will again source the data. Our region prediction structure is similar to the regions used to determine the necessity of broadcasts in [5], but is easier to maintain since it is not required to be correct. At the time of the prediction, if no circuit-switched path exists between the requesting and sourcing processors, one is established. If the predicted core cannot provide the cache line requested, it responds to the requesting processor to indicate an incorrect prediction. The requesting core must then retry to the directory. The latency of a mispredicted request is thus the round trip latency from cache to cache on the interconnect plus the indirection latency of the conventional directory request. The prediction array is then updated with the core that actually sourced the data. An example of the protocol and prediction mechanism is given in Table II. TABLE II Prediction and Protocol Walk-through Example 1. Processor 1 misses to Address A First miss to A → No Prediction Available 2. Send Request to Directory 3. Directory forwards request to Processor 4 4. Processor 4 responds with data 5. Processor 1 receives data and stores Pred(Region A) = 4 6. Processor 1 misses to A+8 → Predicts Processor 4 Send request to Processor 4 Notify Directory 7. Processor 4 receives request Prediction is correct → responds with data 8. Directory adds Processor 1 to sharing list 9. Proc. 1 receives data from Proc. 4 and ACK from directory In the example in Table II, if Processor 1’s prediction is incorrect, the directory will have already added Processor 1 to the sharing list due to the decoupling of the data request from the ordering request. The directory protocol supports silent evictions of shared lines, so having Processor 1 added as a sharer will not result in any incorrect coherence actions; the sharing list must include all processors caching that block but can contain additional processors at the expense of more invalidation messages should an upgrade occur. Processor 1 will retry its request to the directory once Processor 4 has acknowledged its incorrect prediction. C. Veriﬁcation of Consistency C.1 Protocol Invariants Validation of correctness is an important yet diﬃcult issue when developing or modifying a coherence protocol. To simplify veriﬁcation, we built our modiﬁcations on top of an existing protocol [18]. In both the baseline and the modiﬁed protocol, the directory serves at the sole ordering point for requests. Our modiﬁcations decouple the data request message from the ordering message. The data response may be received prior to an acknowledgment from the directory that the request has been properly ordered, but the requesting processor cannot consume the data without that acknowledgment. To illuminate the protocol changes, as well as demonstrate that ordering properties have been preserved, we include pseudo-code for a read request in both the baseline and modiﬁed protocols in Table III. C.2 Simulation Veriﬁcation In addition to preserving the directory as the sole ordering point for all coherence requests, we verify that sequential consistency is maintained through our simulation environment. Our simulation infrastructure includes tools to verify sequential consistency and execution correctness. This tool executes two side-by-side execution-driven fullsystem simulations: the ﬁrst simulation is the application executing on a modiﬁed version of our integrated functional and timing simulator, which produces a memory reference 197197 TABLE III Pseudo-code Comparison of Baseline Protocol to Prediction Protocol Baseline Protocol - Read Request (RdReq) 1. RdReq goes across network to home directory cache Directory Actions 2. Directory cache performs look up if Directory state is Unowned then initiate memory request When memory request completes send data to requester if Directory state is Exclusive then Transition to Busy Send intervention to owner Add requester to sharing list Transition to Shared when cache response is received if Directory state is Shared then Forward request to owner Add sharer to sharing list if Directory state is Busy then Send NACK to requester Cache Response to Directory request 3. Owning cache receives intervention Send data to requester & transition to Owned Send ACK to directory Requesting Node 4. Receives Data from either Directory or Owning Cache Transitions to Shared & forward data to L1 RdReq Complete Prediction Protocol - Read Request (RdReq) 1a. RdReq goes across network to predicted sharer 1b. Directory update goes across network to home node Decoupled Directory Actions (cont. from 1b) 2. Directory cache performs lookup if Directory state is Unowned then Prediction is incorrect → initiate memory request When memory request completes send data to requester if Directory state is Exclusive then if Prediction is correct then Transition to Busy (wait for ack from predicted node) Send ACK to requester else Prediction is incorrect Transition to Busy & send intervention to owner Transition to Shared when cache response received Add requester to sharing list if Directory state is Shared then if Prediction is correct then Add sharer to sharing list & send ACK to requester if Prediction is incorrect then Forward request to owner & send NACK to requester if Directory state is Busy then Send NACK to requester Decoupled Cache Actions (cont. from 1a) 3. Owning cache receive predicted request if Prediction is correct then Send Data to Requester if Block is Exclusive or Modiﬁed then Send Ack to directory else if Prediction is incorrect then Send NACK to Requester Requesting Node 4. if Data received from Predicted Cache then if Directory NACK received then Discard data (stall copy) & wait for valid response else if Directory ACK received then Forward Data to L1 & RdReq Complete else if NACK received from Predicted Cache then Re-initiate RdReq without prediction stream that is used to drive the second simulation which uses an unmodiﬁed, known-to-be-correct simple functional simulator. This memory reference stream contains monotonically increasing memory version numbers that are used by the second simulator to reconstruct a sequentially consistent order. If no sequentially consistent order can be found then we know that our protocol modiﬁcations have violated our consistency model and an error is ﬂagged. Finally, all updates to architected state performed by both simulators are compared instruction by instruction, and any discrepancies ﬂag errors and aid in debugging the protocol. We have simulated billions and billions of instructions on top of this checking infrastructure without incurring errors. This simulation time coupled with the preservation of ordering through the directory, leads us to safely conclude that our protocol modiﬁcations and our hybrid circuit-switched interconnect are substantially correct. IV. Simulation Results TABLE IV Simulation Parameters Cores Memory System L1 I/D Caches (lat) Private L2 Caches Shared L3 Cache Memory Latency Interconnect Link Width Link Latency Optimized PS Router Baseline Setup Network 16 in-order 32 KB 2 way set assoc. (1 cycle) 512 KB (8 MB total 4 way set assoc. (6 cycles), 64 Byte lines 16 MB (1MB bank at each tile) 4 way set associate (12 cycles) 100 cycles Packet Switching 64 Bytes Circuit Switching 64B/C (C=2,4) 1 cycle 1-3 stages, 4 Virtual Channels w/ 4 Buﬀers each Wormhole with 4 Buﬀers A. Evaluation of Hybrid Circuit-Switched Network We use a full system multiprocessor simulator [4] built on SIMOS-PPC conﬁgured with 16 in-order cores on a 4x4 mesh CMP. Included in our simulation infrastructure is a cycle-accurate network model including pipelined routers, buﬀers, virtual channels and allocators. Hybrid CircuitSwitched modiﬁcations such as circuit stealing are also faithfully modeled. Our simulation parameters are given in Table IV. Results are presented for the following commercial workloads: TPC-H and TPC-W [24], SPECweb99 and SPECjbb2000 [22] and several Splash2 workloads [28]. Details for each workload are presented in Table V. We use statistical simulation as described by [2]. One of the primary goals of this work is to reduce the interconnect latency by removing the router overhead. Our hybrid circuit-switched network can reduce interconnect latency by as much as 23% as shown in Figure 6. We measure the average interconnect latency for 2 and 4 circuit planes as compared to an optimized baseline packet-switched interconnect. Average packet delay is calculated as the time between the injection of the head ﬂit and when the critical word arrives at the destination. As the total link bandwidth is kept constant at 64 bytes, the 2 and 4 circuit planes will have 32 and 16 bytes respectively per plane; packets will consist of 2 and 4 ﬂits respectively. The four circuit plane 198198 TABLE V Benchmark Descriptions take further advantage of circuit-switched links and reduce unnecessary reconﬁgurations can further reduce interconnect latency. Bench. SPECjbb SPECweb TPC-W TPC-H Barnes Ocean Radiosity Raytrace Description Standard java server workload utilizing 24 warehouses, executing 200 requests Zeus Web Server 3.3.7 servicing 300 HTTP req. TPC’s Web e-commerce benchmark, DB Tier Browsing mix, 40 web transactions TPC’s DSS Benchmark, IBM DB2 v6.1 running query 12 w/ 512MB DB, 1GB Mem 8K particles, full end-to-end run i.e. init 514x514 full end-to-end run (parallel phase only) -room -batch -ae 5000 -en .050 -bf .10 (parallel only) car input (parallel phase only) conﬁguration gives us additional beneﬁt as circuits can be maintained longer between reconﬁgurations and see more reuse, thus reaping more beneﬁt. To combat the increased serialization delay that moving to 4 circuits would cause, we send the critical word ﬁrst through the network. In addition to comparing HCS against PS, we also present results for Narrow Packet Switching (NPS); in NPS we partition a PS network into 4 narrower networks (similar to the 4 narrow circuit planes in HCS). Each narrow network in NPS has 2 virtual channels with 2 buﬀers per VC. When a packet is injected into the network, it selects an NPS network in a round robin fashion and continues on the same NPS network until reaching its destination. NPS provides modest improvements over PS but underperforms when compared to HCS. Fig. 6. Reduction in Interconnect Latency due to HCS Circuit-switched connections are designed to enable fast connections between frequently sharing cores; however, we do not want to sacriﬁce the performance of messages that do not involve frequent sharing. Our design is able to circuitswitch 18 to 44% of all ﬂits with an average latency of 4.3 cycles. The remaining 56 to 82% of ﬂits that are packetswitched or partially circuit-switched through the network still achieve a reasonable average interconnect latency of 7.9 cycles. Figure 7 gives the contribution of circuit-switched ﬂits and non-circuit-switched ﬂits to overall average network latency. Non-circuit-switched ﬂits encompasses both packet-switched ﬂits and reconﬁgured circuit-switched ﬂits. The x-axis shows the percentage of overall network messages that are either circuit-switched or not. With 4 circuits, we see a larger contribution of purely circuit-switched ﬂits; this is expected as reconﬁgurations are less frequent. This larger contribution of circuit-switched ﬂits causes the overall average network latency to be lower. Policies that 199199 Fig. 7. Latency Breakdown of Circuit-Switched Flits and PacketSwitched/Partial Circuit-Switched Flits Figure 8 shows the overall system performance for hybrid circuit-switching with 2 and 4 circuit planes and narrow packet-switching with 4 narrow networks, all normalized to the baseline PS network. Moving from 2 circuits to 4 circuits shows an average of 3% reduction in execution time (up to 7%) for commercial workloads. Frequent reconﬁguration prevents TPC-H from seeing any beneﬁt from 2 circuits. When characterizing the sharing patterns in TPC-H, 4 recent sharers are needed to satisfy 64% of on-chip misses in contrast to only 2 for the other commercial workloads (Figure 3). Ocean does not beneﬁt from circuits since most misses go oﬀ-chip causing the miss latency to be dominated by the memory access time. The other scientiﬁc workloads see little beneﬁt from hybrid circuit-switching due to low overall miss rates and low numbers of coherence misses. Increasing the number of circuits further would likely yield little beneﬁt due to the increase in ﬂits/packet. For most workloads, little improvement is gained from the NPS conﬁguration; NPS does not provide the added performance improvement for pair-wise sharing that HCS targets. Fig. 8. Overall Performance of HCS Utilization of the setup network is particularly low when circuit construction is limited to a subset of messages. The data in Figure 10 is measured as the average number of ﬂits waiting at a router when a new ﬂit arrives (including the new ﬂit). The always setup policy drives up the load on the setup network but it is still at an acceptable level for wormhole switching. The average delay through the setup network is 10.5 cycles which reﬂects the very low utilization of the setup network. The setup network does not need signiﬁcant buﬀering resources since utilization is low coupled with the small setup ﬂit size (6-8 bits). B. Circuit Setup Policies Two diﬀerent policies regarding the setup of new circuits are explored. In the ﬁrst policy, the decision to allow a new message to construct a circuit-switched path (if one is not already present) is made based on the nature of the message. Invalidation requests from the directory are not indicative of a pairwise sharing relationship and therefore are injected as packet-switched ﬂits. Read requests and data transfers will setup a circuit if one is not present. All types of requests can reuse an existing circuit between given source-destination pairs. This policy is contrasted with a policy that allows all types of messages to construct a new circuit in Figure 9 for 2 circuits. Limiting the construction of new circuits to certain message classes causes a loss in opportunity as noted by a average increase in network latency of 3% with a maximum increase of 7%. Up to 10% more ﬂits take advantage of circuit-switched paths when new circuits are always constructed. The limited setup policy does drive up reuse by 30%. Additional policies to simultaneously drive up reuse while maximizing utilization of circuits may further lower interconnect latency. Fig. 9. Impact on Network Latency of Restricting Circuit Setup to Certain Classes of Messages Limiting the setup of circuits increases the percentage of packet-switched ﬂits and reduces the average time interval between instances of link stealing at each input port. Scientiﬁc workloads see longer intervals between link stealing than commercial workloads due to the lower communication demands in the former. C. Packet-Switched Flit Starvation As described in Section II, to prevent the unlikely scenario of packet-switched ﬂit starvation, a timeout mechanism reconﬁgures the circuit starving the packet-switched ﬂits to allow packet-switched ﬂits to make forward progress. To characterize the potential for starvation, we measure the waiting time of packet-switched ﬂits (with the timeout mechanism disabled). The percentage of all PS ﬂits that must wait at least 1 cycle to steal bandwidth from a circuit, in all cases is less than 1%. Average wait time for this small number of ﬂits is less than 7 cycles across all workloads. The average wait time increases slightly when the number of circuit planes is increased from 2 to 4; this is explained by higher circuit utilization. D. Setup Network Evaluation In Section II we assert that a wormhole network is suﬃcient for the setup network. Figure 10 supports this claim. Fig. 10. Channel Load of Setup Network E. Interactions between Network and Coherence Protocol Overall system performance when HCS is combined with the protocol optimization is shown in Figure 11. Since the protocol optimizations are largely independent from the interconnect design, we compare against the baseline packetswitched network plus protocol optimizations with results normalized to the packet-switched baseline. The HCS results are given for 4 circuit planes and the always setup policy. We see up to 15% improvement in overall system performance with an average improvement of 12% for commercial workloads and 4% for scientiﬁc workloads. The commercial workloads see greater beneﬁt due to their larger miss rates and greater sensitivity to miss latency. TPC-H derives most of its beneﬁt as a result of 82% of misses being satisﬁed on-chip coupled with a very low contribution of store misses to the overall miss rate. As our protocol optimization only targets load and instruction misses, TPCH will see more beneﬁt than those benchmarks that have a larger contribution of store misses. Ocean performance is dominated by oﬀ-chip misses; the injection of additional traﬃc due to the protocol optimization further delays these misses resulting in a slight performance degradation. Comparing Figures 8 and 11, we see that in many cases, the improvement for HCS with the protocol optimization is greater than the sum of the HCS alone and the protocol optimization with packet switching. Given our co-design of both the coherence protocol and the interconnect, hybrid circuit-switching has more opportunities for reuse when the protocol optimization is added, resulting in superior performance; circuit reuse increased by up to 64% when HCS is combined with protocol optimizations. Protocol optimizations reduce coherence miss latency by 50%; with hybrid circuit switching, those miss latencies are further reduced by 10%. 200200 one other node. Since HCS speciﬁcally targets pair-wise sharing, we would expect this type of traﬃc to beneﬁt from circuit reuse and perform very well. At low to moderate loads HCS improves network latency by 20% over PS, and saturates at higher utilization. NPS performs slightly better than PS at very low utilization. As the load increase, NPS performs considerably better than PS (10-15% lower latency) since the load is distributed across multiple narrow network allowing speculation to be more eﬀective. With round-robin placement of packets on NPS networks, those networks eventually saturate at a similar load to PS. Fig. 13. Performance of HCS with Permutation Traﬃc To reiterate, Figure 12 represents worst-case circuit reuse behavior (we observe much higher reuse for real applications), so we are not surprised that HCS saturates somewhat earlier than the NPS case, and are pleased with its robust latency reductions at low utilization. In contrast, Figure 13 demonstrates the robustness of HCS over both PS and NPS under all traﬃc loads when there is signiﬁcant circuit reuse. V. Related Work Our work proposes a hybrid circuit-switched router that interleaves circuit- and packet-switched ﬂits on the same physical network with low area and power overhead. Network design for CMPs is an area of signiﬁcant research effort. Several other hybrid network designs have been proposed in the literature. Here, we highlight some of the key diﬀerences between those proposals and our work. SoCBus [26] only packet-switches the conﬁguration message but holds the data at the source until setup is acknowledged. All data in their proposal must be circuit-switched through the network. Wolkotte et. al [27] propose a design that has both circuit- and packet-switching; however, it is our understanding that these two networks are physically separate. The packet-switched network is used for reconﬁguration and best-eﬀort traﬃc while the circuit-switched network is used for guaranteed-throughput communications. Wave-switching [8] combines circuit-switching and wavepipelining but in their design, wormhole-routed and circuitswitched data do not interact and have physically separate resources. Pipeline circuit switching [10] requires that a setup and acknowledgment message be sent and received before data can use the circuit. HCS diﬀers from these proposals since it obviates the need for setup and acknowledgment messages to be sent and received prior to the data transfer. Additionally, in HCS, PS and CS ﬂits share the same physical network. Fig. 11. Performance of Protocol Opt. + Hybrid Circuit Switching F. HCS with Synthetic Traﬃc In addition to performing full-system simulation with commercial and scientiﬁc workloads, we further explore the performance of HCS through synthetic traﬃc patterns in Figures 12 and 13. Both ﬁgures show average interconnect latency in cycles across all injected packets. All simulations run for 1 million cycles with increasing injection rates (or channel load) as a percentage of maximum link capacity along the x-axis. With uniform random traﬃc in Figure 12, we reduce latency by 10-15% over packet switching across all loads prior to saturation, despite the fact that there is hardly any reuse of circuits due to the randomized traﬃc. HCS has lower latency at low to moderate loads primarily because circuits are always given priority on their ﬁrst use–i.e. the ﬁrst packets on circuits always zoom through– whereas in packet-switching, bypassing within the router will not be possible if there is more than one ﬂit in the entire router. At very low utilization circuit-switching outperforms our PS baseline since we piggyback data ﬂits long with the setup ﬂits which shaves one cycle oﬀ the serialization latency. Figure 12 also shows network latency results for Narrow Packet Switching (NPS).At moderately low loads, approximately 40% more incoming packets are able to bypass directly to the crossbar with HCS than with NPS or PS. When the load reaches roughly 30%, HCS and PS bypass similar number of packets resulting in similar network saturation points. This attests to the eﬀectiveness of packet-switched ﬂits in HCS stealing idle circuit bandwidth. At moderate loads (20-40%), NPS is able to bypass 5-18% more packets than PS, delivering higher saturation throughput. This matches intuition since NPS trades oﬀ serialization delay with bandwidth. Fig. 12. Performance of HCS with Uniform Random Traﬃc In Figure 13, we simulate the performance of HCS under permutation traﬃc, where each node communicates with 201201 gains over a highly optimized baseline packet-switched router with single-cycle delay for low-loads.Our HCS network successfully overcomes some of the drawbacks associated with circuit switching, speciﬁcally: avoiding setup overhead, reconﬁguring circuits on-the-ﬂy, and interleaving circuit- and packet-switched ﬂits on the same physical resources. The co-designed coherence protocol drives up circuit reuse and reaps better performance than the sum of the beneﬁt from the circuit-switched interconnect and the protocol modiﬁcations, when applied separately. Looking forward: while current applications exhibit fairly coarse-grained parallelism, future applications are likely to have more ﬁne-grained parallelism [12] resulting in more frequent sharing and greater latency sensitivity. This increase in sharing will heighten the need for a fast interconnect of the type that our hybrid circuit-switching provides. Server consolidation workloads, an emerging class of applications for CMPs, will exhibit limited sharing and see greater beneﬁts from our hybrid circuit-switching by allowing circuit-switched pairs to persist longer and reap even greater beneﬁt [9]. "
A Lightweight Fault-Tolerant Mechanism for Network-on-Chip.,"Survival capability is becoming a crucial factor in designing multicore processors built with on-chip packet networks, or networks on chip (NoCs). In this paper, we propose a lightweight fault-tolerant mechanism for NoCs based on default backup paths (DBPs) designed to maintain, in the presence of failures, network connectivity of both non-faulty routers as well as healthy processor cores which may be connected to faulty routers. The mechanism provides default paths as backup between certain router ports which serve as alternative datapaths to circumvent failed components within a faulty router. Along with a minimal subset of normal network channels, the set of default backup paths internal to faulty routers form - in the worst case - a unidirectional ring topology that provides network-wide connectivity to all processor cores. Routing using the DBP mechanism is proved to be deadlock-free with only two virtual channels even for fault scenarios in which regular networks degrade to irregular (arbitrary) topologies. Evaluation results show that, for a 2-D mesh wormhole NoC, only 12.6% additional hardware resources are needed to implement the proposed DBP mechanism in order to provide graceful performance degradation without chip-wide failure as the number of faults increases to the maximum needed to form ring.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip A Lightweight Fault-Tolerant Mechanism for Network-on-Chip Michihiro Koibuchi1 , Hiroki Matsutani2 , Hideharu Amano2 , and Timothy Mark Pinkston3 1National Institute of Informatics, 2-1-2, Hitotsubashi, Chiyoda-ku, Tokyo, JAPAN 101-8430, koibuchi@nii.ac.jp 2Keio University, 3-14-1, Hiyoshi, Kohoku-ku, Yokohama, JAPAN 223-8522, {matutani, hunga}@am.ics.keio.ac.jp 3 University of Southern California, 3740, McClintok Ave., EEB 208 Los Angeles, California 90089-2562, tpink@usc.edu Abstract Survival capability is becoming a crucial factor in designing multicore processors built with on-chip packet networks, or networks on chip (NoCs). In this paper, we propose a lightweight fault-tolerant mechanism for NoCs based on default backup paths (DBPs) designed to maintain, in the presence of failures, network connectivity of both nonfaulty routers as well as healthy processor cores which may be connected to faulty routers. The mechanism provides default paths as backup between certain router ports which serve as alternative datapaths to circumvent failed components within a faulty router. Along with a minimal subset of normal network channels, the set of default backup paths internal to faulty routers form—in the worst case—a unidirectional ring topology that provides network-wide connectivity to all processor cores. Routing using the DBP mechanism is proved to be deadlock-free with only two virtual channels even for fault scenarios in which regular networks degrade to irregular (arbitrary) topologies. Evaluation results show that, for a 2-D mesh wormhole NoC, only 12.6% additional hardware resources are needed to implement the proposed DBP mechanism in order to provide graceful performance degradation without chip-wide failure as the number of faults increases to the maximum needed to form ring. 1 Introduction Networks-on-chip (NoCs) have been shown to efﬁciently interconnect many functional units, tiles, and cores— collectively referred to in this paper as processing elements or PEs—of a chip [19, 3, 18]. As device technology continues to scale into the nanometer regime, the number of PEs on a single chip will increase considerably, making the need for robustly designed NoCs even more pronounced. Along with this extreme device scaling comes an increased likelihood of failures, both transient (soft) and permanent (hard), to occur within the NoC. Soft faults cause data to be momentarily corrupted (e.g., bit errors), which can be corrected within the network through link-level and end-to-end protocol techniques [14]. Hard faults are caused by physical and permanent damage to resources that generate and/or transport data, and the probability of their occurrence depends on various design and technology parameters. Typically, the larger, more complicated and more stressed the structure, the more likely it is to be susceptible to faults. A NoC consists of routers, links, and network interfaces attached to PEs in the system, each of which may possibly fail. Packets are transported through one or more of these network components, with a large number of PE sourcedestination pairs sharing each component. Each faulty network component thus affects the communication among a large number of PEs. A faulty network component may exclude healthy PEs from gaining access to the rest of the system (i.e., cause healthy PEs to be masked out, as is done typically) or, even worse, prevent the entire system from operating reliably. Redundancy is often used to combat failures. To build robust NoCs using redundancy, different spare resources could be used for every component, but fully duplicating hardware in this manner is prohibitively expensive. Moreover, in contrast to the case for off-chip networks, components in on-chip networks cannot be ﬁxed or replaced post deployment. Thus, keeping in mind that the simpler the redundant resource is, the less likely it is to suffer a fault, nominal redundancy should be built into the design of the NoC such that connectivity of all non-faulty network components as well as all healthy PEs attached to faulty components is maintained. In this paper, we propose a lightweight fault-tolerant mechanism based on the notion of default backup paths (DBPs). It uses nominal redundancy to maintain network 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.34 DOI 10.1109/NOCS.2008.34 13 13 connectivity of non-faulty NoC routers and healthy on-chip PEs in the presence of hard failures occurring in the network. In achieving a lightweight reliable structure, the mechanism provides nominal default paths as backup between certain router ports which serve as alternative datapaths to circumvent failed components (i.e., input buffers, crossbar switch, etc.) within a faulty NoC router. Along with a minimal subset of normal network channels, the set of default backup paths internal to faulty routers form—in the worst case—a unidirectional ring topology that provides network-wide connectivity to all PEs. This lightweight fault-tolerant mechanism is premised on the notion that complicated redundancy techniques need not be used to support high reliability in NoCs. The proposed DBP mechanism is shown to provide graceful performance degradation without chip-wide failure as the number of faults increases to the maximum tolerable to form a ring. The rest of this paper is organized as follows. In Section 2, we brieﬂy discuss some related fault-tolerant techniques for NoCs to provide additional background. In Sections 3 and 4, we describe the DBP mechanism for reliability-constrained NoCs and discuss how routing with the DBP mechanism can be done in a deadlock-free manner. In Section 5, we evaluate the performance of the DBP mechanism and, ﬁnally, conclude the paper in Section 6. 2. Related Work NoCs are composed of router switches and point-topoint links; thus their hard failures can be individually detected by existing techniques. Unlike off-chip interconnects using bit-serial links, NoC channels have wider bit-widths. It is possible to employ channel reconﬁguration techniques to tolerate link faults with graceful performance degradation by decoupling singular wire faults from the other wires composing the channel [21]. Analogous to this, when channel utilization is low, powering down some wires through similar decoupling techniques can provide energy savings within the interconnect [17][1]. Moreover, techniques and supporting theory have been proposed recently for static and dynamic reconﬁguration of the network routing algorithm to tolerate faults that may occur [4][11]. These approaches are all orthogonal to the DBP mechanism as it focuses on fault-tolerance support for routers as opposed to channels or the network routing algorithm. Router architectures have also been proposed that include fault-tolerant mechanisms for bypassing hard faults in some units along the router internal datapath such as the routing computation, input buffer, and switch arbiter units [9]. Similarly, a mechanism called BLAM provides central bypass buffers so that a packet passes the previous misrouted packet on the same input port [20]. Another technique using additional datapaths is called “preferred paths” in order to drastically reduce packet latency at routers [13]. These techniques, while useful for the purposes proposed, do not provide support for bypassing the entire router internal datapath nor network-wide support for ensuring connectivity and deadlock-free routing on those resources. The lightweight fault-tolerant mechanism proposed here does provide this support. The redundancy techniques for bypassing faults within NoC hardware components can be broadly grouped into three approaches or combinations of approaches: resource sparing, fault-tolerant routing, and network reconﬁguration. Their designs often suppose simple fault models that use a network graph in which each vertex is a router and each arc is a bidirectional link. Moreover, faults are simply classiﬁed into those of link and router, and router faults are sometimes regarded as all link faults around the router. The DBP mechanism derives from a combination of the above approaches, and its fault model makes use of a network graph in which unidirectional links and DBP resources are explicitly represented. 3. The Default Backup Path Mechanism In this section, we describe the proposed DBP mechanism, which is mainly designed to (1) maintain the network connectivity of healthy PEs associated with a faulty router and (2) avoid disconnecting the network due to faults occurring along the internal datapath of routers. The basic idea is to bypass faulty datapaths within failed routers through the use of backup default paths that, themselves, have low susceptibility to failure due to their simplicity of design. The set of router input-output port pairs connected by the default backup paths at routers across the network in combination with normal network channels corresponding to those ports must form a connected network that includes all routers and PEs. With this, the DBP mechanism plays the role of a lifeline for the NoC, allowing performance to degrade gracefully as the number of router faults increase to the maximum possible (i.e., all routers becoming faulty) without having the network to fail. NoCs are switched point-to-point networks characterized by a combination of topology, routing, switching technique, ﬂow control, and router microarchitecture. The DBP mechanism can be applied to NoCs composed of direct or indirect topologies, adaptive or deterministic routing algorithms, any switching and ﬂow control technique (including wormhole routing), and most router architectures. To explain the DBP mechanism, a 4×4 2-D mesh using conventional virtual channel routers as detailed in [21] is used as an example of a typical NoC, shown in Figure 1. In the router, the pipeline to transfer packets consists of routing computation (RC), virtual channel allocation (VC) for output ports, switch allocation (SW) for allocating the time-slot on the crossbar, and switch transfer (ST) for ﬂight of ﬂits. 1414 Figure 1. A conventional NoC Figure 3. Default backup path to local PE (black router in Figure 2) PE local (i.e., network interface or NI) output port by hard wires with a multiplexer, as shown in Figure 3. The newly introduced default backup path to the NI enables packets to bypass all router modules as it sinks them at the local PE. It may or may not require a FIFO buffer as a repeater, depending on the implementation (i.e., critical path margins), as shown in Figure 3. 2. For each router, as in datapaths through the router crossbar, a PE local (i.e., NI) input port is directly connected to the output DBP port (which connects to the neighboring router by the channel link) by hard wires with a multiplexer, as shown in Figure 4. This newly introduced default backup path from the NI enables packets to bypass all router modules as it sources them from the local PE. 3. A function must be added to NIs that forwards packets that happen to sink unintentionally at an NI through the default backup path of the associated router due to a fault(s). This functionality is similar to that used in the In-Transit Buffer technique [6]. The default backup path and the original datapath via the crossbar can be selected by the channel multiplexer, as shown in Figures 3 and 4. For the sake of control simplicity, as long as the router is healthy, its channel multiplexer always selects the original datapath. When there are no local PEs at a router, a pair of input and output DBP ports for neighboring routers is directly connected along the unidirectional cycle, as shown in Figure 5. This is the case for indirect networks, such as nonleaf switches in a fat tree. Conversely, when there are multiple PEs at a router, an input and all local output ports are directly or indirectly connected through no crossbars. All local input ports are also connected to an output port through no crossbars. Figure 2. Embedded unidirectional cycles 3.1 Building Default Backup Paths The DBP mechanism can be applied to NoCs by ﬁnding an embedded unidirectional cycle that includes all routers that have a local PE in the topology of the network and adding a bypass datapath along the unidirectional cycle. 3.1.1 Finding an Embedded Unidirectional Cycle A unidirectional cycle that includes all routers that have a local PE is constructed in the NoC topology. Since either a Hamiltonian cycle (Figure 2.a) or a ring along a spanning tree (Figure 2.b) can be the unidirectional cycle, an arbitrary topology can always be embedded [15]. The input and output router ports in the cycle are referred as “DBP ports” in this paper. 3.1.2 Adding Default Paths We add default paths that bypass the original datapath (i.e., crossbar) within a router such that packets can be transferred along the unidirectional cycle without traversing the router input buffers, crossbar, routing-computation unit, VC/SW allocators, etc., as follows. 1. For each router, in addition to the datapath through the crossbar, an input DBP port is directly connected to a 1515 in the next subsection). Since none of the NIs have to consume an entire packet immediately, a wormhole switching technique can also be used. The enabled default backup path to local PEs disables the packet transfer from the other port to the local PE, and the PE is able to receive packets only from a single neighboring router via the default backup path. In contrast, the enabled default backup path from the local PE disables the packet transfer from the local PE to ports except the output DBP port. Although it can decrease the throughput around the local PE associated with the faulty router, the system still works correctly using all the healthy PEs. The default backup path can transfer packets with shorter latency and lower energy than router pipelines on the original datapath via the crossbar because the default backup path consists only of hardwires or repeater buffers without routing. These trade-offs in performance are evaluated in Section 5. 3.3 DBP Mechanism for Other Component Failures Although the DBP mechanism is resilient to router failures, other network components such as the default backup path itself may also fail, though the likelihood is much lower. Here, we present the DBP mechanism extended to tolerate the faults of the network interface, the link, and the default backup path itself. 3.3.1 Bypassing NI Faults When the network interface at PEs are permanently broken, forwarding through the corresponding default backup path to the intended PE whose NI may be healthy is prevented. To tolerate NI faults so as to allow packets to reach their intended destinations, we propose to add another default backup path between the input and output DBP ports of a router, as shown in Figure 6. This provides an additional default backup path at the router to perform the function similar to that used for forwarding through the NI at the router, as in Figure 4. Only when both the router datapath and the network interface fail would the newly introduced default backup path be enabled. Its operation bypasses both the faulty router datapath and the faulty NI, and it operates similar to the DBP for indirect networks shown in Figure 5. 3.3.2 Bypassing Damage of Link Wires When the channels connected to DBP ports are faulty, the default backup paths are of no use. To tolerate the damage, the DBP mechanism can be extended by employing multiple DBP cycles that compose different topologies. When the link wires fail on a channel along one DBP unidirectional cycle, another backup DBP cycle that consists of healthy channels can be invoked. To support multiple unidirectional DBP cycles, a DBP router must be equipped with more than one DBP port to/from neighboring routers. To Figure 4. Default backup paths to/from local PE (black router in Figure 2) Figure 5. Default backup path between routers on indirect networks 3.2 Behavior of the DBP Mechanism As long as all routers are healthy, none of the default backup paths are used, as described in the previous subsection. Only when (1) a local PE cannot send or receive packets or (2) a packet cannot be properly transferred along the datapath via the crossbar to/from the DBP port (caused by a hard fault on a router) is the failed datapath replaced by the corresponding default backup path. Only the default backup path at a faulty router is enabled simply by switching the channel multiplexer. Then a healthy PE associated with the faulty router continues to communicate with the other PEs via the default backup path. When all default backup paths are enabled—as when all router crossbars fail—the network topology takes the form of a unidirectional ring, such as the embedded cycle in Figure 2. Then, a packet is transferred via both intermediate routers and their local PEs. In such a case, the network interface at a PE receives packets destined for the other PEs and forwards them on to the intended PEs from the associated router (the detailed routing mechanism is discussed 1616 Figure 6. Default backup path bypassing both router modules, and network interface Figure 7. Disconnecting DBP network by up*/down* routing maximize their fault tolerance, a large number of ports are set as DBP ports (all ports are marked as DBP), even though this increases hardware complexity. 3.3.3 Bypassing Faults of Default Backup Path Itself Because of the simplicity of the DBP mechanism, the probability that it will experience a hard failure is low, but not zero. To tolerate this hard failure, multiple unidirectional rings and default backup paths bypassing both the local PE and router modules introduced in this section can be applied. Another method duplicates some of the hardware. It is reasonable to duplicate to some extent the default backup paths, because the nominal hardware needed is small and much simpler compared to that of the router datapath. 4 Deadlock-free Routing in DBP Networks Although on-chip topologies, such as meshes, are usually regular, faults make the topologies irregular and hard for the network to establish paths that are free of routing deadlocks. Moreover, the DBP mechanism introduces a new routing problem in which ports can be partially disconnected by enabling the unidirectional default backup path on a router. In this section, we present ways in which the deadlock problem in DBP networks can be resolved based on former well-known theory and techniques. 4.1 Network Graph To design deadlock-free paths, interconnection networks are usually modeled using a connected directed graph, I = G(N , C ). Vertices of graph N are the set of routers, whereas arcs of graph C are the set of channels[5]. Since the default backup path disables the datapath between the corresponding port and crossbar, the ports occupied by the default backup path and the remaining ports are physically disconnected in the same router. To make a directed graph that corresponds to the DBP mechanism, the router that enables the default backup path is distinguished as two sub-routers: the set of ports corresponding to the enabled default backup paths (i.e., set “A”) and the set of remaining ports (i.e., set “B”), as shown in Figure 7 for the directed graph with Up*/Down* routing. 4.2 Building Routing Paths Using the network model introduced in the previous subsection, we present a deadlock-free routing design. Since topology-agnostic routing algorithms, such as Up*/Down* routing that transfers packets along tree-based paths [16], provide a deadlock-free path set on arbitrary topologies, this path set seems to ﬁt with DBP networks. However, they cannot be directly applied to the NoCs using the DBP mechanism. In the case of Up*/Down* routing, as shown in Figure 7, there are no legal paths from PE 0 and 1 to PE 2 as both require “down” to “up” transitions. This is because most topology-agnostic routing algorithms assume that each link consists of bidirectional channels, while the default backup path has only unidirectional paths. Consequently, a new routing strategy is needed for DBP networks. We present a deadlock-free routing design using v virtual channels (2 ≤ v ) for the DBP mechanism on arbitrary topologies, where “virtual channel network” stands for a logical network using a single virtual channel number. 1. Routing restrictions are imposed for all virtual channels, in order to make the deadlock-free path set that allows packet transfer along the unidirectional ring cycle. • Routing restrictions within each virtual channel network are decided to satisfy deadlock freedom as long as every packet is routed inside the virtual channel network. It could be done by applying 1717 an existing deadlock-free routing algorithm for parallel computers [5]. • To prevent deadlocks across virtual channel networks, packet transfer to a lower virtual channel network is prohibited. As shown in Figure 8, in the case of a 2-D mesh, for example, the West-First Turn Model [7] is used as a deadlock-free escape virtual channel network. Its routing rule is simple: a packet is ﬁrst transferred to the west direction zero or more hops, then adaptively to the destination without any turns to the westward direction [7]. Allowed paths include a path set of dimension-order routing used in various current NoCs. If a packet must take a forbidden turn, it must change to a virtual channel network with an incremented virtual channel number. 2. Find shortest paths between each source-destination pair under the condition with the above routing restrictions on the network as follows. (a) Search shortest paths when virtual channel i = 0 is used at the source. (b) Search the paths that have the same length as the paths in Step 3(a), when the virtual channel i ← (i + 1) is used at the source. (c) Repeat Step 3(b) until no legal paths are found, or until the search which uses virtual channel (v−1) at the source is complete. (d) When the target routing is deterministic, select a single path using a path selection algorithm when multiple shortest paths are found between a source-destination pair. In the case of adaptive routing, a path set obtained by Step 3(c) is used. Step 1 guarantees paths between all pairs of PEs that can be non-minimal. Since NoCs usually have regular topologies, such as a 2-D mesh, we can apply routing algorithms used in regular topologies for the DBP network, as shown in Figure 8. Two virtual channels are sufﬁcient for deadlock-free routing on an amended unidirectional ring. As long as deadlock freedom is maintained, packets can use channels at both DBP ports and normal (non-DBP) ports. A packet can thus be sent via normal ports as a short cut, compared with non-minimal paths along the unidirectional ring in an arbitrary topology. Theorem The DBP routing mechanism using v virtual channels (2 ≤ v ) is deadlock-free. Proof No knotted cyclic dependencies can form within each virtual-channel network (0, 1, . . . , v − 1) as packets must follow the routing restrictions imposed by a deadlockfree routing algorithm when transferred within each virtual channel network. No knotted cyclic dependencies can form Figure 8. Routing restriction on a DBP network across virtual channel networks as packets are passed between virtual channel networks in increasing order only. As there are no deadlocks within virtual channel networks nor across virtual channel networks, the DBP routing mechanism is deadlock-free. This routing approach is similar to virtual channel transition-based routing [10]. In the case of no virtual channels, the In-Transit Buffer method [6] that temporally stores some packets at NIs so as to break channel cyclic dependency can also be used. In that method, the NI associated with the router at the dateline temporarily stores only the packets transferred along the unidirectional ring. 5 Evaluation of the DBP Mechanism The DBP mechanism was evaluated through simulations in terms of the network logic area, energy consumption, and throughput. 5.1 Hardware Cost The network logic area in a NoC is mainly composed of routers and network interfaces that connect processing elements to the network. Using the Synopsys Design Compiler, the generated NoC design with a ASPLA 90 nm standard cell library, and we completed its place and route. After the place and route, the behavior of the synthesized NoC design was conﬁrmed assuming an operating frequency of 500MHz. We implemented a conventional wormhole router whose architecture was fully three-stage pipelined. The ﬂit-width 1818 Table 1. Breakdown of the 5-port DBP router and NI area (Kilo gate) Xbar & Arb Channels DBP Misc NI Total No VC 2.396 (10.76%) 13.598 (61.10%) 1.690 (7.59%) 1.196 (5.37%) 3.376 (15.17%) 22.255 (100.00%) 2-VC 10.056 (20.21%) 27.457 (55.17%) 3.376 (6.78%) 2.371 (4.76%) 6.507 (13.07%) 49.766 (100.00%) was set to 64 bits, and each pipeline stage had a buffer for storing one ﬂit. Each input port has a FIFO buffer to store four ﬂits. The routing decisions were stored in the header ﬂit prior to packet injection (i.e., source routing); thus routing tables that require register ﬁles for storing routing paths were not needed in each router, resulting in a low cost router implementation. This router architecture is the same as the one used in [12]. The DBP router has a single DBP input/output port, and the other features are the same as those of the conventional router. Its router structure ﬁts with a 2-D mesh, and its DBP unidirectional cycle is shown in Figure 8. We implemented the default backup path by inserting a FIFO buffer for storing two ﬂits in each router. The network interface is designed to interface between a PE and its router with minimum hardware. We implemented a simple NI that employs a two-ﬂit FIFO buffer for switching ﬂits. Figures 9(a) and 9(b) show the place and route results of 3-, 4-, 5-, and 6-port routers. In these ﬁgures, “Conv” stands for a conventional wormhole network with 2-D mesh for 16 PEs, while “DBP” stands for it with DBP mechanism using the unidirectional cycle in Figure 2. Using the values in Figures 9(a) and 9(b), Figure 9(c) shows the total router area of the 2-D mesh network, where “16-0VC” stands for 16-routers without virtual channels. These results indicate that the DBP mechanism increases only by up to 12.6% the amount of hardware for the 2-D mesh. This is because that the DBP mechanism requires only at least two additional datapath, paths from/to local PE to/from the neighboring routers, which consists of a multiplexer and a 2-ﬂit FIFO buffer for a DBP link bypassing the internal router modules. Table 1 shows the amount of NI area and itemizes the network logic area of the 5-port router. In Table 1,“DBP” stands for the hardware amount for the default backup path at a router. “Misc” includes inserted buffers for adjustment avoiding timing violation. The ratio of additional hardware for the DBP mechanism reduces as the number of ports per router increases. Note that every virtual channel requires a buffer, and the virtualchannel mechanism makes the structure of the arbiter and crossbar more complicated; thus increasing by 124% the router hardware, as reported in [12]. 5.2 Throughput and Latency Performance A ﬂit-level simulator written in C++ was used for measuring the throughput. Every router has three, four, or ﬁve ports, and a single PE connected to every router. Wormhole switching was used as the switching technique of the router, and a FIFO buffer was included along the default backup path. The other features are the same as those used for estimating the amount of hardware. The PEs inject packets independently of each other, and we set the packet length at 16 ﬂits, including one header ﬂit. The destination of a packet is randomly determined, resulting in a uniform trafﬁc pattern. Each host injects packets synchronized to the same interval, leading to bursty trafﬁc like that in most scientiﬁc applications. A 2-D mesh using one or two virtual channels is employed, and the West-First Turn Model [7] is also assumed for routing on each virtual network, as explained in Section 4. Since current NoCs usually support deterministic routing, we evaluated the DBP mechanism with deterministic routing. To ﬁnd a deterministic path from a set of alternative path provided by an adaptive routing algorithm such as West-First Turn Model, a path selection algorithm is needed, as explained in Section 4. We use Sancho’s algorithm [8], which is based on a static analysis of routing path, to determine a single path between each source-destination pair. In the case of no hardware faults with two virtual channels, both virtual channels are used in order to avoid Head-of-Line (HOL) blocking as follows: virtual channel 0 is used for paths to even-numbered destinations while virtual channel 1 is used for paths to odd-numbered destinations. In the case of faults, the DBP mechanism establishes paths using the procedure described in Section 4. In the case of no virtual channels, the In-Transit Buffer method [6] is employed at a single router located at the dateline crossing the DBP unidirectional cycle (Figure 8). Theoretically, inﬁnite buffers are needed at the NI (or PE) associated with the dateline In-Transit Buffer router [6]. Since inﬁnite memory cannot be provided in NoCs, some packets cannot be temporarily stored when the buffer is ﬁlled with packets waiting for their reinjection. In this case, such overﬂowed packets are discarded at the intermediate node, and a NACK (negative acknowledgment) must be sent to its original source node so as to request a retransmission of the discarded packet. This method simply extends the end-toend ﬂow control mechanism in the higher-level protocol on NoCs. Twenty different fault patterns are randomly generated for each fault scenario evaluated (i.e., number of faults). In this evaluation, a fault is considered to be a failure anywhere along the datapath between an input and output port pair of a router. As we are evaluating the DBP mechanism considering faults occurring only in the network, all PEs are assumed to be healthy. Figures 10(a) and 10(b) show the throughputs of the 1919 (a) Router comparison, no VCs (b) Router comparison, two VCs (c) Routers of 2-D mesh networks Figure 9. Hardware amount of DBP and wormhole networks DBP networks, averaged over 20 different fault patterns for each number of faults. The 0-fault case is simply the network without the need for the DBP mechanism. Figures 10(c), 10(d), 10(e) and 10(f) show the relation between the average latency, the accepted trafﬁc, and the average packet hops of the DBP networks whose faulty patterns provide nearly average relative performance. Notice that the number of faults ranges from zero to 48 on 16-router and 224-router networks, causing the topology to degenerate from 2-D mesh to a unidirectional ring. The DBP mechanism thus allows the network to gracefully degrade in the presence of a an increasing number of faults without disconnecting healthy PEs and routers from the network. Figures 10(c), 10(d), 10(e) and 10(f) show the average path hop count of the DBP networks. This is the main factor behind the performance degradation (i.e., lower throughput and increased latency). 5.3 Energy Consumption To estimate the power consumption of the router mentioned previously, the following steps were performed: (1) synthesis by Synopsys Design Compiler, (2) place and route with buffer insertions at CTS using Synopsys Astro, (3) post place-and-route simulation by Cadence Verilog-XL to obtain switching activity information of the router, and (4) power analysis based on the switching activity using Synopsys Power Compiler. A 90nm CMOS process with a core voltage of 1.0V was selected in this analysis. Clock gating and isolation were fully applied to the router to minimize its switching activity. The router was simulated at 500MHz with various ﬁxed workloads (throughputs), in the same manner as in [2]. A packet stream is deﬁned as intermittent injections of 16ﬂit packets, which utilize about 30% of the maximum link bandwidth of a single router link. Each header ﬂit contains a ﬁxed destination address, while data ﬂits contain a random payload. The number of packet streams injected into the router was changed so as to generate various workloads. We assume 64-bit networks with 16 and 64 PEs placed in 6 × 6mm2 and 12 × 12mm2 chips, respectively. Figures 11(b) and 11(c) show the results of average energy consumption of packet transfers between PEs in the case of uniform trafﬁc. We calculated the energy consumption using the energy of the original datapath, default backup path, NI, channel wire, and the number of packet hops along the path. The case of no faults is simply the network without the need for the DBP mechanism. The other cases make use of the DBP mechanism to maintain network connectivity in the presence of faults. With two virtual channels, the DBP network consumes only 9.5% more energy on average than the fault-free network when the number of faults increases to 80. As shown in Figures 10(c), 10(d), 10(e) and 10(f), the number of hops increases as the number of faults increases, which decreases the throughput. Because of the longer path hops, the energy consumption of packet transfer between PEs increases in the DBP network. As shown in Figure 11(a), energy per router via of the default backup path is less than that of the normal router datapath via the internal crossbar as the simpler default backup path bypasses all the internal router modules. Since the default backup path transfers packets via a network interface at an intermediate router, the energy consumption at network interfaces is increased compared to that of the network interfaces in the conventional healthy network. All the above factors affect the total energy consumption of the packet transfer between PEs on the DBP network. It can be seen that the DBP network, especially with virtual channels, does not so much increase the energy consumption in most cases. However, when all router datapaths except default backup paths fail, a unidirectional ring topology manifests and the total energy consumed is drastically increased up to 128% in 16 PEs, and 352% in 64 PEs. This is because the average path hop count is drastically increased, as shown in 2020 (a) Average throughput for 16 PEs (b) Average throughput for 64 PEs (c) Accepted trafﬁc vs. latency, no VCs, 16 PEs (average path hop-count is given in parentheses) (d) Accepted trafﬁc vs. latency, two VCs, 16 PEs (average path hop-count is given in parentheses) (e) Accepted trafﬁc vs. latency, no VCs, 64 PEs (average path hop-count is given in parentheses) (f) Accepted trafﬁc vs. latency, two VCs, 64 PEs (average path hop-count is given in parentheses) Figure 10. Throughput of DBP networks Figures 10(c), 10(d), 10(e) and 10(f), and the number of hops increases as the number of faults increases. 6. Conclusion In this paper, we propose a lightweight fault-tolerant mechanism based on the notion of default backup paths which maintain network connectivity in the presence of faults occurring in NoC routers. The mechanism is lightweight in that only a nominal amount of simple redundant hardware is needed to maintain network connectivity. With the DBP mechanism, in addition to the original router datapath, default paths connect certain input and output ports of a router to allow any faulty components along the datapath within a router to be bypassed, such as failed input channel buffers, failed crossbar switches, and other router microarchitectural components. As faulty routers cause the network topology to become partially irregular, deadlockfree paths along the network resources—including the default backup paths—must be ensured. Well-known techniques can be applied straightforwardly to networks employing the default backup path mechanism to guarantee deadlock freedom in routing packets around and through network faults. Evaluation results show that the proposed mechanism increases hardware costs by a modest 12.6% for 2-D mesh wormhole networks while providing graceful performance degradation without chip-wide faulure as the number of faults increases to the maximum possible. The DBP mechanism can, thus, be regarded as serving the role of a lifeline to increase the the lifetime of NoCs and processor chips built from them. Acknowledgments This work was partially supported by Joint Research Fund, “Network-on-Chip Architecture”, National Institute of Informatics, JST CREST, and KAKENHI #1880008. It was also supported, in part, by NSF grant CCF-0541417. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views of the National Science Foundation. "
Impact of Process and Temperature Variations on Network-on-Chip Design Exploration.,"With the continuing scaling of CMOS technologies, process variation is becoming a key factor highly impacting system-level power and temperature. Traditional methods of assuming a uniform temperature and no process variation can lead to gross inaccuracies even for system-level design, thus it is critical to consider the effects of process variation and temperature variation during early design exploration. In this paper, we describe the implementation of an architecture- level early-stage design space exploration tool that incorporates the effect of process and temperature variation for network-on-chips(NoC). The tool is used to study the impact of process and temperature variations on power and energy-delay-product-per-flit metrics for different NoC architectures, and our simulation results show that design choices are influenced by the effects of process and temperature variation, thus demonstrating the importance of considering, and enabling the high- level impact analysis of process and temperature variation early in the design flow.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Impact of Process and Temperature Variations on Network-on-Chip Design Exploration Bin Li Dept. of EE Princeton University NJ 08544, USA binl@princeton.edu Li-Shiuan Peh Dept. of EE Princeton University NJ 08544, USA peh@princeton.edu Priyadarsan Patra Intel Corporation Hillsboro OR 97124, USA priyadarsan.patra@intel.com Abstract With the continuing scaling of CMOS technologies, process variation is becoming a key factor highly impacting system-level power and temperature. Traditional methods of assuming a uniform temperature and no process variation can lead to gross inaccuracies even for system-level design, thus it is critical to consider the effects of process variation and temperature variation during early design exploration. In this paper, we describe the implementation of an architecturelevel early-stage design space exploration tool that incorporates the effect of process and temperature variation for Network-on-chips(NoC). The tool is used to study the impact of process and temperature variations on power and energy-delay-product-per-ﬂit metrics for different NoC architectures, and our simulation results show that design choices are inﬂuenced by the effects of process and temperature variation, thus demonstrating the importance of considering, and enabling the highlevel impact analysis of process and temperature variation early in the design ﬂow. 1. Introduction The continuing scaling of technology poses several design challenges for future high performance architectures. One such challenge is dealing with the increased effects of process variation. Besides, the continuous increase in operating frequency along with higher on-chip integration of functionalities has been exacerbating chip power density and within-die temperature ﬂuctuations. These problems and their impact on power and performance have gained attention in the past few years. Techniques that mitigate process variations have been proposed [1, 2]. Several works used actual chip measurements to study the magnitude and spatial correlation of process variation [3, 4], while others developed statistical models for estimating leakage power and yield in the face of process variations [5–10]. However, power estimation accounting for variability at architecture or system level have gained attention only recently [11–16]. Many decisions taken at system level can signiﬁcantly affect the power and temperature proﬁle as well as the overall performance. Assuming a uniform temperature and no process variation can lead to substantial inaccuracies in system-level design choices. It is thus important to accurately and efﬁciently estimate power taking into account process and temperature variations so that they can be accounted for early in the design stage. In this paper, we investigate how system-level design decisions for multi-core chips are affected by process and temperature variations, focusing speciﬁcally on the network-on-chip (NoC) interconnecting these chips, as NoCs are emerging as the scalable interconnect replacing buses and crossbars in many-core chips [17, 18]. Except for [14], prior works on system level power estimation were performed for small circuit functions or uniprocessors [11, 13, 15, 16]. NoC power estimation is important as NoCs consume a signiﬁcant amount of total on-chip power. For example, 16-tile MIT RAW’s on-chip interconnection network consumes 36% of total chip power, with each router dissipating 40% of individual tile power [19, 20]. In Intel 80-tile TeraFLOPS processor, the measured on-chip network power per tile with all ports active consumes 39% of total tile power [21]. In this paper, we extend Polaris [22], a system level power/performance design space exploration tool for NoCs to take into account process and temperature variations. In particular, we focus on leakage power estimation as dynamic power is not signiﬁcantly impacted by channel length variations and threshold voltage variations [13]. Polaris is a rapid design space exploration tool that estimates network power-performance and provides designers with relative power-performance rankings that can be used to make architectural choices at early design stage. By factoring in process and temperature variations, our results show the importance of considering and quickly estimating the impacts of both the process and temperature variations together because the design decisions taken at early design stage might be changed. The remainder of the paper is organized as follows. Section 2 presents background on how process and temperature variations impact leakage power. Section 3 explains how Polaris is extended to take into account process and temperature variations. Section 4 studies the impact of process and temperature variation on onchip interconnection network power and energy-delayproduct-per-ﬂit metrics estimation across different ar978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.19 DOI 10.1109/NOCS.2008.19 117 117 chitectures. The paper is then concluded in section 5. 2. Background and Motivation Systematic and random variations in process, supply voltage and temperature have become a major challenge to future high performance architecture design. Process variation is mainly caused by the difﬁculties in the precise control of lithography and inherent random processes, thus causing line edge roughness. With the continuing reduction of the number of dopant atoms in the channel between source and drain in a MOSFET, random dopant-density ﬂuctuation causes variation in the transistor characteristics. Moreover, the increase in operating frequency for each processor generation has resulted in signiﬁcantly higher power-density and ondie temperature; additionally the spatial and temporal variation in workloads and levels of activity across the multi-core die, the uneven thermal environment of the chip, etc. inevitably lead to substantial power-density and temperature variation within the chip. Temperature variation can lead to hot-spots and points of reliability failure and has an exponential relationship with leakage which can cause further exacerbation of power [23]. Process variations can be classiﬁed into die-to-die (D2D) and within-die (WID) variations. D2D variations affect all the transistors on the same chip in the same way while WID variations affect different transistors differently on the same chip [5]. For higherperformance IC designs, D2D and WID variations have a signiﬁcant impact on system performance and power consumption. A key process parameter subject to variation is the transistor threshold voltage (Vt h ). Process and temperature variation leads to variation in threshold voltage, and leakage current has exponential relationship with threshold voltage. So transistor sub-threshold leakage is strongly dependent on threshold voltage and temperature. Variation in functionality across the chip results in uneven power dissipation; this variation results in uneven temperature proﬁle across the chip, which in turn causes leakage variation across the chip and increases the variability. The sub-threshold leakage current can be given by BSIM3 SPICE model [24] as: Isub = I0 [1 − ex p(− Vd s Vt (cid:2) )]ex p( Vgs − Vt h − Vo f f ) (1) nVt qεsi · Nch V 2 t (2) I0 = μ0 W 2Φs L where Vt h is the threshold voltage, Vd s is drain-tosource voltage, Vgs is gate-to-source voltage, Vt = kT is the thermal voltage, Vo f f is the offset voltage, n is the subthreshold swing coefﬁcient, μ0 is the zero bias mobility, W/L is the aspect ratio of the transistor, εsi is silicon relative permittivity, Nch is channel doping concentration, and Φs is surface potential. From Equation (1) and Equation (2), we can get q that: Isub ∝ T 2ex p(− qVt h nkT ) (3) 118118 Equation (3) illustrates that Isub has strong relationship with temperature T and threshold voltage Vt h . As Vt h is highly impacted by process variations due to Le f f variation and dopant concentration variations, Isub will also be critically impacted. Figure 1 shows the relationship between leakage power and threshold voltage Vt h [25] at 65nm technology. The leakage power is normalized to the leakage at ﬁxed Vt h of 0.25V. We can see leakage power increasing rapidly with the decrease of Vt h . Fig. 2 plots the leakage power as a function of temperature. The leakage power is normalized to the leakage power at 40 ◦C. We can see that leakage power increases rapidly with the increase in temperature. Besides, different functionality across different circuit blocks will lead to further temperature ﬂuctuation on the chip, thus causing uneven leakage power on the chip. Figure 1. Leakage power and Vt h relationship Figure 2. Leakage power and T relationship In short, we see that leakage power is strongly affected by process variation and temperature variation. With the continuous scaling of technology, this problem is becoming more and more critical. We can no longer assume uniform temperature and ignore process variation even at the early stages of design. 3. Proposed Work Polaris is a system level roadmap for on-chip interconnection networks developed by Soteriou et al. [22, 26]. It is a toolchain that can rapidly explore a large design space of NoCs, estimate system-level power/area/delay and guide designer towards the most suitable architectures that best balance cost/performance based on designer’s needs at the early design stage. The reason we choose to use Polaris is because it incorporates a large design space of 7872 NoC designs and the simulation time is much faster than detailed cycle-accurate simulation while ensuring reasonable accuracy. Thus, this tool is suitable for us to use for exploring the effects of process and temperature variations for early design space exploration. We choose to use Polaris also because Polaris and Orion have a signiﬁcant user base of several hundreds users, and so our extending of it to include process and temperature variations will hopefully beneﬁt those users as well. We will ﬁrst introduce the original Polaris toolchain which does not consider parameter variation effects, before explaining how the tool is extended to estimate NoC power with consideration of process variation and temperature ﬂuctuation. 3.1. Introduction to the Polaris toolchain Figure 3 shows Polaris’s ﬂow chart for rapidly estimating power/area/delay of large design space and provide designers with roadmapping tables, i.e. tables with estimates of various metrics for alternative NoC designs at different processes [22]. The ﬂow chart includes three steps. The ﬁrst step is synthetic trafﬁc traces generation using Trident [27], which are then used to drive and exercise each NoC design. Trident is a synthetic trafﬁc generator which can generate artiﬁcial trafﬁc traces based on designer’s requirement. The author of [27] ﬁrst derives a trafﬁc model based on three parameters which can accurately capture characteristics of real-world trafﬁc, and then classify them into several categories which can represent different trafﬁc traces. The three parameters are trafﬁc burstiness (models the temporal burstiness of the trafﬁc at each node and how large these bursts are), trafﬁc injection distribution (models the ratio of total network trafﬁc each router injects into the network and their distribution) and trafﬁc hop distance (models the average hop count packets travel from source to destination). In Polaris, currently 8 categories are considered based on the permutations of moderate and highly bursty trafﬁc, hot-spot and evened-out injected trafﬁc, and short distance and long distance trafﬁc. Trafﬁc burstiness is modeled using the Hurst parameter that deﬁnes the level of selfsimilarity. In Polaris, highly bursty trafﬁc is denoted as H=0.9, and moderately bursty trafﬁc is denoted as H=0.5. Hot-spot trafﬁc is modeled as 10% of the nodes receive 64% of the total injected trafﬁc, and in evenedout trafﬁc, 20% of the nodes receive 64% of the total trafﬁc. For short distance trafﬁc, it’s classiﬁed as the trafﬁc where only 20% of the total injected trafﬁc traverses distances greater than four hops, and for long distance trafﬁc, this value increases to 40%. The designers can specify their trafﬁc characteristics or provides their own categorization, and Trident can generate artiﬁcial trafﬁc traces according to designer’s application. The second step in Polaris is network resource utilization with LUNA (Link Utilization for Network Analysis) [28]. LUNA is a network analyzer which takes the trafﬁc traces from Trident as input and calculates network resource utilization for a wide range of architectures, and then estimates network activity/utilization, delay and contention. In LUNA, a router pipeline delay model in terms of pipeline stages and wire delays in terms of cycles are incorporated to calculate latencythroughput of the trafﬁc. The router pipeline stages is calculated based on the number of physical channels per router and number of virtual channels per physical channel [29]; the wire delay cycle is calculated based on wire length in terms of hops. The third step is network power and area estimation using Orion [30]. Orion is a power and area library for different router conﬁgurations which projects potential circuit structures for each conﬁguration at each technology node. It takes LUNA’s resource utilization information for each router and link as input activity and factors that with Orion’s router power estimates and wire capacitance estimates projected by ITRS [31] along with router distance either provided by designer or projected by ITRS [31]. After this, router power and link power are added together to estimate the whole on-chip interconnection network power. Orion also estimates the area for each network-on-chip conﬁguration based on the prescribed circuit structure and assumed layout. Polaris D esign space explora tion Step 1 Trident Synthetic traffic generation Microarchitecture parameters Step 2 LUNA H igh-level on -chip network analysis Step 3 ORION Power and area models power CMOS area Performance (latency ) NoC designs projections Figure 3. Polaris network roadmapping toolchain After the three steps above, Polaris compares results of power/area/delay among each network-on-chip conﬁguration and provides the designer with roadmap tables: for instance, network power, latency, energydelay-product-per-ﬂit and power per area. Based on this roadmap table information, designers can then choose the most suitable network-on-chip architecture that satisﬁes their requirements and design constraints. 3.2. Extension of Polaris power models to consider process and temperature variations The original Polaris toolchain explained in 3.1 assumes uniform temperature within the chip and no process variation. To study how process and temperature variation affects the power consumption for on-chip interconnection networks, we extended this tool to calculate power consumption with consideration of process variation and temperature ﬂuctuation for on-chip inter119119 connection networks. Figure 4 presents an overview of the power modeling methodology considering process and temperature variations which is incorporated into Polaris toolchain. This iterative approach was adapted from [11]. In [11], the author estimates the full chip leakage considering power supply and temperature variations. We use this methodology to consider process and temperature variations. We extended Orion’s leakage power model [32] to make it process and temperature aware. For dynamic power, since it is not as signiﬁcantly affected by process and temperature variations as leakage power, we left Orion’s dynamic power model [30] untouched. D2D Process Variation Models (Vth) Network Resource Utilization from LUNA ORION Leakage Power HotLeakage Dynamic Power ISAC Temperature profile Stop when power and temperature prof iles converge at each process sample point Total Power Profile at each process sample point N Set simulation number achieved? Y Power Distributions Figure 4. Power model ﬂow chart considering process and temperature variation using Monte Carlo simulation In Figure 4, a process sample point from the D2D process variation model is fed into the leakage power model, and leakage power consumption is calculated at an initial temperature. Combined with dynamic power estimation, the total power proﬁle is calculated. This power proﬁle is then fed into thermal simulator to estimate the thermal proﬁle. This thermal proﬁle is then used to re-calculate the leakage power proﬁle since leakage power has strong dependence on temperature. This power changes will again affect temperature proﬁle [11]. After several iterations, the difference between each loop will be small enough and we can get acceptable accuracy for the power and temperature estimation with high efﬁciency. This procedure is performed based on Monte Carlo simulation and randomly generated sample point is used for each simulation until a certain conﬁdence level is ensured. After Monte Carlo simulation, a power distribution proﬁle is generated for this design point. Designer can run the simulation for different design choices and select the most suitable design parameters that satisfy the design requirements. We will next explain each of the new components in detail. 3.3. Leakage power model As transistor feature size gets smaller and smaller, it’s getting more and more difﬁcult to precisely control the fabrication process, thus causing process variations. There are two major parameters subject to process variations that are important for microarchitectural and system level design. One is the effective transistor channel length (Le f f ), the other is transistor threshold leakage (Vt h ). We choose to use Vt h as the process variation parameter in our power model, but other sources of variations such as Le f f can be incorporated in our work as well. In [32], the authors propose an architectural level leakage power modeling methodology and the proposed leakage power model was incorporated into Orion. While it is validated against Spice to be accurate at 70nm, the leakage power model does not incorporate the effects of process and temperature variations. Besides, the leakage power model is for sub-threshold leakage. With the contiguous transistor scaling, gate oxide thickness is projected to scale for future technologies [31], which causes gate leakage to increase rapidly. So it’s important to consider gate leakage as well in the leakage power model. In order to consider process variation and temperature variation effects, we incorporate leakage current models from HotLeakage developed by Zhang et al. [33] into Orion for estimating sub-threshold leakage and gate leakage. HotLeakage is an architecture level leakage power model that includes temperature, voltage, gate leakage and parameter variations. It uses the BSIM3 V3.2 [24] leakage equation of MOSFET to model the leakage of a single transistor and extends the Butts-Sohi [34] model to take into account the stack effect and interaction among multiple transistors. It includes parameters of supply voltage, threshold voltages, oxide thickness and temperature. In our simulator, we replace the original leakage model in Orion with the leakage power models from HotLeakage. We ﬁne tune the sub-threshold leakage current model from HotLeakage with simulation and real chip measurements. We keep the gate leakage current model from HotLeakage untouched. While Hotleakage models supply voltage and oxide thickness parameters, we only concentrate on Vt h and T as our parameters because these two parameters are the major contributors to sub-threshold leakage. For Vt h , we consider D2D Vt h variation currently because we are targeting at early design space study and D2D variatons are more interesting to us. We assume the same Vt h in each chip while different chips have different Vt h . We also assume a normal distributions among chips for Vt h variations. We estimate the on-chip temperature at the router granularity, that is different routers on chip have different temperatures based on the trafﬁc activity, but a single router is modeled as a single temperature source. 3.4. Thermal model To calculate the temperature proﬁle, we use the thermal simulator ISAC developed by Yang et al. [35]. ISAC is a chip-package thermal analysis tool used in IC synthesis and design. It takes a three-dimension chip and package thermal conductivity proﬁle, as well as power dissipation proﬁle as input parameters. It uses a multigrid incremental solver to progressively reﬁne 120120 thermal element discretization and rapidly produce a temperature proﬁle. The thermal analysis provided by ISAC is very fast due to their adaptation of spatial resolution and temporally decoupled element time marching techniques. Further, the authors show an accuracy of 99% using industrial and academic synthesis test cases and chip designs. Hence we chose to incorporate this model for thermal proﬁle analysis in our early design stage exploration. In our simulator, we use steady-state thermal proﬁle. Designer can provide a power proﬁle for the computing and storage parts on the chip. The simulator calculates the power consumption of each router on the chip using Orion with the leakage model from HotLeakage. Then the NoC power proﬁle is combined with the user-deﬁned computing and storage power proﬁle to form a whole chip power proﬁle. This whole chip power proﬁle is then fed into ISAC. ISAC rapidly calculates the temperature for the whole chip and provides the thermal proﬁle for the chip as the output. The updated thermal proﬁle is then fed into Orion to re-calculate the power consumption. This procedure will iterate until the temperature and power proﬁle converges. power distribution, latency, area, energy-delay-productper-ﬂit for different network conﬁgurations. PolarisPT Design -space exploration Step 1 Trident Synthetic traffic generation D2D Process Variation Models (Vth) Microarchitecture parameters Step 3 ORION Step 2 LUNA H igh-level on -chip network analysis Leakage Power HotLeakage Dynamic Power ISAC Temperature profile Stop when power and temperature profi les converge at each process samp le po int Total Power Profile at each p rocess samp le po in t Pow er distribution pro fi le CMOS area Performance (la tency ) NoC designs projections 3.5. Monte Carlo Simulation Figure 5. PolarisPT toolchain with consideration of process and temperature variations We use Monte Carlo simulation to estimate power distribution for interconnection network under process variation. For each simulation, a sample Vt h is randomly generated from the pre-deﬁned process variation model and leakage power is calculated at this Vt h . This step is performed with enough sample points to ensure a predeﬁned conﬁdence level is achieved, thereby generating a power distribution proﬁle. 3.6. PolarisPT: Polaris toolchain considering process and temperature variations After explaining each part of the power model ﬂow chart, now we incorporate this power model into Polaris toolchain. Figure 5 presents the new Polaris toolchain (PolarisPT) which now considers process and temperature variations for power estimation. The artiﬁcial trafﬁc generator Trident ﬁrst generates synthetic trafﬁc trace, and this trafﬁc trace is fed into LUNA to capture the network resource utilization and calculate the network latency. The network resource utilization information is then fed into Orion (which now includes a process-variation-aware leakage power model) to calculate the power consumption distribution with consideration of process and temperature variations. Monte Carlo simulation is performed at this step with enough sample points so that a pre-deﬁned conﬁdence level can be achieved. (designers can deﬁne the number of samples as simulation input as well). Within each run at this step, leakage power is calculated iteratively with the sampled Vt h and simulated temperature until the power/thermal proﬁle converged. After the Monte Carlo simulation, a power distribution envelope is generated. Orion also calculates the area for on-chip interconnection networks at this step. Finally, PolarisPT will provide designers simulation results containing network 4. Experimental results This section analyzes the impact of die-todie(D2D) threshold voltage Vt h variation and within-die (spatial) temperature variation on interconnect network design. Especially, we study the power and the energydelay-product-per-ﬂit (EDPPF) distributions for various interconnection network architectures. 4.1. Experimental setup We consider a mockup chip similar to Intel’s 80core teraﬂops NoC [21, 36] for our baseline system and analysis. While this is a hypothetical chip, the parameters are derived largely from the aforementioned 80core chip for a realistic baseline. As such, our experiments assume 64-node NoC designs, 65nm processing technology, a supply voltage of 1.2V and the operating frequency of 3.8GHz. This operating frequency is a ﬁxed frequency where the network clock is tied to the computing element clock, but router pipeline stages is modeled based on the number of physical channels per router and number of virtual channels per physical channel. For our study, we scaled this chip’s ﬂoorplan to 64 cores, which comes to 14.4mm by 14.4mm. The standard deviation of D2D threshold voltage is assumed to be 6% based on the ITRS projection [31]. Table 1 summarizes the parameters used in our simulation. Our study considers several network topologies: 2D mesh plain, 2D torus plain, 2D mesh with express cube, 2D torus with express cube, 2D mesh with hierarchical link and 2D torus with hierarchical link. Table 2 shows the design space studied in our experiment. For each topology, we assume a packet has ﬁve 64-bit 121121 Table 1. Parameter values Technology Clock frequency Supply voltage Vt h Non communication component power Conﬁ dence interval Die size Heat sink Ambient air temperature 65 nm 3.8 GHz 1.2 V μ = 0.25V , σ / μ = 6% 1.2W/core 95% 14.4 mm × 14.4 mm × 0.6 mm 60 mm × 60 mm × 6.8 mm 45 ◦C ﬂits 1 . Synthetic trafﬁc traces generated from Trident [27] are used as the input to the system simulator. We run simulations for all the eight classes of trafﬁc as categorized in Trident. Due to the limited space, the simulation results shown here are for long-distance, moderately bursty and hot-spot trafﬁc, as characterized by Trident and explained in section 3.1. Our results show similar trends for other trafﬁc patterns though. Table 2. Design space explored in the experiment Topology 2D mesh plain 2D mesh with express cube interval 2,3 2D mesh with hierarchical link interval 2,3,4 2D torus plain 2D torus with express cube interval 2, 4 2D torus with hierarchical link interval 2,3,4 Buffer size (64-bit ﬂits) Virtual channels per link Routing Flow control 4, 8, 16, 32 1, 2, 4, 8 Deterministic routing Wormhole, virtual cut-through 4.2. Effects of process variation and spacial temperature variation Our baseline experiment involved simulating our ”chip” under the assumption of no D2D Vt h variation and a single uniform temperature of 80 ◦C. Then the chip power and the energy-delay-product-per-ﬂit for the trafﬁc described above were estimated for the various interconnection network conﬁgurations. We then simulated the system considering D2D Vt h variation and the spatial T variation on a set of 500 chips. For all the described experiments, we made a simplifying assumption that the change in temperature did not affect the power dissipation in components other than the network. In other words, we assumed that power dissipation in storage and computation blocks of the simulated chips all remained constant, and that the leakage of the network components were affected by the temperature and vice versa. (We suspect that the change in power dissipation and performance of these non-network blocks will further accentuate the total effect of variation on the design metrics.) We modeled total leakage as the sum of sub-threshold and gate leakages. Although our system can be easily extended to assign different power densities for the different computation and storage areas of each tile (a physical area associated with a core and its 1 Flit is ﬂow control unit, a ﬁ xed-length segment of a packet. router) on the chip based on block-level power estimations as desired, for our simulation, we used a uniform power density for these non-network components due to the lack of information on computation and storage part. In ﬁgure 6, the x-axis shows the ﬁrst eight network architectures that have the lowest power consumptions assuming no process variation and uniform temperature. By architecture here we mean the network topologies and their speciﬁc conﬁgurations denoted in the format: topology variant (buffer size, number of virtual channels). For example, by ”mesh plain (4,2)” we mean a 2D mesh topology in its plain variant with an input buffer-size of 4 ﬂits/virtual-channel and 2 virtual channels per router port. From left to right on the x-axis, the architectures are ordered in increasing value of their estimated power consumption. The y-axis represents the power consumption normalized to the lowest-power NoC architecture, among the set considered (still assuming no variation effects), which is mesh plain with 4 buffers per virtual channel and 1 virtual channel per port ( i.e., no virtual channel). The bottom plot in the ﬁgure shows two bars for each architecture where the left bar indicates estimated interconnect power assuming no variations. The right bar shows the estimated power when considering both the effects of Vt h and T variations. The bands in the right bars show the power variations across the set of chips simulated. The longer bands imply higher variations across chips. From this bottom part of the ﬁgure, we can see that when considering the effects of Vt h and T variations, the average power consumption increases compared to the no variation scenario, for each network architecture shown in the ﬁgure. This is because leakage power has exponential relationship with T . The higher the T, the leakier the transistors. Now with the consideration of Vt h and T variations, the power consumption becomes a distribution rather than a single, deterministic number. We note that the larger the average power consumption, the higher the variations. We have used the mode of the distribution to mean the single ’average power’ number in the discussion here. (In practice, typically the slowest and the fastest, i.e. very leaky, parts get rejected and the rest get binned. So, the average power may be suitably deﬁned for each bin considered.) The upper part of the ﬁgure 6 shows the product of the power distribution’s standard-deviation and mean (σ × μ) – this is a metric relevant while considering parametric yield and total power of chips manufactured under the reality of Vt h and T variations. We use this metric to evaluate the power ranking taking into account both the average power and its variance caused by variation effects. Using this metric, we can see that the relative ranking for these lowest-power architectures still keeps the same trend as the ranking assuming no variation. From both the plots of our results, we observe that even though the average power increases when considering Vt h and T effects, the relative ranking for the lowest-power network conﬁgurations doesn’t vary much. This is because the ones that have lower power consumption also have typically simpler architectures using fewer network resources (thus more tolerant of the variations), and have longer latencies. Across our design space, we found out that typically torus plain 122122 and mesh plain are more tolerant to Vt h and T variations than the architectures with express links or hierarchical links. Even so, it is important to estimate power taking into account process and temperature variation because even though the lowest-power ranking may not vary much, a design may have a power envelope (constraint) within which the design is being optimized for performance. So, signiﬁcant inaccuracies in total power dissipation may lead to incorrect design decisions as variations can introduce substantial differences in dissipation. In addition to power, we also need to consider about performance. So next we evaluate the EDPPF (energy delay product per ﬂit) across our design space as this accounts for both performance and power dissipation. Figure 7 shows the ﬁrst eight network conﬁgurations that have the lowest EDPPF with and without Vt h and T variations considered. The x-axis in the ﬁgure lists, in increasing order of the EDPPF, these eight network architectures and conﬁgurations that have the lowest mode EDPPF when assuming no process variation with uniform temperature. The y-axis is the EDPPF normalized to the lowest EDPPF architecture under no variation, which is the torus plain (8,2). From the ﬁgure we can see that when assuming no variations, torus plain(8,2) has the lowest EDPPF. But when considering Vt h and T variation effects, torus(4,2) actually has the lowest average EDPPF. Besides, torus (4,2) has lowest EDPPF variations across chips. So, designers might want to choose torus (4,2) when looking for conﬁgurations targeted at low EDPPF and if the layout/area constraints are feasible. From the ﬁgure, we can also notice that even though torus (4,1) has relatively higher average EDPPF among these top eight conﬁgurations, its EDPPF variance is much smaller than torus (16, 2) and torus (8, 4), so this factor should be taken into account when making design decisions. The upper part of the ﬁgure shows the associated product of mean and standard-deviation (σ × μ) metric. We use this metric to evaluate both the average EDPPF and the variance across chips together. Using this metric, we can see that torus plain(4,2) has lower σ × μ than torus plain (8,2). Torus plain(8,1) now ranked third in EDPPF which is better than torus plain (4,4). An evident from the ﬁgure, upon considering the combined effects of mean and variance of EDPPF, the ranking becomes quite different when compared to the no variations scenarios. Designer taking into account several metrics and considering the effects of Vt h and T variations, as we demonstrate, can signiﬁcantly alter design decisions. Hence, this illustrates the importance of considering effects of variations on power and performance during early design exploration. We also compare the simulation time of PolarisPT to Polaris. Due to the Monte Carlo algorithm that is integrated in PolarisPT, the simulation time is about 22 times slower than that of Polaris (500 simulation points). We may decrease that overhead by initially disabling the Monte Carlo feature in our simulator and use mean Vt h as input to Orion and thus obtain the network architectures that have the lowest power consumption or EDPPF. In our example, we selected a set of 15 low power architectures and then reran PolarisPT with the Monte Carlo feature enabled. This allowed us to calculate power and EDPPF distribution, while having the overhead reduced to 1% of its original value. Figure 6. Normalized power considering T and Vt h variation topology variant (buffer size, number of virtual channels) Figure 7. Normalized EDPPF considering T and Vt h variation 4.3. Sensitivity analysis Next we perform sensitivity analysis in the design space, i.e., the effect of the two considered variations are analyzed independently of each other. 4.3.1. Effect of temperature variation only. First, we study the impact of within-die temperature variation on power dissipation of interconnection networks, and compare the results against the experimental results that assume no process variation and a uniform temperature at 80 ◦C. Again, in this simulation, we assume that the temperature variation comes only from power dissipation variation across different interconnection network blocks on the chip (i.e., all the computation and storage blocks on the chip are held at the same, ﬁxed power density for simplicity). The x-axis of ﬁgure 8 presents the ﬁrst eight network architectures or conﬁgurations that have the lowest power consumption when assuming no process variation and uniform temperature. The left and right-hand bars for each of these architectures shows power dissipation in presence of no variations and in presence 123123 of temperature variation only, respectively. The y-axis is the power consumption normalized to the lowestpower dissipating architecture, under no variation effects, which is mesh plain (4,1). From ﬁgure 8, we see that NoC power consumption increases from 2.2% to 6.4% with an average increase of 4% for these eight conﬁgurations, due to the impact of temperature variation across the chip. It is also seen that although the power consumption increases across all eight conﬁgurations upon considering temperature variation, the relative power ranking among them does not vary much for the reasons discussed before. pute new leakage power. This leakage power affects the power density which results in a new temperature estimation. This simulation “loop” typically lasts for 4 to 5 iterations before converging to stable temperature and leakage values. We also studied the dependence, on the initial temperature, of the number of iterations to converge and the ﬁnal temperature reached. Our experiments show remarkable stability where neither the number of iterations nor the ﬁnal converged value depend much on any reasonable starting temperature, as shown in ﬁgure 10. Figure 8. Power comparison Figure 9. EDPPF comparison Next we evaluate the EDPPF among our design space. Figure 9 shows the ﬁrst eight network conﬁgurations that have the lowest EDPPF with and without temperature variation consideration. From the ﬁgure we can see that when assuming uniform temperature across the chip, torus plain torus(8, 2) has the lowest EDPPF. But when considering temperature variation across the chip, torus plain torus(4, 2) actually has the lowest EDPPF. This is because temperature variation has more impact on power for torus(8, 2) than torus(4, 2). From the ﬁgure we can observe that the ranking is changed due to the effects of temperature variation. These results demonstrate that it is important to consider temperature variation at the early design stage as design decisions can change. In our simulation, we assume an initial temperature of 80 ◦C for each router region. Thermal simulation gives us a new temperature which in turn is used to com124124 Figure 10. Thermal simulator initial temperature set on stability analysis 4.3.2. Effect of process variation only. When considering process variation for the power estimation, the power consumption is a distribution rather than a deterministic number as we explained before. Figure 11 shows that the power variance increases as the power consumption rises. Since mesh plain and torus plain have relatively simpler router/topology and lower power consumption, the standard deviation of their power distributions are relatively small as well. From our experimental result, we found that typically torus plain and mesh plain are more tolerant to process variation than the architectures with express cubes or hierarchical links. In our simulation, torus with hierarchical link of interval 2 has the lowest latency, but their power variance is also much higher, making them less tolerant of process variations. This is because the network architectures which have higher performance are also the ones that use a lot of resources (larger buffer sets, more virtual channels, larger switches), thus tend to be worse in tolerating process variations. (see ﬁgure 12). This ﬁgure shows that the 2D torus with hierarchical link of interval 2 with 16 buffer-size and 4 virtual channels – plotted on the right side – has much higher power and spread/variance than the mesh-plain(4,1) plotted on the left. The latency for this mesh is, however, 1758 cycles as opposed to the 53-cycle latency of the said torus for a particular simulation of trafﬁc. Figure 13 shows the EDPPF result when consider process variation. It shows that even though the standard deviation of EDPPF varies for different network architectures, the relative ranking among this ﬁrst eight network architectures do not vary much except for torus plain (4,1) now has lower σ × μ than torus plain (16,1). In summary, we found that it’s important to consider and quickly and accurately estimate the impacts Figure 11. Normalized power vs. Vt h variation Figure 13. Normalized EDPPF for Vt h variation scale, the importance of considering these effects will grow. For future work, we will extend it to study how within die variations and dynamic voltage variations affect power consumption and how these factors affect the convergence of the iterative power estimation. Besides, we will also study how process and temperature variations affect the operating frequency of NoCs. We will explore the validation of our models against lower-level measurements. 6. Acknowledgement The authors would like to thank Vassos Soteriou and Noel Eisley of Princeton University for their help in understanding and using of Polaris, Hang-Sheng Wang of Freescale Semiconductor for his technical support of Orion and valuable suggestions on this work, Li Shang and Yonghong Yang of Queen’s University for their assistance with ISAC thermal simulator, Niraj Jha of Princeton University for insightful technical discussions, and Liqun Cheng and Sadagopan Srinivasan of Intel Corporation for valuable discussions. We also wish to thank anonymous reviewers for their valuable suggestions and comments. This work was supported in part by MARCO Gigascale Systems Research Center and a grant from Intel Corporation. Figure 12. Normalized power for torus with hierarchical link interval 2 (16, 4) and mesh plain (4,1) of both the process and temperature variations together. Otherwise, if considered separately, the design decisions can be signiﬁcantly different from the reality where both factors occur simultaneously [37]. Furthermore, we showed the signiﬁcance of considering both power and performance of designs as both those design properties are very important to practical designs. Although, we have focused on Vt h for process variation, the other sources of variation such as Le f f can be incorporated in our work. 5. Conclusions "
Dual-Channel Access Mechanism for Cost-Effective NoC Design.,"In this paper, we propose dual-channel access mechanism to design cost-effective NoC based on 2D-mesh topology. Compared with traditional single-channel access mechanism, our scheme greatly increases the throughput and cuts down the average latency with reasonable implementation cost, especially when the traffic load is high.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Dual-channel access mechanism for cost-effective  NoC design  Shijun Lin, Li Su, Depeng Jin, Lieguang Zeng  Dept. of electronic and engineering  Tsinghua University  Beijing, China  {linsj05, suli99}@mails.tsinghua.edu.cn; {jindp, zenglg}@mail.tsinghua.edu.cn;   Abstract—In  this paper, we propose dual-channel access  mechanism to design cost-effective NoC based on 2D-mesh  topology. Compared with traditional single-channel access  mechanism, our scheme greatly increases the throughput and  cuts down the average latency with reasonable implementation  cost, especially when the traffic load is high.    INTRODUCTION  I.  As SoC (System-on-Chip) design is entering billiontransistor era, more and more semiconductor IPs are integrated  in one chip  [1]. Traditional bus-based  synchronous  communication architecture has shown its limits in bandwidth,  clock synchronization [2-3] and energy consumption [2, 4].  To meet the communication requirements and cut down the  communication energy consumption of large SoCs, a Networkon-Chip paradigm is emerging as a new design methodology [1,  3-4]. NoC design is different from traditional network design  because of the following three characteristics: 1) Resourcelimited; 2) Latency-sensitive; 3) Traffic predictability.   II. DESIGN OF ROUTER AND NETWORK INTERFACE (NI)   A. Router and NI design in single-channel access mechanism  Router and NI architectures in single-channel access  mechanism are shown in Fig. 1. In this mechanism, every IP  only has one channel to enter the network.   A router contains an arbiter, a crossbar switch module,  multiplexers  (MUX), demultiplexers  (DEMUX), virtual  channel (VC) buffers, access channel (AC) buffers and control  modules such as writing controller (WrC), reading controller  (RdC), sending controller (SC), receiving controller (RC).   A NI contains two processes — sending process and  receiving process. Sending process contains a packetizing  controller (PC), a packetizer, an AC buffer and a SC.  Receiving process contains a depacketizer and a depacketizing  controller (DPC).  B. Router and NI design in dual-channel access mechanism  Router and NI architectures  in dual-channel access  mechanism are shown in Fig. 2. In dual-channel access  mechanism, every IP has two channels to enter the network.   978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.9 DOI 10.1109/NOCS.2008.9 219 217 Figure 1.  Router and NI design in single-channel access mechanism.   Figure 2.  Router and NI design in dual-channel access mechanism.  In the router design, dual-channel access mechanism is  similar to introducing two VCs in the local port (the port which  connects with NI).         NI also contains two processes. In the sending process, to  make sure that data is transported through the network in order,  an access arbiter is used to allocate access channels for data of  different destination IPs. There may be several allocation  methods. In the design, we choose the static allocation method  which is based on the traffic predictability of NoC. In the  method, we pre-allocate the access channels for data of  different destination IPs according to their average traffic load.  The principles of the pre-allocation are as follows: 1) data of  the same destination IP is allocated to the same access channel;  therefore, the transmission order is guaranteed; 2) make sure  that the average traffic loads of both access channels are as  close as possible so as to increase the utilization of access  channels.   In order to support dual-channel access, two PCs, two  packetizers, two AC buffers and a multiplexer (MUX) are used  in the sending process and two depacketizers, a DPC and a  demultiplexer (DEMUX) are used in the receiving process.   In fact, dual-channel access mechanism increases the  injection rate by parallel access method. It guarantees that the  network works in a saturated state most of the time, so it  improves the throughput and reduces the average latency.   III. EXPERIMENT RESULTS AND ANALYSIS  VHDL language is used to design our simulation platform  and localized traffic with a self-similar distributed injection  rate is used to characterize the performance of multiprocessor  platforms.   Other details of the platform are shown in Tab.Ⅰ.  TABLE I.   PARAMETERS IN OUR S IMULATION PLATFORM  Parameter  Pack et length  Topology  Number of IPs  Buffer size of every virtual channel  Buffer size of every access channel  Number of bits in every flit  Total flit number for simulation  Value  16 flits  2D-mesh  16  3 flits  3 flits  32  120000  A. Comparison of performance  Tab.Ⅱ shows the comparison results of NoC performance  between single-channel and dual-channel access mechanism  based on different configuration parameters and traffic loads.    From Tab. Ⅱ , we can see that under any configuration  parameters,  the performance of dual-channel  access  mechanism is similar to the single one when the traffic load is  low, but it improves a lot when the traffic load is high.   B. Comparison of area  Design Compiler tool of Synopsys Company is used to  compare the implementation cost of single-channel and dualchannel access mechanism  in 0.18 µm  technology.  Configuration parameters are also shown in Tab. Ⅰ and  synthesis results are shown in Tab.Ⅲ.   220218 Simulation results in Tab. Ⅲ show that compared with the  improvement in performance, dual-channel access mechanism  has much less increase in area than in performance.   TABLE II.   COMPAR ISON RESULTS OF PERFORMANCE  Note: “F2” is the frequency of all the clocks used among routers, NI and IP; “F1” is the frequency of all  the clock used inside routers; routing clock cycle is the reciprocal of “F1”; “Th” and “La” represents  throughput and latency respectively.   TABLE III.   COMPAR ISON OF AREA  IV. CONCLUSIONS  In this paper, dual-channel access mechanism is proposed  to design cost-effective NoC. This access mechanism increases  the injection rate by parallel access method and thus improves  the throughput and latency performances greatly. Simulation  and synthesis results show that dual-channel access mechanism  increases the throughput and cuts down average latency greatly  with reasonable implementation cost, especially when the  traffic load is high. Thus, dual-channel access mechanism is  more cost-effective than single-channel access mechanism.  ACKNOWLEDGMENT  This work is supported by National Natural Science Fund  (NNSF-90607009).  "
Implementation of Wave-Pipelined Interconnects in FPGAs.,"Global interconnection and communication at high clock frequencies are becoming more problematic in FPGA. In this paper, we address this problem by presenting an interconnect wave-pipelining strategy, which utilizes the existing programmable interconnects fabrics to provide high-throughput communication in FPGA. Two design approaches for interconnect wave-pipelining, using simple clock phase shifting and asynchronous phase encoding, are presented in this paper. Experimental results from a Xilinx Virtex-5 FPGA device are also presented.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Implementation of Wave-Pipelined Interconnects in FPGAs Terrence Mak1 ∗ , Crescenzo D’Alessandro2 , Pete Sedcole1 , Peter Y.K. Cheung1 , Alex Yakovlev2 and Wayne Luk3 1Department of Electrical and Electronic Engineering, 3Department of Computing, Imperial College London, London, UK 2School of Electrical, Electronic and Computer Engineering, Newcastle University, UK Abstract a state-of-the-art FPGA and hardware testing results are reported. Global interconnection and communication at high clock frequencies are becoming more problematic in FPGA. In this paper, we address this problem by presenting an interconnect wave-pipelining strategy, which utilizes the existing programmable interconnects fabrics to provide high-throughput communication in FPGA. Two design approaches for interconnect wave-pipelining, using simple clock phase shifting and asynchronous phase encoding, are presented in this paper. Experimental results from a Xilinx Virtex-5 FPGA device are also presented. 1 Introduction Recently, several novel designs of global communication link have been proposed. These new proposals provide an energy efﬁcient and high throughput alternative to the conventional point-to-point interconnections. Notably, interconnect wave-pipelining [4, 3, 2] was introduced as an effective solution to increase the global interconnection throughput. It offers an opportunity to overcome the everincreasing global interconnection delay problems and can potentially be adopted in FPGAs. This paper presents two different approaches to realize wave-pipelined interconnects in FPGAs. The ﬁrst approach is a synchronous design using clock phase shifting at the receiver end to sample the wave-pipelined data. The second approach is using the asynchronous phase-encoding technique to encode data with differential signaling in two wires. This approach is robust due to the differential signaling and can potentially provide higher throughput. We implemented these two approaches with wave-pipelining in ∗ Email: t.mak@imperial.ac.uk; T. Mak is gratefully acknowledge supports from the Croucher Foundation. 2 FPGA Implementation 2.1 Simple Clock Phase Shifting Clock shifting approach is a simple and efﬁcient approach to implement wave-pipelining. It requires calibration of phase-shifting for the receiver clock after the placement and routing of the link. Sender and receiver blocks are clocked by snd clk and rsv clk respectively. The receiver clock has a phase relationship φ with respect to the sender clock. The testing circuit also comprises of a test pattern generator at the sender and an identical pattern generator at the receiver, which will be used to verify the incoming data. The error results will be registered and counted by the Microblaze processor in the FPGA. For a Xilinx FPGA, clock phase shifting can be realized by using the Digital Clock Manager (DCM) embedded module, which can provide reasonably high resolution phase shifting of the clock. Alternatively, the phase can be controlled by inserting delay logics, such as clock buffers. The advantage of this approach is that it does not require any extra dedicated logic in order to implement the wave-pipelining. However, the design requires proper calibration of the phase. Also, FPGA without embedded phase lock-loop (PLL) or DCM would be difﬁcult to provide exact matching of the clock phase at the receiver end. 2.2 Asynchronous Phase Encoding Phase encoding [1] is an asynchronous signalling approach that the clock is embedded in the encoded data. The concept is employing the order of events on a pair of wires to indicate the bit value. The scheme allows the use of both rising and falling edges for transmission, allowing a natural multiplexing of two channels onto the same link. This 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.32 DOI 10.1109/NOCS.2008.32 215 213 snd_clk snd_data n n/2 n/2 shift register data_rise modulator wire_a wire_b shift register link_clk data_fall clock recovery C Phase−detector Phase−detector full shift register full shift register n/2 n/2 rcv_full n rcv_data Figure 1. Schematic for a dual-channel phase-encoding link. connection with 5.5 ns propagation latency, the maximum frequency of data rate is at around 185 MHz. With phase shifting, there will be more than one data bit traversing the line simultaneously. For frequency at around 350 MHz, which is almost doubles the original maximum frequency. For the phase encoding design, it can achieve a maximum frequency 170 MHz of the link clk at Xilinx Virtex-5 XC5VLX50 FPGA. Since the link transmit data with both rising and falling edges, the link can achieve a transmission rates of 340 Mb/s. For a link with length 75 tiles and with transmission rate 340 Mb/s, it doubles the synchronous transmission rate with wave-pipelining. Incorporation of wave-pipelining design into real applications and aiming to reduce area and power will be our future work. "
Adding Slow-Silent Virtual Channels for Low-Power On-Chip Networks.,"In this paper, we introduce the use of slow-silent virtual channels to reduce the switching power of on-chip networks while keeping the leakage power small. Adding virtual channels to a network improves the throughput until each link bandwidth is saturated. This enables us to reduce the switching power of on-chip networks by decreasing their operating frequency and supply voltage. However, adding virtual channels increases the leakage power of routers as well as the area due to their large buffers; so the runtime power gating is applied to individual virtual channels to eliminate this problem. We evaluate the performance of slow-silent virtual channels by using real application traces, and their power consumption (switching and leakage) is evaluated based on the detailed design of a virtual-channel router placed and routed with a 90 nm technology. These evaluation results show that a network with three or four virtual channels achieves the best energy efficiency in a uniform traffic. In the cases of neighboring communications, a network with two virtual channels is better than the other networks with more virtual channels, because the performance improvement from no virtual channel to two virtual channels is the largest and their frequency and supply voltage can also be reduced well in these cases.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Adding Slow-Silent Virtual Channels for Low-Power On-Chip Networks Hiroki Matsutani1 , Michihiro Koibuchi2, Daihan Wang1 , and Hideharu Amano1 1Keio University 3-14-1, Hiyoshi, Kohoku-ku, Yokohama, JAPAN 223-8522 {matutani,wang,hunga}@am.ics.keio.ac.jp 2National Institute of Informatics 2-1-2, Hitotsubashi, Chiyoda-ku, Tokyo, JAPAN 101-8430 koibuchi@nii.ac.jp Abstract In this paper, we introduce the use of slow-silent virtual channels to reduce the switching power of on-chip networks while keeping the leakage power small. Adding virtual channels to a network improves the throughput until each link bandwidth is saturated. This enables us to reduce the switching power of on-chip networks by decreasing their operating frequency and supply voltage. However, adding virtual channels increases the leakage power of routers as well as the area due to their large buffers; so the runtime power gating is applied to individual virtual channels to eliminate this problem. We evaluate the performance of slow-silent virtual channels by using real application traces, and their power consumption (switching and leakage) is evaluated based on the detailed design of a virtual-channel router placed and routed with a 90nm technology. These evaluation results show that a network with three or four virtual channels achieves the best energy efﬁciency in a uniform trafﬁc. In the cases of neighboring communications, a network with two virtual channels is better than the other networks with more virtual channels, because the performance improvement from no virtual channel to two virtual channels is the largest and their frequency and supply voltage can also be reduced well in these cases. 1 Introduction Many studies have been conducted on Network-onChips (NoCs) [3][5][23] to connect a number of processing cores on a single chip by introducing a packet-switched network structure. NoCs have been utilized not only in highperformance microarchitectures, but also in cost-effective embedded devices mostly used in consumer equipments. These embedded applications usually require low power, since power consumption is the dominant factor on their battery life, heat dissipation, and packaging cost. The overall power consumption consists of dynamic switching power and static leakage power. Switching power is still the major component of the overall power consumption during active operations; thus it should be reduced ﬁrst. In addition, we need to take care of the leakage power, since it has already been consuming a substantial portion of the active power in recent process technologies, and it will further increase while switching power becomes smaller when the technology is scaled down. Different saving techniques have been used for the switching power and the leakage power. For example, clock gating, operand isolation, and dynamic voltage and frequency scaling (DVFS) have been used for switching power reduction, while multi-threshold voltages and power gating have been used for leakage power reduction. Therefore, combinations of these techniques are essential to reduce both the switching and leakage power. In this paper, we introduce the use of slow-silent virtual channels to reduce the switching power of on-chip networks while keeping the leakage power small. This proposal is based on a simple idea: adding virtual channels to a network improves the throughput until each link bandwidth is saturated. This enables us to reduce the switching power of on-chip networks by decreasing their operating frequency and supply voltage without degrading the throughput. However, adding virtual channels increases the leakage power of routers as well as the area due to their large buffers; so the runtime power gating is applied to individual virtual channels to eliminate this problem. Our claim is that the routers with extra virtual channels can reduce their power consumption if they are slow and silent. The other contributions of this paper are detailed evaluations of slow-silent virtual channels in terms of switching and leakage power. These results will answer the question of how many virtual channels are needed to minimize the power consumption for a given trafﬁc pattern. The rest of this paper is organized as follows. Section 2 shows architecture of a typical on-chip router and analyzes its power consumption. Section 3 surveys the low-power techniques on microprocessors and NoCs. Section 4 introduces the slow-silent virtual channels and their sleep control method. Section 5 conﬁrms that adding slow-silent virtual channels reduces the overall power consumption through evaluations, and Section 6 concludes this paper. 2 On-Chip Virtual-Channel Router Prior to discussing low power techniques for on-chip routers, an architecture of a simple on-chip virtual-channel router is presented, and then its dynamic and static power consumption is analyzed with the method proposed in [2]. 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.18 DOI 10.1109/NOCS.2008.18 23 23 INPUT RC VA SA ARB OUTPUT Router parameters p0 p1 p2 p3 p4 RC VA SA XBAR Switch p0 p1 p2 p3 p4 Process  Voltage Speed  ASPLA 90nm 1.0V Max 500 MHz Flit size 64-bit # of ports 3, 4, 5, 6 (configurable) # of VCs 1, 2, 3, 4 (configurable) Buf size 4-flit for each VC Packet len 4-flit data + 1-flit header Figure 1. Router parameters and an example 2.1 Router Architecture For investigation on NoC architectures, we have implemented a wormhole router that has up to six physical channels and up to four virtual channels. We also developed an NoC generator that automatically connects the routers in arbitrary network topologies. The generated NoC is synthesized, placed, and routed with a 90nm standard cell library. Figure 1 illustrates the router architecture used in this paper. This router consists of a crossbar switch (XBAR), an arbitration unit (ARB), and ﬁve input physical-channels (or ports), each of which has two virtual channels. Notice that the numbers of ports and virtual channels are conﬁgurable. Each physical channel consists of a routing computation (RC) unit and up to four virtual channels, each of which has a FIFO buffer for storing four 64-bit ﬂits. The RC unit in this design is very simple, because routing decisions are stored in the header ﬂit prior to packet injection (i.e., source routing); thus routing tables that require register ﬁles for storing routing paths were not needed. This is a typical input buffered router, which has buffers at only its input channels. These FIFO buffers can be implemented with either SRAMs or registers, depending on the depth of the buffers, not the width. We assume that buffers should be implemented with SRAM macros if their depths are more than 32. Otherwise buffers should simply be implemented with registers. Since the depth of the FIFO buffers in this design was only 4, the input buffers were implemented with small registers. As mentioned above, we used a small p × p crossbar and a simple RC unit with no routing tables. As a result, up to 67% of the total router area was used for the buffers when each port had four virtual channels. The router architecture is fully pipelined. Although some 1- or 2-cycle routers have been developed by using some aggressive techniques[6][15], we selected a simple 3-cycle router architecture with no fancy techniques. Thus, our router transfers a header ﬂit through three pipeline stages that consist of a routing computation (RC), a virtual channel and switch allocation (VSA), and a switch traversal (ST). 2.2 Power Analysis To estimate the power consumption of the router mentioned previously, the following steps were performed: 1) a synthesis done by Synopsys Design Compiler, 2) a place 2424 ] W m [ r e w o P n o i t p m u s n o c  7  6  5  4  3  2  1  0 3-port router 4-port router 5-port router 6-port router Standby power (leakage >= 57%) 6543210543210432103210 Number of streams Figure 2. Active power at various workloads (3-6 ports; 4 VCs; 200MHz) and route, including a clock tree synthesis and buffer insertion, done by Synopsys Astro, 3) a post place-and-route simulation, done by Cadence Verilog-XL, to obtain the switching activity information of the router, and 4) a power analysis based on the switching activity done by Synopsys Power Compiler. A 90nm CMOS process with a core voltage of 1.0V was selected for this analysis. Clock gating and operand isolation were fully applied to the router to minimize its switching activity and dynamic power. In step 3), the router was simulated at 200MHz to 500MHz with various ﬁxed workloads (i.e., throughputs), in the same manner as in [2]. A packet stream is deﬁned as intermittent injections of packets that utilize approximately 30% of the maximum link bandwidth of a single router link. Each header ﬂit contains a ﬁxed destination address, while the data ﬂits contain random values as a payload. The number of packet streams injected into the router was changed so as to generate various workloads. In this experiment, up to n streams were applied to a router that has n physical channels (i.e., n ports), and the power consumption at each workload level was analyzed, where 3 ≤ n ≤ 6. Figure 2 shows the results on a router that has up to six physical channels, each of which has four virtual channels, in the case of 200MHz1. The router consumes more power as it processes more packet streams, in the following way: Ptotal = Pstandby + xPstream , (1) where x is the number of packet streams and Pstream is the dynamic power for processing a packet stream. Notice that the router consumed a certain amount of power even with no trafﬁc (i.e., Pstandby ). Figure 3 shows the breakdowns of the standby power for the 5-port router running at 200MHz and 500MHz. Leakage power consumes a substantial portion of the standby power. In particular, the percentage of the leakage power consumed in the virtual channels to the overall standby power is shown in the graph. As shown, the virtual channels consumed up to 49.4% of the standby power due to their FIFO buffers. The remaining power is the dynamic power consumed by the clock tree buffers and the latches inserted for the clock gating; so further reduction of the switching activity would be difﬁcult. 1Although we obtained a lot of evaluation results from these experiments, only some of them are shown here to make our point.     Dynamic Leak (misc) Leak (xbar) Leak (VCs) 29.9% 27.1%  2.5  2  1.5  1 ] W m [ n o i t p m u s n o c r e w o P 49.4% 26.7% 45.9% 44.9% 27.8% 2VC 3VC 4VC 1VC 2VC 3VC 200MHz                              500MHz 4VC  0.5 45.7%  0 1VC Figure 3. Breakdowns of the standby power (5 ports; 1-4 VCs; 200-500 MHz) From the above discussion, we need to reduce Pstream while keeping Pstandby small. In Section 4, we will present a possible solution that meets these requirements by simply adding extra virtual channels running at a lower frequency, each of which can be power-gated if it is not used. 3 Low-Power Techniques Various low-power techniques have been used for microprocessors and on-chip routers. In particular, clock gating and operand isolation are common techniques and they have already been applied to our router design. In this section, we survey the voltage and frequency scaling in Section 3.1, the runtime power gating in Section 3.2, and the dynamic channel and link shutdown of networks in Section 3.3. 3.1 Voltage and Frequency Scaling The voltage and frequency scaling is a power saving technique that reduces the operating frequency and supply voltage according to the applied load. It has been applied to microprocessors[8][16][17], accelerators [12], and network links[19][21]. In [19], the frequency and the voltage of network links are dynamically adjusted based on the past utilization. In [21], the network link voltage is scaled down by distributing the trafﬁc load using an adaptive routing. In [12], the supply voltage of a H.264/AVC decoder is adaptively changed between 1.00V and 0.55V. The voltage and frequency scaling techniques can be classiﬁed into two schemes: dynamic and static. The frequency can be controlled by a PLL frequency divider, and the supply voltage can be adjusted by controlling an offchip dc-dc converter[16]. They are adaptively adjusted in the dynamic scheme, while they are statically conﬁgured at the beginning of each application in the static scheme. The transition time of the clock rate and the supply voltage cannot be negligible in the dynamic scheme (e.g., 10,000 cycles[21] or 50µs[12]); so the frequent transitions sometimes overwhelm the beneﬁts of dynamic scheme. In this paper, the frequency and the voltage of on-chip routers are reduced by enhancing the number of virtual channels. They are adjusted per application basis to eliminate the frequent transitions of the clock frequency, but our technique can also be applied to ﬁner-grain adjustments. 2525 3.2 Runtime Power Gating Power gating is a representative leakage-power reduction technique, which shuts off the power supply of idle blocks by turning off (or on) the power switches inserted between the VDD line and the blocks or between the GND line and the blocks. This concept has been applied to circuit blocks with various granularities, such as processor cores[11], execution units in a processor[10], and primitive gates[22]. In this paper, we focus on the execution unit level, since its granularity is close to a virtual channel in the on-chip router. We need to understand both the negative and positive impacts of power gating when we use it. Actually, a state transition between the sleep and active modes incurs a performance penalty, and turning the power switches on or off dissipates an overhead energy, which means a short-term sleep rather increases the power consumption. In [10], an analytical model of the run-time power gating of execution units in a microprocessor is provided. The following three parameters quoted from [10] affect the performance and energy. • Twakeup : Number of cycles required to charge up the local voltage of a sleeping block. A delay for turning on its power switch is also lumped into the Twakeup value. • Tidledetect : Number of cycles required to detect an idle duration in an active block and decide to shut off the block. A delay for turning off its power switch is also lumped into the Tidledetect value. • Tbreakeven : Number of sleep cycles at least required to compensate for the overhead energy to turn the power switch on and off. The Twakeup value affects the performance (e.g., packet throughput of routers), since a pipeline stall will occur if a new request suddenly comes to a sleeping block. Also, Tidledetect shortens the sleep duration of blocks, since an idle block must stay in the active state for Tidledetect cycles before it decides to go to the sleep mode. A short-term sleep of less than Tbreakeven cycles cannot compensate for the energy overhead of driving a power switch, and the power consumption will be increased; thus the Tbreakeven value determines the beneﬁts of power gating. The Tbreakeven value depends on various parameters, itance. [10] reports that Tbreakeven ≈ 10 based such as the sizes of a power switch and a decoupling capacon the typical parameters of a recent microprocessor. 3.3 Dynamic Link/Channel Shutdown [4] proposes power-aware router buffers based on Drowsy and Gated Vdd SRAMs to regulate their leakage power. [20] provides a thorough discussion about power-aware networks whose links can be turned on and off, in terms of connectivity, routing, wake-up and sleep decisions, and router pipeline architecture. These works are proposed for both off-chip and onchip interconnects, and they assume to use relatively large     buffers in their routers, compared to those in the simple onchip wormhole routers[14]. In [4], the router buffers are constructed with SRAMs. As a sleep control policy for the buffer, a certain portion (i.e., window size) of the buffer is made active before it is accessed. By tuning the window size, the input ports can always provide enough buffer space for the arrival of packets, and the network performance will never be affected[4]. Our light-weight wormhole router uses a small 4-ﬂit buffer for each virtual channel, unlike the routers that use SRAMs for their input and output buffers. Since the buffer depth is shorter than the window size in low-cost routers, the wake-up delay of the buffers directly affects the network performance if the links or channels are dynamically turned on and off. MOSFET[18] and is about 1.6 as reported in [12]. Therefore, adding extra virtual channels can reduce the supply voltage as well as the operating frequency. The dynamic switching power can be expressed as Psw = a · C · f · V 2 , (3) where a is the switching activity, C is the capacitance, and f is the operating frequency. Although adding extra virtual channels increases the effective switched capacitance (i.e., aC ), it can reduce the operating frequency and the supply voltage. Section 5 evaluates the switching power reduction of networks with up to four slow-silent virtual channels whose frequency is adjusted for a given application. 4 Slow-Silent Virtual Channels 4.2 Silent Virtual Channels In this section, we introduce the slow-silent virtual channels to reduce the on-chip network’s overall power by adding extra virtual channels running with lower clock frequencies. We assume that the clock frequency is controlled by the PLL divider, and the supply voltage is adjusted by the off-chip dc-dc converter. They are conﬁgured for each application, but ﬁner-grain adjustment is also possible. The problem of this approach is the increase of leakage power due to the extra virtual channels; thus runtime power gating is applied to each virtual channel to alleviate this problem. We ﬁrst discuss the voltage and frequency scaling of virtual channels. Then we propose a sleep control method and routing strategy for virtual-channel level power gating. 4.1 Adding Slow Virtual Channels The saturated throughput of a network is the data acceptance rate, in which the communication latency goes to inﬁnity. Here, we simply express the saturated throughput of a given network with v virtual channels as Θv . The Θv value highly depends on the network topology, routing algorithm, network size, trafﬁc pattern, and arbitration technique. In this paper, a network simulator is used to obtain the Θv . Assume that a given network has v virtual channels and its performance, Θv , meets the requirements of the target application. When we add extra n virtual channels to the network, the performance improvement can be expressed as Θv+n/Θv . This means that the operating frequency of the network can be reduced by Θv /Θv+n without degrading the original throughput 2 . There is a relationship between the operating frequency and the supply voltage. The gate delay dependence on the supply voltage can be approximated by Tdelay ∝ C V (V − Vth )α , (2) where Tdelay is the gate delay, C is the capacitance being switched, V is the supply voltage, Vth is the threshold voltage, and α is the velocity saturation index in a short channel 2 It is also possible to consider the throughput value at a certain communication latency (e.g., 200 cycles) instead of the saturated throughput. In the previous section, we showed the probability of the switching power reduction with the addition of extra virtual channels. However, adding virtual channels proportionally increases the buffer area of the light-weight wormhole routers mentioned in Section 2. The leakage power consumption is proportional to the device area; thus adding extra n virtual channels to an original network that has v virtual channels increases the overall leakage power by (v + n)/v . Since the leakage power has already become a major component of the power consumption in on-chip routers, the leakage power of extra virtual channels may overwhelm the switching power reduction obtained by the voltage and frequency scaling. The runtime power gating of individual virtual channels can mitigate this problem. Ideally, only the virtual channels occupied by packets are active and consume leakage power when the runtime power gating is applied to each virtual channel. This means that the leakage power consumption is proportional to the data acceptance rate (i.e., throughput), rather than the number of virtual channels. However, the above discussion assumes an ideal case in which the negative impacts of power gating are ignored. 4.3 Sleep Control for Early Wake-Up Delay to activate a sleeping virtual channel (Twakeup ) affects the performance of the network, since a pipeline stall will occur if a new request suddenly comes to the sleeping virtual channel. In this section, we propose a sleep control method that detects the arrival of the packets three cycles ahead, so as to mitigate the negative impacts of Twakeup . Here, a “sender” refers an input physical channel that transmits a packet and a “receiver” refers an input physical channel that receives the packet. Each virtual channel in a receiver monitors the “wakeup” signal, which indicates that new packets (or requests) are approaching to the virtual channel. These wakeup signals are controlled by senders directly connected to the receiver. Figure 4(a) shows the wakeup signals that control the north channel of router 7 from three channels of the neighboring router (i.e., west, north, and east channels of router 4 are senders). Figure 4(b) shows the detail of wakeup signals between the west 2626 R0 R1 R2 R3 input channel (west) R4 WAKEUP 4 4 4 R6 R7 R8 input channel (north) ROUTER (R4) Channel (West)    Routing computation  Wake-up Prediction EMPTY WAKEUP ROUTER (R7) Channel (North) VC0 VC1 sleep VC2 sleep VC3 (a) Network overview (b) West ch. of R4 (cid:1)→ North ch. of R7 Figure 4. Wake-up signals for north channel of R7 (R denotes a router) WAKEUP is asserted DATA_0 is stored in a buffer 3 CYCLES HEAD RC VSA ST RC VSA ST RC VSA ST DATA_0 IB DATA_1 SA IB ST SA IB SA ST IB ST SA IB SA ST IB ST SA ST 1 2 3 4 5 6 7 8 ELAPSED TIME [CYCLE] 9 10 11 12 ROUTER A ROUTER B ROUTER C Figure 5. Router pipeline with early wake-up channel of router 4 and the north channel of router 7. The wake-up control procedures of the receiver and the sender are described separately. Receiver The receiver uses the wakeup signals to decide which virtual channel in the receiver should be activated. That is, the receiver activates a sleeping virtual channel when the wakeup signal to the sleeping virtual channel is asserted by the senders. The receiver also uses the wakeup signals to decide which virtual channel should sleep. The receiver checks the wakeup signals after forwarding a packet, and if the wakeup signal to the empty virtual channel is de-asserted, the empty virtual channel will be power-gated. The performance penalty due to a wake-up delay depends on how early new requests can be detected. Sender To reduce the wake-up delay, the sender notiﬁes the directly-connected receiver that a packet will be arriving at the receiver a few cycles later. Figure 5 shows the router pipeline, in which a packet consisting of a header ﬂit and several data ﬂits is transferred from router A to router C. At cycle 1 in Figure 5, the RC stage of router A detects which input physical-channel of router B is going to be used. In our design, the RC stage of the sender predicts which virtual channel is going to be used in the receiver. The RC stage of a sender performs the following three steps: 1) the output channel of the incoming packet is computed (i.e., receiver is selected); 2) a virtual channel to be used in the receiver is predicted; and 3) the wakeup signal to the predicted virtual channel is asserted to activate the virtual channel. Note that step 1) is the normal RC operation while steps 2) and 3) are newly introduced for our router design. There are some ways to predict it, but we employ a very simple one, which selects a single empty virtual-channel of (i-1)-th hop i-th hop (i+1)-th hop sleep sleep WAKEUP sleep sleep sleep VC layer #0 VC layer #1 VC layer #2 VC layer #3 PACKET A PACKET B PACKET C Figure 6. A routing example with 4 VC layers the least VC number in the receiver. In Figure 4(b), VC2 is the empty virtual channel of the least VC number in the receiver; so the sender selects VC2 and asserts the wakeup signal for VC2 in the receiver. We implemented the prediction unit in the RC stage of our router. The prediction unit was implemented with simple combinational logic and the critical path of the router was not affected. As a ﬂow control, the sender ST stage monitors the status (e.g., active or sleep) of each virtual channel in the receiver, and it forwards data ﬂits to one of virtual channels in the receiver if the virtual channel is ready to receive. As shown in Figure 5, at cycle 5, the ﬁrst data ﬂit (i.e., DATA 0) is stored in a virtual channel in router B. Since the virtual channel must be activated before cycle 5, there is a three-cycle margin after router A asserts the wakeup signal. igated, or it is removed when Twakeup ≤ 3. Otherwise, inIf the prediction is right, the performance penalty is mitcoming packets must wait Twakeup cycles until the allocated virtual channel in the receiver wakes up. Notice that the performance penalty induced by the miss predictions is small, because a miss prediction occurs only when more than two senders select the same virtual channel in the same receiver at the same time3 . 4.4 Routing Design Since active virtual channels consume a standby power, they should be gradually activated according to the trafﬁc load of the network. We designed a packet routing for networks with multiple slow-silent virtual channels, as follows. All packets are injected into the network via the virtualchannel number 0 (VC0). Then the packet increments its virtual-channel number whenever it conﬂicts with other packets on the original virtual channel. Thus only the VC0 is activated at the low trafﬁc load, while the other virtual channels are additionally activated as the trafﬁc load increases (Figure 6). This enables us to achieve a high peak performance with the least standby power of routers. Notice that all virtual channel layers except for the bottom layer (i.e., VC layer #3) can employ arbitrary routing algorithms as far as the bottom layer guarantees the deadlock-freedom by itself. This property is known as Duato’s protocol [7] and it provides a ﬂexibility for the routing designs. 3 If the three-cycle margin is not enough, it is possible to employ a lookahead based sleep control method that detects the arrival of packets ﬁve cycles ahead[14]. However, the method introduces long wakeup signals that cover the twice longer length than normal links between routers cover. 2727 5 Evaluations In this section, we demonstrate that adding slow-silent virtual channels to a network can reduce its switching power while keeping its leakage power small. Assuming that the throughput of a network with no virtual channels (i.e., 1-VC network) meets the requirements of the target application, the voltage and frequency scaling technique is applied to 2-VC, 3-VC, and 4-VC networks. As preliminary evaluations, Section 5.1 and 5.2 evaluate the original throughput and power consumption of these networks with various application traces, respectively. Based on these results, Section 5.3 calculates how much operating frequency and supply voltage can be scaled down. Section 5.4 evaluates the overhead energy and the leakage power reduction of the runtime power gating. Finally, Section 5.5 evaluates the overall power reduction when both the voltage and frequency scaling technique and the runtime power gating technique are applied to these networks. 5.1 Original Performance We ﬁrst introduce the simulation environment used in this experiment, and then we evaluate the network throughput without frequency scaling (i.e., original performance). Simulation Environment A ﬂit-level network simulator written in C++ was used for this experiment. A simple wormhole router mentioned in Section 2.1 was used as the switching element in the simulator. That is, each router had up to four virtual channels, it had three pipeline stages, and each packet consisted of ﬁve ﬂits including one ﬂit header (see Figure 1). The network topology used in this simulation was an 8 × 8 two-dimensional mesh, and dimensionorder routing (DOR)[6] was used for each virtual-channel layer. The simulation time was set to at least 200,000 cycles, and the ﬁrst 1,000 cycles were ignored to avoid distortions due to the startup transient. As for the trafﬁc patterns, we used ﬁve application traces captured from NAS Parallel Benchmark (NPB)[1] as well as [13] and [14]. NPB consists of typical numerical parallel application programs described with MPI library, and it includes various trafﬁc patterns, such as all-to-all and stream fork/join. To conduct evaluations using wide range of trafﬁc patterns, we selected the following ﬁve programs: Block Tridiagonal solver (BT), Scalar Pentadiagonal solver (SP), Conjugate Gradient (CG), Multi-Grid solver (MG), and large Integer Sort (IS). The class of problems was set to “W”, and the numbers of tasks to 64. In addition to these programs, we used uniform random trafﬁc as a baseline for comparison. For each trafﬁc pattern, we evaluated its throughputs at various workloads by linearly changing time span between packet transfers (i.e., time compression). Simulation Results Figure 7(a) shows the throughput (accepted trafﬁc) versus the latency using 64-core uniform trafﬁc on 1-VC, 2-VC, 3-VC, and 4-VC networks. The average hop count is shown in the caption of the graph. The performance increases as the number of virtual channels increases. The performance improvement from 1-VC to 2Table 1. Original throughput [Mﬂit/sec/core] 1VC uniform 56.08 BT.W 92.54 SP.W 88.08 CG.W 70.20 MG.W 92.37 IS.W 57.91 2VC 92.68 131.9 120.3 111.3 132.6 102.6 3VC 116.9 133.0 126.6 124.2 132.5 118.6 4VC 123.2 132.0 125.8 123.3 131.5 125.6 VC is the largest, while that from 3-VC to 4-VC is not so large. A similar result can be seen in IS.W trafﬁc, which contains many all-to-all communications (Figure 7(f)). In the BT.W and SP.W traces, the performance improvement from 2-VC to more is saturated, since their communication patterns contain many neighboring communications insusceptible to the head-of-line blockings (Figure 7(b) and 7(c)). Table 1 summarizes the saturated throughput. Note that we assume that the 1-VC, 2-VC, 3-VC, and 4-VC networks are running at 500.0MHz, 498.8MHz, 497.7MHz, and 493.8MHz, respectively. These frequency values were obtained from the placed and routed design of each network with the same design constraints. 5.2 Original Power Consumption We introduce the energy model of the NoCs used in this experiment, and then we evaluate the power consumption without voltage scaling (i.e., original power consumption). Active Power Model Our energy model takes into consideration the active and the standby power separately. The average energy consumption needed to transmit a single ﬂit from a source to a destination can be estimated as Ef lit = wHaveElink + w(Have + 1)Esw , (4) where w is the ﬂit-width, Have is the average hop count, Esw is the average energy to switch the 1-bit data inside a router, and Elink is the 1-bit energy consumed in a link. We used Synopsys Power Compiler to extract the Esw of the router placed and routed with the 90nm technology. The switching activity of the running router was captured through the post place-and-route simulation of the router operating at 500MHz with a 1.0V supply voltage. The gatelevel power analysis based on this switching activity shows that Esw is 0.144pJ for 1-VC, 0.153pJ for 2-VC, 0.154pJ for 3-VC, and 0.156pJ for 4-VC network, respectively. Elink can be calculated as Elink = dV 2Cwire /2, (5) where d is the 1-hop distance (in millimeters), V is the supply voltage, and Cwire is the wire capacitance per millimeter. Cwire can be estimated using the method proposed in [9], and is 300fF/mm in the case of a semi-global interconnect in the 90nm CMOS technology. For instance, Elink is 0.150pJ when the 1-hop distance is 1mm on average. We assumed 64-bit 64-core networks placed in an 8mm × 8mm chip; thus the size of each tile is 1mm × 1mm. 2828 1VC 2VC 3VC 4VC  2000  1500  1000  500 ] l e c y c [ y c n e t a L 1VC 2VC 3VC 4VC  2000  1500  1000  500 ] l e c y c [ y c n e t a L 2VC 3VC 4VC 1VC 2VC 3VC 4VC  2000  1500  1000  500 ] l e c y c [ y c n e t a L 4VC 2VC 3VC  0  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (a) Uniform trafﬁc (5.33 hops)  0  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (b) BT trafﬁc (2.33 hops)  0  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (c) SP trafﬁc (2.34 hops) 1VC 2VC 3VC 4VC  2000  1500  1000  500 ] l e c y c [ y c n e t a L 1VC 2VC 3VC 4VC  2000  1500  1000  500 ] l e c y c [ y c n e t a L 2VC 3VC 4VC  0  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (d) CG trafﬁc (2.93 hops)  0  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (e) MG trafﬁc (2.94 hops) Figure 7. Original performance ] l e c y c [ y c n e t a L  2000  1500  1000  500  0 1VC 2VC 3VC 4VC  20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (f) IS trafﬁc (5.14 hops) The 1-hop distance d was set to 0.7mm, since a router consumes a 0.3mm × 0.3mm area of the tile. Then we derived Ef lit using Equation 4 with the various parameters mentioned above. Standby Power Model The standby power includes: 1) the leakage power of routers, 2) the dynamic power of clock tree buffers, and 3) the dynamic power of the latches inserted for the clock gating. They were estimated based on a post place-and-route simulation with no trafﬁc load. Evaluation Results Figure 8(a) shows the applied trafﬁc load versus the overall power consumption (left scale) and the leakage power (right scale) with uniform trafﬁc. The overall power consumption at zero trafﬁc load is the standby power. The total power increases as the trafﬁc load increases, while the leakage is constant. The leakage power is proportional to the network logic area; thus a 4-VC network consumes the largest standby power. Similar results can be seen in the NPB traces. These results show that adding extra virtual channels without voltage scaling and runtime power-gating techniques increases the power consumption. We will present the effect of the voltage scaling and the runtime power gating in the following sections. Table 2. Scaled operating frequency [MHz] 1VC uniform 500.0 BT.W 500.0 SP.W 500.0 CG.W 500.0 MG.W 500.0 IS.W 500.0 2VC 301.8 350.1 365.1 314.6 347.4 281.5 3VC 238.8 346.2 346.3 281.3 346.9 243.1 4VC 224.8 346.1 345.9 281.3 346.8 227.8 Table 3. Scaled supply voltage [V] 1VC 2VC 3VC 4VC uniform 1.00 0.77 0.70 0.68 BT.W 1.00 0.82 0.82 0.82 SP.W 1.00 0.84 0.82 0.82 CG.W 1.00 0.78 0.74 0.75 MG.W 1.00 0.81 0.82 0.82 IS.W 1.00 0.74 0.70 0.69 be reduced based on Equation 2, and the results are shown in Table 3. In Section 5.5, we will show the ﬁnal power consumption with scaled frequencies and core voltages. 5.3 Voltage and Frequency Scaling 5.4 Runtime Power Gating Assuming that the throughput of a 1-VC network running at 500MHz meets the requirements of the target application, the frequencies of the other networks can be scaled down, as shown in Table 2. The more performance is improved, the more frequency can be reduced. Therefore, the core voltages of networks with multiple virtual channels can We introduce the leakage power model of the power gating, and then we evaluate the overhead energy and the leakage power reduction of the power-gated virtual channels. The leakage power can be reduced by turning off the power switch of the circuit block if the sleep duration is longer than Tbreakeven . Otherwise, the overhead energy to 2929              800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (a) Uniform trafﬁc (5.33 hops)  0  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] Leakage Total 1VC 2VC 3VC 4VC  800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (b) BT trafﬁc (2.33 hops)  0  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (c) SP trafﬁc (2.34 hops)  0  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (d) CG trafﬁc (2.93 hops)  0  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (e) MG trafﬁc (2.94 hops)  0  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  800  700  600  500  400  300  200  100  0  0 20 40 60 80 100 120 140 Accepted traffic [Mflit/sec/core]  (f) IS trafﬁc (5.14 hops)  0  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC Figure 8. Original power consumption (w/o voltage and frequency scaling; w/o power gating) Table 4. Energy parameters of virtual channel 200MHz 500MHz 1.0V 1.0V 0.052mW 0.052mW 0.078mW 0.194mW 0.67 0.27 0.12 0.12 V supply voltage static energy dynamic energy Eleak Esw L a = Eleak /Esw switching factor turn the power switch on and off would overwhelm the beneﬁt of the power gating. Assuming that the overhead energy is lumped into the leakage power, we modeled the leakage power reduction of the power-gated virtual channel, in the same manner as proposed in [10]. The router was simulated at 200MHz to 500MHz to analyze the power consumption of each virtual channel. Table 4 shows the energy parameters of the router channel, such as the dynamic power, leakage power, and switching activity. These parameters were used in the following leakage power model to estimate that with runtime power gating. As reported in [10], the total energy saved over N cycles (denoted as EN saved ) can be calculated as follows: EN saved = Eleak DIBL mVt N 2 2 aLV 2( 1 2 + CD CS ) , (6) where DIBL is the drain-induced barrier lowering, which is typically close to 0.1, Vt = kT /q ≈ 25mV is the thermal voltage, and m ≈ 1.3 [10]. Also, WH is the ratio of the total area of the power switch to the area of the target block (i.e., a virtual channel), CS is the total switching capacitance of  0  0.05  0.1  0.15  0.2  0.25  0  5  10  15  20 Sleep duration (N) [cycle]  25  30 P o w e r u s n o c m p i t n o [ m W ] NoPG       PG(200MHz) PG(300MHz) PG(400MHz) PG(500MHz) BE=6.3 BE=9.5 BE=12.6 BE=15.8 Figure 9. Leakage power vs. sleep duration the block, and CD is the total capacitance at the local power supply including the power switch. Typically, WH is 0.1, and CD /CS is 0.5 as reported in [10]. As reported in [10], the energy overhead to turn the power switch (denoted as Eoverhead ) can be calculated as follows: Eoverhead ≈ 2 WH a Eleak . (7) Based on Equation 6 and 7, we calculated the average leakage power consumed in a virtual channel during an N cycle sleep, where 0 < N < 100. Again, the average leakage power consumption in this experiment includes the dynamic energy overhead to turn the power switch. The results are shown in Figure 9. “NoPG” stands for the leakage power of the virtual channel without power gating, while “PG” shows the result of the power-gated chan3030                                                                             nel at each operating frequency. As shown in the graph, the average leakage power of the power-gated channel is decreased as the sleep duration N gets longer. Since the leakage power of NoPG is 0.052mW, we can estimate that the Tbreakeven is 6.3 cycles for PG(200MHz), 9.5 cycles for PG(300MHz), 12.6 cycles for PG(400MHz), and 15.8 cycles for PG(500MHz). 5.5 Final Power Consumption Here, we evaluate the overall power reduction when both the voltage/frequency scaling and the runtime power gating are applied to networks with multiple virtual channels. Simulation Environment The energy model used in this section is the same as that in Section 5.2, except for the leakage power modeling. The leakage power was estimated as follows. We ﬁrst performed the same network simulations with the runtime power gating of virtual channels, assuming that the Twakeup and Tidledetect were two and four cycles [14], respectively. From these simulation results, we obtained the length (i.e., number of cycles) of every sleep in every virtual channel during the total execution time. Then, we calculated the average power consumption for each sleep period according to its length, based on the “Leakage power vs. sleep duration” graph shown in Figure 9. That is, a sleep longer than Tbreakeven contributes for reducing the average power consumption, while a sleep shorter than Tbreakeven adversely eats up additional power. Evaluation Results Figure 10 shows the ﬁnal results. Just as in Figure 8, the left scale shows the overall power and the right scale shows the leakage power. As shown in these graphs, the overall power consumption is drastically reduced by the voltage and frequency scaling compared to the original power consumption (Figure 8). When the uniform trafﬁc is injected into the 4-VC network at 56 million ﬂits per second per core, the original network consumes 598mW (Figure 8(a)) while the network with voltage and frequency scaling consumes 250mW (Figure 10(a)); thus up to 58.2% of the total power was saved in this case. Notice that the wakeup delay of a sleeping virtual channel did not affect the performance by the sleep control method that detects the arrival of packets three cycles ahead, because the Twakeup was set to two cycles. In addition, the virtual channel allocation was packed into the RC stage of routers in this simulation for the baseline evaluation; thus the miss predictions did not happened. The leakage power is also greatly reduced. Although the leakage power consumption without runtime power gating is constant (Figure 8), that with power gating consumes only the necessary leakage power (Figure 10). In the 4-VC network with uniform trafﬁc, the leakage power of the original network is 79mW, while that with runtime power gating increases from 12mW to 46mW as the trafﬁc load increases; thus the leakage power was saved by 40.9%-84.9%. In the cases of uniform and IS.W (Figure 10(a) and 10(f)), 3-VC and 4-VC networks achieve the best energy efﬁciency, because their performance can be well improved by adding more than two virtual channels. In these trafﬁc patterns, the 4-VC network consumes 37.8%-40.7% less energy than the 1-VC network at the peak throughput. In the cases of BT.W and SP.W, on the other hand, the 2-VC network achieves the best energy efﬁciency, followed by 3VC, 4-VC, and 1-VC networks. This is because the performance improvement from 1-VC to 2-VC is the largest but those from 2-VC to more are not so crucial, as their trafﬁc patterns contain a lot of neighboring communications. Notice that the energy efﬁciencies of 3-VC and 4-VC are better than that of 1-VC in all cases; thus adding extra virtual channels can reduce the overall power consumption if they are slow and silent. 6 Conclusions The combinations of the switching and leakage power reduction techniques are essential to reduce the overall power consumption of on-chip networks. Adding the slowsilent virtual channels proposed here is a low-power technique that scales down the operating frequency and the supply voltage of routers and alleviates the leakage power by the runtime power gating of individual virtual channels. We also proposed their routing strategy and sleep control method that detects the arrival of packets three cycles ahead. To evaluate the performance and the power consumption of slow-silent virtual channels, we developed a cycleaccurate network simulator that can model the leakage power reduction by the runtime power gating, based on the detailed design of on-chip router with a 90nm technology. The evaluation results show that the 4-VC network with the voltage and frequency scaling and the runtime power gating reduces the leakage power by up to 84.9% and the overall power by up to 58.2% compared with the original network. We also investigated how many virtual channels are needed to minimize the power consumption for a given trafﬁc pattern. In all-to-all communications, the 3-VC and 4-VC networks achieve the best energy efﬁciency and they reduce up to 40.7% energy compared to the 1-VC network, while the 2-VC network is better than the other networks in the cases of neighboring communications due to the less performance improvements from 2-VC to more virtual channels. The concept of slow-silent virtual channels is versatile, and can be applied to other network designs. We are planning to apply this concept to fat tree topologies consisting of multiple trees, each of which can be individually powergated according to the trafﬁc load. That is, adding extra slow and silent trees to the original fat tree would reduce the overall power consumption. We will carefully consider such possibilities as a future work. Acknowledgments A part of this work was supported by Toshiba Semiconductor Company, NII, and JST CREST. We would like to thank VLSI Design and Education Center (VDEC) and Kyoto University for a design ﬂow of ASPLA/STARC 90nm CMOS process. Also, we would like to thank the reviewers for their valuable comments that improved our router design and this paper. 3131  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (a) Uniform trafﬁc (5.33 hops)  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] Leakage Total 3VC,4VC 1VC 2VC 3VC 4VC  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (b) BT trafﬁc (2.33 hops)  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (c) SP trafﬁc (2.34 hops)  50  100  150  200 o T t a l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (d) CG trafﬁc (2.93 hops)  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (e) MG trafﬁc (2.94 hops)  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 1VC 2VC 3VC 4VC  400  350  300  250  200  150  100  50  0  0  0  20  40  60  80  100 Accepted traffic [Mflit/sec/core]  (f) IS trafﬁc (5.14 hops)  50  100  150  200 a o T t l o p w e r [ m W ] o p e g a k a e L w e r [ m W ] 2VC,3VC, 4VC 1VC 2VC 3VC 4VC Figure 10. Final power consumption (w/ voltage and frequency scaling; w/ power gating) "
"Invited Talk 1- Past, Present, and Future Communicating Processors.","Multiprocessor chips are here - and over the next decade they will scale to hundreds of communicating processors per chip. They offer the possibility of computer systems scaling to millions of processors. But perhaps more important is that they will make it possible to design electronic systems using concurrent software to program high-volume multiprocessor chips. Individual processors in these systems will be used to execute conventional software, or to emulate functions normally performed by hardware. And communicating processors - programmed in terms of communicating processes - provide a natural way to unify approaches to hardware and software design.","Invited Talk 1  Past, Present, and Future Communicating Processors  David May  Department of Computer Science, University of Bristol, Merchant Venturers Building, Woodland  Road, Bristol, BS8 1UB, United Kingdom  Abstract  Multiprocessor chips are here — and over the next decade they will scale to hundreds of communicating processors  per chip.   They offer the possibility of computer systems scaling to millions of processors. But perhaps more important is that  they will make it possible to design electronic systems using concurrent software to program high-volume  multiprocessor chips. Individual processors in these systems will be used to execute conventional software, or to  emulate functions normally performed by hardware. And communicating processors — programmed in terms of  communicating processes — provide a natural way to unify approaches to hardware and software design.  Biography  David May is Professor and Head of Computer Science at Bristol University. Before joining the university in 1995,  he worked for 16 years in the microelectronics industry, joining Inmos (now STMicroelectronics) at its formation in  1979. He is well known for his work on innovative microprocessors including the Inmos transputer. He is the author  of over 100 papers and patents, and has given numerous conference presentations.  In 1990 he was elected a Fellow of the Royal Society for his contributions to computer architecture and parallel  computing. David’s current research interests are in microprocessor architecture; system design and verification;  mobile, wearable and pervasive computing. He maintains active relationships with industry and technology  investors, and is on the Technical Advisory Boards of several recent microelectronics design companies. Alongside  this, he has advised on intellectual property issues and acted as an expert witness in litigation.  His most recent interests are as CTO of XMOS (microcomputers), director of Mista (location-based services), and  co-founder of the Bristol Robotics Labs (fun!).  xivxiv                                                  "
Design of Bandwidth Aware and Congestion Avoiding Efficient Routing Algorithms for Networks-on-Chip Platforms.,In this paper we demonstrate that it is possible to design highly efficient application specific routing algorithms which distribute traffic more uniformly by using information regarding applications communication behavior (communication topology and communication bandwidth). We use off-line analysis to estimate expected load on various links in the network. The result of this analysis is used along with the available routing adaptivity in each router to distribute less traffic to links and paths which are expected to be congested. The methodology for Application Specific Routing Algorithms (APSRA) is extended to incorporate these features to design highly adaptive deadlock free routing algorithms which also distribute traffic more uniformly and reduce network congestion. We show that the number of congested links (links exceeding threshold bandwidth) is reduced by up to 100% with this extension. Significant reduction in average delay is also obtained for both synthetic (up to 25%) as well as a real application (12.5%) communication traffic with this extension to APSRA. We discuss architectural implications and area overhead of our approach on the design of a table based NoC router.,"Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Design of Bandwidth Aware and Congestion Avoiding Efﬁcient Routing Algorithms for Networks-on-Chip Platforms∗ M. Palesi† , G. Longo† , S. Signorino† , R. Holsmark‡ , S. Kumar‡ , V. Catania† † Department of Computer Science and Telecommunications Engineering, University of Catania, Italy ‡ Department of Electronics and Computer Engineering, J ¨onk ¨oping University, Sweden Abstract In this paper we demonstrate that it is possible to design highly efﬁcient application speciﬁc routing algorithms which distribute trafﬁc more uniformly by using information regarding applications communication behavior (communication topology and communication bandwidth). We use off-line analysis to estimate expected load on various links in the network. The result of this analysis is used along with the available routing adaptivity in each router to distribute less trafﬁc to links and paths which are expected to be congested. The methodology for Application Speciﬁc Routing Algorithms (APSRA) is extended to incorporate these features to design highly adaptive deadlock free routing algorithms which also distribute trafﬁc more uniformly and reduce network congestion. We show that the number of congested links (links exceeding threshold bandwidth) is reduced by up to 100% with this extension. Signiﬁcant reduction in average delay is also obtained for both synthetic (up to 25%) as well as a real application (12.5%) communication trafﬁc with this extension to APSRA. We discuss architectural implications and area overhead of our approach on the design of a table based NoC router. 1. Introduction One of the main factors which affect the overall performance of a Network-on-Chip (NoC) is represented by its routing algorithm [12]. Routing algorithm determines the path selected by a packet to reach its destination. Routing algorithms can be classiﬁed as deterministic or adaptive. In deterministic routing the path from the source to the destination is completely determined by the source and the destination addresses. In adaptive routing multiple paths from the source to the destination are possible. Thus, generally, it provides packets with a better chance to avoid hot spots or faulty regions in the network as compared to deterministic ∗ This work was supported by the European Commission in the context of the HiPEAC network of excellence (project 004408 and 217068), under the research cluster on High Performance Interconnection Networks for Embedded Applications. routing. Traditionally, routing algorithms have been designed without any reference to the characteristics of the trafﬁc which will stimulate the network. However, in the application speciﬁc domain, which characterize the area of embedded systems, an accurate estimation of the communication trafﬁc is often possible. The embedded system designer has good knowledge of the application (or the set of applications) which will be mapped on the system. This knowledge opens new directions in system optimization like, for instance, the customization of the routing algorithm for a given application. Based on this, APSRA, a methodology to design application speciﬁc routing algorithms for NoC systems was presented in [13]. Starting from the knowledge of the communication topology (i.e., which are the network nodes that communicate and which are the one that do not), the goal of APSRA was to maximize the degree of adaptiveness of the routing function while guaranteeing freedom from deadlock. The basic APSRA does not take into account the communication attributes like the communication bandwidth requirements of different communicating task pairs mapped on different network nodes. Thus, selection of the routing paths to be removed to restrict the routing function and to guarantee deadlock freeness, is carried out in a blind fashion. It is equivalent to assuming that all the communications have the same bandwidth requirements. Such unawareness may lead to a bad distribution of the trafﬁc load over the network. This is particularly true when the range of the bandwidth requirements of different communications is large. Unfortunately, this is a very frequent case in real applications. In [16], for example, the range of communication bandwidth requirements for a Video Object Plane decoder in a MPEG-4 decoder system spans from 16 MB/s to 500 MB/s. The performance of a routing algorithm designed using APSRA methodology will also be greatly affected by the selection function in a router. This function should dynamically choose one among multiple admissible output ports 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.31 DOI 10.1109/NOCS.2008.31 97 97 for a new packet. One of the ways to implement the selection function is to randomly distribute packets to admissible output ports [13]. But this selection policy can lead to a large load imbalance on network links and in actual practice degrade network performance. Online information about trafﬁc density and congestion on paths leading to the packet destination can be useful in selecting the appropriate admissible port. Most of the current approaches use local information regarding usage of buffer associated with an output port in the router (or neighboring router in that direction) as a measure of communication trafﬁc. Some approaches use more elaborate look-ahead strategies for this purpose [3]. These selection strategies give better latency performance, especially when communication volume is high. On-line measurement or estimation of trafﬁc density in a network is costly and difﬁcult. Even costlier and harder is to put in place mechanisms to broadcast trafﬁc information to the required subset of nodes in such a way that the information is current and useful for decision making. Some researchers have proposed a separate network for trafﬁc management task. In the context of NoC, the performance gain achievable with extra infrastructure may not be able to justify its cost. We propose a different strategy for load estimation and design of the selection function. We propose that the application’s communication behavior along with routing function (topology, admissible paths, communication bandwidth between pairs etc.) should be analyzed off-line and selection probabilities should be assigned to each admissible output port for packet coming from a certain input port. For example, let a router has two admissible output ports (say East port and North port) with selection probabilities 0.75 and 0.25 for a packet coming from West port and destined for a particular destination address. Then the probability that the packet will be forwarded through East port is three times higher than through North port. This weighted selection policy can help to distribute the trafﬁc more uniformly over the network as compared to the selection policy in which output ports were selected uniform randomly. The above two considerations motivate this work and our proposal for improvement of APSRA methodology. As the trafﬁc characteristics of a communication node pair is generally different from that of another pair, they should be distinguished. For this reason, we believe that emphasizing the role of communication bandwidth requirements during the design of the routing algorithm design adds a new degree of freedom in system performance optimization. The rest of the paper is organized as follows. In the next section we brieﬂy present research related to our work. Section 3 and 4 describe our two extensions to improve trafﬁc distribution in NoC platforms. In Section 5 we describe simulation experiments to demonstrate the improvements in performance as a result of our proposals. Section 6 discuss Figure 1. Routing and Selection blocks of a router. implications of our proposal to NoC router design and its cost. The paper is concluded in Section 7 by listing our contributions and some possibilities of future work. 2. Related Work An adaptive routing algorithm can be seen as the cascade of two main blocks which implement an adaptive routing function and a selection function (a.k.a., selection policy or selection strategy) respectively as shown in Fig. 1. First, a routing function computes the set of admissible output channels towards which the packet can be forwarded to reach the destination. Then, a selection function, is used to select one output channel from the set of admissible output channels depending on dynamic network conditions and/or locally stored information. Both the blocks have an important impact on overall network cost and performance and will constitute the topic of this paper. Regarding routing functions, many proposals for wormhole-switched networks have been presented in the literature [4, 7, 15]. Glass and Ni in [7] propose a turn-model for designing wormhole routing algorithms for mesh and hypercube topologies that are deadlock and livelock free. This model has been later utilized by Chiu in [4] to develop the Odd-Even adaptive routing algorithm for meshes without virtual channels. In comparison with the turn-model, the degree of routing adaptiveness provided by the model is more even. An application speciﬁc routing algorithm named APSRA has been proposed by Palesi et al. in [13]. APSRA exploits communication information to maximize the adaptivity while ensuring deadlock free routing. In [8] Hansson et al. propose an approach to couple routing and mapping of cores to minimize the network required to meet the constraints of the application. Similarly to [13] the routing is computed on the basis of the application but it is limited to the class of deterministic routing algorithms. Regarding selection functions, in [14], Schwiebert and Bell presented a detailed simulation study of various selection functions for several fully adaptive wormhole routing algorithms for 2D meshes. The obtained results show that the choice of selection function has a signiﬁcant effect on the average message latency and saturation behavior. An analysis of several selection functions in order to evaluate 9898 their inﬂuence on network performance has been carried out by Martinez et al. in [11]. Increasements in network throughput (up to 10%) and in latency when network is close to saturation (up to 40%) have been observed. Hu and Marculescu in [10] propose a routing scheme called DyAD which combines the advantages of both deterministic and adaptive routing schemes. The router works in deterministic mode when the network is not congested, and switches to adaptive mode when the network becomes congested. 3. Bandwidth Awareness and Deadlock Free Routing Function 3.1. Background For a given routing function and a given network topology it is possible to build a corresponding channel dependency graph (CDG) [5] which represents the available paths in terms of sequence of network channels. The CDG is a directed graph whose nodes are the network channels and whose edges represents direct dependencies between these channels. There is a direct dependency between two channels, li and l j , if the routing algorithm allows l j to be used immediately after li by messages destined to some node of the network. The concept of application speciﬁc channel dependency graph (ASCDG) was introduced in [13]. The ASCDG is a subgraph of the CDG, obtained by exploiting communication information using APSRA. An edge in CDG between channel li and l j is removed if no communication in the application will use it. In [13] a heuristic was proposed to break all the cycles in such a way to minimize loss in routing adaptivity. In the next section, we present a new technique to break cycles in the ASCDG which is bandwidth-aware. That is, communications bandwidth information is used to select which application speciﬁc channel dependency to remove. The aim is to uniformly distribute trafﬁc over the network. More precisely, the basic idea is to allocate more routing paths (i.e., give more adaptivity) to communications characterized by higher communication bandwidth demands. In addition, we propose a recovery procedure that reallocates communication paths in such a way that communication load does not exceed networks channels capacity. 3.2. Problem Formulation Simply stated, for a given application and a given network topology, the goal is to generate a routing algorithm which is strongly adaptive and spreads the trafﬁc over the network in such a way that the communication trafﬁc of any link will not exceed its capacity (maximum sustainable bandwidth). To formulate the problem more formally, we borrow the following terms from [13]. The Communication graph, CG = G(T ,C), is a directed graph, where T is the set of tasks and C is the set of commuFigure 2. Effective bandwidth for a communication from node ns to node nd at 100 MB/s assuming a fully adaptive minimal routing. nications. Each communication ci, j = (ti , t j ) ∈ C connects task ti ∈ T to task t j ∈ T . For a communication c ∈ C, the function B(c) returns the bandwidth requirement of c. This is the minimum bandwidth that should be allocated by the network in order to meet the performance constraints for communication c. The Topology graph, T G = G(N , L), is a directed graph which models the network topology. N is the set of netli, j = (ni , n j ) connects node ni ∈ N to node n j ∈ N . Given a work nodes, and L is the set of network channels. Channel channel l ∈ L, the function Ca p(l ) returns its capacity. The Mapping function, M : T → N , maps tasks to network nodes (e.g., if M(ti ) = n j then task ti is mapped on node n j of the network). As we are dealing with adaptive routing, the required bandwidth for communication c is split over multiple paths. For the sake of example, consider Fig. 2 which shows a 4 × 2 mesh-based network topology. Let us suppose that communication c = (ts , td ) requires a bandwidth of 100 MB/sec and that the routing function allows all the minimal paths from node ns = M(ts ) to node nd = M(td ) (four paths in total). The load is distributed as shown in Fig. 2, which reports, for each network channel, the effective bandwidth (E B) and the total number of paths associated with each channel. Formally, the effective bandwidth of a channel l ∈ L due to a communication c ∈ C can be computed as: E B(c, l ) = B(c) × |PT (c, l )| |P (c)| where P (c) denotes the set of minimal paths admitted by the routing function for communication c. PT (c, l ) = {P ∈ P (c) : l ∈ P} is the pass through link set, that is the set of paths of c which contain the link l . Finally, we indicate with AB(l ) the aggregate bandwidth of l which is computed as: E B(c, l ). AB(l ) = ∑ c∈C Using these deﬁnitions, the bandwidth-aware routing algorithm problem should meet the following constraint. 9999 3 2 1 BreakCycles ( ASCDG : application specific CDG , C : set of communications , P : set of admissible paths ) { w h i l e ASCDG is not acyclic d o { D ← GetCycle(ASCDG) ; cost ← ∞ ; f o r d ∈ D { i f ¬∃ c ∈ C : P (c) 7 4 5 6 8 Given a communication graph CG, a topology graph T G and a mapping function M , ﬁnd a routing function R which is deadlock-free such that: ∀l ∈ L ⇒ AB(l ) ≤ Ca p(l ), that is, the communication load of any channel, l , must not not exceed its capacity Ca p(l ). (1) 3.3. Bandwidth Aware Routing Algorithm A cycle in the ASCDG is a succession of application speciﬁc direct dependencies D = {d1 , d2 , . . . , dn }, where d ∈ D is a pair (li , l j ) with li , l j ∈ L. The problem is to select the most appropriate dependency to be removed to break the cycle D. Removing a dependency means to remove all paths which form that dependency. As soon as a path is removed, the fraction of bandwidth it transports must be redistributed over the remaining paths. The idea we propose in this paper is to remove the dependency d such that the overhead of bandwidth that should be allocated to the remaining paths is minimized. Formally, let us indicate with PT 2 (c, d ) the pass through dependency set, that is the set of paths of c which use the dependency d = (l1 , l2 ): PT 2 (c, d ) = PT (c, l1 ) ∩ PT (c, l2 ). Let d be an application speciﬁc direct dependency. To remove d all the paths of any communication c which use d must be removed. For communication c the aggregated bandwidth to be redistributed is [B(c)/|P (c)|] × |PT 2 (c, d )|. This bandwidth is redistributed between the |P (c)| − |PT 2 (c, d )| remaining paths which do not use the dependency d . Based on this, the dependency to be removed is the d ∈ D such that the cost function: B(c) × |PT 2 (c, d )| cost (d ) = ∑ |P (c)| × (|P (c)| − |PT 2 (c, d )|) (2) c∈C is minimized. This ensures that the load on paths which use dependency d is redistributed such that it results in minimum increase in load on alternative paths. The breaking cycles algorithm is reported in Fig. 3. For each cycle of the ASCDG, only the channel dependencies that, if removed, do not cause reachability problems, are considered. This check is performed by assuring that there does not exist any communication whose all routing paths traverse such channel dependency (line 9). Thus, the channel dependency, d , which minimizes the cost function (2) is selected and removed from the ASCDG (line 16). Then, all the routing paths which use d are removed from the set of admissible paths (line 17). (cid:8) (cid:8) 3.4. Bandwidth Reallocation Using the procedure discussed in the previous subsection, we obtain a routing function which is deadlock free 9 6 2 3 4 7 8 1 BandwidthRealloc ( L : set of links , C : set of communications , t hreshol d : integer ) { P : set of admissible paths , 5 w h i l e ∃ l ∈ L : AB(l ) > t hreshol d d o { rem f l ag ← f al se ; Sort links in L = {l1 , l2 , . . . , ln } in descending order of load . That is , such that AB(li) > AB(li+1 ), i = 1, 2, . . . , n − 1 ; f o r l ∈ L { f o r c ∈ C : PT (c, l ) (cid:12)= /0 { pat hs2rem ← pat hs2enr ← /0 ; i f f o r P ∈ P (c) { i f ∃ l ∈ P : AB(l ) > t hreshol d pat hs2rem ← pat hs2rem ∪ {P} ; e l s e pat hs2enr ← pat hs2enr ∪ {P} ; i f pat hs2enr (cid:12)= /0 { rem f l ag ← t rue ; f o r P ∈ pat hs2rem { i f ∃ P (cid:8) ∈ pat hs2enr : ∃ l b r e a k ; P (c) ← P (c) \ {P} ; |P (c)| > 1 { (cid:8) ) > t hreshol d (cid:8) ∈ P : AB(l } (cid:8) 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 } } } } } 26 27 28 29 30 31 32 33 34 } 35 36 37 } i f ¬rem f l ag { show ( ""Not able to reallocate paths to meet the required threshold."" ) ; r e t u r n ; } Figure 4. Bandwidth reallocation algorithm. are repeated until the load on each link does not exceed the threshold. This procedure aborts if the path elimination step requires to remove a path which is unique for a certain communication. 4. Load Balancing Selection Function To be effective, a good routing function must be coupled with an effective selection function. In fact, selection schemes strongly affect the overall performance of any adaptive routing algorithm [11, 14]. Generally, selection policies take decisions based on on-line measurement or estimation of trafﬁc density. However, such an estimation is a costly and difﬁcult task. The idea behind our proposed selection policy can be summarized by means of an example. Let us consider again 101101 Fig. 2. Let us suppose that all the four minimal paths from node ns to node nd are admitted by the routing function. When ns receives a header ﬂit destined to nd , the routing function returns, as a set of admissible output channels, the set {east , sout h}. Now, let us suppose that the router in node ns is aware of the number of admissible paths to reach node nd starting from channel east and sout h respectively. In our example, there are three paths from east and one path from sout h. So, the selection policy should use the east output channel with higher probability than sout h output channel (e.g., use east port with probability 0.75 and sout h port with probability 0.25). Formally, let ξ be a uniformly distributed random variable in the interval [0, 1], and {l1 , l2 , . . . , ln } the set of admissible output channels returned by the routing function, then the selection function is deﬁned as: S(l1 , l2 , . . . , ln ) = li , i : ξ ∈ [ Pr{l j }, Pr{lk }], where Pr{l} indicates the probability to select output channel l , which is proportional to the number of admissible paths starting from l and that can be used to reach the destination. Of course, these probabilities are computed off-line and stored into the router as discussed in Section 6. i−1∑ i∑ k=1 (3) j=1 5. Experiments and Results We evaluate the proposed approach on both synthetic and real trafﬁc scenarios. As synthetic trafﬁc scenarios, we consider uniform, transpose, bit-reversal, shufﬂe, butterﬂy, and hot-spot [6]. For them the bandwidth for each communicating pair has been randomly generated between 10 and 100 MB/sec. As a more realistic communication scenario we consider a generic MultiMedia System (MMS) which includes an H.263 video encoder, an H.263 video decoder, an mp3 audio encoder and an mp3 audio decoder [9]. The communication graph of MMS is depicted in Fig. 5. It has been partitioned into 40 distinct tasks which have been mapped on a 5 × 5 mesh-based NoC using the mapping technique proposed in [2]. In the following we refer to APSRA as the approach proposed in [13], APSRA-BW as the variant of APSRA using the heuristic presented in Subsection 3.3, and APSRABWL as the augmented version of APSRA-BW with the bandwidth reallocation procedure discussed in Subsection 3.4. Let us start by showing the effectiveness of the proposed approach in uniformly distributing the trafﬁc over the network. To do this, we use as a metric the standard deviation of the aggregate bandwidth on the network links. Using this metric, we compare APSRA, APSRA-BW, and APSRABWL on a 8 × 8 mesh based NoC under different trafﬁc scenarios. For APSRA-BWL, we ﬁx the threshold to 90 percent of the maximum aggregate bandwidth when fully adaptive minimal routing is used. For each trafﬁc, Table 1 Figure 6. Adaptivity exhibited by Odd-Even and by routing algorithms generated by APSRA, APSRA-BW, and APSRA-BWL under different trafﬁc scenarios. l d o h s e r h t e h t i g n d e e c x e s k n i l k r o w t e n f o r e b m u N 30 25 20 15 10 5 0 APSRA APSRA−BW APSRA−BWL 327.464 425.464 523.464 Threshold (MB/s) 621.464 719.464 Figure 8. Absolute number of network links which exceed the threshold when APSRA, APSRA-BW, and APSRA-BWL are used. of the routing function as shown in Fig. 6. It is interesting to observe that, for some trafﬁcs, like bit-reversal and shufﬂe, the adaptivity of APSRA-BW is higher than that of APSRA. Although the main objective of APSRA is the maximization of adaptivity, the heuristic used to break cycles immediately stops when the ﬁrst solution is found. As can be observed, the average adaptivity still remains much higher as compared to that of Odd-Even [4]. 9 × 9 mesh based NoC under uniform trafﬁc for both the Fig. 7 shows the aggregate bandwidth on the links of a routing algorithm generated by APSRA and by APSRABWL. The threshold has been ﬁxed to 550 MB/sec. As can be observed, when APSRA is used, the aggregate bandwidth in several link exceeds the threshold. If this threshold represents the network link capacity, such bandwidth overheads translates into local network congestion. Due to back pressure mechanisms along with the wormhole switching techniques, this propagates through the network and degrades network performance. Figure 5. Communication graph of the MultiMedia System (MMS). Table 1. Percentage reduction of standard deviation of the aggregated bandwidth on network links. Trafﬁc Uniform Bit-reversal Butterﬂy Shufﬂe Transpose1 Transpose2 Hot-spot C Hot-spot TR MMS Average APSRA-BW APSRA-BWL 25% 27% 19% 23% 0% 2% 18% 19% 0% 2% 0% 2% 10% 12% 5% 10% 5% 5% 10% 12% reports the reduction in percentage of standard deviation of the aggregated bandwidth in network links when both APSRA-BW and APSRA-BWL are used. As can be seen, the proposed heuristic to break cycles of the ASCDG allows better distribution bandwidth across the network. There are some situations, in which there is not any reduction in standard deviation. This is the case of transpose and butterﬂy trafﬁc in which the ASCDG is acyclic and the cutting edge heuristic does not take place. On average the standard deviation of the aggregated bandwidth in network links decreases by 10%. An additional improvement of 2% is obtained when the bandwidth redistribution procedure is used. On the other side, as discussed in Subsection 3.4, the elimination of some routing paths operated by the bandwidth redistribution procedure, negatively affects the adaptiveness 102102             APSRA APSRA-BWL Figure 7. Aggregate bandwidth per link for a 9 × 9 mesh-based NoC under uniform trafﬁc. Routing algorithm used is generated by APSRA (top) and APSRA-BWL (bottom). Fig. 8 shows the absolute number of network links which exceeds a given threshold when APSRA, APSRA-BW and APSRA-BWL are used. As can be observed, both APSRABW and APSRA-BWL allows to reduce the number of bandwidth violations as compared to APSRA. On average, the number of links exceeding the threshold when APSRABWL is used, is about half of that obtained by APSRA. In particular, APSRA-BWL allows to meet bandwidth constraints which are almost 30% and 20% more stringent as compared to APSRA and APSRA-BW respectively. Now, we evaluate the different routing algorithms in terms of average delay1 . Noxim [1] is used as NoC simulation platform. Poisson packet injection distribution is used for synthetic trafﬁc scenarios whereas self-similar packet injection distribution is used for MMS scenario (self-similar trafﬁc has been observed in the bursty trafﬁc between onchip modules in typical multimedia applications [17]). With exception made for MMS, whose communications bandwidth information are shown in Fig. 5, the bandwidth of the 1Delay is deﬁned as the time (in clock cycles) that elapses from the occurrence of a header ﬂit injection into the network at the source node to the occurrence of a tail ﬂit reception at the destination node. Figure 9. Percent average delay reduction obtained when APSRA-BW and APSRA-BWL are used taking APSRA as a baseline. communicating pairs are randomly generated between 10 and 100 MB/sec. Taking APSRA as baseline, Fig. 9 shows the average delay reduction in percentage when APSRABW and APSRA-BWL are used. As can be observed, excluding transpose trafﬁc, on average the percent delay reduction is over 15% and 20% for APSRA-BW and APSRABWL respectively. 103103 APSRA APSRA−BW (sel=RND) APSRA−BW (sel=LB) APSRA−BWL (sel=RND) APSRA−BWL (sel=LB) 1000 900 800 700 600 500 400 300 200 100 ) l s e c y c ( l y a e d e g a r e v A 0 10−25 10−50 10−75 10−100 Band range (MB/s) 10−125 10−150 Figure 10. Average delay variation under uniform trafﬁc for different ranges of communication bandwidth. Fig. 10 shows the average delay variation under uniform trafﬁc for different ranges of communication bandwidth. That is, the bandwidth for each communicating pair has been randomly generated between the lower and upper bound reported on the x-axes. In this experiment both the random selection policy (RND) and the load balancing selection policy (LB) have been used to distinguish the effect of the selection policy. Once again, APSRA-BW and APSRA-BWL outperform APSRA. For a given average delay, APSRA-BW and APSRA-BWL are able to sustain higher bandwidth communication trafﬁc than APSRA. As can be observed, the improvements are signiﬁcant when the range of bandwidth is larger than 10-75 MB/s. APSRABWL increases the communication bandwidth range by approx. 25% before the network starts saturating. Finally, Fig. 11 shows the link utilization under uniform trafﬁc for APSRA and APSRA-BWL. Link utilization values are discretized by three levels: low (white), medium (gray), and high (black). As can be observed, when APSRA-BWL is used links utilization is more evenly distributed as compared to APSRA. For instance, looking at link utilization when APSRA is used, there are several heavily utilized links (black) and many low utilized links (white). When APSRA-BWL is used, trafﬁc ﬂows responsible for the high utilization of some links, are redistributed in favor of low utilized links. This is conﬁrmed by the higher number of medium utilized links when APSRA-BWL is used. 6. Implications for Router Architecture Fig. 12 shows an architecture of the proposed router for the case of a mesh network topology and minimal routing. The top part of the picture shows the top level view of the router, whereas the bottom part shows block diagrams of the modules which implement routing function and selection 104104 function associated to the west input port. The routing function is implemented by means of a routing table. The routing table is addressed by the destination id. An entry of the routing table contains two main ﬁelds: AOC and Pr. AOC encodes the set of admissible output channels that can be used to reach the current destination. If we consider the west input port, AOC is a four bit word whose bits indicates which of the output ports between nort h (N), east (E), sout h (S), and local (L) can be used to reach the current destination. Pr encodes the probability used by the selection function as discussed in Section 4. The number of bits used to encode Pr determines the precision of the selection function. For instance, using three bits, eight probability levels are possible. A possible implementation of the selection function reported in Equation (3) is shown in the bottom right corner of Fig. 12. The connector labeled with 1, is used in several parts of the circuit. It is set when the routing function returns more than one admissible output channels. If it is zero, only one admissible output channel can be used. In this case, the selection logic is bypassed and clock gating is used to prevent the unnecessary activity of unused blocks. The DirEncS block converts the one-hot encode used at the input, to the encode of the selected output channel. If more than one (max two, because we are considering minimal routing) output channels can be used, a selection must be operated. The input pr is shifted left (multiplied) and compared with the current value stored in the linear feedback shift register (LFSR). If it is less, the ﬁrst output channel is selected, otherwise the second one is selected. This selection is, of course, conditioned by the whrt word which encodes the reservation status of the output channels operated by wormhole switching technique. For example, suppose that nort h and east output channels are admissible and nort h should be selected after the comparator. However, if nort h output channel is reserved but east is not, east will be selected. This computation is performed by the DirEncM block which returns the code of the selected output channel. Two table based routers (for 8 × 8 mesh topology networks, and 64-bit, 4-ﬂits FIFO input buffers), one implementing a random selection policy (RND) and the other implementing the load balancing selection policy (LB), have been designed in VHDL and synthesized using Synopsys Design Compiler and mapped on a 90 nm technology library from TSMC. Table 2 reports the silicon area of the main blocks of the routers. The use of LB determines an area overhead on routing function block and selection function block of 18% and 120% respectively. However, as input FIFO buffers dominate the design, the overall overhead is approx. 5%. Therefore, area overhead of the new selection function in context of the whole router area is considered to be small.     APSRA APSRA-BWL 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 63 55 47 39 31 23 15 7 62 54 46 38 30 22 14 6 61 53 45 37 29 21 13 5 60 52 44 36 28 20 12 4 59 51 43 35 27 19 11 3 58 50 42 34 26 18 10 2 57 49 41 33 25 17 9 1 56 48 40 32 24 16 8 0 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 63 55 47 39 31 23 15 7 62 54 46 38 30 22 14 6 61 53 45 37 29 21 13 5 60 52 44 36 28 20 12 4 59 51 43 35 27 19 11 3 58 50 42 34 26 18 10 2 57 49 41 33 25 17 9 1 56 48 40 32 24 16 8 0 Figure 11. Links utilization under uniform trafﬁc for APSRA and APSRA-BWL. Table 2. Silicon area of the main blocks of a table based router for two different selection policies. Block Area (µm2 ) RND LB 910.22 910.22 6648.16 6648.16 40286.23 40286.23 326.69 326.69 2327.98 2327.98 12775.62 15067.39 949.03 2166.19 64223.94 67732.87 Arbiter XBar FIFO WHRT Ctrl Routing Function Selection Function Total Regarding timing, for the LB conﬁguration, the critical path is determined by the following blocks: routing table, LFSR, comparator, DirEncM, Mux2, Mux3, and arbiter. However, the latency is mainly due to access time to the SRAM routing table which is 2.103 ns and 2.111 ns for RND and LB respectively. The contribution of the rest of the logic in the critical path is 0.39 ns and 0.58 ns for RND and LB respectively. 7. Conclusions In this paper we have presented a new approach to design topology-agnostic, highly adaptive bandwidth-aware application speciﬁc deadlock-free routing algorithms for NoCs. The basic idea of the approach is exploitation of communication bandwidth information to customize the routing algorithm for a given application. The approach is divided in two phases. In the ﬁrst phase all the cycles of the ASCDG are removed by means of a heuristic whose main objective is to uniformly spread the load over the network. Then, in the second phase, the routing function is restricted by removing routing paths that cause the overload of some network links. The approach has been evaluated using both synthetic and real trafﬁc scenarios. The results obtained show that the routing algorithm generated by the proposed approach i) is highly adaptive, ii) reduces the variation of load on network links, iii) ensures that the link bandwidth limit is not violated. We also propose a technique to enhance the selection function of an adaptive router asserting selection probabilities based on expected communication demand. Results show that this technique further improve performance. A table based router is the best implementation option for the proposed routing scheme. Although we have used 2D homogeneous mesh topology network for describing and evaluating, the proposed ideas are topology agnostic. It will be interesting to evaluate these ideas for irregular mesh topology as well as other topologies. "
Physical Implementation of the DSPIN Network-on-Chip in the FAUST Architecture.,"This paper presents a physical implementation of the DSPIN network-on-chip in the FAUST architecture. FAUST is a stream-oriented multi- application SoC platform for telecommunications addressing IEEE 802.11a and MC-CDMA standards. The original asynchronous network-on-chip (ANOC) of FAUST has been replaced by the multi-synchronous DSPIN network-on-chip. In this paper, we analyze how the DSPIN network-on-chip, originally designed to support shared memory and multi-processors architectures, can support stream-oriented architectures. The physical implementation of both ANOC and DSPIN are presented. Finally, a comparison between ANOC and DSPIN designs in a 130 nm technology is carried out in terms of area, throughput, packet latency, and power consumption.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Physical Implementation of the DSPIҭ ҭetwork-on-Chip  in the FAUST Architecture  Ivan Miro-Panades1,2, Fabien Clermidy3, Pascal Vivet3, Alain Greiner1  1The University of Pierre et Marie Curie, 75252 Paris, France  2STMicroelectronics, 38921 Crolles, France  3CEA-Leti, MI̱ATEC, 38054 Grenoble, France  {ivan.miro, alain.greiner}@lip6.fr, {fabien.clermidy, pascal.vivel}@cea.fr  Abstract  This paper presents a physical implementation of  the DSPI̱  network-on-chip  in  the FAUST  architecture. FAUST  is a stream-oriented multiapplication SoC platform  for  telecommunications  addressing IEEE 802.11a and MC-CDMA standards.  The original asynchronous network-on-chip (A̱OC) of  FAUST has been replaced by the multi-synchronous  DSPI̱ network-on-chip. In this paper, we analyze how  the DSPI̱ network-on-chip, originally designed to  support  shared memory  and multi-processors  architectures,  can  support  stream-oriented  architectures. The physical implementation of both  A̱OC and DSPI̱ are presented. Finally, a  comparison between A̱OC and DSPI̱ designs in a  130nm technology is carried out in terms of area,  throughput, packet latency, and power consumption.  1. Introduction  Increasing the system performance by scaling the  technology and the clock frequency become more and  more complex due to the lower scalability of the wire  delays. New approaches such as Network-on-Chip  (NoC) architectures and the Globally Asynchronous,  Locally Synchronous (GALS) paradigm tries to solve  the design bottleneck by partitioning the circuit in  small synchronous islands while they communicate  asynchronously. Each  island can be clocked by  independent  clock  frequency,  while  the  communications between neighbor islands are carried  out by the NoC. Moreover, the NoC approach attempts  to solve the bandwidth bottleneck of a central bus by  splitting the communications over a plurality of routers  and links.  A large number of NoC architectures have been  published, but there is very few detailed analysis of  their physical implementation: SPIN [16,10], Terascale [11], Silistix [14], and FAUST [8], Xpipes [17].  A 32-port SPIN NoC has been implemented in [10,13].  However, the architecture is not design-flexible and  does not support the GALS approach because it was  designed as a synchronous centric hard macro. The  Tera-scale  [11] architecture contains an 80-tile  processor architecture interconnected by a NoC. A  mesochronous technique was used to distribute a 4GHz  clock signal over the 275mm² die. However, its  network router takes 0.34mm² in CMOS 65nm, which  is several times larger than the DSPIN router presented  in this paper (when compared at the same fabrication  process) while offering the same type of service. The  Silistix CHAIN network [14] is based on packet  switching using asynchronous QDI 4-rail links and is  composed of basic elements such as muxes, demuxes,  arbiters. The CHAIN architecture allows the GALS  strategy but do not offer a real Network-on-Chip  protocol, neither offer Quality-of-Service features.  The DSPIN [2] network-on-chip is an evolution of  the SPIN [16] architecture, and has been developed by  the  LIP6  laboratory,  in  cooperation with  STMicroelectronics. DSPIN is a 2D mesh distributed  NoC well suited to the GALS approach. Its architecture  is synthesizable on standard synchronous cells library  with neither custom nor asynchronous cells. The  DSPIN architecture was initially designed to support  shared memory multi-processors architectures. In this  work, we present the physical implementation of  DSPIN network in a stream-oriented, multi-application  platform, the FAUST generic architecture, developed  by CEA/LETI [8]. The main goal is to evaluate if a  network architecture optimized for shared memory can  efficiently support stream-oriented applications. In  order  to do  this evaluation, we  replaced  the  asynchronous network-on-chip (called ANOC) from  FAUST chip by the DSPIN network-on-chip.  The FAUST and ANOC architectures are firstly  analyzed in section 2. DSPIN architecture is detailed in  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.35 DOI 10.1109/NOCS.2008.35 139 139               section 3. Section 4 compares  the  two NoCs  architectures and describes the migration from ANOC  to DSPIN. In section 5, the sep-by-step implementation  of FAUST with the DSPIN network is presented.  Finally, in section 6 the ANOC and DSPIN designs are  compared in terms of silicon area, throughput, latency,  and power consumption.   2. FAUST Application  FAUST, which stands for Flexible Architecture of  Unified Systems  for Telecom  is a hardware  demonstration platform for  the 4MORE mobile  terminals. 4MORE [1] is an IST program targeting 4G  baseband modem chips. The FAUST project was  initiated in 2003 for supporting multiple OFDM air  interfaces in a single SoC. FAUST architecture (Figure  1) is composed by processing units interconnected by a  NoC. It also includes an ARM946ES in an AHB  subsystem. The communication protocol between the  functional units is carried out by message passing  through the NoC. Each processing unit contains a  programmable Network Interface Controller, which  contains input and output FIFOs and regulates the  traffic through the network. This regulation is carried  out by credits to synchronize the producer to the  consumer on a self-synchronized data pipeline manner.  NOC1 IF 84 Pads SPort APort EXP RAC JTAG Clk & Reset CTRL Clk , Rst OFDM MOD. ALAM. MOD. CDMA MOD. MAPP. BIT INTER. TURBO CODER CONV. CODER NoC Perf. AHB RAM ARM946 RAM EXT. RAM CTRL RAM IF 58 Pads ROTOR EQUAL. CHAN. EST. CONV. DEC. ETHER NET ETHERNET IF 17 Pads FRAME SYNC. ODFM DEM. CDMA DEM. DEMAPP. DEINTER. TX units AHB units RX units Async/ Sync IF Async node NOC2 IF 83 Pads EXP SPort APort     Moreover, source routing can be used to minimize the  congestion on some links, and thus reduce the packet  latency. The first flit of the packet contains the routing  information and the router uses this “path-to-target” to  decide the correct routing destination. A flit is the  smallest flow control unit of the network. The routing  information is enclosed on 18-bits and two bits encodes  each routing hop as shown in Figure 8a. Hence, the  routing path is limited to nine hops H0 to H8. However,  a path extension mechanism is also proposed to extend  the routing path [6].  ANOC provides two virtual channels per NoC link.  A low latency channel VC0 for real-time applications  and a higher latency and lower priority channel VC1  for best effort traffic.  2.2. AҭOC Implementation  The ANOC design has been implemented in the  STMicroelectronics 130nm technology, using standard  place-route tools (EncounterTM from Cadence). In the  proposed architecture, two challenges need to be  addressed: the physical implementation of the ANOC  router, which is robust QDI 4-phase/4-rail asynchronous  logic [6], and the implementation of the GALS  interfaces [7].  the tool using the reset signal of ANOC router logic  (Figure 3).  Using this pseudo-clock mechanism, asynchronous  logic timing loops are broken, and static timing  analysis of the QDI logic can be performed using  standard tools. Due to the 4-phase protocol, the  pseudo-clock frequency must be equal to 4 times the  asynchronous targeted average frequency. Once the  ANOC router hard macro was available, the standard  abstract and gds files were generated. A pseudosynchronous timing model of the asynchronous ANOC  router was also automatically generated using this  pseudo-clock.  For the GALS interfaces implementation, a softmacro approach was defined. This approach allowed to  perform clock tree balancing with their attached  synchronous unit, and also bring less constraints for  top-level floor-planning.   For top-level, the complete floor-planning was  done in order to place all the hard-macros: ANOC  routers, SRAM memories, ARM946 core (Figure 4).  The place & route was done hierarchically with five  distinct partitions using Encounter tool. Thanks to the  ANOC router hard-macro, no top-level “spaghetti”  routing and the common congestion drawbacks were  observed at all, only parallel routing of ANOC link  signals between ANOC routers was performed. The  timing analysis and optimization of the NoC links was  possible using the pseudo-synchronous timing model  of the ANOC router. For the GALS interfaces, the  timing optimization has been nevertheless more  difficult due  to mix-timing constraints of  these  interfaces [7].  Figure 3 QDI logic optimization with   pseudo-clock  For the ANOC router, a hard-macro approach was  defined in order to re-use the ANOC router all over the  FAUST top floor-plan. This choice obviously allows  proper placing of the ANOC router port signal pins  (North, East, South, West, Unit). The ANOC router  contains robust QDI logic, which is implemented using  standard-cells and specific C-elements from the TAL  library [15], jointly developed by the TIMA laboratory  and CEA-Leti. Due to the un-clocked nature of the  logic, in order to optimize place&route under timing  constraints, a pseudo-clock has been emulated within        compatible with the Globally Asynchronous, Locally  Synchronous approach, where synchronous islands or  subsystems  communicate  asynchronously. Each  DSPIN router  is clocked by  the network-clock  frequency but a phase skew can exist between two  neighbor routers. Moreover, each subsystem can have  its own clock frequency, which can be independent of  the network-clock frequency. Hence, the inter-router  communication  is mesochronous while  the  communication between router and subsystem  is  asynchronous. These communications are carried out  by bi-synchronous FIFOs [3,4,5].   Finally, due to the GALS nature of the chip, the  clock-tree of  the chip was constituted of 27  independent clock trees: one distinct clock tree per  synchronous IP unit. The 27 clock-trees were then  easily generated one-by-one by the tool with neither  timing convergence problems nor floor-planning issues  (clock congestion, and so on).  3. DSPIҭ ҭoC  DSPIN NoC [2] stands for Distributed, Scalable,  Programmable, Integrated Network. It is a wormhole  packet-based NoC, with a 2D mesh topology. The  packets are routed following the X-first deterministic  routing algorithm. With this algorithm, packets are first  routed on the X direction and then on the Y direction.  The routing information on the packets is encoded by  the absolute address of the destination subsystem on  the first flit of the packet. Figure 8b shows the first flit  and the following flits of the packet. DSPIN uses a  generic flit size, which has been tuned to 34-bit flit in  this implementation, providing a payload of 32-bits.  (Y+1,X-1) (Y,X -1) GS BE GS BE E a s t (Y-1,X-1) t s e W South North South North Cluster(Y+1,X) (Y+1,X+1) Cluster(Y,X) (Y,X+1) E a s t t s e W Local Cluster(Y-1,X) (Y-1,X+1) Figure 5. DSPIN architecture  In order to address the GALS issues, the DSPIN  router itself is distributed, and is composed by five  modules. Four of them are placed on the north, south,  east, and west side of the subsystem. Finally, a local  module communicates to the local subsystem through  the Network Interface Controller (NIC). Figure 5  presents the DSPIN architecture and its modules. The  local subsystem and the associated DSPIN router  compose a synchronous cluster. With this approach,  the longest wires are the intra-cluster wires (for  example, from one input module on the west side to  one output module on the east side), and cannot be  longer than the cluster size.   DSPIN  is  a multi-synchronous  architecture  synthesizable with standard cells. Moreover, it is        can be directly extracted from the MSB bits of the  destination address. Thus, the NIC does not require any  configuration.  ANOC, and integrates two of the four GALS interfaces  FIFOs. Therefore, a protocol_conversion module was  designed to interface the FAUST NIC with the DSPIN  router (Figure 9b). This module adapts the flow control  signals, converts the routing algorithm, and integrates  two bi-synchronous FIFOs. The routing algorithm  conversion was implemented with a Look Up Table  (LUT) where the source-routing path of ANOC is  recoded into the (Y,X) destination of DSPIN. This  solution is not optimized as it uses a hard-wired LUT.  However,  this work was  focused on  the  fair  comparison of two NoC on the same architecture and  not on the optimization of the architecture for each  NoC. Otherwise, it would be required to modifying the  NIC of FAUST.  CLK_IP CLK_IP IP NIC IP NIC Synchronous SEND/ACCEPT Synchronous SEND/ACCEPT GALS interface Protocol_conversion LUT Asynchronous SEND/ACCEPT ANOC router DSPIN router Asynchronous SEND/ACCEPT Asynchronous READ/WRITE Mesochronous READ/WRITE 5. DSPIҭ Implementation  DSPIN architecture has been designed to be  synthesizable on standard cells and easily implemented  on a synchronous digital flow. Therefore, neither  custom nor asynchronous cells have been used. The  clock boundaries and the long wires issues have been  analyzed to minimize the timing cloture effort [2].   5.1. Synthesis  We used a hierarchical approach for the physical  synthesis of the FAUST architecture with the DSPIN  NoC. Each cluster was synthesized separately, before  being assembled on the top FAUST architecture. Thus,  no RTL synthesis was performed on the top level. The  design was synthesized using STMicroelectronics  CMOS 130nm low power standard cells.  The timing constraints for the DSPIN routers  synthesis were chosen to take into account the physical  implementation. Thus, the DSPIN long wires (intracluster wires) were constrained with 300ps of  propagation time. Moreover, low power standard cells  with low Vt transistors were uses in conjunction with  clock-gating  techniques  to minimize  the power  consumption.  CLK_NoC 5.2. Floorplanning  a) ANOC IP template b) DSPIN IP template Figure 9. IP integration detail  The FAUST architecture does not follow a regular  2D mesh topology, which is imperative for the DSPIN  NoC. Therefore, some FAUST connections were  rearranged in order to respect a regular mesh topology.  The FAUST mapping topology was designed for a  source  routing algorithm. However, when  the  deterministic DSPIN X-First routing algorithm was  used, some GS routing conflicts appeared, because the  source routing algorithm can avoid using some  congested  links, which  is not possible with a  deterministic routing algorithm. In order to respect the  real-time constraints while avoiding modifying the  mapping topology, the DSPIN BE and GS FIFOs were  dimensioned to 7 words depth to support these routing  conflicts.   Finally, the system performance for the reference  OFDM application described in section 2, were  equivalent for both ANOC and DSPIN networks. A  more detailed and systematic comparison using  synthetic traffic, is described in section 6.  The DSPIN routers are not built using hard macros.  They are placed and routed as standard cells modules.  This property gives to the designer the flexibility to  decide the best shape and position to place the DSPIN  router modules. Hence, the routers shape and position  is constrained using  regions. A  region  is a  floorplanning delimiter that conditions all the cells of a  module to be placed inside the defined area. However,  the region does not define an exclusive area, because  cells of other modules can be placed inside this area.  The DSPIN routers were designed using five regions,  one for each module (North, South, East, West, and  Local). The placement density for these regions was  tuned around 70%. Figure 10 shows the FAUST floorplan using DSPIN routers. The clusters areas are  delimited by the colored rectangles while the N, S, E,  W, and L filled boxes denote the North, South, East,  West, and Local DSPIN router modules respectively.   The top left and bottom red boxes are reserved for  the RAC and DART hard macros. However, these  modules are not used by the Matrice application and  they were not implemented. Nevertheless, its area was  reserved for fair comparison.   144144               will be higher  than  the gate delays, a multisynchronous architecture as DSPIN would have higher  packet throughput than an asynchronous one as  ANOC. Fortunately, pipeline stages can be inserted on  the long wires in order to cope with these delays and  improve the throughput, despite of the added latency.  6.3. Packet Latency  The minimal Packet Latency is the end-to-end delay  between the time a packet header enters into the network  and the time it exits the network, assuming no  contention. This path can be decomposed in three parts:  First, Intermediate, and Last latency [12]. The First  latency is the time it takes the packet to cross the GALS  interface and the first router. The Last latency is the time  it takes the packet to cross the last router and the GALS  interface. The Intermediate latency is the time it takes  the packet to cross an intermediate routers between the  first and the last router as shown in Figure 12.  interfaces (ANOC requires 4 FIFOs while DSPIN  requires 2). The total DSPIN area is 33% smaller than  the ANOC area.  Table 2. ANOC and DSPIN router area  comparison  Router  AҭOC  0.211 mm²  Interface GALS  0.070 mm²  Clock tree  Total  0.000 mm²  0.281 mm²  DSPIҭ  0.161 mm²  0.024 mm²  0.0016 mm²  0.187 mm²  6.2. Throughput  The throughput on the ANOC router depends on  the fabrication process, on the voltage applied, and on  the temperature condition. The throughput of ANOC is  160Mflit/s in worst-case and 220Mflit/s in nominal  conditions. Moreover, the asynchronous circuits have  the advantage to auto-adapt its performances to the  process, temperature, and voltage of the circuit.   The DSPIN router throughput depends on the clock  frequency. Its throughput is one flit per clock cycle  (1Mflit/s for a clock frequency of 1MHz). The  throughput for the DSPIN router is 289Mflit/s in  worst-case and 408Mflit/s in nominal-case.  Table 3 shows the throughput comparison between  the ANOC and DSPIN  routers. On a  real  implementation, the ANOC will operate on its nominal  conditions 220Mflit/s while the DSPIN router should  be clocked not far away from the worst-case condition  289MHz to improve the fabrication yield.  Table 3. Throughput comparison  Throughput on worst-case  conditions  Throughput on nominal  conditions  AҭOC  DSPIҭ  ~ 160Mflit/s  ≤ 289Mflit/s  ~ 220Mflit/s  ≤ 408Mflit/s  In terms of critical path analysis and cycle time for  long distance communications, the ANOC critical path  crosses four times the long wires in between ANOC  routers while DSPIN crosses just one time. This comes  from the fact that ANOC uses a 4-phase QDI  asynchronous protocol. Thus, the long wire delay has  four times higher influence on the ANOC router rather  than on the DSPIN router. Consequently, on deep  submicron technologies where the interconnect delays                        The ANOC intermediate router latency is lower  than the DSPIN one. This comes from the fact that the  DSPIN routers resynchronize the data packets on each  hop. To obtain the same intermediate router latency,  the DSPIN router should be clocked to 367MHz.  Moreover, the first and last router latency is better  optimized on the DSPIN side.  Table 5 shows the latency of the ANOC and  DSPIN router for 5 and 9 hops path. It is clear that the  ANOC router have lower latency than the DSPIN  router for  low clock frequencies. However,  the  latencies are quite similar when the DSPIN clock  frequency increases.  Table 5. Latency analysis for 5 and 9   hops path  AҭOC  DSPIҭ  AҭOC  DSPIҭ  F = 150 MHz  F = 250 MHz  80.00 ns  106.66 ns  68.00 ns  64.00 ns  106.66 ns  173.30 ns  96.00 ns 104.00 ns  Latency for 5  hops path  Latency for 9  hops path  6.4. Power Consumption  In order to analyze the power consumption of the  NoC  architectures,  back-annotation  gate-level  simulations were performed on both architectures. The  back-annotation data was extracted from the physically  implemented architectures using typical conditions.  Both architectures computed the same OFDM frame  demodulation using real functional traffic in order to  compute accurate power consumption estimations.  Table 6 shows the detailed power consumption  analysis for both architectures. The GALS interface  power corresponds to the power consumption of the 4  FIFOs on the GALS interface module of ANOC, and  the 2 FIFOs on the protocol_conversion module of  DSPIN.   Table 6. Power consumption comparison  AҭOC  DSPIҭ   F = 150 MHz F = 250 MHz  Router  2.07 mW  2.89 mW  4.85 mW  GALS interface  1.62 mW  0.56 mW  0.81 mW  Clock tree  0.00 mW  2.44 mW  4.73 mW  Total  3.69 mW  5.89 mW  10.39 mW  The power consumption of the ANOC router is  lower than the DSPIN router even at 150 MHz. This  comes from the fact that DSPIN uses larger FIFOs (7  words depth compared to 2 words depth on ANOC).  On the other hand, the GALS interface on DSPIN is  more efficient that the one on the ANOC. Finally,  DSPIN requires a clock tree that consumes as much  power as the router itself. Consequently, the total  power consumption of ANOC is at least 37% lower  than the one of DSPIN for the same application.  7. Conclusion  A physical implementation of the DSPIN networkon-chip on  the generic, stream-oriented, FAUST  platform has been presented. The multi-million gates  FAUST architecture using the DSPIN network was  physically implemented up to mask layout. The DSPIN  architecture was adapted to manage stream-oriented  communications. This adaptation was simple because  both DSPIN and ANOC respect the OSI reference  model. A dedicated wrapper has been designed to  adapt the ANOC packet format into the DSPIN format  without modifying the network interface controllers  defined by the FAUST architecture. We demonstrated  that a network architecture designed to support shared  memory multi-threaded applications can efficiently  support stream-oriented applications. The DSPIN  implementation has similar performances as the ANOC  implementation in terms of silicon area, throughput,  latency, and power consumption. The area of DSPIN is  33% smaller than the area of ANOC. The maximum  sustained throughput of DSPIN is 31% higher than  ANOC throughput, considering that ANOC operates at  nominal conditions and DSPIN  in worst-case  conditions. In terms of packet latency, DSPIN should  be clocked at least to 367 MHz to obtain the same  packet latency as ANOC router. However, at that  frequency, the power consumption of the DSPIN router  is three times higher than the ANOC one. Therefore,  the ANOC NoC is a good candidate for low latency  and low power applications, while DSPIN is more  suited to low area and high performance applications.   From a design-flow point of view, the multisynchronous DSPIN network is implemented using  only standard cells and soft-macro conception. It does  not use any asynchronous nor custom cells, giving to  the designer a complete flexibility to control the floorplan of the circuit. On the other hand, ANOC is an  asynchronous network requiring additional standard  cells such as Muller gates and dedicated synthesis  tools. Therefore, to hide the complexity of the  147147                         asynchronous logic, a hard-macro approach has been  used for the ANOC router design, that helps the toplevel timing optimization.  We demonstrated  that  the multi-synchronous  DSPIN architecture can be simply and automatically  implemented, and can directly be ported to other  CMOS process  technologies,  as  it  is  fully  synthesizable.  Acknowledgments  The authors would like to thank Didier Lattard,  Yvain Thonnart, Edith Beigne, and Jean Durupt from  CEA-Leti for their contribution to this work.  "
An On-Chip and Inter-Chip Communications Network for the SpiNNaker Massively-Parallel Neural Net Simulator.,"SpiNNaker is a scalable, multichip system designed for the purpose of real-time modelling of spiking neurons with an efficient multicast communications infrastructure inspired by neurobiology. SpiNNaker uses a GALS packet-switched network to emulate the very high connectivity of biological systems. This paper presents the on-chip and inter-chip communications network for SpiNNaker.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip An On-Chip and Inter-Chip Communications Network for the SpiNNaker Massively-Parallel Neural Net Simulator Luis A. Plana1 , John Bainbridge2 , Steve Furber1 , Sean Salisbury2 , Yebin Shi1 and Jian Wu1 {luis.plana, steve.furber, jian.wu, yebin.shi}@manchester.ac.uk, {wjb, sjs}@silistix.com 1The University of Manchester, 2Silistix Ltd. The real-time modelling of large systems of spiking neurons is very demanding in terms of processing power and communication throughput. SpiNNaker [1] is a scalable, multi-chip system designed for this purpose with an efﬁcient multicast communications infrastructure inspired by neurobiology. SpiNNaker uses a GALS packet-switched network to emulate the very high connectivity of biological systems. The packets represent neural spikes and are source-routed, i.e., they only carry information about the issuing neuron and the network infrastructure is responsible for delivering them to their destinations. INTER−CHIP LINKS ON−CHIP PROCESSORS RX RX RX RX RX RX CC CC CC CC 1 0 0 S−>A S−>A S−>A S−>A Input NoC fabric A−>S ROUTER BUF BUF BUF BUF BUF BUF BUF BUF BUF BUF S−>A S−>A S−>A S−>A S−>A S−>A S−>A S−>A S−>A S−>A Output NoC fabric A−>S A−>S A−>S A−>S TX TX TX TX TX TX CC CC CC CC M H z 2 0 0 M H z 1 0 0 M H z INTER−CHIP LINKS ON−CHIP PROCESSORS Figure 1. Communications Network-on-Chip. Each packet contains an identiﬁer that is used to determine which output(s) the packet should be sent to. In neural applications, the identiﬁer is a number that identiﬁes the neuron that generated the message. The router operates as a look-up table composed of two parts: an associative (content-addressed) memory responsible for comparing simultaneously the identiﬁer of the packet with the all keys in the table and a conventional lookup RAM that holds the output routing words. If a match is found, the associative memory generates a hit-address for the look-up RAM. To reduce the size of the associative memory, neurons can be associated in groups which are routed using the same table entry. This is accomplished by masking some of the identiﬁer bits in the look-up process, as shown in Figure 2. routing key key data 32 mask data 32 32 line hit hit/miss hit addr 10 I Y R T E R D O O C R N P E I Figure 2. Masked Associative Memory. The network is shown in Figure 1. The input section receives packets from other chips, through the inter-chip input links, and from the on-chip processors, and passes them to the router. The router determines the destination of each packet and sends it via the output section to the interchip link outputs and the on-chip processors. The router is able to replicate packets where necessary to implement the multicast function associated with sending the same neural event packet to several destination neurons. The NoC operates in a GALS fashion, with the synchronous router and on-chip processors connected through a self-timed fabric. In addition to the look-up table, a default routing mechanism is used. If no match is found in the table the packet is transferred from the input link to the output link directly opposite. In neural network applications, default routing can signiﬁcantly reduce the size of the routing tables. The router, shown in Figure 3, is implemented as a pipeline to sustain the input bandwidth. A back-pressure mechanism is used to selectively stop pipeline stages when a required output link is blocked or congested. This is also used as a power-saving mechanism. To minimize the im978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.30 DOI 10.1109/NOCS.2008.30 217 215       Packet Checking Routing Emergency Routing Packet In Pipeline Stage 1 Pipeline Stage 2 Pipeline Stage 3 Packet Out Buffer Full Flag1 Flag2 Flag3 Clock Clock Disable Pipeline Control Clock Disable Pipeline Control l l u F 1 e g a S t l l u F 2 e g a S t Clock Disable Pipeline Control l l u F 3 e g a S t e r u s s e r P k c a B Figure 3. Router Back-Pressure. pact of temporary network congestion as well as to simulate the fault tolerance of real neural networks, an emergency routing mechanism is implemented. When an output link is congested or broken the router will stop sending packets through that link and automatically redirect them through predeﬁned alternative links. The packet is ﬂagged as emergency-routed so that the receiving routers can route it appropriately. The network fabric is implemented using delayinsensitive CHAIN technology [2]. Communication between the synchronous islands and the asynchronous fabric requires synchronization. Figure 4 shows a block diagram of a sync-to-async parallel path synchronizer, based on the well-known two ﬂop synchronizer. data0 req0 ack0 data1 req1 ack1 data2 req2 ack2 data valid ready clk data0 req0 ack0 data1 req1 ack1 data2 req2 ack2 data ack Figure 4. Parallel Path Synchronizer. The synchronizer latches data internally and operates as a pipeline. The parallel paths (data0, data1 and data2) are used to allow the sending of data on every clock cycle of the sender, without incurring the 2-cycle latency of the synchronizer. An async-to-sync parallel path synchronizer is implemented in a similar way. The trafﬁc provided by the inter-chip links and on-chip processor must be delivered to the router without excessive latency and with a fair distribution of the bandwidth. The input fabric uses a ’bandwidth aggregation’ scheme to allow full-bandwidth trafﬁc to ﬂow from every input and reach the router without any noticeable delay. Bandwidth aggregators are implemented as shown in Figure 5. The ﬁrst stage consists of a 1:N deserialiser. This 218216 route data eop ack ack 6 ack DESERIALISER 6*N 1:N T TRIGGERED−FIFO ack ack 6*N ack route data eop Figure 5. Bandwidth Aggregator. stage transforms an input link of width 1 into an output link of width N buy steering successive ﬂits to different output sub-links and issuing them as a single output ﬂit. The second stage consists of a triggered FIFO. The ﬂits are stored in the FIFO until a threshold level is reached. At this point, the FIFO starts to send the ﬂits through its output link. If the threshold is chosen correctly, the output ﬂits will be issued at the maximum rate possible in the output link, without pause and without holding the fabric components longer than required. Delay-insensitive communication is also attractive for inter-chip interconnect. With a suitable protocol, each interchip link matches the data bandwidth of an on-chip link when connecting two CMPs on the same circuit board, and the self-timed protocol guarantees correct operation (albeit at a lower data rate) when the CMPs are on different circuit boards, automatically adapting to the additional delays incurred by any signal buffering that may be required. Detailed Verilog simulations show that the network-onchip design effectively optimises the use of the available bandwidth and delivers one packet per clock cycle to the router. The simulations also show that, after an initial setup period during which input packets may be delayed, packets can also be input without pause and at the maximum input rate. Acknowledgements The Spinnaker project is supported by the Engineering and Physical Sciences Research Council, UK, and also by ARM and Silistix. "
Real-Time Communication Analysis for On-Chip Networks with Wormhole Switching.,"In this paper, we discuss a real-time on-chip communication service with a priority-based wormhole switching policy. A novel off-line schedulability analysis approach is presented. By evaluating diverse inter-relationships among the traffic-flows, this approach can predict the packet network latency based on two quantifiable different delays: direct interference from higher priority traffic-flows and indirect interference from other higher priority traffic-flows. Due to the inevitable existence of parallel interference, we prove that the general problem of determining the exact schedulability of real-time traffic-flow over the on- chip network is NP-hard. However the results presented do form an upper bound. In addition, an error in a previous published scheduling approach is illustrated and remedied. Utilizing this analysis scheme, we can flexibly evaluate at design time the schedulability of a set of traffic-flows with different QoS requirements on a real-time SoC/NoC communication platform.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Real-Time Communication Analysis for On-Chip Networks with Wormhole Switching Zheng Shi and Alan Burns Real-Time Systems Research Group, Department of Computer Science University of York, UK {zheng, burns}@cs.york.ac.uk Abstract— In this paper, we discuss a real-time on-chip communication service with a priority-based wormhole switching policy. A novel off-line schedulability analysis approach is presented. By evaluating diverse inter-relationships among the trafﬁc-ﬂows, this approach can predict the packet network latency based on two quantiﬁable different delays: direct interference from higher priority trafﬁc-ﬂows and indirect interference from other higher priority trafﬁc-ﬂows. Due to the inevitable existence of parallel interference, we prove that the general problem of determining the exact schedulability of real-time trafﬁc-ﬂow over the onchip network is NP-hard. However the results presented do form an upper bound. In addition, an error in a previous published scheduling approach is illustrated and remedied. Utilizing this analysis scheme, we can ﬂexibly evaluate at design time the schedulability of a set of trafﬁc-ﬂows with different QoS requirements on a real-time SoC/NoC communication platform. I . IN TRODUC T ION With the development of semiconductor technology over the last ﬁfteen year, it is possible to offer more than many tens of million of transistors on a single chip. Under this condition, designers are developing ICs integrating complex heterogeneous functional elements into a single device, known as a System-on-Chip (SoC). Generally, SoC is an integrated circuit that implements most or all of the functions of a complete electronic system. In such a system, different components need a standard approach to support on-chip communication. Early SoCs employed busses or a point-to-point approach to fulﬁl the information exchange demands. However, with the rapid increase in the number of blocks to be connected and the increase in performance demands, busses and point-to-point based platforms suffer from limited scalability and quickly become a communication bottleneck [9], [11]. On-chip packet-switched networks have recently been proposed as a signiﬁcant solution for complex communication of SoCs. Network on Chip (NoC) [7], [4] is an architectural paradigm for scalable on-chip interconnection architectures. This architecture offers a general and ﬁxed communication platform which can be reused for a large number of SoC designs. Networks as a subject has been studied for decades. However, the situation for NoC is different from off-chip networks meaning that we can not deploy general networks on SoC platforms directly. NoCs differ from off-chip networks mainly in that they are more constrained and less non-deterministic [3]. The structure of an off-chip network or general network is in principle unknown, ie. topology is not ﬁxed and behaviours of nodes are not predictable. So the protocols need enough adaptability to meet various requirements. Some results used in traditional networks can’t be employed directly and must be re-evaluated. A few distinctive limitations are unique for on-chip networks, namely, minimal energy consumption, and small size [12] (both computation and storage functions implemented in a small silicon area). Therefore many network design choices need to be modiﬁed so that the implementation cost as well as speed/throughput performance is acceptable. The new on-chip communication architecture needs to provide different levels of service for various application components on the same network. One kind of communication, namely real-time communication, has very stringent requirements, the correctness relies on not only the communication result but also the completion time bound. For a packet transmitted over the network, this time bound is denoted by the packet network latency. A data packet received by a destination too late could be useless. For instance, the signal message packet or control message packet of an application requires timely delivery. The worst case acceptable time metric is deﬁned to be the deadline of the packet. A trafﬁc-ﬂow is a packet stream which traverses the same route from the source to the destination and requires the same grade of service along the path. For hard real-time trafﬁc-ﬂows, it is necessary that all the packets generated by the trafﬁc-ﬂow must be delivered before their deadlines even under worst case scenarios. In another words, the maximum network latency for each packet can not exceed its deadline. A set of real-time trafﬁc-ﬂows over the network are termed schedulable if all the packets belonging to these trafﬁc-ﬂows meet their deadlines under any arrival order of the packet set. As a popular switching control technique, wormhole switching [19] has been widely applied for on-chip networks due to its greater throughput and smaller buffering requirement [12]. However, few works have been done to analyze the real-time packet schedulablility for wormhole switching networks. In order to support real-time requirements, particularly satisfying its deadline bound, predictable behaviour of the network service is essential. But the situation for on-chip wormhole networks is partially non-deterministic due to the contentions in communication. In on-chip networks, several tasks running on different nodes exchange information periodically. During a transmission period, one transmitted packet shares the resources, such as buffers or physical links, with other packets. When several packets try to access the same resource at the 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.11 DOI 10.1109/NOCS.2008.11 161 161 same time, contention occurs and the network only can serve one packet and suspend the others based on some arbitration policy. Once a packet becomes blocked, it can block other packets, which can in turn block other packets, and so on. The exact analysis of congestion in this situation is hard [2] due to the possibility of a packet becoming blocked at several routers during its journey from source to destination. The contention problem leads to packet delays and even missed deadlines. Therefore, it is necessary to give a scheduling strategy and analysis approach to predict whether all the real-time packets can meet their timing properties. In this paper we explore real-time communication in wormhole switching for on-chip networks. We assume the prioritybased transmission preemption method [2], [10], [13]. A novel analyzable approach, the worst case network latency evaluation, is presented, within which a broad class of realtime communication services can be explored and developed. By evaluating diverse inter-relationships and service attributes among the trafﬁc-ﬂows, our model can predict the packet transmission latency for a given trafﬁc-ﬂow based on two quantiﬁable different delays: direct interference from higher priority trafﬁc-ﬂows and indirect interference from other higher priority trafﬁc-ﬂows. Due to the inevitable existence of parallel interference, we prove that the general problem of determining the exact schedulability of real-time trafﬁc-ﬂows over the on-chip network is NP-hard. We also prove that the real maximum network latency is bounded by the theoretical calculation in our model. By using this approach, we can ﬂexibly evaluate at design time the schedulability of a trafﬁcﬂow set with different quality of service (QoS) requirements in a real-time SoC/NoC communication platform. The rest of this paper is organized as follows: section II introduces the major features of wormhole switching. A preemptive arbitration structure is deployed to implement priority-driven transmission scheduling. A novel real-time communication model and associated analysis are represented in sections III and IV. Section V discusses the limitation of our model when there exists parallel interference. Finally, section VI concludes the paper. I I . WORMHOL E SW I TCH ING IN R EA L - T IM E COMMUN ICAT ION A. Wormhole switching It is a major challenge for NoCs to provide real-time support. The area and energy constraints determine that the cut-through switching approach (wormhole switching) is the more practical deployment strategy than the store-and-forward switching (packet switching) policy [8], [12]. In a wormhole switching network, data is encapsulated into a packet format for network transmission. So for convenience in discussing, a packet is treated as the basic information unit throughout this paper. Each packet in a wormhole network is divided into a number of ﬁxed size ﬂits [19]. The header ﬂit takes the routing information and governs the route. As the header advances along the speciﬁed path, the remaining ﬂits follow in a pipeline way. If the header ﬂit encounters a link already in use, it is blocked until the link becomes available. In this situation, all the ﬂits of the packet will remain in the router along the path and only a small ﬂits buffer is required in each router. But this blocking will decrease the available resource for other communication trafﬁc-ﬂows and reduce the network resource efﬁciency. Fig. 1. A General NoC Platform A general communication infrastructure for the wormhole on-chip network is illustrated in Figure 1. A set of routers and point-to-point links interconnecting the routers are organized in a mesh structure. Each router has one or several intellectual property (IP) modules which hold tasks for execution. These tasks, executing on different IPs, communicate with each other by transmitting packets through the on-chip interconnection network. Two unidirectional links, one for each direction, connecting two routers realize the full-duplex transmission media. The network uses dimension-order X-Y routing, which is simple and easy to be implemented in the regular topology. The virtual channels (VCs) technique [6] is deployed which decouples resource allocation by providing multiple buffers for each physical link in the network. Each of these buffers is considered as a virtual channel and can hold one or more ﬂits of a packet. By combining with the virtual channels technique, the transmitting packet can bypass a blocked one. This strategy efﬁciently utilizes the network resource (link bandwidth) and improves the performance with a very small buffer overhead [5]. Figure 1 also illustrates a number of trafﬁc-ﬂows loaded on this NoC platform. For example, τ1 starts in router 7 and passes through routers 11 and 15 before terminating in router 14. B. Priority preemptive arbitration In conventional wormhole routers, data ﬂits held by VCs access the output link based on ﬁrst-come ﬁrst-service arbitration. This scheme is suitable for non-real-time networks since it is fair and produces good average performance. But in real-time communication, the network must ensure each realtime packet meets its deadline bound. Priority arbitration is 162162 proposed to resolve this problem [2], [10], [13]. We employ the ﬂit-level preemption method implemented by using virtual channels, which have similar structure as in [10], [13]. The arbitration with priority method uses priority preemption to provide delivery guarantees for hard deadline packets. We assume there are as many virtual channels as priority levels at each output port. Each virtual channel is assigned a different priority. An output port structure of a router is shown in Figure 2. The trafﬁc-ﬂows loaded in the wormhole network have priorities associated with them. Each packet generated by a trafﬁc-ﬂow inherits the corresponding priority of the trafﬁcﬂow. A packet with priority i can only request the virtual channels associated with priority value i. At any time the packet with the highest priority always gets the privilege to access the output link. In addition, a higher priority packet can also preempt a lower priority packet during its transmission. Since the real-time trafﬁc-ﬂows between different routers in a speciﬁc on-chip network is known a prior, a global priority assignment policy should be ameanable to off-line analysis [2]. Fig. 2. Priority Arbitration Output Port Consider n trafﬁc-ﬂows, each one with an associated virtual channel containing ﬂits. The arbiter fetches ﬂits from these queues according to priority arbitration and forwards them over a shared output link. If the highest priority packet can not send data because it is blocked elsewhere in the network, the next highest priority packet can access the output link. The allowable service time for a trafﬁc-ﬂow is all the time intervals at which no higher priority trafﬁc-ﬂow competes for the same physical link. C. Current works Wormhole switching achieves high throughput performance with less buffer requirement comparing with packet-switched technique [8], [12]. But it also introduces unpredictable network delay [8]. Hard real-time communication, on the contrary, requires the timing to be predictable even under the worst case situation. Besides this, the network resource allocation and scheduling for the real-time trafﬁc-ﬂow should be analysable during the design phase. Predictability of performance is essential for NoCs design to take early decisions before actual implementation. Fortunately, the communication pattern of a SoC is determined during a pre-conﬁguration period; interconnection topology and characteristics of trafﬁc pattern are foreseeable. Therefore, we need an off-line static evaluation approach to ensure the packet network latency never violates its timing bound. Utilizing this approach, we also can plan and explore the distribution of the real-time applications over the network to produce a very effective mapping. The ﬁrst work to explore the packet’s timing property in wormhole switching was published by Li and Mutka [16] in 1994. Utilizing the priority strategy, for a wormhole network with the same number of virtual channels as the number of priority levels, a packet can request only a virtual channel which is numbered lower than or equal to its priority [16]. Song et al [20] proposed a ﬂow control approach to avoid the priority inversion problem. By ﬂit-level preemption, the different priority trafﬁc-ﬂows can be catered for by a very small number of virtual channels. However the upper bound of network latency for each packet in the network are not delivered by Song and Li’s methods. Balakrishnan et al [2] proposed a quite naive and simple approach - lumped link to address this problem. All the links the trafﬁc-ﬂow travels are lumped as one shared resource - like a bus structure. Static priority preemptive policy is adopted to assure at any time only the highest priority trafﬁc-ﬂow can access the link resources. However, due to lumping, direct and indirect contentions are treated in the same way, Balakrishnan’s result is sufﬁcient but pessimistic [18]. Hary et al [10] utilized the same model proposed in [2] but ignored indirect competition, the result of [10] is optimistic. In this paper we treat the indirect contentions as interference jitter and get an upper bound on network latency. The analysis and relative example are represented in section IV. The analysis by Lu et al [18] takes account of the parallel interference in disjoint trafﬁc-ﬂows and tries to minimize the direct interferences of higher priority trafﬁc-ﬂows. But this parallel consideration is not reasonable when worst case network latency is desired. I I I . R EAL - T IM E COMMUN ICAT ION MOD EL AND A S SUM PT ION S A. System model and attributes The packet level analysis approach of real-time communication in general networks [22] in the absence of buffer restrictions is not suitable for wormhole networks. We need a new analysis model for real-time wormhole switching communication. Some conditions, assumptions and explanations are essential. A wormhole switching real-time network Γ comprises n real-time trafﬁc-ﬂows Γ ={τ1 , τ2 , . . . τn }. Each trafﬁc-ﬂow is characterized by attributes τi = (Pi , Ci , Ti , Di , J R i ). We assume that all the trafﬁc-ﬂows which require timely delivery are periodic1 . The length of time between releases of successive packets of τi is a constant, which is called the period Ti for this trafﬁc-ﬂow. Each trafﬁc-ﬂow τi has a priority value Pi . All the packets that belong to the τi inherits the τi 1 This periodic restriction is for presentation reason, the analysis can be extended to sporadic trafﬁc-ﬂows where T is the minimum inter-arrival interval. 163163 same priority Pi . The value 1 denotes the highest priority and larger integers denote lower priorities. We assume the trafﬁcﬂow is prioritized by any possible priority assignment policy. The issue of priority assignment is beyond the scope of this paper. Each real-time trafﬁc-ﬂow has deadline Di constraint which means all the packets belonging to this trafﬁc-ﬂow have the restriction that it should be delivered from a source router to a destination router within a certain delay bound even in the worst case situation. Our model has the same restriction as [2], [13], [18] that each trafﬁc-ﬂow’s deadline must be less than or equal to its period, Di ≤ Ti for all τi ∈ Γ. J R is the release jitter [1] denotes the maximum deviation of successive packets released from its period. If a packet from τi is generated at time a, then it will be released for transmission by time a+ J R and have an absolute deadline of a + Di . The basic network latency happens when no trafﬁc-ﬂow contention exists. The basic network latency is determined by its source/destination routing distance, packet size, link bandwidth and some additional protocol control overheads. For real-time evaluation purpose, we use the term maximum basic network latency. Let H denote the hops between source and destination nodes and S indicate the constant processing delay in each router. Let the maximum packet size belonging and the ﬂit size for wormhole switching be fsize , the maximum basic network latency Ci [8] is given by: to τi be Lmax i i i Ci = d Lmax i + Ladd fsize e · fsize /Blink + H · S (1) where Ladd is the additional data for wormhole switching such as header and tail ﬂit information. Here we only consider the longest possible, or maximum, basic network latency for evaluation. If the real-time trafﬁc-ﬂow can meet its deadline with the maximum basic network latency scenario, it will meet the deadline for any other basic network latency scenario. Note that the network latency here does not consider contention. The competing interventions can disturb and extend the packet network latency. The competing interventions and related worst case evaluation are discussed in section IV. B. Inter-relationships between trafﬁc-ﬂows To capture the relations between trafﬁc-ﬂows and the physical links of the network, we formalize the mesh network topology deﬁned as a directed graph G : V × E . V is a set, whose elements are called nodes, each node vi denotes one router in the mesh network. E is a set of ordered pairs of vertices, called edges. An edge ex,y = {vx → vy } is considered to be a real physical link from router vx to router vy ; vx is called the source and vy is called the destination. We deﬁne a mapping space from the trafﬁc-ﬂow set to the physical links Γ → E . Given a set of n trafﬁc-ﬂows Γ, we can map them to the target network. The routing <i of each trafﬁc-ﬂows τi is denoted by the ordered pairs of edges, <i = {e1,2 , e2,3 , . . . , en−1,n }. If a trafﬁc-ﬂow τi shares at least one link with τj , the intersection set between them is <i tasks contends for the shared processor resource. In wormhole switching networks, the shared physical communication links are also contended for by the associated trafﬁc-ﬂows. Utilizing the preemptive ﬁxed priority scheduling policy, we can analyze this model following the real-time scheduling approach in single-processors. We introduce the concept of worst case network latency which is inspired by worst case response time (WCRT) [14] proposed in real-time system scheduling. A trafﬁc-ﬂow is schedulable if and only if the network latency of all the packets belonging to this trafﬁc-ﬂow is no more than its deadline. If we can ﬁnd the worst case network latency of this trafﬁc-ﬂow, we can judge whether this trafﬁc-ﬂow is schedulable. Generally, we need to ﬁnd the condition which can trigger the trafﬁcﬂow’s worst case network latency. Liu and Layland in their seminal paper [17] identiﬁed two major conditions to achieve the worst case response: • All the tasks execute for their worst-case execution time and all tasks are subsequently released at their maximum rate. • The task is released at the critical instant. The critical instant is the time that the task is requested simultaneously with requests of all higher priority tasks. We borrow the concept of critical instant to apply it for real-time scheduling in wormhole switching. The worst case network latency is assumed to occur when the packet from the observed trafﬁc-ﬂow is ﬁred simultaneously with all the packets from higher priority trafﬁc-ﬂows with their maximal release rates. We have discussed that the worst case network latency is primarily determined by the interference after computing the maximum basic network latency. Next, we need to quantify the analysis based on two distinguishing interferences: • Direct interference from higher priority trafﬁc-ﬂows. • Indirect interference from other higher priority trafﬁcﬂows. A. Interference from direct higher priority For an observed trafﬁc-ﬂow τi , the network latency Ri of a packet released from τi is: Ri = B + Ci + Ii (2) where Ii is the interference summation from the higher priority trafﬁc-ﬂow(s). The maximum basic network latency Ci is constant and known a prior by static analysis (Eq.(1)). B is the maximum blocking time by any lower priority trafﬁcﬂow which has already begun transmission. The maximum blocking happens when a higher priority packet arrives just after a lower priority packet starts its service. Consider our ﬂitlevel preemptive scheduling strategy, the higher priority packet waits at most one ﬂit time and then starts its transmission at each hop output port. The maximum blocking time is represented by B = fsize × H/Blink . The ﬂit size and link bandwidth is constant after on-chip network conﬁguration. Thus, the blocking time could be regarded as a constant parameter and incorporated in the basic network latency Ci . The network latency equation Eq.(2) is simpliﬁed into Ri = Ci + Ii (3) SD i We assume the packet from the observed trafﬁc-ﬂow is released simultaneously with all the packets from higher priority trafﬁc-ﬂows, this triggers the worst case network latency based on the condition of critical instant. Without loss of generality, we assume this time instant is at time 0. Until the time instant Ri when the packet is accepted completely by the receiver, during the time interval [0, Ri ], the maximum possible direct competition interference from higher priority trafﬁc-ﬂows in Ii = X to a packet from τi when release jitter is considered is: The packet from τi may be blocked by more than one packet from each τj , τj ∈ SD i , since the packet releases are periodic. e is the maximum number of packets a trafﬁcﬂow can release during the time interval [0, Ri ]. Using Eq.(4) Ri = X to substitute Ii in Eq.(2), we can produce: We ﬁnd the variable Ri appears on both sides of the Eq.(5). This equation can be solve using an iterative technique [1]. be the (n + 1)th iterative value generated from the d Ri + J R Tj d Ri + J R Tj The d Ri+J R Tj eCj + Ci Let rn+1 ∀τj ∈SD eCj ∀τj ∈SD i (4) (5) j i j j i equation: = X ∀τj ∈SD i rn+1 i d rn i + J R Tj j eCj + Ci (6) rn The iteration starts with r0 i = Ci and terminates when rn+1 = i . This iteration also should halt if rn+1 > Di , which denotes the deadline miss for this packet. By this iterative technique, the worst case network latency with direct interference can be calculated (Ri=rn+1 i ). =rn i i i B. Interference from indirect higher priority The model indicated by Eq.(5) only considers the direct interference from higher priority trafﬁc-ﬂow. Indirect interference also needs to be taken into account. Fig. 3. A Case of Indirect Interference Consider the following scenario: τ1 , τ2 , . . . , τj , τi and τn are loaded on the network with the inter-relations of trafﬁc-ﬂows in Figure 3. Trafﬁc-ﬂows are sorted with priority descending, τ1 with highest priority, τn with lowest priority. We examine n = {τi }, the competing relation of τn and τi and get SD i = ∅. Without n = {τ1 , . . . , τj }, SD i = {τ1 , . . . , τj } and S I S I 165165 considering the possible indirect interference from τ1 , . . . , τj , the worst case network latency of τn occurs when τi and τn are released at the same time. Fig. 4. The Problem of Indirect Interference When τ1 , . . . , τj as indirect higher priority trafﬁc-ﬂows are taken into account, even though they do not share any physical link with τn , we ﬁnd their services still can impose an extra interference on τn . The time-line graph in Figure 4 shows such a situation. The solid up arrow in the graph indicates the release time of a packet from a trafﬁc-ﬂow. A packet served by the network for some time is depicted as a shaded rectangle. The preemption of a packet is depicted as a white rectangle. The bold circle denotes the complete packet received by the destination. We assume τi is released with the other higher priority packets at the same time 0, the packets from τ1 , . . . , τj will contend with τi . This contention delays the start time of τi until time ti , ti is the start time of τi ﬁrst transmission service. At the time 0 + ti , τn is released, the packet from τi immediately preempts τn . It is easy to ﬁnd that τi imposes the interference Ci upon the τn during the time interval [t, Ri ]. At the time 0 + Ti , τi is released again but this time all the higher priority trafﬁc-ﬂows τ1 , . . . , τj only send a very small packet or even do not send any packet. Flow τi in this situation does not suffer any interference from them and gets network service immediately. From the view of τn , the time interval between two successive releases from τi is only (Ti - ti ). Consider our original assumption, the worst case network latency occurs when all the packets from the higher priority trafﬁc-ﬂows are released periodically with the minimum packet release interval T . The maximum interference a packet from τn suffered from a higher priority trafﬁc-ﬂow is calculated by d Rn+J R e. But in this case, the minimum interval between subsequent preemptions from τi is only (Ti - ti ) which is less than the original minimum interval assumption Ti . Note that this phenomenon can only occur when considering indirect interferences. Theorem 1: The upper bound of interference suffered by τn from direct higher priority trafﬁc-ﬂow τi is: Ti i d Rn + Ri − Ci + J R Ti i eCi (7) 166166 when the indirect interference is considered. Proof: Let si denote the packet release time from τi . In this analysis assumption, without loss of generality, the ﬁrst packet is released at time 0. Therefore, each packet from τi is generated periodically at the time instant 0, Ti , 2Ti , . . ., kTi . si,k = (k − 1)Ti , where k is the sequential number of the packets. But a real application does not always meet this constraint and has application release jitter. More speciﬁcally, the release time si,k satisﬁes: (k − 1)Ti ≤ si,k ≤ (k − 1)Ti + J R i (8) In addition, in Figure 4, we observe that the possible interference from higher priority packets also defers its starting service time. If the worst case network latency for τi is Ri , the upper bound of start service time is Ri − Ci . The real service start time for each packet satisﬁes: (k − 1)Ti ≤ si,k ≤ (k − 1)Ti + J R i + Ri − Ci (9) Now we evaluate the maximum interference suffered by τn from τi in a given time interval. Here we assume the start service time of τi is a = Ri − Ci + 0, this is the upper bound of the start service time since it is released. A packet from τn is released simultaneously with τi and b is the corresponding completion time of this release. The worst case interference occurs when most packets from τi are released since τn is released. Figure 5 illustrates this situation: Fig. 5. Upper Bound Analysis of Indirect Interference The number of preemptions by τi is given by the positive integer number g between the interval [a, b], g ∈ N. The last release of τi should fall into the interval before the completion of τn , g is the largest value that satisﬁes: a − (Ri − Ci ) − J R i + (g − 1)Ti < b or, equivalently, g < i + Ri − Ci + b − a J R Ti + 1 (10) (11) The largest positive integer number satisfying this inequality is given by j + Ri − Ci + b − a g = d J R Ti e (12) The interval [a, b] marks the worst case network latency of τn , b − a = Rn . Therefore, the interference upper bound from τi is: i + Ri − Ci + Rn d J R Ti eCi (13) The packet from τn will experience worst latency than what predicted by Eq.(5) on account of the indirect interference from τ1 , . . . , τj which delays τi and further force more hits on τn . Therefore, the worst case network latency does occur not when the packet is released simultaneously with higher priority packets but at the point when the packet from the observed trafﬁc-ﬂow is released at the same time as the higher priority packets ﬁnish waiting and start to receive service. This deviation induced by higher priority interference between consequtive releases is called interference jitter, using symbol J I to denote the interference jitter of trafﬁc-ﬂows. The interference jitter of a trafﬁc-ﬂow is the maximum deviation between two successive packet start service times which can be obtained by computing the difference between the maximum and minimum value of packet start service times. Consider the situation that no higher priority packet is sent in a period, the minimum packet start service time becomes zero. Accordingly, the interference jitter of the trafﬁc-ﬂow is the maximum number of start service time which can be given by an upper bound: i = Ri − Ci J I (14) Note that not all the trafﬁc-ﬂows suffer interference jitter, this only happens when the observed trafﬁc-ﬂow τn has indirect interference, namely, J I i exists if and only if SD i Real-Time Trafﬁc-ﬂow τ1 τ2 τ3 P 1 2 3 T 5 10 15 D 5 10 15 J R 0 0 0 C 1 3 4 TABLE II TRA FFIC - FLOW S D E SCR I P T ION any physical link; and this will force an extra delay on τ3 . The problem is when we schedule all the trafﬁc-ﬂows with the resource competing relationship, we always ideally assume at any time instant only one trafﬁc-ﬂow can be served by the subset of the network which hosts the interfering ﬂows service. Fig. 7. Scheduling Sequence With Parallel Interference Lu et al in his paper [18] found this phenomenon that realtime transmission scheduling can be parallel for disjoint concurrent contentions. Figure 7(A) illustrates this concurrency. If all trafﬁc-ﬂows release the packets simultaneously, τ1 and τ2 are executed at the same time in this scheduling sequence. This parallel interference reﬂects the fact that no real link resource is shared between the direct higher priority trafﬁc-ﬂows of the observed one. For τi , this parallel interference phenomenon exists when the following condition is met: τj , τk ∈ SD i and <j n+1 = max{s1 , . . . , sn+1 } and P = lcm{P1 , . . . , Pn+1 }. in parallel. The observed one τn+1 with lower priority contends with ﬁrst N higher priority trafﬁc-ﬂows, so SD {τ1 , τ2 , . . . , τn }. In order to determine the network latency, we need to take account all the possible free gap intervals for the observed trafﬁc-ﬂow. The case in Figure 7(B) implies the worst case network latency no longer occurs when all the trafﬁcﬂows are released simultaneously. Thus, we need to examine all the possible packet release sequences to achieve the worst case network latency calculation. We now shown that to solve this problem when parallel interference exists is NP-hard. Lemma 1: For trafﬁc-ﬂows set Γ meeting the conditions shown in Figure 8, the observed trafﬁc-ﬂow τn+1 is schedulable on the network if and only if all the deadlines are met during time interval [0, t1 ], where t1 = s + P , s = Proof: ⇒ : If the observed trafﬁc-ﬂow is schedulable on the network, relying on the schedulable condition, all the deadlines are met since it was released. Thus, all deadlines in the interval [0, t1 ] are met. ⇐ : At any time instant ti , the network state is denotes by E (e1 , . . . , en )ti , where ei is the amount of time for τi has ﬁnished transmission service since last release. The time interval [0, s + P ] is separated into two parts [0, s) and [s, s+P]. After s, all the trafﬁc-ﬂows are released and executed in parallel except τn+1 . Let ti ∈ [s, s + P ] and tj = ti + j × P for j is positive integer and j > 0, it is not difﬁcult to see the network state Eti = Etj is always true. This means the schedule progress repeats itself every P units of time after s. Since all deadline of τn+1 in [s, s+P] are met, all the deadline after s+P should also be met. As the assumption, the deadline of τn+1 in [0, s] are met. Thus τn+1 is schedulable in this network. Strictly speaking, we need to check all the inﬁnite scheduling sequences after packet releases of the trafﬁc-ﬂow set to ensure the deadline is always met. Lemma 1 gives us an easy method to estimate whether the trafﬁc-ﬂow set is schedulable in ﬁnite schedule time interval [0, s+ P ]. If all the deadlines in [0, s + P ] are met, then this trafﬁc-ﬂow set is a valid schedule. If we know period, maximum basic network latency and release time of all packets in a trafﬁc-ﬂow set in advance, we can ﬁnd all the available gap intervals in [0, s+P] for observed trafﬁc-ﬂow with a polynomial time algorithm. Determining the schedulability of observed trafﬁc-ﬂow, namely ﬁnding the worst case network latency when knowing all the available gap intervals in advance is also taking polynomial time. Now we prove that if the trafﬁc-ﬂow set with arbitrary release time, ﬁnding the worst case network latency is intractable. Utilizing the K Simultaneous Congruences [15] which has been shown to be the NP-complete, our problem can be proved to be intractable by reducing the current problem to a known NPcomplete problem in polynomial time. K Simultaneous Congruences: Given N ordered pairs of positive integers (a1 ,b1 ), . . . , (an , bn ) and a positive integer K ( 2 ≤ K ≤ N ). Is there a subset of ‘ ≥ K ordered pairs (ai,1 , bi,1 ), . . . , (ai,‘ , bi,‘ ) such that there is a positive integer x with the property that x = ai,j + pj × bi,j for each 1 ≤ j ≤ ‘? Theorem 3: For a trafﬁc-ﬂow set with arbitrary release time, the problem of determining schedulability when parallel interference exists is NP-hard. Proof: The proof includes two steps, ﬁrst, we try to prove ﬁnding all the gap intervals for the observed trafﬁcﬂow is NP-hard. Suppose n sorted pairs of positive integers (a1 ,b1 ), . . ., (an ,bn ) with constraint ai ≥ bi − 1 and a positive integer K , we construct n parallel trafﬁc-ﬂows communications (τ1 , . . . , τn ) with attributes Ti = Di = bi , Ci = bi − 1, and si + Ci = ai . In our construction, each trafﬁc-ﬂow in each period only exports one free time unit. For this trafﬁc-ﬂow set, ﬁnding the gap interval on the network only and only if all the N trafﬁc-ﬂows output free time units simultaneously. Thus, the K Simultaneous Congruences problem has a solution if and only if the gap intervals can be found in the constructed model. Since this construction progress can be done in polynomial time, the problem of ﬁnding all the gap intervals is as hard as the K Simultaneous Congruences problem. We assume a trafﬁc-ﬂow τn+1 which has the lowest priority comparing with τ1 , . . . , τn . Determining the schedulability of τn+1 when knowing all the gap intervals is polynomial time complexity, so the problem of determining schedulability in the parallel interference situation is NP-hard. V I . CONC LU S ION The new on-chip communication architectures need to provide different levels of service for various components on the same network. The requirement of real-time applications needs a scheduling strategy and analysis approach to predict whether all the real-time packets can meet their timing bounds. In this paper, we introduce an analysis approach for real-time on-chip communication with wormhole switching and ﬁxed priority scheduling. The worst case network latency upper bound for each trafﬁc-ﬂow can be achieved for all situations. When parallel interference exists in a real network, we show that the exact determinant of schedulable for trafﬁc-ﬂow sets is NP-hard. Utilizing this analysis scheme, we can ﬂexibly evaluate the schedulability of trafﬁc-ﬂow sets with different QoS requirements in a real-time communication platform at the design phase. The future work will involve the issues of priority assignment and the practical consideration of having less virtual channel and priority levels. "
ReNoC - A Network-on-Chip Architecture with Reconfigurable Topology.,"This paper presents a network-on-chip (NoC) architecture that enables the network topology to be reconfigured. The architecture thus enables a generalized System.-on-Chip (SoC) platform in which the topology can be customized for the application that is currently running on the chip, including long links and direct links between IP-blocks. The configurability is inserted as a layer between routers and links, and the architecture can therefore be used in combination with existing NoC routers, making it a general architecture. The topology is configured using energy-efficient topology switches based on physical circuit-switching as found in FPGAs. The paper presents the ReNoC (Reconfigurable NoC) architecture and evaluates its potential. The evaluation design shows a 56% decrease in power consumption compared to a static 2D mesh topology.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip ReNoC: A Network-on-Chip Architecture with Reconﬁgurable Topology Mikkel B. Stensgaard†‡ and Jens Sparsø† Technical University of Denmark (DTU)† Informatics and Mathematical Modelling (IMM) 2800 Kgs. Lyngby, Denmark {mikkel.stensgaard,jsp}@imm.dtu.dk Teklatech‡ Borgergade 20, 2 1300 Copenhagen K mikkel@teklatech.com Abstract Traditional NoC Architecture This paper presents a Network-on-Chip (NoC) architecture that enables the network topology to be reconﬁgured. The architecture thus enables a generalized System-on-Chip (SoC) platform in which the topology can be customized for the application that is currently running on the chip, including long links and direct links between IP-blocks. The conﬁgurability is inserted as a layer between routers and links, and the architecture can therefore be used in combination with existing NoC routers, making it a general architecture. The topology is conﬁgured using energy-efﬁcient topology switches based on physical circuit-switching as found in FPGAs. The paper presents the ReNoC (Reconﬁgurable NoC) architecture and evaluates its potential. The evaluation design shows a 56% decrease in power consumption compared to a static 2D mesh topology. 1 Introduction Every new CMOS technology generation enables the design of larger and more complex systems on a single integrated circuit. The increasing complexity also means that design, test and production costs reach levels where large volumes must be produced for a chip to be feasible. The time it takes to get a new product to the market (time-tomarket) thereby also increases. As envisioned in [1], this trend seems to make ASICs infeasible for the main bulk of applications - the development time will simply be too long and the cost too high. For many applications a more general System-on-Chip (SoC) platform chip could be a viable solution. Such a SoC platform would contain many different IP-blocks including RAMs, CPUs, DSPs, IOs, FPGAs and other coarse and ﬁne grained programmable IP-blocks. The communication is provided by means of a ﬂexible communication infrastrucApplication 1 − use cases − constraints Application N − use cases − constraints Mapping Static Topology (Physical Architecture) ReNoC Architecture Application 1 − use cases − constraints Application N − use cases − constraints Mapping Mapping Topology 1 (logical) Topology N (logical) Runtime Initialization Topology configuration Physical Architecture Figure 1. The ReNoC architecture enables a logical network topology to be conﬁgured by the application running on the physical SoC platform. ture in the form of a Network-on-Chip (NoC) [2, 3]. This allows the same SoC platform to be used in a wide range of different applications and thereby increases the production volume. As the same SoC platform is to be used for many different applications, the NoC must be able to support a wide range of bandwidth and Quality-of-Service (QoS) requirements. The requirements of the applications can be very different, and the NoC must therefore be very ﬂexible. Currently, the only way to provide such ﬂexibility is to employ a large packet-switched NoC with an over-engineered total bandwidth capacity. Such a NoC would take a signiﬁcant part of the SoCs silicon area and only a fraction of its capacity is utilized by a given application. In this paper we present the ReNoC (Reconﬁgurable 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.13 DOI 10.1109/NOCS.2008.13 55 55 NoC) architecture that enables the network topology to be conﬁgured by the application running on the SoC. Figure 1 illustrates the difference between ReNoC and a traditional NoC architecture with static topology. In ReNoC, the NoC architecture as viewed by the application is actually a logical topology built on top of the real physical architecture. The logical topology is conﬁgured in an initialization phase before the application starts, denoted ’initialization’ in the ﬁgure. This allows the topology to be conﬁgured based on the communication requirements of the application using energy-efﬁcient topology switches. The topology switches are implemented using physical circuit-switching as found in FPGAs, to minimize the power consumption and area overhead. The motivation for inserting a conﬁgurable layer below existing NoC architectures is that physical circuitswitching is far more efﬁcient (in terms of area, power and speed) than intelligent, complex packet-switching which therefore must be avoided when possible. The communication requirement for the application is therefore used to conﬁgure a logical topology that minimizes the amount of packet-switching. The novelty of the ReNoC architecture is that it combines packet-switching and physical circuit-switching within the same NoC. It thereby includes the best of both worlds - ﬂexibility from packet-switching and energyefﬁciency from physical circuit-switching. This combination makes it possible to create application-speciﬁc topologies in a general NoC-based SoC platform. ReNoC can be used in combination with any packet-switched router, making it an extension to any traditional NoC architecture. This paper presents and evaluates the ReNoC architecture, and is organized as follows. Section 2 states some basic terminology. Section 3 discusses related work and the observations behind the ReNoC architecture. The ReNoC architecture is presented in section 4, while section 5 presents an evaluation of the architecture. Section 6 contains implementation details for the evaluation before the results are presented and discussed in section 7. Section 8 concludes the paper and discusses future work. 2 Terminology This section introduces key terms used in the paper. Physical architecture is the actual physical layout of the NoC architecture as shown in the lower part of ﬁgure 1. Logical topology is the topology that is conﬁgured on top of the physical architecture as shown in ﬁgure 1. This is the topology as it is viewed by the application. Physical circuit-switching is used to denote a dedicated physical connection. Once the connection is set up, data can be transferred through the connection without any header information and no routing or arbitration is needed. This is not to be confused with virtual circuit-switching such as Time-Division Multiplexing (TDM). Router is used to denote any packet-switched router. The router might implement Quality-of-Service features such as TDM, and/or prioritization of data. 3 Motivation and Related Work Most NoC research has focused on packet-switching, which is very ﬂexible as it allows the same physical link to be shared by many different connections. Typically, general purpose topologies, such as the widely used 2D mesh, are employed. In these homogeneous topologies, a packet passes several routers, even when the communicating IPblocks are localized close to each other. As future SoC platforms are expected to contain hundreds of IP-blocks the NoC needs to support an even larger number of connections and many connections span a large number of routers. This means that routers have to be faster to provide the required bandwidth and that more buffers are needed to support the large number of independent connections. As many applications have communication constraints, routers also get more complex in order to support different levels of Quality-of-Service, such as bandwidth and latency guarantees or prioritization of trafﬁc. Routers therefore contribute a very large part of the total NoC power consumption. In [4], for example, each port in a 5x5 router uses 10 times more power than a 2 mm link in a 130 nm technology. The key to obtaining lower area, latency and power consumption in the NoC, is to exploit knowledge of the application running on the SoC. In the context of homogeneous topologies, a few long links [5] can be inserted in the topology. This allows connections spanning many routers to bypass these routers using the long links, and it thereby decreases the amount of trafﬁc in the intermediate routers. A more efﬁcient option is to generate a heterogeneous, application-speciﬁc topology that matches the communication requirements for the application running on the SoC. This includes long links, and direct links between IP-blocks. Application-speciﬁc topologies have been shown to be very energy, area, and latency efﬁcient compared to regular topologies, and have recently been receiving more attention [6, 4, 7, 8, 9]. Common for this research is that only static topologies are considered and the usage of application-speciﬁc topologies is therefore limited to application-speciﬁc chips designed for a single, or a number of very similar, applications. In contrast to packet-switching, physical circuitswitching enables efﬁcient, direct, physical connections to be set up between IP-blocks. As connections are dedicated, no buffering, arbitration and routing are needed and physical circuit-switching is therefore very energy, area, and latency efﬁcient. In [10], the authors report that the delay is decreased by 85% and the energy by 70% by bypassing 5656 FIFO buffers and synchronization logic. On the other hand, physical circuit-switching is inﬂexible as links can not be shared, and few articles have considered it in the context of NoC. An example of a physical circuit-switched NoC is [11], where connections can be set up directly between IPblocks. The connections are conﬁgured using a separate packet-switched network which is also used for Best Effort (BE) trafﬁc. The disadvantage is that the connections can not be shared, and that two separate networks exist. The goal of the ReNoC architecture is to combine the best from the worlds of packet-switching and physical circuit-switching. Physical circuit-switching is used to set up energy-efﬁcient end-to-end connections between IPblocks and/or to form (long) links between routers, bypassing intermediate routers (which may or may not be powered down). Thereby, the topology can be changed by reconﬁguring the circuit-switches (in the following, denoted topology switches due to their functionality) while packetswitching can be used to share the circuit-switched connections when the ﬂexibility is needed. To our knowledge, no previous work has been done in combining packetswitching and physical circuit-switching such that the two methods co-exist in the same architecture. A somewhat related idea is presented in [12, 13]. Here the authors argue - from an algorithm and parallel processing viewpoint - that the interconnect topology in a multiprocessor platform should be reconﬁgurable. The authors suggest that the network be implemented in FPGA technology, but beyond this the papers offer limited information on implementation issues. Our work is different in that it originates in a desire to provide efﬁcient interconnect in (heterogeneous) multi-core systems-on-chip, by combining packet-switching, circuit-switching and reconﬁgurability, and in that we present an implementation which is reconﬁgurable at a more course grained level. The latter results in a higher performance and a more cost-effective solution. 4 ReNoC Architecture In this section we present the Reconﬁgurable NoC (ReNoC) architecture. First, the basic concepts of the architecture are explained through a simple example, before the generality of the architecture is discussed. 4.1 Basic Concepts Figure 1 shows an overview of the ReNoC architecture. As introduced in section 1, it allows a logical topology to be conﬁgured on top of the real physical architecture. The topology conﬁguration is transparent for the application, and the application experiences the topology as an ordinary static topology. Network Node IPIP IP 1 IP 2 IP 3 Router IP IP 4 IPIP 7 IP 5 IP 8 IP 6 IP 9 R IPIPIP 10 IP 11 IP 12 Topology Switch Figure 2. A simple physical architecture where network nodes are connected in a 2D mesh topology. A network node consists of a router that is wrapped by a topology switch. The fundamental ideas of ReNoC are best explained through an example. For this, ﬁgure 2 shows a physical architecture consisting of network nodes connected by links in an 2D mesh topology. Each network node consists of a conventional NoC router which is wrapped by a topology switch. The topology switches are used to connect links and routers into a logical topology and they thereby allow different application-speciﬁc logical topologies to be conﬁgured on top of the same physical architecture. Figure 3 shows two examples of logical topologies that can be created by conﬁguring the topology switches appropriately. As seen, it is possible to form long logical links connecting: (i) Any two IP-blocks, (ii) any two routers, and (iii) any IP-block and router. The physical distance between the IPblock/router does not matter, as long as a logical link can be established. Figure 3 illustrates that it is possible to conﬁgure logical topologies that are very different from the basic 2D mesh. If desired, it is also possible to conﬁgure a logical topology which is a 2D mesh. In the logical topologies illustrated in ﬁgure 3, many of the routers and several of the links are unused. Clock gating may be used to eliminate the dynamic power consumption of these, and leakage power consumption can be reduced or eliminated completely by the use of power gating techniques. This is a key feature motivating the development of ReNoC. The ”physical architecture” and the ”logical topology 1” shown in ﬁgure 2 are part of the evaluation that is presented in section 5 and are discussed more at that point. 4.2 Topology Switches As illustrated in ﬁgure 2, topology switches are inserted as a layer between the links and the routers, allowing links 5757 Physical Architecture Link Link IPIP IP 1 IP 2 IP 3 IP IP 4 IPIP 7 IP 5 IP 8 IP 6 IP 9 IPIPIP 10 IP 11 IP 12 Configuration Router Port 1 Port 2 Port 3 Port 4 Port 5 Link Link Logical Topology 1 Logical Topology 2 IP1 IP2 IP3 IP1 IP2 IP3 Topology switch IP−block R IP5 R IP6 IP4 IP7 R IP8 IP9 R R R R IP4 IP7 IP5 IP8 R R R R IP6 IP9 IP10 IP11 R IP12 IP10 IP11 IP12 Figure 3. Two possible conﬁgurations of the physical architecture in ﬁgure 2. By conﬁguring the topology switches appropriately, a wide range of different logical topologies can be created. to be connected to a port on the router or directly to other links. Topology switches are meant to be conﬁgured infrequently such as once every time the chip is powered up, or when a new application is started. Fast reconﬁguration is therefore not required, allowing an area and energy efﬁcient implementation. In many respects, a topology switch is analogue to a switch-box in an FPGA and it can be implemented using the same techniques such as pass-gates, tristate buffers or multiplexers. The topology switch in ﬁgure 2 connects 4 links, an IPblock and a 5 port router. It must be able to connect links directly to each other, or to a single port on the router. If the ”outside” ports connecting the topology switch to the links, including the link to the local IP-core, are denoted LN , LE , LS , LW and LIP (north, east, south, west, and local IP) and if the ”inside” ports connecting the topology switch to the router are labeled RN , RE , RS , RW and RIP then the topology switch must support the following directional connections: 5858 Figure 4. A multiplexer-based implementation of an asymmetric topology switch that can be used to connect 4 links, an IP-block and a 5-port router. Links can be connected directly to other links, the IP-Block or the corresponding port on the router. • Li → L j where i, j ∈ {N , E , S,W , IP} and i 6= j i.e., incoming links can be connected directly to outgoing links - thereby bypassing the router altogether. • Li → Ri where i ∈ {N , E , S,W , IP} i.e., incoming links can be connected to the corresponding ports on the router. • Ri → Li where i ∈ {N , E , S,W , IP} i.e., ports on the router can be connected to outgoing links. Figure 4 shows a possible multiplexer-based implementation of such an asymmetric topology switch. If the links use low-swing signalling, it is also possible to implement the topology switches using low-swing switches as presented by Dally [14]. It should be noted, though, that low-swing links and low-swing topology switches cannot be implemented using standard cell libraries as it requires custom circuitry. 4.3 Routers As there is a clear separation between topology switches and routers, the architecture is not restricted to a speciﬁc router. The only requirement is that the link width, including wires for ﬂow-control, matches the ports on the router. In principle the communication protocol is deﬁned by the routers and the topology switches and links act as passive Router R Topology Switch Topology Switch Router + R IP IP IP IP IP IP IP IP IP IP Figure 5. Example of a complex, heterogeneous, physical architecture. Network nodes can contain a router, a topology switch, or both. Several IP-blocks can be connected to the same network node, several links can exist between network nodes, and IPblocks can be directly connected. circuit-switched interconnects. This means that the architecture can be used in combination with any existing router. The routers can contain Virtual Channels (VC), Qualityof-Service (QoS) implementations such as TDM, queuingbuffers, and can be implemented using synchronous or asynchronous circuit techniques. The ReNoC concept can thus be used with existing routers including Æthereal [15], Mango [16], and Xpipes [17]. 4.4 Generalization and Discussion The physical architecture is not restricted to a simple 2D mesh as has been considered so far for illustration purposes. The physical architecture can be organized as any topology such as a tree, a mesh, some heterogeneous topology or hierarchical topology. To illustrate the full potential of ReNoC, ﬁgure 5 shows a heterogeneous physical architecture. As shown in the ﬁgure, network nodes can contain a router, a topology switch, or both. Links between network nodes can be both bi- and uni-directional, and several links can exist between two speciﬁc network nodes. Direct physical links can also exist between IP-blocks, and several IPblocks can be connected to the same network node. Note, that routers do not need to have the same number of ports as the number of links that is connected to the topology switch. The topology switch enables the same router port to be connected to different links depending on the conﬁguration. Hence, the router port becomes a sharable resource. In ﬁgure 5, some of the topology switches contains a large number of link ports. If these topology switches were to allow links to be connected in all possible combinations, they would consume a large amount of energy and area. Instead, we envision the large topology switches to be highly asymmetric such that each incoming port can only be connected to a subset of the outgoing ports. The logical topology must be conﬁgured such that the latency of the slowest logical link does not exceed the clock period. If needed, it is also possible to pipeline the logical links by inserting pipeline registers in the topology switches or on the physical links. Depending on the physical link length and the operating frequency of the router, it might be enough to have pipeline registers in a subset of the topology switches. As in any design, clock-skew is also an issue to consider but this issue is beyond the scope of this paper. In our current work the logical topology is conﬁgured at initialization time, and the different use-cases of an application will run on this logical topology. This is the scenario illustrated in ﬁgure 1. More elaborate architectures and scenarios are possible which allow run-time conﬁguration of an individual logical topology for each use-case, but this implies signiﬁcant added complexity and is beyond the scope of this paper. 5 Evaluation The purpose of the evaluation is to demonstrate the potential of the ReNoC architecture and estimate the overhead of the topology switches. This is done by mapping an application onto a NoC architecture with a static 2D mesh topology as well as a simple ReNoC architecture in two different topology conﬁgurations. The physical architecture is chosen such that it, besides being conﬁgured as an application-speciﬁc topology, can be conﬁgured as an ordinary 2D mesh. This illustrates a ReNoC architecture that is a general platform where all IP-blocks are able to communicate but which can also conﬁgured in an application-speciﬁc topology. In the following we describe the application, the physical architecture, and the router choice in more detail. The implementation details are presented in section 6 and the results in section 7. 5.1 Benchmark Application and Network Topologies As benchmark we use the Video Object Decoder (VOPD) application that is presented in [6] where an application speciﬁc, hard-wired topology is compared to a 2D mesh topology. Figure 6(a) illustrates the Task Graph of the VOPD. Each node in the graph represents a task while the edges denote the average required bandwidth between tasks 5959 vld 70 362 run le. dec inv scan vld run le. dec inv scan 362 We assume that each physical link has a length of 1 mm which allows the IP-block to be approximately 1 mm2 . iDCT 357 iQuant 362 ac/dc predict R iQuant R ac/dc predict 5.3 Router Choice 353 27 49 iDCT up sample 300 VOP reconstr. stripe mem up sample R VOP reconstr. stripe mem 16 500 ARM VOP mem (a) 313 94 313 padding ARM VOP mem R padding (b) Figure 6. (a) Task graph of the VOPD application. Edges denote bandwidth in Mbit/s. (b) ReNoC architecture where a logical application-speciﬁc topology is conﬁgured for the VOPD application. in Mbit/s. The placement of the tasks in the graph represents the mapping onto the architectures used in the evaluation. The following architectures are used for comparison: Static mesh: A static 2D mesh topology used as reference. It is similar to the topology shown in ﬁgure 2 where each network node contains a statically connected router. ReNoC mesh: The ReNoC architecture that is conﬁgured to provide a 2D mesh logical topology similar to Static mesh. This conﬁguration is used to characterize the overhead of the topology switches. ReNoC speciﬁc: The ReNoC architecture that is conﬁgured with the application speciﬁc topology shown in ﬁgure 6(b). The beneﬁts of ReNoC depends on the relative energy consumption of topology switches and routers. If the routers consume much more energy than the topology switches, ReNoC will have a clear advantage as an application-speciﬁc topology decreases the amount of trafﬁc in the routers. If the topology switches, on the other hand, consume as much energy as the routers, the overhead of the topology switches will dominate the total power dissipation making ReNoC infeasible. In order to obtain a reasonably fair evaluation, which does not overestimate the beneﬁts of the ReNoC concept, it is important to choose a router whose bandwidth and features does not signiﬁcantly exceed the requirements of the application. A router with advanced QoS features, or a heavily pipelined router operating at 900 MHz, use much more power than a simple low-frequency router. High operating frequency also means a large power consumption in clocked elements even when no ﬂits are passing through the router. The level of clock-gating is also a very important factor as routers provide bandwidth in Gbit/s and therefore can be idle for large periods of time. To make the comparison fair, we have implemented a simple, low-power, packet-switched router and topology switch. The router architecture is presented in detail in section 6 and is a standard architecture as presented by Dally [18]. The router is operating at 100 MHz, which gives a maximum bandwidth of 2.4 Gbit/s per link if ﬂits contain 32 bit data and a packet is made of 4 ﬂits with the ﬁrst ﬂit being a dedicated header ﬂit. This bandwidth is more than enough for the VOPD application with the largest needed average bandwidth between two tasks being 500 Mbit/s. 5.2 Physical ReNoC Architecture 6 Implementation The physical architecture used in the evaluation is shown in ﬁgure 2 and was introduced in section 4.1. Each network node consists of a router wrapped by a topology switch. There are 3 different types of network nodes that differ in the number of connected links and router size. The two network nodes in the middle of the mesh contains 5x5 routers and connect 4 links. The network nodes in the sides, bottom, and top contains 4x4 routers and connect 3 links, while the network nodes in the corners contains 3x3 routers and connect 2 links. As explained in section 4.2, topology switches are constructed such that they can connect links in all possible combinations as well as links directly to corresponding ports on the router. The evaluation is conducted using area and energy models for routers, topology switches and links. Routers and topology switches have been synthesized and power characterized using commercial synthesis and power characterization tools using estimated wire-load models while link characterization is based on ﬁgures from existing literature. All ﬁgures are based on low-leakage cells from a commercial 90 nm standard cell library, using a 1 V supply voltage at nominal parameters. The designs are implemented for low-power applications operating at 100 MHz. Table 1 summarizes the area and energy consumption of the models. Four ﬁgures are stated for each model: (i) Area is simply the area reported by the synthesis tool, (ii) energy/packet is the average energy consumed when sending 6060 Table 1. Characterization of topology switches and link. the routers, Module Area Link, 1mm 5x5 Router Topology Switch 4x4 Router Topology Switch 3x3 Router Topology Switch (mm2 ) 0.061 0.007 0.047 0.005 0.032 0.003 Energy Leakage per packet ( pJ ) (µW ) Idle power (µW ) 21 32 0.6/0.8 31 0.6/1.1 30 0.6/1.3 8.6 0.7 6.7 0.6 4.7 0.3 136 109 82 Table 2. Characterization of the modules in the 5 port router with 2 virtual channel buffers in each input port. Module Area Input Port Virtual Channel Output Port 5x5 Switch VC Allocator Switch Allocator (mm2 ) 8900 4300 1350 3800 5100 900 Energy Leakage per packet ( pJ ) (µW ) 21.1 16.4 5.7 2.6 1.6 0.8 1.2 0.6 0.15 0.4 0.8 0.13 Idle power (µW ) 18.8 8.7 6.3 11.3 a packet based on random data, (iii) leakage is the leakage power consumption, and (iv) idle power is the dynamic power that is always consumed - independent of the use. Idle power accounts for clocking of clock-gates and registers that are not clock-gated. A packet contains a 96 bits of data. In the following routers, topology switches and links are discussed in more detail. 6.1 Routers Figure 7 shows and overview of our router architecture. The router is a conventional source-routed, input-buffered, packet-switched router with Virtual Channels (VCs) as presented by Dally [18, chapter 16]. Input ports contain 2 Virtual Channel (VC) buffers, each capable of holding 4 ﬂits which is implemented using a small register ﬁle. Besides the registers in the VCs, there is a single register in the output ports. A packet contains a dedicated header ﬂit, followed by 3 payload ﬂits. The ﬂit size is 34 bits - 32 bits for Virtual Channel Allocation Switch Allocation Switch NxP Flow−ctrl Data Flow−ctrl Data Input Port 1 Input Port 2 Output Port 1 Output Port 2 Flow−ctrl Data Flow−ctrl Data Flow−ctrl Data Input Port N Output Port P Flow−ctrl Data Flow−ctrl Data Control VC VC Flow−ctrl Data Data Flow−ctrl Data Figure 7. Overview of the router architecture used in the evaluation. data/header, 1 bit to indicate the virtual channel, and 1 bit to indicate the last ﬂit in a packet. Besides these 34 bits, the link contains a single bit to indicate the presence of a ﬂit as well as 2 bits for ﬂow-control which is credit-based. Hence, the total link width is 37 bits, including ﬂow-control. The router is synthesized to operate at 100 MHz and is singlecycled - meaning that it can perform virtual channel allocation, switch allocation and switch traversal in a single cycle. As there is a register in the output ports, this means that it ideally takes one cycle to traverse the router and one cycle to traverse the link. The router can actually be synthesized to operate at 400 MHz (with 5 input and 5 output ports), but this speed is not needed and leads to a larger router that consumes more energy. The router is clock-gated at buffer-level, such that it only consumes a small amount of power when it is sparsely used. Table 2 lists the characterization of the different submodules of a router with 5 input and 5 output ports. The energy/packet is based on simulations using random data both for address and payload data at 20% maximum bandwidth utilization. 6.2 Topology Switches The topology switches are implemented using multiplexers as illustrated in ﬁgure 4. All outgoing ports can be disabled to avoid toggles to be propagated to the corresponding port. Besides multiplexers, each topology switch contains registers to control the multiplexers. In this paper we do not 6161 consider how these conﬁguration registers are written. The topology switches are synthesized for low energy and area, and as for the router, the energy/packet is based on simulations using random data both for address and payload data at 20% maximum bandwidth utilization. As the topology switches are asymmetric, table 1 states two energy ﬁgures for each topology switch. The ﬁrst ﬁgure is the energy consumed when sending a packet to a router port while the second ﬁgure is the energy consumed when sending a packet to a link or IP-block. The worst-case latency of the largest topology switch is 550 ps. 6.3 Links Energy consumption in the links is based on the SPICE simulated ﬁgure presented in [19]: 0.36 pJ/transition/mm at a supply voltage of 1.2 V. Scaling to 1 V this becomes 0.25 pJ/transition/mm, which is the ﬁgure used in our evaluation. The energy/packet is estimated by assuming 50% switching activity on the 34 bits in the ﬂit, 2 transitions on the request wire and 2 transitions on the ﬂow-control. As a packet consists of 4 ﬂits and links are assumed to 1 mm, this sums up to 21 pJ/packet containing 96 bits. A pessimistic estimate of the latency of a 1 mm link is 120 ps. This is based on an lumped delay model added 50% driver overhead using an estimated wire capacitance and resistance of 0.2 pF/mm and 0.4 KΩ/mm. 7 Results and Discussion Table 3 shows the area and power consumption of the 3 architectures that were presented in section 5.1. As seen in ﬁgure 6(b), only 25% of the routers are used in ReNoC speciﬁc, and the remaining routers are assumed to be powergated to decrease the leakage- and idle power consumption. The area overhead of the ReNoC architecture is found by comparing the area of Static mesh with the area of ReNoC mesh. The area increases with 10% which shows that the area overhead of the topology switches is small. The overhead in terms of power consumption is evaluated by comparing Static mesh with ReNoC mesh, as they both have a 2D mesh logical topology. The topology switches increase the power consumption by 3%, indicating that the overhead in terms of power consumption is minimal. When an application-speciﬁc topology is conﬁgured in ReNoC speciﬁc, the power consumption is decreased by 56% compared to Static mesh, including the power consumption in the topology switches. The topology switches only use 5% of the power in ReNoC speciﬁc. An important observation that illustrates the potential of the ReNoC architecture, is that only a few ports are used on the routers in ReNoC speciﬁc. The area and power consumption can be decreased further by using routers with fewer ports - for example 3 ports. Even though it will no longer be possible to conﬁgure a 2D mesh topology, it will still be possible to conﬁgure a wide range of different topologies. Thereby the area and power consumption will approach that of a static application-speciﬁc topology. ReNoC is evaluated using a low-power router using an operating frequency of 100 MHz. As the latency of a link and topology switch is 120 and 550ps, respectively, it is possible to traverse approximately 14 links and topology switches within a single cycle - assuming near zero clock skew. ReNoC can also be used in high performance designs. As discussed in section 5.3, the area and power overhead will be relatively smaller if larger, more complex, routers are used and/or the router is clocked at higher frequencies. If the routers are clocked at a higher frequency, it might be necessary to synthesize the topology switches with focus on latency instead of energy. Pipeline registers can also be inserted in the topology switches or physical links as discussed in section 4.4. 8 Conclusion and Future Work In this paper we have presented the ReNoC architecture that enables the network topology to be reconﬁgured using energy-efﬁcient topology switches. The architecture was evaluated by mapping an application to a static 2D mesh topology as well as a ReNoC architecture in two different topology conﬁgurations. The power consumption was decreased by 56% when conﬁguring an applicationspeciﬁc topology, compared to the static 2D mesh topology. The topology switches increased the area of the NoC architecture with 10%, and only contributed with 5% of the power consumption in the application-speciﬁc topology. The evaluation shows that the ReNoC architecture enables application-speciﬁc topologies to be conﬁgured with little overhead and indicates that the architecture has great potential for future SoC platforms. Future research include exploration of physical architectures for multiple applications as well as automatic generation of homogeneous and heterogeneous physical architectures. More research also has to be done on efﬁcient implementation and conﬁguration of the topology switches. "
"Simulation and Evaluation of On-Chip Interconnect Architectures - 2D Mesh, Spidergon, and WK-Recursive Network.","Network-on-chip has been proposed as an alternative to bus-based system to achieve high performance and scalability. The topology of on-chip interconnect plays a crucial role in system on chip performance, energy, and area requirements. In this paper, an on-chip interconnects architecture based on WK-recursive network is proposed. WK-recursive structure is analyzed and compared to 2D mesh and Spidergon structures. Simulation results show that WK-recursive on-chip interconnect generally outperforms the other architectures.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Simulation and Evaluation of On-Chip Interconnect Architectures: 2D mesh,  Spidergon, and WK-recursive network   S. Suboh, M. Bakhouya, T. El-Ghazawi  ECE Department, George Washington University  {suboh, bakhouya, tarek}@gwu.edu  Abstract  2. Methodology and analysis  Network-on-chip has been proposed as an alternative  to bus-based system to achieve high performance and  scalability. The topology of on-chip interconnect plays  a crucial role in System on chip performance, energy,  and area requirements. In this paper, an on-chip  interconnects architecture based on WK-recursive  network  is proposed. WK-recursive structure  is  analyzed and compared to 2D mesh and Spidergon  structures. Simulation results show that WK-Recursive  on-chip interconnect generally outperforms the other  architectures.  Performance metrics are explored for the considered  topologies. A simulator developed in [4] is upgraded  and modified to suit different topologies and their  related parameters [5]. Recently, NoC architectures  have been studied and compared based on different  performance metrics  such as message delay,  throughput and network load [1, 5, 6]. In our study,  topologies of 16-nodes of 2D mesh, Spidergon, and  WK(4,2) are constructed (see figure 1). WK-Recursive  network with amplitude W and level L, is denoted by a  WK(W,L) [3].   1. Introduction  Network on a Chip (NoC) is a platform where the  design is centered on a dedicated network that is used  instead of traditional non-scalable bus-based systems.  One of the main issues in NoC is the network topology  and how flexible can be extended without major  modification.   Different topologies, proposed initially in parallel  computing field, have been studied and adapted for  NoC (e.g., 2D Mesh, Torus) [1]. In this paper, a new  architecture, based on  recursive networks,  is  investigated. WK-recursive network was  initially  proposed in [2] as a network for VLSI implementation.  Since this topology has many attractive properties,  such as a high degree of regularity, symmetry and an  efficient communication, WK-Recursive networks  have also received considerable attention in parallel  computing community [3]. An interesting property that  makes  this  structure most  suitable  for NoC  architectures is the ability to expand the network to any  arbitrary size level without reconfiguring the edges. In  this paper, WK-recursive network is compared with the  most commonly used topologies in NoC: 2D regular  mesh and Spidergon networks. Simulation results are  reported for different performance metrics.  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.25 DOI 10.1109/NOCS.2008.25 205 205 Figure 1. The chip layout of (a) 2D Mesh, (b)  Spidergon, and (c) WK.   To analyze and compare the above interconnect  topologies, the following performance metrics are  considered: latency, flits loss, aggregated throughput,  and communication load [4, 5]. The considered values  of the injection rate are 70, 100, 130, 160, and  190Mbps. The size of the buffer is fixed to 32 flits.  Figure 2 compares the latency of the three topologies  when a heavy traffic is applied. In this figure, 2D mesh  and Spidergon show higher maximum  latency  compared to the WK-recursive topology. Figure 3  shows the variation of aggregated throughput under  different injection rates. Wk-recursive interconnect  outperforms the rest of the topologies when the  injection rate is less that 160Mbps because of lower  loss rate as depicted in figure 4. Figure 5 shows that                       WK outperforms  the rest of  communication load.  topologies  in  the  He avy tr af ic (190M bps ) ) s m ( t y c n e a L x a M 0.64 0.62 0.6 0.58 0.56 0.54 0.52 0.5 0.48 e a t r s s o L 0.1 0.09 0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01 0 60 110 160 In je ction r ate Me sh S pi der gon Wk 210 Mesh Spidergon Wk Figure 2. Maximum latency for the three  topologies.  Figure 4. Variation of loss rate vs. injection  rate  d a o L . m m o C 0.6 0.5 0.4 0.3 0.2 0.1 0 Mesh Spi der go n Wk 60 110 160 Inje ction rate Mesh Sp i der g on Wk 210 Figure 5. Variation of communication load vs.  injection rate   [2] G. D. Vecchia and C. Sanges, “A Recursively Scalable  Network VLSI  Implementation”, Future Generation  Computing Systems, 1988,  4(3), pp. 235-243.  [3] A. Mahdaly, H. T. Mouftah, and N. N. Hanna,  “Topological properties of WK-recursive networks”,  Proceeding of Second IEEE Workshop on Future Trends of  Distributed Computing Systems, 1990, pp. 374-380.  [4] Y. R. Sun, S. Kumar, and A. Jantsch, “Simulation and  Evaluation of a Network on Chip Architecture Using ns2”, In  Proceedings of the IEEE NorChip Conference, 2002.  [5] S. Suboh, M. Bakhouya, S. Lopez-Buedo, and T. ElGhazawi. “Simulation-based Approach for Evaluating OnChip Interconnect Architectures”, Proceeding of SPL 2008,  to appear.   [6] L. Bononi and N. Concer, “Simulation and Analysis of  Network on Ship Architectures: Ring, Spidergon, and 2D  Mesh”, Proceedings of DATE’06, 2006.  ) s p b M ( t u p h g u o r h T 2000 1800 1600 1400 1200 1000 800 60 80 100 120 140 16 0 180 200 In je ction r ate Figure 3. Variation of throughput vs. injection  rate  3. Conclusion and future work  In this paper, a NoC interconnect based on the WK  recursive network is proposed. The simulation study  compares this topology with two NoC architectures:  2D regular mesh and Spidergon. WK-recursive  interconnect generally outperforms 2D mesh and  Spidergon topologies because of its regular and stable  behavior at the nodes’ level. Other important metrics,  such as energy consumption and area requirements are  under investigation.    4. "
A Design-for-Test Implementation of an Asynchronous Network-on-Chip Architecture and its Associated Test Pattern Generation and Application.,"Asynchronous design offers an attractive solution to overcome the problems faced by networks-on-chip (NoC) designers such as timing constraints. Nevertheless, post-fabrication testing is a big challenge to bring the asynchronous NoCs to the market due to a lack of testing methodology and support. This paper first presents the design and implementation of a design-for-test (DfT) architecture, which improves the testability of an asynchronous NoC architecture. Then, a simple method for generating test patterns for network routers is described. Test patterns are automatically generated by a custom program, given the network topology and the network size. Finally, we introduce a testing strategy for the whole asynchronous NoC. With the generated test patterns, the testing methodology presents high fault coverage (99.86%) for single stuck-at fault models.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip A Design-for-Test Implementation of an Asynchronous Network-on-Chip   Architecture and its Associated Test Pattern Generation and Application  Xuan-Tu Tran1, 3, Yvain Thonnart1, Jean Durupt1, Vincent Beroulle2, and Chantal Robach2  1CEA-LETI, MINATEC – 17 rue des Martyrs, 38 054 Grenoble, France, {yvain.thonnart, jean.durupt}@cea.fr  2INPG-LCIS – 50 rue B. de Laffemas, 26 902 Valence, France, {vincent.beroulle, chantal.robach}@esisar.inpg.fr  3VNU-COLTECH – 144 Xuan Thuy Road, 10 000 Hanoi, Vietnam, xuan-tu.tran@ieee.org  Abstract  Asynchronous design offers an attractive solution to  overcome the problems faced by Networks-on-Chip (NoC)  designers such as timing constraints. Nevertheless, postfabrication testing is a big challenge to bring the asynchronous NoCs to the market due to a lack of testing  methodology and support.  This paper first presents the design and implementation of a Design-for-Test (DfT) architecture, which  improves the testability of an asynchronous NoC architecture. Then, a simple method for generating test patterns  for network routers is described. Test patterns are automatically generated by a custom program, given the  network topology and the network size. Finally, we  introduce a testing strategy for the whole asynchronous  NoC. With the generated test patterns, the testing methodology presents high fault coverage (99.86%) for single  stuck-at fault models.  1. Introduction  To overcome the problems faced by Network-on-Chip  (NoC) designers such as timing constraints, the GALS  (Globally Asynchronous - Locally Synchronous) paradigm  has been proposed  [1]. In a GALS system, a number of  synchronous islands communicate asynchronously with  each others using an asynchronous communication environment. The NoC architecture is perfectly adapted to the  GALS platform where the network architecture (network  routers and links) are fully implemented using asynchronous logic while the computational resources (i.e. Intellectual Properties or IPs) are implemented with standard  synchronous design methodologies.   Recent works have proposed some asynchronous implementations of NoC architectures  [2],  [3],  [4],  [5]. The  main advantages of asynchronous NoCs are robustness  (insensitivity to delay variation due to physical constraints, temperature and voltage), ease of routing, low  power management.   As the NoC paradigm is being brought to market, the  test of NoC-based SoCs for post-fabrication faults becomes a major challenge. Actually, in NoC-based systems,  the embedded computational resources can be tested using  traditional methods, while efficient testing methods for  NoC architectures are really needed because of their  regular structures.  Several Design-for-Test (DfT) propositions were made  for testing NoC architectures. Most of them, however,  focus on synchronous NoCs  [1],  [6],  [7],  [8]. To the best  of our knowledge only two propositions were made for the  test of asynchronous NoC architectures  [9],  [10].  In this paper, we present: (1) the design and implementation of such a DfT architecture using a Quasi-DelayInsensitive (QDI) asynchronous logic template and a  65nm CMOS technology from STMicroelectronics; (2) a  simple method to generate test patterns for network  routers and links; and (3) a testing strategy for the whole  NoC architecture.  The remaining part of this paper is organized as follows: Section  2 presents an overview of NoC-based  systems testing. The asynchronous NoC architecture used  in our work is shortly presented in Section 3. The proposed DfT architecture is presented in Section  4. Section   5 presents the design and implementation of the proposed  architecture. The method to generate test patterns is  introduced in Section  6. Section 7 describes a testing  strategy for the whole network architecture. Finally,  experimental results and conclusions are presented in  Section  8 and Section  9, respectively.  2.  NoC-based SoC testing: State of the Art   Like other SoCs, NoC-based SoCs have to be tested for  manufacturing defects. Because of their regular structures,  the testing strategy for NoC-based system should address:  (i) the test of embedded computational resources (IPs) and  their corresponding network interfaces; (ii) the test of the  interconnection  infrastructure consisting of network  routers and links between the routers.   2.1. Reuse of the network architecture for testing  embedded computational resources  To test the embedded IPs in NoC-based SoCs, the  IEEE 1500 standard’s test wrapper  [11] can be used for  each embedded IP while the network architecture can be  used as a high bandwidth test access mechanism. Test data  are encapsulated into packets that are transported on the  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.24 DOI 10.1109/NOCS.2008.24 149 149                         network using the network protocol. The idea of using the  network architecture as a Test Access Mechanism (TAM)  has been first proposed by Mohsen Nahvi and André  Ivanov at the University of British Columbia, Canada with  the NIMA (Novel Indirect and Module Architecture)  network  [12]. This network architecture has been intentionally developed for test purposes, not for communication purposes. Not long after that, several IP testing  solutions reusing NoC as high bandwidth TAMs have  been also proposed  [13],  [14]. The main difference  between these propositions is the design of test wrappers  and their adaptation to the network behavior.    The principal advantages of this approach are the  absence of extra TAM hardware cost and the availability  of multi-path core test. In addition, test data process is  decoupled from its transfer and scalability of test architecture is also improved. However, to be used the NoC  architecture should be searched for defects before.   2.2. Test of the interconnection architecture  A simple way to test the network is to route test data in  the network with different paths using the network protocol. If the test responses are different from expected or if  they are lost, one can say that the network is faulty. The  advantages of this approach are its simplicity and no  hardware area cost. However, this approach has also  several drawbacks. Although the network routers can be  configured to transport test data to anywhere in the network, the testability of the network is still unresolved. We  cannot access directly all inputs of the router-under-test  for controlling purpose, and we cannot access directly all  outputs of the router-under-test for observing purposes.   There are several DfT propositions for testing NoC  architectures. For synchronous NoCs, because network  routers consist of FIFO buffers and routing logic parts,  most of discussions  [1],  [6] said that the test of network  router should be done partially: using a BIST (Built-In  Self-Test) for FIFOs, and traditional methods for routing  logics. Unfortunately, FIFOs are distributed all over the  chip, which is a big challenge for this approach.   Several propositions  [7],  [8] have been done since then  using serial scan, which is very expensive for the test of  asynchronous NoCs in terms of area and test time. Besides, these works focus only on testing network routers,  and do not address the test of network links across clock  domains.   Asynchronous NoCs are designed and implemented in  asynchronous logics without global clock. The test of  asynchronous NoCs is more difficult than the test of  synchronous NoCs because of many feedback loops in  asynchronous circuits and the lack of EDA (Electronics  Design Automation) supports for testing  [15]. There are  several DfT approaches for asynchronous circuits but area  overhead is quite important.  [9] presents a testing architecture for an asynchronous NoC based on scan-latches  insertion to break the feedback loops of Muller-Celements1. Unfortunately, the area overhead is then of  about 43% of the total area, whatever the size of the  design.  [10] presents a DfT architecture that uses a test  wrapper around network routers. In such an approach,  DfT area is not proportional to the total area but to the  number of inputs/outputs, which may lead to a lower area  overhead. However,  [10] does not present any implementation result.   3. Presentation of the base NOC Architecture  This section aims at presenting the asynchronous NoC  architecture that served as a basic for the present study.  Edith Beigné et al. proposed an Asynchronous Network-on-Chip architecture providing low latency Quality  of Service (QoS)  [4], named ANOC. The ANOC is  composed of network routers, network links, asynchronous(cid:1)synchronous  interfaces (SAS  interfaces), and  network interfaces (NIs), as described in Figure 1. The  ANOC was used as an interconnect architecture for a  GALS-based SoC, named FAUST (Flexible Architecture  Unified System for Telecoms)  [16].  IP IP IP NI S A S NI S A S NI S A S R R R IP IP IP NI S A S NI S A S NI S A S R R R IP IP IP NI S A S NI S A S NI S A S R R R Figure 1: ANOC architecture.  The asynchronous network routers are the basic elements of network architecture and they have 5 bidirectional ports that connect to four neighboring routers  and the nearest synchronous computational resource via a  network interface (NI) and a SAS interface. Network  routers and links have been designed and implemented in  QDI asynchronous logic style  [17]. The communication  between network routers is established by a handshake  1 The Muller element is a basic building block for self-timed  digital design. It implements a join on signal transitions  (events).  150150                                                                           protocol (flit-level “send/accept” protocol) with two  virtual channels in order to improve system's QoS. The  network links are 34-bit bidirectional channels, in which  32 bits used for data and 2 bits used for encoding packet  information: Begin-of-Packet (BoP) and End-of-Packet  (EoP). Routing information is included in the header flit in  a path-to-target field shifted in each router after using the  2 lower bits for next direction (source routing), as shown  in Figure 2.  BoP EoP Payload Path–to-Target 33 32 31                         18 17                            0 (a) Header flit BoP EoP Payload 33 32 31                                                              0 (b) Body flit or Tail flit Figure 2: Data flit formats.  4. Proposed Testing Approach for ANOC  As mentioned in Section  2, structural testing approaches used for asynchronous circuits are expensive in  terms of area overhead and test time. Moreover, the lack  of testing supports from EDA companies makes the  ATPG (Automatic Test Pattern Generation) for asynchronous circuits very difficult, sometime impossible.  Therefore, our approach bases on the regularity and characteristics of the network architecture. The main challenge is  how to isolate each network elements, then to apply  directly test patterns to the element-under-test and to get  out the test results.   To ease the test of the ANOC, we have proposed a DfT  architecture as illustrated in Figure 3. In this architecture,  NI S A S NI S A S NI S A S NI S A S NI S A S NI S A S Test W rapper data_in data_ou t cfg_in cfg_ou t GAC un it WCM Configuration chain Figure 3: The proposed Design-for-Test Architecture.  each asynchronous network router is surrounded by an  asynchronous test wrapper in order to improve the controllability and the observability of the routers. The  network links are reused to establish high bandwidth  TAMs.   The test wrappers are used: (a) to insert test vectors to  the elements-under-test (routers and network links) and to  get out the test results; (b) with network links, to establish  high bandwidth asynchronous TAMs to transport test data.  To test a network link between routers, two test wrappers are used to insert test vectors and to get out the test  results.   All operations of the test wrapper are controlled by its  own control module, named Wrapper Control Module  (WCM). To establish a test flow for the whole architecture, a dedicated 2-bit configuration chain (dash line) is  built by connecting serially all wrappers' control modules.  Test flows of the whole architecture are defined by an  external controller. This controller is integrated in a unit,  named GAC (Generator-Analyzer-Controller). The role  of GAC unit is to generate test vectors, to generate test  configurations, and to analyze the test results.   The communication interface between GAC unit and  ANOC architecture is composed of a 34-bit bidirectional  channel and a 2-bit input/output test configuration chain.   The proposed DfT architecture has been designed and  implemented in QDI asynchronous logic style for many  reasons: well adapted to the ANOC architecture, no  dedicated test clock required, and no asynchronous(cid:1)  synchronous interface overhead. In addition, QDI design  is easier to be tested since every transition is necessary to  the good operation of the circuit and QDI circuits are  proven to stall in case of single stuck-at output faults  [18].  The reuse of the inter-router links allows not only getting a high bandwidth TAM but also avoiding wire congestion problems at layout processing phase. The proposed architecture has been designed for the ANOC, but  can also be used to for other QDI asynchronous NoCs or  interconnects.   5. Design and Implementation  In this section, we present how to design and implement the test wrapper, a basic element of the proposed  DfT architecture. The DfT architecture is then realized by  assembling simply these test wrappers.  5.1. Test wrapper architecture  The role of the test wrapper is to transport test vectors  to the router-under-test and to get out the test results. In  corresponding to the number of input/output ports of the  ANOC router, the test wrapper is composed of 5 input test  cells (ITC), 5 output test cells (OTC), and a wrapper  control module (WCM), as described in Figure 4. The  ITCs and OTCs are alternatively interconnected to establish a boundary-scan path around the router. The reason to  interconnect alternatively the ITCs and the OTCs is to  optimize test wrapper’s area cost and wire implementation. The role of the WCM is to control all test cells to do  the test wrapper's function.   151151                    In addition, to reduce test time and to minimize test  complexity, bypass function is always preferred in DfT  architectures. It allows reducing the length of test paths by  giving short-circuits between the inputs and the outputs of  NORTH RES ITC OTC O T C IT C WEST OTC ITC ITC OTC EAST ANOC router 34 OTC ITC Test wrapper SOUTH WCM 2 cfg_in 2 cfg_out Figure 4: Proposed test wrapper with router.  test wrappers. With bypass function, only the routerunder-test is situated in test mode. Therefore, the routerunder-test seems to be directly connected to GAC unit; the  other routers are inactive. In Figure 4 illustrates a bidirectional bypass (dashed bold lines) between EAST input/output ports and WEST input/output ports. The test  data from the EAST input port of the test wrapper is  directly transported to the WEST output port of the test  wrapper and the data from the WEST input port of the test  wrapper is directly transported to the EAST output port of  the test wrapper, without passing the router or passing the  other test cells.  Because the external interface of test wrappers is similar to the external interface of network routers, there is no  change to network architecture except that a 2-bit test  configuration chain is added. As ANOC, the proposed test  wrapper are fully designed and implemented in QDI  asynchronous logic style. We use the 4-phase RTZ (Return-to-Zero) signaling protocol for asynchronous channels, associated to a WCHB (Weak-Condition Half  Buffer) reshuffling for pipelined stages. To get low power  consumption, the full data path (32 bits + BoP + EoP) is  entirely designed with the 1-of-4 (MR4) encoded data   [19], requiring 17 MR4 QDI connections (an MR4 connection includes 4 rails and an acknowledge signal). The  2-bit test configuration path is also designed with the 1-of4 code, requiring an MR4 connection. The other control  channels are designed with the 1-of-2 encoded data (DR:  Dual-Rail) or Single-Rail (SR) encoded connections (a  DR connection includes two rails and an acknowledge  signal, and a SR connection includes a rail and an acknowledge signal).  5.2. Test cells micro-architecture  The main components of the test wrapper are test cells  (ITCs and OTCs). The function of test cells can be described as follows:   In normal mode, communication data are transported  from network to router via ITCs and from router to  network via OTCs, with no need of test control, aside  from the global signal disabling test mode.   In test mode, the operations of an ITC can be explained  as follows: test data from either the network or the previous test cell are stored on this test cell, and then the stored  test data will be transported to either the router-under-test  or the next test cell. It is similar for an OTC: test data  from either the router-under-test or the previous test cell  are stored on this test cell, and then the stored test data  will be transported to either the network or the next test  cell. All of these operations are controlled by control  channels provided by test wrapper’s WCM.   To implement the above functions, we have developed  the micro-architecture of the test cells (for both of ITCs  and OTCs) as illustrated in Figure 5.   0 1 LO CAL S2 noc-in B S1 A cell-in MUX 1 0 MODE ctrl-mux ctrl-mode noc-out cell-out Figure 5: Micro-architecture of input/output test cells.  This micro-architecture is composed of two asynchronous multiplexers (MUX and MODE) and two asynchronous splitting blocks (S1 and S2). With this architecture,  communication data are transported from ‘noc-in’ input to  ‘noc-out’ output via MODE in normal mode. In test  mode, test data from either ‘noc-in’ input or ‘cell-in’ input  are stored on the asynchronous channel ‘LOCAL’ between  MUX and MODE/next-cell thanks to memorizing characteristics of asynchronous channel design, then the stored  test data will be transported to either ‘noc-out’ output or  ‘cell-out’ output. These operations are controlled by two  asynchronous channels,  ‘ctrl-mux’ and  ‘ctrl-mode’,  provided by WCM.  In normal mode, ‘ctrl_mode’ is only probed, and needs  152152                   no acknowledge (using an asymmetric C-element) for  minimal added latency and control.  To send data to either one of two sub-components, we  use an un-controlled splitting block. The input channel  ‘noc-in’ is hence split by S1 to two channels (A and B)  that are connected to MODE and MUX. Similarly, the  local memorizing channel ‘LOCAL’ is split by S2 to two  channels that connected to MODE and ‘cell-out’. These  un-controlled splitting blocks are combinational and they  can be easily implemented by combining the acknowledge  signals (the acknowledge signals from MUX and MODE  for S1, and the acknowledge signals from MODE and  ‘cell-out’ for S2) in order to reduce both latency (a single  gate) and area cost. The detail implementation of these  blocks is beyond the scope of this paper. In addition, in  our architecture we use two accept signals (‘accept0’ and  ‘accept1’) to control data flows of two virtual channels.  Each multiplexer (MUX and MODE) generates a pair of  accept signals. Thanks to their exclusive condition, the  output accept signals at ‘noc-in’ are generated by merging  the accept signals from these multiplexers. This can be  done by a small combinational block. In order to simplify  the representation of test cells, the implementation of  send/accept signals is not included in the Figure 5.   The size of test channels is the same as the size of network links because the multiplexers and splitting blocks  are implemented with 34-bit wide channels. Therefore,  each test channel has 17 MR4 QDI connections for data  path, a dual-rail (DR) connection for send signal, and two  single-rail (SR) connections for two accept signals (‘accept0’ and ‘accept1’).   5.3. Test cells with bypass function  As mentioned above, the bypass function is often preferred in DfT architectures. In our case, to implement a  bypass function for the test wrapper, we have modified the  test cells as illustrated in Figure 6.   cell-in MUX 0 1 LO CAL noc-in S1 S2 ce ll-in MUX 0 1 LO CAL noc-in bp-in S1 S2 ctrl-mux ctrl-mode noc-out ctrl-mux ctrl-mode noc-out bp-out MODE MODE (a) cell-out (b) cell-out Figure 6: Micro-architecture with bypass function:  (a) input test cell ; (b) output test cell.  The most significant modification is made on the  MODE multiplexer. For the ITCs, we add a bypass output  channel (‘bp-out’), Figure 6(a). For the OTCs, we add a  bypass input channel (‘bp-in’), Figure 6(b). The ‘ctrlmode’ channel is now encoded by an MR3 data to encode  3 mode values (normal, test, and bypass). In bypass mode,  data from ‘noc-in’ will be transported to ‘bp-out’ output  of the ITCs, and data from ‘bp-in’ input will be transported to ‘noc-out’ of the OTCs. To get minimal control,  in bypass mode, ‘ctrl-mode’ is also probed as in normal  mode. The following table resumes test cell’s operations  according to control channels’ values.   Table 1: Description of test cells’ operations  ctrlmode  0  ctrlmux  -  -  -  1  -  2  0  1  -  -  -  Description of test cell’s operations  Normal mode  (enabled forever for minimal control)  Receive data from ‘noc-in’ and store it  Receive data from ‘cell-in’ and store it   Transport stored data to ‘noc-out’  Transport stored data to ‘cell-out’ if there is  a request from the next cell.  Bypass  (enabled forever for minimal control)  In this table, the sign (-) means that no value is written  on the control channel. To receive a data from ‘noc-in’,  store it on ‘LOCAL’ channel and then send it to ‘noc-out’,  ‘ctrl-mux’ should be written with value ‘0’ and ‘ctrlmode’ should be written with value ‘1’.  5.4. Wrapper control module (WCM)  The operation of the test wrapper is decided by test  configuration frames (TCFs) generated by GAC unit. In  order to reduce the number of control channels provided  by GAC unit, the whole test configuration frame is split  into 2-bit pieces, which are sent serially to WCM. In our  architecture, each test configuration frame includes 25  configuration pieces of 2 bits (encoded by the 1-of-4 data  encoding scheme), as illustrated in Figure 7.   24 23 : 21 RO – RI W…S…E NO – NI 0 EoF ID [2:0] EMO4 MCO4 EMI4 MCI4 EMO0 MCI0 EMO0 MCI0 M Figure 7: Test configuration frame (TCF).  The role of WCM is to gather the successive configuration values sent on the configuration chain until it forms  the test configuration frame for the test wrapper. When it  has received a complete configuration frame by detecting  an “End-of-Frame” (EoF) indication as the last piece of  configuration, it has to determine whether the received  configuration frame is reserved for the test wrapper or not.  This is done by means of the “Identifier” (ID) field  addressing the successive router test wrappers on the  configuration chain. If the frame identifier corresponds to  one of test wrappers, WCM of the target test wrapper will  generate control channels (according to the configuration  frame’s values) to control test cells.  153153                            To implement the above function, WCM is composed  of a “Frame Shifter”, an “EoF Detector”, an “ID Verifier”, and a “Transferring Block”, as seen in Figure 8.   ctrl-mode[i] & ctrl-mux[i] with i = 0..4 Transferring B lock cfg-in MR[4] Frame Shifter MR[4] cfg-out EoF Detector EoF ID  Verifier ID ok Figure 8: Wrapper Control Module (WCM).  The purpose of “Frame Shifter” is to read a new configuration from the GAC unit via ‘cfg-in’ input, to shift  the test configuration frame one position (i.e. a 2-bit  piece) to the right, and to write out the lowest significant  configuration position to the configuration chain through  ‘cfg-out’ output. The “EoF Detector” detects the completion of a test configuration frame and the “ID Verifier”  will verify the identification of the received test configuration frame. The “Transferring Block” is used as a driver  to control all the test cells. It receives control values from  “Frame Shifter” when an EoF is detected with a good ID.  The outputs of this block are 20 control channels (‘ctrlmode[i] ’ and ‘ctrl-mux[i] ’, with i gets values from 0 to 4  for indicating NORTH, EAST, SOUTH, WEST, RES directions respectively) used to control 10 test cells.  The explanation of the test configuration frame is presented in Table 2.  Table 2: Explanation of the test configuration frame  EoF  End of Frame indicator  ID[2:0]  Identification number of test wrapper  EMO[i]  Enable ‘ctrl-mode’ channel for OTC i  MCO[i] Value of ‘ctrl-mux’ channel of OTC i  Enable ‘ctrl-mode’ channel for ITC i  EMI[i]  MCI[i]  Value of ‘ctrl-mux’ channel of ITC i  M  Mode of test wrapper  Each configuration position is encoded by an MR4  data (2 bits), the value of each position therefore may be  “0”, “1”, “2”, and “3”[MR4] (i.e. {00}, {01}, {10}, and  {11} in binary respectively). The value of “3”[MR4] is  reserved for EoF indication, hence other configuration  positions can use up to 3 values. With 3 configuration  positions for test wrapper identification, this test configuration frame can be used for NoC architectures up to 27  routers. For larger NoC architectures, we would need to  add more identification positions.   The value of Mode (M) may be “0”[MR4] (normal  mode), “1”[MR4] (test mode), or “2”[MR4] (bypass  mode). The value written on the control channel ‘ctrlmode[i] ’ of ITCs or OTCs is the value of Mode position.  However, in test mode the ‘ctrl-mode[i] ’ channel of the  ITC i is written only when EMI[i] equals “1”[MR4], and  the control channel ‘ctrl-mode[i] ’ of the OTC i is written  only when EMO[i] equals “1”[MR4]. The value written on  each ‘ctrl-mux[i] ’ channel of ITCs or OTCs depends on  the value of MCI[i] or MCO[i], respectively: the ‘ctrlmux[i] ’ channel of the ITC i gets ‘0’ when MCI[i] equals  “1”[MR4], it gets ‘1’ when MCI[i] equals “2”[MR4];  similarly, the ‘ctrl-mux[i] ’ channel of the OTC i gets ‘0’  when MCO[i] equals “1”[MR4], it gets ‘1’ when MCO[i]  equals “2”[MR4]. We can resume the relations between  TCF and control channels explained above in Table 3.   Table 3: Relation between TCF and control channels  For direction i  OTC i  M EMO MCO EMI MCI ctrlctrlmode  mux  0  -  2  -  -  -  1  -  -  0  -  1  X  X  0  1  0  0  X  X  0  0  1  2  0  2  1  1  1  1  X  X  0  0  1  2  X  X  0  1  0  0  ITC i  ctrlctrlmode  mux  0  -  2  -  -  -  1  -  -  0  -  1  Now, we take an example of testing the NORTH  SOUTH routing path of a router, as illustrated in Figure 9.  In this example, we suppose that the eastern port (EAST)  of test wrapper is connected to test access mechanism.  NORTH RES ITC-0 OTC-0 Routing path Under test O T C -4 IT C -4 WEST OTC-3 ITC-3 ANOC router 34 OTC-2 ITC-2 Test wrapper SOUTH ITC-1 OTC-1 Input EAST Output WCM 2 cfg_in 2 cfg_out Figure 9: Wrapper configuration for testing the  NORTHSOUTH routing path.   We can easily generate the test configuration frame for  154154                           this test, see Table 4.  Table 4: TCF for testing NORTH- SOUTH routing path  EoF  3  ID RO-RI WO-WI SO-SI EO-EI NO-NI M  001  00-00  00-00  01-02  12-01  02-12  1  This test configuration frame can be explained as follows. The most significant value (EoF = “3”[MR4])  indicates the end of test configuration frame. The next  three values (ID = “001”[MR4]) means that this test  configuration frame is used for the test wrapper number 1.  The lowest significant value (Mode = “1”[MR4]) puts the  test wrapper in test mode. EI = “01” (i.e. EMI[1] = ‘0’ and  MCI[1] = ‘1’) means that the ITC-1 (EAST) receives test  data from the TAM and shifts them to the OTC-0  (NORTH). NO = “02”[MR4] means that the OTC-0 is in  shifting mode, hence the test data is shifted to the ITC-0  (NORTH). The test data is then inserted to the routerunder-test by the ITC-0 because NI = “12”[MR4].   After router's operations, with SO = “01”[MR4] the  OTC-2 (SOUTH) receives the test result from the routerunder-test and transports them to the ITC-2 (SOUTH). The  ITC-2 is in shifting mode because SI = “02”[MR4]. The  test result is therefore shifted to the OTC-1 (EAST). With  EO = “12”[MR4] the OTC-1 receives the test result and  send it to test analyzer (integrated in GAC unit) via TAM.   We note that the TAM is established by other test  wrappers and the network links. Other test configuration  positions such as RO, RI, WO, WI equal “00”[MR4] means  that the following test cells: OTC-4 (RES), ITC-4 (RES),  OTC-3 (WEST), and ITC-3 (WEST), are not concerned and  are not controlled.   The objective of the above example is to show how to  generate a test configuration frame. Actually, these test  configuration frames are automatically generated by a  custom program according to the test strategy.  6. Test Pattern Generation  6.1. Fault model for QDI asynchronous circuits  Synchronous circuit operation is based on the logical  values observed on nets at every clock cycle. Synchronous  circuit testing is hence based on control and observation  of the logical levels of the nets. Conventional synchronous  ATPG methods use this property to force flip-flop outputs  to different logical levels, and observe levels at flip-flop  inputs in order to detect single stuck-at faults on the  circuit-under-test. ATPG tools determine value combinations on all flip-flops in order to detect a fault.  However, QDI asynchronous circuit operation is based  on tokens flowing inside the logic. M-of-N return-to-zero  encoding is used to propagate tokens: every net alternates  between logical ‘1’ (data present) and logical ‘0’ (no data)  during operation. A stuck-at net will impede this alternation, and block one of the handshaking loops, and all the  following. No data will be observed at the output. Furthermore, multiple stuck-at nets on different handshaking  loops will block the design under test in the same way and  can also be detected.  In order to observe stuck-at faults on the nets of a QDI  asynchronous circuit, it is hence sufficient to force a  handshake on each net and check for liveness. There is no  need for observation of the results. Test pattern generation  is therefore simpler, but since there is no existing automated tool, patterns must be manually derived from a  functional analysis of the circuit. Since Networks-onChips are  interconnection structures, not processing  structures, there is very little control needed in order to  excite all nets, and the test wrapper only needs to be  configured to inject a vector at an input and collect it at an  output.  6.2. Test patterns for network links  Network links need no control at all: they transmit the  values at a link input to the link output. Exhaustive test  vectors for the links are given by the 4 possible values on  each 1-of-4 digit of the data signals, that is “0.0.0….0”,  “1.1.1….1”, “2.2.2….2”; “3.3.3….3”. These vectors are  sent from the test wrapper of a router to the test wrapper  of a neighboring router. Besides, to test the virtual channel  indicating signal (‘send’ signal), a 1-of-2 digit need to be  used with these above test vectors.  6.3. Test patterns for network routers  The functionality of an ANOC router can be explained  as follows: The computational resources exchange data  packets, which can be individually routed in the network.  A packet is composed of successive flits (a flit is a network flow control unit that is composed of 32 data bits  and 2 control bits). A packet is always composed of a  header flit, which may be followed by zero or more body  flit(s) and a tail flit, as illustrated in Figure 2. The header  flit provides routing information, indicated on path-totarget field, which is a vector containing the successive  directions to follow. Each router uses two lower bits of  this vector to route the whole packet in given direction,  and shift the path-to-target field so that it can be used by  the following router. The body flit contains communication data and the tail flit informs the router that it is the  end of the packet.  Hence, the control that determines operation of a router  is the 1-of-4 digit containing the BoP/EoP information  (header/body/tail), and the 1-of-4 digit containing the  current direction of the data flit (highest and lowest  digits), plus the 1-of-2 digit indicating the virtual channel  to use. These control digits must be set to all possible  combinations in order to test every net of each inputoutput couple. All other digits need only iterate on possi155155               ble values as for the network links.  Given an input, an output and a virtual channel, the  following vectors cover the whole functionality range:  “2.0.0.0………….0.dir”  “0.0.0.0………….0.0”  “0.1.1.1………….1.1”  “0.2.2.2………….2.2”  “1.3.3.3………….3.3”  “3.1.1.1………….1.dir”  “3.2.2.2………….2.dir”  “3.3.3.3………….3.dir”  1 multiple-flit packet iterating  on all body/tail payload  values  3 single-flit packets iterating  on remaining header payload  values  Since a router has 5 inputs, 4 outputs connected to each  input, and 2 virtual channels, this gives a total of 320 test  vectors in order to test a whole router. The associated test  configurations can be computed by a custom program and  give a total of 640 test configuration frames since vector  injection and collection are separated.  Section  8.4 will show the coverage on stuck-at faults  given by those functional vectors. The following section  will present how to test the whole ANOC network.  7. Testing Strategy  In this section, we present a simple testing strategy that  allows testing all network elements of the ANOC. With  this strategy, only one network router is tested at a time.  Then, we test all the network links that are connected to  this router. Once the current router and its network links  are tested, we will configure the test wrapper to put this  router in bypass mode and go to test the next router and its  network links. The test flow is defined by the test configuration chain and indicated by bold arrow, as illustrated in  Figure 10.   links-under-test current-router H-next router V-next router 5 6 15 4 3 2 1 cfg-in 10 11 config & bypass chain 16 cfg-out  Figure 10: Test flow for ANOC network.  20 TTTTESTING  ESTING AAAALGORITHM FOR  ESTING  ESTING  LGORITHM FOR  LGORITHM FOR ANOC LGORITHM FOR  ANOC    NNNNETWORK ETWORK ETWORK     ETWORK ANOC ANOC Set current-router = 1;  While current While current ----router  While current While current router ≤≤≤≤ N do router  router   N do  N do      N do /* N is number of network routers */  /***** Router test *****/     /***** Router test *****/ /***** Router test *****/ /***** Router test *****/ Set current-router in test mode;  /* see Figure 11 for different modes used in test  process */  Apply all router test vectors (320) to the routerunder-test;  /* A test vector is applied with its 2 TCFs */   /***** Network Link test *****/     /***** Network Link test *****/ /***** Network Link test *****/ /***** Network Link test *****/ If current-router is not in the last row of the network  then  Set current-router in transfer mode;  /* Transfer direction towards SOUTH (V-next  router */  Set V-next-router in loop-back mode;  /* because of loop-back, a single vector tests both  directions of bidirectional links */  Apply all link test vectors (4) to the vertical linksunder-test;  /* links-under-test is the vertical links between  current router and V-next router */  End if;  If the current-router is not the last router of the rowunder-test then  Set current-router in transfer mode;  /* Transfer direction towards H-next router */  Set H-next-router in loop-back mode;  Apply all link test vectors (4) to the horizontal  links-under-test;  /* links-under-test is the horizontal links between  current router and H-next router */  End if;  /***** Prepare next test iteration *****/     /***** Prepare next test iteration *****/ /***** Prepare next test iteration *****/ /***** Prepare next test iteration *****/ Set current-router in bypass mode;  /* Set current-router in bypass mode to go to the  next-router. Note that the bypass direction is defined  by the test flow, see Figure 10 */  current-router = current-router + 1;  End while; End while;     End while; End while; Router Router (a) (b) Router Router (c) (d)  With this test flow, we can define the following testing  algorithm:  Figure 11: Testing configurations: (a) Test mode; (b)  Bypass mode; (c) Transfer mode; (d) Loop-back mode  156156                                 The testing strategy presented above requires that the  DfT architecture operates correctly. Hence, the DfT  architecture needs to be tested in a preliminary phase  before applying the test of the routers and links. This test  can be done by setting all test wrappers in transfer mode  and the corresponding test vectors can be generated using  the same principle as like the test vector generation of  network links.   8. Experimental Results  8.1. Area overhead  The proposed asynchronous DfT architecture has been  implemented using a 65nm CMOS technology from  STMicroelectronics (with the TIMA 65nm asynchronous  library). The area of a test cell is 8560µm2 and the area of  WCM is 10400µm2. In consequence, a test wrapper  composed of 5 input test cells, 5 output test cells, and a  WCM block costs 96000µm2, i.e. 32.7% of the area of a  testable asynchronous network router.   However, the proposed DfT architecture is used to test  not only the network architecture, but also as a TAM to  test other parts of the ANOC-based system (computational  resources and their network interfaces) that are not presented in this paper. The effective DfT area cost is hence  to be shared between all computational resources of the  whole chip.   8.2. Additional latency  Test wrappers are used to improve the accessibility,  testability of ANOC architecture, but they lead to additional latency for ANOC communication in normal mode.  In our implementation, the additional latency is 0.34ns for  a pair of input and output ports compared to router latency  of 2.00ns (post-layout measurement), see Figure 12.   NORTH RES ITC OTC O T C IT C WEST OTC ITC ITC OTC EAST ANOC router 0.17ns 2.00ns 0.17ns Figure 12: Additional latency.  This corresponds to the delay in two asymmetric Celements and two AND gates. However, since the handshaking loops at the inputs/outputs of the router are not  the most critical ones (in QDI asynchronous circuits,  performance are determined by the length of the handshaking loops) there is no degradation of the NoC communication throughput at all, that is 500Mflits/s in normal  mode.  8.3. Test application time  By reusing network links as test access mechanism, the  proposed DfT architecture possesses high-bandwidth test  paths. However, we need to send test configuration frames  in order to control injection and collection of the test  vectors. Throughput on the configuration chain is of about  2ns per symbol, i.e. 50ns for a complete test configuration  frame.  In the test of network links, we need two test configuration frames per test vector for both inserting test vector  and observing test result because two test wrappers are  used. As regards router testing, in most cases, a single test  configuration frame would be sufficient to insert a test  data flit and to observe the test result, and hence the  maximum test speed would be about 20Mtest-vectors/s;  however, to simplify the test configuration frames generation, we use two test configuration frames per test vector  in the test of network routers: one for inserting test vector  and other for observing test result, which is the general  case. This gives a test speed of about 10Mtest-vectors/s.  With generated test vectors, the test time for each network  router is 32µs and the test time for each bi-directional  network link is 0.4µs.   In consequence, for an ANOC of 20 network routers,  the total test application time for the whole NoC is less  than 0.7ms.  8.4. Fault coverage  To evaluate the efficiency of the testing approach, we  use the well-known single stuck-at fault model on either  inputs or outputs of the circuit cells. Because there is no  support tool to calculate fault coverage for asynchronous  design, we have built a script-based program to insert  automatically faults on every net of the router (a single  fault at once), simulate and calculate the detected faults. A  fault is detected if the circuit stalls (no more transitions on  outputs or acknowledge signals) before the expected end  of the test. With the generated test vectors, the proposed  testing method presents a fault coverage of 99.86% for the  network routers, 100% for the network links. Coverage of  the DfT architecture itself is 99.75% using all possible test  vectors. This high coverage is made possible because of  the dataflow architecture of the network router, mainly  based on multiplexers and demultiplexers on a pipelinelike structure, and the token-based design style used in  ANOC: the only faults that were not detected in the router  were localized before the inputs of the very few asymmetric C-elements used in the design to check for race conditions on control tokens used for several data tokens.  157157                 Table 5: Single Stuck-At (SSA) fault coverage report for router testing  Circuit-under-test  SSA faults on outputs  SSA faults on inputs  SSA faults on both inputs and outputs  Input controller  3178/3178 (100%)  6016/6016 (100%)  9194/9194 (100%)  Output controller  5185/5198 (99.74%)  8925/8944 (99.78%)  14110/14142 (99.77%)  Entire router  41815/41880 (99.84%)  74705/74800 (99.87%)  116520/116680 (99.86%)  Table 5 presents a brief report on the number of injected faults, the number of detected fault, and the fault  coverage of each router’s parts as well as an entire  network router.  9. Conclusions  Although asynchronous NoCs are likely to become  good solutions for on-chip communication of GALS  systems, they have serious testability issues that need to  be addressed. Therefore, a DfT-based testing approach  for asynchronous NoCs has been proposed. In the case  of ANOC architecture, a fully asynchronous DfT  architecture has been designed and implemented. It is a  configurable architecture that can be adapted to other  asynchronous NoCs with different topologies.  In the paper, we have presented the design and the  implementation of the proposed DfT architecture in a  STMicroelectronics 65nm CMOS technology, using a  specialized asynchronous standard cell library from the  TIMA laboratory. The validation of the implementation  was done using a custom SystemC/Verilog netlist cosimulation platform. To prove our testing approach, the  DfT architecture has been integrated into an actual  asynchronous NoC-based SoC.   A simple method for generating test patterns is also  proposed. The test vectors and corresponding test  configurations are automatically generated by a custom  program. With these test vectors, the testing approach  presents a high test coverage of 99.86% (using single  stuck-at fault models).   The implemented DfT architecture is targeted to test  the network architecture (routers and links), but it can  also be used to test the computational resources and their  network interfaces. The detail of this work is out of the  scope of this paper. Thanks to the reuse of the network  links as a high throughput TAM to transport test data, no  dedicated test bus is required.   10. "
Debugging Distributed-Shared-Memory Communication at Multiple Granularities in Networks on Chip.,"We present a methodology to debug a SOC by concentrating on its communication. Our extended communication model includes a) multiple signal groups per interface protocol at each IP port, b) the handshakes per signal group (e.g. for command), and c) the handshakes within a signal group (e.g. for write and read data elements). As a result, our debug methodology is the first to offer debug control at three communication granularities: individual data elements in a message, messages (i.e. requests or responses), and entire transactions. Communication to distributed shared memories is supported in networks on chip (NOC) by transparently (demultiplexing different master-slave channels based on the memory address, also called narrowcast. In this paper, we extend previous work on NOC debug that allowed per-connection debug (i.e. a master without differentiating between its slaves) to also support per-channel (i.e. per master-slave pair) debugging, also for narrowcast connections. This enables essential fine-grained debug control for multi-processor SOCs that use distributed-shared-memory communication. The debug infrastructure consists of hardware components, and a software API and library. We define the hardware infrastructure and the required changes to a NOC. Our architecture cleanly separates the monitoring and distribution of events from how they are interpreted and used, in terms of hardware and programming. We define a high-level software API for run-time user control. The debug methodology offers run-time programmable breakpoints, stopping, continuing, and single-stepping of distributed- shared memory communication at three granularities, at the cost of 2.5% NOC area increase and no speed penalty.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Debugging Distributed-Shared-Memory Communication at Multiple Granularities in Networks on Chip Bart Vermeulen1 , Kees Goossens1 2 , Siddharth Umrani2 1 Research, NXP Semiconductors, The Netherlands, {Bart.Vermeulen,Kees.Goossens}@nxp.com 2 Computer Engineering, Delft University of Technology, The Netherlands , Abstract We present a methodology to debug a SOC by concentrating on its communication. Our extended communication model includes a) multiple signal groups per interface protocol at each IP port, b) the handshakes per signal group (e.g. for command), and c) the handshakes within a signal group (e.g. for write and read data elements). As a result, our debug methodology is the ﬁrst to offer debug control at three communication granularities: individual data elements in a message, messages (i.e. requests or responses), and entire transactions. Communication to distributed shared memories is supported in networks on chip (NOC) by transparently (de)multiplexing different master-slave channels based on the memory address, also called narrowcast. In this paper, we extend previous work on NOC debug that allowed per-connection debug (i.e. a master without differentiating between its slaves) to also support per-channel (i.e. per master-slave pair) debugging, also for narrowcast connections. This enables essential ﬁne-grained debug control for multi-processor SOCs that use distributed-shared-memory communication. The debug infrastructure consists of hardware components, and a software API and library. We deﬁne the hardware infrastructure and the required changes to a NOC. Our architecture cleanly separates the monitoring and distribution of events from how they are interpreted and used, in terms of hardware and programming. We deﬁne a highlevel software API for run-time user control. The debug methodology offers run-time programmable breakpoints, stopping, continuing, and single-stepping of distributedshared memory communication at three granularities, at the cost of 2.5% NOC area increase and no speed penalty. 1. Introduction With the emergence of complex SOCs comes the unintentional but inevitable slip of some design errors (located in hardware or software) to the product bring-up phase. Finding these errors in a timely and cost-effective manner is increasingly important to ensure that the product can be released to the market on time. Traditionally the task of debugging an embedded system has been made easier through the up-front inclusion of debug support functions in the design, an activity known as Design-for-Debug (DfD). Debug support functions included in SOCs across the industry today [11] fall into two categories: real-time trace and runstop control. To enable real-time trace, key internal signals are brought out, in real-time, onto chip pins. The ability to observe these signals is a great advantage during debugging. Run-stop control uses on-chip support to stop the functional operation of the chip when a programmable condition occurs. Traditionally the response to this occurrence is to either have the processors in the system jump to an exception handler, and wait to be contacted by an external debugger tool, or by gating all functional clocks, freezing the complete system state. Afterwards, the external debugger software can switch the system to a debug mode, in which the system state can be examined, and where required, modiﬁed, before functional execution is resumed or restarted [12]. Software debugging takes place at the application source code level. Hardware debugging takes place at the IP clock cycle level. A single source code line can take many clock cycles to execute, making the system debug process very time consuming, as there are no intermediate levels on which debugging can take place as well. In addition, debugging at the clock cycle level is known to be very difﬁcult, especially in SOCs with multiple clock domains, and in the presence of non-deterministic behavior and environmental conditions [5, 4]. In this paper, we therefore establish new intermediate debugging levels, address communication based on distributed shared memories for multi-processor SOCs, implement single stepping, and deﬁne and implement a high-level user API for run-time debug. For this we focus on the on-chip communication architecture, and extend the concepts and implementations explored in [8] and [18]. Key contributions of this paper are: 978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.20 DOI 10.1109/NOCS.2008.20 3 3 • We introduce an extended communication model that includes multiple protocol signal groups, handshaking per group (e.g. for the command group) and within a group (e.g. write and read data elements). • This allows us to deﬁne intermediate levels for effective run-stop debugging of embedded systems, focussing on the on-chip communication, instead of on the on-chip computation. These increasingly coarse levels are: individual data elements (of write and read data), request and response messages, and entire transactions. The ﬁrst level is new. • NOCs implement distributed-shared-memory communication by demultiplexing requests from a master to the appropriate slave, and multiplexing the responses, called a narrowcast connection [16]. Prior work [8, 18] allowed debugging of connections with a master and multiple slaves, such as a narrowcast connection, only in a limited manner. This paper deﬁnes and implements per-channel, i.e. per master-slave pair, debug support. This signiﬁcantly increases the ﬂexibility and applicability of the debug methodology, which is required by SOCs with multiple processors that communicate via distributed shared memories. • We show new details of the event distribution mechanism, including ﬁnite state machines (FSM) and the operation of stop event distribution. • Single stepping, i.e. repeated stopping and continuing, is a key feature of a debug methodology. Although prior work introduced the concept, it did not implement it. In particular, single stepping at any of the three debug levels introduced here, while guaranteeing that no events are missed requires additional hardware support to atomically continue and stop. This is more complex than the separate stop and continue functions, described by earlier work. • The new features (three debug levels, narrowcast debug, and single-stepping) all require changes to the network interface (NI) shell FSMs. We show an implementation for a particular protocol (DTL [14]), and a general recipe to modify NI Shell FSMs for other protocols. • While prior work deﬁned the basic steps on how to use a debug infrastructure, this paper gives both more low-level details of the test point registers (TPR), and deﬁnes a generic debug interface port and software API to abstract away from the basic, implementationspeciﬁc operations to a more generic and user-friendly interface. In our examples we use a network on chip (NOC), but our concepts and implementation can be applied equally well to bus-based SOC architectures. The remainder of this paper is organized as follows. Section 2 discusses the interconnection and communication Figure 1. Example signal groups and signals of a DTL port. models. In Section 3 we describe a typical session for debugging a system using a communication-centric approach, and derive debug control requirements. Section 4 describes how these can be implemented in a NOC and made accessible via a generic debug interface. Section 5 contains a description of the high-level software API we developed to control the SOC communication at the system level with different granularities of stopping and single stepping. In Section 6 we present the results of experiments we conducted, including silicon area cost, and impact on the maximum functional network frequency. We conclude in Section 7. 2. Interconnection & Communication Models Communication Model To enable their re-use, IPs communicate on their ports using standardized transaction-based protocols, such as DTL [14], AXI [1], and OCP [13]. A transaction is initiated by a master port on an IP, and consists of a request message from master to slave. The execution of a request message by the slave can generate an optional response message. A request message is encoded as two or more signal groups: the command group and the write-data group. A response message is encoded as one or more signal groups, e.g. the read-data group. Successive data words of the write and read data groups are called message (data) elements. Figure 1 shows some of the signal groups of DTL, which we use as a running example in Sections 4.3 (converting transactions to packets) and 6 (experimental results). A valid/accept handshake is used to transfer an element per signal group. For example, the element of the command group comprises the command (read/write), address, and perhaps some ﬂags. For the command and data groups 44 Figure 2. Narrowcast connection, implementing distributed shared memory communication between one master and multiple slaves. the initiator produces data on the signal group and asserts the group’s valid signal. The target then consumes the data and indicates this by asserting the group’s accept signal. For the response message the role of initiator and target are reversed. We distinguish three consistent granularities of communication. Starting with the smallest, these are: elements (coinciding with signal group handshakes), messages (requests or responses, consisting of one or more elements on one or more signal groups), and transactions (consisting of a request message and optional response message). The debug infrastructure introduced in Section 4 allows the debugging of the communication of a SOC to take place at each of these levels, depending on how it is conﬁgured. Our canonical NOC [7] consists of routers and network interfaces (NI). A master communicates with a slave using two uni-directional channels: one for request messages and one for response messages. Most communication protocols implement distributed shared memory, where a master communicates transparently with multiple slaves. In other words, the master uses an address space without knowing how it is distributed over the slaves (on-chip and external memories, peripherals, etc.). A master communicates transparently with multiple slaves using a single narrowcast connection [16], see Figure 2. NI Architecture As illustrated in Figure 3, channels are implemented by the NI kernel, and connections are implemented by the NI shells [16]. After serializing the request signal groups (“s” in Figure 3), requests of a single master are demultiplexed to multiple slaves on a single connection in the master NI shell (“d” in Figure 3). Split pipelined requests may be sent to different slaves, and the responses may come back with different delays, hence the master NI shell also interleaves the responses in the correct order. A slave may be used by different masters. Hence the slave NI shell multiplexes requests of different masters and demultiplexes the responses. The NI Shell FSMs implement the (de)serialization, reordering, and handshaking for the particular protocol of the between the breakpoint hit and the system communication reaching a quiescent state may take a long time when large transactions are used. Either the system reaches a quiescent state by itself, or the user has to force the subsequent switch to debug mode. Once in debug mode, the debug engineer has access to the contents of all internal registers and memories, via for example the manufacturing scan-chains [10]. Once the system’s state has been inspected, it may be required to restart and/or resume the system’s execution to stop at another point (earlier or later) in time for more accurate analysis of the error. To this end, the breakpoint can be reprogrammed, and the execution of the system is either restarted (by resetting the system), or resumed (by reenabling system execution control). From the description of a communication-centric debug session, we derive the following control requirements to debug the on-chip communication: • Reset: Functionally reset the system to (re)start the execution from a well-deﬁned, start-up state. • Internal stop: Stop initiated by an on-chip monitor programmed to recognize and trigger on a condition or sequence on internal signals. When these triggers reach the network interfaces, they may take effect at different levels of granularity (see Figure 4). • External stop: Stop initiated by the user from the external debugger tool. Due to the latency of the debug channel through which this stop command is communicated, it is often very difﬁcult to precisely control the point at which the system actually stops executing, hence the predominant use of on-chip monitors. • Continue: Resume functional execution of the system. The traditional single-step operation also exists for communication debug, but is not explicitly mentioned as a requirement, as a single-step action is the combination of a continue action with a subsequent stop action at a userspeciﬁed granularity. The breakpoint programmed can be either an absolute or a relative breakpoint. For singlestepping, a relative breakpoint is used, where the breakpoint is set after the next clock cycle, ﬂit, element, message, or transaction, depending on the user’s granularity requirements. 4. On-Chip Debug Infrastructure In this section we describe the on-chip debug infrastructure that supports a communication-centric debug session as shown in Figure 5 and that meets our communication debug requirements. An overview of this infrastructure is shown in Figure 6. The components speciﬁcally added to provide debug support are shown in light gray. Figure 4. Communication Debug Granularity. Figure 5. Communication-centric Debug Session. a channel), or even elements within a message. If the communication infrastructure itself is suspect, debugging might need to take place at the even lower, ﬂit level. Finally, the smallest granularity at which the execution of the system can be controlled, and hence stopped, is the clock-cycle level. Note that when stopping a system at a higher granularity than clock cycles, the stopping may not be immediate, i.e. the system may continue to execute for a certain period of time after the breakpoint was detected, for example to complete an active message or transaction. Based on these additional levels of granularity, a new ﬂow for a communication-centric debug session can be derived. It is shown in Figure 5. After programming the breakpoint, the engineer can choose to functionally reset the application, to start its execution from a well-deﬁned start-up state, or to let the system continue as is. The external debugger software then continuously checks the execution state of the system, to determine whether the programmed breakpoint has already been hit or not. Once the breakpoint has been hit, the debugger software also has to check whether the system has reached a quiescent state, for example by polling the state of the communication queues in the NI shells. Especially with the transaction granularity, the time 66 Figure 6. DfD Infrastructure for Communication Debug. Figure 8. Example Event Distribution Interconnect. Figure 7. (a) Monitor TPR, and (b) NI Shell TPR. Figure 9. FSM of the Event Distribution Interconnect Node. 4.1. On-chip Monitors 4.2. Event Distribution Interconnect Monitors may be added to a system to observe the progress of the computation in the master and slaves, and/or the communication in the communication architecture. Communication monitors observe the data on the interfaces at the boundaries of the network [17], and/or on internal links [2, 3], routers, NIs, etc. Under which conditions a monitor generates a trigger can be programmed via the Debug Control Interconnect (DCI). In our case, the DCI consists of a daisy-chain of, among others, Monitor Test Point Registers (TPR) (see Figure 6). A Monitor TPR contains a breakpoint condition, and its enable and triggered ﬂags (refer to Figure 7(a)). The TPR chain is accessible from an IEEE 1149.1 Test Access Port (TAP) using a special debug instruction (see Subsection 4.5). This access mechanism is identical to the DCBs in [19]. Once the monitor detects the programmed breakpoint condition on the link or interface it observes, it asserts its output for as long as the breakpoint condition remains true. The output signals of the monitors are connected to the Event Distribution Interconnect (EDI). The basic component of the EDI is the EDI node. The EDI node is parametrizable in the number of neighboring nodes. The EDI follows the topology of the communication architecture (for an example with one monitor, refer to Figure 8). The FSM diagram of an EDI node is shown in Figure 9. Upon a functional reset, this FSM enters the wait state, in which it waits for an incoming event signal from its nearby monitor or other EDI nodes. When an event is detected, the FSM transitions to the send state, while it broadcasts the event to all its neighboring EDI nodes. In the next clock cycle, the FSM transitions to the idle state where it deactives its outgoing event signal, and ignores any incoming returning event signals from its neighbors. This state is key to the attenuation of the event signals in the EDI, as it ensures that eventually the entire EDI will be free of event signals again. In the next clock cycle, the FSM transitions to the more? state, where it checks whether the event input 77 Figure 10. Event Distribution Example. Figure 11. Modiﬁed Network Interface FSM for a Narrowcast Master. signal is still asserted. If so, it will transition back to the send state, while broadcasting the event to all its neighboring EDI nodes. If the event input signal is deasserted, the FSM transitions to the initial wait state, where it again resumes to wait for an incoming event signal. For the example EDI shown in Figure 8, the concerted operation is shown in Figure 10. Monitor M0 asserts its output (monitor stop[0]), thereby signalling an event to EDI Node N0. EDI Node N0 transitions to the send state while asserting its output signal, stop out[0]. In the next clock cycle, its neighboring EDI nodes, N1 and N3, take similar action, to signal the remaining EDI nodes, N2, and N4 via stop out[1] and stop out[3] respectively. Consequently all nodes go through the state sequence wait → send → idle → more? → wait. Afterwards, the complete EDI is in the same state as it was before the event came in from the monitor, but in between all network interfaces have been informed of this event, through the assertion of the stop out[i] signals. It takes the EDI a single clock cycle to propagate the pulses generated by a monitor through a EDI node. Given a communication architecture that communicates data at the granularity of ﬂits (3 cycles for the Æthereal NOC), this ensures that any monitor event always reaches the borders of the network ahead of the data itself. This is a key debug feature we exploit, as it allows this data to be kept within the borders of the communication architecture for an (potentially) inﬁnite amount of time. The actual processing of this data by the receiving IP can then be analyzed in the necessary detail required to ﬁnd an error cause, by subsequently single-stepping the delivery operation for this data at the required debug granularity. 4.3. Network Interface Debug Operation We illustrate the functional states and transitions of the NI shell FSMs, and then describe how they are modiﬁed for debug. Figure 11 shows the FSM of the narrowcast NI 88 shell for a DTL master port as shown in Figure 3(a). Other NI shell FSMs are similar. Please refer to Figure 1 for the relevant signals and groups of a DTL port, which we use in our implementation. The states of the FSM serialize and handshake the DTL signal groups in the correct order (cmd dec and cmd accpt for the command, then read for read data or wdata accpt for write data). The cmd dec state decodes the address group to select the channel corresponding to the right slave, which is the deﬁning feature of the narrowcast connection that implements distributedshared-memory communication. For the communication to be stopped when a breakpoint is detected, this FSM needs to be adapted. The states that are responsible for handshaking are duplicated in socalled shadow states. These are the lighter gray states in the state diagram, with an apostrophe appended to the name of the original state. Shadow states differ from their original counter-part. First, when in a shadow state, the FSM deactivates the NI shell’s handshake signals, causing communication between the master and NI shell ports to (eventually) stop. Second, to take an FSM out of a shadow state, a signal from the external debugger software is required. In the particular FSM of Figure 11, the stop transitions s2 and s6 are equal to the original f2 and f6, but include checking that the channel should be stopped, and that an unconditional stop or stop condition occurs: (stop enable[i] = logic-1) AND ((stop = logic-1) OR (stop condition[i] = logic-1)), where i is the channel identiﬁer. f2’ and f6’ are modiﬁed from f2 and f6 respectively by including the negated stop condition. The continue transitions c2, c6, and c7 are equal to the original f2, f6, and f7 ANDed with the continue[i] = logic-1 signal, respectively. A general recipe for other protocol FSMs can be easily derived from this example. The and continue signals come from the NI shells TPRs, stop condition, stop enable, described in the following section. They control how the NI shell hardware reacts to incoming events on the stop signal. TAP controller instructions set and read the TPRs, as described in Section 4.5. The user uses a higher-level debug API, deﬁned in Section 5, built on top of the TAP controller instructions. 4.4. Network Interface Debug Control The debug signals required to control the state progression of the NI shell FSMs originate from an NI-shell TPR (see Figure 6). All NI-shell TPRs are included in the TPR daisy-chain described earlier in Section 4.1. The NI TPR is a data register that provides the user with all required debug control over the interconnect interactions. By programming the various NI TPRs the user can achieve transaction, message, and/or element debugging per channel. As shown in Figure 7(b), the NI TPR consists of 5 ﬁelds: stop enable, stop granularity, stop condition, continue, and ip stop. All but the last ﬁeld are present per channel. 1) Stop Enable: This ﬁeld indicates whether the communication on a particular channel is stopped on an internal event or not. A logic-0 means that the communication on this channel does not stop when an event signal is received from the EDI. Also a possible software stop is ignored (see the description of the stop condition ﬁeld below). A logic-1 stops the channel on the conditions, speciﬁed by the stop granularity and stop condition ﬁelds. 2) Stop Granularity: This ﬁeld controls the granularity at which the communication on a certain channel is stopped. A logic-0 and logic-1 allow ongoing messages and elements, respectively, to complete before stopping. The latter will stop the channel faster. 3) Stop Condition: Provided that stopping has been enabled (i.e. stop enable set to logic-1) for the channel, and the appropriate stop granularity has been set, this bit determines under which condition this channel will stop. A logic-0 means that the channel will stop only after a pulse from the EDI has been received. A logic-1 means the channel will stop unconditionally before the next element, at the granularity speciﬁed by the stop granularity bit. This channel will stop irrespective of whether a stop pulse arrived from the EDI or not. This ﬁeld gives the user the ﬂexibility to either wait for a stop pulse from the EDI (i.e. for an absolute breakpoint or an external stop command), or program a channel to be stopped unconditionally (for a pre-programmed or forced user stop). There are two reasons for providing this ﬁeld. First, in case of (inﬁnitely) long transactions or errors on the interface, the user can stop the NOC by programming this ﬁeld without having to wait for a transaction to complete. Second, a single-step consists of a continue atomically followed by an implicit unconditional stop. This ﬁeld enables this implicit stop. 4) Continue: The stop combined with the continue gives the user the power to observe the functional behavior of the SOC in a controlled fashion during debug. The continue ﬁeld is interpreted differently from the other ﬁelds. Writing logic-1 in the continue TPR causes an active-high signal to be fed to the NI shell. Upon continuing communication, the shell resets this signal’s value automatically through special reset logic. Setting this bit to logic-1 is thus interpreted as a single continue pulse for the channel. A continue with the appropriate stop condition therefore ensures an atomic continue and stop, to ensure that exactly one handshake takes place. This accuracy cannot be guaranteed by separate continue and stop commands because they involve user interaction, TPR programming, stop event distribution, etc. all which take time, during which an IP may execute multiple handshakes. 5) IP Stop: Every NI shell TPR also has a single ip stop bit which enables the NI shell to forward an event to the connected IP cores. This is used for a functional stop request for the IP cores, enabling the stopping all the components (the interconnect and the IPs) of a SOC close to each other in time. Otherwise, only stopping the interconnect without the IP cores means that the computational state of the IP cores might still advance as they continue internal, non-communication-related operations. This complicates debug as the states of different parts of the system retrieved later on may be difﬁcult to correlate to one another. A logic-0 means not to signal the connected IP cores to stop. Setting the value to logic-0 is also used to signal a continue action when the IP cores were previously stopped using this method. A logic-1 signals a stop to the connected IP cores, when a trigger event comes in via the EDI. 4.5. Extra TAP Controller Instructions The entire on-chip debug infrastructure is controlled and programmable through an IEEE 1149.1 Test Access Port (TAP). A TAP is often already included in a chip design to allow board-level manufacturing test. To support communication-centric debug, the controller associated with the TAP has been extended with a number of userdeﬁned instructions: • DBG RESET: issue a functional reset of the chip. • PROGRAM TPR: program the monitor and NI TPRs. The former determine the breakpoint condition(s). The latter control the resulting debug control actions. • QUERY TPR: query the status of the breakpoint (triggered or not) and the channels (whether there are still on-going transactions) in the NI shells. • JTAG STOP: send a trigger pulse to the EDI from the TAP. 99 • PROGRAM TCB: switch the system between functional and debug modes. • DBG SCAN: scan out the complete state of the system via the scan chains in debug mode. instruction. Then the system is switched back to functional mode, using the PROGRAM TCB instruction. The complete state is stored in an internal database for subsequent query by the user. These instructions implement safe reading and writing of TPRs (which can be non-trivial due to the difference in debug and functional clock domains). They hide SOC-dependent implementation details of the TPRs in scan chains, etc. These generic instructions are however still fairly low level for an end user because (s)he would have to know the exact TPR layouts of Figure 7 and their positions in the TPR chain. It is for this reason that we deﬁned a higher-level software API, which is described in the following section. 5. Off-chip Debugger Software API We extended the TCL interface of our hardware debugger [15] to control the debug functionality in a user-friendly manner. The following API functions are implemented: • reset : Issues a functional reset of the system by using the DBG RESET instruction. • set bp <monitor> [<condition>]: Sets up the <condition> in the monitor’s TPR. When the optional <condition> ﬁeld is left out, the breakpoint setting is cleared. This call uses the PROGRAM TPR instruction to program the appropriate monitor TPR bits via the TAP. Here, and below, <monitor>s and <channel>s are speciﬁed using their full, hierarchical design names. • set bp action <channel> [<granularity> <condition>]: Sets up a breakpoint action on the channel. The <granularity> is one of transaction, message, or element. The <condition> is edi or always. When the optional <granularity> and <condition> ﬁelds are left out, the breakpoint action setting is cleared. This call uses the PROGRAM TPR instruction to program the appropriate NI shell TPR bits via the TAP. • get mon status [ list of <monitor>s ]: Returns an ASCII string, indicating whether the speciﬁed monitors have triggered (logic-1) or not (logic-0). • get ni status <ni>: Returns an ASCII string indicating whether the channels in the speciﬁed NI are idle (logic-1) or not (logic-0). • continue [ list of <channel>s ]: Causes the communication on the channels to continue. If the optional ﬁeld is left out, all channels are continued. This call uses the PROGRAM TPR instruction to set the continue bits in the appropriate NI TPRs to logic-1 via the TAP. • synchronize: Retrieve the complete state of the system by ﬁrst switching the system to the debug mode, using the PROGRAM TCB instruction, and subsequently scanning out the manufacturing test scan chains, using the DBG SCAN 6. Experimental Results 6.1. Example Use Case In this subsection we show how the debug infrastructure and the software API work together on an example. Our automated design ﬂow [6] generated the system shown before in Figure 6. This includes the RTL VHDL of the NOC, the clock and reset controllers, test bench and trafﬁc generators, embedded C code to program the NOC, and scripts for gate-level synthesis, scan-chain insertion, etc. Each master has a connection to both slaves. In Figure 12 we show signal traces of the gate-level implementation of the NOC with scan chains. We boot the system until it is running in functional mode (omitted from the trace). The system is debugged ﬁrst at the message level, and then element level. This is accomplished by Script 1, which uses the software API deﬁned above to control the on-chip debug support. Script 1 Example Debug Script 1: set bp top.R00.M 378 2: set bp action {top.NI1.ch1} edi 3: while {[get mon status top.R00.M] eq “0”} {} 4: while {[get ni status NI1 ] ne “1111”} {} 5: set bp action {top.NI1.ch1} always 6: continue {top.NI1.ch1} 7: continue {top.NI1.ch1} 8: set bp action{top.NI1.ch1} element always 9: for {set i 0} {$i<5} {incr i} { continue } 10: set bp action {top.NI1.ch1} element edi 11: continue Line 1 sets a breakpoint at the monitor attached to router R00, to match the value 378 on the output links of the router. Line 2 speciﬁes that the channel top.NI1.ch1 between Master 1 and Slave 2 is sensitive to events generated by the monitors and user (via the TAP) (edi). Channel ch0to Slave 1 continues to operate. On reception of an event from the EDI, the NI ﬁnishes the ongoing message (message). These two commands are executed by the offchip debugger software, which uses the TAP and DCI (i.e. the TPR chain) to load the appropriate values (Section 4.4) in the monitor and NI TPRs. This is for example shown by the transition of stop enable, labelled A, in Figure 12. Line 3 polls the monitor TPR to see if it triggered. After a number of transactions (box labelled B), the monitor triggers, which is shown by the transition on signal 1010 ni stop in labelled C. NI1 completes the ongoing message on the channel between Master 1 and Slave 2. It then stops, i.e. does not accept the messages for Slave 2 offered by the master (command valid is high, see label D). In line 4 the TPR of NI1 is checked. First that there are no packets in transit on channel ch1 containing (parts of) messages (cf. live tx wr r 1 and live tx rd r 1). Second that all credits have arrived in the producer’s NI [9]. Line 5 changes the sensitivity of channel ch1 to singlestep mode (always), i.e. only a single message is accepted before stopping again. This is visible at label E, where the stop condition changes. Line 6 continues operation of channel ch1 (label F). Immediately, the write request message that was waiting (label D) is accepted, sent to Slave 2, and executed. Immediately after, Master 1 offers a read transaction, but this command is not accepted. All this is shown in box G. When line 7 is executed, the waiting read request is accepted, executed, and the corresponding response data consumed (see the box labelled H). The read data dtl rd data transitions from “xxx” to a deﬁned value, but this is hard to read in the signal trace due to the timescale used. We then change the stop granularity of channel ch1 to the element level, line 8, label I), followed by 5 continue commands (line 9). In the boxes labelled J and K, ﬁve elements are accepted: the command dtl cmd accept and 4 data elements on dtl wr accept. Finally, line 10 (label L) makes channel ch1 sensitive to the EDI only, i.e. no single stepping. Label M shows how the system continues at full speed after a continue pulse. All debug commands are given from the debug clock domain. The system operates on the functional clock, and parts of the system that are not debugged operate normally. For example, although not shown for lack of space, throughout the example the other master can continue to send transactions to both slaves. Figure 12 has been obtained with a simulator. To debug an FPGA or real silicon, the synchronize call has to be used to download the state of the chip to the debugger, or vice versa. This means that the entire system, including master 2, has to transition from functional mode to debug mode. In general, clock cycle synchronization leaves the system in a potentially inconsistent state due to clock-domain crossings that do not utilize valid/accept handshakes. Proper continuation can then only be achieved be executing again from a system reset. In our case, however, the state of the NOC can be synchronized safely and independently from the clocks used by the IP cores because all interfaces do use valid/accept handshakes. At the start of the synchronize call, all channels have to be stopped, e.g. at the element level which is quickest, and they have to be re-enabled after the synchronization. 6.2. Required Silicon Area For the example described above, the amount of silicon area needed to implement the proposed debug infrastructure is very low: a 2.5% increase of the NOC area, and no decrease in speed when synthesized at 250 MHz. The increase in area is almost entirely due to the TPRs; the area for the monitors and EDI nodes are neglible. Regarding timing, the NI shell FSM complexity is increased marginally, but this is not in the critical path. The EDI runs at NOC speed, and the DDI and DCI speeds are determined by the scan chains and boundary scan logic inserted for manufacturing test. 7. Conclusion We presented a debug methodology to debug a SOC by concentrating on its communication. We applied it to a NOC because they represent the most complex interconnects. Our extended communication model includes handshakes for each of the multiple signal groups per IP port, and multiple handshakes per signal group (e.g. for read and write data elements). It also addresses narrowcast communication based on distributed shared memories, where a master transparently sends read and write transactions to multiple slaves in its address space. As a result, debug control is offered at three granularities: data elements, messages, and transactions. Orthogonally, it is offered per channel (master-slave pair), also within narrowcast connections. Different channels can be simultaneously debugged at different granularities. We prove our concepts with an RTL implementation that is automatically generated by our NOC design ﬂow. We show how to extend NI shell FSMs for general communication protocols with shadow states to suspend the valid/accept handshakes on the port interfaces. The monitoring and distribution of events is cleanly separated from how they are interpreted (the debug granularity per channel), in terms of hardware and programming. The software infrastructure has a clearly deﬁned hardware interface (the TPRs and IEEE 1149.1 TAP with additional, generic debug instructions), and an intuitive high-level software API that uses it. The infrastructure offers powerful run-time programmable breakpoints, stopping, continuing, and single stepping at three granularities. In particular, single stepping is a non-trivial extension to atomically continue and stop, to guarantee that no event escapes detection. Our debug infrastructure consists of hardware components (monitors and event distribution interconnect), and a software API and library. The hardware infrastructure is modular, requires very few changes to the NOC, and scales linearly with the size of the NOC in terms of area. The area cost is only 2.5% compared to the NoC and without speed penalty. 1111 Figure 12. Traces of our Example Debug Session. "
Invited Talk 2 - Optical Interconnects for Backplane and Chip-to-Chip Photonics.,"The growth in computing power has placed increasing demands on low cost technologies for the transmission of large bandwidths over short distances using highly compact forms. As a result, in recent years a diverse range of photonic technologies have been developed not only to allow high speed point-to-point links, but also to enable the simple creation of networks within computing infrastructure, and indeed to allow an element of reconfiguration. In addition, related work has sought to make possible such functions directly on chip using new silicon based technologies. Following a general review of the field, this lecture will illustrate new cost effective optical technologies, developed at Dow Corning, which can be formed directly on printed circuit boards using materials that withstand solder overflow. The technology has the potential of delivering both board-to-board and chip-to-chip communications. For typical required lengths, polymer waveguides can be formed which are essentially bit rate transparent with high crosstalk performance. With readily available parallel optics, this allows a high capacity (of Terabit order) backplane performance. Recent results show efficient high-speed data transmission at 10 Gbps individual channel rates with low loss and excellent crosstalk performance. The lecture will conclude by reporting how we are exploring the potential extension of this technology for use in high-speed on-board optical networks.","Invited Talk 2  Optical Interconnects for Backplane  and Chip-to-Chip Photonics  Ian H White and Richard V. Penty  Electrical Engineering Division, Engineering Department, University of Cambridge, 9 JJ  Thomson Avenue, Cambridge, CB3 0FA, UK, email: ihw3@cam.ac.uk  Abstract  The growth in computing power has placed increasing demands on low cost technologies for the transmission of  large bandwidths over short distances using highly compact forms. As a result, in recent years a diverse range of  photonic technologies have been developed not only to allow high speed point-to-point links, but also to enable the  simple creation of networks within computing infrastructure, and indeed to allow an element of reconfiguration. In  addition, related work has sought to make possible such functions directly on chip using new silicon based  technologies.  Following a general review of the field, this lecture will illustrate new cost effective optical technologies, developed  at Dow Corning, which can be formed directly on printed circuit boards using materials that withstand solder  overflow. The technology has the potential of delivering both board-to-board and chip-to-chip communications. For  typical required lengths, polymer waveguides can be formed which are essentially bit rate transparent with high  crosstalk performance. With readily available parallel optics, this allows a high capacity (of Terabit order) backplane  performance. Recent results show efficient high-speed data transmission at 10 Gbps individual channel rates with  low loss and excellent crosstalk performance.  The lecture will conclude by reporting how we are exploring the potential extension of this technology for use in  high-speed on-board optical networks.   Biography  Prof. Ian White is currently van Eck Professor of Engineering, Chair of the Council, School of Technology and  Head of the Photonic Research Group in the Engineering Department at the University of Cambridge. He gained his  B.A. and Ph.D. degrees from the University of Cambridge, England, in 1980 and 1984. He then was appointed a  research fellow and assistant lecturer at the University of Cambridge before moving to become Professor of Physics  at the University of Bath in 1990. In 1996 he moved to the University of Bristol, becoming Head of the Department  of Electrical and Electronic Engineering in 1998, before returning to the University of Cambridge in October 2001.    Ian White has built up a substantial research activity in the field of optoelectronics and optical communications and  his team numbers approximately 40 people publishing on average 60 papers a year. Highlights of Ian’s research  have included: the first negative chirp electro-absorption modulator and the invention of a technique for transmitting  radio frequency signals over long distances of multimode optical fibre. Several of these advances have already made  commercial impact, the offset launch technique for enhancing the bandwidth of optical fibre links having been  adopted within Gigabit Ethernet standard, and a technique for the polarization pinning of VCSELs having been  employed in laser optical mice. He has chaired the channel model sub-task force of the IEEE 10 GbE LRM standard.  The Institution of Electrical Engineers has awarded him the Blumlein-Browne-Willans Prize and the Ambrose  Fleming Premium Award. Ian is currently an editor-in-chief of Electronics Letters and is also a co-founder of  ZinWave.  xvxv                       "
Low-Cost VC Allocator Design for Virtual Channel Wormhole Routers in Networks-on-Chip.,"Through low-level simulation and analysis, we find that the virtual channel allocator (VA) consumes large area and power while it is not critical in the performances of a NoC. Thus, it is possible to reduce the costs of VA with only a small penalty in network performances. This paper proposes two low-cost VA architectures: look-ahead VA and unfair VA. Compared with a general VA, the look- ahead VA reduces the number of both input VC arbiters and output VC arbiters while the unfair VA decreases the size of the output VC arbiters. Our experiments based on UMC 130 nm SP library show that the two architectures jointly save area cost by 70.95% and power consumption by 76.21% with nearly no adverse effect on network latency and throughput. To the best of our knowledge, it is the first time a VC allocator design is optimized in the context of NoC.","Second ACM/IEEE International Symposium on Networks-on-Chip Second ACM/IEEE International Symposium on Networks-on-Chip Low-cost VC Allocator Design for Virtual Channel Wormhole Routers in  Networks-on-Chip  Min Zhang, Chiu-Sing Choy  Department of Electronic Engineering, The Chinese University of Hong Kong  {mzhang, cschoy}@ee.cuhk.edu.hk  Abstract  Through low-level simulation and analysis, we find that  the virtual channel allocator (VA) consumes large area  and power while it is not critical in the performances of a  NoC. Thus, it is possible to reduce the costs of VA with  only a small penalty in network performances. This paper  proposes two low-cost VA architectures: look-ahead VA  and unfair VA. Compared with a general VA, the lookahead VA reduces the number of both input VC arbiters  and output VC arbiters while the unfair VA decreases the  size of the output VC arbiters. Our experiments based on  UMC 130 nm SP library show that the two architectures  jointly save area cost by 70.95% and power consumption  by 76.21% with nearly no adverse effect on network  latency and throughput. To the best of our knowledge, it is  the first time a VC allocator design is optimized in the  context of NoC.  1. Introduction and Motivation  Peh and Dally detailed the complexity of a general VA  in [1]. As shown in figure 1, if the routing computation  block returns all available VCs of a single output physical  channel (PC), the VA performs arbitration in two stages.  In the first stage, each input VC selects one available VC  from the returned output PC. Since there are at most V  available VCs in an output PC, a V:1 arbiter is needed for  each input VC. In the second stage, each output VC grants  one out of all the requests. The number of requests to an  output VC is (pi-1)V in the worst case, so each output VC  needs a (pi-1)V:1 arbiter.   According to the router pipeline, VA is a packet-level  operation. As it is low in utilization, we guess it is not the  bottleneck  in network performances. Meanwhile,  although there are theoretically (pi-1)V requests for an  output VC in the worst case, it will not occur due to the  balance by routing algorithm and VC selection algorithm.  In other word, it is overly generous to allocate an arbiter  to each input VC and each output VC, particularly when  every output VC arbiter is constructed as a worst-case  round robin arbiter. Therefore, both the number and the  size of these arbiters can be reduced.  2. Proposed VA architectures  2.1. Look-ahead VA  Figure 2 shows VA utilization probability. It can be  seen that the probability (p1 in figure 2) that two or more  output VCs (4 VCs per output PC) are concurrently  requested is no bigger than 0.15%. Therefore network  performances will only be affected slightly if only one (pi1)V:1 arbiter is allocated to an output PC. Figure 3  describes proposed look-ahead VA. Compared with the  general VA, the piV V:1 round-robin arbiters are replaced  by po V:1 comparators in the first stage. Each comparator  selects the VC that has the maximum available credits in  an output PC. This scheme has two advantages. Firstly,  the output VC with the maximum credits has the  minimum flits. Thus, a new flit going to such a VC will  probably have the lowest queuing latency in it. Secondly,  two or more VCs in an output PC will never be requested  simultaneously. In the second stage, the number of (pi1)V:1 arbiters decreases from poV to po.  2.2. Unfair VA  The large (pi-1)V:1 arbiters used in the second stage  may be simplified by organizing them as a tree of smaller  arbiters (Figure 4) [2]. In general, in order to achieve  fairness, all the smaller arbiters are matrix arbiters.  However, it is absolutely unnecessary to have (pi-1)  fair V:1 arbiters since the probability (p2 in figure 2) that  there are two or more effective requests (4 VCs per input  port) from the same input port is no larger than 0.15%. As  a result, replacing a complex V:1 fair arbiter with a  simple V:1 unfair arbiter can hardly hurt network  performances. Also, because VA  is a packet-level  operation and doesn’t run every cycle, starvation rarely  happens for a V:1 fix-priority arbiter. In the proposed  unfair VA, each (pi-1)V:1 arbiter is implemented by (pi-1)  unfair, fixed-priority V:1 arbiters and one (pi-1):1 matrix  arbiter which ensures the fairness between input ports.  3. Results and analysis  978-0-7695-3098-7/08 $25.00 © 2008 IEEE 978-0-7695-3098-7/08 $25.00 © 2008 IEEE DOI 10.1109/NOCS.2008.12 DOI 10.1109/NOCS.2008.12 207 207                               We compared four VAs in terms of area, power and  network performances: 1. general VA, 2. look-ahead VA,  3. unfair VA, 4. VA combining 2 & 3 techniques.  Uniform, local and global traffics are used in the  experiments. The spatial distribution of local and global  traffics is implemented by p model proposed in [3]. VA  utilization probability and power consumption was  analyzed when the network was near saturation.  NoC latency/throughput differences (figure5) were  calculated as the ratio of standard deviation of network  latency/throughput using  the 4 VAs  to network  latency/throughput using the general VA. We can see that  latency differences are no larger than 5% until the  network is nearly saturated and throughput differences are  always smaller than 1%. These results substantiate our  claim that NoC network performances change little with  the VA.  Compared  to  the small variances  in network  performances, cost savings are much more significant.  Look-ahead VA saves area cost by 60.24% (figure 6) and  power consumption by 61.11% (figure 7) while unfair VA  achieves 42.91% area reduction and 55.54% power saving.  As expected, the two techniques jointly cut the costs  further. Another important thing is that three tested traffic  patterns dissipate similar amounts of VA power. Thus, the  enormous VA cost savings described above may be  expected for all other untested traffics. For simplicity,  only uniform traffic is used for illustration.  0.16% 0.12% 0.08% 0.04% 0.00% p1 p2 uniform local glob al Figure 1. General VA         Figure 2. VA utilization  Figure 3. Look-ahead VA  208208 requests for  an output VC reques ts from  an input port  V:1  arbiter 1 V:1  arbiter  (p i-1) (pi -1) :1   arbiter Figure 4. Tree architecture for a (pi-1)V:1 arbiter  Figure 5. NoC latency/throughput differences  12348 7050 4910 3587 Gene ra l Look-ahead Unfa ir Combined Figure 6. Area of 4 VAs  Uniform Local Global ) 2 D N A N f o # ( a e r A 14000 12000 10000 8000 6000 4000 2000 0 ) w m ( r e w o P 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 General Look-ahead Unfair Combined Figure 7. Power consumption of 4 VAs  4. "
