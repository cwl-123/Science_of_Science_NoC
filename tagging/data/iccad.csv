year,title,abstract,full_text
2003,Performance Efficiency of Context-Flow System-on-Chip Platform.,"Recent efforts in adapting computer networks into system-on-chip (SOC), or network-on-chip, present a setback to the traditional computer systems for the lack of effective programming model, while not taking full advantage of the almost unlimited on-chip bandwidth. In this paper, we propose a new programming model, called context-flow, that is simple, safe, highly parallelizable yet transparent to the underlying architectural details. An SOC platform architecture is then designed to support this programming model, while fully exploiting the physical proximity between the processing elements. We demonstrate the performance efficiency of this architecture over bus based and packet-switch based networks by two case studies using a multi-processor architecture simulator.","PERFORMANCE EFFICIENCY OF CONTEXT-FLOW SYSTEM-ON-CHIP PLATFORM Rami Beidas, Jianwen Zhu Electrical and Computer Engineering University of Toronto Ontario M5S 3G4, Canada {rbeidas, jzhu}@eecg.toronto.edu ABSTRACT Recent efforts in adapting computer networks into system-on-chip (SOC), or network-on-chip, present a setback to the traditional computer systems for the lack of effective programming model, while not taking full advantage of the almost unlimited on-chip bandwidth. In this paper, we propose a new programming model, called context-ﬂow, that is simple, safe, highly parallelizable yet transparent to the underlying architectural details. An SOC platform architecture is then designed to support this programming model, while fully exploiting the physical proximity between the processing elements. We demonstrate the performance efﬁciency of this architecture over bus based and packet-switch based networks by two case studies using a multi-processor architecture simulator. 1. INTRODUCTION The continued advancement in semiconductor technology allows system-on-chips (SOC) to accommodate an increasing number of computational elements and embedded memory modules. So far, the industry has been using common busses and design speciﬁc communication channels to interconnect these components. Such global-wiring communication architectures are unable to scale with the large dies fabricated in the near future with a 0.1µm technology or below [1]. To overcome this problem and accommodate future applications that need massive parallelism, researchers proposed the use of interconnection networks, previously used to interconnect supercomputer components, to fulﬁll on-chip communication requirements [2]. While a burst of efforts have appeared under the banner of network-on-chip, we observe some common, yet important ommissions. First, while traditional computer architecture is well abstracted with a programming model, new SOC architectures have not made much progress on that front. An SOC platform is either modeled in system-level languages, such as SystemC [3] or SpecC [4], where a distinction between application, architecture and hardware does not exist, or using traditional parallel programming models, which are usually very complex. For example, the popular Message Passing Interface (MPI) programming model [5] deﬁnes an API with 127 C functions and there is no easy path to parallelize a sequential program into an MPI program other than the use of array-oriented scientiﬁc applications. Second, while traditional networks in supercomputers are designed with the bandwidth limitation imposed by chip pin count, new SOC platforms do not take full advantage of the much relaxed physical constraints and almost unlimited onchip bandwidth. We propose a new solution to address these problems and the following contributions are made in this paper. First, we propose a new programming model, where, in contrast to the common practice of supersetting the C language with new syntax or APIs, we subset the C language by imposing very few constraints revolving around a new concept, called context, which is essentially an abstraction of autonomous dynamic data structures. An application written with this programming model is not only simple, as it is “less” than the usual C code, but also safe in the sense of Java, as it is free of problems such as free memory access and dangling pointers. Second, we propose a new SOC platform architecture, called the context-ﬂow architecture, revolving around an on-chip network infrastructure called a tunnel, which takes full advantage of the physical proximity of tightly coupled processing elements. The tunnel implements the on-chip remote procedure call abstraction, therefore achieving the transparency of the programming model, since an application does not have to change with respect to the change in the underlying architecture, yet with a cost almost as cheap as local procedure calls, thereby achieving performance efﬁciency. Third, we have built a development suite by extending the popular SimpleScalar environment, which was designed for single processor architecture evaluation, so that complex applications can be compiled and simulated on the multi-processor context-ﬂow architecture platform. We validate the performance efﬁciency of this architecture by real world applications. The rest of the paper is organized as follows. In Section 2, we introduce the context-ﬂow programming model. In Section 3 the design of baseline context-ﬂow architecture is then described. In Section 4, we describe the performance evaluation framework we built for our architecture before we demonstrate in Section 5 its performance efﬁciency on two applications, namely an MP3 decoder and a cryptography accelerator. We discuss related work in Section 6 before we draw conclusions. 2. CONTEXT-FLOW PROGRAMMING MODEL A programming model is an abstraction that separates application from architecture. This separation is important to allow applications be developed and reused across different architectures, and vise versa. A programming model can be deﬁned at different levels of abstraction, and a hardware/software infrastructure is usually needed to support such abstraction. For example, an instruction set is a programming model deﬁned at the low level to abstract away Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.  ICCAD’03, November 11-13, 2003, San Jose, California, USA. Copyright 2003 ACM 1-58113-762-1/03/0011 ...$5.00. 356 Proceedings of the International Conference on Computer Aided Design (ICCAD’03)  1092-3152/03 $ 17.00 © 2003 ACM  architectural details such as pipelining and out-of-order issue, and a massive amount of hardware logic is used to realize this abstraction. A programming language is deﬁned at the higher level to abstract away the differences between different instruction sets, and a compiler is used to realize such abstractions. For the same programming model, a middleware infrastructure, such as CORBA [6] or DCOM, can be used to abstract away architectural details of a distributed environment to implement a distributed application the same way as a sequential one. The importance of programming model, however, is ignored in the hardware-centric CAD community. Even though platformbased design is advocated to allow the reuse and customization of pre-aggregated components, the concept of platform has not been formalized with a programming model for applications. Recent interest in building the communication infrastructure on massive parallel SOC has led to the concept of network-on-chip. Building a programming model for network-on-chip either has to use explicit communication with send/receive system calls, a wide departure from the traditional imperative programming model, or has to build another middleware infrastructure on top of the network, leading to performance degradation with the number of layers one communication session has to go through. We propose a new programming model formally deﬁned in Deﬁnition 1. Deﬁnition 1 Given a program with a set P of procedures, operlocated memory blocks. A block bi ∈ B is said to point to b j ∈ B, ating on a program state consisting of a set B of dynamically alif there exists a program point when the content of bi contains the address of b j . A context C ⊂ B is a set of blocks that are closed under the point-to relation, that is, any block bi reachable from block b j ∈ C is also an element of C . A contexted procedure is a procedure p such that all parameters of p points to memory blocks of the same context. A context-ﬂow program (cid:3)P,C(cid:4) is a program such that all its procedures p ∈ P are contexted procedures, and all its memory blocks, which capture the program state, belongs to a context c ∈ C . A context-ﬂow program (CFP) is extremely simple: it is simply a C program with the same sequential semantics. It therefore can be compiled using any conventional compiler and executed on any conventional machine. Contexts can be implemented by using the API shown in Figure 1. While the API consists of only three functions, it is the complete API seen by the application programmer. Here, cfNewContext creates a context and returns a unique identiﬁer. cfDelContext destroys a context, thereby reclaiming all the memory blocks contained in the context. cfAlloc allocates a memory block of certain size from the speciﬁed context. We now argue that a CFP is in fact simpler than a usual C program: note that the counterpart of cfAlloc, which should be responsible for memory block deallocation, is not provided by design. In fact, the memory is deallocated at the context level by cfDelContext. This relieves the task of ﬁne-grained memory management, thereby simplifying the programming task in a way similar to garbage collection. This simpliﬁcation can lead to program safety in the same sense of what garbage collection brings to modern languages such as Java. A CFP is free from dangling pointers and free memory access problems thanks to the closure property of contexts: there cannot be any references to freed memory blocks, since the memory containing the reference should belong to the same context, int int void* cfNewContext( void ); cfDelContext( int c ); cfAlloc( int c, int size ); 1 2 3 Figure 1: Context-ﬂow API. and therefore be freed already as well. On the other hand, the implementation of context is far cheaper than a garbage collector, in fact cheaper than the malloc/free in a normal program: the cost of memory allocation can be conﬁned to constant time using a stack based mechanism. Context is designed to be an abstraction of autonomous data structures. It can be anything ranging from arrays, linked lists, trees, graphs, or the combination of all. The concept of context offers a macroscopic view of the program and therefore makes coarse-grained parallelization much easier, which shall become apparent in the next section. 3. CONTEXT-FLOW ARCHITECTURE An architecture is an aggregate of architectural components such that an application can be executed or implemented through a well deﬁned programming model. A micro-architecture is an aggregate of components such as fetch stage, decode stage, execution stage and memory stage to implement a sequential application in C or other programming languages by its instruction set. On the other hand, a macro-architecture is an aggregate of components such as processing elements (PEs) and memories to implement a parallel application by a programming model such as MPI. The composition of a macro-architecture in a traditional parallel system is pre-deﬁned, whereas in the case of SOC, the composition is often customized according to one application or one family of applications. A macro-architecture is said to be homogeneous if all PEs are of the same type, e.g., processors, and heterogeneous if PEs can be microprocessors, DSPs, ASIPs or custom hardware cores. We consider the design of a macro-architecture, called the context-ﬂow macro-architecture (CFA), formally deﬁned in Definition 2. Deﬁnition 2 Given a context-ﬂow program (cid:3)P,C(cid:4), a context-ﬂow macro-architecture is a tuple (cid:3)E , M , S C , N (cid:4), where E is a set of processing elements (PEs), M is a set of memory banks, S C : P (cid:5)→ E is the static architectural conﬁguration which maps a procedure in the program to a processing elements, and N is the on-chip network where a runtime conﬁguration (cid:3)F : C → M , A : M (cid:5)→ P (cid:4) is maintained to bind each context to a distinct memory bank, and connects each memory bank to a PE for direct access, in such a way that a program point (cid:3) p, c(cid:4) ∈ P × C is active implies that S C ( p) = A (C (c)). Unlike an application in traditional programming model, A CFP is highly parallelizable, since different procedures, each accessing their own private data structures maintained in different context, can be run in a CFA in different PEs in parallel, without the concern of dependency hazard or cache coherence that frequently occur in the traditional shared or distributed memory architecture. The accesses of contexts do switch from one procedure Proceedings of the International Conference on Computer Aided Design (ICCAD’03)  1092-3152/03 $ 17.00 © 2003 ACM  357 to another, when a procedure call occurs. When the remote procedure call (RPC) abstraction is implemented by the on-chip network of a CFA, whose runtime conﬁguration in Deﬁnition 2 is dynamically adjusted, then a CFP is also highly transparent, meaning that it does not need to be changed no matter how the PEs in a CFA is allocated, and how the procedures are mapped. The key problem in the design of a CFA is the design of its on-chip network. We start by ﬁrst deﬁning a programming model, which abstracts how it interacts with the PEs that it connects. We deﬁne the programming model in the form of an instruction set, as shown in Figure 2. The instruction set is simple enough to contain only 10 instructions. It is encoded by the values of the wires on each port that connects a PE to the network. From the perspective of the network, it encodes a command or request from a PE. From the perspective of a PE, the instruction set is a complement of its own for which it can assume the availability of a co-processor for actual execution – effectively by driving the right wires in the corresponding ports. int void void* word void void void void word word cﬁAllocBank( void ); cﬁFreeBank( int bankid ); cﬁMalloc( int size ); cﬁLoad( int addr ); cﬁStore( int addr, word data ); cﬁCnctBank( int bankid ); cﬁRPC( int procid ); cﬁRet( int procid ); cﬁAckRPC( void ); cﬁAckRet( void ); 4 5 6 7 8 9 10 11 12 13 Figure 2: Context-ﬂow instruction set. We now consider how to implement an on-chip network that can implement this instruction set efﬁciently. There are several alternatives, each employing a different network topology. As shown in Figure 3 (a), a bus based CFA maintains a private memory bank for each of its PEs, in other words, the connection conﬁguration C in Deﬁnition 2 is static. The context is also maintained in its private memory bank. On the other hand, every time a RPC is invoked, the content of the corresponding context needs to be copied to the memory bank that belongs to the callee, and this data transfer is carried out by a shared bus. As shown in Figure 3 (b), a packet-switch based CFA is the same as bus-based except that the data transfer can be performed more efﬁciently: while a shared bus may invite transfer congestion, a well designed packet-switched network can distribute the communication trafﬁc evenly. Like previous efforts, these two alternatives do not take full advantage of the fact that the network we are designing is on-chip, and the PEs are physically close to each other. We propose a new based on-chip network, called a CFA tunnel. As shown in Figure 3 (c), the tunnel maintains a pool of separate memory banks, as well as an intelligent crossbar switch. Each context is dynamically mapped to a single memory until it is deallocated, and the crossbar ensures the access to the memory is dynamically switched to the callee whenever an RPC occurs. Note that our crossbar should not be confused with the crossbars in previous efforts, which is designed still for the purpose of data transfer. Instead, the goal of our crossbar is to provide the direct, wired access for memories. RPC, or the ﬂow of contexts from one PE to another, can then be achieved at virtually no cost! It is important to note that there is a physical limit for the scalability of the CFA tunnel. As the network gets larger, the delay of the crossbar grows quickly, thereby increasing the cost of each memory access. This can be contained by employing a two-layer strategy, where PEs are partitioned into clusters based on the communication trafﬁc among them, and intra-cluster network is based on the tunnel, whereas the inter-cluster network is based on packet switch. In this paper, we focus only on the study of the ﬂat network, which we believe is appropriate for the applications we are interested in. 4. PERFORMANCE EVALUATION FRAMEWORK We target complex applications which are usually described in C using high-level language features such as pointer references and complex data structures. The speculated performance advantage can only be validated on such applications. A performance evaluation environment, which can simulate CFA with reasonable architectural details for any CFP applications, is therefore needed. A good example of an architectural evaluation environment is the SimpleScalar toolset developed at Wisconsin [7]. It is designed to study new innovations in micro-architecture such as pipelining, branch prediction, out-of-order issue etc. The environment provides a complete compiler tool chain that can compile a C application into a binary in the PISA instruction set. An instruction set simulator can then be used to simulate the binary, while collecting performance metric of interest. Figure 4 (a) shows the pseudo code of sim-safe, a fast simulator provided in SimpleScalar, which maintains the processor state by a simulated memory (mem) and registers (regs). It starts by loading the application binary into a simulated memory, and then entering a loop which fetches an instruction from the simulated memory at a time, decodes it, and then performs an action that is consistent with the instruction semantics, while updating simulated registers and memory accordingly. In the sequel, we ﬁrst introduce how the SimpleScalar infrastructure is extended into a multi-processor, CFA performance evaluation environment. We then show how a C program is mapped into a CFA in our environment by a simple, yet complete example. 4.1. Sim-CFA We consider a homogeneous CFA where each PE is implemented by a processor equipped with the PISA instruction complemented by the context-ﬂow instruction set deﬁned in Section 3. The processor state in a single processor environment ﬁrst needs to be replicated, as shown in Figure 4 (b). While each PE has its own private address space, an unused memory space segment of each PE, from address 0x00000000 to 0x03FFFFFF, is mapped to context memory pool. With this approach, high-level language features, such as array references, pointer indirection and structure member references, can still be used directly in the source code to access objects within the context. The simulator was modiﬁed to run multiple SimpleScalar processors simultaneously modeling the multiple threads executing in parallel on the system PEs. For this purpose, the memory space and register ﬁles were replicated, one per PE, and the main execution loop of the simulator was modiﬁed to execute one instruction from each PE code at each simulation cycle. SimpleScalar suite provides a very useful annotation interface where unused bits in the instructions can be used to introduce new Proceedings of the International Conference on Computer Aided Design (ICCAD’03)  1092-3152/03 $ 17.00 © 2003 ACM  358 PE PE PE PE PE M E M M E M M E M M E M M E M P E M E M P E M E M Packet Switch P E M E M DMA P E M E M P E M E M PE PE PE PE PE                   Tunnel M E M M E M M E M M E M M E M M E M M E M (a) (b) (c) Figure 3: Alternative Implementations of Context-Flow Architectures RegsType     regs; MemSpaceType mem; RegsType     regs[NUM_OF_PES]; MemSpaceType mem [NUM_OF_PES]; void simCore(  ) {   /* create memory space &    *load target program    */   memCreate(mem);   loadProg(prog, mem);   while(TRUE) {     /* fetch next instruction      * to execute      */     inst = Fetch(mem, reg.PC);     /* decode, execute, and      * commit the instr      */     switch (  opcode(inst)  )     {       case ADD: perform_add;       case SUB: perform_sub;     }     /* go to next instr */     reg.PC=reg.NPC; reg.NPC++;   } } (a) void simCore(  ) {   /* create memory space &    * load target program */   for( each PE p ) {     memCreate(mem[p]);     loadProg(prog[p], mem[p]);   }   while(TRUE) {     for( each PE p ) {       /* fetch ... */       inst = Fetch(mem[p], reg.PC[p]);       /* decode, execute, and commit */       if( annotated(inst) )         switch ( annotation(inst) ) {           case RPC: perform RCP;           case AllocBank: perform alloc;         }       else if (memAccess(inst) &&                addr<0x04000000) access context flow memory banks;       else { /* normal code */         switch (  opcode(inst)  )           case ADD: perform add;           case SUB: perform sub;         }       /* go to the next instruction */       reg.PC[p]=reg.NPC[p]; reg.NPC[p]++;     }   } } (b) Figure 4: The Original and Modiﬁed SimpleScalar Simulator Core instructions without the change of compiler tool suite. A new instruction is deﬁned by giving a non-zero annotation value to predeﬁned instruction opcodes. This annotation value can be detected at runtime and interpreted by emulating the corresponding behavior. We use this feature to help introduce the context-ﬂow instruction set to each PE. Some of the instructions will be used to implement the context-ﬂow API (Section 2), while others will be used by the compiler described in the next section to implement RPC. As shown in Figure 4 (b), the simulation engine starts by loading the binaries for each PE into the simulated memories. At each simulation cycle, for each PE, the simulator fetches an instruction from memory and decodes it. If its annotation ﬁeld is non-zero, meaning that it is a context-ﬂow instruction, it will invoke the corresponding on-chip network simulation to process a request on one of the ports of the network. If it is a memory access whose address falls into the range from 0x00000000 to 0x03FFFFFF, the corresponding location inside the context memory pool will be accessed. Otherwise, it will interpret the instruction the same way as SimpleScalar does. We implemented different networks deﬁned in Section 3, including bus based, packet switched and tunnel based. Note that at this stage of implementation, our packet switched network is very preliminary: we assume a perfect network where no congestion can ever occur (equivalent to point-to-point), which can nevertheless give the performance upper bound. Another simpliﬁcation we use for now to obtain a ﬁrst order approximation of heterogeneous CFA, where processing elements can be custom hardware, is to include a linear speedup number for a PE intended for ASIC, thereby getting an approximate execution time. Our simulator collects several useful performance statistics during simulation. Throughput measures the rate at which CFA can accept the top-level RPC. Utilization measures the percentage at which the PEs are busy computing rather than idling. 4.2. Architecture Conﬁguration and Application Compilation top(float* B, int n) { sqrtArray(B, n); addArray(B, n); } sqrtArray(float* B, int n) {   for(i=0; i<n; i++)      B[i] = sqrt(B[i]); } addArray(float* B, int n) {   for(i=0; i<n; i++)      B[i] += 2.0; } Figure 5: Original C Implementation of a Simple Array Processor √ Consider that we need to implement an array processor that calculates f (A) = A + 2.0 : A ∈ Rn . A possible traditional C implementation that breaks down the calculation into two steps is shown in Figure 5. To transform the program into a CFP, the ﬁrst step is context deﬁnition. In this example, the context is simply the data array. Figure 6 presents a transformation of the source code that runs on two PEs, mapping top() and sqrtArray() to PE0 and addArray() to PE1. Procedure mappings to system PEs are deﬁned in “conﬁg.dat” along with these procedures’ stamps. This ﬁle is used to generate proxies and main functions for each PE via an automatic code generator (Figure 7). Note that the main() for each PE simply runs an inﬁnite loop waiting for call to the procedures it implements. WAIT FOR RPC() and READ 2 ARGS() are simply macros that use cﬁAckRPC() and cﬁLoad(), respectively. Once coded/generated, the source ﬁles of each PE along with proxies’ deﬁnition are compiled by the SimpleScalar gcc compiler ss-gcc. Sim-CFlow then can simulate the modeled system by runProceedings of the International Conference on Computer Aided Design (ICCAD’03)  1092-3152/03 $ 17.00 © 2003 ACM  359 sqrtArray(float* B, int n) {   for(i=0; i<n; i++)      B[i] = sqrt(B[i]); } addArray(float* B, int n) {   cfiRPC(ADD_ID); }                      { top(float* B, int n) sqrtArray(B, n); addArray(B, n); } main() {   while(1) {     WAIT_FOR_RPC();     if(callee==TOP_ID) {       READ_2_ARGS(A, n);       top(A,n);     } else {       if(callee==SQRT_ID) {       READ_2_ARGS(A, n);       sqrtArray(A,n);     }   } } PE0 addArray(float* B,int n) {   for(i=0; i<n; i++)      B[i] += 2.0; } main() {   while(1) {     WAIT_FOR_RPC();     if(callee==ADD_ID) {       READ_2_ARGS(A, n);       addArray(A,n);     }   } } PE1 Figure 6: The Context-Flow Version of a Simple Array Processor ning the generated binary ﬁles to generate detailed performance reports. config.dat code gen. mapping description ss-gcc pe0.ss pe1.ss pe2.ss pe3.ss pe4.ss pe5.ss sim-cflow performance statistics cflow.h proxies.h proxies.c main.c methods source code (*.c,*.h) PE2 Figure 7: Sim-CFlow Simulation Process 5. TEST CASES AND PERFORMANCE RESULTS In this section we present performance results of several architectural conﬁgurations in comparison of our proposal. Evaluations were applied to two real-life applications, namely, MPEG1LayerIII decoder and cryptography acceleration processor. The performance evaluation framework presented in Section 4 was used to hold the experiments. 5.1. MPEG1-LayerIII Decoder MPEG1-LayerIII, commonly referred to as MP3, is the de-facto standard of high-quality high-compression of audio data. MP3 decoders became of interest after their popular use in portable multimedia devices. An overview of the decoder stages is presented in Figure 8. The highlighted stages were implemented in our testbench. Each Input Stream Synch CRC Huff. Tbl. Scalefac Huffman Decoding Requantize Reorder Stereo Decoding Alias Reduction IMDCT Frequency Inversion Subband Synthesis Output Stream Figure 8: MP3 Decoder stage is implemented in a single procedure processing one data granule at a time. Procedures are grouped in PEs such that the sum of method delays within PEs are as close as possible, targeting efﬁcient thread-level pipelining. Due to the absence of accurate hardware implementation performance numbers, the delay of each method is determined using the number of memory accesses per call, assuming a perfect pipeline implementation of the processors and that memory bandwidth is the primary bottleneck. Current datapath synthesis tools (such as Module Compiler by Synopsys) can easily pipeline the computational parts of the target algorithm. In our experiment, each conﬁguration uses 6 4-KBytes SRAM banks. Simulation results are shown in Table 1, where the second column reports the throughput in cycles per request. The third column reports the average PE utilization. Architecture Context-Flow Single-PE Shared-bus Perf. Packet Switched Throughput 3439 9800 5944 5043 PE Util. 71% 100% 41% 48% Table 1: MP3 Decoder Results 5.2. Cryptography Acceleration Processor IN Packets (encryption) OUT Packets (decreption) MD5 SHA1 RC4 DES ECB 3DES ECB DES CBC 3DES CBC RSA IN Packets (decryption) OUT Packets (encreption) Figure 9: Crypto Accelerator Flow Cryptography acceleration processors are becoming of central interest with the increase of SSL-based trafﬁc over the internet. In our bench mark, we implemented a number of symmetric and asymmetric algorithms commonly used in SSL and IPSec. The implemented functions and the possible ﬂows of packets are shown in Figure 9. Delay of processing methods were obtained from actual RTL implementations [8] and comparison results [9]. The longest path of an input packet is to go through all three categories of processing, namely hashing (MD5 or SHA1), symmetric or privatekey encryption (DESECB, DESCBC, 3DESECB, 3DESCBC, or Proceedings of the International Conference on Computer Aided Design (ICCAD’03)  1092-3152/03 $ 17.00 © 2003 ACM  360 RC4), asymmetric or public-key encryption (RSA). Packets could skip hashing, public-key encryption, or both. To carry out the experiment, we coded a packet generator that generates a packet mix which uses various processing paths according to a given distribution. A set of packets was generated and an appropriate mapping, not necessarily optimal, to a 6 PE system was used to get the results summarized in Table 2. Architecture Context-Flow Single-PE Shared-bus Perf. Packet Switched Throughput 742 9039 1808 1156 PE Util. 65% 100% 26% 44% Table 2: Crypto Accelerator Results 5.3. Discussion By looking at the evaluation results, we start by noting the importance of parallelizing the application on multiple PEs. The single PE implementation of the crypto processor is 12x slower than the tunnel-based implementation. It is also clear that the tunnel approach provides better performance when compared to alternative multi-PE conﬁgurations. A speedup of 2.43x and 1.56x were obtained by using tunnel-based architecture instead of a shared-bus and packet switch, respectively. The 56% increase in performance was achieved even though that the packet switch implementation assumes congestion-free trafﬁc, which is usually not the case with real designs. The performance enhancement can also be viewed by comparing the average utilization of PEs, which also implies a better utilization of system memory resources. Similar results were also obtained with the MP3 application. In short, using our proposed architecture and thread-level pipelining results in a fairly large performance gain without any change in processing element designs. 6. RELATED WORK The MIT Raw machine was one of the earliest designs to utilize on-chip interconnection networks [10]. It uses several 2-D mesh networks to connect an array of identical programmable tiles of RISC processing cores. Dally in [2] suggests the use of on-chip interconnection networks for future SOC where traditional interconnection techniques do not scale. It suggests the use of regular interconnection topologies, such as torus and mesh networks, as a means of communication between square tiles of identical dimensions, but not necessarily homogeneous. The work in [11] elaborates on this architecture targeting design exploration at the system level. Their work proposes mapping algorithms that target the power/performance optimization problems for the regular communication architecture. The use of crossbar based interconnects started to become popular in recent years. The Berkeley IRAM [12] and Stanford Smart Memory system [13] both use a crossbar to interface a single general purpose programmable RISC PE to an array of memory banks, targeting the high bandwidth that crossbars provide. However, the high-level interface we implemented in our tunnels is not used in those systems as only a single PE is interfaced to the memory pool. 7. CONCLUSION AND FURTHER WORK In this paper, we introduced the context-ﬂow programming model and proposed a supporting platform architecture. A simulation environment was developed and used to evaluate the new architecture in comparison with traditional interconnection organizations. The results obtained conﬁrm the performance improvement of contextﬂow architecture using real-life applications. Several issues are still open for further investigation and development. The SimpleScalar based simulator used in our study will undergo several enhancements for a better representation of heterogeneous systems. Future work will also investigate compiler techniques for automatic code translation of system description into context-ﬂow program. 8. "
2004,Application-specific buffer space allocation for networks-on-chip router design.,"We present a system-level buffer planning algorithm that can be used to customize the router design in networks-on-chip (NoCs). More precisely, given the traffic characteristics of the target application and the buffering space budget, our algorithm automatically assigns the buffer depth for each input channel, in different routers across the chip, to match the communication pattern, such that the overall performance is maximized. This is in deep contrast with the uniform assignment of buffering resources (currently used in NoC design) which can significantly degrade the overall system performance. For instance, for a complex audio/video application, about 85% savings in buffering resources can be achieved by smart buffer allocation using our algorithm without any reduction in performance.","Application-Specific Buffer Space Allocation for  Networks-on-Chip Router Design*  Jingcao Hu  Carnegie Mellon University  Pittsburgh, PA 15213-3890, USA  jingcao@ece.cmu.edu  Radu Marculescu  Carnegie Mellon University  Pittsburgh, PA 15213-3890, USA  radum@ece.cmu.edu  ABSTRACT  In this paper, w e present a novel system-level huffer planning algo-  rithm that can be used to customize the router design in Networks-  on-Chip (NoCs). More precisely, given the tr&c characteristics of  the target application and the buffering space budget, our algorithm  automatically assigns the buffer depth for each input channel, in  different routers across the chip, to match the communication pat-  tem , such that the overall performance is maximized. This is in  deep contrast with the uniform assignment of buffering resources  (currently used in NoC design) which can significantly degrade  the overall system performance. For instance, for a complex au-  diolvideo application, about 8 5% savings in buffering resources can  be achieved by smart buffer allocation using our algorithm without  any reduction in performance.  1. INTRODUCTION  With the advances in the semiconductor technology, i t becomes  possible for designers to integrate tens of Intellectual Pmperty (IP)  blocks together with large amounts of embedded memory on a sin-  gle chip. This richness of the computational resources (CPU or  DSP cores. video processors, erc .) places tremendous demands on  the communication resources as well. Additionally, the shrinking  of feature s i r e in the deep-subm icmn (DSM) technologies makes  interconnect delay and power consumption the dominant factors in  the optimization of modem systems. Interconnect optimization un-  der DSM effects is complicated because of the worsening effects  due t o crosstalk, e lec tromagne t ic interference, err. [ZI].  T h e NoC approach was proposed as a promising solution to these  complex on-chip communication problems [51[9][1][20]. For such  an architecture, the chip is divided into a set of interconnected  b locks (or nodes) where each node can be a general-purpose pro-  cessor, a DSP, a memory subsystem, err. Fig. l ( a ) shows an exam-  ple of a NoC implementation where nodes are connected in a 2 0  mesh topology. A router is embedded within each node with the ob-  jective of connecting it to its neighboring nodes (a typical on-chip  router for a 2 0 mesh NoC is shown in Fig. l(h)). As such, instead  of routing design-specific global wires, the inter-nodes communi-  cation can be achieved by routing packets.  Compared to a standard data macro-network, an on-chip network  is by far more resource limited. To minimize the implementation  cost, the on-chip network should be implemented with very little  area overhead. This is especially important for those architectures  composed of nodes designed at a fine-level of granularity. Th e in-  put buffers in a typical on-chip router (highlighted in Fig. l(b)) take  a significant portion of the silicon area of the NoC and consequently  *Research supported by NSF CCR-00-93 104 and Marco Gigascale  Systems Research Center (GSRC).  (b)  F i g u r e 1: (a) NoC imp l em en t ing a 2D mesh topology (b) Typ ica l  on - ch ip r o u t e r a r ch i t e c tu r e  their s ize should be carefully minimized. On the other hand, the  raw performance of a NoC is drastically impacted by the amount  of buffering resources it can use, especially when the network be-  comes congested. Moreover, s ince the traffic characteristics varies  significantly across different applications, the buffering resources  have to he judiciously allocated to each input channel in order to  match the specific communication pattems that characterize vari-  ous applications. Th e uniform distribution of buffering resources,  although straightforward and widely used in current NoC designs,  fails to achieve this objective: this leads to poor performance andlor  excessive use of the silicon area. To address such issues, the con-  tributions of this paper are twofold:  First, we propose an efficient algorithm which optimizes the  allocation of buffering resources across different router chan-  nels, while matching the communication characteristics of  the target application. More precisely, given the total avail-  able buffering space, the arrival rates between different com-  0-7803-8702-3/04/$20.00 02004 IEEE.  354  municating E' pairs and other relevant architectural param-  eters (e.g., routing algorithm, arbitration delay, e t c . ) , ou r al-  gorithm automatically decides the buffer depth fo r every in-  put channel in each on-chip router. As an example, refemng  to Fig. I , instead of uniformly assigning the buffer size to  be four units in each and every input channel, w e may as-  sign the size of the east input buffer in the router located at  tile (12 ) to be six while keeping the size of the south in -  put buffer in the router located at tile (2.2) to b e one. This  can be done according to the communication characteristics  of the target application, such that the overall network per-  formance is maximized. For a complex aud io lv idw applica-  tion, such an application-specific buffer customization allows  us to achieve the same performance level as a straightfor-  ward implementation which assigns the buffer s ize uniformly  across the chip, but using 85% less buffering resources. This  i s also important from a power dissipation perspective.  Second, we propose a novel analytical model which can be  used to quickly analyze a given buffer size configuration and  detect potential performance bottlenecks in the muter chan-  nels. Th is is done by solving a set of nonlinear equations de-  rived from detailed queuing models. This analytical model  lies at the very heart of the algorithm for allocating buffer  resources. Th e main advantage in using this analytical ap-  proach as opposed to straightfonvard simulation i s the ability  to quickly analyze the impact of various application-specific  communication patterns on the overall system's performance.  T h e remaining part of this paper is organized as follows. In Sec-  tion 2, w e give a brief review of the relevant work. The problem of  buffer allocation for NoCs is then described in Section 3. Follow-  ing that, in Section 4 , an efficient heuristic is proposed to solve this  problem. Experimental results in Section 5 show that, compared to  uniform buffer allocation, significant performance improvements  can be achieved while satisfying the same total buffering space bud-  get. Finally, we summarize our contribution and suggest possible  directions for future work.  2. RELATEDWORK  NoC design typically targets a specific application o r a limited  class of applications. Thus, the NoC architecture can be customized  for each specific application in order to achieve best energy, perfor-  mance and cost trade-offs [S][ l l] . There exists interesting work in  this direction. In [ 2 ] , Jalabert er al. show the benefits of the network  topology customization a n the system area, power and latency. Th e  authors of [ 14][17l investigate the topological mapping of E's onto  the No€ architectures for bandwidth and communication energy  savings. The work presented in this paper follows a different direc-  tion by addressing the customized, application-specific, allocation  of buffer resources to different channels in each router. To the best  of ou r knowledge. our work is the first to address the buffer alloca-  tion problem for NoC-based architectures and provide an efficient  way to solve it.  Traditional work on performance evaluation in parallel comput-  ing either uses either time-consuming simulation (e.g., [12][6]) or  provides analytical models for limited traffic conditions (typically  uniform models) [4][7]. Th e assumption of uniform traffic makes  sense in general purpose parallel computing as the interconnect ar-  chitecture needs to support a wide spectrum of applications. How-  ever, such an assumption may not be appropriate for NoC designs;  NoCs are typically designed for specific applications and thus ex-  hibit very specific traffic patterns.  Adve and Vernon in [3] model a wormhole-based [8] mesh net-  work as a closed queuing network and use approximate mean value  analysis to calculate the average packet latency under arbitrary source-  destination probabilities. However, all of these analytical models  apply only to networks with infinite buffers (e.g., [4][7]) andlor  single-flit buffers [31. As such, they can not be used for buffer allo-  cation in which the effect of arbitrary, but finite, buffer s ize has to  be explicitly modeled.  3. THE PROBLEM OF ROUTER BUFFER  ALLOCATION FOR NoCs  Simply stated, given the communication probability between each  communicating IP pair and the total budget of buffering resources  that the designer is allowed to use, the problem we need to solve is  to find the buffer depth assignment f o r each input channel, across  all the on-chip routers, such that the communication performance  is maximized. If the performance i s measured in terms of average  packet latency, then maximizing the performance means, in fact,  minimizing the end-to-end packet latency.  Next, we review the network platform and the traffic models  which are relevant to our algorithm. We then formalize the problem  and illustrate the significance of finding a good solution to it.  3.1 System characterization  3 .1 .1 Platform characterization  The system under consideration is composed of m x n tiles in-  terconnected by a 2 0 mesh network. Because of its simplicity, the  choice of a 2 0 mesh as the underlying NoC architecture serves  only as an example for our algorithm '. We further assume that de-  terministic routing (e.g.. dimension-ordered routing [MI) is used  to dircct the packets across the network instead of adaptive rout-  ing because of the resource limitations, as well as the out-of-order  packet delivery problem associated with the adaptive routing. More  precisely, store-and-forward or virtual cut-through [ 161 routing is  assumed to be used for the network. Thus, in our analysis, a packet  can be treated as a basiclatomic unit since it will always be trans-  mitted or buffered as an indivisible entity.  For the sake of simplicity, w e assume that all the packets in the  network have a fixed size. Thus , in the absence of packet con-  tention, the service time of each packet in a router (measured as the  time span from the moment when the packet an ives at the header  of the input channel of the router to the time it takes to receive it  by the input channel of the downstream router) is f ix ed and can be  accurately calculated. More precisely, the sew ice time pe r p a c k t  ( S ) in a router wirhout contention can be calculated as follows:  s = TAD + T SEL i TAR S TCS t T L I N X  (1)  In Eq. ( I ) , T A D , T S E L and TARS are the delays of the address  decoding, routing path selection and crossbar arbitration, respec-  tively. These parameters are usually independent o f the packet  length. On the other hand, T c e and T L ~ N K model the delays in  the crossbar and link traversal, respectively; they are usually pro-  portional to the packet size. We note that different router architec-  ture may lead to different delay models (e.g., [19]) but this will not  change the flow of our buffer allocation algorithm.  We assume that the on-chip routers have the structure shown in  Fig. I(b). Each input controller has a separate buffer (typically im-  plemented using registers for performance reasons) which buffers  'The algorithm can be extended for arbitrary topologies as i t will  be explained later.  355  the input packets before delivering them to the output channels.  Each such input buffer in the router can have a different depth. This  can h e easily implemented, for instance, at the instantiation phase  through a parameterized design methodology. When a new packet  is received, the address decoder processes the incoming packet and  sends the destination address to the channel controller; this con-  troller determines which output channel the packet should be deliv-  ered to. Once the router has made the decision on which direction  the da ta should he routed to, the channel controller sends the con-  nection request to the Cmssbar Arbiter in order to set up a path to  the corresponding output channel.  T h e actual use of the input buffer is regulated through a back-  pressure mechanism. Under this scheme, a packet is held in the  buffer until the downstream router has enough empty space avail-  able (in the corresponding input buffer) such that network will not  drop any packet in transit. This is extremely important for N&  architectures where implementing advanced end-to-end protocols  may not he possible. Once a packet arrives at an inpu t buffer, it  will be served on a j i r s t -come -~ r s t - se rved (FCFS) manner.  Without loss of generality, we assume that the buffer s ize is mea-  sured in multiples of packet size. More specifically, le t size of  a packet be S P bytes; then the size of any input buffer must be  m x S P , where m is a positive integer. We also assume the size  of th e local input buffer (the input channel which accepts packets  from the router's local PE) to be infinite. This i s a reasonable as-  sumption since the PE can also use i ts local memory (which is usu-  ally much larger compared to router buffers) to store inpu t packets.  Due to this assumption, the s ize of local input buffer will not he  considered anymore in our allocation process.  T h e Crossbar Arbiter maintains the status of the current cross-  bar connection and determines whether o r not to grant connection  permission to the channel controller. When there are multiple input  channel controllers requests for the same available ou tpu t channel,  the Cm s sba r Arbiter also uses the FCFS policy to dec ide which in-  put channel gets the access, such that the starvation at a panicular  channel can be avoided.  3 .1 .2 Traffic characterization  Similar to most previous work on interconnection network per-  formance evaluation, the traffic pattem of a given application is  modeled assuming that each processing element (PE) injects pack-  e ts w i th a Poisson distribution. More specifically, let (x, y ) he the  location of the tile at the column x and row y of the NoC as shown  in Fig. l(a) ; this means that for the PE located a t (z, y), the packet  injection is modeled with a Poisson input rate  Moreover, we  assume that any packet injected in the network i s independent. For  a packet generated by PE at (x, y). the probability that the packet  i s delivered to the PE at (x', y') is represented by d$$ .  T h e average packet latency ( L ) is used as the metric for NoC  communication performance. Similar to previous work, w e assume  that th e packet latency spans the instant when the packet is created,  to th e time when the packet i s delivered to the destination node,  including the queuing time spent at the source. We a lso assume  that the packets are consumed immediately once they reach their  destination nodes. Although this is a simplificd model, we feel that  such simplifications are necessary in order to provide an analytical  solution to the buffer allocation problem.  3.2 Problem formulation  For convenience, we summarize the basic parameters in Table 12.  With these notations, the problem of router buffer allocation for  'Some of the parameters will be explained later in more detail.  Param. I  S P  ~~  1.  [I  Tab le 1: P a r a m e t e r no t a t ion  Descr ip t ion  I The size of a packet  ' The total huffennf space budget  The average p a c k 1 Ialcncy  Packet service time in a router without  contention  R Routing function  Th e router located at tile (x, y )  The d i r direction inpu t channel in router R z , y  Th e PE located at tile ( z , y )  The buffer size of channel C z , v , a i v  Packet injection rate of PE.,,  The probability of a packet generated by PE,,,  to he delivered to PE,,,,,  The packet an iva l ra te at channel Cz,y,d.r  Th e probability of a packet at channel Cz,y,dir  to he delivered toward d ir ' direction  The service rate for packet at channel C z , v , d ; F  Th e utilization factor of channel C..y,d,r  The probability of th e buffer at Cr,y,d,r being  R z ,y  C r ,y ,d i r  PE,,,  l=,v,d;F  a=.y  d::by'  X r , y , d i r  d ir ,  p = ,Y , d *T  pz,y,d,p  p.,.,,dir  b o , v , d i r  full  I  2  c - 0 -  P  U 5 B  2 Y)  '=  - E  ?2  8 1  U 4 B  v) 8  .- -  .- -  0  3 a:  performance maximization under total buffering space constraints  can be formulated as follows:  Given:  Total available buffering space B  Application communication characteristics  and d : , P  Architecture specific packet servicing time S a n d routing func-  tion R  D e t e rm in e :  Buffer size l z , y , d < v for each input channel  which m in im izes the average packet latency L :  I , 3.3 Significance of the problem  In order to be reduce the NoC implementation cost and power  dissipation, small on-chip routers are definitely needed. To bet-  ter understand the main resource consumers, we implemented a  prototype of an on-chip router based on the architecture shown in  Fig. I(b) [IS]. Th e router supports XY routing with FCFS crossbar  arbiter and uses a 0.16um technology. In this design, each input  port has a fixed link width of 32 bits. Th e FIFOs are implemented  using registers for good performancelpower efficiency.  Fig. 2 shows the area of the router as a function of FIFO size.  Th e X axis represents the FIFO capacity as number of words (a  word i s equal to 32 hits in this plot), while the Y axis gives the  area of router in equivalent gates. As we can s e e , increasing the  FIFO capacity significantly increases the router area. For instance,  increasing the FIFO size in each inpu t channel from 2 to 3 words  leads to an increase of total router area by 30%. Thus, to minimize  the implementation overhead of NoC. an effective approach is to  reduce the overall use of the buffering space in the routers.  356    ,x lo‘  0.51  FIFO capacity (words)  F i g u r e 2: R o u t e r sizes with d i f f e r en t F I F O capac i ty  To show the impact of the FIFO capacity on the communica-  tion performance, we simulated a 4 x 4 NoC system under differ-  ent traffic pattems when the FIFO capacity changes. Each sim-  ulation i s first run for a w a m - u p period of 2000 cycles. After  that, performance data is collected once 20,000 packets are sent.  A cycle-accurate interconnection network simulator (Ne t s ) was im-  plemented in C++. Nets suppons 2 0 mesh networks with packet  routing; it has been designed to be easy customized to simulate d if-  ferent designs under various traffic patterns. Since many factors  (e.g., routing path selection delay, crossbar arbitration delay, e tc . )  have a significant impact on the NoC performance, Nets models  them accurately with the actual values taken from the prototype  router design.  to use the silicon area. Because of the heterogeneity of the traffic  pattern in most application-specific NOCs, it makes sense to allo-  cate more buffering resources only to the heavy loaded channels.  The main idea is that the more “important” channels ger allocated  larger FIFOs comparrd 10 other, less importunr, channels.  Indeed, it tums ou t that customizing the buffer s ize individually  can improve the overall system performance significantly. To illus-  trate this idea, we arbitrarily select the system in which each input  channel has a uniform buffer s ize of 4 x S P and use it as an ex-  ample to see how much performance improvement can we gain by  jud ic ious buffer allocation. We note that the routers at the border of  the NoC may have fewer input channels (for instance, the routers  in the bottom row do not need south input channel). Thus, there  are in fact only 48 channels and the total buffering space used is  thus 4 x S P x 48 = 192 x S P (that is , B = 192). We ran-  domly generate 1000 solutions, all of them using 192 x S P buffer-  ing space. Each configuration is then simulated under the injection  rate o f 0.171 packets per second. The performance is shown as a  histogram in Fig. 4.  As we can see, the solutions vary significantly in terms of aver-  age packet latency, despite the fact that all o f them use the exact  same total amount of buffering space. Another interesting thing to  note is that, among the IO00 random generated solutions, the best  solution ever found has average packet latency of 187 clock cycles,  which is significantly better than the performance of the system  having every buffer uniformly assigned of s ize 4 x S P , whose av-  erage packet latency is as high as 1856 clock cycles. (There is a  fac to r of I O difference between the two latency values!)  40  35t  I  I ‘I  10 illlikL  15  I  00  OO 5  Average  2000 Packet 4000 Latency [cycles)  6000  Packet iniection rate (packetslcycle)  F i g u r e 3: Sys tem p e r fo rm an c e with d ifferen t FIFO capac i ty  Fig. 3 shows a typical latencylthroughput plot under different  communication loads and FIFO sizes. The simulated traffic pat-  tem is hot spot’, where the PES located at tiles (1 ,O ) and ( 2 , 2 )  (see Fig. I@)) are the ones chosen t o generate the two hot spots.  Th e impact of the buffer size on the average packet latency is ob-  vious from Fig. 3. More specifically, when the network becomes  congested, increasing the buffer size helps in reducing the average  packet latency. For instance, under the injection rate of 0.16 pack-  e ts per clock cycle, the average packet latency of the system with  a uniform buffer size of 2 is 862 clock cycles (point A in Fig. 3) .  while the average packet latency for a uniform buffer size of 3 is  only 64 clock cycles (point B in Fig. 3) .  On the other hand, increasing uniformly the capacity of every  FIFO in every on-chip router may not be the most effective way  3The ho t spo r traffic is explained in Section 5 .  F i g u r e 4 H i s tog r am for 1000 d ifferen t r a n d o m bu f f e r configu-  r a t i o n s  On the other hand, 1000 random solutions represent only a small  portion of the entire solutions space, thus the optimal solution may  perform even better than the best solution shown above. Indeed, by  applying our buffer allocation algorithm, th e system generated by  the algorithm has an average packet latency of as low as 29 c lm k  cycles at the injection rate of 0.171 packets per cycle. We need to  note that the performance of the system with the customized FIFO  buffers performs even better than the system with uniform FIFO  capacity of 8 x SP, which has an average packet latency of 91  clock cycles at this injection rate. Consequently, by customizing  the buffer size. we can actually implement a system which has bet-  ter performance, but uses only half of the buffering resources com-  pared to a system with FIFO s ize uniformly assigned to 8 x S P .  This fully justifies the approach we take for FIFO size customiza-  tion.  3 5 1  4. SOLVING THE ROUTER BUFFER AL-  LOCATION PROBLEM  In this section, we present a novel buffer allocation algorithm  which starts from the minimum buffer size configuration (where  each input channel has a buffer s ize of only one packet) and itera-  tively increases the buffer size of the bottleneck channels until the  specified value of the buffer budget is reached.  4.1 Routerkhannel analytical models  The main part of the algorithm implements a technique for de-  tecting the performance bottleneck among the different router chan-  nels. More specifically, giving the current buffer size configura-  tion, the algorithm tries to identify the channels where adding ex-  tra buffering space leads to the maximum improvement in perfor-  mance. One way to guide this process would be to simulate the  system implementing such a configuration and then profile the sim-  ulation results. Unfortunately, despite i ts flexibility, the simulation  approach suffers from extremely long simulation times. Since we  need to evaluate the system for every possible buffer configuration,  the evaluation based on direct simulation i s simply impossible to  afford.  In the following, we propose a novel analytical model which can  he used to quickly analyze the current buffer size configuration and  detect the performance bottlenecks in the router channels; this is  done by solving a series of nonlinear equations derived from queu-  ing models. Th e basic idea i s that, given the system configuration  (which includes the traffic pattem, the routing delay and the s ize  of each FIFO in the current solution), the algorithm detects the  FIFO which has the highest probability to be in the "" f i l l srate"".  The channel which owns this particular FIFO becomes the real per-  formance bonkn e ck in the current configuration and thus its s ize  should be increased.  To solve this problem analytically, w e resort to the theory of f i -  nite queuing networks [131. Th e basic element in the model is a  W I / K finite queue (the first two ""M"" mean that the customer  arrival time and server's service time follow exponential distribu-  tions, ""1"" tells that the queue has one server to provide the service,  and finally ""K"" represents the capacity of the queue). In this case,  the channel Cr,,,,diP is modeled as a finite queue of length l z , v , d ; r ,  with the arrival rate X r , y , d i r . served by one server with service rate  Both inrer-arrival and service rimes are independent and  identically distributed, following exponential distributions.  With this model, we can further develop the queuing model of  a router as shown in Fig. 5 . Th e five bubbles in the left hand side  represent the five channels of R z ,v (that is, the router placed at  tile ( x , y ) ) , with N , E , W , S and L representing the directions  of norrh, easr, west, sourh and focal, respectively. On the right  hand side, the upper four bubbles represent the four correspond-  ing input channels in router R,,,'s neighboring routers and the  bottom bubble represents the output channel to R.,,'s  local PE  These five bubbles on the right side give all the queues  that the packets in R z , y can possibly go to during the next time step  and thus directly affect the calculation of the parameters related to  R=,,'.  Now let us consider, for instance, the north input channel at  router R z , v . Th is channel i s represented as C=,.,.N in Fig. 5. As-  suming the network is not overloaded ( tha t is, Xr,y,d;r < ~=,~,,j,,),  then the arrival rate of C z , y , ~ can be calculated using the following  equation:  F igu r e 5 : Qu eu ing mude l of a r o u t e r  In Eq. (3), the routing function R ( j , k , j ' , k', x , y , N ) equa ls 1  if the packet from PE,,* to PE,.,&. uses th e channel C s , y , ~ ;  it  equals 0 otherwise. Note that we assume a deterministic routing  algorithm, thus the function of R ( j , k 3 j ' , k ' , z , y , N ) can be pre-  determined. Also, because the traflic flow i s predetermined, the  N  parameters P & , N . P & , , N , P ~ , ~ . N . P = , ~ , N and P ~ $ , N can be pre-  calculated. (We use LO to represent the local output direction, thus  P : $ , ~ gives the probability of a packet in C 2 , 1 , ~  to be delivered  to PE,,,.)  Now, the only unknown parameter for C r , y , ~  the value of p r , y , ~  i s determined, the probability of C l , y , ~ to be  in ""fufl stare"" can be calculated straightforward using the finite  MIMIIK queuing model with the following equations [13]:  i s p z , y , ~ . Once  P = , y , N = __  X.&N  k V , N  (4)  Th e calculation of & = , y , ~ is not trivial, as it depends not only on  the router's service delay (as shown in Eq. ( I ) ) , but also on prob-  abilities of a packet being routed to each downstream channel and  whether o r not the downstream channels are full. For instance, if  the packet is to be delivered eastward and C ,+I , , ,W i s full, then  the packet has to wait in C2 ,y,~ .  We derive the following models to take in to consideration such  effects. For the sake of simplicity, we assume next that the packet  s ize is fixed and a link can transmit a packet within one clock cycle.  This assumption can be relaxed to arbitrary packet sizes providing  that the buffer is always allocated as an integer number of packet  size and the network uses store-and-forward or virtual cut-through  so that each packet can be treated as an atomic entity.  4To make the figure more readable, not all the connections and  parameters are explicitly shown in Fig. 5 .  358  F igu r e 6 Qu eu ing mode l of a channel  As shown in Fig. 6 , we derive the queue model as observed by  an input channel (in our example C . , v , ~ ) by separating ou t the  remaining p x t into two distinct queues. The bubble labeled with S  models the delay involved in router’s service delay (Eq. ( I ) ) , while  the five bubbles in the right hand side model the delay of the packet  to be accepted by each downstream input channels (Fig. 6).  Now let us consider the behavior of a downstream channel and  use C ,+ l , , ,w as an example. I t can accept a new packet in the  next clock cycle provided that it still has available space in its  FIFO, while no packet can be accepted when its FIFO i s full. Thus,  we can use the reciprocal of the blocking probability to approxi-  mate the service rate that can be provided to the upseeam router.  More specifically, the efecrive se lv ice rate as observed by C r , y , ~  is approximated as 1 Since the total arrival rate to channel  C.+l.,,w  is A = + I , ~ , W , by using LiltLe’s Formula [131. the average  waiting time for entering the FIFO of C z + l , y , ~  can be approxi-  mated as:  b . + l . Y .W  ’  Note that the contention delay over the link between on-chip  routers is also taken into consideration in Eq. (6). On the other  hand, W ~ + I , ~ , W should also be the average waiting time observed  by a packet in the channel C 2 . y , ~  if it is to be delivered eastward to  C.+l,,,w.  In order to facilitate the analysis, we now assume that  C z , y , ~ has an equivalent separate eastward queue without compet-  ing with other input channels. The arrival rate of this queue is then  p f , , , , x ,& ,N .  If this virtual queue should provide the same av-  erage latency packet, then its service rate  must satisfy the  following equation, again based on Little’s Formula:  of C r , l l . ~ should be equal to th e sum of the length of these two  queues:  Combining Eq. (IO) and Eq. (1 1) together, we have:  At this point, we have described the relation between the chan-  ne1 service rate p and the channel blocking probability b (by com-  bining Eqs. (8). (9) and (12)). By performing similar derivations  for all input channels, we can finally build a series of equations  which describe the system’s behavior. When given other parame-  ters (i.e., routing function R ( j , k , j ’ , k ‘ , x , y, dir), aZiy, d $ / . S  and lz,9,d;r), these equations can be solved together by a nonlin-  ear equation solver to determine the important parameters related  to the system performance (such as p z ,y ,d ; r and bz ,v ,d ; , ) . This is  described next.  4.2 The buffer allocation algorithm  We propose an efficient greedy algorithm to solve this problem  based on the aforementioned analytical model. The flow of algo-  rithm is shown in Fig. 8.  w r+1 ,y ,w = .E  1  p = , y , N - p z , y , N  X Z , Y ~ N  ( 7 )  Substituting W ~ + I , ~ , W  in Eq. (6) with the right hand side of  queue ( P 5 , y . ~ ) by:  Eq. (7). we can calculate the equivalent service rate of this virtual  - E  & , y , N = __ - X=+I,Y,W + P = , ~ , N x X W , N  1  E  b = + l , y , w  (8)  T h e average service contributed by all five downstream channels  can now be calculated by the following equation:  N  N  &7,V.N = P z , b N & b N  P z . , N + P : , v . N  + P z , v , N x p = . g , N  - L a  + P z . , N  fpz,, N  L 6  E  E  !%L~%N  k z , y . N  (9)  With this representation of f i Z I y , ~ , the model in Fig. 6 can be  further reduced as shown in Fig. 7.  : . . . . . . . . . ! l .bN .  .I  F igu r e 7: R edu c ed mode l of a ch ann e l  Th e next step to further simplify the model is merging the two  queues as shown i n the dashed box i n Fig. 75 . Thus, the average  queue length of C z , y , ~ can be approximated by:  9 z . v . N =  P = , v . N - A = , y , N  I  (10)  On the other hand, if we treat the two queues in the dashed box  as two independent M iM lI queues, then the average queue length  ‘Think o f the dashed box in Fig. 7 to act as a server and serving the  packet in C s , y , ~ with the rate of P = , ~ , N .  _.__.._..._...._  , I F igu r e 8 T h e bu f f e r a l loca t ion a lgo r i thm flow  Given the architecture parameters (such as the routing algorithm,  delay parameters. erc.), and the application parameters (a.,s and  d:,bY ) , t h e System Analyzer (written in Ct+) automatically gener-  ates the system equations for all the routers using the above mod-  eling technique and writes the equations to a M a t l a b script file.  At the same time, it also generates the initial buffer configuration  which assigns the buffer in all th e used channels (A r , y , , j , r # 0)  to be one packet large. Next, the Equation Solver is used to solve  the given equations and determine br,y.d;r for each input channel.  Currently, in our tool flow, the f s o l v e utility from Matlab is  used as the nonlinear solver.  In the next step, the channel which has the largest bl;,y,d.r is  selected as the bottleneck channel and the size of its buffer ( l z , y , d i l )  is incremented by one packet. Th e above procedure is repeated  chip reaches the buffer limit B (i.e. E a , Cay Cad i , lr , l ) ,d ir =  until the total buffering space used in all the channels across the  Let C to be the number of channels participating in channel  buffer allocation and F ( C ) to be the complexity of the nonlinear  E ) .  .  359    solver used in solving the equations. Then the complexity of the  buffer allocation algorithm is O (B x F ( C ) ) , as it will invoke the  solver f a r O ( B ) iterations. Although simple in nature, the algo-  rithm performs extremely well in allocating buffering resources, as  demonstrated by the experimental results.  5. EXPERIMENTAL RESULTS  5.1 Evaluations under random traffic  In this set of experiments, we applied our algorithm to applica-  tions with random traffic models [ 6 ] [ 121. In addition, we also tested  our algorithm with different routing schemes, as well as different  buffering resource budget values ( B ) .  Table 2 shows the average packet latency comparison between  the NoCs with uniformly allocated FIFO buffers (denoted by UNoC  hereafter) and the systems that benefited from customized buffer  allocation (denoted by CNoC) . A l l th e NoCs reported in Table 2  are composed of 4 x 4 tiles and use XY routing. (In short, for 2 0  mesh networks, the XY routing first routes packets along the X-  axis. Once the packets reach the column where lies the destination  tile, they are then routed along the Y-axis.) Two traffic pattern?  used in this evaluation are uniform and hot spar. Under the uniform  traffic pattern, a PE sends a packet to any other node with equal  probability. Under hot spot traffic pa t tem , one o r more nodes are  chosen as hot spots which receive an ex tra proportion of traffic in  addition to the regular uniform traffic.  Table 2: Packet latency (cycles) comparison (XY routing)  in the third column of Table 2 is the average packet latency of the  UNoC where each input channel has a FIFO s ize of 3 ( B = 144 =  48 x 3). Under all these traffic pattems, UNoC with B = 144  always performs better than CNoC with B = 96. Please note that  UNoC with B = 144 requires 50% more buffering space compared  to CNoC with B = 96 .  To see the impact of the total available buffering space (B), we  applied the algorithm with the limit of total buffering space B =  192. Thus , edch input channel in the corresponding UNoC has a  size o f 4 ; the results are shown in Table 3. Compared to Table 2,  the packet injection rate has been increased in order to make the  optimization really necessary and the results more interesting.  Table 3: Packet latency (cycles) comparison (XY routing)  Again, in this case, CNoC performs much better than UNoC  ( E = 192) under the same buffering constraints. Moreover, the  increase in the buffering space budget offers more flexibility and  finer control in buffer allocation. which enables the generation of  better configurations even for the uniform traffic pattern. In fact, ex-  cept for the uniform traffic, CNoC performs even better than UNoC  ( B = 240). Th is means that by customizing the FIFO size accord-  ing to the traffic pattern, the proposed algorithm i s ab le to generate  systems with much better performance while using 20% less buffer-  ing resources compared to systems with uniformly assigned FIFO  sizes.  To show that our algorithm can be used for NoCs with other de-  terministic routing algorithms as well, we applied i t to NoCs with  Odd-even b e d (OE-fixed) routing. OE-Jiied i s indeed a determin-  istic version of odd-even [ 6 ] routing by remov ing the odd-even's  adaptiveness. For instance, in odd-even routing, if a packet with a  given source and destination can he routed t o both direction d i r l  and d i r z , it will always be routed to d i q in O E - f i e d .  Referring to Table 2, both lhorspor-1 and lhorspor-2 have only  one hot spot. which is located at PEz.2 and PEo.1, respectively.  2horspot and 3horspoi arc the hot spor traffic pattems which have  two and three hot spots, respectively, with the hot spo ts ' location  arbitrarily selected across the chip. For each traffic pattern, we set  the packet injection rate such that the system with uniform FIFO al-  location works close to its critical point (that is, close to the bending  point in Fig. 3).  Th e second column in Table 2 shows the average packet latency  of the UNoC where each input channel has a FIFO s ize of 2 packets  (thus the total buffering resource used i s B = 96, that is, 48 links  times 2). while each number in the last column (CNoC ) shows the  performance of an NoC customized under the corresponding traffic  pattern using the exact same amount o f 96 total buffering space.  As we can see, except for the uniform traffic pattern, significant  performance improvements are observed by allocating the buffer  sizes according to the corresponding application traffic pattem.  For uniform traffic pattern, our allocation algorithm distributes  the buffering space uniformly across a l l the input channels. The  reason for this interesting result is that under uniform traffic, the  XY routing happens to spread the packets almost evenly across the  mesh. Since the total buffering space is very tight (on average each  channel only gets a buffer size of 2 ) . allocating the buffering space  uniformly appears to best match the traffic pattem. Also. reported  6Th e evaluation results using other network sizes and other random  traffic pattems are consistent but not reported here due to space  limitations.  Table 4: Packet latency (cycles) comparison (OE-fired routing)  As we can see, from Table 4, significant performance improve-  ment is again achieved by performing application-specific buffer  size customization. I t is interesting to note that, unlike in XY rout-  ing, in this case CNoC performs much better compared to UNoC  ( B = 96) under uniform traffic. Th e reason i s that OE - jx ed rout-  ing does not spread the traffic evenly across the mesh under uniform  pattem, which makes uniform buffer allocation unsuitable,  Finally, we would like to point ou t that th e proposed algorithm  is also very fast. Take the buffer allocation for 4 x 4 NoC with  XY routing and B = 192 as an example (this corresponds to the  data in the second and fourth columns in Table 3), the run rime for  generaring rhe buffer allocation for each traffic pattern i s less than  100 seconds, when running on a desktop with a Pentium III 1 GHz  processor.  360  lation of the aITival rate for each channel as multiple routing paths  are possible in adaptive routing. Another important extension i s to  support the NoC with wormhole routing. In this case, a new ana-  lytical model needs to be derived, as it is necessary to treat each flit  (instead of a packet) as a separate customer. Moreover, the header  flit and the payload flits can no longer be treated as independent as  they are tightly coupled. Finally, we are working on F'PGA proto-  type and plan to use it for accurate evaluation of the effectiveness  of the buffer allocation algorithm.  "
2004,SILENT - serialized low energy transmission coding for on-chip interconnection networks.,"On-chip source-synchronous serial communication has many advantages over multi-bit parallel communication in the aspects of skew, crosstalk area cost, wiring difficulty, and clock synchronization. However, the serial wire tends to dissipate more energy than parallel bus due to the bit multiplexing. We propose a coding method to reduce the transmission energy of the serial communication by minimizing the number of transitions on the serial wire. We demonstrate the significant energy saving in a multimedia application, 3D graphics. We also apply the coding technique to a CMOS SoC implementation which integrates various processing units with packet switched on-chip networks.","SILENT Serialized Low Energy Transmission Coding  for On-Chip Interconnection Networks  Kangmin Lee, SeJoong Lee, and Ho iJun Yo0  K o r e a Advanced I n s h t u t e of Sclence and T e c h n o l o g y , D a e j e o n , K o r e a  k a n g rm n@ e em f o . k a i s t . a c !U  ,-  U;-  \-  I ( 2 ) s k e w  hold-time  violation  setup-time  violation  (3) c r o s s t a l k :  de lay , noise  E  pu 3 ,  ser ial da ta  ...... 0 ...........  s  _______..............  E (  S  ABSTRACT  On-chip source-synchronous serial communication has many  advantages over multi-bit para l le l communication in the aspects of  skpw, crosstalk. area cost, w i r ing d ~ f l c u lw , and clock  synchronization. However, the serial w i re tends to dissipate more  energy than para l le l bus due to the bit multiplexing. In this paper.  we propose a novel coding method to reduce the transmission  energy ofthe serial communication by minimizing the number of  transitions on the serial w ire . We demonstrate the significant  energy saving in a muliimedia application, 3 0 graphics. We also  apply the coding technique to a CMOSSoC implementation which  integrates various processing units w i th packet switched on-chip  networks.  1. INTRODUCTION  A multi-bit bus with a global common c lock has been widely used  as a communication architecture for the most of VLSl designs.  However , in a deep-submicron and h igh performance SoC, long  and multi-bit bus lines have several problems such as skew ,  crosstalk, wiring difficulty, and large area . (Figure I ) .  Sk ew or j i t te r on multi-bit bus lines makes it difficult to increase  the frequency o f a global c lock because a number of da ta on the  bus must be synchronized with the common clock. Moreover, the  crosstalk between adjacent bus l ines causes da ta dependant signal  de lay and noise, thus finally makes the communication channe l  unreliable. The area cos t of the wide-bit bus in multimedia SoC is  ser ious . Therefore the multi-bit bus communication with a global  common clock will reach its limit and make further performance  enhancemen t expensive.  Source-synchronous serial communication  is one of the key  technologies to overcome such problems. Serial communication  occup ies  less area due  to  less communication  lines  Furthermore, the cross ta lk problem can he mitigated by wide  spac ing of  serial  lines. T h e  source-synchronous  serial  commun ica t ion uses a sideband s trobe signal a long the serial data  l ine a s shown in Figure 2 . The s trobe signal is a kind of clock  s igna l but it is activated only when the ser ia l da ta line is valid. It  has an identical load and wire delay w i th the da ta line, so that the  sk ew between clock and da ta is m in im ized . Th is technique is used  in a high-performance memory U 0 [2], and a lso on-chip inter-  connec t ion networks recently [ I , 3 , 81.  As the die s izes and the number o f subsys tems on a chip increase,  the power consumed by  the interconnection structures takes  s ign if ican t portion of the overall power-budget. There were many  researches about low-power bus cod ing but they are mostly for  parallel bus [5-61. On the other hand, previous works on on-ch ip  ser ia l commun ica t ions have not considered the power efficiency [ I ,  31. In this paper, a low-energy transmission coding method is  [I] .  0-7803-8702-3/04/$20.00 02004 IEEE.  448  D 7 - n  (a) data words from sender  4 (b) encoded data wards  CODING  D, hhhhh  WO w1 wz w3 w4  7 0 0 0 0 0  D6 T-4  ~5 70 o o o o r  D4 7vTT7-n  D3 i o o o o a i  DZ 7 0 0 0 J3-T  D1  w7T-w""  7 transitions  (a) Bbit p a r a l l e l bus  a  SERIALIZING  SERIALIZING  f c ) s e r i a l data without rodioe  . ,  (d) serial d i t s with coding  ('  '-+<-:..,  W&4  3 I transitions  (b) single b i t s e r i a l b u s  Figure 3. An example of activity factors with the same data panem on  (a) parallel wires and (h ) a serial wire  during signal transitions, VDD is a supply voltage,  is a  voltage swing across the wire, and N is a number o f wires o f the  channel.  In serial communications, the wire frequency is multiplied by  serialization ratio to support the same bandwidth as in parallel  communication but the N is divided by the serialization ratio. Thus.  the product o f f and N is the same in serial and parallel  communication channels. However, the switching activity factor  o f serial wire, a, is different from that of parallel wires and the  difference depends on the data pattems. Figure 3 shows an  example for the comparison o f activity factors in parallel and  serial communications. In this examp le , Bbit parallel bus has 7  transitions. However, when the same data stream is serialized onto  a single wire, the number o f signal transitions on the wire increase  u p to 31 as shown in Figure 3@). If there is correlation between  adjacent data words, some bits o f the parallel bus stay calm  without any transition. However, such correlation is not helpful in  the serial communication because da ta bits arc multiplexed onto  the single wire. Therefore, the activity factor o f the serial wire gets  higher  than  that o f parallel bu s statistically.  In common  multimedia applications, the most significant bits tend to have  high spatial and temporol correlations because of the sign  extension o r the locality characteristics of multimedia streams [4].  In these applications, the serial communication dissipates more  energy than the parallel communication. In the next section, we  propose a new coding method to reduce the activity factor on the  serial wire.  3. LOW ENERGY TRANSMISSION CODING  Many parallel bus coding methods have been proposed to reduce  the switching power on the address or data bus between a  processor and memories [5-61. However, such conventional  parallel bus coding methods cannot b e employed in the serial bus.  Therefore, we propose a serialized low-energy  transmission  (SILENT) coding technique to minimize the transmission energy  on the serial wire. We first introduce the terminology and notation  that will be used throughout this paper.  t+l  t tz  tt3  t+4  0 1 0 1 0 0 1 0 7  0 1 0 1 0 0 1 1 5  0 1 0 1 0 1 0 0 7  0 1 0 1 0 1 0 1 7  t 6 T l o  "" .__ 1 --- o n  ..... - ..... 0 1  t+l n n o o o o ~ ~  t+2 o o o o o n o i  t+3 o o o o n i i i  t+4 n o o o o o o 1  Figure 4. (a) original data words with 7 transitions, (h ) encoded data  words, (c) conventional serial data panem with 31 transitions, (d)  encoded serial data paltern with 13 transitions  (1)  b""'[n-l:O]: n-bit data word from a sender at time f  B""[n-l:O]: n-bit encoded data word at time I  The encoder works as follows:  B(LJ[i] = b(t) [ 'I , @ b""')[i]  f o r i = O - n - 1  The encoded words, B(lJ, are equivalent to the displacement o r the  difference between successive da ta words.  By serializing the encoded data words, th e frequency o f the  appearance of zeros on the wire  increases because of the  correlation between the successive data words, bR! Figure 4 shows  an example for the advantage of this coding method. All bits from  B[7] to B[3] become zeros after these da ta words arc encoded  because those bits do not change with time. Serializing these  encoded words reduces the number of transitions of the serial wire  as shown in Figure 4(d) and the wire looks silent. In th is example,  a conventional serial wire without the SILENT coding, shown in  Figure 4(c), has three times a s many transitions from t f l to t+4.  By reducing the number of transitions on the serial wire, the  transmission energy can be saved proportionally.  After deserialization at the receiver end, the decoder works as  f o r i = 0 - n-I  follows:  bh) [i] = B(') [i] @ b"".""  [i]  (2)  The original data word from a sender unit, b(IJ, can be recovered  by XORing the encoded word, B(') , and a previously decoded  word, b('-').  4. PERFORMANCE ANALYSIS  Figure 5 shows the circuit implementation o f SILENT codec and  the bold  line indicates a critical path  in the circuits. The  implementation o f the SILENT encoder and decoder is so  lightweight that the area, power, and latency overhead due to the  codec become negligible. The power consumption for 32bit data  449  ( a ) en cod e r  I  (b ) d e cod e r  F igure 5. Circuit implementation of (a) encoder, and (b) decoder  word encoding and decoding is about 390pW and 385pW,  12 r  I  3M - I S M  .- - -  '5 2M  I  $ 1.5M  s  yi  I  1M  2 0.5M  0 ' "" "" "" ' "" "" "" '  6  8  ' "" "" "" "" "" "" ' "" "" ""  IO I 2 14 16 I8 20 22 24 26 28 30 32  '  0  2  4  U aftransitions b/w successive data words  F igure 6 . Average pawer consumption on serial communications with  SILENT coding and without it  respectively, at IOOMHZ operating frequency in the worst case  da ta pattem.  In order to analyze the energy efficiency of this coding scheme,  we evaluate the energy consumption with various data p an em s in  th e communication channel such a s encoders, transmitters, 8mm  serial wires with repeaters, receivers, and decoders. Th e energy  consumption in the communications depends on the da ta panems  to be sent. So, we evaluate the power consumption with all  possible vx i a t ion s from a random data word. Figure 6 shows the  comparison o f the average power consumption of th e serial  communication with and without SILENT coding at IOOMHz  operating frequency. The x-axis stands for the number of da ta  displacement between successive 32bit da ta words, b(t). The 0 on  the x-axis means that b(t) is the same a s b(t-I), and the 16 means  that arbitrary 16bits among 32bits, b(t), have changed from their  previous values, b( t-I) . In result, when the number o f transitions  between successive data is less than I I , the encoded da ta words  contain many zeros, and thus the encoded serial wire h a s fewer  transitions. Meanwhile, when the number o f transitions is more  than 22, the encoded da ta words contain many I s , thus, the  encoded serial wire also has fewer transitions. Therefore the  region under 11 or above 22 in the x-axis is energy saving region  du e t o the SILENT coding. However, there is some power  overhead for random data transitions at most 14% in a region from  11 to 22. As shown here, the energy saving range i s two times  wider than the overhead range and the power saving is much  larger than the overhead. Therefore, the SILENT cod ing has lots  of opportunity to save energy in the most of da ta panems . In the  next section w e analyze the performance o f t h e coding method in a  real application.  0  # of transitions blw succesive data words  ( a ) i n s t r u c t i o n memory access  -  4S0K  4OOK  1 350K  - 250K  i 300K  Y 2 100K  ISOK  I  2 LOOK  5 0K  0  0  2  4  6  8 10 I 2 I 4 16 I 8 20 22 24 26 28 30 32  # oftransitions b/w succesive data words  (b) d a t a memory access  Figure 7. Distribution o f the displacement between successive (a)  instruction and @) data memory access  5. ON-CHIP NETWORK FOR A MULTIMEDIA  APPLICATION  To evaluate the performance of th e proposed SILENT coding in a  real application, we trace the transactions of the on-chip traffic  between a RISC processor and system memories while a 3D  Graphics application is running [ 7 ] . Full 3D Graphics pipelines o f  geometry and rendering operations are executed for 3D scenes  with 5878 triangles. F igure 7 show s t h e distribution of the  displacement of the memory address and data for the successive  memory accesses. The instruction memory address i s so sequential  that the 99.5% of 6 million transactions are within the energy  saving region. Although the instruction codes are qu i te random,  the 60% is within the energy saving region. In the case of the da ta  memory access, the 79% and 70% of 1.5 million data memory  address and da ta transactions are within the energy saving region,  respectively.  With this memory access pattem, we evaluated the energy  consumption for the serial communications in the environment. I n  result, Figure 8 shows the normalized average energy consumption  on the serial wire with and without SILENT coding. The energy  consumption with SILENT coding includes the energy dissipation  in the codec circuits. The SILENT coding shows the best  performance for instruction address, about 77% energy saving.  Even i n the random traffic, in th e case of the instruction codes,  13% energy saving is achieved. It also saves 40 - 50%  transmission energy for multimedia data traffic. I n conclusion, the  450  I o: wlo codine 0 : w/ SILENT codina  Code  Address  Address  Data  Figure 8. Normalized average energy consumption in each memory  access type  SILENT coding reduces the energy consumption o f the serial  communication in all kinds o f on-chip data trafiic in the 3D  Graph ics application.  W e applied the SILENT coding to the multimedia SoC design  where the communication architecture is packet switched on-chip  interconnection network [8]. The on-chip network (OCN)  serializes a fixed size packet of 80 bits onto 8bit serial wires.  F igure 9 shows the overall architecture o f the SOC . W e integrated  tw o clusters as a prototype; a main cluster and a peripheral cluster.  T h e main cluster contains a RISC processor, an application  processor, FPGA, two 64kb memory arrays, and an off-chip  ga teway for off-chip connection. We assumed that the peripheral  cluster is far from the main cluster to emulate a large SoC, thus,  two clusters are connected with each other via S m m small-swing  differential serial wires. PLL generates IOOMHz clock for main  cluster and I.6GHz network clock for the on-chip networks. The  on-chip network supports 3.2GByteIs bandwidth  for each  processing unit.  T h e serializer, deserializer, and the SILENT codec circuits are  integrated in each network interface ( N I ) . The area o f the on-chip  network is reduced significantly due to the serialization technique  In this implementation, the enable signal of the SILENT  encoder is controlled by s o h a r e , therefore the coding scheme can  b e tumed on and off in runtime for the energy optimization  accord ing to each application. n e n , the receiver unit should know  th e currently received packet i s encoded o r not. Therefore, the  information is transferred to the receiver by embedding it into the  header unit of each packet. The long error propagation due to the  differential encoding can be controlled by disabling the coding  periodically by software.  D i e micrograph and a performance summary are shown in Figure  I O . By using the SILENT coding method, about 13% energy  sav ing was obtained on the overall on-chip network architecture.  [ I ] .  6. CONCLUSION  In this paper, we have proposed a low-energy transmission coding  method applicable to a multimedia SoC incorporating on-chip  serial communications. This coding technique reduces the number  of transitions on serial wires using the data correlation between  success ive data words. We show that the coding method saves  significant amount of the communication energy for 3D graphics  applications, and reduces maximum 77% o f energy for instruction  memory access, and 4040% of energy for data memory access.  W e implemented a prototype SoC with various processing units  45 J  Off-Chip Network + - *  -  IP Ciocb  +  Main,Clurter  Figure 9. Overall architecture of a prototype S a c  Peripheral C l u s t e r  Figure I O . Implementation resulu  and  packet  switched  serialized  on-chip  networks  communication architecture by using 0.18pm CMOS process. By  applying the coding method, abou t 13% power reduction has been  obtained on the overall on-chip networks. For more energy  optimization in each application, the coding can be tumed on and  off by soflware.  as  "
2005,NoCEE - energy macro-model extraction methodology for network on chip routers.,"In this paper we present NoCEE, a fast and accurate method for extracting energy models for packet-switched network on chip (NoC) routers. Linear regression is used to model the relationship between events occurring in the NoC and energy consumption. The resulting models are cycle accurate and can be applied to different technology libraries. We verify the individual router estimation models with many different synthetically generated traffic patterns and data inputs. Characterization of a small library takes about two hours. The mean absolute energy estimation error of the resultant models is 5% (10% max) against a complete gate level simulation. We also apply this method to a number of complete NoCs with inputs extracted from synthetic application traces and compare our estimated results to the gate level power simulations (mean absolute error is 5%). Our estimation methodology has been integrated with commercial logic synthesis flow and power estimation tools (synopsys design compiler and primepower), allowing application across different designs. The extracted models show the different trends across various parameterizations of network on chip routers and have been integrated into an architecture exploration framework.","NoCEE : Energy Macro-Model Extraction Methodology for Network on Chip Routers Jeremy Chan† , Sri Parameswaran†‡ †School of Computer Science and Engineering, The University of New South Wales, Australia ‡National ICT Australia (NICTA), Australia∗ {jeremyc, sridevan}@cse.unsw.edu.au ABSTRACT In this paper we present NoCEE, a fast and accurate method for extracting energy models for packet-switched Network on Chip (NoC) routers. Linear regression is used to model the relationship between events occurring in the NoC and energy consumption. The resulting models are cycle accurate and can be applied to different technology libraries. We verify the individual router estimation models with many different synthetically generated trafﬁc patterns and data inputs. Characterization of a small library takes about two hours. The mean absolute energy estimation error of the resultant models is 5% (10% max) against a complete gate level simulation. We also apply this method to a number of complete NoCs with inputs extracted from synthetic application traces and compare our estimated results to the gate level power simulations (mean absolute error is 5%). Our estimation methodology has been integrated with commercial logic synthesis ﬂow and power estimation tools (Synopsys Design Compiler and PrimePower), allowing application across different designs. The extracted models show the different trends across various parameterizations of Network on Chip routers and have been integrated into an architecture exploration framework. 1. INTRODUCTION Networks on chip has arisen as a solution to the poor wire scaling and increasing complexity of large System on Chip (SoC) design. NoCs aim to replace long shared bus wires with scalable switched networks with higher performance, predictable wiring and better interconnect properties. These networks can be made latency insensitive, simplifying the design of complex systems since communication and computation problems can be treated separately. Although NoCs provide many beneﬁts, they add additional logic complexity to the communication architecture. Power consumption in the communication architecture is a major bottleneck in current design [17] and hence, energy-aware optimizations for NoCs is of primary importance. Several optimization methods have been proposed to reduce energy consumption through application speciﬁc customizations. These include: customized router buffer sizing[15]; custom topology generation [25]; adaptive routing [16]; and mapping processing elements to tiles [14, 21]. Motivation for this work Various NoC architectures have been proposed, each with a differing implementation and hence, varying energy consumption characteristics. In order to explore the design space for energy minimization, a method for estimating energy is needed. Typically, a design’s energy consumption is evaluated using a register transfer level (RTL) or gate level power simulator. Power simulations are essential for ﬁnding implementation bottlenecks but their lengthy run-times make them unsuitable for early design space exploration (days for a typical trace). For this reason, techniques are needed to quickly extract a fast and accurate estimation model. Estimation models also provide useful insights, especially towards architecture parameterization trends, and identiﬁcation of potential energy reduction areas. While energy estimation for a whole system is of paramount importance, the energy of speciﬁc components allows the system to be laid out to reduce hot spots in the ﬁnal design, thus improving reliability of ∗National ICT Australia is funded through the Australian Government’s Backing Australia’s Ability initiative, in part through the Australian Research Council. 0-7803-9254-X/05/$20.00 ©2005 IEEE. 254 the whole design. Cycle accurate power estimation allows peaks of the power spectrum to be more accurately determined, so that the design can be re-engineered to extend battery life, as battery life is heavily inﬂuenced by power peaks. Therefore, this work is motivated by not only having to estimate energy of a router, but being able to rapidly estimate the consumption of each of the major components, and also being able to estimate energy in a cycle accurate manner. Finally, in an era where technologies are rapidly changing, it is important to be able to characterize a router built upon different technologies rapidly. In this paper we present NoCEE1 , a methodology for obtaining a fast and accurate energy macro-model for a synthesizable packet switched NoC router. The NoC router is decomposed into constituent router components and a model is built for each component. Linear regression is used to obtain a good ﬁt between the component’s events and observed cycle energy obtained from a gate-level simulator. The combination of individual component models is used to predict the cycle energy consumption of a complete router. A single trafﬁc pattern consisting of various trafﬁc loads and random distributions is used to stimulate the NoC router during characterization. We apply our methodology to several 3, 4 and 5 port wormhole mesh routers with uniform FIFO depths at various levels, and validate that good correlation exists between the model and gate level power simulations. The models of several routers are used together to predict the energy consumption of a complete NoC. The predicted energy consumption is compared against several complete NoC gate level power simulations to evaluate its accuracy. The rest of the paper is organized as follows: Section 2 surveys the related work and states our contribution. Section 3 gives some background and theory. The NoC model is described in Section 4 and Section 5 presents the experimental results. Section 6 concludes the paper. 2. RELATED WORK Early work [22] in power estimation attributed a ﬁxed energy to a structural block. These pattern independent models were inaccurate as they did not account for input statistics. Thus, models were formulated to capture the changes in power dissipation when inputs are stimulated [19]. Many pattern dependent models use linear regression to obtain a good ﬁt between the model parameters and energy consumption. Regression-based macro-modeling at the RTL has been extensively applied to various combinational and sequential circuits [2, 13, 20], as well as application speciﬁc instruction set processors [7, 12]. However, this technique has yet to be applied to packet switched routers. For the ﬁrst time, we apply linear regression-based macro-modeling for energy model extraction of an NoC packet switched router. NoC power estimation has been addressed by several recent research works. In [29], Ye et. al. proposed an energy estimation ﬂow to derive bit energy models that are used to evaluate different switch fabrics (e.g fully-connected, Banyan, Batcher-Banyan) in network routers. Their methodology derives the energy cost for transmitting a bit in the network router from ingress to egress ports but ignores clock power and leakage power. In [26], Wang et. al. created a network simulator to estimate dynamic power of router components from CACTI scaling equations[23]. This simulator was augmented in [6] to support leakage power. The same authors have used this simulator for architectural exploration to explore energy savings through segmented crossbars [28], and to trade off of router complexity and energy [27]. Banerjee et. 1NoC Energy Estimation: pronounced gnocchi Figure 1: NoC router model al. in [1] addressed leakage power modeling in mesh routers and derived a power-state machine for a wormhole router based on SPICE net-lists. The power-state machine allowed power to be estimated on a cycle accurate basis. However, both [26] and [1] contain models that are tightly coupled with circuit implementations. As such, these models cannot be migrated to different technology libraries without a large amount of re-characterization. The authors in [4] automate the extraction of a power model for the STBus, a high performance communication architecture supporting shared buses as well as crossbars. They use regression based techniques to obtain a relationship between average power and the architectural parameterizations of the STBus. A packet switched router contains additional components that are not present in the STBus. Our characterization differs from the models in [1, 26, 29] by being more adaptable to changing technologies and differing router types. We use a semi-automatic system containing linear regression to characterize each router, while the models in [1, 26, 29] have to be manually extracted. While the work in [4] automates the extraction of a power model for an STBus using linear regression, their work does not address packet switched networks, nor cycle accurate models. The novel contributions of our work are: 1. the ability to derive accurate and system-level cycle-accurate estimation models for power consumption of synthesizable NoC routers; 2. a methodology to automate the extraction of the power estimation for an NoC router library based on regression analysis between control signals and cycle-based power; and 3. that we demonstrate the use of this methodology to predict NoC power at the router level, NoC level and within a fast estimation framework. 3. BACKGROUND AND THEORY 3.1 The NoC Architecture and NoC Router In NoCs, longer interconnect wires are broken down into shorter channels with routers or relay stations forming a micro-pipeline between processing elements. Each router is buffered to allow it to be latency insensitive and the communication between the routers uses a predeﬁned protocol and ﬂow control. Although many NoC router variations exist, the major component subsystems remain the same. These are: (i) link controllers; (ii) crossbars switches; (iii) routing and (iv) arbitration units (see Figure 1). As NoC routers have a well-deﬁned structure, the subsystems can be modularized with similar interfaces for different implementations. For example, two routing algorithms, X-Y and west-ﬁrst routing can be designed to have the same inputs and outputs (address input and destination port). Standardizing the interfaces between subsystems allows the variations to be created and reused in different architectural parameterizations. 3.2 CMOS Power Consumption and Estimation There are two broad categories of power consumption: (i) dynamic power and (ii) static power. Dynamic power is dissipated when the circuit is active caused by the charging and discharging of the internal and load capacitance of a gate. Static power is dissipated when a circuit is inactive, consisting mostly of source to drain sub-threshold leakage current where the gate does not turn off completely. Commercial gate-level power simulators use look up tables based on input net transition delay and output net capacitance to determine 255 Figure 2: Energy model extraction methodology energy dissipation. Dynamic switching power is determined by summing the switching energy with the number of transitions. Obtaining the number of transitions requires a full gate level simulation, or designer knowledge to estimate the switching probabilities of nets in the design. Leakage power in these tools is estimated by determining via table lookup given the inputs on the gates. 4. METHODOLOGY Much of this work is inspired by existing work on regression-based macro-modeling used to characterize smaller circuits at the RTL. We refer the interested reader to [3] for an overview of macro-modeling techniques. In this section, we ﬁrst describe the procedure to construct an NoC energy macro-model. Next, we describe how model variables are chosen and construct macro-models for each of the major NoC subsystems in a wormhole NoC router. 4.1 Overview There are two major parts in our energy estimation ﬂow: (i) characterization and (ii) energy estimation (see Figure 2). The characterization step builds a macro-model given a set of technology libraries, NoC parameters and trafﬁc patterns (Steps 1 - 7). The technology libraries and NoC parameters are used to create the synthesizable NoC while the trafﬁc patterns are used to simulate the router under various conditions. The second part, energy estimation, predicts the cycle energy of an NoC router from the macro-models and the event timings from a high level simulation (Steps 8 and 9). As NoCs have a well-deﬁned structure, macro-models can be built for each parametrization of the major subsystems and reused. We characterize each of the subsystems separately by extracting their models while they are operating within a complete NoC router. This allows multiple subsystems to be characterized together in a single simulation while capturing the frequently occurring behaviors of individual subsystems. A range of possible router conﬁgurations are created in order to build models for various subsystem parameterizations (Step 1). We sweep through a range of possible parameters and create a number of NoC router implementations using the NoC generator[5]. Macro-model Inputs and Trafﬁc Generation To obtain a good model, a single trafﬁc pattern must be generated that exercises the circuit under a wide range of possible conditions (Step 2). For an NoC router, it is possible to control these trafﬁc patterns by varying the packet injection and acceptance rates, packet destination ports and switching activity on the data bus (changing the hamming distance between successive ﬂits). Varying the injection rates and acceptance rates will synthetically exercise the router under different levels of contention. Meanwhile, adjusting the switching activity can be used to reveal the NoC router circuit’s dependency on the input data. A calibration trace is created that includes a mixture of trafﬁc patterns. The power and signal values for every cycle are proﬁled via two separate simulations. The NoC conﬁguration is synthesized and the cycle power is obtained through the gate-level power estimation ﬂow (Steps 3 and 4). An RTL simulation is performed using the same calibration simulation to capture the signal waveforms on important control and data signals (Step 5). The signal waveforms are compared against the power simulation to see which signals may affect power dissipation. Events relating to control and data signal values are chosen for inclusion in the macro-model based on their importance to the energy behavior (Step 6). Using Regression Analysis to Obtain the Macro-model The energy consumption and signal values at each cycle are used as observations in the regression analysis. Regression analysis is performed between the cycle energy and the macro-model signal observation (Step 7). Statistical parameters such as the R2 and p-values (probability values) from the regression output are used as a metric of the goodness of ﬁt, and importance of variables [11]. The model parameters are modiﬁed and, if necessary Steps 5 to 7 are repeated until a good ﬁt is found. Steps 3 to 7 are repeated for each of the conﬁgurations until the entire library is characterized. Energy Estimation Using the Macro-model Once a macro-model is built, it can be used to predict cycle power. Network statistics such as number of packets sent and bit switches can be used to quickly evaluate the total energy by substitution into the model. Multi-dimensional interpolation is used to obtain an estimate of the model coefﬁcients, if the lie between two characterized points. A cycle accurate system-level network simulator is required to reproduce cycle-power at the system level. If a network simulator is able to produce a trace of the events (Step 8), a power waveform can be produced by substituting the timing of these events into the macro-model (Step 9). (a) Link Controller (b) Crossbar Figure 3: Router Components energy consumption. The router designers are often aware of these signals as they are often similar to the signals used for debugging the circuit. Hence, these signals can be selected without much effort. Evaluation of Macro-model Energy Consumption The cycle energy consumption of a component Ecom ponent can be expressed as: Ecom ponent (t ) = β0 + βiXi (t ) + Pl eakage · tcl k n∑ i=1 where βi is the ﬁtting energy coefﬁcients for model parameter Xi , and β0 is cycle energy not related to any of the predictor variables, and Pl eakage is the average component leakage power, and tcl k is the cycle period. Thus, given clock frequency fcl k , cycle power can be calculated as follows: Pcom ponent (t ) = (β0 + βiXi (t )) · fcl k + Pl eakage n∑ i=1 Leakage power and Clock power 4.2 Selection of Macro-model Variables A macro-model is built by choosing variables that have a strong relationship to energy consumption. In this context, variables Xi are events that occur in the NoC router. Two types of events are considered for inclusion: control events, and data events. Control events occur when a control signal triggers energy consumption; these are: one signal transitions (0 to 1, 1 to 0), and two, the value of a particular signal being either 0 or 1 in a particular cycle. In some cases, a control event may affect energy in a future cycle (for example pipelined operations). Control events can be time-shifted such that a vector of events match the energy consumption. In NoC routers, energy is dominated by several major components such as FIFO buffers and multiplexors. The control signals of these major components have a strong inﬂuence on the total energy consumption. A larger amount of activity on the data inputs also contributes to higher energy consumption. Hence, the hamming distance of the data inputs is also considered. Selecting inputs from these two domains results in the following expression for the energy of a component. · Xi Ecom ponent = βresid ual + βeventi n∑ i=1 where n is the number of events, βresid ual is the energy that is independent from the model variables, and βeventi is the regression coefﬁcient for the data or control event Xi . Xi takes the value 1 for control events when a signal is present or 0, when it is not present. In cases where Xi is a data variable such as hamming distance, it is represented using a integer. In the characterization of our router, we only use hamming distance of the combination of all the input ports together. In routers design or situations where individual router ports consume more energy, more data variables may be needed. Model variables should be selected to be independent whenever possible. The decision to include or exclude a model variable can be aided by the use of statistical parameters such as the p-values. The process of model selection can be automated by using a ﬁxed criterion using a threshold value for removal or selection of parameters with model variables iteratively removed. Clever algorithms such as branch and bound can be used to avoid ﬁtting all combinations of variables [11]. In NoC routers, there are very few signals that have a large effect on 256 The two major sources of independent power are transistor leakage power and clock-related power. For the purposes of system-level modeling, we assume that the variance of average leakage power inputs is small. We observed this phenomena experimentally, as leakage power for individual components are nearly invariant in the power simulations for the same conﬁguration. We use average leakage power ﬁgures available in the power simulation report as the architecture’s ﬁxed leakage power. Clock-related power includes dissipation in the clock network i.e. buffers, register clock gates and clock inputs to ﬂip-ﬂops. All these exhibit a static power dissipation because a similar number of transitions occur on every clock cycle. In the following models, the uncorrelated energy composed of the clock and leakage energies will be labeled as βx0 where x is the component name. 4.3 NoC Router Model We develop energy macro-models for a complete router using the procedure described in the Section 4.1. For the sake of brevity, we only consider the model for an input-queued router; the output link controller is considered as pass-through wires that consume no energy. Although signiﬁcant, energy consumed between the routers is not modeled as layout information was not available. The capacitance of wires can be found using logic synthesis tools once the length of wires is known and applied to the macro-model. For each of the major router components a macro-model is derived; each can be summed to obtain the total router energy consumption as follows: Erout er = Eil c + Exbar + Earb + Erout e + Eot her where Eil c , Exbar , Earb , Erout e and Eot her is the energy values derived from the component macro-models for the input link controller, crossbar, arbiter and routing unit and the miscellaneous glue logic respectively. In the following sections, we apply this method to the NoCGEN router libraries[5] but this method should be applicable to other NoC libraries such as Xpipes[8] and Proteo[24]. Link controller We consider the energy macro-model for a single input-queued link controller (ILC). The signiﬁcant contributors to the power consumption of the link controller are FIFO memory elements (implemented as RAM or register ﬁles) and their control logic (Figure 3(a)). The empty and full signals are determined based on an internal counter. In the target routers, there are two FIFOs in each link controller port ( f i f o0 and f i f o1) due to separate data and address buses. Hence, the power consumption of the link controller can be modeled as: Eil c = E f i f o0 + E f i f o1 + Ecount + Eil c ot her where E f i f o0 and E f i f o1 are the FIFO energy consumptions, Ecount is the counter energy consumption and Eil c ot her is energy of the less signiﬁcant components in the link controller. When a ﬂow control digit (ﬂit) arrives at the link controller, it is written to the storage element. Similarly, when a ﬂit is acknowledged by the next router, the next read address is incremented and the outputs are updated. Energy can be attributed to the reading and writing of the memory elements, hence the read en and writ e en control signals are good candidates for inclusion. When contention occurs, the counters begin incrementing, resulting in a small increase in energy consumption. Hence, the link controller model can be formulated as: Eil c =βil c0 + βil c1Edwrit e + βil c2Ed read + βil c3Eawrit e+ βil c4Earead + βil c5Ecount en where Ed read and Edwrit e are the read and write control signals for the data FIFO ( f i f o0); Earead and Eawrit e are the read and write control signals for the address FIFO ( f i f o1); and Ecount en is the counter enable control signal. Crossbar Switch A two-port crossbar is depicted in Figure 3(b). In this crossbar implementation, an enable control input sel en disables the output when a port is unused. Through experimentation, it was found that the two major contributing factors to energy consumption are data bus switching and the initial selection of the crossbar port when the ﬁrst ﬂit arrives. The initial selection of the crossbar port is mirrored by the 0 → 1 transition of the sel en signal. The crossbar traversal energy is: Exbar = βxbar0 + βxbar1Ed ist + βxbar2Esel0→1 where Ed ist is the input hamming distance of the inputs of the crossbar and Esel0→1 is the selection energy when a packet ﬁrst enters the crossbar. Arbitration When an arbitration decision is made, the selected port is stored in a register that is used to control the crossbar port selectors. In a simple priority arbiter, the energy can be decomposed into storage and computation. We selected a signal that occurred in the same cycle as computation and included it in the macro-model. The arbitration energy can be estimated by: Earb = βarb0 + βarb1Esel + βarb2Eselt−1 where Esel energy consumption during the cycle that arbitration occurs and Eselt−1 is the energy related to control input from the previous cycle. Eselt−1 is an example of the same signal time-shifted to reﬂect energy dissipated due to the signal’s value in a previous cycle. Route Unit The route units for both the X-Y routing algorithm and street sign routing algorithm are purely combinational and are determined based on the address presented by the input link controller. Based on this observation, some energy will be dissipated initially when the head ﬂit of a packet Ehead is passed through the routing unit and a smaller amount in following ﬂits E f l it . The model is as follows: Erout e = βrout e0 + βrout e1Ehead + βrout e2E f l it Other Several other miscellaneous glue logic circuits consume a small amount of total energy in the circuit. As the dynamic energy changes are small, we do not characterize these individual components. Instead, the average energy Eaverage is included as part of the additional power uncorrelated power that is added to the model. 257 5. EXPERIMENTAL RESULTS All experiments were conducted on a dual Opteron 224 with 2 GB of RAM. The routers were generated from the NoCGEN[5] library and generation tool (Step 1). Two types of routers were used in experiments: custom routers (capable of a variable number of ports) and mesh routers. All routers were conﬁgured with 32-bit data buses and 16-bit address buses. FIFO buffers were implemented using two-port clock-gated register ﬁles with counter logic determining FIFO full and empty signals. The routers were characterized at an operating frequency of 125 MHz, 250 MHz and 500 MHz. At these three frequencies, the model coefﬁcients were similar with clock-cycle leakage energy scaled. The results shown here are for 250 MHz. A C++ program was written to generate a trace ﬁles for the VHDL simulation given a random distribution (Poisson, Gaussian etc) for packet arrival times and packet length (Figure 2, Step 2). This trace ﬁle contains send packet, idle and receive packet commands that are use to control the trafﬁc in and out of the router ports. Each send packet is annotated with the source and destination addresses to enable control of the destination and the data bus switching activity. All router designs were synthesized using Synopsys Design Compiler and a 90 nm TSMC standard cell library (tcbn90gtc) with automatic clock gating enabled. Modelsim was used for all the VHDL simulations. As layout information is unavailable until after place and route, we assign an estimated load of 50 fF to the router outputs. Synopsys PrimePower was used to obtain the power estimates and the power waveform. A program was written in C++ to combine the outputs of PrimePower and Modelsim into a time-series comma separated ﬁle. The statistical package GNU R was used to perform regression analysis. Perl scripts were used to link all the tools together. 5.1 Experiments Conducted Three separate experiments were performed to ensure the validity of our models: at the single router level; within a complete NoC (multiple routers connected together in a mesh arrangement); and in a fast power estimation environment. First, we characterize the NoC library for two library parameters: number of ports and FIFO depth using the method described in Section 4. We evaluated the model prediction error against several gate-level power simulations with a separate set of randomly generated trafﬁc patterns (72 traces in total) with varying injected loads. Second, we investigate port scaling energy characteristics of different components in the router. Next we create and synthesize various complete NoCs and stimulate these using applications traces. The errors between the model and gate simulation experienced when running these applications on complete NoCs are also provided. 5.2 Validation (a) (c) (b) (d) Figure 4: 3 port, 4 port and 5 port ﬁtting errors, cycle errors We characterized 3, 4 and 5 port mesh routers with uniform FIFO depths of 4, 8, 16 and 32. The resultant model coefﬁcients (labeled Comp. Variables Description Eawrit e Earead Edwrit e Ed read Ecount en const ant const ant const ant Eot her const ant Ed ist Esel0→1 Ed ist Esel0→1 Esel Eselt−1 Erout e const ant ILC XBAR0 XBAR1 ARB Route Other adr ﬁfo write adr ﬁfo read data ﬁfo write data ﬁfo read counter en residual hamming dist head ﬂit residual hamming dist head ﬂit residual arb arb delayed residual route residual average misc. aPorts = 3, FIFO depth = 4 3,4a 566 168 1237 361 218 400 31 714 23 117 147 34 147 115 47 1 1 147 3,8 849 218 1682 691 319 533 49 534 73 99 153 63 153 113 58 5 1 153 3,16 1382 188 1799 652 494 671 35 874 42 101 55 59 55 105 55 15 1 55 3,32 2362 168 1931 785 839 1195 37 934 40 92 164 68 164 115 57 14 1 164 Energy Coeffcient (fJ) 4,4 4,8 4,16 561 842 1379 113 124 135 1218 1694 1826 355 669 648 224 314 463 400 534 673 31 50 35 862 639 994 38 106 65 187 146 170 216 250 56 104 190 177 216 250 56 167 196 182 55 68 62 40 96 119 7 6 7 216 250 56 4,32 2371 116 1965 799 757 1200 37 1051 62 139 255 205 255 201 67 124 7 255 5,4 602 120 1273 399 209 404 32 732 54 174 345 99 345 199 58 82 13 345 5,8 881 160 1768 746 298 539 49 459 149 131 454 172 454 244 65 191 13 454 5,16 1403 148 1900 720 429 679 37 839 97 160 218 185 218 203 65 231 12 218 5,32 2391 135 2071 883 672 1209 39 934 94 140 438 205 438 231 69 241 12 438 Table 1: Coefﬁcients for various conﬁgurations ports, depth by {ports, FIFO depth}) are shown in Table 1. Characterization took about ﬁve to ten minutes per conﬁguration and only a couple of hours for the complete set of conﬁguration points. Note, that characterization only needs to be done once for each sub-component. For example, the input link controller circuit for a single port may be identical in 3 port and 4 port routers, hence, the model for a 3 port router can be used in the 4 port router model. Table 1 shows that the coefﬁcients for the 3 port and 4 port routers exhibit similar coefﬁcients. Once the routers were characterized, we used these macro-models to predict the energy consumption for a set of trafﬁc patterns that were different from the calibration set. These patterns were randomly generated with ﬁxed applied load. Each router port trace consists of 500 packets sent to random destination ports with a given ﬁxed applied load varying from 0.1 to 0.6 ﬂits per port with each packet containing ﬁve ﬂits. Figures 4(a - c) show the errors across different trafﬁc loads for the 3 port, 4 port and 5 port routers respectively. From these ﬁgures the maximum absolute energy estimation error is 9.9% and the average absolute error is 4.6%. Given the application statistics such as number of packets, data switching rate and time in contention, it takes less than a second to determine the energy consumption. (a) (c) (b) (d) Figure 6: The relationship between the number of ports vs. energy It can be seen from Figure 6(a) that in this custom router library the increase in ports does not greatly affect the link controller buffering energy for a single ﬂit (βaread + βawrit e + βd read + βdwrit e ). Figure 6(b) shows that for a single link controller, residual energy βil c0 remains nearly constant. For a complete router, there is one link controller for every input port, hence the residual energy will increase linearly with the number of ports. Figure 6(c) shows the increase in the crossbar hamming energy Ed ist with the increase in the number of ports. The observed relationship is linear and can be explained by increased logic depth in larger crossbars. Meanwhile, the crossbar residual energy (Figure 6(d)) increases quadratically with the increase in the number of ports. This is due to the quadratic increase in area as the number of inputs ports and output ports increase. The macro-models from the previous section can be used to rapidly predict the energy consumption of an application running on any supported network topology (2 × 2, 4 × 2 or 4 × 4 etc). We integrate the energy macro-model into a graph-based NoC performance estimation framework to predict the energy for a complete NoC. This framework estimates the performance and power given the application as a task graph, the NoC architecture as a topology graph, and energy model as speciﬁed in Section 4 (see Figure 7). Task graphs model the application dependencies in a graph with three types of nodes: communication, computation and handshake nodes. Graph edges deﬁne the dependencies between the different types of nodes. The task graph format is similar to the Communication Analysis Graphs presented in [18]. Task graphs are obtained from various sources including synthetically generated task graphs and realistic hand-crafted task graphs [9]. We estimate the energy consumption usFigure 5: Predicted and Measured Power Waveforms Figures 4(a - c) shows that the model tends to slightly under-predict power when there is a high applied load. This is caused by the fact that our model captures most but not all dynamic effects when there is a large amount of port contention. For cycle-based prediction, the absolute cycle mean relative error is less than 20% across the validation set. A proportion of the power waveform from the validation trace of the 4 port mesh-router with FIFO depth of 4 with 0.2 ﬂits per port applied load is shown in Figure 5(a). The PrimePower waveform is the dotted line and the predicted is the unbroken line. Figure 4(d) shows the distribution of the cycle based energy estimation errors (measured energy - predicted energy) for the same trace as in Figure 5. 5.3 Custom Router and Router Port Scaling An exploration of the energy coefﬁcients trends was undertaken for several larger non-mesh routers. We parameterized the NoC generator to create a custom topology router with destination port embedded in the address with a varying number of ports from 4 to 32 and a uniform 4-ﬂit FIFO buffer. Each router was synthesized using the same methods as in previous experiments and models were extracted. Figure 6 shows the trends in the link controller and crossbar switch. 258 a complete gate simulation. As such, we conclude that our models are accurate enough for the purpose of high-level design space exploration for NoC router architectures. Benchmark auto-industry telecom TGFF1 TGFF2 TGFF3 TGFF4 Graph-based CPU Time < 0.001 s 0.001 s 0.03 s 0.43 s 0.15 s 0.05 s Speed Up PrimePower CPU Time 495 s > 100000 1504 s > 100000 1498 s 50000 7.58 h 63000 2951 s 20000 1800 s 36000 Table 4: Efﬁciency of Complete NoC simulation 6. CONCLUSIONS We have presented a technique for extracting a fast and accurate energy macro-model from a Network on Chip library. Using this technique, we have characterized a set of routers generated using the NoCGEN framework. Validation between the macro-model and gate level estimates show that for the randomly generated test patterns, the energy estimation error had a mean absolute error of less than 5%. We are currently applying these models for use in an architecture synthesis environment. "
2005,The feasibility of on-chip interconnection using antennas.,,
2005,Application-specific network-on-chip architecture customization via long-range link insertion.,,"Application-Specific Network-on-Chip Architecture  Customization via Long-Range Link Insertion Umit Y. Ogras Radu Marculescu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA e-mail: uogras@ece.cmu.edu Department of Electrical and Computer Engineering Carnegie Mellon University Pittsburgh, PA 15213-3890, USA e-mail: radum@ece.cmu.edu Abstract Networks-on-Chip (NoCs) represent a promising solution to complex on-chip communication problems. The NoC communication architectures considered so far are based on either completely regular or fully customized topologies. In this paper, we present a methodology to automatically synthesize an architecture where a few application-specific long-range links are inserted on top of a regular mesh network. This way, we can better exploit the benefits of both complete regularity and partial customization. Indeed, our experimental results show that inserting application-specific long-range links significantly increases the critical traffic workload at which the network state transits from a free to a congested regime. This, in turn, results in a significant reduction in the average packet latency and a major improvement in the network achievable throughput. I. INTRODUCTION Continuous scaling of CMOS technology makes it possible to put many heterogeneous devices on a single chip. Largescale integration of these blocks onto a single chip calls for truly scalable Networks-on-Chip (NoC) communication architectures [1,2,3]. Regular NoC architectures based on grid-like (or 2D lattice) topologies provide well-controlled electrical parameters and reduced power consumption across the links. However, due to the lack of fast paths between remotely situated nodes, such architectures may suffer from long packet latencies. Indeed, having many hops between different communicating nodes, not only increases the message latency, but also increases the message blocking probability thus making the end-to-end packet latency more unpredictable. Consequently, such generic platforms may become easily less attractive for application-specific designs that need to guarantee a given level of performance.  On the other hand, fully customized topologies [8-11] can improve the overall network performance, but they distort the regularity of the grid structure. This results in links with widely varying lengths, performance and power consumption. Consequently, better logical connectivity comes at the expense of a penalty in the structured nature of the wiring which is anyway one of the main advantages offered by the regular on-chip networks [1]. In the extreme case, fully customized solutions may end up resembling ASIC-style designs where individual modules communicate by packet switching. Hence, the usual problems of cross-talk, timing closure, global wires etc. may undermine the overall gain obtainable through customization.  0-7803-9254-X/05/$20.00 ©2005 IEEE. 246 Figure 1. Illustration of adding long-range links to a 4x4 standard mesh network. Fortunately, these two extreme points in the design space (i.e. designs based on purely regular or completely customized topologies) are not the only solutions possible for NoC architectures. In fact, it is interesting to note that many technological, biological, and social networks are neither completely regular, nor irregular [14,15]. One can view these networks as a superposition of clustered nodes with short links and a collection of random long-range links that produce “shortcuts” among different regions of the network. Regular lattice networks with a number of additional random long-range links, similar to the one shown in Figure 1, can be used to model such networks [15]. This paper explores precisely the potential of using standard mesh networks in conjunction with a few additional longrange links to improve the performance of regular NoCs.  Inserting long-range links to regular architectures clearly reduces the average distance between remote nodes. However, inserting long-range links cannot be done randomly for NoCs because adding extra links has a more pronounced, yet barely studied, impact on the dynamic properties of the network, which are characterized by traffic congestion. At low traffic loads, the average packet latency exhibits a weak dependence on the traffic injection rate. However, when the traffic injection rate exceeds a critical value, the packet delivery times rise abruptly and  the network  throughput starts collapsing (Figure 2). The state of the network before congestion (i.e. the region on left hand side of the critical value) is the free state, while the state beyond the critical value (right hand side) is said to be the congested state. Finally, the transition from the free state to the congested one is known as phase transition region.  As it turns out, the phase transition in regular networks can be significantly delayed by introducing additional long-range links (see Figure 2) [16]. Due to the exponential increase in the latency beyond the critical point, even a small right hand shift uniform traffic. The packets in the network consist of a single atomic entity containing address information only. Also, due to the infinite buffer assumption, the authors do not deal with deadlock states explicitly.  In contrast to this prior work, we do consider wormhole routing with arbitrary flit sizes and network routers with bounded input buffers. Most importantly, instead of uniform traffic, we assume application-specific traffic patterns and present an algorithm which inserts the long-range links in a smart manner rather than randomly. Due to the bounded input buffers, additional long-range links may cause deadlock states. For this reason, we also present a deadlock-free routing algorithm that exploits the long-range links to achieve the desired performance boost. III. LONG-RANGE LINK INSERTION ALGORITHM We start by formulating the long-range link inserting problem. After that, we present the details of the solution following a top-down approach. A.  System model and basic assumptions The system of interest consists of a set T of  m n×  tiles interconnected by a 2D mesh network1. The tiles of the network (referred to as PEs) are populated with processing and/or storage elements that communicate with each other via the network. We do not make any assumption about the distribution of the packet injection rate into the network, but only consider the frequencies at which the PEs communicate with each other. Due to limited on-chip buffer resources and low latency requirements, it makes sense to assume wormhole switching for the network; the results derived here, however, are also applicable to packet- and virtual cut-through switching networks. Further, we do not assume any particular routing algorithm for the mesh network; the only requirement is that the underlying routing algorithm has to be deadlock-free and minimal. Deadlockfree property is desirable for on-chip networks for two reasons: First, implementing deadlock detection and recovery mechanisms is expensive in terms of silicon resources. Second, such mechanisms can cause unpredictable delays, which need to be avoided for most embedded applications.  After inserting the long-range links as explained in Section C, the routers without extra links simply use the default routing strategy. Since this default strategy cannot route the packets across the newly added links, we define a deadlock-free routing strategy which enables the use of the newly added longrange links (Section E).  B.  Problem formulation The communication volume between the PE located at tile i T∈  and the PE located at tile  j T∈  is denoted by Vij. We compute the frequency of communication, fij, between PEs i and j by normalizing the inter-tile communication volume as follows:     1. The following discussion assumes a 2D mesh but the proposed technique is applicable to other topologies for which a distance definition as in equations 6 and 7 (in Section III) exists.  Figure 2. Shift in the critical traffic load after the insertion of longrange links to a 6x6 mesh network under hotspot traffic (Section V). in the critical traffic value may result in orders of magnitude reduction for latency. Similarly, the achievable throughput grows with the right shift of the critical traffic value. This phenomenon is at the very heart of our optimization technique.  The main objective of our optimization technique is to boost the network performance (i.e. reduce the average packet latency and increase the network throughput) by maximizing the value of the critical traffic load via smart insertion of application-specific long-range links. To this end, our contribution is twofold:   • First, for a given application, we propose an algorithm that determines the most beneficial long-range links to be inserted in a mesh network.   • Second, we present a deadlock-free decentralized routing algorithm that exploits the long-range links to achieve the desired performance level.  The paper is organized as follows. Section II reviews related work. The proposed approach for smart link insertion is explained in Section III. Practical considerations in implementing long-range links are discussed in Section IV, while the experimental results appear in Section V. Finally, Section VI concludes the paper by summarizing our main contribution.  II. RELATED WORK The use of NoCs as a scalable communication architecture is discussed in [1,2,3]. Design methodologies for applicationspecific NoCs are discussed in [4-11]. Studies in [6,7] consider regular network topologies and present algorithms for application mapping under different routing strategies. On the other hand, fully customized communication architecture synthesis for a given application is addressed in [8,9,10].  To the best of our knowledge, the idea of optimizing a generic grid-like network with application-specific long-range links is first addressed in this paper. Previous work on a similar idea comes from the networks theory side and uses very idealistic assumptions. For instance, the authors of [16] investigate the effect of adding random links to mesh and torus networks under 247 ∀ i j p q , , , ∈ T     f i j = -------------------------(1) V i j ∑ p ∑ q p≠ Vp q 1– The addition of long-range links introduces an overhead due to the additional wires and repeaters1 connecting the wire segments to ensure the latency-insensitive operation. Hence, we need to model the cost of long-range links to have a measure of this overhead.  Without losing the generality, we measure the size of longrange links,  s l( ) , in multiples of basic link units which are identical to the regular links used in the mesh network. This is reasonable, since the long-range links consist of a number of standard links connected by repeaters, as shown in Figure 8. The number of repeaters required by a long-range link is given by  s l( ) . Consequently, the maximum amount of permissible overhead can be expressed as a multiple of the standard link segments that make up the long-range link. For example, a resource constraint of S means that only long-range links consisting of at most S units of standard links, total, can be added.  We can now state the application-specific long-range link insertion problem as follows:  Given  • fij  i j  • Maximum number of links that can be added, S  • Routing strategy for the mesh network, R Determine  • The set of long-range links to be added on top of the mesh network,  LS  • A deadlock-free routing strategy that governs the use of the newly added long-range links,  RL such that  T∈,∀ m a x λ c( )   s u b j e c t t o    l s l( ) S< ∑ L S∈ (2) λ c λ c where   is the critical load at which the network enters the congested phase. To give some intuition, the long-range links are added to maximize the critical traffic,  , subject to the total amount of available resources; that is, the phase transition region is delayed beyond the value a standard mesh network (of exactly same size) can offer. Maximizing   increases the achievable throughput and reduces the latency compared to the original critical load, as shown later in the experiments. Note that, the objective of inserting long-range links is by no means limited to maximizing  . Indeed, other objective functions (e.g. increased fault-tolerance, guaranteed service, etc.), can replace or augment the objective of maximizing   in order to take the full advantage of the inserted links. λ c λ c λ c C.  Iterative link addition algorithm We propose an efficient iterative algorithm that inserts the most beneficial long-range links to the current configuration of the network, provided that the available resources are not used up yet. The link insertion algorithm is summarized in Figure 3.  1. In our terminology, the repeaters act primarily as storage elements (like FIFO buffers), as explained in Section IV in more detail. 248 Figure 3. The flow of the long-range link insertion algorithm. The evaluation step is detailed in Section D. ) ( The algorithm starts with a standard mesh network and takes the communication frequencies between the network tiles, the default routing algorithm and the amount of resources allowed to use as inputs. Then, the algorithm selects all possible pairs of tiles (i.e.  C T 2,  pairs where  T  is the number of nodes in the network) and inserts links between them. After inserting each long-range link, the resulting network is evaluated to find out the gain obtained over the previous configuration. Since our goal is to maximize  , we compare different configurations in terms of critical traffic load as detailed in Section D. After the most beneficial long-range link is found, the information about this link is stored and the amount of utilized resources updated. For example, if a long-range link consisting of four equivalent segments of standard links is added, the utilization is incremented by four.  The procedure described above repeats until all available resources are used up. Once this happens, an architecture configuration file is generated. Then, the routing strategy governing the use of long-range links is produced and written to a routing configuration file, as described in Section E. λ c D.  Evaluation of the critical traffic value While the impact of routing strategy, switching techniques and network topology on the critical point have been studied via simulation [18], no work has been done to maximize the traffic critical value subject to resource constraints. The major obstacle in optimizing the critical load comes from the difficulty in modelling the variation of critical point as a function of the design decisions. Several theoreticians [16,17] estimate the criticality point using mean field models. However, unlike our work, these studies assume uniform traffic, infinite buffers, and the estimates are valid only for regular grids without long-range connections. The key idea of our contribution is to reduce the estimation of critical point of the network to just one parameter that can be computed analytically, much faster than simulation. This is important since using very accurate estimates obtained through simulation would be simply too costly to use within an optimization loop. The optimization goal can still be achieved using the simple parameter, as long as the comparison between two network configurations matches the one with the critical load.   λ c In the following, we relate   to the free packet delay (τ0) in the network, which can be efficiently computed. Let the number of messages in the network (at time t) be  N t( )  and the aggregated packet injection rate be  , i.e.  λ i , λ i : t h e i n j e c t i on rate o f t i l e i T∈ λ λ ∑= i T∈ In the free state (i.e. when  ), the network is in the steady-state, so the packet injection rate equals the packet ejection rate. As a result, we can equate the injection and ejection rates to obtain the following approximation:     λ λ c< λ ≈ ----------N a v e τa v e (3) = Na v e <N t( ) > where τave is the average time each packet spends in the network, and   is the average number of packets in the network. The exact value of τave is a function of the traffic injection rate, as well as topology, routing strategy, etc. While no exact analytical model is available in the literature, we observe that τave shows a weak dependence on the traffic injection rate when the network is in the free state. Hence, τ0 can be used to approximate τave. If we denote the average number of N c packets in the network, at the onset of the criticality, by  , we can write the following relation:  N c ------------a v e a v e (4) λ c ≈ τ 0 ⁄ ) = = a v e λ c λ c λ c a v e τ 0⁄ τ a v e λ c( λ N a v e τ a v e τ 0 ≤ λ c N c This approximation is also an upper bound for the critical load  , since  . We note that   follows also Little’s law. Indeed, other theoretical studies proposed to approximate   using mean field [16] and distance models [17] under uniform traffic. Given that the number of messages in the network, at the onset of the criticality, is bounded by its capacity,  N c , the critical traffic load   and the average packet latency are inversely proportional to each other. Indeed, if the average packet latency decreases, the phase transition point is delayed, as demonstrated in Figure 2, where the reduction in the latency is obtained due to the long-range links. Our optimization technique uses the relationship between   and τave to maximize the critical load. More specifically, we minimize τ0 which can be efficiently computed in the optimization loop, as opposed to   for which there is no known analytical result to date. Experimental Verification of the Equations 3 and 4 For completeness, we verified experimentally both Equation 3 and Equation 4, as shown in Figure 4. The dotted line shows the actual packet injection rate (λ), for reference. The solid line with the square marker is obtained for a  network under the hotspot traffic, as the ratio between the average number of packets in the network and the average packet delay at that particular injection rate. From these plots, it can be clearly seen that there is a good agreement between the actual value obtained through simulation and the one predicted by Equation 3 before entering the criticality. Since the network is not in steady-state beyond the critical traffic value, the Equation 3 does not hold for higher injection rates. As mentioned before, the exact value of the average packet delay at a given load,  , can only be found by simulation. The dashed τ λ( 8× λ c 8 ) 8x8 Mesh Network λ Nave / τave  Nave / τ0 e l c y c / s t e k c a p λ (packets/cycle) Figure 4. Experimental verification of Equation 3 and Equation 4 for a 8x8 mesh network. i j ) ) i≠ τ 0 (5) ∑ ) tr ( ∑= T∈,∀ f i j d i j,( line with triangular markers in Figure 4 illustrates the upper bound given in Equation 4. We observe that this expression provides a good approximation at lower data rates and holds the upper bound property. Computation of τ0 For arbitrary traffic patterns characterized by the communication frequencies fij  i j , τ0 can be written as  + + ts tw ) m a x t s + tw+( L ----W where  d i j,(  is the distance from routers i to router j, and tr, ts, tw are the is architectural parameters representing time to make the routing decision, traverse the switch and the link, respectively. Finally, L is the length of the packet, while W is the width of the network channel. For the standard mesh network, the Manhattan distance (dM) is used to compute  d i j,( , i.e.  dM i j,( = i x iy where subscripts x and y denote the x-y coordinates, respectively. For the routers with long-range links, an extended distance definition is needed in order to take the long-range connections into account. Hence, we use the following generalized definition:  jx– j y– (6) + ) ) ( ) )   d i j,( =   dM i j,( )        if no long-range link is attached to i m i n dM i j,( ) 1 +, dM k j,( )  if l i k,( )  exists In this equation, l(i,k) means that node i is connected to node k via a long-range link. The applicability of the distance definition is illustrated in Figure 5. Note that the distance computation does not require any global knowledge thus making the routing decision algorithm decentralized. (7) Figure 5. Illustration of distance definition (see Eqn. 7). 249 Interestingly enough, Equation 4 also confirms that the average number of hops between the nodes, a common performance metric, has indeed a positive impact on the dynamic behavior of the network. as being illegal, as in Figure 7. Therefore, we check whether or not the long-range links cause any of these prohibited turns. If it is legal to use a long-range link, then the packet is forwarded to this link. Otherwise, the default routing algorithm is employed.  E.  Routing strategy for long-range links The routers without any extra link use the default routing strategy. Defining a strategy for the routers with long-range links is a necessity dictated by two factors:   • Without a customized mechanism in place, the newly added long-range links cannot be utilized at all by the default routing strategy;  • Introducing long-range links may result in cycling dependencies. Therefore, arbitrary use of these links may result in deadlock states. The routing strategy proposed in this section tries to produce minimal paths towards the destination by utilizing the long-range links effectively, as shown in Figure 6. To this end, we first check whether or not there exists a long-range connection to the current router. If there is one, the distance to the destination with and without the long-range link is computed using Equation 7. It is interesting to note that we can obtain global improvements in the network dynamics by using local information only.  If a newly added long-range link produces a shorter distance to the destination, we check whether or not using this link may cause deadlock before accepting it as a viable route. In order to guarantee that using the newly added link does not cause a deadlock state, some limitations on the use of long-range links are introduced. We achieve deadlock-free operation by extending the turnmodel [13] to long-range links. More precisely, in the original turn model, one out of four possible turns is prohibited to avoid cyclic dependencies (Figure 7). However, unlike standard links, the long-range links can extend in two directions, such as NE, NW, etc. For this reason, one has to consider the rotation from middle directions, NE, NW, SE, SW to the main directions N, S, E and W. In the extended model, we arbitrarily chose the Sto-E, S-to-W, SE-to-E, SE-to-W, SW-to-E, and SW-to-W turns Figure 6. The description of the routing strategy. 250 Figure 7. Possible routing directions, basic and extended turn models. A long-range link may become a traffic attractor and jam the network earlier than the regular short links. For this reason, if the routing algorithm is not adaptive (as it is our case), one more check point is needed before assigning a traffic stream to a new link. For instance, by assessing the amount of traffic assigned to a long-range link, further traffic can be routed over the link only if it is not likely to become a bottleneck. IV. PRACTICAL CONSIDERATIONS We analyze next the implications of customizing the regular network architecture with long-range links on the actual design implementation.  A.  Implementation of long-range links In order to preserve the advantages of structured wiring, the long-range links are segmented into regular, fixed-length, network links connected by repeaters. The use of repeaters with buffering capabilities guarantees latency-insensitive operation, as discussed in [19]. Repeaters can be thought as simplified routers consisting of only two ports that accept an incoming flit, stores it in a FIFO buffer, and finally forwards it to the output port, as illustrated in Figure 8. If the depth of buffers in the repeaters is at least 2 flits, then the packets can be effectively pipelined to take the full advantage of the long-range links [20].  The final consideration in terms of implementation is the increased size of the routers with extra links due to increased number of ports (Figure 8). To measure the area overhead, we implemented routers with 5 and 6 ports using Verilog and synthesized them for a 1M gate Xilinx Virtex2 FPGA. The router with 5 ports utilizes 387 slices (about 7% of total resources), while the one with 6 ports utilizes 471 slices of the target device. We also synthesized a pure   mesh network, and a  mesh network with 4 long-range links and observed that the extra links induce about 10% area overhead. This overhead has to be taken into account, while computing the maximum number of long-range links that can be added to the regular mesh network. While there is no theoretical limitation imposed by our approach on the number of additional links a router can have, a maximum of one long-range link per router is used in our experiments. This way the regularity is minimally altered, while still providing significant improvements over the standard mesh networks, as explained in Section V. 4 4× 4 4× < < 2 α 3 The worst-case complexity of the technique, that is link insertion and routing table generation, is  O SNα  where . The run-time of the algorithm for the examples analyzed ranges from 0.14sec for a   network to less than half hour for a   network on a Pentium III machine with 768MB memory under Linux OS. 4 4× 8× 8 ( ) A.  Experiments with synthetic traffic workloads We first demonstrate the effectiveness of adding long-range links to standard mesh networks by using synthetic traffic inputs. Table 1 compares the critical traffic load, average packet latency and throughput at the edge of criticality under hotspot traffic pattern for   and   networks. For the hotspot traffic three nodes are selected arbitrarily to act as hotspot nodes. Each node in the network sends packets to these hotspot nodes with a higher probability compared to the remaining nodes.   Critical load Latency at the critical load 6 6× 4 4× (packet/cycle) (cycles) hotspot 4x4 hotspot 6x6 λM c 0.41 0.62 λL c 0.50 0.75 LM λM c ( ) L L λM c ( ) 196.9 224.5 34.4 38.2 Table 1: Critical load (packet/cycle) and latency comparison (cycles) for regular mesh (M) and mesh with long links (L). As shown in Table 1, inserting 4 long-range links (consisting of 10 short link segments) to a   network makes the phase transition region shift from 0.41 packet/cycle to 0.50 packet/cycle (the resulting network appears in Figure 1). Similarly, the average packet latency at 0.41 packet/cycle injection rate drops from 196.9 to 34.4 cycles. We also show the variation of the network throughput and average packet latency as a function of traffic injection rate using a much denser scale in Figure 9. 4 4× Hotspot Benchmark (a) (b) Figure 8. Implementation of the repeaters. Routers 1 and 3 are both connected by Router 2 (a), the underlying mesh network, and the inserted long-range link (b). B.  Energy-related considerations One can measure the energy consumption using the Ebit metric [12], defined as the energy required to transmit one bit of information from the source to the destination. Ebit is given by  E (8) + = E b i t EB b i t + Sb i t EL b i t ES b i t EL b i t EB b i t where  ,   and   represent the energy consumed by the interconnect, buffering and switching in the router, respectively. Analyzing the energy consumption before and after the insertion of long-range links shows that the proposed approach does not induce a significant penalty in the total communication energy consumption of the network. Indeed, since the longrange links consist of several regular links with repeaters between them (instead of routers), the link energy consumption stays approximately the same whether the traffic flows over the long-range link or over the original path provided by the mesh network. On the other hand, the energy consumption due to the switch and routing logic is greatly simplified in the repeater design compared to the original routers. This results in a reduction in the switching energy consumption. Finally, the routers with extra links will have slightly increased energy consumption due to the larger crossbar switch. We compared the energy consumption obtained by simulation before and after the insertion of the long-range links, for the traffic patterns reported in Section 6. We observed that the link and buffer energy consumptions increase about 2% after the insertion of long-range links, while the switch energy consumption drops about 7%, on average. The results show that the overall energy consumption increases by only about 1%.  V. EXPERIMENTAL RESULTS We present next an extensive experimental study involving a set of benchmarks with synthetic and real traffic patterns. The NoCs under study are simulated using an in-house cycle accurate C++-based NoC simulator developed specifically for this project. The simulator models the long-range links precisely as explained in Section IV. The configuration files describing the additional long-range links and the routing strategy for a given traffic pattern are generated using the proposed technique and supplied to the simulator as an input.  Figure 9. Traffic injection rate vs. average packet latency and network  throughput  for hotspot  traffic  is  shown. The improvement in terms of critical point and latency values at criticality are indicated on the plots. 251 6 6× Similar results have been obtained for a   grid, as shown in Table 1. In this case, the phase transition region shifts from 0.62 packet/cycle to 0.75 packet/cycle. Likewise, with the addition of long-range links, the average packet latency at 0.62 packet/cycle injection rate drops from 224.5 to 38.2 cycles.  Comparison with the torus network We also compared the performance of the proposed approach against that achievable with a torus network, which provides wrap around links added in a systematic manner. Our simulations show that application-specific insertion of only 4 long-range links, with an overhead of 12 extra standard link segments, provides 4% improvement in the critical traffic load compared to a   torus under hotspot traffic. Furthermore, the average packet latency at the critical point of the torus network, 0.48 packet/cycle, drops from 77.0 to 34.4 cycles. This significant gain is obtained over the standard torus network by utilizing only half of the additional links, since the extra links are inserted in a smart way considering the underlying application rather than blindly adding wrap-around channels. Scalability Analysis To evaluate the scalability of the proposed technique, we also performed experiments involving networks of sizes ranging from   to  . Figure 10 shows that the proposed technique results in consistent improvements when the network size scales up. For example, by inserting only 6 long-range links, consisting of 32 regular links in total, the critical load of a  network under hotspot traffic shifts from 1.18 packet/ cycle to 1.40 packet/cycle giving a 18.7% improvement. This result is similar to the gain obtained for smaller networks. Figure 10(a) also reveals that the critical traffic load grows with the network size due to the increase in the total bandwidth. Likewise, we observe consistent reduction in the average packet latency across different network sizes, as shown  in Figure 10(b). 10 10× 10 10× 4 4× 4 4× B.  Experiments involving real applications In this section, we evaluate the performance of the link insertion algorithm using two applications with realistic traffic: A 4x4 auto industry benchmark and a 5x5 telecom benchmark retrieved from E3S benchmark suite [21]. The variation of average packet latency and network throughput as a function of traffic injection rates for auto industry benchmark is given in Figure 11. These plots show that the insertion of long-range links shifts the critical traffic load from 0.29 packet/cycle to 0.33 packet/cycle resulting in a 13.6% improvement. Similarly, as shown in Table 2, we observe that the average packet latency for the network with long-range links is consistently lower compared to that of a pure mesh network. For instance, at 0.29 packet/cycle injection rate, the latency drops from 98.0 cycles to 30.3 cycles giving about 69.0% reduction.    Similar improvements have been observed for the telecom benchmark as shown in Figure 12. Specifically, the critical traffic load is delayed from 0.44 packet/cycle to 0.60 packet/cycle showing a 36.3% improvement due to the addition of longrange links. Likewise, the latency at 0.44 packet/cycle traffic injection rate drops from 73.1 cycles to 28.2 cycles (Table 2).  252 Figure 10. Scalability results. Performance of the proposed technique for larger network sizes. Comparison with the mesh network with extra buffers Implementation of long-range links requires buffers in the repeaters. To demonstrate that the savings are the result of using the long-range links, we also added extra amount of buffers to the corresponding channels of the pure mesh network, equal to the amount of buffers utilized for the long-range links. Table 2 summarizes the results for standard mesh network (M), standard mesh network with extra buffers (MB) and the network with long-range links (L). We observe that insertion of buffers improves the critical load by 3.5% for the auto industry benchmark. On the other hand, the corresponding improvement due to long-range links is 13.6% over initial mesh network and 10% over the mesh network with additional buffers. Likewise, we note that with the insertion of long-range links, the average packet latency reduces by 69% compared to the original value and 57.0% compared to the mesh network with extra buffers. Consistent results have been obtained for the synthetic traffic workloads mentioned in the previous section and for the telecom benchmark. Due to the limited space, we report only the results for telecom benchmark (Table 2). The results show that, with the addition of extra buffers, the critical traffic point shifts only from 0.44 packet/cycle to 0.46 packet/cycle. Inserting long-range links, on the other hand, shifts the critical point to 0.60 packet/cycle which is a huge improvement in the network capability. Similarly, the average packet latency obtained by the proposed technique is almost 1/3 of the latency provided by standard mesh and about 1/2 of the latency provided by mesh with extra buffers.  Critical load (packet/cycle) Latency at critical load (cycles) auto-indust M auto-indust MB auto-indust L telecom M telecom MB telecom L λ c 0.29 0.30 0.33 0.44 0.46 0.60 L λM c ( ) 98.0 70.5 30.3 73.1 56.0 28.2 Table 2: Critical load (packet/cycle) and latency (cycles) comparison for pure mesh (M), mesh with extra buffers (MB) and mesh with long links (L).   Figure 11. Traffic rate vs. packet latency and network throughput for auto industry benchmark.  Figure 12. Traffic injection rate vs. average packet latency and network throughput for telecom benchmark. VI. CONCLUSION AND FUTURE WORK We have presented a design methodology to insert application-specific long-range links to standard grid-like networks. It is analytically and experimentally demonstrated that insertion of long-range links has an important impact on the dynamics, as well as static properties of the network. Specifically, additional long-range links increase the critical traffic workload. We have also demonstrated that this increase means significant reduction in the average packet latency in the network, as well as improvement in the achievable throughput.  Our current work employs oblivious routing to utilize the long-range links. We plan to extend this work to employ adaptive routing instead. Other possible extensions include inserting long-range links for different objective functions such as faulttolerance and QoS operation.  Acknowledgements : This research is supported by Marco GSRC , NSF CCR-00-93104, and SRC 2004-HJ-1189. VII.  "
2005,Deadlock-free routing and component placement for irregular mesh-based networks-on-chip.,"Routing is one of the most crucial key factors which decides over the success of NoC architecture based systems or their failure. This paper uses well known principles from parallel computer architecture to develop a deadlock free highly adaptive routing algorithm for a 2D-mesh based network-on-chip (NoC) architecture including oversized IP cores. The paper consists of a short introduction into related routing theories and then gives a detailed description of the developed routing scheme. The last part is dedicated to a new floorplanning method, which allows to generate high density layouts suitable for the presented routing algorithm.","Deadlock-Free Routing and Component Placement for Irregular Mesh-based Networks-on-Chip Martin K.-F. Sch¨afer, Thomas Hollstein, Heiko Zimmer and Manfred Glesner Institute of Microelectronic Systems, Darmstadt University of Technology, Germany schaefermartin@gmx.de, thomas@mes.tu-darmstadt.de, hz@metalab.de, glesner@mes.tu-darmstadt.de Abstract Routing is one of the most crucial key factors which will decide over the success of NoC architecture based systems or their failure. This paper uses well known principles from parallel computer architecture to develop a deadlock free highly adaptive routing algorithm for a 2D-Mesh based Network-on-Chip (NoC) architecture including oversized IP cores. The paper consists of a short introduction into related routing theories and then gives a detailed description of the developed routing scheme. The last part is dedicated to a new ﬂoorplanning method, which allows to generate high density layouts suitable for the presented routing algorithm. 1 Introduction System-on-Chip (SoC) design will be the most challenging issue for chip concepts in the next decade. Increasing system complexity, driven by ongoing technology improvements and application requirements, creates a demand for highly eﬃcient and ﬂexible system architectures and appropriate design methods [1, 2]. Relatively increasing on-chip transmission line length and an increasing degree of component reconﬁgurability (embedded processors and FPGA cores) imply the requirement of an on-chip communication paradigm capable to provide the needed adaptivity for running diﬀerent application scenarios on one and the same implementation platform. Flexible Network-on-Chip (NoC) architectures, providing segmented communication (shared communication resources) combined with eﬃcient routing capabilities have turned out to be able to provide the required interconnect ﬂexibility. The performance of the NoC communication links and the embedded routers is essential for the overall system performance. In [22] a performance and cost analysis of NoCs has been presented. Based on the physical hardware, higher OSI protocol layers have to be implemented within NoCs. An overview of the implementation of OSI layers in NoCs can be found in [20] and [2]. Depending on application demands, different transmission modes have to be oﬀered by the NoC: the Philips approach [18] and HiNoC [12] provide combined best-eﬀort and quality-of-service (QoS) transmission modes. Recently several NoC architectures for diﬀerent application domains have been proposed. In [5] some general discussions on network topologies and router architectures can be found. NOSTRUM [13], SOCBUS [23], RAW (MIT) [21] are regular 2D-Mesh architectures. In [16] a torus architecture (NTNU) is described. An alternate FAT tree based structure is used in the SPIN [2] and PROPHID [11] approaches. PROTEO [19] is a ﬂexible architecture, where routers are operating as communication gateways. MESCAL [20] provides routers with attached memory as base components for building ﬂexible interconnection topologies. In many applications, depending on the system components to be attached to the NoC, irregular structures are required in order to be able to integrate SoC components of diﬀerent size. An enhancement of a constant grid 2D mesh approach to irregular mesh-based topologies is reasonable, since it combines the ﬂexibility of multi size component integration with eﬃcient local routing strategies of 2D mesh architectures [12]. In contrast to most NoC approaches, the HiNoC architecture provides the capability of building irregular topologies based on a constant grid router 2D-Mesh structure. IP components of any size can be included just by leaving out a certain amount of routers (Fig. 1). Routing (wormhole routing) is performed based on local decisions of the routers, providing a maximum of scalability. Packet headers are routed, subsequent data ﬂits are just switched to the same output 0-7803-9254-X/05/$20.00 ©2005 IEEE. 238 based scenario). The odd-even turn model overcomes this disadvantage by alternating the prohibited turns according to the column position of the current router (odd or even). Since no type of turn is totally prohibited, a very homogeneous adaptivity is achieved (refer also to [3] for numerical comparison of adaptivities). Furthermore the algorithm can easily be implemented to achieve minimal routing, which leads to good routing performance [8] and prevents livelock. The following rules specify which turns are allowed and which are prohibited in the odd-even turn model. Figure 2 gives an additional graphic explanation. Turns in an odd column  Turns in an even column  NE ES WS NW NE ES WS NW WN SW SE EN WN SW SE EN (a) (b) Figure 2: Turns in the Odd-Even Turn Model (Dashed Turns are prohibited) Rule 2.1 For all routers situated in odd columns turns from northern or southern propagation to western propagation are prohibited (NW and SW turns, Figure 2(a)) Rule 2.2 For all routers in even columns the turns from eastern to southern or northern propagation are prohibited (EN, ES turns, cf. Figure 2(b)). Rule 2.3 Furthermore inversions of the propagation direction (also referred to as 180 degree turns) are prohibited. The application of these rules leads to some elementary consequences which have to be considered when implementing routing algorithms based on the oddeven turn model [3]. These consequences are described in the following. The propagation of a packet is expressed by transitions from one state scurrent with its position (xcurrent , ycurrent ) to a new one snew with (xnew , ynew ). The gap between the current state’s position and the desired destination according to the cartesian coordinates is expressed as dx = xdestination − xcurrent and dy = ydestination − ycurrent . • Deduced from rule 2.1 Whenever a packet is routed westwards from an odd column and has not arrived in the column of its destination, it is prohibited from going north or south in this column. If it would, further routing in western direction would be prohibited by rule 2.1. Rule 2.4 If xcurrent = odd ∧ (dx < 0) ∧ (dy 6= 0) ⇒ dynew = dycurrent • Deduced from rule 2.2: If a packet is traveling eastwards with a destination situated in an even column, the packet must attain the row of its destination before attaining the column. Otherwise, since EN and ES turns are forbidden by rule 2.2 in even columns, it would not be able to reach the destination row when it has reached the destination column. If (dx > 0) ∧ (dy 6= 0) ∧ (xdestination = even) ⇒ Rule 2.5 |dx|new > 0 • Deduced from rule 2.3: Since 180 degree turns never belong to the shortest path between two points, the simplest way to prohibit them is to allow only proﬁtable routing decisions Dec that approach a packet to its desired destination and thus create a minimal routing scheme, which in addition guarantees the livelock freeness of the algorithm [3]. Obviously this is only valid for purely regular meshes that allow a minimal path between every source - destination couple. The rule therefore does not apply to irregular meshes as described in section 3. Rule 2.6 Dec ∈ {scurrent → snew : (|dy |new < |dy |current ) ∨ (|dx|new < |dx|current )} 3 Routing for Partially Irregular NoC-Layouts The above given rules provide necessary and suﬃcient conditions for the design of minimal deadlock free algorithms for purely regular meshes. As soon as a NoC layout contains oversized IP cores, the topology is no longer a purely regular mesh and the odd-even turn model is no longer applicable in its original form. It must be enhanced by special rules that deﬁne routing patterns capable of treating the irregularities created by oversized IP cores. The ﬁrst step to formulate these rules is to give a detailed speciﬁcation of which kind of IP core is to be supported. 3.1 Oversized IP Cores In the context of this work we will limit the scope of supported irregularities to those created by the placement of rectangularly shaped IP cores c with a height 240 6 y (row) 5 4 W 3 2 1 0 even odd even odd even odd even odd N Ncut Forbidden placing:  r  S C D E Excut Ecut Wcut Wxcut Scut 0 1 2 3 4 S 5 6 7 8 x (Column) hy and a length hx that are multiples of ∆x and ∆y . Further the connection point (xo, yo) of a core must be situated in its SW-Edge (cf. also Figure 3). 3.2 Horizontal Circumvention of an Oversized IP Core The original odd-even turn model only relies on isolated topology knowledge. A routing decision only depends on the current routers position (odd or even) and on the destination of the treated packet. As soon as oversized IP cores are placed in a layout and thus an irregular mesh structure is created, the application of pure local knowledge no longer suﬃces to take appropriate routing decisions. The routers directly adjacent to the oversized IP core in Figure 3 (in this context also called block) are identiﬁed as belonging to the direct inﬂuence zone of the block called adjacent boundary zone (similar to [24]). The following deﬁnitions form the sets of the adjacent boundaries Ecut, Scut, Wcut and Ncut. They are simply based on grouping the routers according to their cut links (cf. Figure 3). Deﬁnition 3.1 Adjacent Boundary Zones E cut = {r ∈ M : re = cut} S cut = {r ∈ M : rs = cut} W cut = {r ∈ M : rw = cut} N cut = {r ∈ M : rn = cut} To know whether a router is member of such a deﬁned boundary is nevertheless not suﬃcient to provide a horizontal circumvention not violating the odd-even turn rules. The block in Figure 3 has even columns on its western and eastern sides. Any packet coming from the west with a destination lying behind the block like the couple S − D cannot make the mandatory turn in vertical direction in the even column directly in front of the block. To circumvent the block, the turn must already be taken in the odd column. This implies that all routers in an odd column which are situated one hop from a cut E-link must be aware of this. These routers are grouped in the set of the extended east cut boundary zone E xcut. A similar situation occurs when blocks have odd boundaries, which leads to the formulation of the extended west cut boundary zone. The described situations can be formulated using the following representations. Deﬁnition 3.2 Extended Boundary Zones E xcut = {r ∈ Odd : ∃n ∈ E cut| (nx = rx + 1) ∧ (ny = ry )} W xcut = {r ∈ E ven : ∃n ∈ W cut| (nx = rx − 1) ∧ (ny = ry )} 3.3 Vertical Circumvention of an Oversized IP Core The knowledge of the deﬁned boundary regions sufﬁces to a certain extent to handle horizontal blocking situations. Unfortunately they do not solve vertical blocking situations. Figure 4 shows two paths from S 1 to D1. Since the rules of the odd-even turn model apply, any circumvention of block C in eastern direction would be impossible, leading to a prohibited EN-Turn. Thus only the ﬁrst path provides a legal solution, which implies to turn west and to route around the block making a detour. As it must always be avoided to route in vertical direction in an odd column if a block is to be circumvented, there must exist a sort of anticipation to the described situation, which lies beyond locally based knowledge. This anticipation can be furnished by a concept baptised Line of Sight, which will be explained in the following. even odd even odd even odd even odd N be evaded by using the rules for horizontal circumvention, the deﬁnition of a LoS is independent from the horizontal link situation. The following algorithm uses this advantage to deﬁne all LoS for an entire irregular 2D-Mesh. Cycling through the rows, it creates lists of northern an southern LoS distinguishing between odd end even ones. This distinction is necessary because due to rule 2.2 in section 2.2 even LoS are only applicable for routing towards western situated destinations, and odd LoS are only usable for routing in eastern direction respecting rule 2.1. Algorithm to determine LoS f o r ( k = 1 : m e s h r ow s ) %i t e r a t e t h e r o w s f o r ( l = 1 : m e s h c o l um n s )% i t e r a t e t h e c o l um n s c u r r e n t p o s = ( k , l ) c u r r e n t r = mesh ( c u r r e n t p o s ) %c a l c u l a t e n o r t h e r n LoS f o r c u r r e n t p o s i f ( c u r r e n t r o u t e r . n l i n k == on ) n r=g e t ( a l l r o u t e r s n o r t h o f c u r r e n t p o s i n c u r r e n t p o s . c o l um n ) c l o s e s t r = g e t ( c l o s e s t o f n r w i t h n l i n k == o f f ) L o S n ( k , l )= c l o s e s t r . y−c u r r e n t p o s . y e l s e L o S n ( k , l ) = 0 end %c a l c u l a t e s o u t h e r n LoS f o r c u r r e n t p o s i f ( c u r r e n t r . s l i n k == on ) . . . D1 D2 end end E 3.4 The Fault Tolerant Routing Algorithm 6 y (row) 5 4 W 3 2 1 0 C 2nd Path 1st  Path S1 S2 LoS 0 1 2 3 4 S 5 6 7 8 x (Column) Figure 4: Solution for the Circumvention of a Block in Vertical Direction Unlike the formerly described situation S 1 − D1, the source destination couple S 2 − D2 would allow a minimal path routing according to the rules of the turn model. It would simply be suﬃcient to follow one of the paths leading eastwards and then approaching the column of D2, following the boundary of block C . The ma jor diﬀerence between the two situations is the existence of the intact router line in the column of D2, which provides the possibility of reaching D2 after having turned block C in eastern direction. The existence of this free Line of Sight (LoS) must be known to the router of S 2 before it can make the decision to route the packet dedicated to D2 eastwards. Since any obstacle situated in the row of a traﬃc source can Taking all the presented concepts together, it is possible to design a deadlock and livelock free routing algorithm for NoCs. The algorithm described in the following is a routing table based version. Generating routing tables for every router in a given layout, fast routing decisions can be achieved with relatively low router intelligence. If no oversized cores block a routing path, the algorithm is furthermore minimal due to application of rule 2.6. The depicted algorithm listing uses the following predeﬁned expressions which already include many of the rules implied by the oddeven turn model and boundary issues. • cnode_even/odd: The current node’s column position • c_dx,c_dy: Distance from current node to destination • ex_own_los: Flag set if the column of the current node is a LoS for the current destination regardless of the current column type. • ex_w_los,ex_e_los: Flag set if there are western/eastern LoS for the current destination. 242 • only_w_los,only_e_los: Flag set if the current node’s column is the only remaining LoS for the current destination. • nsblocked,nsfree: Evaluate N/S cut together with c_dy. • wblocked,...: Evaluate W/E (x)cut together with c_dx. • route_w_only,...: Table entries for the named direction • try_ns_w and try_ns_e: Variable table entries already including an evaluation of N/S cut together with c_dy. The actually stored table entry diverges between a combination of a horizontal and a vertical component in the direction of the destination and a purely horizonal component. The outer iteration of the algorithm cycles through the list of all enabled routers in the mesh to set up the routing table for each of them. This setup is implemented in the inner iteration which cycles through the list of all routers having an enabled terminal, thus representing a valid destination. In this iteration the destination position is evaluated and the deduced routing decision is written to the current routing table. Algorithm to Create Routing Tables % i t e r a t e a l l e n a b l e d r o u t e r s t o c r e a t e %r o u t e r t a b l e s c o v e r i n g a l l e n a b l e d T e rm i n a l s f o r ( i = 1 : s i z e ( f i l t e r e d r o u t e r t a b l e , 1 ) ) % i t e r a t e a l l p o s s i b l e p a c k e t d e s t i n a t i o n s %( r o u t e r s w i t h u s e d T e rm i n a l s ) f o r ( k = 1 : s i z e ( t e n l i s t , 1 ) ) %s e t up c u r r e n t l i n e o f c u r r e n t t a b l e %( d e c i s i o n i s b a s e d on d e s t i n a t i o n ) i f ( c d x == 0 ) %Same co lumn i f ( c d y == 0 ) → r o u t e t o n l y e l s e i f ( e x o w n l o s ) → r o u t e n s o n l y ; ( w b l o c k e d ) → r o u t e s o n l y ; ( c n o d e o d d ) → r o u t e w o n l y ; → t r y n s w ; e l s e i f e l s e i f e l s e end e l s e i f ( c d x <0) %P a c k e t w a n t s t o g o w e s t i f ( o n l y w l o s ) → r o u t e n s o n l y ; ( w b l o c k e d ) → r o u t e s o n l y ; ( c n o d e o d d ) → r o u t e w o n l y ; → t r y n s w ; e l s e i f e l s e i f e l s e end e l s e i f ( c d x >0) %P a k e t w a n t s t o g o e a s t %t h e r e a r e no c l e a n l o s → w e s t i f ( ˜ e x e l o s ) ( w b l o c k e d ) → r o u t e s o n l y ; ( c n o d e o d d ) → r o u t e w o n l y ; → t r y n s w ; i f e l s e i f e l s e end %t h e r e a r e l o s s o g o i n g e a s t i s a l l o w e d e l s e i f ( o n l y e l o s ) → r o u t e n s o n l y ; ( e b l o c k e d ) → r o u t e s o n l y ; ( c n o d e e v e n ) → r o u t e e o n l y ; → t r y n s e ; e l s e i f e l s e i f e l s e end end end w r i t e d e c i s i o n t o c u r r e n t r o u t i n g t a b l e end end 4 Topology Adaptation The introduced routing scheme provides a powerful, fast routing solution covering a large scope of imaginable NoC conﬁgurations. Unfortunately the rules 3.1 and 3.2 imply restrictions to be observed during the ﬂoorplanning of a layout. To evaluate the severeness of these restrictions the rules were integrated into an automatic condition veriﬁer integrated into a basic iterative ﬂoorplanning algorithm. Besides the condition veriﬁer the algorithm only implies the two following rules. Rule 4.1 In the beginning all blocks are sorted according to their height (hy) and their width (hx) and are considered rotated in the way, that hy ≤ hx. Rule 4.2 Components are considered as rotatable. Thus if a component could not be placed in its original orientation it is rotated by 90 degrees which enables additional placing alternatives. Several exemplary analysis based on this ﬂoorplanning algorithm showed that due to the imposed restrictions on average 8% of a layout space could not be used if layouts with a large number of oversized IP cores were considered (over 50% surface covered by oversized cores). Since this loss of density was a rather unsatisfying result we undertook some additional research to enhance the ﬂoorplanning algorithm. The formulation of two additional placing guidelines, which are described in the following, ﬁnally led to satisfying results. Rule 4.3 During placing the remaining free surface should be kept as compact as possible to have maximum placing liberty for further decisions. Compact free areas are achieved by placing components in rows which already contain elements of the same height. Rule 4.4 Oversized blocks that create unusable zones on their eastern side are placed as far east as possible, other components as far west as possible. The four rules together were implemented into the placing algorithm depicted in the following page. The algorithm also allows the utilization of ﬁxed components, which are placed at custom deﬁned positions. The placing of these components is done before the automatic iteration. 243 Algorithm Place %T ry t o p l a c e a l l f i x e d b l o c k s i t e r a t e ( l i s t o f f i x e d b l o c k s ) { ( b l o c k . p o s i t i o n i s o k ) update s c e n a r i o ; i f e l s e e x i t ; } i f %P l a c e v a r i a b l e b l o c k s , s t a r t w i t h h i g h e s t i t e r a t e ( l i s t o f v a r i a b l e b l o c k s ) { ( b l o c k i s b i g g e r t h a n mesh ) e x i t ; % I n t e l l i g e n t p a r t , t r i e s t o %p l a c e b l o c k i n a row w i t h %sam e hy h a s a l r e a d y b e e n p l a c e d i f ( t h e r e a r e p l a c e d b l o c k s ) { %u n r o t a t e d b l o c k i t e r a t e ( r o w s w i t h b l o c k s o f sam e hy ) { i f ( b l o c k . hy >1 ){ i t e r a t e ( c o l um n s from e a s t t o w e s t ) { ( p l a c i n g a t ( row , c o l um n ) i s o k ) { update s c e n a r i o , q u i t c . i t e r a t i o n ; i f constraints. An analysis of scenarios based on a 10×10 2D-Mesh, where 10% of the surface were covered by ﬁxed components led to 8.8% of unusable space for the simple algorithm and only 3.3% for the enhanced version. If no restrictions are observed 0.6% of the space remain unusable. y (Row) Simple Placing Algorithm y (Row) Enhanced Placing Algorithm } } } e l s e { i t e r a t e ( c o l um n s from w e s t t o e a s t ) { ( p l a c i n g a t ( row , c o l um n ) i s o k ) { update s c e n a r i o , q u i t c . i t e r a t i o n ; i f } } } i f ( b l o c k wa s p l a c e d ) q u i t r . i t e r a t i o n ; } i f ( b l o c k wa s p l a c e d ) c on t inu e w i t h n e x t ; %r o t a t e b l o c k i f p o s s i b l e , s e c o n d c h a n c e i f ( ( b l o c k r o t a t a b l e )& ( r o t a t e d s m a l l e r t h a n mesh ) ) { r o t a t e b l o c k by 9 0 d e g r e e s ; r e d o i t e r a t i o n ; } } i f ( b l o c k wa s p l a c e d ) c on t inu e w i t h n e x t ; e l s e r o t a t e t h e b l o c k b a c k ; %B r u t e f o r c e i t e r a t i o n ” u n r o t a t e d b l o c k ” i f ( b h y >1 ){ i t e r a t e ( c o l um n s from e a s t t o w e s t ) { i t e r a t e ( r o w s from n o r t h t o s o u t h ) { ( p l a c i n g a t ( row , c o l um n ) i s o k ) { update s c e n a r i o , q u i t r . i t e r a t i o n ; i f } } i f ( b l o c k wa s p l a c e d ) q u i t c . i t e r a t i o n ; } } e l s e { % i f b h y==1 i t e r a t e ( c o l um n s w e s t t o e a s t ) { i t e r a t e ( r o w s from n o r t h t o s o u t h ) { ( p l a c i n g a t ( row , c o l um n ) i s o k ) { update s c e n a r i o , q u i t r . i t e r a t i o n ; i f } } i f ( b l o c k wa s p l a c e d ) q u i t c . i t e r a t i o n ; } } i f ( b l o c k wa s p l a c e d ) c on t inu e w i t h n e x t ; %r o t a t e b l o c k i f p o s s i b l e , s e c o n d c h a n c e i f ( ( b l o c k r o t a t e a b l e )& ( r o t a t e d s m a l l e r t h a n mesh ) ) { r o t a t e b l o c k by 9 0 d e g r e e s ; r e d o i t e r a t i o n ; i f ( b l o c k wa s p l a c e d ) c on t inu e w i t h n e x t ; e l s e mark b l o c k a s u n p l a c e a b l e ; } e l s e mark b l o c k a s u n p l a c e a b l e ; } 4.1 Results By applying the described algorithm to 1000 randomly generated scenarios including 50% oversized IP cores, the unusable space was found to be less than 0.1%. Even if ﬁxed components were placed at predeﬁned positions, the intelligent algorithm performed nearly as good as a placing done without any routing caused x (Column) x (Column) Figure 5: Comparison between Simple and Enhanced Placing Algorithm Figure 5 shows one of the analysed scenarios: An initial list of blocks containing a total surface of 100∆a was treated by the two algorithms. The blocks marked in a darker shade of grey have been ﬁxed at predeﬁned positions. The left image shows the scenario after using the simple algorithm. The remaining elementary cells cannot be used due to the application of the rules postulated in section 3, thus there are 6 remaining blocks, which cannot be placed. The right image results from the application of the enhanced algorithm. The diﬀerent placing pattern leads to a denser structure permitting a complete coverage of the mesh. 5 Conclusion In this work a maximally adaptive deadlock free routing algorithm capable to handle NoC layouts with embedded oversized IP cores was developed. The algorithm does not produce signaling overhead but obtains its properties simply by formulating spatial routing rules. The algorithm was implemented to automatically generate VHDL compliant routing tables, which were integrated into an existing VHDL model of a NoC also developed in the research context of our group. The only drawback of the routing concept, its layout restrictions leading to decreased integration densities, was overcome by creating an adapted ﬂoorplanning algorithm. This algorithm uses the knowledge of the postulated rules to furnish intelligent placing decisions achieving integration densities nearly as high as conventional ﬂoorplanning. Taking all these issues together, the work accomplished provides a complete routing solution for a NoC, the only input needed is the mesh size and the used IP cores. 244 6 Next Steps In the near future we will focus on increasing the ﬂexibility of the introduced routing scheme mainly by enlarging its application domain beyond traﬃc adaptation towards the toleration of structural changes during operation mode. This dynamic adaptation capability would not only enable the algorithm to cope with faulty routers but would also permit to switch of whole parts of a chip layout including the routers to save energy. The necessary modiﬁcation of the routing tables on-the-ﬂy after the start of a NoC could be possible by creating a central unit inside a NoC which analyses the topology and cyclically updates the existing LoS (e.g. by sending out special evaluation packets). Based on these LoS the central unit could generate new adapted routing tables which could be broadcasted to all routers in the network thus realizing the adaptation to a new topology. "
2005,An automated technique for topology and route generation of application specific on-chip interconnection networks.,"Network-on-chip (NoC) has been proposed as a solution to the communication challenges of system-on-chip (SoC) design in nanoscale technologies. Application specific SoC design offers the opportunity for incorporating custom NoC architectures that are more suitable for a particular application, and do not necessarily conform to regular topologies. Custom NoC design in nanoscale technologies must address performance requirements, power consumption and physical layout considerations. This paper presents a novel three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisfies the performance and architectural constraints. We present an analysis of the quality of the results of the proposed technique by experimentation with realistic benchmarks.","An Automated Technique for Topology and Route Generation of Application Speciﬁc On-Chip Interconnection Networks Krishnan Srinivasan, Karam S. Chatha, and Goran Konjevod Department of CSE, PO BOX 875406, Arizona State University, Tempe, AZ 85287-5406 Email: (cid:0)ksrinivasan,kchatha,goran(cid:1)@asu.edu Abstract— Network-on-chip (NoC)) has been proposed as a solution to the communication challenges of System-on-chip (SoC) design in nanoscale technologies. Application speciﬁc SoC design offers the opportunity for incorporating custom NoC architectures that are more suitable for a particular application, and do not necessarily conform to regular topologies. Custom NoC design in nanoscale technologies must address performance requirements, power consumption and physical layout considerations. This paper presents a novel three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisﬁes the performance and architectural constraints. We present an analysis of the quality of the results of the proposed technique by experimentation with realistic benchmarks. I . INTRODUCT ION On-chip interconnection networks or Networks-on-Chip (NoC) have been proposed as a solution for addressing the global communication challenges in System-on-Chip architectures that are implemented in nanoscale technologies [1] [2]. An example of the NoC architecture is shown in the right hand side of Figure 1. The ﬁgure depicts a physical layout of an example SoC architecture. The various square blocks with labels (P1, P2, and so on) denote processing or storage cores. The black ﬁlled boxes denote routers that are connected by physical links. Application speciﬁc SoC design offers the opportunity for incorporating custom NoC architectures that are optimized for the target problem domain, and do not necessarily conform to regular topologies. Regular topologies are suitable for general purpose architectures such as the MIT RAW [3] that include homogeneous cores. Application speciﬁc SoC architectures consist of heterogeneous cores and memory elements which have vastly different sizes. For such architectures, the custom NoC architecture has been demonstrated to be superior to regular architecture in terms of power, area and performance by Jalabert et. al. [4]. This paper concentrates on the design of custom NoC topologies that are optimized for the target application. The design of custom NoC architectures poses several challenges to the designer. The interconnection architecture must provide sufﬁcient bandwidth for low latency congestion free P2 P5 P7 P3 {B, L] P1 P4 P6 [H, W] P1 P4 P2 P5 P3 P6 P7 Fig. 1. Application Speciﬁc NoC Design Problem communication between the various units in the architecture. Power reduction has emerged as a ﬁrst order design goal in nanoscale technologies. Hence, the designer must aim to minimize the power consumption for on-chip communication in the interconnection architecture. Due to technology scaling, the physical links consume upwards of 30 % of the total communication power. The power consumption in the physical links is linearly dependent on their length. Therefore, custom NoC design must include physical layout information. The custom NoC design problem is depicted in Figure 1. The input to the problem is the system-level speciﬁcation described by a directed communication trace graph in which the nodes represent various computation and storage elements, and edges denote communication between two units. The nodes include physical dimension information (height and width, H and W in the ﬁgure) about the processing and storage elements, and edges are annotated with bandwidth and latency requirements (B and L in the ﬁgure). The output of the custom NoC design stage (shown in the right side of the ﬁgure) is a physical layout aware topology and a unique route for every edge in the system-level speciﬁcation that satisﬁes the performance requirements, and minimizes the power (primary goal) and area (secondary goal) of the interconnection architecture. This paper presents an automated technique for solving the custom NoC design problem. Automated design of custom NoC architectures requires a characterized library of interconnection network building blocks. We characterized the power consumption of the unit router in 100 nm technology with the help of a cycle accurate power and performance evaluator [5]. In the interest of space, we have omitted the complete details of the experiments. The variation of power consumption with injection rate for the input and output ports of a router are shown in Figures 2 0-7803-9254-X/05/$20.00 ©2005 IEEE. 231 0.00E+00 2.00E-01 4.00E-01 6.00E-01 8.00E-01 1.00E+00 1.20E+00 1.40E+00 1.60E+00 1.80E+00 0 0.01 0.02 0.03 0.04 Injection Rate (packets/cycle) 0.05 0.06 I u p n t o P t r o P w e r ( W m ) Fig. 2. Input port power consumption 0.00E+00 5.00E-02 1.00E-01 1.50E-01 2.00E-01 2.50E-01 3.00E-01 3.50E-01 4.00E-01 0 0.01 0.02 0.03 0.04 0.05 Cumulative Injection Rate (packets/cycle) 0.06 0.07 O u t u p t o P t r o P w e r ( W m ) Fig. 3. Output port power consumption 0.00E+00 2.00E-01 4.00E-01 6.00E-01 8.00E-01 1.00E+00 1.20E+00 0 0.01 0.02 0.03 0.04 0.05 Cumulative Injection Rate (packets/cycle) 0.06 0.07 o P k n L i w e r ( W m ) Link Length = 2500 um Fig. 4. Link power versus injection rate 3.00E-01 1.00E+03 4.00E-01 5.00E-01 6.00E-01 7.00E-01 8.00E-01 1.50E+03 2.00E+03 2.50E+03 Link Length (um) 3.00E+03 3.50E+03 o P k n L i w e r ( W ) Injection Rate = 0.0089 Fig. 5. Link power versus length 0 200 400 600 800 1000 1200 1400 1600 0 0.01 0.02 0.03 0.04 Injection rate (packets/cycle) 0.05 0.06 0.07 a L t y c n e ( s e c y c l ) Latency Fig. 6. Latency for 2 routers 0 200 400 600 800 1000 1200 1400 0 0.01 0.02 0.03 0.04 0.05 Injection rate (packets/cycle/node) 0.06 0.07 a L t y c n e ( s e c y c l ) Latency Fig. 7. Latency for 4x4 mesh and 3, respectively. The power consumption of the input and output ports vary linearly with the injection rates, respectively. Quantitatively, we estimated the power consumption of the input port as (cid:0)(cid:1)(cid:2)(cid:1)(cid:2) (cid:4), and (cid:3)(cid:4)(cid:7)(cid:4)(cid:1)(cid:2) (cid:4) for the output port. We studied the variation of link power with respect to the bandwidth ﬂowing on the link, and its length. Figure 4 plots the variation of link power with the supported bandwidth. Figure 5 plots the variation of link power with its length. The power consumption of the physical links varies linearly with both the supported bandwidth, and the length of the link. We estimated the power consumption of the links to be equal to (cid:5)(cid:6)(cid:7)(cid:6)(cid:1)(cid:2) (cid:4)(cid:2). The variation of average latency for data packets that travel over two router hops with respect to injection rate is shown in Figure 6. The average latency remains almost constant in the un-congested mode, and onset of congestion is marked by a sharp increase in latency. As shown in Figure 7, a similar trend is observed for average latencies of packets in a 4x4 mesh. Our technique prevents network congestion by static routing of the communication traces subject to the peak bandwidth constraint on the router ports. Since the network is always operated in the un-congested mode, we can represent the network latency constraint in terms of router hops (such as 1 or 2) instead of an absolute number (such as 100 cycles). In the following section we deﬁne the NoC design problem. A. Problem Deﬁnition Given: (cid:0) A directed communication trace graph (cid:9)(cid:10) (cid:11) (cid:12) , where each (cid:13)(cid:0) (cid:0) (cid:10) denotes either a processing element or a memory unit (henceforth called a node), and the directed edge (cid:14)(cid:1) (cid:9) (cid:1)(cid:13)(cid:0) (cid:11) (cid:13)(cid:2) (cid:2) (cid:0) (cid:12) denotes a communication trace from (cid:13)(cid:0) to (cid:13)(cid:2) . For every (cid:13)(cid:0) (cid:0) (cid:10) , the height and width of the core is denoted by  (cid:0) and (cid:4)(cid:0) , respectively. (cid:0) For every (cid:14)(cid:1) (cid:9) (cid:1)(cid:13)(cid:0) (cid:11) (cid:13)(cid:2) (cid:2) (cid:0) (cid:12) , (cid:15)(cid:14)(cid:1)  denotes the bandwidth requirement in bits per cycle, and (cid:16)(cid:14)(cid:1)  denotes the latency constraint in hops. (cid:0) A router architecture, where (cid:10) denotes the peak input and output bandwidth that the router can support on any one port. Thus, each port of a router can support equal bandwidth in input and output modes. Since a node (cid:13) (cid:0) (cid:10) is attached to a port of a router, the bandwidth to any node from a router, and from any node to a router is less than (cid:10). Two quantities 	(cid:0) and 	 that denote the power consumed per  (cid:4) of trafﬁc bandwidth ﬂowing in the input and output direction, respectively for any port of the router. (cid:0) A physical link power model denoted by 	  per  (cid:4) per . Let (cid:5) denote the set of routers utilized in the synthesized architecture, (cid:12) represent the set of links between two routers, and (cid:12)(cid:6) represent the set of links between routers and nodes. The objective of the NoC design problem is to generate a system-level ﬂoorplan, and a network topology (cid:17) (cid:5)(cid:11) (cid:10) (cid:11) (cid:12) (cid:11) (cid:12)(cid:6) , such that: (cid:0) for every (cid:14)(cid:1) (cid:9) (cid:13)(cid:0) (cid:11) (cid:13)(cid:2)  (cid:0) (cid:12) ,  (cid:9)(cid:1)(cid:13)(cid:0) (cid:11) (cid:0) (cid:11) (cid:0) (cid:11) (cid:2) (cid:11) (cid:7) (cid:7) (cid:7) (cid:1) (cid:11) (cid:13)(cid:2) (cid:2) in (cid:17) that satisﬁes (cid:15)(cid:14)(cid:1) , and (cid:16)(cid:14)(cid:1) , there exists a route (cid:0) the bandwidth constraints on the ports of the routers are satisﬁed, and (cid:0) the total system-level power consumption for inter-core communication is minimized (primary goal), and number of router resources is minimized (secondary goal). In the above problem formulation we assume that the maximum physical link length that permits single clock cycle data transfer between neighboring routers is denoted by the 232                         maximum dimension (  (cid:13) or (cid:1) (cid:13)) of a node in the systemlevel speciﬁcation. This assumption is based on the fact that it is possible to perform intra-core single clock cycle data transfer from one corner of node to the any of the neighboring corners. We also consider that the dimensions of the routers are much lower than the sizes of the cores. This assumption is supported by the observation of Dally et al. [1] that the entire NoC places an area overhead of 6.6% on the SoC architecture. Therefore, we assume that the routers that are possibly utilized in the layout are located at corners of the cores. If (cid:20) (cid:13)(cid:11) (cid:21) (cid:13) denotes the lower left hand side corner of the node, the core is mapped to one of the routers located at (cid:20) (cid:13)(cid:11) (cid:21) (cid:13), (cid:20) (cid:13)  (cid:4)(cid:6) (cid:11) (cid:21) (cid:13), (cid:20) (cid:13)(cid:11) (cid:21) (cid:13)   (cid:6)  or (cid:20) (cid:13)  (cid:4)(cid:6) (cid:11) (cid:21) (cid:13)   (cid:6) . The power consumption of the NoC can be minimized by minimizing the cumulative trafﬁc ﬂowing through the ports of all routers. Trafﬁc ﬂowing in a network can be reduced by placing communicating cores close to each other. However, the close location of the communicating cores must be traded-off with the latency constraints. The latency constraints imposed by the trafﬁc traces specify the maximum number of hops allowed for the trace. Bandwidth requirements and latency constraints of communication traces can be viewed as mutually independent. A trace such as a signalling event or a cache miss is not expected to have high bandwidth requirement, but is bound by tight latency constraints. On the other hand, many non-critical multimedia streams have high bandwidth requirement, and their latency is bound only by the period constraint of the application [6]. A NoC design framework has to perform a trade-off between placing communicating cores with high bandwidth, and those with tight latency close to each other to minimize power, and to satisfy the performance constraints, respectively. The NoC synthesis problem as described above is a variation of the generalized steiner forest problem that is known to be NP hard [7]. We present a three phase technique that i) generates a performance aware layout of the SoC, ii) maps the cores of the SoC to routers, and iii) generates a unique route for every trace that satisﬁes the performance and architectural constraints. The paper is organized as follows: in Section II we discuss previous work, in Section III we present our technique, in Section IV we discuss our experimental results, and ﬁnally in Section V we conclude the paper. I I . PREV IOU S WORK Many researchers [8] [9] [10] [11] have presented core mapping and routing techniques for mesh based NoC architectures. Recently, researchers have begun to address the problem of automated design of application speciﬁc NoC architectures. Pinto et al. [12] presented a technique for constraint driven communication architecture synthesis of point to point links by utilizing deterministic heuristic based k-way merging. Their technique results in network topologies that have only two routers between each source and sink. Hence, their problem formulation does not address routing. In [6], Murali et al. C1 B C2 A C5 C C4 D C3 E C6 (A) C7 C8 F V H H V V V V A B C D E F Fig. 8. CTG Fig. 9. Slicing Tree A D A D A B E X B Y E C F C F B C Y D E F B (A) (B) (C) Fig. 10. Initial Floorplanner D F A C E (D) presented a technique that integrates physical planning with quality of service. However, they do not address synthesis of custom NoC topologies. We on the other hand, synthesize an application speciﬁc custom topology optimized for the target application. Further, they propose a computationally complex solution for the problem, where they iteratively invoke an MILP based placement technique in a tabu search framework. In contrast, we present polynomial time algorithms for integrated ﬂoorplanning, and topology synthesis of application speciﬁc custom NoC architectures. I I I . SYNTHE S I S O F CU S TOM NOC ARCH IT ECTURE S In this section, we present our application speciﬁc onchip interconnection architecture synthesis technique. Our technique operates in three phases. In the ﬁrst phase, it invokes a performance aware slicing tree based ﬂoorplanner to obtain an initial physical layout of the nodes constituting the SoC. In the second phase, the technique invokes a linear programming (LP) based algorithm that maps the processing cores to different routers such that the power utilized for communication is minimized. Finally, in the third phase, it executes a LP based routing algorithm that generates routes for the traces such that the total number of routers utilized in the topology are minimized. In the following sections, we will discuss each phase in detail. A. Initial Floorplanner We utilize a slicing tree based initial ﬂoorplanner (IF) described in [13]. In this paper, we present an overview of the technique, and refer the reader to [13] for further details. Unlike [13], we do not add extra nodes. Figures 8, 9, and 10 give examples of an input CTG, slicing tree, and various stages of the algorithm execution, respectively. The slicing tree is formed by recursively dividing the layout area into vertical and horizontal sections. In Figure 9, the letter (cid:10) denotes that the plane is divided into a left and right sub-plane by a vertical cut, and the letter   denotes that the plane is divided into top and bottom sub-planes by a horizontal cut. IF invokes a graph equicut algorithm proposed by Fiduccia and Mattheyses (FM) [14] to generate the partitions. The partitioning technique assigns nodes to one of the sub-planes such that the total weight of the edges across the cut is minimized. IF assigns a weight to each edge as follows. Bandwidth constraints on the ports of routers can be satisﬁed 233 (cid:9)(cid:8)(cid:0) (cid:1) (cid:6) (cid:7)(cid:8)(cid:2)  (cid:7)(cid:8)(cid:0)  by ﬁnding alternative (sometimes longer) route for the trace. Latency constraints on the other hand cannot be adhered to by ﬁnding alternative paths. Therefore, IF gives higher priority to latency compared to bandwidth. Let (cid:14)(cid:0) be a trace with the highest bandwidth requirement among all traces in the graph. Let (cid:14)(cid:2) be the trace with tightest (lowest) latency constraint among all traces in the graph. IF determines an integer (cid:22) such that it is the minimum value required to ensure that (cid:9)(cid:8)(cid:2) (cid:1) . Once (cid:22) is determined, IF assigns an edge weight to each edge given by (cid:7)(cid:14) (cid:0) (cid:12) (cid:11) (cid:23)(cid:14) (cid:9) (cid:7)(cid:8) (cid:9)(cid:8)(cid:1) . For two edges with the same edge weight, the one with tighter latency has higher priority. This heuristic ensures that traces with low bandwidth requirements, but with tight latency constraints are given priority over those with high bandwidth requirement and relaxed latency constraints. After the ﬂoorplan is generated, our technique invokes a compaction algorithm that takes the actual sizes of the processing cores into account and generates a ﬁnal layout. The compaction stage is required as we utilize a slicing tree based ﬂoorplanning algorithm. The slicing tree based heuristic assigns the nodes to bounding boxes at rectangular grid locations. As the size of the bounding box is typically larger than the size of the node, we require a compaction stage. The compaction algorithm ﬁrst moves all nodes toward the center of the layout in the X direction, and then moves all nodes in the Y direction, again toward the center of the layout. The movement in X and Y directions is repeated until no further compaction is possible. B. Core to router mapping technique In this section, we present a linear programming based technique called CMT that maps each processing or storage core to one router that is located at the corners of the core. We present a lower bound on the optimal solution, and utilize a randomized rounding algorithm to arrive at the optimal (or near optimal) solution. For node (cid:24), let (cid:25)(cid:0) denote the set of routers to which (cid:24) can be mapped. Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) (cid:0) (cid:25)(cid:0) , else 0. Each node is mapped to one of the routers located at its four corners. Therefore, there are (cid:13)  (cid:9)(cid:10) (cid:9) variables of this type. For each edge (cid:24)(cid:11) (cid:22) let (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  denote the communication cost when node (cid:24) is assigned to router (cid:26) and node (cid:22) is assigned to router  . The cost denotes the power consumed to perform this communication. Therefore, (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:15)(cid:0)(cid:10)(cid:1)  (cid:29)(cid:24)(cid:2)(cid:10)  where (cid:15)(cid:0)(cid:10)(cid:1) is the bandwidth requirement of the edge (cid:24)(cid:11) (cid:22), and (cid:29)(cid:24)(cid:2)(cid:10)  is the Manhattan distance between routers (cid:26) and  . Let vector (cid:20) (cid:14)(cid:13)  (cid:9)(cid:10) (cid:9) (cid:15) (cid:16)(cid:17) denote the possible assignments of nodes to different routers, and matrix (cid:31)(cid:14)(cid:13)  (cid:9)(cid:10) (cid:9)  (cid:13)  (cid:9)(cid:10) (cid:9)(cid:17) (with elements (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0) (cid:31)) denote the costs of the various mappings. The problem is to obtain an assignment of the nodes such that the total communication cost is minimized. The problem is a special case of the quadratic assignment problem (QP) and can be expressed mathematically as follows. (cid:24)(cid:24)(cid:24) (cid:14) (cid:20) (cid:11) (cid:31)(cid:20) ! 	(cid:4)(cid:26) (cid:14)#  (cid:7)(cid:24) (cid:0) (cid:10) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:2)(cid:1)(cid:12)(cid:0) where (cid:25)(cid:0) denotes the set of routers that node (cid:24) can be mapped to. The constraints enforce the requirement that each node is mapped to exactly one router. QP is among the hardest problems to solve in combinatorics. It is well known that the formulation presented above cannot be solved in polynomial time unless the matrix (cid:31) is positive semi-deﬁnite. In other words, in order for the QP to be polynomial time solvable, all determinants of the principal submatrices of (cid:31) should be nonnegative [15]. In matrix (cid:31), the diagonal elements indicate the communication cost from a node to itself, and therefore, are zero. Hence, (cid:31) is not positive semi-deﬁnite. One way to make the QP polynomial time solvable is to increase the cost of the diagonal elements of (cid:31) by some value % to make the matrix positive semi-deﬁnite, solving the QP, and ﬁnally subtracting % obtain the ﬁnal solution. But this can result in sub-optimal solutions for the QP [15]. The objective function of QP with constant % added to the diagonal elements is of the form (cid:0) (cid:0)(cid:10)(cid:2) (cid:1)(cid:13) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:20)(cid:1)(cid:10)   (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)   %  (cid:0) (cid:0)(cid:1)(cid:14) (cid:0) (cid:20) (cid:2) (cid:0)(cid:10)(cid:2) (cid:2) (cid:2)(cid:12)(cid:0) (cid:2) ((cid:9) (cid:3) (cid:3) If % is large, the square terms dominate the objective function, and therefore, the minimizer would tend to assign values close to (cid:4) for the stated problem) to the variables (cid:20)(cid:0)(cid:10)(cid:2) . Hence, a randomized rounding scheme that assigns a variable (cid:20)(cid:0)(cid:10)(cid:2) to 1 with probability (cid:20)(cid:0)(cid:10)(cid:2) , will assign node (cid:24) to any of the four routers with almost the same probability, and may not perform well. We are interested in the integer solution of the QP. Since even the continuous version (where variables can take fractional values) is hard to solve, we formulate the integer version as an integer linear program (ILP). An ILP in general is not polynomial time solvable unless  (cid:9)   . Therefore, we relax the integer constraints on the ILP, and solve the problem as an LP. An optimal solution to any linear program can be generated in time polynomial in the number of variables and constraints [16]. Noting that the integer versions of the QP and LP solve the same problem, we apply a randomized rounding technique on the QP by rounding a variable to 1 with a probability given by the value assigned to the variable by the LP. 1) ILP Formulation: In this section, we present our ILP formulation for the quadratic assignment problem. We give a unique number to each node. For each node (cid:24), let (cid:25)(cid:0) (cid:9) (cid:1)(cid:0)(cid:5) (cid:11) (cid:0)(cid:3) (cid:11) (cid:0)(cid:2) (cid:11) (cid:0)(cid:6) (cid:2) denote the set of routers to which (cid:24) can be mapped. Variables We deﬁne the following variables. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) (cid:0) (cid:25)(cid:0) , else 0. There are (cid:13)  (cid:9)(cid:10) (cid:9) variables of this type in the formulation. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  denote a (0,1) integer variable that is set to 1 if node (cid:24) is mapped to router (cid:26) , and node (cid:22) is mapped to router  , else 0. We deﬁne these variables only when 234 (cid:24)(cid:11) (cid:22) (cid:0) (cid:12) or (cid:22) (cid:11) (cid:24) (cid:0) (cid:12) . Hence, there are (cid:16)(cid:3)  (cid:9)(cid:12) (cid:9) The overall expected cost of the solutions is given by variables of this type. Objective Function The objective is to minimize the total communication cost. It can be expressed as follows.  (cid:24)(cid:24)(cid:24) (cid:14) ( (cid:9) (cid:0) (cid:0) (cid:0) (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)   (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)(cid:1)(cid:12)(cid:0)  (cid:1)(cid:12)(cid:1) where (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  is the product of the bandwidth of the trafﬁc for edge (cid:24)(cid:11) (cid:22), and the Manhattan distance between routers (cid:26) and  . We can represent (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  as (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:15)(cid:0)(cid:10)(cid:1)  (cid:29)(cid:24)(cid:2)(cid:10)  where (cid:15)(cid:0)(cid:10)(cid:1) is the bandwidth requirement of the edge (cid:24)(cid:11) (cid:22), and (cid:29)(cid:24)(cid:2)(cid:10)  is the Manhattan distance between routers (cid:26) and  . Note that the objective function is deﬁned only for node pairs that have an edge between them. Constraints (cid:0) Each node should be mapped to exactly one router. This constraint can be modeled as follows. (cid:7)(cid:24) (cid:0) (cid:10) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:2)(cid:1)(cid:12)(cid:0) (cid:0) The variable (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  represents node (cid:24) mapped to router (cid:26) , and node (cid:22) mapped to router  . Therefore, if node (cid:24) is mapped to router (cid:26) , all communication should take place through that router. This condition is represented by the following two equations. (cid:7)(cid:24)(cid:11) (cid:22) (cid:0) (cid:12) (cid:11) (cid:7)(cid:26) (cid:0) (cid:25)(cid:0) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:1)(cid:12)(cid:1) (cid:7)(cid:24)(cid:11) (cid:22) (cid:0) (cid:12) (cid:11) (cid:7)  (cid:0) (cid:25)(cid:1) (cid:11) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (cid:20)(cid:1)(cid:10)  (cid:2)(cid:1)(cid:12)(cid:0) C. Discussion We show with the help of lemmas that a randomized rounding technique can be successfully applied to obtain near optimal solutions. Lemma 1: The optimal solutions of the integer versions LP and QP have the same cost. Proof: Let us denote the integer versions of the problems as ILP and IQP, respectively. We note that the ILP and IQP solve the same problem, and therefore, the cost of their optimal solutions will be the same. Lemma 2: The expectation of the integer solution generated by randomized rounding of the variables of the QP with probability equal to the value of the variable in the solution is equal to the cost of solution generated by QP. Proof: Let the cost of the solution of QP be denoted as (	 , and the cost of the integer version of QP be denoted as (	 . Consider an experiment of picking one router (cid:26) among the four routers placed in the corners of node (cid:13)(cid:0) , with a probability (cid:20)(cid:0)(cid:10)(cid:2) . For an edge (cid:24)(cid:11) (cid:26)  (cid:0) (cid:12) , the cost of mapping nodes (cid:24) and (cid:26) is given by (cid:12) (cid:14)( (cid:0)(cid:10)(cid:2) 	 (cid:17) (cid:9) (cid:0) (cid:0)  (cid:20)(cid:0)(cid:10)(cid:2) (cid:9) (cid:16) (cid:1)  (cid:20)(cid:1)  (cid:9) (cid:16)  (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:2)   (cid:12) (cid:14)(	 (cid:17) (cid:9) (cid:0) (cid:0) (cid:0)  (cid:20)(cid:0)(cid:2) (cid:9) (cid:16) (cid:1)  (cid:20)(cid:1)  (cid:9) (cid:16)  (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)   Noting that the probabilities are independent and (cid:20)(cid:0)(cid:10)(cid:2) is set to 1 with probability (cid:20)(cid:0)(cid:10)(cid:2) , we get (cid:12) (cid:14)(	 (cid:17) (cid:9) (cid:0) (cid:0) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2)  (cid:20)(cid:1)(cid:10)   (cid:27)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1)(cid:10)  (cid:9) (	 (cid:0)(cid:10)(cid:1)(cid:1)(cid:13) (cid:2)   The lemma proves that there is some feasible assignment of the nodes to routers such that the cost of the solution and that of the infeasible optimal solution obtained by relaxing the integer constraints is the same. Let this optimal feasible solution be represented by (  	 . Let the cost of the LP be denoted as ( , and the cost of the ILP be denoted as (  . From the above argument, it follows that ( (cid:6) (	 (cid:9) (  	 (cid:9) (    Lemma 3: Let ((cid:19)	 represent the cost of the solution obtained by adding a constant % to the diagonals of matrix (cid:31) to make it positive semi-deﬁnite. Then, (	 (cid:12) ((cid:19)	  (cid:9)(cid:10) (cid:9)% . Proof: From Lemma 2, We also know that (  	 (cid:9) (	 (   (cid:19)	 (cid:12) ((cid:19)	 In the optimal integer solution, one and only one (cid:20)(cid:0)(cid:10)(cid:2) per node (cid:24) is set to one. The remaining variables are set to zero. Therefore, ( (cid:19)	 is minimized only when the ﬁrst part of the sum in the objective function is minimized. But the ﬁrst part represents (	 . Therefore, (   (cid:19)	 (cid:9) (  	  %  (cid:9)(cid:10) (cid:9) Now, since (   (cid:19)	 (cid:12) ((cid:19)	 , and (  	 (cid:9) (	 , (	 (cid:12) ((cid:19)	   (cid:9)(cid:10) (cid:9)  % . Therefore, we can solve for ((cid:19)	 in polynomial time, and obtain a lower bound on (	 . From Lemma 2, this gives us a lower bound on the expected value of the integer solution. To obtain an integer solution with a cost given by the lower bound, we utilize the randomized rounding technique. 1) Randomized rounding: Based on the LP formulation, we present a randomized rounding algorithm using (	 as a lower bound. The algorithm iteratively assigns routers to nodes with probability given by the value of the corresponding variable ((cid:20)(cid:0)(cid:10)(cid:2) ), until the number of iterations is maximum, or an optimal solution is found. Once the exit criterion is satisﬁed, the algorithm returns the best solution found thus far. 235 2) Merging routers: At the end of the ﬂoorplanning and mapping phases, the architecture may have routers that are placed very close to each other. In order to eliminate redundant routers and also to reduce the complexity of the routing stage, we merge pairs of routers that are less than a certain distance apart. The distance is speciﬁed by the designer, and can be set to the maximum permitted link length for single clock cycle data transfer. Our merging algorithm checks all pairs of available routers and merges two routers if (cid:0) the distance between them is less than the maximum allowable distance under single clock cycle data transfer, and (cid:0) merging the two routers does not cause a violation of the single clock cycle data transfer for any other router. D. Routing Technique In this section, we present RT, a linear programming based algorithm for routing communication traces such that the total number of routers utilized in the topology is minimized. The problem is a variation of the rectilinear steiner arborescence problem which is known to be NP-Complete [17]. Our heuristic models the problem as an LP formulation, and employs a randomized rounding technique to arrive at the ﬁnal solution. In the following paragraphs, we discuss our technique in detail. Variables: We deﬁne the following variables. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2) denote a (0 1) variable that is set to 1 if the router at location (cid:24)(cid:11) (cid:26)  is selected for routing. (cid:0) Let (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1) denote a (0 1) variable that is set to 1 if edge (cid:22) utilizes router at location (cid:24)(cid:11) (cid:26)  for routing. The number of variables of this type is equal to the product of the number of edges and the number of (cid:20)(cid:0)(cid:10)(cid:2) variables. Objective: The objective is to minimize the number of routers. The objective can be expressed as  (cid:24)(cid:24)(cid:24) (cid:14) ( (cid:9) (cid:0) (cid:20)(cid:0)(cid:10)(cid:2) Constraints: For each edge in the CTG, consider a bounding box on the layout deﬁned by the location of the source and sink nodes. The bounding box for the communication trace speciﬁes the routers that can be utilized for routing with the shortest Manhattan path length. For edge (cid:14), let the bounding box be denoted as )(cid:8) . (cid:0) An edge in CTG always passes through the source and sink routers. For edge (cid:14), let  denote the source node, and  denote the sink node. Let the location of the router that connects to  be ((cid:24)(cid:11) (cid:26) ), and the location of the router that connects with  be ((cid:22) (cid:11)  ). The following two equalities must hold. (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:8) (cid:9) (cid:16)(cid:11) (cid:20)(cid:1)(cid:10) (cid:10)(cid:8) (cid:9) (cid:16) (cid:0) If a router at location (cid:24)(cid:11) (cid:26)  is utilized to route an edge (cid:14), at least one of its adjacent routers that is closer to the sink node, should also be utilized in the route. Assuming that router (cid:20)(cid:0)(cid:10)(cid:2) is considered, and locations that take the router close to sink are (cid:20)(cid:0)(cid:10)(cid:2)(cid:3)(cid:10)(cid:8) , and (cid:20)(cid:0)(cid:3)(cid:10)(cid:2)(cid:10)(cid:8) , we need the following inequality. (cid:7)(cid:24)(cid:11) (cid:26) (cid:0) )(cid:8) (cid:11) (cid:20)(cid:0)(cid:10)(cid:2)(cid:3)(cid:10)(cid:8)  (cid:20)(cid:0)(cid:3)(cid:10)(cid:2)(cid:10)(cid:8)   (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:8) (cid:12) (cid:18) SPR (tbd trace list) for t (cid:1) tbd trace list for e (cid:1)  /* For all physical links in  */ if ((cid:7)(cid:8)  (cid:7) (cid:21) (cid:8)) /* BW violation */ edge weight(e) = (cid:4) else edge weight(e) = 1 end if end for shortest path((cid:10)  (cid:10) (cid:5)) end for end Fig. 11. Shortest path router Benchmark Nodes Edges dsp 263 encoder mp3 encoder mpeg4 mwd vopd mp3 enc mp3 dec 263 dec mp3 dec 263 enc mp3 enc 263 enc 263 dec 6 7 8 12 12 12 13 14 15 16 5 7 8 13 13 13 12 12 17 17 Power ((cid:3)(cid:4) ) 1686 172.6 6.48 7392.18 993.6 2611.1 9.15 11.98 181.6 159.5 Routers 2 2 3 5 3 5 4 5 4 5 TABLE I R E S U LT S (cid:0) If a router is utilized to route an edge, it should be present in the ﬁnal solution. Therefore, (cid:7)(cid:22) (cid:11) (cid:20)(cid:0)(cid:10)(cid:2) (cid:12) (cid:20)(cid:0)(cid:10)(cid:2)(cid:10)(cid:1) The objective function makes sure that if a router is not utilized in routing any edge, the corresponding (cid:20)(cid:0)(cid:10)(cid:2) will be set to zero. 1) Randomized rounding technique: The randomized rounding technique operates as follows. Initially, we solve the LP, and ﬁx all (cid:20)(cid:0)(cid:10)(cid:2) variables that are assigned a value 1. Among the variables that have fractional values, we randomly pick a variable, and assign it to 1 with a probability given by the fractional value of the variable. The LP is solved again and the randomized rounding step is repeated until all variables are either set to 0 or 1. At the end of the routing phase, there might be links that violate bandwidth constraints. We un-map the traces with minimum bandwidth requirement from these links, and reroute them by invoking Dijkstra’s shortest path algorithm. The re-routing technique is described in the following paragraph. 2) Shortest path router: The shortest path router (SPR) is called for each trafﬁc trace that is unmapped at the end of RT phase. SPR attempts to ﬁnd alternate routes for these traces. For each trace in (cid:4)(cid:29) (cid:27)#(cid:14)  (cid:24), SPR sweeps all possible links  of the physical layout grid. It assigns an edge weight of (cid:14) to all links that would see a bandwidth violation on the ports constituting the links, if the trace was routed through that link. These links are not utilized to generate the route for the trace. This step is followed by calling Dijkstra’s shortest path algorithm to ﬁnd a route for the trace on the mesh. IV. RE SULT S We present and analyze the experimental results obtained by execution of our technique on representative multimedia applications. We ﬁrst discuss the benchmark applications, the 236 vu 0.5 190 au 60 600 mem 1 910 mem2 32 670 upsp 0.5 dsp cpu 600 rast 40 mem 3 193 bab idct 250 500 risc Fig. 12. MPEG 4 decoder CTG risc dct mem 3 dsp bab au rast upsp cpu mem 1 vu mem 2 Fig. 13. Floorplan and NoC architecture experimental setup, and ﬁnally, we present and discuss the results. A. Benchmark applications We generated custom NoC architectures for six combinations of four multimedia benchmarks namely, mp3 audio encoder, mp3 audio decoder, H.263 video encoder, and H.263 video decoder. The applications were obtained from the work presented by Hu et al. [11]. In addition, we obtained results for four other benchmarks namely, mpeg4 decoder, video object plane decoder (vopd), multi-window display (mwd), and DSP ﬁlter application (dsp). The mpeg4 decoder, vopd, and mwd applications were obtained from [4], and the dsp application was obtained from [9]. B. Experimental setup We estimated the power consumption for the input and output trafﬁc of a port in 100  technology to be (cid:0)(cid:1)(cid:2)(cid:1)(cid:2) (cid:4) and (cid:3)(cid:4)(cid:7)(cid:4)(cid:1)(cid:2) (cid:4), respectively. We estimated the link power consumption to be equal to (cid:5)(cid:6)(cid:7)(cid:6)(cid:1)(cid:2) (cid:4)(cid:2). All results were obtained on a 950 MHz dual sparc processor. We utilized the XPRESS-MP solver [18] to generate our LP solutions. C. Results and discussion The LP formulations of CMT technique generated integer solutions for all benchmarks. Since the solution generated by LP is less than or equal to the that generated by the integer version, we conclude that the integer solutions generated by our CMT formulations are optimal. The solutions of the RT formulation required at most 3 iterations of rounding to generate the ﬁnal design. The results are presented in Table I. In the table, the ﬁrst column describes the benchmark application, the second and third columns present the size of the benchmark in terms of nodes and edges respectively, the fourth column presents the power consumption of the NoC, and the ﬁfth column presents the number of routers in the solution. An LP formulation can be solved in polynomial time, and in all our test cases, the LP generated results in fraction of a second. The communication trace graph for MPEG4 decoder is shown in Figure 12. In the graph, the nodes denote processing cores, and the edges are annotated by bandwidth requirement in Mbps. Figure 13 shows the physical layout and NoC architecture for the MPEG4 decoder application. V. CONCLU S ION In this paper, we proposed a novel three phase automated ﬂoorplanning and synthesis technique for generation of application speciﬁc custom on-chip interconnection architectures. Our technique utilizes a low complexity slicing tree based ﬂoorplanner, and linear programming based techniques for core to router mapping and routing of communication traces. Our linear programming based techniques are able to generate optimal results for node to router mapping stage. We demonstrated that the complexity of our techniques is low, and as stated in the results section, the techniques are able to generate solutions in less than a second. ACKNOWL EDGEMENT The research presented in this paper was supported in part by a grant from the National Science Foundation (IIS0308268) and Consortium of Embedded Systems "
2006,Designing application-specific networks on chips with floorplan information.,"With increasing communication demands of processor and memory cores in systems on chips (SoCs), scalable networks on chips (NoCs) are needed to interconnect the cores. For the use of NoCs to be feasible in today's industrial designs, a custom-tailored, application-specific NoC that satisfies the design objectives and constraints of the targeted application domain is required. In this work, we present a design methodology that automates the synthesis of such application-specific NoC architectures. We present a floorplan aware design method that considers the wiring complexity of the NoC during the topology synthesis process. This leads to detecting timing violations on the NoC links early in the design cycle and to have accurate power estimations of the interconnect. We incorporate mechanisms to prevent deadlocks during routing, which is critical for proper operation of NoCs. We integrate the NoC synthesis method with an existing design flow, automating NoC synthesis, generation, simulation and physical design processes. We also present ways to ensure design convergence across the levels. Experiments on several SoC benchmarks are presented, which show that the synthesized topologies provide a large reduction in network power consumption (2.78 times on average) and improvement in performance (1.59 times on average) over the best mesh and mesh-based custom topologies. An actual layout of a multimedia SoC with the NoC designed using our methodology is presented, which shows that the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC from input specifications to layout in 4 hours, a process that usually takes several weeks","Designing Application-Speciﬁc Networks on Chips with Floorplan Information Srinivasan Murali(cid:1) , Paolo Meloni§ , Federico Angiolini‡ , David Atienza†+ , Salvatore Car ta¶ , Luca Benini‡ , Giovanni De Micheli† , Luigi Raffo§ (cid:1)CSL, Stanford University, Stanford, USA, smurali@stanford.edu §DIEE, University of Cagliari, Cagliari, Italy, {paolo.meloni, luigi}@diee.unica.it ‡DEIS, Univerity of Bologna, Bologna, Italy, {fangiolini, lbenini}@deis.unibo.it ¶DMI, University of Cagliari, Cagliari, Italy, salvatore@unica.it † LSI, EPFL, Lausanne, Switzerland,{david.atienza, giovanni.demicheli}@epﬂ.ch +DACYA, Complutense University of Madrid (UCM), Madrid, Spain. ABSTRACT With increasing communication demands of processor and memory cores in Systems on Chips (SoCs), scalable Networks on Chips (NoCs) are needed to interconnect the cores. For the use of NoCs to be feasible in today’s industrial designs, a custom-tailored, application-speciﬁc NoC that satisﬁes the design objectives and constraints of the targeted application domain is required. In this work, we present a design methodology that automates the synthesis of such application-speciﬁc NoC architectures. We present a ﬂoorplan aware design method that considers the wiring complexity of the NoC during the topology synthesis process. This leads to detecting timing violations on the NoC links early in the design cycle and to have accurate power estimations of the interconnect. We incorporate mechanisms to prevent deadlocks during routing, which is critical for proper operation of NoCs. We integrate the NoC synthesis method with an existing design ﬂow, automating NoC synthesis, generation, simulation and physical design processes. We also present ways to ensure design convergence across the levels. Experiments on several SoC benchmarks are presented, which show that the synthesized topologies provide a large reduction in network power consumption (2.78× on average) and improvement in performance (1.59× on average) over the best mesh and mesh-based custom topologies. An actual layout of a multimedia SoC with the NoC designed using our methodology is presented, which shows that the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC from input speciﬁcations to layout in 4 hours, a process that usually takes several weeks. Keywords Networks on chips, deadlock-free routing, topology, ﬂoorplan 1. INTRODUCTION With technology scaling, the number of processor, memory and hardware cores on a chip is increasing. This has resulted in increased computation and communication complexity of the design, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. ICCAD’06, November 5-9, 2006, San Jose, CA Copyright 2006 ACM 1-59593-389-1/06/0011 ...$5.00. 355 and scalable approaches are needed to design the system. Networks on Chips (NoCs) have emerged as the paradigm for designing scalable communication architecture for Systems on Chips (SoCs) [4], [5]. In NoCs, instead of the traditional non-scalable buses, on-chip micro-networks are used to interconnect the various cores. NoCs have better modularity and design predictability when compared to bus based systems. Some of the most important phases in designing the NoC are the synthesis of the topology or structure of the network and setting of various design parameters (such as frequency of operation or link-width). The standard topologies (mesh, torus, etc.) that have been used in macro-networks result in poor performance and have large power and area overhead when used for SoCs. Such topologies are required for on-chip systems where the trafﬁc characteristics of the system cannot be predicted statically, as in chipmultiprocessors. However, for most SoCs the system is designed with static (or semi-static) mapping of tasks to processors and hardware cores and hence the communication trafﬁc characteristics of the SoC can be obtained statically. This is true from SoC designs that are small to state-of-the art SoCs, such as, the Philips Nexperia platform [1], ST Nomadik [2], TI OMAP [3], etc. Another motivation for the use of NoCs is the fact that the interconnect structure and wiring complexity can be well controlled. When the interconnect is structured, the number of timing violations that occur during the physical design (ﬂoorplanning and wire routing) phase is minimum. Such design predictability is critical for today’s SoCs for achieving timing closure. It leads to faster design cycle, reduction in the number of design re-spins and faster time-to-market. As the wire delay as a fraction of gate delay is increasing with each technological generation, having shorter wires is even more important for future SoCs. Early works on NoC topology design assumed that using regular topologies (such as mesh) would lead to regular and predictable layouts [16]. While this may be true for designs with homogeneous processing cores and memories, this is not true for most SoCs as they are typically composed of heterogeneous cores. This is due to the fact that the core sizes of the SoC are highly non-uniform and the ﬂoorplan of the design does not match the regular, tile-based ﬂoorplan of standard topologies [7]. An application-speciﬁc NoC with structured wiring, which satisﬁes the design objectives and constraints is important to have feasible NoC designs. As a motivating example, the network power consumption (switch and link power consumption), hop-count, wire-length and design area of two different NoC topologies for a video processor SoC with 42 cores is presented in Table 1. The ﬁrst topology is a Table 1: Topology Comparisons Parameter Mesh Application-speciﬁc Power (mW) 301.78 79.64 Hop-Count 2.58 1.67 Total wire-length (mm) 185.72 145.37 Design Area (mm2 ) 51.0 47.68 mesh, while the second is a custom topology generated using the methodology presented in this paper. The wire-lengths and design area are obtained from ﬂoorplanning of the NoC designs. The detailed explanation of the topologies and the ﬂoorplanning process is described later in this paper (Sections 5, 6 B). The custom topology leads to a 3.8× reduction in network power consumption, a 1.55× reduction in average hop-count and a 1.28× reduction in total length of wires when compared to the mesh. In this work, we present a methodology to design the best topology that is tailor-made for a speciﬁc application and satisﬁes the communication constraints of the design. Our topology design process supports two objective functions: minimizing network power consumption and hop-count for data transfer. The designer can optimize for one of the two objectives or a linear combination of both. The topology design process supports constraints on several parameters such as the hop-count (when the objective is power minimization), network power consumption (when the objective is hop-count minimization), design area and total wire-length. The topology synthesis process uses a ﬂoorplanner to estimate the design area and wire-lengths. The wire-length estimates from the ﬂoorplan are used to evaluate whether the designed NoC satisﬁes the target frequency of operation and to compute the power consumption of the wires. As deadlock-free routing is critical for proper operation of custom topologies, we integrate methods to ﬁnd deadlock free paths during the topology design process. We have built accurate analytical models for power consumption and area of the network components. The power consumption values are obtained from layouts with back-annotated resistance, capacitance information and from the switching activity of the components. We also automatically tune several NoC architectural parameters (such as the NoC operating frequency, link-width) in the design process. The methodology can be streamlined with existing tool ﬂows for instantiation, synthesis, FPGA emulation and layout of the NoC design. We present ways to close the design gap across the various levels of the ﬂow: from topology design to ﬂoorplanning to simulation of the design. The methodology also supports manual intervention, if needed, at several levels (like manually setting up frequency, link-width). To the best of our knowledge, this is the ﬁrst work that presents a streamlined design methodology for NoC topology synthesis that is completely integrated with the state-of-the commercial tools for back-end physical design. Unlike all earlier works (please refer to Section 2), we present a ﬂoorplan aware topology design method for NoCs that leads to detecting timing violations on the NoC links early in the design cycle, with the resulting designs fully veriﬁed for timing correctness using standard place&route tools. This is also the ﬁrst work on custom NoC topology synthesis that guarantees a complete deadlock-free network operation without requiring special hardware mechanisms, which is critical for using NoCs in real designs. Our topology synthesis process is integrated with NoC architectural parameter setting and uses accurate switch area, power models and link power models that are obtained from layouts of the components. The presented topology synthesis process is both performance and power consumption aware, which are two of the important design objectives in SoC design. Finally, the topology design process is integrated with an existing design ﬂow and we present ways to ensure design convergence across the levels. The tool ﬂow presented automates the entire NoC design process, including topology synthesis, routing and path computation, RTL code generation and layout generation; thereby bridging an important gap in the design of application-speciﬁc NoCs. An actual layout obtained from an industrial tool (Cadence SoC Encounter [37]) of a 30-core multi-media SoC with the NoC designed using our methodology is presented in Sub-section 6 A. At the layout level, the designed NoC supports the required frequency of operation (close to 900 MHz) without any timing violations. We could design the NoC architecture from input speciﬁcations to layout in 4 hours, a process that used to take several weeks. A layout level comparison with a hand-designed architecture for this example is also presented, which shows that our automatic design methodology produces excellent results (in terms of power consumption and performance), matching those of carefully hand-crafted designs. Experiments on several SoC benchmarks show large power, performance and wire-length improvements when compared to standard topologies. Despite the very large design space considered, due to the use of fast algorithms and tools, the design process completes in reasonable time for all the experiments (see Sub-section 6 B). 2. PREVIOUS WORK A large body of research works exists in synthesizing and generating bus-based systems [9]-[14]. A ﬂoorplan-aware point-to-point link design and bus design methodologies are presented in [15] and [14]. While some of the design issues in the NoCs are similar to bus based systems (such as link-width sizing), a large number of issues such as ﬁnding the number of required switches, sizing the switches, ﬁnding routes for packets, etc. are new in NoCs. Methods to collect and analyze trafﬁc information that can be fed as input to the bus and NoC design processes have been presented in [12] and [13]. Mappings of cores onto standard NoC topologies have been explored in [16]-[19]. In [17], [19] a ﬂoorplanner is used during the mapping process to get area and wire-length estimates. Unlike the method presented here, these works only select topologies from a library of standard topologies. In [18], a uniﬁed approach to mapping, routing and resource reservation has been presented. However, the work does not explore topology design process. The NoC design process for supporting multiple applications has been presented in [20]. This research complements our work and its methods can be applied here to support multiple applications as well. Important research in macro-networks has considered the topology generation problem [21]. As the trafﬁc patterns on these networks are difﬁcult to predict, most approaches are tree-based (like spanning or Steiner trees) and only ensure connectivity with node degree constraints [21]. Hence, these techniques cannot be directly extended to address the NoC synthesis problem. Applicationspeciﬁc custom topology design has been explored earlier in [22][25]. The works from [22], [23] do not consider the ﬂoorplanning information during the topology design process. In [24], a physical planner is used during topology design to reduce power consumption on wires. However, the work does not consider the area and power consumption of switches in the design. Also, the number and size of network partitions are manually fed. In [25], a slicing tree based ﬂoorplanner is used during the topology design process. This work assumes that the switches are located at the corners of the cores and it does not consider the network components (switches, network interfaces) during the ﬂoorplanning process. Also, deadlock free routing, which is critical for custom NoC designs is not 356 User Objective: power, hop−delay, combination Constraints: area, power,  wire−length, hop−delay Application characteristics switch area, switch, link power models phase 1 phase 2 NoC Architecture Synthesis mismatch parameter switch link NI SystemC library RTL simulations RTL synthesis Placement & Routing  phase 3 FPGA emulation Layout To Fab Network  generation Processor models Figure 1: NoC Design Flow Vary NoC frequency from a range Vary link−width from a range Vary the number of switches from one to number of cores Synthesize the best topology with the particular frequency, link−width, switch−count Perform floorplan of synthesized topology, get link power consumption, detect timing violations  Choose topology that best optimizes user objectives  satisfying all design constraints Figure 2: NoC architecture synthesis (phase 2 of design ﬂow) supported in the work. Moreover, a complete design space exploration, from architectural parameter setting to simulation is not presented. Several works exist on automatically generating the Register Transfer Level (RTL) code of a designed topology for simulation and synthesis [26]-[28]. These works again complement ours, as the input to them is a designed topology. Building area, power models for on-chip networks has been addressed in [29]-[32]. 3. DESIGN FLOW Our ﬂow for designing NoCs is presented in Figure 1. In the ﬁrst phase, the user speciﬁes the objectives and constraints that should be satisﬁed by the NoC. The application trafﬁc characteristics, size of the cores, and the area and power models for the network components are also obtained (see Section 4). In the second phase of the ﬂow, which is the main contribution of this work, the NoC architecture that optimizes the user objectives and satisﬁes the design constraints is automatically synthesized. The different steps in this phase are presented in Figure 2. The steps are explained in detail in Section 5. In the outer iterations, the key NoC architectural parameters (NoC frequency of operation and link-width) are varied in a set of suitable values. The bandwidth available on each NoC link is the product of the NoC frequency and the link-width. During the topology synthesis, the algorithm ensures that the trafﬁc on each link is less than or equal to its available bandwidth value. The synthesis step is performed once for each set of the architectural parameters. In this step, several topologies with different number of switches are explored, starting from a topology where all the cores are connected to one switch, to one where each core is connected to a separate switch. The synthesis of each topology includes ﬁnding the size of the switches, establishing the connecMem ory 100 FFT 200 ARM 10 100 100 100 100 Disp lay Filter 100 IFFT v1 v4 100 100 v5 v2 200 100 100 100 100 v6 v3 100 critical stream weighted by 10 sustained traffic rates Figure 4: Core graph with sustained rates and critical streams Figure 3: Filter application tivity between the switches and connectivity with the cores, and ﬁnding deadlock-free routes for the different trafﬁc ﬂows. In the next step, to have an accurate estimate of the design area and wirelengths, the ﬂoorplanning of each synthesized topology is automatically performed. The ﬂoorplanning process ﬁnds the 2D position of the cores and network components used in the design. For this, we use Parquet, a fast and accurate ﬂoorplanner [35]. Based on the frequency point and the obtained wire-lengths, the timing violations on the wires are detected and the power consumption on the links is obtained. In the last step, from the set of all synthesized topologies and architectural parameter design points, the topology and the architectural conﬁguration that best optimizes the user’s objectives, satisfying all the design constraints is chosen. Thus, the output of phase 2 is the best application-speciﬁc NoC topology, its frequency of operation and the width of each link in the NoC. In the last phase of the design (phase 3 in Figure 1), the RTL (SystemC) code of the switches, network interfaces and links for the designed topology is automatically generated. For this, we use the ×pipes library [8], [34], a library of soft macros for the network components and the associated tool ×pipesCompiler [26] to interconnect the network elements with the cores. At this phase, we also obtain a synthesizable RTL design that can also be emulated on FPGA. From the ﬂoorplan speciﬁcation of the designed topology, the synthesis engine automatically generates the inputs for placement&routing. The placement&routing of the design is performed using SoC Encounter [37] for obtaining the layout, including the global and detailed routing of wires. The output of this phase is a complete layout of the NoC design that can be sent to a foundary. As the ﬂow has several steps, it is important to close the design gap across the different steps. To ensure that the designed topology will satisfy the timing constraints after place&route, we evaluate the wire-lengths for detecting timing violations early in the design process, i.e. during the topology synthesis phase itself. To bridge the gap between the initial trafﬁc models and the actual observed trafﬁc after simulating the designed NoC, we use a mismatch parameter. The parameter is read as part of the input speciﬁcations by the topology synthesis engine. The user can manually tune the parameter and re-design the NoC to suit the actual trafﬁc characteristics (explained in Sub-section 6 C). Several other options are also supported by the topology synthesis engine, such as support for cores with ﬁxed locations in the layout (due to pin/pad constraints). Due to lack of space, here we only present the major features of the synthesis process. 4. INPUT MODELS The trafﬁc characteristics of the application are represented by a graph [16], [17], [19], deﬁned as follows: D E FIN I T ION 1. The core graph is a directed graph, G(V , E ) with each vertex vi ∈ V representing a core and the directed edge (vi , vj ), denoted as ei,j ∈ E , representing the communication between the cores vi and vj . The weight of the edge ei,j , denoted 357 Table 2: Component Area-Power Component Parameter Analytical Experimental 4x4 area(mm2 ) 0.036 0.035 switch power(mW) 22.16 22.54 area(mm2 ) 5x5 0.048 0.047 switch power(mW) 28.38 28.70 link (2mm) power(mW) 0.57 0.57 by commi,j , represents the sustained rate of trafﬁc ﬂow from vi to vj weighted by the criticality of the communication. The set fk , ∀k ∈ 1 · · · |F |, representing the sustained rate of ﬂow between F represents the set of all trafﬁc ﬂows, with value of each ﬂow, the source (sk ) and destination (dk ) vertices of the ﬂow. The core graph for a small ﬁlter example (Figure 3) is shown in Figure 4. The edges of the core graph are annotated with the sustained rate of trafﬁc ﬂow, multiplied by the criticality level of the ﬂow, as done in [19]. We built accurate analytical models for the power consumption and area of the network components, based on the ×pipes architecture [8]. To get the power estimates, the place&route of the components is performed using SoC Encounter and accurate wire capacitances and resistances are obtained, as back-annotated information from the layout, with 0.13µm technology library. The switching activity in the network components is varied by injecting functional trafﬁc. The capacitance, resistance and the switching activity report are combined to estimate power consumption using Synopsys PrimePower [38]. A huge number of implementation runs were performed, varying several parameters such as the number of input, output ports, link-width and the amount of switching activity at the layout level. Linear regression was used to build analytical models for the area and power consumption of the components as a function of these parameters. Due to the intrinsic modularity and symmetry of NoC components, the models built are very accurate (with maximum and mean error of less than 7% and 5%, respectively) when compared to the actual values. Power consumption on the wires is also obtained at the layout level. The analytical and experimental area, power consumption values for some components (with 900 MHz frequency, link-width of 32 bits, buffer depth of 3 in the switches) are presented in Table 2. 5. DESIGN ALGORITHMS The algorithms for the topology design process are explained in this section. In the ﬁrst step of Algorithm 1, a design point θ is chosen from the set of available or interesting design points φ for the NoC architectural parameters. In our current implementation, the synthesis engine automatically tunes two critical NoC parameters: operating frequency (f reqθ ) and link-width (lwθ ). As both frequency and link-width parameters can take a large set of values, considering all possible combinations of values would be infeasible to explore. The system designer has to trim down the exploration space and give the interesting design points for the parameters. The designer usually has knowledge of the range of these parameters. As an example, the designer can choose the set of possible frequencies from minimum to a maximum value, with allowed frequency step sizes. Similarly, the link data widths can be set to multiples of 2, within a range (say from 16 bits to 128 bits). Thus, we get a discrete set of design points for φ, as done in [14]. In all our experiments, we support 8 frequency steps and 4 link-width steps, providing 32 discrete design points in the set φ. The rest of the topology design process (steps 3-15 in Algorithm 1) is repeated for each design point in φ. As the topology synthesis and mapping problem is NP-hard [22], we present efﬁcient heuristics to synthesize the best topology for the design. For each design point θ , the algorithm synthesizes topologies with different numbers of switches, starting from a design where all the cores are connected through one big switch until the design point where each core is connected to only one switch. The reason for synthesizing these many topologies is that it cannot be predicted beforehand whether a design with few bigger switches would be more power efﬁcient than a design with more smaller switches. A larger switch has more power consumption than a smaller switch to support the same trafﬁc, due to its bigger crossbar and arbiter. On the other hand, in a design with many smaller switches, the packets may need to travel more hops to reach the destination. Thus, the total switching activity would be higher than a design with fewer hops, which can lead to higher power consumption. For the chosen switch count i, the input core graph is partitioned into i min-cut partitions (step 3). The partitioning is done in such a way that the edges of the graph that are cut between the partitions have lower weights than the edges that are within a partition (refer to Figure 5(a)) and the number of vertices assigned to each partition is almost the same. Thus, those trafﬁc ﬂows with large bandwidth requirements or higher criticality level are assigned to the same partition and hence use the same switch for communication. Hence, the power consumption and the hop-count for such ﬂows will be smaller than for the other ﬂows that cross the partitions. For partitioning, we use Chaco, an efﬁcient hierarchical graph partitioning tool [36]. At this point, the communication trafﬁc ﬂows within a partition have been resolved. In steps 5-9, the connections between the switches are established to support the trafﬁc ﬂows across the partitions. In step 5, the Switch Cost Graph (SCG) is generated. D E FIN I T ION 2. The SCG is a fully connected graph with i vertices, where i is the number of partitions (or switches) in the current topology. Please note that the SCG does not imply the actual physical connectivity between the different switches. The actual physical connectivity between the switches is established using the SCG in the PATH COMPUTE procedure, which is explained in the following paragraphs. In NoCs, wormhole ﬂow control [39] is usually employed to reduce switch buffering requirements and to provide low-latency communication [6], [7]. With wormhole ﬂow control, deadlocks can happen during routing of packets due to cyclic dependencies of resources (such as buffers) [39]. We pre-process the SCG and prohibit certain turns to break such cyclic dependencies. This guarantees that deadlocks will not occur when routing packets. For ﬁnding the set of turns that need to be prohibited to break cycles, we use the turn prohibition algorithm presented in [33], [18]. The algorithm has polynomial time complexity (very fast in practice, see Section 6) and guarantees that at most 1/3 of the total number of turns would be prohibited to remove cycles. The algorithm also guarantees connectivity between all nodes in the SCG after prohibiting the turns. From the algorithm, we build the Prohibited Turn Set (PTS) for the SCG, which represents the set of turns that are prohibited in the graph. To provide guaranteed deadlock freedom, any path for routing packets should not take these prohibited turns. These concepts are illustrated in the following example: EXAM P L E 1. The min-cut partitions of the core graph of the ﬁlter example (from Figure 3) for 3 partitions is shown in Figure 5(a). The SCG for the 3 partitions is shown in Figure 5(b). After 358 Partition 1 Partition 2 v1 v4 100 100 v5 v2 200 100 100 100 100 v6 v3 100 Partition 3 p2 p1 p3 prohibited turns 0.70 0.63 p2 0.63 0.63 0.70 p1 0.63 p3 (a) Min-cut partitions (b) SCG graph (c) Path selection Figure 5: Algorithm examples applying the turn prohibition algorithm from [33], the set of prohibited turns is identiﬁed. In Figure 5(b), the prohibited turns are indicated by circular arcs in the SCG. For this example, both the turns around the vertex P3 are prohibited to break cycles. So no path that uses the switch P3 as an intermediate hop can be used for routing packets. Our topology synthesis process also supports freedom from another type of deadlock, known as message-level deadlock [39], by routing the trafﬁc ﬂows of the different message types in the design onto different physical links. Due to lack of space, we do not explain this in detail in this paper. 5: 6: 7: 8: Algorithm 1 Topology Design Algorithm 1: Choose design point θ from φ: f reqθ , lwθ 2: for i = 1 to |V | do 3: Find i min-cut partitions of the core graph 4: Establish a switch with Nj inputs and outputs for each partition, ∀j ∈ 1 · · · i. Nj is the number of vertices (cores) in partition i. Check for bandwidth constraint violations. Build Switch Cost Graph (SCG) with edge weights set to 0 Build Prohibited Turn Set (PTS) for SCG to avoid deadlocks Set ρ to 0 Find paths for ﬂows across the switches using function PATH COMPUTE(i, SCG, ρ, PTS, θ) Evaluate the switch power consumption and average hopcount based on the selected paths Repeat steps 8 and 9 by increasing ρ value in steps, until the hop-count constraints are satisﬁed or until ρ reaches ρthresh If ρthresh reached and hop-count not satisﬁed, go to step 2. Perform ﬂoorplan and obtain area, wire-lengths. Check for timing violations and evaluate power consumption on wires If target frequency matches or exceeds f reqθ , and satisﬁes all constraints, note the design point 14: end for 15: Repeat steps 2-14 for each design point available in θ 16: For the best topology and design point, generate information for ×pipesCompiler and Cadence SoC Encounter 11: 12: 13: 9: 10: The actual physical connections between the switches are established in step 8 of Algorithm 1 using the PATH COMPUTE procedure. The objective of the procedure is to establish physical links between the switches and to ﬁnd paths for the trafﬁc ﬂows across the switches. Here, we only present the procedure where the user’s design objective is to minimize power consumption. The procedure for the other two cases (with hop-count as the objective and with linear combination of power and hop-count as objective) follow the same algorithm structure, but with different cost metrics. An example illustrating the working of the PATH COMPUTE procedure is presented in Example 2. In the procedure, the ﬂows are ordered in decreasing rate requirements, so that bigger ﬂows are assigned ﬁrst. The heuristic of assigning bigger ﬂows ﬁrst has been shown to provide better results (such as lower power consumption 359 Algorithm 2 PATH COMPUTE(i, SCG, ρ, PTS, θ) 1: Initialize the set P H Y (i1, j 1) to false and Bw avail(i1, j 1) to f reqθ × lwθ , ∀ i1, j 1 ∈ 1 · · · i 2: Initialize switch size in(j ) and switch size out(j ) to Nj , ∀ j ∈ 1 · · · i. Find switching activ ity(j ) for each switch, 3: for each ﬂow fk , k ∈ 1 · · · |F | in decreasing order of fc do based on the trafﬁc ﬂow within the partition. 4: for i1 from 1 to i and j1 from 1 to i do {Find the marginal cost of using link i1, j1} 5: {If physical link exists and can support the ﬂow} 6: 7: 8: if P H Y (i1, j 1) and Bw avail(i1, j 1) ≥ fc then Find cost(i1, j 1), the marginal power consumption to re-use the existing link else {We have to open new physical link between i1, j1} Find cost(i1, j 1), the marginal power consumption for opening and using the link. Evaluate whether switch frequency constraints are satisﬁed. end if end for Assign cost(i1, j 1) to the edge W (i1, j 1) in SCG Find the least cost path between the partitions in which source (sk ) and destination (dk ) of the ﬂow are present in the SCG. Choose only those paths that have turns not prohibited by PTS Update P H Y , Bw avail, switch size in, switch size out, switching activ ity for chosen path 9: 10: 11: 12: 13: 14: 15: 16: 17: end for 18: Return the chosen paths, switch sizes, connectivity and more easily satisfying bandwidth constraints) in several earlier works [17], [18]. For each ﬂow in order, we evaluate the amount of power that will be dissipated across each of the switches, if the trafﬁc for the ﬂow used that switch. This power dissipation value on each switch depends on the size of the switch, the amount of trafﬁc already routed on the switch and the architectural parameter point (θ) used. It also depends on how the switch is reached (from what other switch) and whether an already existing physical channel will be used to reach the switch or a new physical channel will have to be opened. This information is needed, because opening a new physical channel increases the switch size and hence the power consumption of this ﬂow and of the others that are routed through the switch. These marginal power consumption values are assigned as weights on each of the edges reaching the vertex representing that switch in the SCG. This is performed in steps 8 and 11 of the procedure. When opening a new physical link, we also check whether the switch size is small enough to satisfy the particular frequency of operation. As the switch size increases, the maximum frequency of operation it can support reduces (as the critical path inside the switch gets longer) [8]. This information is obtained from the placement&routing of the switches, taken as an input to the algorithms. Once the weights are assigned, choosing a path for the trafﬁc ﬂow is equivalent to ﬁnding the least cost path in the SCG. This is done by applying Dijkstra’s shortest path algorithm [40] in step 15 of the procedure. When choosing the path, only those paths that do not use the turns prohibited by PTS are considered. The size of the switches and the bandwidth values across the links in the chosen path are updated and the process is repeated for other ﬂows. EXAM P L E 2. For the SCG from Example 1, let us consider routing the ﬂow of value 100 between the vertices v1 and v2, across the partitions p1 and p2. Initially no physical paths have been established across any of the switches. If we have to route the ﬂow across a link between any two switches, we have to ﬁrst establish the link. The cost of routing the ﬂow across any pair of switches is obtained from step 11 of the PATH COMPUTE procedure. The SCG with the edges annotated with the costs is presented in Figure 5(c). The costs on the edges from p2 are different from the others due to the difference in initial switching activity in p2 compared to the other switches. This is because the switch p2 has to support ﬂows between the vertices v2 and v3 within the partition. The least cost path for the ﬂow, which is across switches p1 and p2 is chosen. Now we have actually established a physical path between these switches and this is considered when routing the other ﬂows. Also, the size and switching activity of these switches have changed, which is noted. The PATH COMPUTE procedure returns the sizes of the switches, connectivity between the switches and the paths for the trafﬁc ﬂows. The objective function for establishing the paths is initially set to minimizing power consumption in the switches. Once the paths are established, if hop-count constraints are not satisﬁed, the algorithm gradually modiﬁes the objective function to minimize the hop-count as well, using the parameter ρ (in steps 7, 10 and 11 of Algorithm 1). The upper bound for ρ, denoted by ρthresh , is set to the value of power consumption of the ﬂow with maximum rate, when it crosses the maximum size switch in the SCG. At this value of ρ, for all trafﬁc ﬂows, it is beneﬁcial to take the path with least number of switches, rather than the most power efﬁcient path. The ρ value is varied in several steps until the hop-count constraints are satisﬁed or until it reaches ρthresh . In the next step (step 12, Algorithm 1), the algorithm invokes the ﬂoorplanner to compute the design area and wire-lengths. The ﬂoorplanner minimizes a dual-objective function of area and wirelength, with equal weights assigned to both. The ﬂoorplanner used [35] also supports soft cores, ﬁxed pin/pad locations and aspect ratio constraints for the generated design. From the obtained wire-lengths, the power consumption across the wires is calculated. Also, the length of the wires is evaluated to check any timing violations that may occur at the particular frequency (f reqθ ). In the end, the tool chooses the best topology (based on the user’s objectives) that satisﬁes all the design constraints. At the last step, for the synthesized topology, the algorithm automatically generates the information required for the ×pipesCompiler tool for network instantiation and the SoC Encounter tool to perform placement&routing. The presented NoC synthesis process scales polynomially with the number of cores in the design. The number of topologies evaluated by the methodology also depends linearly on the number of cores. Thus, the algorithms are highly scalable to a large number of cores and communication ﬂows. The synthesis time for several different SoC benchmarks is presented in Section 6 B. 6. EXPERIMENTS AND CASE STUDIES 6.1 Layout-level Comparisons We had earlier manually developed a NoC design for a SoC that runs multi-media benchmarks [34]. The design consists of 30 cores: 10 ARM7 processors with caches, 10 private memories (a separate memory for each processor), 5 custom trafﬁc generators, 5 shared memories and devices to support inter-processor communication. The hand-designed NoC has 15 switches connected in a 5x3 quasi-mesh network (2 cores connected to each switch), shown in Figure 6(a). The design is highly optimized, with the private memories being connected to the processors across a single switch and the shared memories distributed around the switches. The layout of the design (presented in Figure 6(b)) was performed using SoC Encounter and the mesh structure was maintained in the layout. Each of the cores has an area of 1 mm2 [34] in the design. The entire process, from topology speciﬁcation to layout generation took several weeks. The post-layout NoC could support a maximum frequency of operation of 885 MHz, which is determined by the critical path in the switch pipeline. The power consumption of the topology for functional trafﬁc has been evaluated to be 368 mW. We apply our topology synthesis process with the objective of minimizing power consumption, to automatically synthesize the NoC for this application. We set the design constraints and the required frequency of operation to be the same (885 MHz) as that of the hand-designed topology. The synthesized NoC topology and the layout obtained using SoC Encounter are presented in Figures 6(c) and 6(d). The synthesized topology has fewer switches (8 switches) than the hand-designed topology. It can support the same maximum frequency of operation (885 MHz), without any timing violations on the wires. As we considered the wire-lengths during the synthesis process to estimate the frequency that could be supported, we could synthesize the most power efﬁcient topology that would still meet the target frequency. To reach such a design point manually would require several iterations of topology design and place&route phases, which is a very time consuming process. Layout level power consumption calculations on functional trafﬁc show that the synthesized topology has 277 mW power consumption, which is 1.33× lower than the hand-designed topology. Given the fact that the hand-designed topology is highly optimized, with much of the communicating trafﬁc (which is between the ARM cores and their private memories) traversing only one switch, these savings are achieved entirely from efﬁciently spreading the shared memories around the different switches. The layout of the hand-designed NoC was manually optimized to a large extent (by moving switches, network interfaces) to reduce the area of the design. The layout of the synthesized topology is obtained completely automatically, and still the area of the design is close to that of the manual design (only a marginal 4.3% increase in area). We perform cycle-accurate simulations of the hand-designed and the synthesized NoCs for two multimedia benchmarks. The total application time for the benchmarks (including computation time) and the average packet latencies for read transactions for the topologies are presented in Figures 7(a) and 7(b). The custom topology not only matches the performance of the hand-designed topology, but provides an average of 10% reduction in total execution time and of 11.3% in packet latency. 6.2 Experiments on SoC Benchmarks We have applied our topology design procedure to six different SoC benchmarks: video processor (VPROC-42 cores), MPEG4 decoder (12 cores), Video Object Plane Decoder (VOPD-12 cores), Multi-Window Display application (MWD-12 cores), Picture-inPicture application (PIP-8 cores) and IMage Processing application (IMP-23 cores). We refer the readers to [7] for the communication characteristics of some of these benchmarks. For comparison, we have also generated mesh topologies for the benchmarks by modifying the design procedure to synthesize NoCs based on mesh structure. To obtain mesh topologies, we generate a design with each core connected to a single switch and restrict the switch sizes to have 5 input/output ports. We also generated a variant of the basic mesh topology: optimized mesh (opt-mesh), where those ports and links that are unused by the trafﬁc ﬂows are removed. 360 M0 T3 T2 T1 S14 S13 S12 S11 S10 T0 M9 M8 M7 M6 P9 P8 P7 P6 P5 P4 P3 P2 P1 M5 M4 M3 M2 M1 P0 T4 (a) Hand-designed topology 6 . 5 9 m m 5.1 mm 2 1 mm (b) Layout P6 P5 P4 P3 P2 P1 M5 M4 M3 M2 M1 P0 M0 T4 T3 T2 T1 S14 S13 S12 S11 S10 T0 M9 M8 M7 M6 P9 P8 P7 (c) Automatically synthesized 5.05 mm 7 . 2 3 m m 2 1 mm (d) Layout Figure 6: (a), (b) Hand-designed topology and layout. M: ARM7 processors, T: trafﬁc generators, P, S: private and shared slaves (c), (d) Automatically synthesized topology and layout. In Figure (c), bi-directional links are solid and uni-directional links are dotted. 256B 1KB 4KB 256B 1KB 4KB 0 1 2 3 4 5 6 x 105 hand−design automatic E x e c u t i T n o i m e ( n s ) Benchmark 1 Benchmark 2 (a) Execution time (b) Average read latency Figure 7: Run time and latency for different cache sizes 256B 1KB 4KB 256B 1KB 4KB 0 50 100 150 200 250 300 A e v r e g a R y c n e a L d a e t ( s n ) hand−design automatic Benchmark 1 Benchmark 2 The core graph and the ﬂoorplan for the custom topology synthesized by our tool for one of the benchmarks (VOPD) are shown in Figure 8. The network power consumption (power consumption across the switches and links), average hop-count and design area results for the different benchmarks are presented in Table 3. Note that the average hop-count is the same for mesh and opt-mesh, as in the opt-mesh only the unused ports and links of the mesh have been removed and the rest of the connections are maintained. The custom topology results in an average of 2.78× improvement in power consumption and 1.59× improvement in hop-count when compared to the standard mesh topologies. The area of the designs with the different topologies is similar, thanks to efﬁcient ﬂoorplanning of the designs. It can be seen from Figure 8 that only very little slack area is left in the ﬂoorplan. This is because we consider the area of the network elements during the ﬂoorplanning process, and not after the ﬂoorplanning of blocks. The total run time of the topology synthesis and architectural parameter setting process for the different benchmarks is presented in Table 3. Given the large problem sizes and very large solution space that is explored (8 different frequency steps, 4 different link-widths, 42 cores for VPROC and several calls to the ﬂoorplanner) and the fact that the NoC parameter setting and topology synthesis are important phases, the run-time of the engine is not large. This is mainly due to the use of hierarchical tools for partitioning and ﬂoorplanning and our development of fast heuristics to synthesize the topology. We also performed comparisons of synthesized topology against several other standard topologies. For mapping the cores onto the standard topologies, we use the tool from [17]. As the power libraries used for switches, links in the tool are different from the Table 3: Comparisons with standard topologies Appl Topol. Power Avg. Area Time (mW) Hops mm2 (mins) 79.64 1.67 47.68 68.45 301.8 2.58 51.0 136.1 2.58 50.51 27.24 1.5 13.49 96.82 2.17 15 60.97 2.17 15.01 30.0 1.33 23.56 95.94 2.0 23.85 46.48 2.0 23.79 20.53 1.15 15 90.17 2.0 13.6 38.60 2.0 13.8 11.71 1 8.95 59.87 2.0 9.6 24.53 2.0 9.3 52.13 1.44 29.66 198.9 2.11 29.4 80.15 2.11 29.4 custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh custom mesh opt-mesh VPROC 4.04 MPEG4 4.47 VOPD 3.21 MWD 2.07 PIP 31.52 IMP ones used in the synthesis process, we optimized the topologies for performance, subject to the design constraints. The comparisons against 5 standard topologies (mesh, torus, hypercube, Clos and butterﬂy) for an image processing benchmark with 25 cores is presented in Figure 9. The custom topology synthesized by 1.73×) over the standard topologies. our method shows large performance improvements (an average of As an interesting observation, we found that prohibiting certain turns to avoid deadlocks during routing had a negligible impact on the power and performance results for all of the benchmarks. This was because, even if some turns were avoided, the path computation procedure could easily ﬁnd other paths with low cost, as several alternative low cost paths exist between each source and destination in the SCG (refer to Section 5). 6.3 Handling Dynamic Effects When the designed NoC is simulated, there can be some mismatch between the observed trafﬁc patterns and the initial trafﬁc estimates. This may be either because of inaccurate trafﬁc models or because of dynamic effects, such as congestion. Note that it will be too time consuming to simulate each topology during the synthesis process. To bridge the gap between topology synthesis and simulation, we use the mismatch parameter; the input trafﬁc rates are multiplied by the value of this parameter. The parameter is fed as an input to the synthesis engine. It is initially set to 1 and the user can manually tune the parameter and re-design the NoC, until the simulations satisfy the required performance level. The 361               y l a e D p o H e g a r e v A 3 2.5 2 1.5 1 0.5 0 Mesh Tor Hyp Clos Bfly Cust ) s n n i ( y c n e a L t t e k c a P e g a r e v A 150 100 50 1 1.25 Mismatch parameter 1.5 1.75 2.0 Figure 8: VOPD custom topology ﬂoorplan and core graph effect of increasing the parameter on performance for the MPEG4 NoC is presented in Figure 10. Extensions of the concept to handle localized congestion effects in the NoC are currently underway. 7. CONCLUSIONS To have a power and latency efﬁcient design, the communication architecture should closely match the application trafﬁc characteristics, satisfying the different design constraints. Synthesizing such Network on Chip (NoC) architecture is non-trivial, given the large design space that needs to be explored. In this work, we have presented a methodology that automates the process, generating efﬁcient NoCs that satisfy the design constraints of the application. To have fewer design re-spins and faster time-to-market, we consider fast and accurate ﬂoorplan information early in the design cycle. This leads to detecting timing violations on the NoC links during the NoC synthesis phase, thereby leading to timing closure with quicker convergence between the high level design and the physical design phases. We use accurate switch and link power models that are based on layouts of the components and accurate link power estimates based on the wire-lengths obtained from ﬂoorplanning. We also integrate deadlock free routing methods in the NoC synthesis process, which is critical for proper NoC operation. Experiments on several SoC benchmarks show that the synthesized topologies are much better (an average of 2.78× power reduction, 1.59× hop-count reduction) than the best mesh topology and meshbased custom topologies for our case studies. 8. "
2007,Slot allocation using logical networks for TDM virtual-circuit configuration for network-on-chip.,"Configuring time-division-multiplexing (TDM) virtual circuits (VCs) for network-on-chip must guarantee conflict freedom for overlapping VCs besides allocating sufficient time slots to them. These requirements are fulfilled in the slot allocution phase. In the paper, we define the concept of a logical network (LN). Based on this concept, we develop and prove theorems that constitute sufficient and necessary conditions to establish conflict-free VCs. Using these theorems, slot allocation for VCs becomes a procedure of computing LNs and then assigning VCs to different LNs. TDM VC configuration can thus be predictable and correct-by-construction. We have integrated this slot allocation method into our multi-node VC configuration program and applied the program to an industrial application.","Slot Allocation Using Logical Networks for TDM Virtual-Circuit Conﬁguration for Network-on-Chip Zhonghai Lu and Axel Jantsch Department of Electronic, Computer and Software Systems, Royal Institute of Technology, Sweden Email:{zhonghai,axel}@kth.se Abstract— Conﬁguring Time-Division-Multiplexing (TDM) Virtual Circuits (VCs) for network-on-chip must guarantee conﬂict freedom for overlapping VCs besides allocating sufﬁcient time slots to them. These requirements are fulﬁlled in the slot allocation phase. In the paper, we deﬁne the concept of a logical network (LN). Based on this concept, we develop and prove theorems that constitute sufﬁcient and necessary conditions to establish conﬂict-free VCs. Using these theorems, slot allocation for VCs becomes a procedure of computing LNs and then assigning VCs to different LNs. TDM VC conﬁguration can thus be predictable and correct-by-construction. We have integrated this slot allocation method into our multi-node VC conﬁguration program and applied the program to an industrial application. I . IN T RODUC T ION In Network-on-Chip (NoC), routing packets may bring about unpredictable performance due to contention for shared links and buffers. To overcome the nondeterminism, researchers proposed various resource reservation and priority-based scheduling mechanisms to achieve Quality of Service (QoS), i.e., to provide guarantees in latency and bandwidth. The Æthereal [1] and Nostrum [2] NoCs establish Time-Division-Multiplexing (TDM) virtual circuits (VCs) to offer guaranteed services. The Æthereal VC, which is developed for a network using buffered ﬂow control, is open-ended. The Nostrum VC, which is designed for a network employing bufferless ﬂow control, is closed-loop. Both networks operate synchronously. The Mango [3] NoC realizes guarantees in an asynchronous (clockless) network by reserving virtual channels for end-to-end connections and using priority-based scheduling in favor of connections in switches. Alternatively, QoS may be achieved through trafﬁc classiﬁcation in combination with a differentiated service. For example, the QNoC [4] characterizes trafﬁc into four priority classes, and switches make priority-based switching decisions. VC is a connection-oriented technique in which a deterministic path must be established and associated resources are pre-allocated before packet delivery can start. A TDM VC means that each node along the path conﬁgures a time-sliced routing table to reserve time slots for input packets to use output links. This reservation is accomplished in the connection setup phase. In this way, VCs multiplex link bandwidth in a time division fashion. As long as a VC is established, packets sent over it, called VC packets, encounter no contention and thus have guarantees in latency and bandwidth. In a network delivering both Best-Effort (BE) and guaranteed-service trafﬁc, BE packets utilize resources that are not reserved by VCs. Conﬁguring VCs involves (1) path selection: This has to explore the network path diversity. As a VC has a number of alternative paths, conﬁguring a set of VCs involves an extremely large design space. The space increases exponentially with the number of VCs; (2) slot allocation: Since VC packets must not contend with each other, VCs must be conﬁgured so that an output link of a switch is allocated to one VC per time slot, i.e., VCs are contention free. In addition, they must be equipped with sufﬁcient slots, thus sufﬁcient bandwidth. In the paper, we address the TDM VC conﬁguration with focus on the slot allocation problem. Current approaches to this problem ([5], [6], [7], [8]) are somewhat ad hoc. The slot allocation problem has been treated as a purely scheduling problem for which a complicated scheduling method is designed. Such methods locally schedule available slots to a set of sorted VCs one by one. The scheduling method guarantees the exclusive use of slots and sufﬁcient slots. While such approaches are intuitive, they lack formal underpinning on the contention analysis and avoidance. As a result, the scheduling is non-trivial and can be an error-prone process. In contrast, we have furthered the investigations by looking into the fundamental reason of contention. We resort to a formal approach by deﬁning the concept of a Logical Network (LN) and developing theorems to guide the construction of conﬂict-free and bandwidth-satisﬁed VCs. Based on these theorems, LNs can be formally partitioned and constructed, and slot allocation is a well-controlled process of VC-to-LN assignment, i.e., assigning VCs to different LNs. The rest of the paper is organized as follows. We outline the related work in Section II. In Section III, we describe the two types of on-chip TDM VCs, namely, open-ended and close-looped VCs. Using LNs to construct contention-free and bandwidth-satisﬁed VCs is exempliﬁed in Section IV. Then we present formal underpinning for the LN-based slot allocation in Section V. In Section VI, we detail how to perform slot allocation via VC-to-LN assignment. An industrial case study is reported in Section VII. Finally we conclude the paper in Section VIII. I I . R E L AT E D WORK As mentioned previously, proposals dealing with the slot allocation problem can be found in [5], [6], [7] and [8]. In [5], the trafﬁc model assumes periodic messages and all message ﬂows have the same period. The scheduling algorithm for slot allocation must guarantee that latency and bandwidth requirements are fulﬁlled. In case a solution is not found, non-minimal VC paths are explored. This method is integrated into a framework unifying IP-to-node mapping, path selection and slot allocation in [6]. In [8], the scheduling method is strengthened by considering slot sharing and using the estimated knowledge of possible contentions while allocating slots to VCs. Besides, to use ﬂexible routing in a network, messages within a ﬂow are scheduled individually and may use different routes. Consequently, the message scheduling is complicated because it has also to ensure the correct message ordering. In [7], dynamic slotallocation methods are presented to dynamically perform both routing and allocation of slots at run-time to establish guaranteed connections. These approaches above only derive sufﬁcient but not necessary conﬁgurations because they lack formal analysis on the contentions and their avoidance. In our approach, we formally derive and proof the sufﬁcient and necessary conditions for conﬂict analysis and avoidance. Using these theorems, the slot allocation can be conducted predictably and in well-deﬁned steps. 1 4 2 4 4 1 3 8 2 6 / 0 7 / $ 2 5 . 0 0   © 2 0 0 7   I E E E 1 8 The core concept for our slot allocation method is LN, which generalizes the concepts of admission class [10] and Temporally Disjoint Network (TDN) [2]. As with LNs, packets belonging to different classes or TDNs do not collide with each other. Admission classes and TDNs are essentially LNs. Comparing with an admission class, a LN takes not only time slots but also the VC path into consideration, thus the VC path-overlapping scenarios can be studied. Comparing with a TDN, a LN is locally deﬁned for a group of overlapping VCs, which can be open-ended or closed-loop. A TDN can be viewed as a special case of a LN in the closed-loop VC when it is globally set up for all overlapping and non-overlapping VCs. I I I . TDM - BA S E D V IRT UA L C I R CU I T S IN NOC S A. Open-ended VCs The on-chip TDM VCs assume that the network is packetswitched, and nodes share the same notion of time. They have the same clock frequency but not phase [9]. The time unit is slot. Since VC packets encounter no contention, they synchronously advance one step per time slot and never stall, using consecutive slots in consecutive switches. A node must conﬁgure a routing table for VC packets such that no simultaneous use of shared resources is possible. The routing table, by conﬁguration, knows the time slot when a VC packet reaches which inport, and addressing information about which outport to use. In effect, the routing function partitions the link bandwidth and avoids contention. Figure 1 shows two VCs, v1 and v2 , and the respective routing tables for the switches. The output links of a switch are connected to a buffer or register. A routing table (t , in, out ) is equivalent to a routing or slot-allocation function R(t , in) = out , where t is time slot, in an inport, and out an outport. v1 passes switches sw1 and sw2 through buffers {b1 → b2 }; v2 passes switches sw3 and sw2 through {b3 → b2 }. The Æthereal NoC [1] proposes this type of VC for QoS. As the path of such a VC is not a loop, we call it open-ended. b1 sw1 v1 in out t 2k W E W N S E v2 sw3 b3 sw2 b2 in out t 2k S E 2k+1 W E in t 2k+1 W N out Fig. 1. Open-ended virtual circuits In open-ended VCs, packets may be partitioned into target classes to avoid contention. With respect to a buffer b, a target class is the set of packets that will occupy slot d in a slot window D. This set of packets may come from any network node as long as they will take slot d in a slot window D of buffer b. As a target class owns dedicated slots of buffers, packets of different classes do not collide. A target class has a reference buffer whereas an admission class [10] does not. It can be viewed as a special case of the admission class. The union of all the target classes for all buffers in the network gives the corresponding admission class. By globally orchestrating the packet admission, contention can be avoided for packets belonging to different VCs. As illustrated in Figure 1, v1 and v2 only overlap in b2 , denoted v1 ∩ v2 = {b2 }. v1 packets are admitted on even slots of b1 . In sw1 , (2k,W, E ) means that sw1 reserves its E (East) output link at slots 2k (k ∈ N) for its W (West) inport (R(2k,W ) = E ). As we can also see, v2 packets are admitted on odd slots 2k + 1 of b3 , and sw3 conﬁgures its odd slots for v2 . Since a v1 packet reaches sw2 one slot after reaching sw1 , sw2 assigns its odd slots to v1 . Similarly, sw2 allocates its even slots to v2 . As v1 and v2 alternately use the shared buffer b2 and its associated output link, v1 and v2 do not conﬂict. B. Container-based Closed-loop VCs The Nostrum NoC [2] also suggests a TDM VC for QoS. However, a Nostrum VC has a cyclic path, i.e., a closed loop. On the loop, at least one container is rotated. A container is a special packet used to carry data packets, like a vehicle carrying passengers. The reason to have a loop is due to the fact that Nostrum uses deﬂection routing [10] whereas switches have no buffer queues. An incoming packet is either sunk or has to be switched out occupying one outgoing link. Since all outgoing links of a switch might be occupied by all incoming packets, a looped container ensures that there is an output link available for locally admitting a VC packet into the container, thus the network. VC packets are loaded into the container from a source, and copied (for multicast) or unloaded at the destination, bypassing other switches. Similarly to open-ended VCs, containers as VC packet carriers have higher priority than BE packets and do not contend with each other. t in out 4k ES 4k+2 S E t 4k+1 4k+3 2k in out E N E N E E sw1 b2 sw2 v1 T DN0 b3 N v2 T DN1 w b4 T DN0 b0 S sw3 b1 sw4 in out t 4k+1 W S 4k+3 W S E in out t 2k+1 W W 4k N W 4k+2 N W Fig. 2. Closed-loop virtual circuits The Nostrum VC [2] uses TDNs to ensure conﬂict freedom. In [2], TDNs are descriptively rather than formally deﬁned. TDNs are independent of VC paths. They are globally set up in a network. The number of TDNs depends on the network topology and the buffer stages in the switches [2]. For example, as shown in Figure 2, in a mesh network with one buffer per outport in the switches, exactly two TDNs exist, T DN0 and T DN1 . To allow more TDNs, more buffers in the switches must be used. For example, placing two buffers in the switches, one at the inport, the other at the outport, results in four sw3 , sw4 , sw1 and sw2 through {b0 → b1 → b2 → b3 → b0 }; v2 loops TDNs. In Figure 2, two VCs, v1 and v2 , are conﬁgured. v1 loops on on sw3 and sw4 through {b0 → b4 → b0 }; and v1 ∩ v2 = {b0 }. v1 and v2 subscribe to T DN0 and T DN1 , respectively. Besides, v1 launches two containers and v2 one container. The resulting routing tables for switches are also shown in Figure 2. Since TDNs are temporally disjoint, overlapping VCs allocated on different TDNs are free from conﬂict. IV. S L OT A L L OCAT ION U S ING LN S A. An Overview of Slot Allocation in a VC Conﬁguration Flow Figure 3 sketches a VC conﬁguration ﬂow. The input to the ﬂow is a VC speciﬁcation set. A VC allows having multiple sources and destinations (multi-node VC, see examples in Section VII.B). The output is a set of TDM VC implementations, which can be either open-ended or closed-loop. The conﬁguration consists of path selection and slot allocation. Both problems are interdependent. They are also orthogonal. The VC conﬁguration is likely iterative until a 1 9 Path selection Terminate Y VC implementation (open−ended/closed−loop) Section IV.C (Avoid conflict) Slot partitioning Slot mapping Section IV.D (Satisfy bandwidth) Bandwidth conversion VC−to−LN assignment Slot refinement Multi−node VC  specification set Slot allocation Section IV.B The problem N Fig. 3. Slot allocation in a VC conﬁguration ﬂow termination condition is met. In this paper, we only brieﬂy introduce our path selection method in Section VII-A. Assuming that the path selection is done, we focus on the slot allocation problem. In the following of this section, we ﬁrst formulate the slot allocation problem in Section IV-B. Then we illustrate the concept of the LN by exemplifying the LN construction for conﬂict freedom in Section IV-C. Then we show how to satisfy bandwidth demand using LNs in Section IV-D. We shall see that our method is applicable to both open-ended and closed-loop VCs. B. The Slot-Allocation Problem Formulation We ﬁrst introduce deﬁnitions, and then deﬁne the problem. Deﬁnition 1: A network is a directed graph G = M × E , where each vertex mi ∈ M represents a node, and each edge ei ∈ E represents a link. All edges are unique. Deﬁnition 2: A VC speciﬁcation set after path selection ¯V comprises a set of VCs to be conﬁgured on the network G, ¯V = { ¯v1 , ¯v2 , · · · , ¯vn }. For each VC ¯vi ∈ ¯V , ¯vi = (mi , ¯bwi ), where: • mi ⊆ M : a subset of nodes in M to be visited by ¯vi . The node set is ordered and two consecutive nodes in mi are adjacent in the network. ¯bwi : minimum bandwidth requirement (bits/second) of ¯vi . Deﬁnition 3: A VC implementation set V comprises a set of TDM VC, V = {v1 , v2 , · · · , vn } . Each VC implementation vi ∈ V implements ¯vi , and vi = (bwi , Ri, j ), where: • bwi : the supported bandwidth (bits/second) of vi . • Ri, j : a partial routing table created for a visiting node n j by vi . ∀rz ∈ Ri, j , rz is an entry (t , ein,x , eout ,y ), specifying that node n j reserves slot t for a vi packet from input link ein,x to use output link eout ,y . R j is the routing table of n j , and R j = ∑i Ri, j . Deﬁnition 4: At node n j , a slot-allocation function R j : (T , Ein, j ) → Eout , j reserves slot t ∈ T for a VC packet from input edge ein, j ∈ Ein, j to use output edge eout , j ∈ Eout , j . Using the deﬁnitions above, we formulate the problem as follows: Given a network G and a VC speciﬁcation set ¯V , ﬁnd a VC implementation set V and determine for V a slot-allocation function R j () for each node n j , such that • ∀ein,x (cid:6)= ein,y , R j (t , ein,x ) (cid:6)= R j (t , ein,y ) (1) ¯bwi ≤ bwi ∀ edge ek , Bw(ek ) ≤ κbw (ek ) where Bw(ek ) = ∑i bwi if ek ∈ E dge(vi ) (2) (3) Condition (1) says that VC packets can not be switched to the same output link simultaneously, i.e., VCs must be conﬂict free. Condition (2) expresses that each VC’s bandwidth constraint must be satisﬁed. Condition (3) means that the total normalized (with the link capacity) bandwidth reserved by all VCs on a link cannot exceed the link bandwidth threshold κbw , which is deﬁned in terms of the link capacity and 0 ≤ κbw ≤ 1. C. Conﬂict Avoidance with LNs To convey the basic ideas of a LN before delving into formalism, we describe how conﬂict can be avoided between overlapping VCs by alternatively scheduling VCs on the use of the shared buffer(s). As we develop further, we shall see that LNs are the natural result of systematically avoiding collision between overlapping VCs. To be speciﬁc, when two VCs overlap, the conﬂict avoidance is assured through two steps: slot partitioning and slot mapping. These two steps create LNs and complete assigning VCs to LNs. We describe the two steps with a pair of closed-loop VCs (v1 , v2 ) in Figure 2. 1) Slot partitioning: As conﬂicts might occur in a shared buffer, we partition the slots of the shared buffer into sets with a regular interval. In Figure 2, b0 is the only shared buffer of v1 and v2 , v1 ∩ v2 = {b0 }. We partition the slots of b0 (b0 is called the reference buffer for v1 and v2 , Re f (v1 , v2 ) = b0 .) into two sets, an even set s2 (b0 ) for t = 2k and an odd set s2 (b0 ) for t = 2k + 1. The notation sTτ (b0 ) represents pairs (τ + kT , b0 ), which is the τth slot set of the total T slot sets, τ ∈ [0, T ) and T ∈ N. Pair (t , b0 ) refers to the slot of b0 at time instant t . 2: s (b0 ) 2ln ln 2 : s (b0 ) 0 1 2 4 6 8 3 5 7 9 0 1 1 0 3 5 7 9 2 4 6 8 3 5 7 9 2 2 2 3 4 3 5 7 9 4 6 8 4 6 8 5 6 7 8 9 0 0 0 0 1 1 1 1 t 0 1 2 4 6 8 3 5 7 9 0 2 1 (v1 , b0 ) (v2 , b0 ) (t , b4 ): (t , b0 ): (t , b1 ): (t , b2 ): (t , b3 ): Fig. 4. Creating LNs by mapping slots on VCs 2) Slot mapping: The partitioned slot sets can be mapped to slot sets of other buffers on a VC regularly and unambiguously because a VC packet or container advances one step each and every slot. For example, a v1 packet holding slot t at buffer b0 , i.e., pair (t , b0 ), will consecutively take slot t + 1 at b1 (pair (t + 1, b1 )), slot t + 2 at b2 (pair (t + 2, b2 )), and slot t + 3 at b3 (pair (t + 3, b3 )). After mapping the slot set s2 (b0 ) on v1 and s2 (b0 ) on v2 , we obtain two slot sets {s2 (b0 ), s2 (b1 ), s2 (b2 ), s2 (b3 )} and {s2 (b0 ), s2 (b4 )}. We refer to the logically networked slot sets in a set of buffers of a VC as a LN. We denote the two LNs as l n2 (v1 , b0 ) and l n2 (v2 , b0 ), respectively. l n2 (v1 , b0 ) = {s2 (b0 ), s2 (b1 ), s2 (b2 ), s2 (b3 )} and (v2 , b0 ) = {s2 (b4 )}. Let T be the number of LNs, l n2 (b0 ), s2 the notation l nTτ (v, b) represents the τth LN of the total T LNs on v with respect to b. We illustrate the mapped slot sets for s2 (b0 ) and s2 (b0 ) and the resulting LNs in Figure 4. We can also see that LNs are the result of VC assignment to slot sets, speciﬁcally, v1 to l n2 (v1 , b0 ) and v2 to l n2 (v2 , b0 ). (v1 , b0 ) ∩ l n2 (v2 , b0 ) = /0, v1 and v2 are conﬂict free, as we As l n2 shall show formally in Section V. 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 2 0 D. Bandwidth Satisfaction with LNs In addition to be contention free, VCs must satisfy their bandwidth requirements. This is achieved in three steps: bandwidth conversion, VC-to-LN assignment and slot reﬁnement. We exemplify the three steps with Figure 5 that shows three open-ended VCs, v1 , v2 and v3 . The buffer set of VCs is listed in Table 5. As can be seen, v1 ∩ v2 = {b1 }, v1 ∩ v3 = {b2 , b3 } and v2 ∩ v3 = /0. sw1 v1 time slot admit packet b1 v2 sw2 sw3 b3 b4 b2 v3 slot set: 0,2s 6 (b1 ) 1,3s 6 (b2 ) 2,4s 6 (b3 ) v1 : 0 slot set: v2 : t 1 2 4 5 7 3 6 8 9 w1=6 w1=6 (b1 ) s 1 4 v1 : 0 1 t 2 4 5 7 3 6 8 9 w1=6 w1=6 (b2 ) 8s 0,2,4 v1 : 0 1 2 4 5 7 3 6 8 w1=6 t 9 w1=6 (b3 ) 8s 1,3,5 t 9 0 1 2 4 5 7 3 6 8 w2=4 w2=4 v3 : t 9 0 1 2 4 5 7 3 6 8 w3=8 v3 : t 0 1 9 2 4 5 7 3 6 8 w3=8 Fig. 5. Packets admitted on slot sets of buffers, i.e., on LNs V C v1 v2 v3 Buf. set b1 , b2 , b3 b1 , b4 b2 , b3 bw 1/3 1/4 3/8 LN N W 2 6 1 4 3 8 0 ln2 ln2 ln2 (v1 , b1 ) (v2 , b1 ) (v3 , b2 ) TABLE I 1 0 Slot set {s6 0,2 1,3 (b1 ), s6 (b2 ), s6 {s4 (b1 ), s4 {s8 (b2 ), s8 (b3 )} (b4 )} (b3 )} 1 0,2,4 0 1,3,5 2,4 1 1 0 0 0 0 0 1 0 1 0 (b2 ) v2 , obtaining the even LN l n2 (v1 , b1 ) for v1 and the odd LN (v1 , b1 ) ∩ l n2 l n2 (v2 , b1 ) for v2 . Since l n2 (v2 , b1 ) = /0, v1 and v2 are conﬂict free. Next, we perform the VC-to-LN assignment with (v1 , v3 ). Let their reference buffer be b2 , Re f (v1 , v3 ) = b2 . Since v1 already holds even slots in b1 , it takes odd slots in b2 , i.e., s2 (b2 ). We assign the remaining even slots in b2 , i.e., s2 (b2 ), to v3 . Therefore, Nln,3 /T = 1/2 > 3/8. We are certain that the supported bandwidth sufﬁces the demand of v3 . We map the slot set s2 (v1 , b1 ) ∩ l n2 on v3 , obtaining l n2 (v3 , b2 ). As l n2 (v3 , b2 ) = /0, v1 and v3 are also conﬂict free. The VC-to-LN assignments are shown in column LN of Table I. 3) Slot reﬁnement: The success of VC-to-LN assignment for all VCs means that all VCs are conﬂict free and enough bandwidth can be reserved. But, a VC may demand only a fraction of slot sets from its assigned LNs. For instance, “v2 on l n2 (v2 , b1 )” means that v2 can use one of every two slots. But N2 = 1 and W2 = 4, v2 actually demands only one out of four slots. This means that we need to further reﬁne the supplied bandwidth. We ﬁrst ﬁnd the candidate slot sets of a reference buffer and then only assign N of them within window size W to v. For example, v3 has four candidate slot sets over b2 , s8 (b2 ). We allocate any three of the four to v3 , for instance, s8 (b2 ). These slot sets are mapped to s8 (b3 ), forming the LN l n2 (v3 , b2 ). The slot sets reserved by the three VCs are illustrated in Figure 5 and listed in column Slot set of Table I. Note that the two columns LN and Slot set of Table I are equivalent. After the three steps above, the VCs are constructed without conﬂict and with bandwidth requirements satisﬁed. In the following, we consider the Slot reﬁnement as part of step VC-to-LN assignment to make the presentation concise. 0,2,4,6 0,2,4 1,3,5 0 E. Requirements for LN-oriented Slot Allocation We have described so far three techniques: (1) establishing VCs by conﬁguring slot-sliced routing tables; (2) partitioning and mapping slots into LNs; (3) assigning VCs to different LNs. These techniques must promise conﬂict freedom and provide enough bandwidth. However, there are several key questions that are not yet addressed: • How many LNs exist when VCs overlap? LN is not global for all VCs. Instead it is local for a group of overlapping VCs. This number is crucial because it deﬁnes how to partition and then map slots. • In the examples, assigning overlapping VCs to different LNs has secured conﬂict freedom. Is it a sufﬁcient and necessary condition, in general? • LN is partitioned with respect to a reference buffer, which is a shared buffer. As overlapping VCs may have many shared buffers, how is this reference buffer selected? Are LNs with respect to all shared buffers equivalent? In the next section, we answer these questions formally. V. F ORMA L UND E R P INN ING ON LN - BA S E D S L OT A L L OCAT ION A. Assumptions and Deﬁnitions We consider static VCs, meaning that VCs do not change their paths and characteristics throughout system execution. We also assume that one LN is allocated to only one VC. But one VC may subscribe to multiple LNs. Deﬁnition 5: A VC v comprises an ordered set of buffers < b0 , b1 , b2 , · · · , bH −1 >. The size of v, denoted |v|, is the number of VC PA RAM E T E R S AND VC - TO -LN A S S I GNM EN T R E S U LT S F O R F I G . 5 1) Bandwidth conversion: We ﬁrst translate the VC bandwidth requirement in bits/second into packets/slot. As bandwidth is an average measurement, we can further scale it to N packets per W slots. W is the window size. For example, we translate bw1 = 1/3 into 2/6 (2 packets every 6 slots), i.e., N1 = 2, W1 = 6, as listed in Table I, where the bandwidth bw metric is packets/slot. 2) VC-to-LN assignment: In this step, we assign VCs to LNs pairwise using the two steps for conﬂict avoidance in Section IV-C. Additionally we must check whether their bandwidth demand can be satisﬁed. This check is conducted after the ﬁrst step slot partitioning. Given a pair of overlapping VCs, the number T of partitioned sets with respect to the reference buffer equals the number of LNs. To satisfy the bandwidth requirement of a VC v, a sufﬁcient number Nln of LNs must be allocated to v. This number can be derived from Nln = (cid:8)N T /W (cid:9)1 , because we must satisfy Nln /T ≥ N /W , where Nln /T is the bandwidth supported by the allocated LNs and N /W the requested bandwidth. The bandwidth requirements of the three VCs in Figure 5 are given in column bw of Table I. We ﬁrst perform the VC-to-LN assignment with VC pair (v1 , v2 ). Since v1 ∩ v2 = {b1 }, Re f (v1 , v2 ) = b1 . Let T = 2, we partition b1 ’s slots into odd and even sets, implying two LNs. Either VC can be allocated to one LN, i.e., Nln,1 = Nln,2 = 1, offering bandwidth Nln,1 /T = Nln,2 /T = 1/2. Since the bandwidth demand of v1 and v2 is less then 1/2, the resulting VC-to-LN assignment will meet the bandwidth constraint. Then we can continue to map the even set on v1 and the odd set on 1 (cid:8)x(cid:9) is the ceiling function that returns the least integer not less than x. 2 1 On v, d (cid:1)bi bi+1 buffers, H . d (cid:1)bi b j is the distance in number of slots2 from bi to b j . = 1, meaning that the buffers are adjacent. packets are admitted in a sequence of D (D ≥ N ) time slots. This Deﬁnition 6: The admission pattern on a VC requires that N gives a bandwidth requirement of N /D packets/slot, but the exact time slots for admitting the N packets are not speciﬁed. A packet ﬂow is deﬁned by inﬁnitely repeating the admission pattern. We call D the admission cycle. With respect to a buffer b and a natural d < D, we b at slots d + kD, ∀k ∈ N. We call d the initial distance of the target deﬁne a target class as an inﬁnite set of packets that arrive at buffer class to buffer b. For an open-ended VC, D = W , where W is the window size of a VC packet ﬂow; For a closed-loop VC, D = H , since v is a loop and a container revisits the same buffer after H slots. N is the number of containers launched on the VC. Deﬁnition 7: Two VCs v1 and v2 overlap if they share at least i.e., v1 ∩ v2 (cid:6)= /0. The two VCs conﬂict one buffer, in buffer b, denoted b ∈ v1 ∧ v2 , if and only if it is possible that two packets, one from each VC, visit buffer b at the same time. v1 ∧ v2 = /0 means that v1 and v2 are conﬂict free. Deﬁnition 8: Given a VC v =< b0 , b1 , b2 , · · · , bH −1 > and its admission cycle D, bi ∈ v, a natural 1 ≤ T ≤ D and a natural τ, 0 ≤ τ < T , we deﬁne a LN l nTτ (v, bi ) as an inﬁnite set of (time slot, buffer) pairs as follows: l nTτ (v, bi ) = {(t , b j )|t = τ + d (cid:1)bi b j + kT , 0 ≤ j < H , ∀k ∈ N} Hence, a LN is deﬁned for a given VC and one of its buffers. The number of LNs for a VC is always equal to T . The motivation of the LN is to precisely deﬁne the ﬂow of packets on the VC and each target class is dedicated to exactly one LN. The time when packets visit buffers of the VC is given by the (time slot, buffer) pairs of the LN. On a LN, every T slots a packet visits a particular buffer. Consequently, the bandwidth possessed by a LN is 1/T packets/slot. The LNs of a VC have an inherent property: if τ1 , τ2 ∈ [0, T − 1] and τ1 (cid:6)= τ2 , then packets admitted on different LNs never collide, (v, b) ∩ l nTτ2 because l nTτ1 VC v with respect to a buffer b, b ∈ v, Deﬁnition 9: A LN-cover is a complete set of LNs deﬁned for a LN−cover(v, b, T ) = {l nTτ (v, b) | 0 ≤ τ < T } Deﬁnition 10: VC-to-LN assignment/subscription: a VC v is assigned to or subscribes to l nTτ (v, b) if and only if, on v, a target class, D, satisﬁes mod (d + kD, T ) = τ, ∀k ∈ N. which has an initial distance d to buffer b and the admission cycle If a VC v does not overlap with any other VCs, the maximum number of LNs on v is D, since v allows for up to D target classes and one class uses exactly one LN. (v, b) = /0. B. Overlapping VCs Lemma 1: Let v1 and v2 be two overlapping VCs and D1 , D2 be their admission cycles, respectively. Let c1 and c2 be any two target classes on v1 and v2 with respect to a shared buffer b, respectively; d1 and d2 are the initial distances of c1 and c2 to buffer b, respectively. We have b ∈ v1 ∧ v2 iff ∃ k1 , k2 ∈ N such that d1 + k1D1 = d2 + k2D2 . Proof: (1) Sufﬁcient: We assume that ∃k1 , k2 ∈ N such that d1 + k1D1 = d2 + k2D2 (= t ). The left-hand side of the equation implies that c1 enters buffer b at time slot t , and the right-hand side implies that c2 enters b the same slot. Hence b ∈ v1 ∧ v2 . 2As one hop takes one slot to travel, we equivalently measure the distance in number of slots. b ∈ v1 ∧ v2 . For c1 , t = d1 + k1D1 ; for c2 , t = d2 + k2D2 . Therefore (2) Necessary: Suppose, after t slots, c1 and c2 collide in buffer b, d1 + k1D1 = d2 + k2D2 . (cid:13) (cid:13) (cid:13) 1 (cid:13)(cid:13) 1 (cid:13)(cid:13) 1 (cid:13)(cid:13) − k Theorem 1: Let T be the number of LNs, which two overlapping VCs, v1 and v2 , can subscribe to without conﬂict. Then T is a Common Factor (CF) of their admission cycles, D1 and D2 . Proof: Suppose that b is the reference buffer. Let l nTτ1 (v1 , b) and l nTτ2 (v2 , b) be the LN subscribed by v1 and v2 , respectively. According to Deﬁnition 10, we have τ1 = mod (d1 + k1D1 , T ) and τ2 = mod (d2 + k2D2 , T ). We start with τ1 = mod (d1 + k1D1 , T ), ∀k1 ∈ N. When k1 = 0, d1 = k 1T + τ1 ; when k1 = 1, d1 + D1 = k 1 T + τ1 and k > k 1 . From the last two equations, we get D1 = (k )T , meaning that T is a factor of D1 . Similarly, using τ2 = mod (d2 + k2D2 , T ), ∀k2 ∈ N, we can derive that T is a factor of D2 . Therefore T is a CF of D1 and D2 , i.e., T ∈ CF (D1 , D2 ). By Theorem 1, the number T of LNs for v1 and v2 can be any value in the common factor set CF (D1 , D2 ). The least number of LNs is 1. However, if the number of LNs for two VCs is 1, only one of the two VCs can subscribe to it. There is no room for the other VC. Therefore we need at least two LNs. In general, if n VCs overlap in a shared buffer, there must be at least n LNs, one for each VC, to avoid conﬂict. In order to maximize the number of options and have ﬁner LN bandwidth granularity, we consider the number T of LNs to be the Greatest Common Divisor (GCD) throughout the paper. Hence, for the two overlapping VCs, v1 and v2 , the number T of LNs equals GCD(D1 , D2 ). Theorem 2: Assigning v1 and v2 to different LNs with respect to any shared buffer is a sufﬁcient and necessary condition to avoid conﬂict between v1 and v2 . Proof: By Theorem 1, the maximum number T of LNs for v1 and v2 is T = GCD(D1 , D2 ). We can write D1 = A1T and D2 = A2T , where A1 and A2 are co-prime. By Deﬁnition 10, v1 and v2 subscribe to different LNs ⇔ mod (d1 + k1D1 , T ) (cid:6)= mod (d2 + k2D2 , T ). Since D1 = A1T and D2 = A2T , mod (d1 + k1D1 , T ) (cid:6)= mod (d2 + k2D2 , T ) ⇔ mod (d1 , T ) (cid:6)= mod (d2 , T ). (1) Sufﬁcient: mod (d1 , T ) (cid:6)= mod (d2 , T ) ⇒ d1 + k 1T (cid:6)= d2 + 2T , ∀k ∈ N. When k = k2 A2 , ∀k1 , k2 ∈ N ⇒ k d1 + k1 A1T (cid:6)= d2 + k2A2T ⇒ d1 + k1D1 (cid:6)= d2 + k2D2 . According to , k = k1A1 and k Lemma 1, v1 and v2 do not conﬂict, i.e., v1 ∧ v2 = /0. (2) Necessary: Suppose v1 ∧ v2 = /0 ⇒ d1 + k1D1 (cid:6)= d2 + k2D2 , ∀k1 , k2 ∈ N. But let us assume mod (d1 , T ) = mod (d2 , T ). Then we have d1 − d2 (cid:6)= k2D2 − k1D1 but d1 − d2 = kT , k ∈ Z. ⇒ k + k1 A1 (cid:6)= k2 A2 , ∀k1 , k2 ∈ N. However, this inequality is not always assumption cannot be true, and mod (d1 , T ) (cid:6)= mod (d2 , T ). This means true, for example, when k1 = A2 ; k2 = A1 + 1; k = A2 . Thus, our that v1 and v2 subscribe to different LNs. (cid:13) 1 (cid:13) 2 (cid:13) 1 (cid:13) 2 (cid:13) (cid:13) c1 c2 d1 d2 (cid:13) 2 d (cid:13) 1 d A B v2 v1 (a) v1 A v2 B C (b) D Fig. 6. Two or multiple shared buffers 2 2 By Theorem 2, VCs must stay in different LNs referring to any shared buffer. However, as overlapping VCs may have multiple shared buffers, LN partitioning might change with a different reference buffer. Figure 6a shows that two open-ended VCs, v1 and v2 , overlap in buffers A and B. Apparently, no conﬂict with respect to buffer A does not imply no conﬂict with respect to another buffer B. We derive the following theorem to check the reference consistency. Theorem 3: Suppose that two overlapping VCs, v1 and v2 , have two shared buffers A and B. Let the distances from buffer A to B along v1 and v2 be d (cid:1)AB (v1 ) and d (cid:1)AB (v2 ), respectively. Let the initial distance of c1 to A be d1 , to B be d 1 ; from c2 to A be d2 , to B be d 2 . Assume that c1 on v1 and c2 on v2 do not conﬂict in A, then (v1 ) − d (cid:1)AB (v2 ) = kT , where T = GCD(D1 , D2 ) and k ∈ Z, is a sufﬁcient and necessary condition for c1 and c2 to be conﬂict-free with respect to B. If so, we say the two shared buffers are consistent. − d1 and d (cid:1)AB − d2 ⇒ d (cid:1)AB Proof: d (cid:1)AB ) − (d1 − d2 ). Further, d (cid:1)AB (v1 ) − d (cid:1)AB (v2 ) = kT ⇔ mod (d , T ) = mod (d1 − d2 , T ). Condition mod (d1 , T ) (cid:6)= mod (d2 , T ) ⇔ mod (d , T ) (cid:6)= mod (d , T ). Thus c1 and c2 are conﬂict free with respect to B. (cid:13) (cid:13) d (cid:1)AB (v1 ) = d (cid:13) 1 (v2 ) = d (cid:13) 2 (v1 ) − d (cid:1)AB (v2 ) = (d (cid:13) 1 − d − d (cid:13) 2 (cid:13) 1 (cid:13) 2 (cid:13) 1 (cid:13) 2 By Theorem 3, we can further conclude that if two VCs have multiple shared buffers, all shared buffers must be consistent in order to be conﬂict-free. For instance, as shown in Figure 6b, if the two v1 ∩ v2 = {A, B,C , D} must be consistent. If the consistency is checked closed-loop VCs, v1 and v2 , have no conﬂict, then all shared buffers u = u(u − 1)/2, pair-wise, the total number of checking times is C2 where u is the number of shared buffers. However, the check can be done efﬁciently. buffers A, B,C ∈ v1 ∩ v2 . If A and B, and B and C are consistent, Theorem 4: Suppose that v1 and v2 have at least three shared then A and C are consistent. (v1 ) − d (cid:1)AB (v2 ) = k1 T . As Proof: As A and B are consistent, d (cid:1)AB (v1 ) − d (cid:1)AC A and C are consistent, d (cid:1)AC (v2 ) = k2 T . By deducting the (v1 ) − d (cid:1)AB (v2 ) − (d (cid:1)AC (v1 ) − d (cid:1)AC two equations, we have, d (cid:1)AB (k1 − k2 )T . Further, we have d (cid:1)BC (v1 ) − d (cid:1)BC (v2 ) = k3T , k3 ∈ Z. According to Theorem 3, B and C are consistent. a result, the total number of checking times is reduced to u − 1. If By Theorem 4, reference consistency may be linearly checked. As all shared buffers are consistent, any shared buffer can be used as a reference buffer to conduct LN partitioning and assignment. If they are not consistent, v1 and v2 conﬂict. In summary, we have formally answered the questions in Section IV-E. The number of LNs of two overlapping VCs, v1 and v2 , equals GCD(D1 , D2 ). Assigning VCs to different LNs is sufﬁcient and necessary to promise conﬂict freedom. If overlapping VCs have multiple shared buffers, reference consistency must be ﬁrst checked, and this check can be done linearly. If consistent, anyone of the shared buffers can be used as the reference buffer. (v2 )) = V I . T H E LN - BA S E D S L OT A L L OCAT ION ME T HOD A. The Slot Allocation Algorithm Algorithm 1 shows the pseudo code of the slot allocation method. The input is a set of n VC speciﬁcations, and the output is a set of TDM VC implementations. If the procedure returns true, the implementation set contains a TDM VC implementation for each VC speciﬁcation, and routing tables in switches. If the procedure fails, the implementation set is empty. As the slot allocation is iterative, the algorithm has a complexity of O(n2 ). The slot allocation comprises • VC-to-LN assignment: This step assigns VCs to different LNs. It is conducted pair-wise in a well-deﬁned order and incrementally. Algorithm 1 The pseudo code of LN-based slot allocation Input: Q: a set of path-deﬁned VC speciﬁcation, { ¯v1 , ¯v2 , · · · , ¯vn }. Output: S: a set of TDM VC implementation, {v1 , v2 , · · · , vn }. Initially, state(vi )=0; // vi ’s LN assignment is not conducted. bool slot allocation(Q, &S){ Sort Q by a priority criterion; for i=1 to n { for j=1 to n { if (i!=j) if (VC to LN(vi , v j )==false) // pair-wise VC-to-LN assignment return false; for i=1 to n create routing table(vi ); return true; } • Routing table creation: This step is performed only if the previous step is performed successfully. Using the VC-to-LN assignment for each VC and the VC path, we can accordingly conﬁgure routing tables in switches. Next, we detail the two steps. B. The VC-to-LN Assignment Procedure VC-to-LN assignment is the key step for the LN-based slot allocation method. We sketch the VC-to-LN procedure in Algorithm 2. The input to the algorithm is a pair of VCs, (vi , v j )3 , and their paths are known. The function returns true if VC-to-LN assignment is done successfully for both VCs, and returns false otherwise. A VC v has two conﬁguration states, either 0 or 1. ’state(v)=0’ means that VC-to-LN assignment has not performed for v yet; ’state(v)=1’ means that the VC-to-LN assignment for v is done successfully. 7 2 6 4 8 1 3 5 9 0 0 2ln ln 2 1 6 2 4 6 8 3 5 7 9 5 9 3 7 1 1 2 8 0 4 0 7 4 8 0 1 2 3 5 6 9 t 0 2ln v2 v1 v3 b1 b2 b3 (t , b1 ): (t , b2 ): (t , b3 ): (v1 , b1 ) (v2 , b1 ) (v3 , b2 ) Fig. 7. An example of VC-to-LN assignment VC v1 v2 v3 Buf. set bw 1/2 1/4 3/8 N W (D) 1 2 1 4 3 8 LN b1 , b2 b1 , b3 b2 , b3 (v1 , b1 ) = {s2 ln2 ln2 (v2 , b1 ) = {s4 (v3 , b2 ) = {s8 ln2 0 1 0 1 0,2,4 (b1 ), s2 (b1 ), s4 (b2 ), s8 1 2 1,3,5 (b2 )} (b3 )} (b3 )} 0 TABLE II VC PA RAM E T E R S AND VC - TO -LN A S S I GNM EN T R E S U LT S F O R F I G . 7 We exemplify how this VC-to-LN assignment is conducted. Figure 7, where a bubble represents a buffer, shows three VCs, v1 , v2 and v3 . Their paths and parameters are listed in Table II. As elaborated below, the VC-to-LN assignments are performed in order (v1 , v2 ), (v1 , v3 ) and (v2 , v3 ). 3VC pairs (vi , v j ) and (v j , vi ) are equivalent in the paper. 2 3 Algorithm 2 The VC-to-LN assignment procedure bool VC to LN(vi , v j ){ if (vi ∩ v j == /0) return true; if (reference consistency(vi , v j )==false) return false; // vi and v j overlap but satisfy reference consistency take any shared buffer b as the reference buffer Re f (vi , v j ) = b; compute the shared number T of LNs, T = GCD(Di , D j ); if (state(vi )==0 && state(v j )==0) { for v in {vi , v j } { // Both states are 0 compute the available LN set for v, ASln (v); compute the required number of LNs Nln (v) = (cid:8)N T /D(cid:9); if |ASln (v)| < Nln (v) return false; assign LNs from ASln to v; allocate slot sets in the assigned LNs within D to v; state(vi )=1; state(v j )=1; } return true; } if (state(vi ) != state(v j ) { // One state is 0 and the other 1 // suppose (state(vi )=0 and state(v j )=1) map v j ’s allocated slot sets to the new LN set as the consumed LN set by v j , CSln (v j ); compute the available LN set for vi , ASln (vi ); compute the required number of LNs Nln (vi ) = (cid:8)Ni Ti /Di (cid:9); if |ASln (vi )| < Nln (vi ) return false; assign LNs from ASln (vi ) to vi ; allocate slot sets in the assigned LNs within Di to vi ; state(vi )=1; return true; } if (state(vi )==1 && state(v j )==1) { // Both states are 1 map vi ’s allocated slot sets to the new LN set as the consumed LN set by vi , CSln (vi ); map v j ’s allocated slot sets to the new LN set as the consumed LN set by v j , CSln (v j ); if (CSln (vi ) ∩ CSln (v j ) == /0) return true; else return false;} 0 1) VC to LN(v1 , v2 ): Re f (v1 , v2 ) = b1 . Since D1 = 2 and D2 = 4, T = GCD(D1 , D2 ) = 2. We can partition b1 ’s slots into two logical sets. Initially, state(v1 )=0 and state(v2 )=0. The branch of “Both states are 0” is executed. We take v1 ﬁrst. The available LN set for v1 ASln (v1 ) = {0, 1}, thus |ASln (v1 )| = 2. The required number of LNs Nln (v1 ) = (cid:8)N1 T /W1 (cid:9) = 1. As |ASln (v1 )| > Nln (v1 ), there are enough LNs to support v1 bandwidth. We assign l n2 (v1 , b1 ) to v1 . The consumed LN set of v1 CSln (v1 ) = {0}. We then allocate slot sets s2 (b1 ) and s2 (b2 ) to v1 . The two sets constitute LN l n2 (v1 , b1 ). Next, we take v2 up. ASln (v2 ) = {0, 1} − CSln (v1 ) = {1}. The required number of LNs of v2 Nln (v2 ) = (cid:8)N2T /W2 (cid:9) = 1. We assign l n2 (v2 , b1 ) to v2 . Then we allocate slot sets s4 (b1 ) and s4 to v2 . After this assignment, state(v1 )=1 and state(v2 )=1. 2) VC to LN(v1 , v3 ): Re f (v1 , v3 ) = b2 . As D1 = 2 and D3 = 8, T = GCD(D1 , D3 ) = 2. Since state(v1 )=1 and state(v3 )=0, the branch of “One state is 0 and the other 1” is executed. We map (v1 , b1 ) with respect to the reference buffer b2 , resulting in l n2 an equivalent LN l n2 (v1 , b2 ). Thus the consumed LN set of v1 CSln (v1 ) = {1}. The available LN set of v3 is ASln (v3 ) = (b3 ) 0 2 1 1 0 0 1 1 0 1,3,5 0,2,4 {0, 1} − CSln (v1 ) = {0}. The required number of LNs of v3 Nln (v3 ) = (cid:8)N3 T /W3 (cid:9) = 1. We assign l n2 (v3 , b2 ) to v3 . Then we allocate slot sets s8 (b2 ) and s8 (b3 ) to v3 . After this assignment, state(v3 )=1. 3) VC to LN(v2 , v3 ): Re f (v2 , v3 ) = b3 . As D2 = 4 and D3 = 8, T = GCD(D2 , D3 ) = 4. Since state(v2 )=1 and state(v3 )=1, the branch of “Both states are 1” is executed. In this step, we check whether the allocated slot sets for v2 and v3 can stay in different LNs after mapping them to the four LNs with respect to the reference buffer b3 . We map s4 (b1 ) of v2 on b3 , obtaining an (v2 , b3 ). Then we map s8 (b2 ) of v3 on b3 , equivalent LN l n4 obtaining LN l n4 (v3 , b3 ). Because l n4 (v2 , b3 ) ∩ l n4 (v3 , b3 ) = /0, v2 and v3 are conﬂict free with their slot assignment. After the above three steps, the VC-to-LN assignments for the three VCs are successful. The slot sets are allocated accordingly, as shown in Table II. These can be used to create routing tables in switches. 2 1,3 0,2,4 1,3 1 2 C. Routing Table Creation When the VC-to-LN assignment is successful for all VCs, a feasible solution or conﬁguration is found. With each VC, a switch’s partial routing table is created according to the VC’s path and the allocated LNs, more accurately, the allocated slot sets within the admission cycle. The slot sets determine when the VC passes a particular buffer in a switch. For instance, if a VC v with an admission cycle D subscribes to sDτ1 (b) and sDτ2 (b), then slots τ1 + kD and τ2 + kD (k ∈ N) of b are reserved for v. The VC path determines the input link ein and the output link eout of the switch used by v packets at the reserved slots. Thus, two routing table entries, (τ1 + kD, ein , eout ) and (τ2 + kD, ein , eout ), can be created in the switch. By composing the partial routing tables of all visiting VCs in a switch, we obtain a complete routing table for the switch. Optimization is also used to shrink the size of the routing tables. For example, entries (4k, ein , eout ) and (4k + 2, ein , eout ) can be reduced to one entry (2k, ein , eout ). V I I . AN INDU S T R IA L CA S E S T UDY A. The TDM VC Conﬁguration Program We have integrated the LN-based slot allocation method into our TDM VC conﬁguration program. To explore the path diversity of VCs, this program runs a back-tracking algorithm. The algorithm is a recursive function performing a depth-ﬁrst search. The solution space in a tree structure is generated while the search is conducted. At any time during the search, only the route from the start node to the current expansion node is saved. As a result, the memory requirement of the algorithm is O(n), where n is the number of VCs. This is important since the solution space organization needs excessive memory if stored in its entirety. Whenever two VCs overlap, the assignment of VCs to LNs is performed. If they can be assigned to two different LNs with sufﬁcient bandwidth, the assignment is done successfully. Otherwise, the assignment fails, and other path alternatives (back-tracking) have to be considered. This VC-to-LN assignment serves as a bounding function by which, if it fails, the algorithm prunes the current expansion node’s subtrees, thus making the search efﬁcient. In general, the more the alternative paths, the longer the run time. The program allows us to set the number of alternative paths to tradeoff between runtime and capability. B. The Case Study We applied our program to a real application provided by Ericsson Radio Systems. As mapped onto a 4×4 mesh in Figure 8, this application consists of 16 IPs. Speciﬁcally, n2 , n3 , n6 , n9 , n10 and n11 are ASICs; n4 , n7 , n12 , n13 , n14 and n15 are DSPs; n5 , n8 and n16 are 2 4 FPGAs; n1 is a device processor which loads all nodes with program and parameters at start-up, sets up and controls resources in normal operation. Trafﬁc to/from n1 is for system initial conﬁguration and no longer used afterwards. There are 26 node-to-node trafﬁc ﬂows that are categorized into nine types of trafﬁc ﬂows {a, b, c, d, e, f, g, h, i}, as marked in the ﬁgure. Trafﬁc a and h are multi-cast trafﬁc, and others are unicast trafﬁc. The trafﬁc ﬂows are associated with a bandwidth requirement. In this case study, we use closed-loop VCs to implement all trafﬁc ﬂows, κbw = 1. n13 b n14 b n15 b cc d n16 c c b n9 a b n10 a b n11 a n12 d n5 n1 to/from all n6 i h n2 f h n7 i h n3 f n8 e g f n4 f a x3: 4096  b x6: 512 c x4: 512 d x2: 2048 e x1: 512 f x4: 128 g x1: 64 h x3: 4096 i x2: 512 unit: Mbits/s Fig. 8. Trafﬁc ﬂows for a radio system The case study comprises VC speciﬁcation and VC conﬁguration. The ﬁrst phase involves determining link capacity, normalizing VC bandwidth demand and merging trafﬁc ﬂows. The second phase runs the conﬁguration program, exploring VC’s all minimal paths. We ﬁrst determine the minimum link capacity bwl ink by considering a heaviest loaded link. Link e(n5 , n9 ) is such a link since the a-type trafﬁc passes it and bwa = 4096 Mbits/s. To support bwa , bwl ink ≥ 4096 Mbits/s. We choose 4096 Mbits/s for bwl ink . This is an initial estimation and subject to optimization later on. Afterwards, we normalize the bandwidth demand into a fraction of bwl ink . For example, 512 Mbits/s is equivalent to 1/8 link capacity. Then we merge trafﬁc ﬂows in order to construct efﬁcient VCs by taking advantage of multi-node VCs. This can be done for multicast and low-bandwidth trafﬁc. For the two multi-cast trafﬁc a and h, we build two multi-node VCs as ˙va (n5 , n9 , n10 , n11 ) and ˙vh (n5 , n6 , n2 , n3 ). The notation ˙v refers to a VC speciﬁcation before path selection. Trafﬁc b, c and f require low bandwidth. We specify a VC to include as many nodes as a type of trafﬁc ﬂow spreads. For trafﬁc b, we deﬁne a six-node VC, ˙vb (n9 , n10 , n11 , n13 , n14 , n15 ); for c, a ﬁve-node VC ˙vc (n13 , n14 , n15 , n16 , n7 ); for f, a three-node VC ˙v f (n2 , n3 , n4 ). Furthermore, as we use a closed-loop VC, two-simplex trafﬁc ﬂows can be merged into one duplex ﬂow. For instance, for two i ﬂows, we specify only one VC ˙vi (n6 , n7 ). Note that, while merging trafﬁc ﬂows, the resulting VC must be able to provide enough bandwidth to support the ﬂows. Performing this step results in 9 multi-node VCs. With the three steps above, we complete deﬁning the VC speciﬁcation set. While executing the program to conﬁgure the VCs, we investigate the impact of VC sorting. Since VC sorting determines the VC levels in the solution tree and the VC-to-LN assignment order, it affects the runtime and the number of solutions. We tried three sorting schemes: random, higher bandwidth ﬁrst, less number of path options ﬁrst. In order to compare the potential of the schemes, our algorithm terminates after all solutions are found. We did not do any tweaking or tuning but used the original IP-to-node mapping and IP communication patterns without change. Corresponding to the three sorting schemes, the number of solutions found is 33, 30 and 76; the run time is 6, 6 and 12 seconds. Sorting by the number of path options is best in this example. This means that VCs with fewer alternative paths should be layouted ﬁrst because they are more constrained. As a result, pruning their subtrees and allocating slots are more effective when they are considered in the upper levels in the tree. V I I I . CONC L U S ION Slot allocation is a critical problem for TDM VC conﬁguration. Its complexity arises from various path overlapping and bandwidth sharing scenarios. In the paper, based on our concept of LN, we develop and proof sufﬁcient and necessary conditions for the conﬁguration of conﬂict-free and bandwidth-satisﬁed VCs. They are applicable to both open-ended and closed-loop VCs in the state-of-the-art NoC proposals. We have also detailed the steps to perform the VC-toLN assignment, i.e., slot allocation, and integrated the method into our multi-node TDM VC conﬁguration program. Our industrial case study justiﬁes our approach in effectiveness and practicality. In the paper, we have considered non-stalled TDM VCs where VC packets use consecutive slots in consecutive switches. This type of TDM VC couples the latency requirement with the bandwidth requirement. For low-bandwidth low-latency trafﬁc, it leads to overbooking bandwidth in order to satisfy the low latency constraint. In the future, we will extend our framework to cover stallable TDM VCs in order to make more efﬁcient use of link bandwidth and to allow asynchronous network communication. ACKNOW L E DGM E N T The research is partially supported by the EU FP6 project SPRINT under contract 027580. "
2007,The design and synthesis of a synchronous and distributed MAC protocol for wireless network-on-chip.,"To bridge the widening gap between computation requirements and communication efficiency faced by gigascale heterogeneous SoCs in the upcoming ubiquitous era, a new on-chip communication system, dubbed wireless network-on-chip (WNoC), is introduced by using the recently developed CMOS proximity wireless interconnection technology. In this paper, a synchronous and distributed medium access control (SD-MAC) protocol is designed and implemented. Tailored for WNoC, SD-MAC employs a binary countdown approach to resolve channel contention between RF nodes. The receiver_select_sender mechanism and hidden terminal elimination scheme are proposed to increase the throughput and channel utilization of the system. Our simulation study shows the promising performance of SD-MAC in terms of throughput, latency, and network utilization. As a major component of simple and compact RF node design, a MAC unit implements the proposed SD-MAC that guarantees correct operation of synchronized frames while keeping overhead low. The synthesis results demonstrate several attractive features such as high speed, low power consumption, nice scalability and low area cost.","The Design and Synthesis of A Synchronous and Distributed MAC Protocol for Wireless Network-on-Chip Yi Wang and Dan Zhao The Center for Advanced Computer Studies University of Louisiana at Lafayette Email: {yxw4316,dzhao}@cacs.louisiana.edu Lafayette, LA 70504 Abstract— To bridge the widening gap between computation requirements and communication efﬁciency faced by gigascale heterogeneous SoCs in the upcoming ubiquitous era, a new on-chip communication system, dubbed Wireless Network-on-Chip (WNoC), is introduced by using the recently developed CMOS proximity wireless interconnection technology. In this paper, a synchronous and distributed medium access control (SD-MAC) protocol is designed and implemented. Tailored for WNoC, SD-MAC employs a binary countdown approach to resolve channel contention between RF nodes. The receiver select sender mechanism and hidden terminal elimination scheme are proposed to increase the throughput and channel utilization of the system. Our simulation study shows the promising performance of SD-MAC in terms of throughput, latency, and network utilization. As a major component of simple and compact RF node design, a MAC unit implements the proposed SDMAC that guarantees correct operation of synchronized frames while keeping overhead low. The synthesis results demonstrate several attractive features such as high speed, low power consumption, nice scalability and low area cost1 . I . IN T RODUC T ION When moving into billion-transistor era, ever increasing complexity, heterogeneity, performance and productivity requirements put a heavy burden on next generation SoC design. The performance of gigascale SoCs will be limited by the ability to efﬁciently interconnect heterogeneous IP cores to accommodate their communication requirements. While design productivity boosts the reuse of plug-n-play IP cores, the reuse of communication fabric had been difﬁcult. The stateof-the-art shared-bus and point-to-point connections have been shown unable to supply nanoscale SoCs with both sufﬁcient bandwidth and low latency under a stringent power consumption limitation [1]. A scalable communication infrastructure with predictable bandwidth and latency is essential to provide plug-n-play interconnection of heterogeneous IP cores. Recently, the concept of Network-on-Chip (NoC) [2], [3], [4], has been proposed as the communication platform for complex multi-processor SoCs. NoC features prominent characteristics, such as transmitting packets instead of words, supporting parallel transaction, and solving clock skew problem in large-scale SoCs. In the meantime, the speed improvements of silicon and SiGe bipolar transistors and MOS transistors have made the implementation of integrated circuits operating at 20GHz and higher feasible. At 24GH z, a quarter wave dipolar antenna is only about 0.9mm in silicon and the wave length scales inversely with the operating frequency [5]. These in conjunction with the increase of chip sizes potentially up to 2.4cm × 2.4cm have made the integration of antennae for wireless communication possible. Recent technology advances such as microfabricated antenna, on-chip RF integration, and extremely short-range RF communication, are making possible tiny, low-cost antennae, receivers and transmitters to be integrated onto 1 This research is supported in part by LA BORSF Research Competitive Subprogram. a single chip. As a result, a new radio frequency (RF)/microwave interconnect technology has been introduced for future intra-chip communication [6], [7], [8]. Using the RoC technology, the chip-based wireless radios can be employed to replace the wires for increasing accessibility, improving bandwidth utilization, and eliminating delay and cross-talk noise in conventional wired interconnects. This brings forth a revolutionary on-chip communication infrastructure based on RF interconnection, which we name as Wireless Network on Chip (WNoC) in contrast to NoC. WNoC will provide higher ﬂexibility, higher bandwidth, reconﬁgurable integration, and freed-up wiring when compared to NoC. With the uniqueness of RoC, existing NoC technologies cannot be applied in WNoC directly, calling for effective solutions to overhaul the on-chip communication infrastructure of nano-scale SoCs. The system architecture of WNoC has been established with the focus on radio frequency infrastructure [9]. As shown in Figure 1, a number of RF nodes, equipped with low-cost, low-power transceivers and tiny antennae, are dispersed on-chip and organize themselves into a multi-hop wireless micronetwork. The IP cores access the network via transparent network interface (TNI), and their packets are delivered to destination through multiple hops across the network. We have addressed the RF node distribution problem that calls for the minimum number of RF nodes to support communication needs of all cores within the chip and to determine their placement [10]. Meanwhile, the cores are properly clustered in order to minimize the routing cost and to balance the communication workload accordingly. The cores in a cluster are hard-wired to an RF node via network interfaces and share it for data/control communication. Adopting a VCI-compatible interface [11], the transparent network interface (TNI) diminishes the heterogeneity of the cores and interacts with the network fabric for packet assembly, delivery, and disassembly. Wireless link RF node TNI TNI TNI TNI TNI TNI Hierarchical Core SoC TNI TNI Fig. 1. A hypothetical WNoC for heterogeneous SoCs. Data transmission protocol is an integral part of WNoC. With the objective of making the implementation simple and efﬁcient, we have proposed to take a cross-layer design approach for developing the data 1 4 2 4 4 1 3 8 2 6 / 0 7 / $ 2 5 . 0 0   © 2 0 0 7   I E E E 6 1 2 transmission protocol, which fulﬁls the functions of medium access control, network, and transport layers in traditional OSI layered structure. We have addressed the design issues to enable efﬁcient onchip addressing and routing at network layer [12]. We have developed an adaptive region-aided routing protocol that achieves minimum path cost and guarantees loop-free. The routing decision logic was implemented accordingly with minimum circuit area overhead. As the nodes in WNoC communicate over the shared wireless medium, it is highly possible that two or more nearby RF nodes transmit data simultaneously which leads to collisions. The receiver in the collision region (i.e., an area where all nodes are within each other’s transmission range) cannot receive the data packet correctly. Thus it is a key design issue to develop efﬁcient medium access control (MAC) protocol for resolving channel contention and minimizing collision probability, with two special requirements to be considered due to the uniqueness of WNoC. First, the MAC protocol should have very low hardware implementation overhead, which prohibits the use of any conventional MAC protocols. Second, it should achieve very low collision probability and packet delivery delay, in order to meet the quality of service requirement of various on-chip applications. In this work we propose a synchronized and distributed MAC protocol, namely SD-MAC, that ensures 100% collision free while having the features of high-efﬁciency, simplicity, robustness, fairness, and QoS capability. Tailed for WNoC, SDMAC resolves contention based on binary countdown. The novel receiver select sender and hidden terminal elimination mechanisms are developed to increase network throughput, to reduce packet delay and to improve channel utilization of the system. Consequently, a MAC unit is implemented that guarantees correct operation of synchronized frames while minimizing the implementation overhead. The rest of the paper is organized as follows. The related work is discussed in Sec. II. Then in Sec. III, we propose a synchronized and distributed SD-MAC protocol that guarantees 100% collision free and enhances data transmission concurrency. The performance of SD-MAC protocol is evaluated in Sec. IV with regard to network throughput, latency and utilization. At last, the protocol is implemented in a MAC unit that ensures correct protocol function, high performance, and low hardware overhead. Finally, the paper is concluded in Sec. VI. I I . BACKGROUND AND R E L AT E D WORK MAC protocols have been widely studied in wireless networks that can be classiﬁed into two categories, distributed and centralized according to the type of network architecture, or contention-based and scheduling-based according to channel access schemes. Wireless MAC protocols can be non-synchronized or synchronized. Nonsynchronized protocols are largely contention-based, where collision nodes back off a random duration before retrying to access the channel [13], [14]. Most synchronized protocols employ a centralized scheduler to ensure that nodes follow some particular schedules to achieve collision-free data transmission [15], [16]. The synchronized but distributed MAC protocols capable of achieving higher performance have not yet been adequately studied. Recently, a binary countdown based scheme has been proposed in [17] to resolve access contention. It employs the Request To Send (RTS) / Clear To Send (CTS) mechanism as in IEEE Std. 802.11 MAC protocol to eliminate hidden terminals. However, collisions can still occur for the RTS/CTS scheme due to different node transmission range. A synchronized protocol based on binary countdown has been proposed in [18] to further prevent collisions. The hidden terminals are efﬁciently eliminated by introducing a Hidden Station Clear Message (HCM). However, the exposed terminals problem is not addressed in these approaches. Following these wireless media access protocols for a single channel, we observe that collisions occur at the receiver, not the sender. In other words, it is the presence of two or more interfering signals at the receiver that constitutes a collision. Competition at sender using binary countdown may not appropriately avoid collision as in “hidden terminal” problem, or defer possible transmission as in “exposed terminal” problem. For example, as illustrated in Figure 2(a), both of the two senders A and C are not within each other’s contention region thus both could win the contention and attempt to transmit data simultaneously. A “hidden terminal” scenario results. An “exposed terminal” scenario results when both the two senders B and C (in Figure 2(b)) are within each other’s contention region and only one (say B) wins the contention. However there is no reason to defer the data transmission from C to D. A B C D (a) Hidden terminal scenerio A B C D (b) Exposed terminal scenerio Fig. 2. Illustration of hidden and exposed terminal problems. In this paper, we propose a synchronized and distributed media access control protocol that propagates synchronized contention periods thus the RF nodes in a WNoC can contend efﬁciently by using binary countdown scheme. We allow the receivers instead of senders to make the contention decision and to select appropriate sender based on the accumulated contention information. In this way, we efﬁciently resolve collision due to both channel contention and the hidden terminal problem. We improve channel efﬁciency by enhancing concurrent data transmission taken into the consideration of exposed terminal problem. I I I . SD -MAC P ROTOCO L FOR WNOC In this section, we introduce the proposed SD-MAC protocol for WNoC. In SD-MAC, channel contention is based on a binary countdown medium access mechanism. The WNoC system needs to be regionally synchronized so that the neighboring RF nodes could compete for the wireless media beginning at the same time point. While the asynchrony between the nodes several hops away will not affect or have trivial effect on the functionality of our SD-MAC protocol. To reach regional synchronization, we introduce several specially designed backbone RF nodes that has longer transmission range but extremely simpliﬁed functionality. We properly disperse them on-chip to cover all RF nodes. These backbone nodes are in sleep mode most of the time, and are awakened only to distribute the network clock. All RF nodes within the transmission range of a backbone node will receive the clock. Each RF node employs a four-step approach to access the shared wireless channel: initialization, channel contention, channel access authorization, and data transmission. The short distance between neighboring RF nodes (within the wireless transmission range) make it feasible to achieve wired controlling 6 1 3 without considerable cost, and thus a separate control channel. Each RF node has a set of n control lines (Rx/T x[n − 1 : 0]) connected to its n neighbors. Each pair of control lines consists of a single bit input (Rx[i])/output (T x[i]) line for handshaking between a RF node and its ith neighbor. Based on this hybrid interconnection infrastructure, the multiple access controlling is performed on these control wires while the data are transmitted through the network wirelessly. Having separate wired controlling channel and wireless data transmission channel induces a number of beneﬁts. First of all, we may avoid expensive data synchronization. Only the control signals are synchronized. Second, the control logic can be simpliﬁed to bit operations and thus faster and simpler to implement. Third, since no control packets are sent through the wireless media, more useful data packets are transmitted. Fourth, by decoupling the mediums of data transmission and medium access control, the MAC protocol controlling of the current packet can be launched at the same time with the data transmission of previous packet, thus increasing the channel efﬁciency. The SD-MAC protocol is based on synchronized time frames, where each frame consists of two intervals: the competition interval and the data transmission interval. With separate control and data transmission channels, the RF nodes that have data to sent compete the wireless media of next time frame through the wired control channel. In the meantime, the RF nodes which win the wireless channel competition in the previous frame transmit data packet through the wireless channel. The competition interval is further divided into three periods as shown in Figure 3. It starts with a synchronization (INIP) period that includes a state initialization slot and a register initialization slot. It is then followed by the channel contention (CP) period, that consists of a series of Ncs contention slots used for binary countdown approach. The competition ends with a channel access authorization (CAAP) period. The operations of each period are described as follows. Competition Interval Competition Interval Competition Interval INIP S_Ini R_Ini CP C B 4 C B 3 C B 1 C B 2 C B 5 C B 6 C B 7 C B 8 CAAP CR INIP: Initialization Period CP: Contention Period CAAP: Channel Access Authorization Period Fig. 3. SD-MAC frame format for the control channel. a) Initialization: Each RF node contains a two-bit status register SR[1 : 0] to indicate its state changing via control handshaking. A node may be in one of four states: T X , a transmitter where SR[1 : 0] = (1, 1); RX , a receiver where SR[1 : 0] = (1, 0); I nA, node inactive where SR[1 : 0] = (0, 1); and SND, node state-not-determined where SR[1 : 0] = (0, 0). In the initialization period, any RF node that has data to send (by checking the waiting signal associated with the buffer pool, asserted when packets waiting in the buffer pool), is identiﬁed as a potential sender by setting SR[1 : 0] = (1, 1). All other nodes are initialized in the state of SND by setting SR[1 : 0] = (0, 0). A node may change from one state to another in the channel access authorization period. Each node also maintains a n-bit potential sender record register PSR[n − 1 : 0] corresponding to its n neighbors. If bit PSRi = 1, the ith neighbor is recorded as a potential sender of the node. A node may have multiple potential senders. The PSR registers are constructed in a way that each sender asserts the only one outgoing T X line connected to the receiver (determined by the routing decision logic) while negating the remaining. All nodes check their incoming RX lines and all their potential senders are recorded in PSR if the corresponding RX lines are asserted. In order to keep a history of channel contention bit survived sender record register SSR[n − 1 : 0] is maintained by throughout a sequence of contention slots in contention period, a neach node and its content is updated at each contention slot. If bit SSRi = 1, the ith neighbor is indicated as a neighboring competing sender survived through the contention. In the initialization period, all senders simply broadcast logic ‘1’ to their neighbors by asserting their T X lines and each node check their RX lines by performing OR operation of RX [n − 1 : 0], i.e. T x.exist . If a node has at least one sender in its neighborhood (T x.exist =1), its SSR register is initialized to all ones, SSR[n − 1 : 0]=(1,...,1), otherwise all zeros, SSR[n − 1 : 0]=(0,...,0). For example, 9 RF nodes form a WNoC as shown in Figure 4. Two nodes are connected by a link if they are within the transmission range of each other. Assuming nodes 1, 2, 5 and 7 have data to send to nodes 3, 4, 4 and 8 respectively. Note that, due to the limited transmission range, some nodes compete the wireless channel with each other, such as nodes 1 and 2. Initially all potential senders such as nodes 1, 2, 5, and 7 are in state of T X while all other nodes in state of SND. Each node also maintains a PSR. The PSRs of nodes 3, 4, 8 are initialized to PSR3 = (0, 1, 0, 0), PSR4 = (0, 1, 0, 1, 0) and PSR8 = (1) respectively. While all other nodes have their PSRs recorded as all zeros. In addition, nodes 0, 5 and 7 have their SSR registers initialized to all zeros while all other SSR registers have the initial value of all ones. SSR0=(0) SSR3=(0,1,0,0) SSR5=(0,0,0) SSR1=(1,0,0) SSR2=(1,0) SSR4=(0,0,0,0,1) SSR7=(0,0,0) SSR6=(0,1) SSR8=(1) RF node 1:  1  1   1  0   1  0   1  0 lose RF node 2:  1  0   1  1   1  0   0  1 lose RF node 5:  1  1   0  1   0  0   1  1 lose RF node 7:  1  1   1  0   1  1   1  0 survive SSR4=(11011) SSR4=(10011) SSR4=(10001) not updated SSR4=(00001) Fig. 4. Illustration of channel contention. b) Channel Contention: In channel contention period, all potential senders contend for the wireless medium by employing a binary countdown scheme. As the relevant contention is at the receiver, not the sender, we let a receiver to choose one among a set of neighboring competing senders. Such a receiver select sender mechanism assures more concurrent data transmission by efﬁciently resolving the exposed terminal problem. At beginning, all incoming RX lines of a node in the collision region are initialized to logic ‘0’. A potential sender (say, X ) generates a Ncs -bit random number, i.e., {CBi |1 ≤ i ≤ Ncs}. If CBi=1, node X asserts all its outgoing T X lines T X [n − 1 : 0] = (1, ...1) in contention slot CSi . Otherwise, if CBi=0, all T X lines are negated, T X [n − 1 : 0] = (0, ...0). The RF nodes (with T x.exist =1) check all their RX lines at each slot and update their SSR registers by calculating bitwise AND of RX [n − 1 : 0] and SSR[n − 1 : 0]. For a particular node A, the bitwise AND operation masks off its neighboring senders with smaller contention number (with their 6 1 4 current contention bit CBi=0) after each contention slot CSi . Its neighboring senders survived till CSi are indicated with logic ‘1’ in SSRA register (i.e. they have equally large contention numbers so far). Note that, if the bitwise AND operation results in all zeros, it’s likely that the contention bits of all survived senders are zero at CSi . Again, the survived senders have the same large contention number till CSi and no survived sender should be masked off. In other words, the SSRA register will not be updated in CSi . Clearly, only one neighboring sender with the largest contention number will survive at last (assume each sender generates distinct random contention number). Finally, SSRA register has only one bit asserted indicating the only survived sender. Node A then ignores further contention bits it receives and its SSRA register will not be further updated. As shown in Figure 4, the channel contention is carried out for the example with the random contention numbers generated for the senders 1, 2, 5, and 7. Let’s use node 4 for illustration. 4 out of 5 neighbors are senders. Among them, nodes 2 and 5 are its potential senders. After the ﬁrst contention slot CS1 , all four neighboring senders indicate themselves as the survived sender by setting SSR4 = (1, 1, 0, 1, 1). Then node 2 with contention bit CB2 2=0 loses contention in CS2 as its contention number is the smallest. SSR4 is updated, SSR4 = (1, 0, 0, 1, 1). Similarly, node 5 loses contention in CS3 that results in SSR4 = (1, 0, 0, 0, 1). We cannot determine which node between 1 and 7 survives until slot CS6 . As node 7 has the largest contention number, it survives at the end with the updated SSR4 = (0, 0, 0, 0, 1). Similarly, all nodes will choose their survived sender using such a binary countdown-based contention scheme. Only the neighboring sender with the largest contention number survives at the end and is indicated in SSR register. c) Channel Access Authorization: After contention period, each node selects exactly one neighboring sender as the survived sender. In channel access authorization period, we need to determine if the survived sender is a potential sender of the node and grant channel access if it ﬁnally wins the contention. The CAA period contains two steps. In the ﬁrst step, each node performs bitwise AND of SSR[n − 1 : 0] and PSR[n − 1 : 0], and records the result in SSR. Then it follows a OR operation to the bits in SSR[n − 1 : 0], i.e., T x.survive. The state of each node is transformed accordingly. For a node with initial state of SND, there are two possible state transformation: • If SSR contains all zeros, i.e. T x.survive=0, the node transforms its state to I nA. • Otherwise, if T x.survive=1, the node transforms its state to RX . In other words, the survived sender of the node is its potential sender. The node is in turn the receiver of the survived sender. There are also two cases for a node in initial state T X : • If T x.survive=0, the node remains as a potential sender (in T X state). • Otherwise, if T x.survive=1, the node transforms its state to RX . All nodes will ﬁnalize their states in the next step. In step two, we will resolve channel contention and eliminate hidden terminals. At beginning, all T X lines are initialized to logic ‘0’. Each potential sender (in state T X ) ﬁrst asserts the only T X line connected to its next-hop while negating all others. Each potential receiver (in state RX ) check their RX lines by calculating OR of RX [n − 1 : 0], i.e. Rx.l ose. If Rx.l ose=0, the node remains as a receiver (in RX state), otherwise, the node changes its state to I nA. It’s simply to avoid those cases where a receiver’s potential sender has changed to RX state in step one. All remaining receivers then compute bitwise OR of SSR[n − 1 : 0] and PSR[n − 1 : 0] and output the results to their T X lines so that the receivers can inform their potential senders. All potential senders (in state T X ) check their incoming RX lines and compute OR operation of RX [n − 1 : 0], i.e., T x.win. • If none of the incoming lines is asserted, i.e. T x.win=0, the node loses contention and simply changes its state to I nA. Such as nodes 1 and 2 in the same contention region, collision is avoided in a way that a node (e.g. node 1) with larger contention number wins the channel access, while node 2 gives up its attempt of gaining access to the channel in this frame. • If a potential sender receives the asserted signal from more than its next-hop (i.e., a potential sender has more than two RX lines asserted or the only asserted RX line is not from its next-hop), T x.mat ch = 0, the sender (e.g. node 5) considers itself as a hidden terminal and gives up its attempt to access the channel in this frame by changing to state I nA. • Otherwise, if the only one asserted signal is sent from its nexthop, T x.mat ch = 1, the sender is a ﬁnal winner and remains in state T X . Only the sender remained in state T X can transmit data in the following data transmission interval. Finally, nodes 1 and 7 will transmit data simultaneously as shown in Figure 5. InA TX d ata TX−>InA RX InA TX−>InA InA TX data RX Fig. 5. Illustration of contention resolution. The proposed receiver select sender mechanism followed by channel authorization efﬁciently resolves exposed terminal problem. For example in Figure 2(b), even though the two senders are within each other’s contention region, their next-hops are not within each other’s transmission range. In other words, A cannot hear C while D cannot hear B. Both A and D will choose their potential sender as their survived sender after the contention period. Then in channel access authorization period, as the handshaking is operated between each separate pair of A and B or C and D, both B and C win the contention and transmit data simultaneously. IV. P E R FORMANC E E VA L UAT ION A. Channel Efﬁciency By separating control channel and data channel, the control handshaking is decoupled from the wireless data transmission, which renders zero protocol overhead for the wireless channel. Moreover, the proposed SD-MAC protocol achieves 100% collision free, thus no overhead may be induced by avoiding packet retransmission. In order to ensure 100% wireless channel efﬁciency, the control handshaking should be conducted in concurrent with the wireless data transmission, and the time spent on wired controlling should be compatible with the high-speed data transmission time. Thereby we may determine the appropriate packet size that ensures 100% channel efﬁciency. Assume the data rate of the wireless channel is D b ps, and the packet size is S bits. The time required to transmit a packet is TD = S D . 6 1 5 ) I C r e p ( t u p h g u o r h T e g a r e v A 7 6 5 4 3 2 1 0 4x4 QG 5x5 QG 6x6 QG 25 TG 0 0.2 0.4 0.6 Injection Rate 0.8 1 y c n a t a l e g a r e v A 8 7 6 5 4 3 2 1 4x4 QG 5x5 QG 6x6 QG 25 TG 0 0.2 0.4 0.6 Injection Rate 0.8 1 t u p t h g u o r h T e g a r e v A 6 5 4 3 2 1 0 2 4x4 QG 5x5 QG 6x6 QG 25 TG 4 6 8 Number of Contention Slot 10 (a) Average throughput Vs. inject rate. (c) Average throughput Vs. Ncs . Fig. 6. Performance evaluated at various inject rate, Ncs , and topology. (b) Average latency Vs. inject rate. = S TCI D×TCI Assume the minimum time we may achieve to ﬁnish a competition interval is TC I . In order to render complete overlapping between should be determined by PC I = max{TC I , TD }. The wireless channel handshaking and data transmission, the actual competition interval efﬁciency is deﬁned by Echannel = TD . To reach 100% channel efﬁciency, TC I should be no greater than TD . In other words, S ≥ D × TC I . As the control handshaking in the proposed SD-MAC is realized with bitwise logic operations, the implementation is simple and fast. TC I is dominated by the time spent in the channel contention period that consists of several contention slots. For an example implementation using 0.18µm technology (explained in Sec. V), the operating frequency of SD-MAC is around 400MH z. The resulted TC I is about 30ns when the number of contention slots is 8. Assume 1 Gb ps data rate of the wireless channel, the packet size is thus estimated no less than 30 bits to assure 100% channel efﬁciency. B. Simulation Study A WNoC with identical and omni directional radio range is built up to cover the communication among the IP cores within a SOC model. The WNoC adopts the adaptive region-aided routing protocol as we developed in [12] to determine the next-hop of each sender. Assume there are sufﬁcient buffer space to temporarily store the packets in an intermediate RF node. Each RF node is associated with a random trafﬁc generator that generates uniformly distributed trafﬁc patterns. We introduce a parameter called injection rate, that is deﬁned as the number of packets generated per trafﬁc pattern distribution. When a packet is generated at a node, the node randomly assigns the destination for the packet. We deﬁne the network throughput as the number of packets that can be transmitted successfully at a time frame by applying SD-MAC protocol. The packet latency is deﬁned as the number of competition intervals it takes to be sent out successfully since when the packet is ready for transmission. The trade-off between architectural design and network concurrency is studied based on two typical grid network topologies, quadrilateral grid (QG) and triangular grid (TG) [10]. We run extensive simulations with the consideration of various network topology, the results are taken an average over 60 different randomly generated network conﬁgurations per topology per injection rate. As the number of contention slots (Ncs ) in the channel contention period determines collision probability (in terms of generating same contention signals), we also evaluate the MAC protocol by varying Ncs . The simulation results are illustrated in Figure 6. From the simulation results we observe that when a small number of RF nodes (Nr f ) are active in WNoC, the throughput is low. As the contention is low as well, data transmission concurrency is largely ensured, that results in low latency and high network utilization. With the increase of Nr f , throughput increases. However the latency increases because more channel contentions restrict the transmission concurrency. When the injection rate reaches 0.2, the throughput and latency become quite stable. Even the number of active nodes keeps on increasing, the network capacitance is quite saturated, thus no signiﬁcant improvement over throughput and latency results. When increasing the network density from 4 × 4 QG to 6 × 6 QG, the throughput increases signiﬁcantly while the latency and network utilization do not change much. When comparing the WNoC in triangular grid (25 TG) to the one in quadrilateral grid (5 × 5 QG) with the same Nr f , we can see that 25 TG induces quite lower throughput and higher latency. It’s simply because 25 TG results in higher network degrees thus higher channel contention. When observing the average throughput changing over the different number of contention slots, the throughput increases with the increase of Ncs due to the decline of collision probability. V. MAC UN I T S YN T H E S I S A. Hardware Implementation The MAC unit implements our proposed MAC protocol, with a primary task of guaranteeing correct clocking of the synchronous time frames and meanwhile keeping the hardware overhead low. The MAC unit includes four major blocks, namely the phase control logic, the state control unit, the pseudo random sequence generator, and the handshaking message generator. The MAC unit is inherently a sequential logic to ease synchronization. As shown in Figure 3, the entire operation timing is divided into frame periods, each of which is further divided into several slots. A sequence of critical signals that are imperative for correct protocol function are generated by a phase control logic (PCL) to ensure accurate clocking based on the global network clock. In particular, PCL (1) indicates the beginning and the end of a frame period; (2) speciﬁes appropriate period length; and (3) indicates the operation time for a contention slot. The pseudo random sequence generator (PRSG) is another building block of the MAC unit, which generates the random contention signals used during contention slots. It is implemented via a 8-level linear feedback shift register (LFSR). The state control unit (SCU) is a simple state machine that implements the state transformation at the 2-bit state registers (SR[1 : 0]). The encoding of the state is controlled by the phase control signals and the state change control signals. The key component of MAC unit is the handshaking message generator (HMG) based on a ﬁnite state machine (FSM), which           6 1 6 takes the phase and state signals and last operation (from RX lines) as the inputs and output the controlling (to T X lines) for the RF node. It also controls the updating of SSR registers. As illustrated in Figure 7, a HMG mainly consists of a PSR register, a SSR register, a single one detection logic (SOD), two multiplexes, several latches and logic gates. The PSR register is setup in INIP period, thus is enabled by Phase[0] = 1 and the content is kept during the whole competition interval. The RN REG and other gates (within dashed box 1) is simply used to allow only the potential senders to join the contention by sending contention bits (CB =)RN , and to make sure that RN will be masked off after CP period. The 5-to-1 multiplexer (MUX1) chooses proper inputs to initialize and update SSR register by setting sel1 signal. The 4-to-1 multiplexer (MUX2) outputs proper handshaking control messages to the T X lines by setting sel2 signal. Both of the multiplexer selection signals, sel1 and sel2 , are decoded from the 7-bit combinations of phase signals Phase[4 : 0] and states SR[1 : 0]. P SR [ n - 1 : 0 ] c l k e n Q D Q R X _ R E G c l k Q D c l k s e t Q D c l k p h a s e [ 0 ] R X R N _ e n 1 s e l 2 T X s e l 1 R N n e x t _ h o p SSR [ n - 1 : 0 ] c l k Q D e n "" 0 "" "" 0 "" S3 "" F F "" S2 S1 S O D R N : p h a s e [ 1 ] 2 Fig. 7. The handshaking message generator block diagram. B. Synthesis Results The MAC unit is implemented by VHDL and synthesized by Cadence PKS and then place-and-routed by Cadence First Encounter based on OSU 0.18µm standard cells library. For illustration, the clock constraint is set to 400MH z, and the number of contention slots Ncs is set to 4. Table I lists the cost and performance of the implemented MAC unit with different network degree. As we can see from the results, the area increases about 10% in average at every degree increment, that demonstrates a nice scalability in terms of hardware overhead. It’s worth to mention the very low area overhead. Even at the largest network degree, the area cost is just about 0.15% of a 1cm2 chip area. The actual operating frequency for a MAC unit is relevant to the data rate of the wireless transceiver associated with each RF node. To ensure 100% channel efﬁciency, we set the competition interval to be short enough to accommodate the data transmission of a packet. As seen from the worst slack time, the MAC unit implemented at various network degree works properly at a frequency slightly different from 400MH z. Since WNoC targets at GHz technology node, there is still enough design space available to adopt higher operating frequency if supported by more advanced technology. In addition, the power consumption estimated from the synthesis tool is proportional to the operating frequency and gate count of the MAC unit. Due to the small area overhead, the overall power dissipation for a MAC unit is quite low. V I . CONC L U S ION We have proposed in this paper a synchronous and distributed SD-MAC protocol tailored for WNoC. Based on binary countdown scheme, SD-MAC has attractive features such as distributed, efﬁcient, and simple while ensuring 100% collision free for data transmission. TABLE I CO S T AND P E R F O RMAN C E O F MAC U N I T Node Degree 4 5 6 7 8 9 10 Num Gates 441 497 512 570 604 644 720 Num Cells 209 256 260 297 305 327 379 Area (µm2 ) 10584 11928 12304 13680 14504 15456 17288 Worst Slack(ns) 0.072 0.050 0.032 -0.04 0.030 0.013 0.001 Operating Freq(MH z) 411.8 408.2 405.2 393.7 404.8 402.1 400.2 Power (mW ) 2.525e-03 2.854e-03 3.074e-03 3.374e-03 3.674e-03 3.884e-03 4.199e-03 The proposed receiver select sender and channel access authorization mechanisms efﬁciently resolves both exposed terminal and hidden terminal problems. An efﬁcient and low-cost MAC unit is implemented, aiming to devise simple and compact RF nodes for establishing WNoC under extremely limited resources. "
2008,MC-Sim - an efficient simulation tool for MPSoC designs.,"The ability to integrate diverse components such as processor cores, memories, custom hardware blocks and complex network-on-chip (NoC) communication frameworks onto a single chip has greatly increased the design space available for system-on-chip (SoC) designers. Efficient and accurate performance estimation tools are needed to assist the designer in making design decisions. In this paper, we present MC-Sim, a heterogeneous multi-core simulator framework which is capable of accurately simulating a variety of processor, memory, NoC configurations and application specific coprocessors. We also describe a methodology to automatically generate fast, cycle-true behavioral, C-based simulators for coprocessors using a high-level synthesis tool and integrate them with MC-Sim, thus augmenting it with the capacity to simulate coprocessors. Our C-based simulators provide on an average 45x improvement in simulation speed over that of RTL descriptions. We have used this framework to simulate a number of real-life applications such as the MPEG4 decoder and litho-simulation, and experimented with a number of design choices. Our simulator framework is able to accurately model the performance of these applications (only 7% off the actual implementation) and allows us to explore the design space rapidly and achieve interesting design implementations","MC-Sim: An Efficient Simulation Tool for MPSoC Designs  Jason Cong, Karthik Gururaj, Guoling Han, Adam Kaplan, Mishali Naik, Glenn Reinman  Computer Science Department, University of California, Los Angeles  Los Angeles, CA 90095, USA  ABSTRACT  The ability to integrate diverse components such as processor  cores, memories, custom hardware blocks and complex  network-on-chip (NoC) communication frameworks onto a  single chip has greatly increased the design space available for  system-on-chip  (SoC) designers. Efficient and accurate  performance estimation tools are needed to assist the designer in  making design decisions. In this paper, we present MC-Sim, a  heterogeneous multi-core simulator framework which is capable  of accurately simulating a variety of processor, memory, NoC  configurations and application specific coprocessors. We also  describe a methodology to automatically generate fast, cycletrue behavioral, C-based simulators for coprocessors using a  high-level synthesis tool and integrate them with MC-Sim, thus  augmenting it with the capacity to simulate coprocessors. Our Cbased simulators provide on an average 45x improvement in  simulation speed over that of RTL descriptions. We have used  this framework to simulate a number of real-life applications  such as  the MPEG4 decoder and  litho-simulation, and  experimented with a number of design choices. Our simulator  framework is able to accurately model the performance of these  applications (only 7% off the actual implementation) and allows  us to explore the design space rapidly and achieve interesting  design implementations.  1. INTRODUCTION  The costs and technical challenges of designing applicationspecific integrated circuits (ASIC) have increased substantially  as we move into nanometer technologies. At the same time, the  exponential increase in silicon capacity has made it possible to  integrate multiple processors in a single chip. Aside from  processor cores, it has also been possible to integrate a variety of  components onto the same chip. These components include onchip L2 cache banks, scratchpad memories for rapid memory  operations, DMA and memory controllers. Chip manufacturers  are also incorporating coprocessors and reconfigurable fabric  alongside processor cores. The encryption engines in Niagara 2  [9] are examples of coprocessors. FPGA manufacturers such as  Xilinx [11] and Altera [25] provide systems with processor  cores and reconfigurable fabric on the same chip. Examples are  Virtex-4 from Xilinx that includes up to two PowerPC 405 cores  and Excalibur from Altera  that  includes an ARM922T  processor. An important component that we have not mentioned  is the on-chip communication fabric. While most of the  commercial chip-multiprocessor (CMP) designs use bus-based  architectures for communication, it is anticipated that CMP  designs in the near future will include complex network-on-chip  (NoC) architectures. This is because bus-based architectures  have been shown to scale poorly in terms of energy consumption  and performance as the number of components increase [1].  The ability to integrate such diverse components on a single chip  has led to the coining of the term Multi-Processor System-onChip (MPSoC). To manage the massive increase in the design  space available for system designers, simulation tools, which  can provide rapid and accurate estimations of the performance  and cost of design instances, are required. Specifically, the tool  should possess the capability to rapidly and accurately evaluate  the performance of multi-core designs, model a variety of  memory systems and NoC configurations, simulate coprocessors  efficiently and allow the designer to migrate from one design  instance to another easily.   1.1 Previous Work  Single processor simulators  Traditional single-core simulators, such as SimpleScalar [7],  were designed to model out-of-order superscalar processor  pipelines, and lack the ability to model multiple application  workloads or shared-memory parallel applications, let alone the  simulation of multiple processor cores. Architecture description  languages such as LISA [15] and EXPRESSION [16] allow  designers to generate compilers and functional and cycleaccurate simulators for application-specific processors from a  high-level specification. While these environments provide  designers with the ability to customize the instruction set and  processor architecture, considerable effort is needed to come up  with descriptions so that efficient compilers and simulators are  generated.  Multi-core simulators  Full-system simulation is frequently used to evaluate CMP  architectures. Although many full-system simulators [17][28]  [33] are capable of executing unmodified binaries, and modeling  partial or complete operating system execution, they are often  very slow and heavyweight, even when simply modeling the  functional execution of an application, unburdened by cycleaccurate models of cores and memories.   For instance,  Michigan's M5 Simulator [33] supports the booting of entire  operating systems, as well as the execution of unmodified  application binaries using system-call emulation. However, only  a shared-bus model is supported to model interconnection of  multiple processor cores, and only four processor cores can be  simulated at a time. Virtutech's Simics [17] is a full-system  functional simulator  that can support  the execution of  unmodified kernel and driver code. Although Simics does not  come prepackaged with a detailed processor model, it has APIs  which  support  plug-in  extension with  timing  or  microarchitecture models. One popular Simics plug-in is  Wisconsin's GEMS Toolset [32], which contains a separate  processor model and memory system simulator. Unfortunately,  this framework is slow and heavy (nearly two orders slower than   SimpleScalar), and as modeled systems are scaled to even tens  of cores, the complete execution of even a small multithreaded  application could require weeks of simulation time.   The SESC simulator [6] is a very fast single/multi-processor  simulator which functionally simulates instructions on a MIPS      allows designers to perform rapid and cycle-true simulation of  heterogeneous multi-core designs. Second, a variety of  configurations for the memory system can be modeled. Third, it  has a flexible NoC model, which allows evaluation of different  NoC architectures. Fourth, it is able to handle multi-tasking and  simulate multi-threaded applications. Finally,  it has  the  important feature of being able to automatically construct fast,  cycle-true behavioral performance models for coprocessors from  functional models by leveraging a high-level synthesis tool and  integrating these performance models with the remainder of the  design.   MC-Sim utilizes a hybrid model for simulation:  (cid:190) A fast, cycle-accurate, functional ISS for modeling the  processor cores.  (cid:190) A detailed structural and cycle-accurate model for the NoC.  (cid:190) A cycle-true, behavioral, C-based model for coprocessors,  which provides more than 45x improvement in simulation  speed over SystemC RTL models.  We summarize the features of MC-Sim and the advantages over  other popularly used simulators in Table 1.  The rest of the paper is organized as follows. Section 2 provides  a high level view of the MC-Sim simulator framework. The flow  for generating and integrating cycle-true C-based coprocessor  models from functional specifications is described in Section 3.  We also describe how the coprocessor models are integrated  with the rest of MC-Sim. In Section 4, we present experimental  results for some real-world applications. Finally, in Section 5,  we conclude the paper and provide directions for future work.  emulator [34] before modeling their execution on an out-oforder superscalar processor pipeline. To enable  faster  simulation, the effects of wrong-path instructions are not  modeled, and no address translation is performed. SESC  supports the execution of either single-threaded or sharedmemory multi-threaded applications (using a POSIX threadbased interface). However, only a single application can be  executed in a given workload. Also, although many cores can be  simulated by SESC, only snoopy cache-coherence protocols and  bus-based interconnects are supported for CMP simulation.  Processor-coprocessor simulation  Researchers investigating hardware-software co-synthesis have  also developed  tools  for performance  estimation of  heterogeneous systems. In [13], coprocessors are simulated  using a VHDL simulator with which the software code  communicates through socket calls. Simulations involving RTL  descriptions in VHDL are unacceptably slow even for medium  sized coprocessors.  C/C++ based system-level description languages such as  SystemC [2] and SpecC [3] have gained popularity as  environments for specifying both hardware and software  components in the design. However, processor simulators  described in these languages are significantly slower than  traditional instruction set simulators (ISSs) such as SimpleScalar  [7] or SESC [6]. The work published in [20][37][21] tries to  address this limitation by integrating an ISS with SystemC,  which is used to model coprocessors and on-chip interconnect.  A set of interfaces are defined to allow the SystemC kernel to  interact and synchronize with the ISS. While the software  simulation speed is improved greatly over pure SystemC  models, the hardware blocks are still described at RT-level, thus  slowing down  the overall simulation significantly. The  MESCAL project [13] uses the Liberty Simulation Environment  [10] to construct a simulator for the specified architecture that  may include both cores and custom hardware accelerators.  Emulation  An ISS is used to simulate the processor core while a prototype  of  the coprocessor  is synthesized on FPGA  in  [14].  Communication between the hardware and software components  occurs via a PCI bus. In [19], the authors present an emulation  platform consisting of multiple VLIW processors, memory  blocks and FPGA with a flexible interconnect mechanism on the  same board. While emulation allows designers to explore  heterogeneous designs rapidly, its setup takes considerable  effort. Also, long compilation times for FPGAs prevent fast  design iterations.  Multi-core and coprocessor simulators  The MPARM simulator [30] is probably the only existing  complete simulator framework for designs with multiple cores  and coprocessors. However, the processor cores that are  currently being supported in the MPARM framework are  relatively simple and automatic construction of performance  models  for  coprocessors  from  high-level  functional  specifications is not supported.  In this paper, we present a simulation framework that addresses  several of the limitations of the aforementioned tools. We call  our simulation framework MC-Sim, short for Multi Core  Simulator. MC-Sim possesses several key capabilities. First, it  Table 1: Feature comparison of microarchitecture simulators  2. MC-Sim SIMULATOR FRAMEWORK  In order to investigate the design-space of future multi-core  systems, a MPSoC simulator should be able to efficiently model  the execution of a many-core CMP. It should be able to support  workloads comprised of one or more single or multi-threaded  applications. Moreover, support for modeling a multi-banked  [35] last-level shared cache, a directory-based cache coherence  protocol that is robust in the face of network reordering, and a  switched network-on-chip that can be parameterized for a range  of topologies is essential.  A top level view of the major components of MC-Sim is shown  in Figure 1. MC-Sim can tractably simulate the execution of 64  or more active superscalar cores, and has a  flexible  configuration interface that allows fast mapping of any thread  from any application to any core in the system. For this  framework, we have designed a custom L1 and L2 cache  interface, with a robust, directory-based, MSI cache-coherence  protocol.  Caches, cores, coprocessors, and memory interfaces  can be flexibly assigned to different positions in the interconnect  topology, and inter-router links can be added or disabled using  configuration files, greatly easing the generation of a variety of  topologies. These features allow us to quickly evaluate the  impact of a variety of design options for many-core chipmultiprocessors and their interconnection networks, directly  measuring their impact on application performance. Unlike  SESC [6], MC-Sim can execute workloads comprised of  multiple applications, each either single- or multi-threaded. A  thin layer of memory system support, called the Central Page Cycle  Multiple  cores  Multithreading  Speed  Scalable  communication  Multiple  application  Coprocessor   accurate  support  models workloads  Simulation Simple Scalar  Simics/ GEMS  M5  SESC  MPAR M  MCSim  Yes  Yes  Yes  Yes  Yes  Yes  No  Yes  Up to 4  Yes  Yes  (simple  cores)  Yes  No  Yes  Yes  Yes  Yes  Yes  fast: ~150 KIPS  slow: ~7.5 KIPS @ 8  cores  slow: comparable to  Simics  fast: ~1.5 MIPS -  fast: ~32 KIPS @ 64  cores (64 threads)  n/a  Yes  No  No Yes  Yes  No  Yes  Yes  No  Yes  Yes  No  No  No  No  Yes  Yes  Handler, allows each application to share a physical view of main  memory, and allocates physical page frames to each application  on-demand. We decided not to support a full fledged OS  primarily because we wanted to ensure the tractable simulation of  multiple cores.  2.1 Processor Cores  To model the processor cores in our framework, we employ a  heavily modified version of the SESC simulator [6], harnessing  only its core processor model, and completely rewriting its L1  and L2 cache code, its on-chip interconnection network, and its  memory manager. We chose SESC primarily because of its high  simulation speed, which is roughly 10 times [6] that of  SimpleScalar [7], as shown in Table 1. This allows us to simulate  designs with 64+ cores.  However, there is no practical restriction  on the choice of simulator for processor model, and other  simulators could be substituted if desired, or a fully customized  model could be designed from scratch.  To integrate a preexisting processor model into MC-Sim, it need only be partitioned  at its L1 instruction and data-cache access point, and rewritten to  call (and be called-back) by the API of the MC-Sim memory  system.  CPH  Processor Simulators  L2  L2 cache bank  C0  C1  Core-NoC Interface  NoC  L2  L2  L2  C0  Processor core  Loosely-coupled  coprocessor  Tightly-coupled  coprocessor  Figure 1: Top level view of MC-Sim  In MC-Sim, each core has a local L1 instruction and data cache.  We have implemented an L1 to L2 cache-communication  infrastructure which maintains cache coherence with a scalable  directory-based MSI protocol. Additionally, we have defined an  interface between the processor core and the NoC that is flexible  enough to model all the kinds of interaction between the core and  the remainder of the system. For multi-tasking workloads, each  application is given its own simulation instance, where simulation  instances share memory through the Central Page Handler (CPH)  and NoC interfaces.  Any core in the system may have a unique  configuration, although the instruction set of all processor cores is  identical. For example, a simulator instance might consist of two  cores, one of which is a 4-issue superscalar processor while the  other is a single-issue processor with in-order execution. This  allows designers to experiment with configurations which have  the same number of cores but different areas by varying the  complexity of the cores used.   2.2 L2 Cache and Central Page Handler  The L2 cache is organized as a shared set of NUCA [35] cache  banks where each bank has its own cache controller. Each cache  controller  implements a directory-based cache coherence  protocol. Thus, different cores can share data through L2 caches.  The number, sizes and positions of the cache banks are  configurable. The CPH handles  the memory management  functions that are normally performed by the OS such as  allocating physical pages in memory and keeping track of the  virtual address to physical address mapping for each application  by creating page tables. This has made modeling multitasking  possible without the overhead of full system simulation.  2.3 Network on Chip  MC-Sim supports simulation of a variety of NoC architectures.  The designer can perform pure timing simulation using the NoC  implemented within MC-Sim. Statistics generated from this  simulation can be used as input to a detailed router model  (example Orion [36]) to generate NoC power numbers. Currently,  the default implementation for the NoC in MC-Sim is a 2-D mesh  with packet switching for on-chip communication. L2 cache  banks, processor cores and main-memory interfaces can be  assigned flexibly to different locations in the network using a  configuration file. Another configuration file can be optionally  specified that adds extra links (or Express Channels [31]) to the  mesh, each given a separate user specified link bandwidth. Using  these capabilities, a user can model additional mesh-based  topologies, such as a torus, or a 3D die-stacked mesh network.  Each core and L2 cache bank has a pair of message queues, one  each for incoming and outgoing messages respectively, through  which the core/bank communicates with the network. A cycle  accurate simulator model for the NoC enables us to take into  account communication latency between different components of  the design.  3. COPROCESSOR MODEL  3.1 Automatic Construction of Cycle-true  Coprocessor Models  In this section, we describe the methodology to automatically  build C-based cycle-true behavioral coprocessor models from  functional C specification. We call it cycle-true behavioral      models because our model accurately reports the number of  cycles elapsed since the invocation of the coprocessor to its  termination. Meanwhile, it is functionally identical to the original  coprocessor design. However, unlike traditional cycle-accurate  RTL models, which accurately simulate the signals and states  every clock cycle, our models filter out details of the intermediate  states in the microarchitecture of the coprocessor. Thus, we can  achieve significant simulation speedup compared  to RTL  simulation methodology, which could be very valuable to design  space exploration at early design stages.  We utilize a behavioral synthesis tool, xPilot [8] from UCLA,  which can generate a synthesizable RTL description from a  functional C-specification of the desired coprocessor. The xPilot  synthesis flow uses a CDFG to represent the coprocessor  functional specification and a state transition graph (STG) to  represent the scheduling information of the final hardware design.  We first formally define these two terms:   DEFINITION 1. A CDFG is a directed graph G(VG; EG) where   and  . Vbb is a set of basic blocks  (i.e., data flow graphs). Vop is the entire set of operations in G,  and each operation in Vop belongs to exactly one basic block. Data  edges in Ed denote the data dependencies between operations.  Control edges in Ec represent the control dependencies between  the basic blocks. Each control edge ec is associated with a  branching condition bcond(ec).  Figure 2 shows the CDFG for an implementation of the greatest  common divisor (GCD) algorithm. Note that the phi node is a  special operator in the single static assignment representation  (SSA) [22].  ∪ ∪ E E E V V V op bb = G d = G c bb2  bb3  ≠  bb1  Ф  Ф  ≤  Data edge  Control edge  Ф       Phi node  ∆       Branch operator  bb4  —  —  ≤  ≤  bb5  Ф  Figure 2: CDFG for GCD implementation  The scheduling information obtained from xPilot is captured by  an STG which is described as follows:  DEFINITION 2: An STG is a directed graph Gs(s0; Vs; Es). Vs is the  set of control states with initial state s0. Each control state  sVs ∈ contains a set of operations OP(s) and each operation op is  associated with a guard condition gc(op) to guard its execution.  Every operation in the CDFG G is assigned to a state and every  operation in the same state s is executed in the same clock cycle  in the generated RTL description. We say a basic block b belongs  to state s if s has at least one operation of b. Es is the set of  transitions edges between the control states and each state  transition edge tu→s, between state u and s is associated with a  transition condition tc(tu→s). The transition condition, tc on a  transition edge tu→s between two states u and s, is the boolean OR  s c e c u u ,s u ,s u ,s u ,s of the bcond(e) for the set of control edges, Eu,s, originating in  basic blocks belonging to u and terminating in basic blocks  → = ∨ belonging  to  s  i.e.  t ( t ) ( bcond ( e ))  where  ∈ = ∈ = → ∈ ∈ e E { e | e E , e ( b' b )  and  b ' u , b s } . xPilot  scheduler will guarantee that one and only one branch condition  will be true when the state transition occurs. A control edge e is  said to be a sub-edge of STG edge es if bcond(e) is a term of the  the transition condition associated with es.  Figure 3 illustrates the xPilot synthesis flow. At the front-end,  xPilot uses the LLVM compiler [26] from UIUC to parse the  functional description of the coprocessor specified in C/SystemC.  The synthesis tool creates a System-level Synthesis Data Model  (SSDM), which is the central data model of the synthesis system.  The C/SystemC functions in the behavioral description of the  desired coprocessor are represented as CDFGs in the SSDM.  Once the SSDM is built, the scheduling engine schedules the  operations in the CDFGs in such a manner that user-specified  timing constraints are met. The back end of xPilot performs  resource binding and generates RTL code.  We add a module in the flow of xPilot to automatically construct  C-based cycle accurate behavioral models.   DEFINITION 3: A Cycle-true Behavioral C Model (CTB-C) for a  coprocessor in our simulator framework is defined to be a CDFG  G’ with the following characteristics:  1. It is functionally equivalent to the CDFG G, i.e. it produces the  same output as CDFG G for the same input.   2. It has a cycle count variable, CV, to track the number of clock  cycles elapsed since the invocation of the coprocessor.  3. After the coprocessor model is executed, the value of CV is  identical to the number of cycles elapsed in the simulation of  the RTL description (generated by the high-level synthesis  tool) for the same set of inputs.   Thus, the coprocessor model generates the same output as the  CDFG and determines the exact number of cycles it would take  for the simulation of the RTL model to complete computation.  C specification  Front-end compiler  SSDM P latform  description   & constraints   Behavioral   synthesis  Platform-based behavioral synthesis  FSMD /SSDM  Coprocessor Simulator generation  Cycle-true C P erformance Model  Coprocessor-P rocessor Interface  Figure 3: Flow for coprocessor performance model  generation  Since CDFGs and STGs capture the behavior of a design and the  scheduling information respectively, together they contain all the  data needed  to generate  the cycle-true simulator for  the  coprocessor. We first make the following observation:  N um _ y c les c = ∑ s N um _ a c t iva t io n s ( s ) s V ∈ s  o f  STG In our work, an additional customizable function called  performance calculator is also introduced, which is used to track                 2 s 2 s 2 s 1 the timing of the coprocessor. The default implementation for this  calculator function increments the value of CV by one whenever  it is invoked. The calculator function should be called once and  only once when its corresponding state is activated. We use the  following notation in the rest of the paper. G is a CDFG and s is a  state in the STG Gs. Bs is the set of basic blocks that belong to  state s.  For a given state s, we consider set Ds that consists of all basic  blocks bb1 such that there is a basic block bb B∈ and control  edge  bb bb→ is a sub-edge of an STG edge terminating at state  s. Thus, set Ds represents all those basic blocks from which the  coprocessor can transit to state s.  LEMMA 1: If the performance calculator is inserted at the end of  all basic blocks bb1 in set Ds and executed subject to the guard  condition on control edge bb1→bb2 ( bb B∈ ), then CV is  incremented if and only if state s is activated during the RTL  simulation.  Proof: The if part – State s is activated implies that a state  transition was made to s. Based on the definition of STG, one and  only one term in the state transition edge condition is true. It also  implies that the execution path in the original CDFG is from the  corresponding sub-edge bb1→bb2 whose guard condition is true.  According to our rule, the inserted performance calculator in bb1  will be invoked once and CV is incremented by one.  The only-if part – When basic block bb1 executes, the condition of  control edge bb1→bb2 ( B∈ ) is satisfied, the performance  bb calculator is invoked. This also implies that in the STG a state  transition to s will be made.  Figure 4(a) shows a scheduling result for the GCD function  shown in Figure 2. Figure 4(b) shows the positions in the CDFG  where the performance calculator function should be invoked for  state transitions S1→S2, S1→S4 and S2→S3. For state transitions  from S1, the performance calculators PC1 and PC2 are inserted as  shown with the guard conditions associated with control edges  bb1 →bb2, and bb11→bb5 respectively. Similarly, for state  transitions from S2, the performance calculators PC3 and PC4 are  inserted as shown with the guard conditions associated with  control edges bb2 →bb3, and bb12→bb4 respectively. We do not  show the performance calculators for the other states because of  lack of space.  Theorem 1: For any coprocessor, when the CDFG annotated with  performance calculators, G’, completes execution, the value of  CV will be identical to the cycles elapsed in the simulation of the  RTL of the coprocessor for the same inputs.  The proof follows from Lemma 1.  2 3.2 Coprocessor Integration  3.2.1 Communication Architecture  We model the communication overhead between the cores and  coprocessors. We allow the coprocessor to interface with the  cores in two different ways.  1. Tightly-coupled coprocessor: Only a single core can access the  coprocessor. This mechanism is similar to that used for the  encryption engines  in  the Niagara 2 processor [9]. The  coprocessor has direct access to the L1 data cache of the core  from which it can read input data and write out its output. The  communication between the core and coprocessor takes place  through a high-speed interconnect such as the HyperTransportTM  [38] that provides high bandwidth between the core and  coprocessor. In our experiments, we set the bandwidth to be 2  Gbps, which is a conservative estimate of the achievable  bandwidth on the HyperTransport. The coprocessor CP1 in Figure  5 shows the architecture associated with a tightly coupled  coprocessor. The communication delay is modeled as the total  number of cycles to bring the data to the L1 cache and to transfer  the data over the high-speed link to the coprocessor. Similarly, we  model the delay associated with transferring the output data back  to the L1 cache.   Figure 4: An example of performance calculator insertion  2. Loosely-coupled coprocessor: The coprocessor is attached to a  router in the NoC just like a processor core. Such a coprocessor  can be shared by multiple cores in the design. Similar to a core, it  possesses a local L1 data cache. Communication with such a  coprocessor takes place over the NoC, identical to how a core  communicates. Data can be transferred to/from the coprocessor  through the shared L2 cache banks. Figure 5 shows the  architecture associated with a loosely coupled coprocessor. The  communication delay is modeled as the total number of cycles to  bring the data over the NoC to the L1 cache of the coprocessor  from the L2 banks. Similarly, we model the delay associated with  transferring the output data back to the shared L2 cache banks.  C – Core   R – NoC router    L1 – L1 cache  CP1 ,CP2 – Tightly  & Loosely Coupled Coprocessors  C L1 CP1  R CP2  L1  R  Figure 5: Coprocessor-core communication architecture  Tight coupling of coprocessors to cores greatly reduces the  communication time; however, tightly coupled coprocessors  cannot be shared by multiple cores. The designer can choose the  mechanism that best suits the characteristics of the application.   3.2.2 Coprocessor API, Invocation and Execution  We provide a configuration file to MC-Sim that describes the  location and the types of arguments of every coprocessor in the  design. Each coprocessor instance in the design is given a unique      id. The configuration file is generated automatically during our  high-level synthesis process.  We define a system call named coprocessor() to invoke a  coprocessor from the application code. This system call takes as  input the id of the coprocessor to be invoked and a list of  addresses of the arguments for the coprocessor. The API is  sufficiently generic to invoke any coprocessor irrespective of the  number of arguments and the data types of the arguments. While  this API is simple, it is adequate for our simulation purposes.   To invoke the coprocessor, the designer needs to modify the  application by replacing the function call with a coprocessor  system call. The arguments to this system call are simply the id of  the coprocessor to invoke and the same arguments passed in the  original function call; MC-Sim automatically performs data fetch  and transfer to/from the coprocessor depending on the type of  each argument.  We describe briefly the steps involved in the invocation and  execution of the coprocessor module. Firstly, MC-Sim “traps” the  coprocessor system call from the application binary. The  argument id of the system call is used to obtain the location of the  coprocessor, number of arguments and the sizes of the arguments.  Using the starting address and size of each read and read/write  argument, a series of read requests are issued to the memory  hierarchy. Once all the reads are complete, the cycle-true  coprocessor model is invoked to determine the values of the  outputs and the number of cycles required for this computation.  After computation is complete, output data is written by issuing a  series of write requests to the memory hierarchy. During the read  and write  steps,  the  timing overhead associated with  communication is modeled based on the architecture described in  Section 3.2.1. Finally, the coprocessor signals to the invoking  core that it has completed execution.  4. EXPERIMENTAL RESULTS  4.1 Evaluating the Coprocessor Simulators  We first compare the accuracy and simulation speed of our cycletrue behavioral C (CTB-C) model with RT-level SystemC model  generated by our synthesis tool.   Table 2 shows the experimental results for five small-sized  computation kernels used in media processing and encryption  applictions. The generated C performance models can provide  exact performance numbers while the simulation speed is much  faster than RTL simulation. On an average, we can achieve 45.3X  speedup for our benchmarks.  Table 2: #Cycles and speed of coprocessor simulator  Simulation Speed(sec)  #Cycles RTL-SystemC CTB-C Speedup 0.128   0.004   32.8  0.219   0.004   56.2  Benchmark  147  283  Dct  Idct  motion  compensation(MC)  pipelined MC  Sha  4.170   0.086   48.5  1.230   0.240   0.030   0.005   41.0  48.0  873  303  396  4.2 Lithography Simulation  In order to evaluate the complete simulation framework after  integrating the coprocessor simulators with MC-Sim, we use a  lithography simulation application developed in [24] as a test  driver. Litho-simulation is a computation intensive application,  which simulates the lithography process used for printing circuit  patterns onto wafers. In [24], the computation intensive kernel of  litho simulation is synthesized on FPGA as a coprocessor. A  number of implementations based on different kernel and  memory partitioning strategies were experimented with in [24].  We validate our simulation results against a design with 5x5  partition [24] implemented on XtremeData’s XD1000 [27]  development system, which consists an AMD Opteron 248 CPU  and Altera’s Stratix II FPGA. The implementation uses 25,042  ALUTs and 2,972,876 memory bits. A 15X speedup compared  with the pure software implementation on this system was  reported in [24]. We configure a similar system in MC-Sim by  integrating the generated coprocessor simulator with a 4-issue,  superscalar core. Table 3 shows the estimated speedup for  different  implementations  over  the  purely  software  implementation. Comparing the result in the third column with  the implementation in [24], we find that our simulation result is  off by a mere 7%. Moreover, RTL simulation of the design used  in [24] would not complete even after 1 week whereas our  simulation finished within 90 minutes.  Table 3. Speedup for different coprocessor implementations  3x3  4x4  5x5  6x6  7.58   11.61   14.49  19.59  Speedup 4.3 MPEG4 Decoder  Finally, we simulate a variety of design instances for the MPEG4  decoder provided by Xilinx [23]. The block diagram for the  CopyControl  Parser MC  Texture Update Input  Stream IDCT  Figure 6: Block diagram for MPEG-4 decoder  MPEG4 decoder is shown in Figure 6. The frame data is divided  into 16x16 macroblocks each containing six 8x8 blocks for  YCbCr 4:2:0 formatted data. The goal was to achieve a  throughput of 30 frames/second for the decoder. We first simulate  the decoder on a 2GHz, 4-issue superscalar processor with 64KB  L1 cache and 256KB L2 cache. We consider this system to be the  base system with which we compare all other implementations.  The profiling results for the decoder when running on the base  system is shown in Table 4.   We generate all coprocessors using xPilot [8] and obtain area  numbers for coprocessors from Magma synthesis tool [40]. For  processors, we obtain area numbers from the ARM website [39].  We obtain the approximate area of our superscalar processor from  the area of the Cortex A8 processor by ARM. A single issue  processor in our experiments is assumed to have approximately  the same area as a processor in the ARM 11 family. We report  area numbers for 65nm TSMC technology. For the cases where  the area numbers for the required technology are not available,  we use quadratic scaling formulas for area [41]. The default NoC  architecture for our case studies is a 2-D mesh.  Based on the block diagram, we first construct a multi-threaded  implementation  of  the  decoder with  the  Parser,  MotionCompensation (MC), TextureIDCT (IDCT) and Texture  Update modules running on four different cores in a pipelined         fashion. The Copy Control module is executed on the same core  as the Parser module. However, as seen in the second row of  Table 5, the pipelined version achieves modest speedup – about  1.47 times - but at a huge increase in area (speedup for a design is  defined as the ratio of the frames per second for the design to the  frames per second for the base system). This is because of the  large disparities in the running times of the different modules,  which caused the cores running the Parser and TextureUpdate to  be idle for a large portion of the time. To obtain a better design,  we synthesized a pipelined coprocessor for the MC module  running at 200MHz and pipelined its execution with the software  components in the system, which now run on a single 4-issue  core. This implementation achieves 1.6X speedup.  Table 4. Profiling information for MPEG4 decoder  Modules  Percentage of total  Avg.  execution time  #Cycles/Call  Parser  21.55  2913  Copy Control  3.85  1476  MC  35.43  15,934  IDCT  19.08  24,810  TextureUpdate  5.66  2546  Further investigation reveals that the IDCT module became the  bottleneck consuming a large portion of the time on the  processor. We implement both the IDCT and MC modules as  coprocessors, running alongside a single core. By pipelining the  execution of the coprocessors with the software components of  the design, we are able to achieve significant speedup – up to 2.75  times. All our results are listed in Table 5. In a further attempt to  reduce system area, we simulate the coprocessors with a simple,  single-issue in-order core with just 32KB L1 cache. As shown in  the last row of Table 5, even this simple system meets the desired  throughput of 30 frames/second. Thus, we obtained a low area  design for the decoder. We repeated all the experiments using a 1  GHz processor. However, we did not find any configuration that  achieves the required throughput.  5. CONCLUSION  In  this paper, we have described  the MC-Sim simulator  framework that is capable of tractably simulating a MPSoC  design with several heterogeneous components. Our framework is  designed with the ability to simulate workloads comprised of  multiple applications (i.e. multi-tasking), each of which can be  single- or multi-threaded (i.e. co-operatively multithreaded).  Additionally, MC-Sim supports a flexible memory system, which  includes L1 caches that are local to processor cores, L2 caches  that are shared between cores and software controlled scratchpad  memories. Our framework has a flexible and accurate structural  model for the NoC for on-chip communication. We also present a  methodology to automatically generate and interface coprocessor  simulators with processor cores. Experiments on real-life  applications indicate that not only is our simulator accurate, but  simulation times are well within acceptable limits. Note that our  simulator framework can be integrated into platforms such as  Metropolis [4] and Artemis [5] to provide accurate timing  information. Future work will take into account power modeling  for the cores and coprocessors as well.  6. ACKNOWLEDGEMENTS  This work is partially supported by the MARCO GSRC center,  the SRC contract 2005-TJ-1317, and the NSF grant CNS0725354.  7. "
2008,ROAdNoC - runtime observability for an adaptive network on chip architecture.,"Hard-to-predict system behavior and/or reliability issues resulting from migrating to new technology nodes requires considering runtime adaptivity in future on-chip systems. Runtime observability is a prerequisite for runtime adaptivity as it is providing necessary system information gathered on-the-fly. We are presenting the first comprehensive runtime observability infrastructure for an adaptive network on chip architecture which is flexible (e.g. in choosing the routing path), hardly intrusive, and requires little additional overhead (around 0.7% of the total link bandwidth). The hardware overhead is negligible, too, and is in fact less than the hardware savings due to resource multiplexing capabilities that are achieved through runtime observability/adaptivity. As an example, our on-demand buffer assignment scheme increases the buffer utilization and decreases the overall buffer requirements by an average of 42% (the buffer area amounts to about 60% of the entire router area [19]) in our case study analysis compared to a fixed buffer assignment scheme [7]. Our runtime observability on an average also increases the connection success rate by 62% compared to the case without runtime observability for the applications from the E3S benchmark suite [6]. We show the advantages obtained through runtime observability and compare with state-of-the art communication-centric designs.","ROAdNoC: Runtime Observability for an Adaptive Network on Chip Architecture Mohammad Abdullah Al Faruque, Thomas Ebi, and J ¨org Henkel University of Karlsruhe, Chair for Embedded Systems, Karlsruhe, Germany {alfaruque, ebi, henkel} @ informatik.uni-karlsruhe.de Abstract— Hard-to-predict system behavior and/or reliability issues resulting from migrating to new technology nodes requires considering runtime adaptivity in future on-chip systems. Runtime observability is a prerequisite for runtime adaptivity as it is providing necessary system information gathered on-the-ﬂy. We are presenting the ﬁrst comprehensive runtime observability infrastructure for an adaptive network on chip architecture which is ﬂexible (e.g. in choosing the routing path), hardly intrusive, and requires little additional overhead (around 0.7% of the total link bandwidth). The hardware overhead is negligible, too, and is in fact less than the hardware savings due to resource multiplexing capabilities that are achieved through runtime observability/adaptivity. As an example, our on-demand buffer assignment scheme increases the buffer utilization and decreases the overall buffer requirements by an average of 42% (the buffer area amounts to about 60% of the entire router area [19]) in our case study analysis compared to a ﬁxed buffer assignment scheme [7]. Our runtime observability on an average also increases the connection success rate by 62% compared to the case without runtime observability for the applications from the E3S benchmark suite [6]. We show the advantages obtained through runtime observability and compare with state-of-the art communication-centric designs. I . IN TRODUC T ION AND MOT IVAT ION The 100 Billion transistor chip is predicted to emerge within a decade [3]. It will allow for integration of hundreds or even thousands of processor cores on a single die. It is obvious that such a large number of cores requires a sophisticated on-chip communication architecture. Hence, it is anticipated that future designs need to be communication-centric [3]. The fact that interconnects need special attention even in current Multi Processor Systems on Chip (MPSoCs) has already been recognized several years ago when research started to focus on Networks on Chip (NoCs) [5], [9]. Application speciﬁc NoCs [1], [14], are design-time parameterized architectures with a custom topology, ﬁxed routing scheme, and a ﬁxed number of allowed virtual connections at each output port [1], [7]. They are generally tailor-made for a certain application or an application domain and fail in scenarios of hard-topredict system behavior and/or in situations where reliability is a concern. Some scenarios are as follows : • The system constraints may change during runtime. • The user of the system may change their pattern of how to operate/use the system. • Smaller feature sizes in the nano age will cause reliability concerns. It will require building future reliable systems out of un-reliable components [3]. A reliable communication-centric System on Chip (SoC) may, for example, depend upon the ability of the NoC to route trafﬁc in such a way that it can efﬁciently bypass faulty areas at runtime. All these scenarios – from user behavior to reliability issues – require designing systems with adaptivity capabilities in mind which allow application variations and to react on faulty situations accordingly. Adaptivity is required in both the system-level as well as in the architecture-level where it is realized through modiﬁcation thereof, or even new paradigms in architectural design. We consider the software part between the application and the underlying hardware layer executed in the processing element as the systemlevel and the data transmission part which is implemented in hardware as the architecture-level. Changes in user behavior, system constraints, and/or reliability issues can be effectively compensated at system-level by, for instance, dynamically (re-)mapping a running application at runtime. Architecturelevel modiﬁcations on the other side may help to increase the resource utilization at runtime as proposed in [7]. In order to assure a certain degree of quality-of-service (e.g. guarantees in performance and bandwidth), a feedback of the current system state must be available. This can be achieved through runtime observability in an adaptive system. A runtime observability infrastructure with small hardware and communication overheads would be more than compensated by the degree of freedom achieved using adaptation. Within this paper we propose an event-based NoC monitoring component1 at architecture-level that offers runtime observability. The prime challenges for runtime observability are scalability, ﬂexibility, non-intrusiveness, real-time capabilities, and cost. For the monitoring components to be as non-intrusive as possible, they need to keep their interference with normal system execution (probe effects) [12] at a minimum. An example of these effects would be the sending of monitoring packets2 through the regular data network. If these packets are injected too rapidly, they demand resources which otherwise may have been used for regular trafﬁc. It is therefore necessary to limit monitoring trafﬁc by keeping its bandwidth usage and occurrence frequency minimal. The rest of the paper is organized as follows. After presenting our novel contribution and related work in II, in III we introduce our adaptive on-chip communication architecture. In IV our novel ROAdNoC infrastructure is explained in detail. Our hardware implementation for the monitoring components is shown in V. Experimental results are discussed in VI with VII concluding the paper. I I . R E LAT ED WORK AND OUR NOV E L CON TR IBU T ION Runtime adaptivity in both the system-level and the architecture-level considering the user behavior and reliability issues, is a relatively new aspect of SoC design introduced in [7], [10]. Recently, several general-purpose NoCs such as Tile64TM , an embedded multicore by Tilera [19], and an 80-core general-purpose processor from Intel [11] have been proposed. They are design-time parametrized (e.g. the number of output ports and the worst case amount of concurrent virtual connections in a single output port) but focus more on generalpurpose issues and are hardly capable of changing different architecture-level parameters such as buffer assignments to different output ports on-demand and thus suffer from low 1 In this paper we denote runtime observability as a complete infrastructure and monitoring as a hardware component attached to each tile. 2 This is the trafﬁc that is generated during runtime observation of the system state and is described in detail later in this paper. Fig. 1. Overview of our adaptive on-chip communication architecture resource utilization. They also lack a sophisticated resource management scheme (e.g. runtime application (re-)mapping). There is also related work in the domain of on-demand interconnection schemes in different problem spaces. In [18] the authors proposed to provide interconnection on-demand by adapting the physical network. The required number of links increases exponentially relative to the number of processing elements making this approach non-scalable. In [16] the authors have proposed a power-aware network whose links are turned on and off on-demand in response to bursts and dips of trafﬁc. Their approach assumes that future trafﬁc characteristics are predicable based on recent trafﬁc patterns which may not be possible in situations similar to those we itemized earlier. In [2] the authors present a dynamic communication infrastructure which routes trafﬁc around modules placed dynamically on a reconﬁgurable device. It is built on top of a reconﬁgurable hardware, i.e. on an FPGA and it is limited to such devices. In summary, it can be stated that observability capabilities for on-chip communication have not been proactively investigated in the NoC domain. In [13] authors have mentioned an operating system controlled on-chip runtime collection of trafﬁc statistics at the Network Interface (NI) to optimize the usage of communication resources in a NoC using a centralized resource management scheme. In [4] authors have presented a generic event-based NoC Monitoring Service (NoCMS) for Æthereal. It is not designed speciﬁcally to detect faults in network trafﬁc during runtime adaptation but instead to gather NoC behavior statistics (debugging). In [17] authors further used the monitoring probes proposed in [4] for a new communication service to control congestion. In a nutshell, the Æthereal monitoring framework is not used to adapt the underlying on-chip communication architecture. Runtime observability is also not included in general-purpose NoCs (e.g. [11], [19]) as these architectures do not adapt at the architecture-level to increase resource utilization. Recently, authors in [15] have also focused on self-monitoring components for NoCs considering reliability factors. We have integrated a runtime observability infrastructure for our adaptive NoC at the architecture-level. It analyzes the communication infrastructure during runtime and self-adapts depending on the monitoring trafﬁc on when and how a certain router should be conﬁgured for a certain connection. Our runtime observability infrastructure on an average increases the connection success rate by 62% compared to having no runtime observability for the automotive application from the E3S benchmark suite [6]. The extra overhead that stems from the monitoring component is smaller than the hardware saving due to resource multiplexing in the architecture. Our on-demand buffer assignment scheme increases the buffer utilization and decreases the overall buffer use on an average of 42% in our experiment compared to a ﬁxed buffer assignment scheme [7]. Our novel contribution is as follows: To employ successful adaptation to the communication infrastructure needs to be observed. Therefore, to provide runtime observability for realizing a successful on-demand adaptation, we present a novel low cost runtime observability infrastructure. It is highly ﬂexible and hardly intrusive. I I I . OUR RUN T IM E ADA P T IV E A P PROACH As most NoCs, our adaptive on-chip communication architecture is pipelined, utilizes packet-based communication, deploys wormhole routing, and has a regular 2-D mesh topology. The overview of our adaptive scheme shown in Fig. 1 is divided into two main parts along with the runtime observability infrastructure, the system-level, and the architecture-level. The adaptivity at system-level is deployed using a runtime agent-based distributed application mapping scheme. An agent is a computational entity, realized in software, that acts on behalf of other entities. A detailed description of our agentbased runtime application mapping is presented in [8]. The architecture-level handles the runtime routing algorithm and the on-demand VCB3 assignment besides the normal dataﬂow functionalities of the router. To accomplish a successful adaptation, both the system-level and the architecture-level require runtime observability. A. System-level Adaptation Our proposed agent-based distributed application mapping algorithm dynamically maps applications at runtime as needed. Therefore, one or more application tasks are mapped onto NoC tiles which fulﬁll the task’s requirements (computation/communication). The detailed scheme is explained in [8]. To obtain a scalable mapping solution we have reduced the 3A Virtual Channel (VC) is a unidirectional virtual connection between two tiles and is realized by message buffers, Virtual Channel Buffers (VCB). computation load by conﬁning mapping to clusters which are a connected subset of NoC tiles. The clusters have a variable size that can be adjusted during runtime and each cluster has one cluster agent which is responsible for (re-)mapping. Among others, there are two main reasons for (re-)mapping. The ﬁrst is due to changing user behavior, i.e. new application tasks scheduled to run at a speciﬁc time t. The second is as a response to faults during adaptation reported by the monitoring component associated with the cluster agent. This causes the cluster agent to attempt to update the current mapping instance based on received information (i.e. connection source, destination tiles, and fault type). This limits the more expensive complete (re-)mappings to when they are absolutely needed. If the cluster agent is unable to ﬁnd a new mapping instance it contacts a global agent. These special agents are responsible for cluster selection, coordination, and reclustering. The global agent then ﬁrst tries to resize the cluster associated with the cluster agent. If this fails, a different cluster is chosen and a new mapping is done. The actual mapping is accomplished using a heuristic which is also explained in [8]. All agents are implemented in software and may be migrated to run on any PE in every tile within their deployment area. All the information necessary to manage a cluster/global agent is stored in the local memory associated with the tile where the current instance of the cluster/global agent dwells. No extra hardware is necessary for managing this information and it is transmitted as regular system conﬁguration trafﬁc. B. Architecture-level Adaptation Once a mapping instance has been set up at the systemlevel, the architecture-level must then handle the resulting connections in every tile. For a requesting connection, the route is ﬁrst checked in every possible direction and the VCB is assigned accordingly on-demand. The adaptive routing algorithm assigns each output port a weight based on available bandwidth, the horizontal distance, and the vertical distance between the current and the destination tiles which maximizes the number of sensible routing choices along its route. Up until now, the number of VCBs at one port has always been ﬁxed at design-time [1], [11]. With on-demand assignment (the runtime routing algorithm and on-demand buffer assignment schemes are explained in [7]), the VCBs are not tied to ports, but only to the router itself. The router may distribute the VCBs to any route as needed by assigning a connection to the VCB through the Virtual Channel Arbiter (VCA) and then assigning the VCB to an output port. The beneﬁts of such an on-demand assignment are evident: through on-demand assignment, buffers are only assigned when needed meaning that VCBs can be reused by different ports and therefore, the buffer utilization increases and that decreases the overall buffer use on an average of 42% in our case study analysis compared to a ﬁxed buffer assignment scheme [7]. IV. RUN T IM E OB S ERVAB I L I TY IN FRA S TRUC TUR E After explaining the main features of our NoC platform we now focus on the contribution of this paper. Our Runtime Observability for an Adaptive Network on Chip (ROAdNoC) that supports successful architecture-level adaptation is implemented using monitoring components inside each tile. A. Events ROAdNoC is event-based. Events are caused by failures in a subsystem of an individual router: i.e. the adaptive routing algorithm. The list of events are explained in the following:4 4 The event list is generic and can be enhanced depending on the architecture. It covers our on-demand buffer assignment and routing algorithm. Fig. 2. Overview of the monitoring component • TTL-expire-event: In order to assure deadlock-free routing, each packet is given a maximum time-to-live (TTL) hop count. If a packet fails to reach its destination within the TTL, it is removed from the network. The TTL is the Manhattan Distance plus a given maximum number of misroutes. • No-route-found-event: If the routing algorithm fails to ﬁnd any available routes inside a router, i.e. there are not enough available bandwidth slots in any direction, the packet is removed from the network. • No-buffer-event: If the VCA fails to ﬁnd a free VCB to hold the incoming packet it is removed from the network. • Buffer-full-event: Occurs when the VCA already has assigned a VCB to a connection but cannot write to it because it is full. This does not directly result in packet loss but is a sign of congestion in the network. This situation is resolved automatically, however it should be observed and be reacted to if it persists. Unlike in Æthereal [4], these events are used to identify the faults during NoC adaptation at architecture-level and are used to invoke the necessary steps to remedy it. The events given here are binary in nature; that is, either an event has occurred or not (except buffer-full-event which is invoked for a given speciﬁed value). This simpliﬁcation eliminates the need for attributes to be supplied for events as with the monitoring component for Æthereal [4]. The user-conﬁguration-events of Æthereal (high level communication conﬁguration events such as connection-opened and connection-closed) are indirectly observed. However this is only done in order to set up the counters for each connection and to free them when the connection closes. B. Design and Event Collection The monitoring component of a router for our ROAdNoC consists of a look-up-table (LUT) containing a set of counters for each connection going through the router. These are tied to events which can occur in the on-demand buffer assignment and the adaptive routing part of the router and are incremented every time one is reported, thereby collecting data on events. The counters are stored in the LUT with the corresponding connection ID and the source address of a connection. In particular, the source address can be the same address as the monitoring component if the corresponding PE is the source of the connection. This is a special case, as the counters PE1 sends C1. C1 arrives at Router R2 M2 adds C1 to ist table. Conn_ID No-buffer Conn_ID No-buffer VCA of R1 fails to find a free VC. M2 increments its counter. Conn_ID No-buffer “No-buffer” threshold is 1, M2 sends message to M1 M2 resets its counter. Conn_ID No-buffer M1 increments its counter since threshold is met,M1 sends tail flit to R2. M1 resets counter, resending C1, M2 removes C1 upon receiving tail flit. Conn_ID No-buffer Conn_ID No-buffer M1 M2 C1 0 0 C1 C1 0 0 M1 M2 Data C1 C1 0 1 M1 M2 Data M1 M2 Data C1 C1 0 0 C1 C1 M1 M2 Data R1 Ri Rj R2 R1 Ri Rj R2 R1 Ri Rj R2 R1 Ri Rj R2 Monitor Packet R1 Ri Rj R2 0 0 1 0 C1 M1 M2 Data R1 Ri Rj R2 (Time) T1 T2 T3 T4 T5 T6 Fig. 3. Runtime observability capabilities of ROAdNoC are not only incremented by events occurring within the router but also through messages received from monitoring components in other routers. Algorithm 1 Aggregation and processing of monitoring trafﬁc input: event e = {event type t, connection ID C, connection source S } deﬁnitions: X : current router; E : event queue LUT[connection ID, event type]: event counter look-up-table τt : given threshold for events of type t δ : given threshold for re-sending sc : send counter in S for C ; NI: network interface CA: cluster agent associated with X 1: get next event e from E 2: event counter ← LUT[C, t] 3: increment event counter 4: if event counter > τ then 5: if X != S then 6: send event message e = {t, C, S } to S 7: else 8: signal NI: send tail ﬂit from packet buffer for C to close conn. 9: if sc < δ then 10: signal NI: re-send packet for C 11: else send (re-)mapping message {remap,S ,t} to CA 12: 13: end if 14: end if LUT[C, t] ← 0 15: 16: else 17: LUT[C, t] ← event counter 18: end if C. Aggregation and Processing An adaptation fault occurs when an event counter reaches a certain value. The event aggregation and processing scheme is explained in Fig. 2 and the functionality upon problem detection is given in Algorithm 1. The aggregation is done through the NI by sending messages to the source of the connection. The processing is done partially in the NI and in the cluster agent. The NI takes care of re-transmission while the cluster agent is invoked if a (re-)mapping is needed. A time-line diagram portraying a certain scenario of the ROAdNoC infrastructure can be seen in Fig. 3. T1 : The processing element PE1 associated with router R1 begins to send data to another PE. The NI assigns this connection the connection ID C1 . Thus, the monitoring component M1 of R1 adds this connection to its list of observed connections. Here, only one exemplary counter representing the event of no-buffer being available in a router is given. Its initial value is zero. T2 : On its way to the destination the header ﬂit of this connection arrives at R2 . R2 is generally not reached after one hop; the header ﬂit may already have been routed through other routers. Upon arrival of the header ﬂit, C1 is added to the connection table of M2 at R2 . T3 : The ﬂit then progresses through R2 until it reaches the VCA which fails to assign a free buffer for C1 . This event is reported to M2 which increments its no-buffer counter. The VCA then simply discards the header ﬂit and all subsequent ﬂits and does not send a NACK signal as it would if the buffer were already successfully assigned but simply full. This prevents blocking in previous routers and a tail ﬂit can arrive to close the connection. T4 : For the no-buffer counter the threshold is one. That is, one no-buffer-event is enough to invoke a monitoring packet from the monitoring component. M2 informs the sender of the connection through its NI which sends a monitoring packet to the monitoring component M1 at time T4 . At the same time, M2 resets its no-buffer counter for connection C1 . T5 : Once the monitoring packet arrives at M1 it increments its own counter for C1 and, since the threshold is met, it informs its NI to close the current connection C1 . This is done by simply sending a tail ﬂit. T6 : M1 has already reset its no-buffer counter and the NI is in the process of re-sending its data. The tail ﬂit arrives at R2 causing M2 to remove C1 from its connection table. D. Monitoring Related Trafﬁc The monitoring component is situated partially between the router and the NI (Fig. 2). It is therefore able to interact with the NI to send its own packets over the regular communication network. This means, however, that the monitoring trafﬁc must compete with regular transmissions for network resources. The monitoring packet must be of a higher priority to allow it to preempt regular connections in a VCB. When using only two priorities, one for regular trafﬁc and one for monitoring trafﬁc, a packet’s priority requires a one-bit ﬁeld in the header ﬂit. For the rest of the ﬁelds we give an example monitoring packet in a 4×4 NoC. It is two ﬂits in size and is composed of a regular header ﬂit for transmission plus a tail ﬂit with payload data containing at least the triggering connection ID and the type of event. In addition, it may also contain information such as the source of the transmission which is used to provide the cluster agent with additional knowledge it may exploit during (re-)mapping. It does not require a source ﬁeld in the header since monitoring packets are not monitored themselves. The size of the monitoring packet can be calculated from the formulas given in Table 1. Size n × m 2 bit log2 (priorities) log2 (n × m) log2 (n + m + 2x† ) Flit part Type Priority Destination TTL BW log2 (BW slots) † x = number of misroutes Table 1: Flit size in an n × m NoC and in a 4 × 4 NoC Size 4 × 4 2 bit 1 bit (2 priorities) 8 bit 4 bit 3 bit (8 slots) The frequency with which monitoring packets are generated is also important. They are event-based and are only sent when an event occurs. Since events are only generated on faults during adaptation, there is no monitoring trafﬁc when the network operates normally. Events can also eventually initiate (re)mapping which comes with a high communication overhead. It is, however, also through observability that unnecessary (re)mapping can be avoided compared to a scheme where any connection fault automatically calls for (re-)mapping. V. HARDWAR E IM P L EM EN TAT ION We implemented ROAdNoC and evaluated the area overhead on a XILINX Virtex2 FPGA [20] board. The event-counter values are stored in an LUT. One entry in the LUT ties the connection ID to the source of the connection and to its associated counters. If there are n VCBs and k inputs, then (n + k) entries are needed. Connections are added to the LUT when a header ﬂit arrives at a router (Fig. 4(b)). The arrival causes the set and conﬁgure ﬂags to be triggered, initiating a write to the LUT and setting the counter values to zero. Similarly, a tail ﬂit arriving at the router causes the conﬁgure ﬂag to be triggered while the set ﬂag remains zero. This causes the monitoring component to remove the connection from the LUT. Once an event occurs it initiates a read from the LUT using the event connection ID (Fig. 4(a)). It then compares the counter value returned from the LUT of the event type corresponding to the event type that arrived. If the counter value has reached its threshold, the NI part of the monitoring component is informed and the counter value is set to zero in the LUT. If not, the incremented value is written to the LUT. FIFO 10 Read/ Write r/w addr F I F O LUT LUT Resend Remap 4 4 8 4 4 TTL No Buffer e g a s s e M d n e S e d o n r e h t o o T No Buffer  Threshold Incr Incr Ä0000"" Ä0000"" TTL  Threshold Router Router 10 8 8 Ä0000"" Ä0000"" 4 4 F I F O ID10 bit Configure Set/reset Ä0..0"" Source 8 bit Ready incr reset Resend Counter out Resend Threshold Own Address NI Write r/w addr LUT a) Analyzing events with LUT b) Adding and deleting connections from  the  monitor using a LUT Fig. 4. Hardware for adding and analyzing monitoring events The NI part of the monitoring component, upon receiving an event, ﬁrst compares the connection source with its own address. If it is not the sender then a packet is sent to the remote sender. Otherwise, the connection send count is examined to ﬁnd out if there are previous send attempts by comparing the connection-send counter stored in a register with a given re-send threshold. Based upon this, the NI is either told to re-send the packet if the threshold has not been met or a (re-)mapping is required. If the packet is re-sent, the connection-send counter is incremented. A (re-)mapping causes the counter to be reset to zero. Each router has 5 input ports resulting in 5 possible simultaneous connections needing to be set up in a monitoring component. Also, using a LUT entails a few cycles delay in which new connections/events cannot be processed. To allow each tile to function using only one monitoring component, FIFOs are added to buffer its inputs. V I . R E SU LT S AND CA S E S TUDY ANA LY S I S We have evaluated our ROAdNoC infrastructure with several parameters that directly inﬂuence the monitoring trafﬁc and bandwidth usage: • The packet injection rate determines the arrival frequency of the new packets to the network in each router. • The packet ﬂit size is responsible for the duration of trafﬁc (along with the allocated bandwidth slots). • The allocated link bandwidth slots per connection inﬂuence the number of simultaneous connections per link. • The number of VCBs limits the number of simultaneous connections per router. A number of assumptions are made to determine the simulation parameters: the trafﬁc distribution used is uniform, the data packet size is 200 ﬂits, the monitoring packet size is 2 ﬂits, and the bandwidth is 20 slots. These parameters have been chosen to observe the effects of both no-buffer-event and no-route-found-event. For the ﬁrst simulation the data packet injection rates are based on allocated bandwidth slots. They are chosen as to supply a (near) continuous stream of data by using the highest possible rates. For instance, a connection allocated 1 slot out of 20 can at most send one ﬂit every 20ns (20 cycles). Hence, the highest accommodatable data packet (200 ﬂits) injection rate is one packet every 4us. The trafﬁc is streaming with packet injection being normally distributed with some variance. This trafﬁc is the worst case for VCB usage as continuous trafﬁc also requires constant VCB assignment. In the simulation each router has 8 VCBs. For the adaptive routing algorithm, the worst case is any slot value greater than 10 as each link can only transmit one connection of this type. The simulation results (Fig. 5) show a gradually increasing monitoring packet injection rate for increasing trafﬁc density. However, the monitoring trafﬁc remains low considering the overall link bandwidth – less than 0.7%. Fig. 6 shows the effect of different number of VCBs per router and allocated bandwidth slots on the monitoring packet injection rate. There is a clear distinction between the low bandwidth/continuous trafﬁc on the left and the high bandwidth/burst trafﬁc on the right. This is due to the VCB assignment being the dominant cause of monitoring events in the left part and the adaptive routing in the right part. Fig. 5. Monitoring packets injection and trafﬁc density The trafﬁc generated by ROAdNoC cannot directly be compared to that of the Æthereal monitoring component. The occurrence of events in Æthereal monitoring component is different to ours as they are mainly managing events necessary for debugging whereas we are managing different types of events that are needed to adapt the on-chip communication architecture. Using only connection-opened-events and connection-closed-events to calculate the resulting data rate assumes that all connections are set up successfully and speciﬁcally no alert-events occur. Under such circumstances our implementation would generate no trafﬁc. For comparison we assume Æthereal to have a comparable routing algorithm which is able to choose alternative routes. It is assumed to produce Æthereal NoC alert-events when no route is found.       Furthermore, it is assumed that any failed connection attempts are resolved through re-routing or (re-)mapping if needed. Taking the assumptions from [4] but expanding the trafﬁc model by the number of successful connections setup by the initial attempt to set up 200 connections, the two approaches may be compared. To calculate the total monitoring trafﬁc tM we require the number of unsuccessful connections u per second, the number of total connections c (200) per second, the monitoring trafﬁc for an unsuccessful connection tu , and the monitoring trafﬁc for a successful connection ts . For the ﬁrst attempt we calculate the monitoring trafﬁc tM 1 : tM 1 = u · tu + (c − u) · ts (1) Unsuccessful connections are assumed to be successful after they are re-routed causing the additional monitoring trafﬁc, tM 2 to be u · ts . By adding tM 1 and tM 2 we obtain the total trafﬁc shown in Table 2. For the ﬁrst comparison, the Æthereal monitoring component produces both connectionopened/closed-events for successful connections and alertevents for unsuccessful ones. The unsuccessful ones then also produce connection-opened/closed-events as they are established successfully after routing. However, since Æthereal can switch the monitoring of speciﬁc events on and off, a more direct comparison is given by limiting the Æthereal monitoring to only alert-events. The results show that ROAdNoC generates less trafﬁc even with the simple proﬁle of the Æthereal monitoring. In conclusion, both monitoring components are Successful connections Fig. 6. Causes of monitoring events. Monitoring Æthereal Æthereal trafﬁc (Alert & (Alert-events) (ROAdNoC) Conﬁg.-events) only) 50 1.2KB/s 6.6KB/s 1.8KB/s 100 0.8KB/s 6KB/s 1.2KB/s 150 0.4KB/s 5.4KB/s 0.6KB/s 200 0KB/s 4.8KB/s 0KB/s Table 2: Trafﬁc comparison using 200 connections/s designed with entirely different goals in mind. Our ROAdNoC infrastructure is designed speciﬁcally to facilitate the adaptivity of the NoC and thus only monitors events required to control the NoC conﬁguration. Fig. 7 shows the effect of re-sending packets on the number of packets which are able to be successfully transmitted for the E3S benchmark suite [6]. On an average, a re-sending threshold of 1 is able to increase the success rate by 62% compared to the case without runtime observability. For higher threshold values this value increases even further, allowing our infrastructure to avoid a costly (re-)mapping. V I I . CONC LU S ION We have introduced our approach of an infrastructure that provides runtime observability for an adaptive network on chip architecture. It is hardly intrusive, i.e. in worst case it may require a mere 0.7% of the total link capacity. Besides the main Fig. 7. Unsuccessful connection for various re-sending thresholds objective of achieving ﬂexibility in the communication architecture for higher resource utilization the hardware overhead at architecture-level due to runtime observation is rather small (46 slices). As a result, ROAdNoC increases the connection success rate by 62% in average compared to state-of-the-art approaches. It is currently the ﬁrst prototype of its kind that can efﬁciently cope with hard-to-predict system behavior as a result of constraints that may change during runtime, reliability issues etc. "
2008,A voltage-frequency island aware energy optimization framework for networks-on-chip.,"In this paper, we present a partitioning, mapping, and routing optimization framework for energy-efficient VFI (voltage-frequency island) based network-on-chip. Unlike the recent work [10] which only performs partitioning together with voltage-frequency assignment for a given mesh network layout, our framework consists of three key VFI-aware components, i.e., VFI-aware partitioning, VFI-aware mapping, and VFI-aware routing. Thus our technique effectively reduces VFI overheads such as mixed clock FIFOs and voltage level converters by over 82% and energy consumption by over 9% compared with the previous state-of-art works [10].","A Voltage-Frequency Island Aware Energy  Optimization Framework for Networks-on-Chip   Wooyoung Jang, Duo Ding, David Z. Pan  Department of Electrical and Computer Engineering  University of Texas at Austin  Austin, TX 78712, USA  {wyjang, ding}@cerc.utexas.edu, dpan@ece.utexas.edu  Abstract— In this paper, we present a partitioning, mapping,  and routing optimization framework for energy-efficient VFI  (Voltage-Frequency Island) based Network-on-Chip. Unlike the  recent work [10] which only performs partitioning together with  voltage-frequency assignment for a given mesh network layout,  our framework consists of three key VFI-aware components, i.e.,  VFI-aware partitioning, VFI-aware mapping, and VFI-aware  routing. Thus our technique effectively reduces VFI overheads  such as mixed clock FIFOs and voltage level converters by over  82% and energy consumption by over 9% compared with the  previous state-of-art works [10].  INTRODUCTION  I.  According to the International Technology Roadmap for  Semiconductors [1], silicon and system complexity  is  rocketing exponentially due to increasing transistor counts  fueled by smaller feature sizes and increasing demands for  complex functionality, higher performances with lower cost  and shorter time-to-market. As SoC (System-on-Chip) designs  target high-performance system level integrations of existing  intellectual properties such as microprocessors, digital signal  processors, controllers, memories and I/Os, previously  dominant point-to-point SoC interconnections and classic busbased mechanisms such as AMBA, STBus and Sonics  MicroNetwork [2] are becoming performance bottlenecks due  to the increase of system complexity. NoC (Network-on-Chip)  has been recently introduced as an effective solution for  scalable on-chip communication for future SoC, where the  network replace the traditional shared bus structures [3][4]. As  a better SoC platform for scalable system integration, on-chip  network provides more competitive features than the previous  ad-hoc global wiring mechanism.  Recently, VFI (Voltage-Frequency Island) and GALS  (Globally Asynchronous Locally Synchronous) paradigm was  introduced to NoC methodology [10], where tiles are  partitioned into islands and each island is optimized with its  own supply voltage,  threshold voltage and operating  frequency to minimize the overall energy consumption. In  spite of its powerful energy efficiency, there are several  This work is sponsored in part by NSF, Texas ARP, and Samsung Electronics.  limitations. First, the partitioning process is only combined  with VF (Voltage and Frequency) assignment process. Such  approach limits the flexibility of VFI optimization. Next, its  search for optimal energy consumption is carried out on a hard  mesh network, where both communication and computation  components are pre-designed. Since its network mapping is  not optimized by a VFI-aware manner, the solution space of  [10] is inevitably constrained. Finally, the VFI based NoC  needs a good routing strategy to bring down the energy  consumption by minimizing the number of a MCFIFO (Mixed  Clock FIFO) and a VLC (Voltage Level Converter).   In this paper, we propose a systematic VFI-aware energy  optimization framework that considers partitioning, mapping  and routing together to tackle the aforementioned problems  and further improve energy efficiency of VFI-based NoC  designs. In the proposed approach, VFI-aware partitioning is  carried out with VFI assignment, followed by VFI-aware  mapping and VFI-aware routing path allocation. The proposed  framework provides much more flexible VFI-aware NoC  optimizations in terms of energy consumption.  The rest of this paper is organized as follows: In section II,  we present a motivational example and summarize our major  contributions. Section III reviews related works. Section IV  introduces our VFI-aware optimization framework problem  formulation. Section V presents a detailed description of the  VFI-aware partitioning/mapping/routing algorithms. Section  VI shows experiment results in comparison with the most  recent work [10]. Finally, Section VII concludes the paper.  A.  II. MOTIVATION AND CONTRIBUTIONS   Motivational Example  For global energy optimization, performing a core  partitioning and a VF assignment is highly desirable before  mapping cores onto NoC tiles. Fig. 1, for instance, shows two  NoC designs with 16 tiles. Each tile operates at either voltage  A or voltage B. Let us apply [10] into these NoC designs. [10]  can improve the energy consumption by running two VFIs in  Fig. 1(a). In this case, its redundancy is only four routers with          a MCFIFO and a VLC. If energy saving by operating two  VFIs is more efficient than the redundancy by four complex  routers, it is regarded as a good solution. However, in the case  of Fig. 1(b), any tile cannot operate together at the same  voltage. Operating each tile as one VFI needs a complex  wiring of power, ground and clock and 24 complex routers  which may be much more expensive than energy saving by  VFI separation. As a result, higher voltage between two  voltages will be used in overall NoC such that [10] fails to  save the energy. This shows that a partitioning with a VF  assignment alone may be misleading during NoC energy  optimization. Our solution is to combine core partitioning, VF  assignment, mapping and routing path allocation together,  which consider VFI-aware manner sequentially.  A voltage B voltage (a) Mixed Clock FIFO and VLC (b) Figure 1.  Motivational NoC example.  B. Major Novelty  The main novelty and contribution of the proposed VFIaware optimization framework include:  • Earlier partitioning and VF assignment than mapping  and routing path allocation provide more opportunities  to build the unified VFIs.  • VFI-aware mapping is performed based on effective  region growing method. Such VFI-aware mapping fits  the VFI-based NoC methodology well.  • VFI-aware routing seeks to further reduce the VFI  overhead  through minimum  traffic routing with  congestion avoidance.  III. RELATED WORKS  The thriving of NoC paradigm has triggered a burst of onchip mapping, routing and partitioning techniques in the last  decade. In [5], an energy aware mapping was proposed for  regular tile-based NoC structures, which was further improved  in [6] by considering the packet routing flexibility during the  mapping process. With on-chip communication bandwidth  constraints applied, [7] developed a fast shortest path  algorithm for mesh-based core mapping. With respect to  routing, [8] presented a deadlock-free technique called turn  model for designing partially adaptive wormhole routing  algorithms without virtual channels. This approach was further  improved by the odd-even turn model in [9] for fault-tolerant  routing algorithms. For minimum energy consumption,  voltage islands concept was applied into NoC design [10]. In  addition, VFI concept combines with GALS paradigm for  global on-chip asynchronous communication. In [11], the  problem of energy optimal local speed and voltage selection in  VFI based system was studied under given performance  constraints. [12] considered the voltage island partitioning,  assignment and floorplanning in SoC Designs.  IV. PROBLEM FORMULATIONS  We start to solve VFI-applied NoC issues from a core  graph consisting of cores and their communication relation  since a core can be one-to-one mapped onto a tile of NoC. We  use EDF (Earliest Deadline First), a heuristic called EAS  (Energy Aware Scheduling) [18] and arbitrary schedulers to  generate a core graph from a task graph.  A. Partitioning and VF Assignment Problem  In this stage, the object is to decide how cores should be  partitioned to minimize the energy consumption except the  communication energy. We assume that the maximum number  of VFIs denoted by max{n(VFI)}, a core graph G with a set of  n cores where the supply and threshold voltages are (V1, Vt1),  (V2, Vt2), …, (Vn, Vtn), NoC topology are given. Clock period  (τi) for each core ci, which can trade off with supply and  threshold voltage, is defined by [10] as:  ( τ i V V , i ti ) = ( i i K V V V α − ) ti i (1)  where α is a technology parameter and Ki is a design specific  constant [15][16]. Operating frequency (fi) of the VFI j is  determined by a core including the longest path as:  min ≤ f i i S ∈ j    τ i 1 ( V V , i j )    (2)  where Sj is a set of tiles that belong to VFI j. Each core can be  performed with different supply and threshold voltages and a  voltage level is regarded as a legal one as long as the  performance constraints can be satisfied. Based on these  constraints, we partition n cores into the maximum number of  VFIs given and assigned supply and threshold voltage to each  core such that total power cost is minimized as follows,  min ∑    ∀ ∈ i G    R C V 2 + T k V i i i i i i exp −    t V S t          (3)  where G is a set of n cores, Ri is a number of active cycles, Ci  is total switched capacitance per cycle, Ti is a number of idle  cycles, ki is a design parameter, and St is a technology  parameter [17].  B. VFI-Aware Mapping Problem  In this section, we determine which tile each core should  be mapped to in order to minimize the communication energy  consumption under stringent performance constraints.  Definition 1: The partitioned core graph G´(V,E) generated  by section IV-A is a directed graph, where each vertex vi∈V                represents a core, and each directed edge ei,j∈E  represents the  communication  from vi  to vj. vol(ei,j)  represents  the  communication volume between vi to vj.  Definition 2: The NoC topology graph N(T,C) is a directed  graph, where each vertex ti∈T  represents a tile, and each  directed edge  ci,j∈C  represents candidate minimum paths  from ti to tj. vol(ci,j) represents the communication volume  between ti to tj, while bw(ci,j) represents the minimum  bandwidth requirement from ti to tj. The one-to-one mapping  function M() of the partitioned core graph G´(V,E) onto the  NoC topology graph N(T,C) is defined as follows:  ( ) M V : T s t M v , . . , , i j i j t v V t T → = ∀ ∈ ∃ ∈  (4)  The mapping is only defined when n(V)≤n(T) where n(X) is  the number of xi∈X. It has also two constraints, i.e., vi should  be mapped to any tj minimizing the overall amount of  communication and to any tj operating at the same voltage  with vi if any core of VFI including vi is mapped before.  C. VFI-Aware Routing Problem  Ebit(ci,j) is the energy consumption of sending one bit of  data from ti to tj. Assuming the bit energy values are observed  at VDD, this is defined by [10] as:  ( ) ( ) ( ) ( ) ( ) ( ), 2 , i 2 DD i j i j bit bit bit p L c ∈ L B S bit V V c E p E p E p E = + + ∑  (5)  where L(ci,j) is a set of links passed from ti to tj  and ELbit, EBbit  and ESbit  is the energy consumed by the link, buffer and  switch fabric, respectively. Therefore, finding a routing path  from ti to tj is formulated to minimize follows:  ( ) ( ) ( ) , , , min ( ) ( ) Vconv MixClkFIFO i j i j bit i j e m E E vol e E c m m ∀ +          +  ∑ ∑ (6)  subject to performance constraint including processing delay  and communication delay. EVconv and EMixClkFifo is the energy  overhead of a VLC and a MCFIFO respectively.  V. VFI OPTIMIZATION FRAMEWORK  In this section, we present the proposed VFI-aware NoC  methodology and detailed algorithms. Fig. 2 shows the overall  flow chart of the proposed VFI-aware NoC optimization  framework. We first partition n cores but not tiles into m VFIs  given. Based on the partitioning of cores, a novel VFI-aware  mapping algorithm and routing path allocation are applied to  minimize communication energy consumption. We establish  unique interconnection for key traffic paths between islands to  remove the overhead of VFI. After routing path allocation is  carried out, we compute the energy consumption and  performance. If they are satisfied, we can get energy-efficient  NoC platform with VFIs. Otherwise, we repeat  these  procedures decreasing the maximum number m of VFIs.  Core Partitioning and Voltage/Frequency Assignment Minimum Path Routing Compute Energy Consumption and Performance C1 C2 C3 C4 C5 C6 C7 C8 C9 Core graph C1 C2 C9 C5 C3 C8 C4 C6 C7 C4 Optimized NoC with Multiple VFIs Mapping Figure 2.  The proposed VFI-Aware NoC Methodology.  A. VFI-Aware Partitioning and VF Assignment Algorithm  The proposed VFI-aware partitioning algorithm is different  from [10] partitioning only tiles placed in a neighbor on NoC  grid. Since the partitioning stage is performed before the  stages of mapping and routing path allocation, any core can be  clustered together to the same VFI. Algorithm 1 shows the  proposed partitioning algorithm for a given core graph G(V,E)  and the maximum number m of VFIs. Since we assume that  the voltage of a core can trade off with its operating frequency,  in line 1, the lowest supply and threshold voltage of each core  are computed by (1), which satisfies performance of each core.  If there are k VFs used by cores and m VFIs are built, we can  choose m VF among k VF, which are total kCm cases. Then,  the lowest VF among the chosen m VFs are assigned to each  core if performance of each core is satisfied by the VF level.  When the chosen m VFs are satisfied with performance of all  cores, energy consumption is computed by (3). This procedure  repeats all kCm VF cases. After completing this procedure, we  choose the best VF pair consuming the lowest energy.  Algorithm 1: VFI-Aware Partitioning and VF Assignment  Input: G(V,E), max{ n(VFI)}=m  1: compute the lowest voltage of each core satisfied with   1: performance using (1);  2: for all cases that choose m voltages among all voltages (k) used   2: in each core do  3: assign the lowest operable voltage among m to all n cores;  4: if chosen m voltages are satisfied with performance of all  4:  n cores then  5: compute overall energy consumption by (3);  6: end if  7: end for  8: choose the best VF pair consuming minimum energy;  Output: G´ (V,E) partitioned into VFI  B. VFI-Aware Mapping Algorithm  We can know which cores a VFI consist of because the  core partitioning is performed in previous section. Therefore,  this information should be reflected in a mapping stage. In the  mapping step, we use a heuristic approach based on the  partitioned core graph, as shown in Algorithm 2. In line 1,  cores are sorted in decreasing order by the amount of traffic  and then they are mapped in the order. We define a VF_List()  indicating whether VF of current core being mapped is already  used on NoC grid. From line 3 to 11, initial mapping  algorithm starts for all sorted vi. In line 4, the proposed  mapping algorithm checks whether VF of current core being  mapped is used throughout VF_List(). If VF of the core being  mapped does not exist in VF_List(), the core is mapped on any  empty tile of NoC grid with the maximum neighbor tiles and            the minimum traffics and VF of the core is recorded in  VF_List() (line 5-6). If VF of the core being mapped exists in  VF_List(), the core is mapped on any candidate tile with the  same VF (line 8). Then candidates are marked in line 10,  where NSWE(ti) indicates north, south, west and east tile of the  mapped ti. They can be candidates for the next cores with the  same VF. This repeats until all cores are mapped onto NoC  grid. The initial mapping algorithm reduces the number of  isolated tiles separating from the group of cores (VFI) running  at the same VF. However, since we cannot completely remove  an isolated tile around the edge of NoC grid, the isolated tile  can be moved into near its main VFI if the moving costs are  less than the overhead of the extra isolated tiles (line 13). The  procedure is repeated until isolated tiles disappear. Finally, a  pair-wise swapping of tiles within each island is executed to  find the best mapping for minimum traffics (line 16).  Algorithm 2: VFI-Aware Mapping  Input: G´(V,E), NoC topology  1:  sort(vol(vi)) in decreasing order;  2:  VF_List() = empty;  3:  for all sorted vi do // initial mapping  4:  if  VF of vi does not exists in VF_List() then  5:  M(vi) on any empty tile tj with max. neighbors and min.  5:   traffics;  6:  add VF into VF_List();  7:  else then   8:  M(vi) on any candidate tile tj with min. traffics;  9:  end if  10:  add empty NSWE(tj) into candidate with VF of vi;  11:  end for  12:  for all isolated island ti do // moving of an isolated tile  13:  pair-wise swapping(ti,tj) to be clustered to VFI using the same  13:   VF under min. traffic increase;   14:  end for  15:  for all ti do // minimization of the overall traffics  16:  pair-wise swapping(ti,tj) within island for min. traffic;  17:  end for  Output: N(T,C) mapped onto NoC grid  Fig. 3 is a simple example for the initial mapping  algorithm. In Fig. 3(a), the number is the mapping order by  sorting cores depending on the amount of traffic of the cores  and two clusters, i.e., grey and white groups denoted VFI 1  and VFI 2 respectively exist. The core 1 which has the  maximum traffic is placed onto the center of the mesh nodes  including the maximum neighbors as shown in Fig. 3(b). Four  candidates, a, b, c and d are also marked as a VFI 1 for the  next mapped core using the same VF. Core 2 which has the  next maximum  traffics  is placed onto  the candidates  minimizing the communication cost with the cores previously  mapped if VFI 2 running at the same VF of core 2 exists.  Otherwise, core 2 is only placed onto any unmapped tile that  minimizes the communication cost with cores previously  mapped. Core 2 is mapped by latter case as shown in Fig. 3(c).  Three candidates, e, f and g are also marked as a VFI 2 for the  next mapped core using the same VF. Core 3 which has the  next maximum traffics is placed onto the candidates of VFI 1  minimizing the communication cost with the cores previously  mapped. In Fig. 3(c), there are three candidates, b, c and d and  candidate b is chosen because b generates minimum traffics  than c and d. Then, three candidates, e, h and i are also marked  as a VFI 1, where any core running at VFI 1 and VFI 2 can be  mapped to tile e in Fig. 4(d). The procedure repeats until all of  the cores are mapped as shown in Fig. 3(e)-(f). Since this  method makes the region of VFI grow toward its candidates, a  VFI is prevented splitting into two VFIs using the same VF.  3 4 2 1 5 6 Partitioned Core graph m 6 5 l (a) (f) i 3 4 j c 1 2 f h k d d 5 l c 1 a c 1 2 f b i 3 4 j (b) (e) h k d g d g c 1 2 f c 1 2 f b e i 3 e (c) (d) h Figure 3.  Incremental core mapping onto NoC grid.  C. VFI-Aware Routing Path Allocation  In this section, we present the VFI-aware routing path  allocation algorithm. The concept of the proposed routing path  allocation is to build minimum interconnection between VFIs.  Fig. 4 shows how interconnection between tiles is built briefly.  After VFI-aware mapping in section V-B, we assume that  there is no interconnection between tiles as shown in Fig. 4(a).  In Fig. 4(b), all of the interconnections are built within each  VFI. Then, interconnections between VFIs are partially built,  as shown in Fig. 4(c). Next, a routing path should be  considered to minimize energy consumption and to improve  performance in irregular NoC interconnection of Fig. 4(c).  (a) No wiring (b) Wiring within VFI (C) Wiring between VFI  Figure 4.  The procedure of connection between tiles or VFIs.  Algorithm 3 shows how an interconnection between tiles  is built and how a routing path is allocated. First, we should  connect all tiles within each VFI (line 1) as shown in Fig. 4(b)  because a router without a MCFIFO and a VLC is cheap. The  optimal number of expensive routers with a MCFIFO and a  VLC for connecting two islands are computed as:  b =   w vol VFI ( j i , ) / bw VFI ( i , j )    i , j (8)  where x   is the smallest integer larger than x, wi,j is the  weight of link between VFIs and vol(VFIi,j) and bw(VFIi,j) is  the communication volume and minimum bandwidth  requirement between VFI i and VFI j, respectively (line 2).        The b number of routers with a MCFIFO and a VLC are  placed between two VFIs, where minimum traffics are  generated. Here is a simple example in Fig. 5, where S1, S2  and S3 communicate with D1, D2 and D3 respectively. We  assume that the amount of each communication is 1Mbit/s,  each link can contain 5Mbit/s and wi,j is 1. Therefore,  vol(VFIi,j) is 3Mbit/s and bw(VFIi,j) is 5Mbit/s such that b is 1.  Now, we can build one connection between islands. The  overall amount of traffic applied the shortest path is 9Mbit/s,  11Mbit/s and 7Mbit/s in Fig. 5(a), (b) and (c) respectively.  Therefore, we build one interconnection between two islands  like Fig. 5(c) because it generates minimum traffic.  D1 S1 S2 D3 S3 D2 (a) D1 S1 S2 D3 S3 D2 (b) D1 S1 S2 D3 S3 D2 (c) Figure 5.  Interconnection between islands.  Now, we perform a routing path allocation for irregular  interconnection. In line 4, ci,j is sorted by communication  distance. In Fig. 5(c), the path from S2 to D2 is the shortest  and the paths from S1 to D1 and from S3 to D3 are the same.  Rule 1: The short path ci,j among C is allocated earlier to  relieve traffic congestion between VFIs.  In Fig. 6(a), the path from S1 to D1 has only path A as the  shortest path and the path from S2 to D2 has two paths, i.e., B  and C as the shortest path. If the path from S2 to D2 is  allocated to path B earlier than the path from S1 to D1, the  path A will overlap with the path B since the path from S1 to  D1 has no choice. However, if the path A is allocated earlier  than the path from S2 to D2, the path C but not the path B can  be chosen as the path from S2 to D2. Therefore, routing order  is important to reduce traffic congestion and balance network  load. In Fig. 5(c), the path from S2 to D2 is allocated earlier  and then S1 to D1 or S3 to D3 is allocated according to rule 1.   Rule 2: If the VFI of communication source is different  from the VFI of its destination, the shortest path which passes  through the fewest islands is allocated.  S2 B C S1 A D1 D2 D 2 1 1 P2 P1 S (a) rule 1                                              (b) rule 2  Figure 6.  Routing Path Allocation.  In Fig. 6(b), the path P1 passing through one island is  better than the path P2 passing two islands due to better  performance and lower energy consumption from (5). As a  method for rule 2, we put a cost into links located between  VFIs (line 5). For each ci,j, a quadrant graph is formed (line 7)  and then, the path with minimum cost is obtained within the  quadrant graph by Dijkstra’s shortest path algorithm. If  performance is not satisfied, link weight wi,j between VFIs  should increase, go to line 2 and then repeat this procedure.  Algorithm 3: VFI-Aware Routing Path Allocation  Input: N(T,C)  1: connect all tiles within each VFI;  2: compute the optimal number of routers with a MCFIFO or a VLS  2: between two VFIs by (8);  3: insert the b number of routers to any place between VFIs, where  3: minimum traffic is generated;  4: sort(length(ci,j)) in increasing order; // rule 1  5: put a cost to link located between VFIs; // rule 2  6: for all ci,j do  7: quadrant graph is formed from source to destination;  8: Dijkstra’s shortest path algorithm;  9: If  performance is not satisfied then   10: increase wi,j of (8);  11: go to line 2;  12: end if  13: end for  Output: deterministic, minimal, deadlock-free routing path  VI. EXPERIMENTAL RESULTS  In this section, we show the experimental results obtained  by applying the VFI-aware NoC framework on MPEG-4  Video Object Plane Decoder [13] and E3S benchmark suites  [14]. Because the first application has 16 cores, this is mapped  onto 4x4 NoC grids. The second application consists of officeautomation, consumer, networking, auto-industry and telecom  application containing 5, 12, 13, 24 and 30 tasks respectively.  They are scheduled on to 4, 9, 9, 16 and 25 processors  respectively by arbitrary schedulers. They are again mapped  onto 2x2, 3x3, 3x3, 4x4 and 5x5 NoC grids respectively.  We experiment the VFI-aware NoC methodology by two  versions, i.e., VFI-aware mapping combined with general  minimum path algorithm and VFI-aware mapping and routing  to verify the performance of mapping and routing, denoted as  VFI-M and VFI-R respectively. Table I shows that the VFI-M  saves more MCFIFOs and VLCs due to VFI-aware mapping  based on early partitioning. In addition, VFI-R needs the least  number of MCFIFOs and VLCs. The VFI-aware NoC  approach commonly causes a slight increase of traffic due to  VFI-aware mapping and routing path allocation. However, the  maximum congestion is more relieved because routing order is  considered to balance network load. The lower congestion  makes a chip stable and operating at a low clock. A thorough  cross-compare of E3S benchmark is listed in Table II. Its runtime ranges from a few seconds to a few minutes.  TABLE I.   COMPARISON OF VIDEO OBJECT PLANE DECODER  Content  # of complex  router  Total traffic  (MB/s)  Congestion  (MB/s)  Algorithm [10]  VFI-M  VFI-R  [10]  VFI-R  [10]  VFI-R  2-VF  6  5  1  4309  4353  923  516  3-VF  11  7  2  4309  4211  923  613  4-VF  14  10  3  4309  4211  923  613                         TABLE II.   CORSS COMPARISON OF E3S BENCHMARK  Content  Algorithm  # of  complex  router  Total  traffic  [10]  VFI-M  VFI-R  [10]  VFI-R  Telecommunication  3-VF  4-VF  24  29  14  22  11  18  107  107  133  138  5-VF 29  20  16  107  153  2-VF  20  13  10  107  133  Auto-Industry  2-VF 3-VF 4-VF 11  12  15  8  10  13  6  7  11  172  172  172  178  193  205  Networking  3-VF 8  6  5  79692 83886 4-VF  9  7  6  79692  109051  2-VF 8  6  5  79692 83886 Consumer  3-VF 8  5  4  30  35  4-VF 10  7  6  30  39  2-VF  4  3  3  30  33  (a) NoC Partitioning by [10]                                                      (b) The Proposed VFI-Aware NoC  Figure 7.  VFI partition illustration on 4x4 NoC.  Fig. 7 illustrates the comparison of [10] and the proposed  VFI-aware approach performed on 4x4 NoC. Now that [10]  has six VFIs (including three islands separated) and the VFIaware NoC has four VFIs, the VFI-aware NoC framework  clearly provides better partitioned VFI such that it is beneficial  for low energy consumption as well as a physical design.  Table III shows that the VFI-R consumes less energy than [10]  since many tiles running at the same VF can be partitioned  into a VFI.  However, in case of Network application, the  VFI-aware NoC approach is worse than [10] because the  amount of traffic enormously increases in case of 4-VFI.    TABLE III.   NOC ENERGY CONSUMPTION COMPARISON  Benchmark Algorithm  Consumer  Network  Autoindustry  Telecom  [10]  VFI-R  [10]  VFI-R  [10]  VFI-R  [10]  VFI-R  Normalized Total Energy Consumption 1-VFI  2-VFI  3-VFI 4-VFI 1  0.56  0.53  0.54  1  0.55  0.51  0.50  1  0.8  0.79  0.79  1  0.78  0.76  0.89  1  0.69  0.65  0.67  1  0.63  0.59  0.58  1  0.58  0.57  0.58  1  0.53  0.51  0.49  VII. CONCLUSION  We proposed a systematic energy optimization framework,  including VFI-aware partitioning, VFI-aware mapping and  VFI-aware routing for VFI based NoC paradigms. Compared  to the recent state-of-the-art NoC design techniques with VFI  [10], our VFI-aware optimization framework demonstrates an  energy efficiency improvement of over 9% and the overhead  reduction of over 82% under a variety of system constraints.  "
2008,A low-overhead fault tolerance scheme for TSV-based 3D network on chip links.,"Three-dimensional die stacking integration provides the ability to stack multiple layers of processed silicon with a large number of vertical interconnects. Through Silicon Vias (TSVs) provide a promising area- and power-efficient way to support communication between different stack layers. Unfortunately, low TSV yield significantly impacts design of three-dimensional die stacks with a large number of TSVs. This paper presents a defect-tolerance technique for TSVs-based multi-bit links through an efficient and effective use of redundancy. This technique is ideally suited for three-dimensional network-on-chip (NoC) links. Simulation results demonstrate significant yield improvement, from 66% to 98%, with a low area cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase the total switch area) in 130 nm technology, with minimal impact of VLSI design and test flows.","A Low-overhead Fault Tolerance Scheme for TSV-based 3D Network on Chip Links Igor Loi† , Subhasish Mitra‡ , Thomas H. Lee‡ , Shinobu Fujita⋆ and Luca Benini† †DEIS, University of Bologna, Bologna, Italy ‡Stanford University, California, Usa ⋆Toshiba, San Jose, CA, USA (Kawasaki, Kanagawa, Japan) igor.loi@unibo.it, subh@stanford.edu, tomlee@smirc.stanford.edu, shinobu.fujita@toshiba.co.jp and lbenini@deis.unibo.it Abstract— Three-dimensional die stacking integration provides the ability to stack multiple layers of processed silicon with a large number of vertical interconnects. Through Silicon Vias (TSVs) provide a promising area- and power-efﬁcient way to support communication between different stack layers. Unfortunately, low TSV yield signiﬁcantly impacts design of three-dimensional die stacks with a large number of TSVs. This paper presents a defecttolerance technique for TSVs-based multi-bit links through an efﬁcient and effective use of redundancy. This technique is ideally suited for three-dimensional network-on-chip (NoC) links. Simulation results demonstrate signiﬁcant yield improvement, from 66% to 98%, with a low area cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase the total switch area) in 130nm technology, with minimal impact of VLSI design and test ﬂows. I . IN TRODUC T ION F OR future integrated system design, two major trends are emerging. Communication-centric architectures based on the Network on Chip (NoC) design paradigm [1], [2] to tackle interconnect and architectural scalability challenges. Three-Dimensional Integrated Circuits (3DICs) that provide a promising technological solution to alleviate the interconnect, I/O bandwidth and latency bottlenecks. 3DICs may enable heterogeneous integration and new classes of applications through signiﬁcantly improved performance and energy efﬁciency of complex system architectures (e.g. technologies from Tezzaron Semiconductor Corporation [3], IMEC, MIT Lincoln Labs, and IBM [4]). One of the most promising technologies for 3D integration is based on Through Silicon Vias (TSVs), which cut across thinned silicon substrates to establish inter-die connectivity after die-bonding. Three-Dimensional Network on Chips (3DNoCs) combine the beneﬁts of short vertical interconnects of 3DICs and the scalability of NoCs. 3DNoCs support both horizontal and vertical links. A vertical link can be physically implemented as a cluster of TSVs. TSVs allow ﬁne pitch, high density and high compatibility with the standard CMOS process. Unfortunately, currently available processes for TSV fabrication have relatively low yield (compared to standard 2D processes). Figure 1 shows limited yield of TSVs from three different process technologies: HRI [5], IMEC [6] and IBM [7]. In this paper, we describe the design of a defect-tolerant TSV-based multi-bit vertical link which enables signiﬁcant yield improvement with respect to random (complete or partial) open defects at an extremely low cost. Like traditional defect-tolerance techniques (such as those used for memories), our technique also relies on redundancy. Our major contribution is in a simple and efﬁcient design of such a defect-tolerant TSV-based link at lowest cost, and also with minimal impact on the overall integrated system design and production test ﬂows. While this TSV-based link design is generally applicable for both NOC-based and bus-based 3D interconnects, it is especially useful for 3DNoCs because it takes advantage of the NoC switch architecture to introduce minimal system-level area impact. The main contributions of this paper are: • Introduction of a robust, defect-tolerant, vertical link architecture (for TSVs) to overcome challenges of low yield for current TSV fabrication processes; • Integration of the defect-tolerant 3D link into a complete three-dimensional Network on Chip design ﬂow; • Experimental evaluation, performed at the layout level, including full placement and routing, to evaluate beneﬁts, feasibility and hardware costs. In our experiments, we achieve signiﬁcant yield improvements (from 66% to 98% for 4.2M TSVs design, arranged in 100K spots made up of 42 TSVs each) for random (complete and partial) open defects that pose major challenges for TSVs. Our layout results demonstrate the feasibility of this approach and its low cost (17% on a vertical link in a NoC switch, which leads a modest 2.1% increase in the switch area). I I . R E LAT ED WORK Interconnect scaling has become one of the most crucial challenges in chip design, and is expected to get worse in the Fig. 1. Yield trend for TSVs in three different processes: IBM, HRI and IMEC. Only random (complete or partial) open defects are considered in this ﬁgure, since misalignments are well controlled during the bonding phase. Yield is evaluated using the Poisson distribution. in(cid:13) R(cid:13)routing(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)contact(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)TSV(cid:13)/2(cid:13) R(cid:13)routing(cid:13) out(cid:13) C(cid:13)routing(cid:13) C(cid:13)TSV(cid:13) C(cid:13)TSV(cid:13) C(cid:13)routing(cid:13) C(cid:13)Load(cid:13) Fig. 3. TSVs and global wire electrical model for two stacked vias(refer to Figure 2) The primary failure mechanisms for TSVs are misalignment and random (complete or partial) open defects [15]. Misalignment refers to unsuccessful wafer alignment prior to and during wafer bonding process (Figure 2), and is caused by shifts of bonding pads with respect to their nominal positions. Random defects comprise a variety of unpredictable physical phenomena related to the thermal compression process used in wafer stacking. Starting from these considerations and based on [12], we have conducted a detailed study to quantify the impact of TSV failures on overall chip yield. We use an electrical model of TSVs and the bonding mechanisms for this purpose. Figure 3 shows the electrical model of two stacked vias (rendered as a T network). The vias are driven by one inverter followed by a stretch of planar interconnect (global routing). The contact resistance is related to the quality and area of bonding. In case of misalignments (e.g. top wafer shifts along the X or Y axes or a small rotation), the bonded area decreases. This phenomenon has been modeled as a variable resistance (central resistor in Figure 3) between the two T networks, and the outcome is summarized in Table I. As can be seen, misalignments of even noticeable entity do not normally compromise functionality (which is dominated by the overall planar routing parasitics [12]) and have a minimum impact on delay. Extreme misalignment, like in the last row of table I are highly unlikely in state-of-the-art wafer bonding processes [3], [4], [16]. This motivates special emphasis on workarounds for the other main source of yield losses: random defects. Random (complete or partial) open defects affect single vias or a small area of the interface because of failure mechanisms such as dislocations, 02 trapped on the surface, void formation, or even mechanical failures in TSVs [17], [18], [18], [4], [19]. To model the effects of these defects, we assumed a uniform TSV defect distribution and performed several Monte Carlo simulations. Based on our results (Section V), we concluded that random (complete or partial) open defects are far more relevant compared to misalignment problems. For this reason, we focus on these defects in the following sections. 2x1(cid:13)XBAR(cid:13) TSVs(cid:13) IN_1(cid:13) IN_2(cid:13) IN_3(cid:13) 1(cid:13) 2(cid:13) 3(cid:13) E(cid:13)_1(cid:13) y(cid:13) OUT_1(cid:13) OUT_2(cid:13) OUT_3(cid:13) 1(cid:13) 2(cid:13) 3(cid:13) 4(cid:13) 5(cid:13) 6(cid:13) 7(cid:13) 8(cid:13) 9(cid:13) E(cid:13)_1(cid:13) E(cid:13)_2(cid:13) E(cid:13)_3(cid:13) ROM(cid:13) ROM(cid:13) (a)(cid:13) z(cid:13) x(cid:13) (b)(cid:13) Fig. 4. Redundant Routing scheme. (a) shows a simpliﬁed crossbar scheme for dynamic routing (functional scheme). (b) shows the TSVs obstruction and the routing crossbar (the orange squares are the TSV pads). Extra pads (E 1 E 2 ...) are spread around the TSV cluster, simplifying fault bypassing by means of a 2X multiplexers. Fig. 2. Cross-section of a vertical link across two tiers. The ﬁgure also shows the worst-case misalignment scenario future. 3D integration and Network on Chip design methodologies are expected to overcome many of these challenges. NoCs have been suggested as a scalable communication fabric [1], [2]. 3D integration has been proposed in different ways (e.g. Tezzaron Semiconductor Corporation [3], IMEC, MIT Lincoln Labs, and IBM Technologies [4]) providing promising solutions to enable connectivity along the vertical direction. Recently, some research has been undertaken on 3DNoCs. In [8], the authors propose a dimension decomposition scheme to optimize the cost of 3D NoC switches, and present some area and frequency ﬁgures derived from a physical implementation. Post-silicon nano-scale 3D interconnections have also been recently investigated [9], [10], but large scale availability of these technologies in the near future is uncertain. As technology scales, fault tolerance is becoming a key concern in on-chip communication. Optical Proximity Correction (OPC) and redundant via placement [11] have solved a huge number of cases of faults related, mainly, to interconnects. Recent experiments by HRI on 3DICs report very high yields of over 60%, and the redundancy scheme used realizes each vertical interconnect as a pair of vias (twins) [5]. Despite the research undertaken on 3DICs and recently on 3DNoCs, to date, yield improvements for vertical links of 3DNoCs have never been studied. In this paper, we propose a novel scheme to overcome this limitation. The starting point of this work is [12], [13], where a thorough physical and timing analysis of the vertical links has been conducted on a real 3DNoC. Further, it is worth stressing that the proposed scheme can also be applied successfully to alternative interconnection schemes, such as buses. I I I . PHY S ICA L L EV E L MOD E L ING AND ANA LY S I S O F TSV FAU LT IM PAC T In this paper we focus on the wafer stacking approach since it is very promising for the implementation of highperformance yet inexpensive 3DICs. Wafer stacking relies on Through-Silicon Vias (TSVs) [14] for vertical connectivity, guaranteeing low parasitics (i.e. low power and propagation delay) and, if needed, extremely high densities of vertical wires (i.e. high bandwidth-per-area ratio). The electrical connectivity between different tiers is provided by creating pads on the wafer surface, and then performing bonding by mechanical thermo-compression. Misalignment [µm] in X-Y 0 1 2 3 3.98 Contact Area [µm 2 ] 4x4 3x3 2x2 1x1 0.02x0.02 Contact Resistance ∆ Delay [%] 0 [Ω] 10m 19m 40m 160m 1K < 1% < 1% < 1% 22% TABLE I PAD CON TAC T R E S I S TANC E AND D E LAY INCR EA S ING FOR CU -CU WA F ER M E TA L BOND ING UND ER D I FF ER EN T M I SA L IGNM EN T CA S E S [17 ] , [20 ] IV. Y I E LD ENHANC EM EN T S FOR 3DNOC S In this section, we describe the target 3DNoC [12], [13] used for our experiments, and present our defect-tolerant solution for TSV-based vertical link design. As pointed out earlier, our solution can be applied not only to 3DNoCs, but also, more generally, to regular structures such as buses. A. The reference NoC architecture To make our study realistic, we developed our approach within the ×pipes [12], [21], [13] NoC library. To enable our NoC for 3D technology we extended the ×pipes switches by adding a couple of vertical ports, and we developed hard macros for the TSVs obstruction [12]. Vertical links are unidirectional, and are composed (as planar links) of data and ﬂow control signals, traveling in opposite directions. For this work we selected a data width of 32 bit, therefore for a pair of 3D links, 76 different signals are needed overall. B. Yield Enhancement Approaches Among the numerous techniques to increase wafer yield of VLSI designs, we focus on hardware redundancy, deployed at design time, with some amount of post-manufacturing conﬁguration. We use active redundancy in the form of spare pads and reconﬁgurable routing hardware in order to minimize the overall complexity, while gaining maximum beneﬁts in term of efﬁciency (Figure 4). The dynamic routing solution is designed to leverage postmanufacturing conﬁgurability of the TSV interconnect map. This allows us to achieve high yield while minimizing the overhead in terms of the number of pads and extra logic. Combining testing resources (e.g., scan chains 1 ) with such reconﬁgurability plays the key role in achieving yield. This solution allows us to test each vertical interconnect and diagnose defects, to isolate any failed TSV, and ﬁnally to restore functionality through reconﬁguration by routing the affected signals over to the spare pads. As we see in Figure 4 (a), in our proposed Dynamic Routing scheme, all pads are driven by a 2×1 crossbar, and each signal can be routed to two different TSVs. We explore conﬁgurations with one extra pad for each cluster (i.e. for each pad column). The crossbar is extremely small, as a strategic choice to keep the area overhead as low as possible - for each additional rerouting degree of freedom, the crossbar radix increases by a factor of one. With this lean architecture, faults are recovered by shifting affected signals to the neighboring pads, and further shifting the displaced connections over to other adjacent pads until all connections are across safe electrical structures. To clarify the recovery scheme, we shall consider Figure 4 (b). 1 The use of scan chains does not normally imply any extra cost, as they are typically integrated in every design Supposing that pad 2 is affected by some defects (resulting e.g. in an open circuit), we route signal 3 normally through its associated pad 3, while signal 2 gets rerouted through pad 1, and therefore signal 1 gets remapped to pad E 1. Signals outside this column are not shifted since the defect is contained inside the ﬁrst cluster; the recovery process is performed locally. The proper routing information is elaborated off-chip (to minimize hardware complexity and overhead) during chip testing, and is then stored on-chip into a small One Time Programmable (OTP) memory (e.g. a fuse ROM). The importance of the testing stage is evident, as it determines all the necessary inputs to correctly set the crossbar up. To test the physical interconnect, we reuse the scan chains which are normally inserted anyway in the design, thus incurring no overhead for this. Figure 5 illustrates the hardware facilities used to test the TSVs. The TSVs are tested by injecting Test Vectors (TVs) in one tier (e.g. the bottom one). The TV is propagated to the destination tier (e.g. the top one), where it is captured and transmitted off-chip. In summary, the approach is split into ﬁve steps: 1) Inject test vectors (e.g. bottom tier); 2) Propagate test vectors across TSVs and capture them (e.g. top tier); 3) Scan out the captured data (e.g. top tier); 4) Elaborate off-chip the interconnect map; 5) Reconﬁgure the crossbar (both bottom and top tier); The process can be performed at any speed allowed by the external I/O pins. Since the interconnect map is devised off-chip, minimal logic is required on-chip for the mapping procedure - mostly, the OTP memory to store the crossbar conﬁgurations. V. EX P ER IM EN TA L R E SU LT S A. Yield and Hardware Cost of the Redundant Solutions The alternative solutions, and a non-redundant baseline case, have been synthesized with the UMC 130nm technology library and inserted into the ﬂoorplan for a 3D chip stack. Placement, routing and post layout veriﬁcation have been performed. As depicted in Figure 8, the planar topology has been partitioned in two parts (dotted line), between the central routers. The topology under test (see Figure 8) includes six processors and six memories, placed on two layers. Vertical communication is achieved through the two central switches Fig. 6. Normalized area cost in case of No Redundancy and Dynamic Routing with 2, 3, 4, 7, 11 and 38 extra pads. The main contribution of this paper is resumed starting from the 2nd bar, which shows only 1.6% area overhead for 2 extra pads, 2.1% for 4 extra pads and 10.5% for full redundancy (38 extra pads) 1* NoC 2D NoC 2D NoC 2D NoC 2D 1* 5* 5* 2* 3* 5* 5 5* Fig. 5. TSV NoC Test Environment: in test mode, test vectors are injected from the Test Access Point (1*) into the switch input buffer (scan), then the path through the crossbar is enabled (1*) and ﬂow control is disabled. After some cycles the stimuli reach the next tier where they are captured (2*) from the input buffer, and then shifted out through the TAP (3*). This stream is analyzed off-chip then, based upon the failure map the OTP memories are programmed (5*), reconﬁguring the crossbar to isolate failed structures which act as a gateway for 3DNoC trafﬁc. The reconﬁgurable crossbars have been inserted between the TSV pads and the switch. For a 32-bit link, the NoC protocol uses 38 bits, where the remaining 6 bits belong to ﬂow control signaling and mesochronous handling (i.e. the clock and reset signals which are forwarded along with the data). The nature of the reference NoC switches, namely their ﬂow control, have inﬂuenced the adopted testing solution. During testing, a portion of the hardware works in scan mode (inject) and the other in capture mode; the ﬂow control has to be explicitly managed to avoid the formation of communication stalls. Four scan chain groups have been inserted, driven by a simple Finite State Machine (FSM), accomplishing high efﬁciency and reliability. The overhead of this approach is mainly due to the crossbar logic around the via bundles, to the OTP memory and to the small FSM. The scan chain cost is not taken into account since, as mentioned before, the design must be testable anyway, and this contribution is present as well on planar ICs. Several experiments have been conducted, especially with the dynamic routing technique, in order to evaluate how many extra pads and area may be needed for implementation, and in order to explore the trade-offs between yield and cost. We implemented six different conﬁgurations, respectively with 2, 3, 4, 7, 11 and 38 extra pads. It is worth noting that, in each unidirectional link of 38 signals, spare pads are separately needed for incoming (mostly, ﬂow control) and outgoing (mostly, data) wires; hence the need for at least 2 Fig. 7. Yield improvement over seven different hardware conﬁgurations: no-redundancy, 2, 3, 4, 7, 11 and 38 extra pads, which correspond to 38, 40, 41, 42, 45, 49, and 76 TSVs per 3D link. A ﬁxed defect frequency of 9.75 Defects Per Million Opportunities (DPMO) is assumed, and 4.2M TSVs design has been analyzed. Fig. 8. 3D NoC topology. Dash boxes indicate the resources involved in the TSV test process. spares. The latter group typically features many more wires than the former (35 vs. 3 in our example), so the correction performance is maximized with an asymmetric assignment of spares to the two groups. For example, with only 2 extra pads, no choice is available; there is only one spare for 35 outgoing signals, while the 3 incoming wires share the second spare. With 4 spares, the optimal arrangement is to assign 3 to the outgoing bundle, and the fourth to the incoming bundle. In the extreme case of 38 spares, each TSVs has a backup. Figure 7 illustrates the yield improvement in case of 2, 3, 4, 7, 11 and 38 extra pads and based on experimental data, assuming a ﬁxed defect frequency of 9.75 Defect Per Million Opportunities (HRI TSV process [5]). We emulated 100K TSVs links with and without redundancy. Without postmanufacturing processing, the system is unable to recover damaged vias, and tolerates only small misalignments, thus exhibiting a yield of only 68%. When Dynamic Routing redundancy is adopted, the recovery algorithm shows excellent results, especially with 2 to 7 extra pads. Further increasing the number of extra pads brings minimal yield beneﬁts, and the increase in cost of TSV obstructions, TSV crossbar and the OTP memory may be unjustiﬁed. With only four extra pads per 3D link, yield increases from 68% to 98%. Concerning the silicon cost, Figure 6 shows the normalized area cost in case of different degrees of redundancy applied to a single 3D link. As the number of extra pads increases, the TSVs spot and the routing logic grow in a linear fashion. The increasing area, with reference to a baseline composed of the Switch and the non-redundant TSVs link is 1.6% in case of 2 extra pads, 2.1% on 4 extra pads, and 10.5% in case of 38 extra pads. As a stand-alone component, the redundant links with 2 extra pads impacts for the 17% on a non-redundant Link. The physical implementation of the redundant hardware is depicted in Figure 9, where a pair of 3D links (42 TSVs each) is surrounded by the routing crossbar, guaranteeing low latency and better area utilization. To evaluate the impact of the Dynamic Routing solution uses advanced technology nodes, we performed an experiment using 65nm technology library. As we can see in Table II, by scaling the technology the Dynamic Routing logic scales as well. But, the TSV obstructions show the same area, since we conservatively assumed that the TSV process is independent from the technology node used for the 2D chip and it does’t scale. Therefore, the area overhead of our solution increases from 2.1% on 130nm to 3.8% on 65nm, which is still very affordable. V I . CONC LU S ION S AND FU TUR E WORK 3DICs, especially those based on Through-Silicon Vias, are gaining traction as a workaround against the increasing costs of chip miniaturization. However, the manufacturing technology is not mature enough, resulting in issues such as misalignments and random defects. Misalignment-reduction techniques have undergone signiﬁcant improvements, so that today random defects must be considered the main source of yield losses. For this reason, minimizing their impact is crucial. In this paper, we study some baseline redundancy schemes and we notably propose a novel Dynamic Routing approach. The latter scheme is based on post-manufacturing study and reconﬁguration of the electrical resources, leveraging a small amount of on-chip spares. The scheme proves capable of yields up to 98% with a minimum silicon cost of just 17% per TSV link in 130nm. This cost is further projected to decrease to just 12% in the newest 65nm technologies. Future work may revolve around timing faults, which are an often underestimated source of failures. ACKNOW L EDGM EN T S This work is the result of a strict collaboration between University of Bologna, Toshiba and Stanford Center for Integrated Systems. This work is supported by European project 214364 ICT-GALAXY for DEIS. "
2008,Integrated code and data placement in two-dimensional mesh based chip multiprocessors.,"As transistor sizes continue to shrink and the number of transistors per chip keeps increasing, chip multiprocessors (CMPs) are becoming a promising alternative to remain on the current performance trajectory for both high-end systems and embedded systems. Since future technologies offer the promise of being able to integrate billions of transistors on a chip, the prospects of having hundreds to thousands of processors on a single chip along with an underlying memory hierarchy and an interconnection system is entirely feasible. This paper proposes a compiler directed integrated code and data placement scheme for two-dimensional mesh based CMP architectures. The proposed approach uses a Code-Data Affinity Graph (CDAG) to represent the relationship between loop iterations and array data and then assigns the sets of loop iterations to processing cores and sets of data blocks to on-chip memories. During the mapping process, the on-chip memory capacity and load imbalance across different cores and the topology of the NoC are taken into account. In this paper, we present two variants of our approach: depth-first placement (DFP) and breadth-first placement (BFP), and compare them to three alternate code/data mapping schemes. The experimental evaluation shows that our CDAG based placement schemes are very successful in practice, achieving average performance improvements of 19.9% (DFP) and 16.8% (BFP), and average energy improvements of 29.7% (DFP) and 27.8% (BFP).","Integrated Code and Data Placement in Two-Dimensional Mesh Based Chip Multiprocessors* Taylan Yemliha† , Shekhar Srikantaiah‡ , Mahmut Kandemir‡ , Mustafa Karakoy§ and Mary Jane Irwin‡ †Syracuse University, Syracuse, NY. ‡Pennsylvania State University, University Park, PA. § Imperial College, London. Abstract— As transistor sizes continue to shrink and the number of transistors per chip keeps increasing, chip multiprocessors (CMPs) are becoming a promising alternative to remain on the current performance trajectory for both high-end systems and embedded systems. Since future technologies offer the promise of being able to integrate billions of transistors on a chip, the prospects of having hundreds to thousands of processors on a single chip along with an underlying memory hierarchy and an interconnection system is entirely feasible. This paper proposes a compiler directed integrated code and data placement scheme for twodimensional mesh based CMP architectures. The proposed approach uses a Code-Data Afﬁnity Graph (CDAG) to represent the relationship between loop iterations and array data and then assigns the sets of loop iterations to processing cores and sets of data blocks to on-chip memories. During the mapping process, the on-chip memory capacity and load imbalance across different cores and the topology of the NoC are taken into account. In this paper, we present two variants of our approach: depth-ﬁrst placement (DFP) and breadth-ﬁrst placement (BFP), and compare them to three alternate code/data mapping schemes. The experimental evaluation shows that our CDAG based placement schemes are very successful in practice, achieving average performance improvements of 19.9% (DFP) and 16.8% (BFP), and average energy improvements of 29.7% (DFP) and 27.8% (BFP). I . IN TRODUC T ION As CPU design has become severely power limited, it is now commonly accepted that staying on the current performance trajectory will come about through the integration of multiple processors on a chip rather than through increases in the clock rate of single processors. Once the number of CPUs on one chip passes some threshold (∼8 CPUs), these future chip multiprocessors (CMPs) will require an on-chip network (an NoC, Network-on-Chip) in order to be able to handle the required communications between the CPUs in a scalable, ﬂexible, programmable, and reliable fashion. With this network-on-chip-based CMP (NoC-based CMP) as the computing platform, a very rich set of research challenges arise. Circuit and architectural challenges such as router design, IP placement, and sensor placement are currently being studied in the context of CMPs in both industry and academia, as is evident from recent publications [16], [9], [11]. In comparison, the work on programming and compiling for these architectures has received considerably less attention. Unfortunately, unless critical software issues such as programming language support, application mapping, data placement, and compiler support are adequately addressed, CMPs may not be able to deliver promised performance levels. Motivated by this observation, the main contribution of this paper is a compiler directed code and data placement scheme for twodimensional mesh based CMP architectures. The proposed approach uses a Code-Data Afﬁnity Graph (CDAG) to represent the relationship between loop iterations and array data and then assigns the loop iterations to processing cores and sets of data blocks to onchip memories. During the mapping process, the on-chip memory capacity and load imbalance across different cores as well as the topology of the NoC are also taken into account. In this paper, we propose two variants of our integrated code-data mapping approach: Depth First Placement (DFP) and Breadth First Placement (BFP).The experimental evaluation shows that our CDAG based placement schemes are very successful in practice, achieving average performance improvements of 19.9% (DFP) and 16.8% (BFP), and average energy improvements of 29.7% (DFP) and 27.8% (BFP). I I . COD E -DATA A FFIN I TY GRA PH Our compiler targets a two-dimensional mesh based chip multiprocessor (CMP), and loop-intensive parallel applications. For the purposes of this study, we assume that each node of this CMP contains a processor core, an on–chip memory component, and a network interface which connects the node to its neighbors. We assume that the compiler/application programmer manages the onchip memory space and thread-to-core assignments. Note that in this architecture, cost of a data access depends on the distance between the requesting core and requested data. We also assume that code parallelization has already been applied prior to our approach, using any known technique. In fact, the choice of the code parallelization scheme used is orthogonal to the main focus of our approach, which performs code and data placement. Therefore, in principle, our approach can work with any code parallelization strategy. Note also that the data dependencies across loop iterations will be taken care of during code parallelization and, consequently we assume that the iteration blocks (used in our approach) do not have data dependencies among them. Our compiler based placement scheme employs a data structure called the Code-Data Afﬁnity Graph (CDAG). CDAG is essentially a bipartite graph G(V1 , V2 , E ), where V1 represents iteration blocks, V2 represents data blocks, and E captures the access relationship between iteration and data blocks. In this context, an iteration block is a set of consecutive loop iterations that belong to the same loop nest and a data block corresponds to a set of consecutive elements that belong to the same array. An edge e ∈ E indicates that at least one of the iterations in V1 accesses at least one of the data elements in V2 . This is referred to as an access relationship in this paper. Note that CDAG is built by the compiler and used for data code placement. Clearly, an important question is how to determine the iteration and data blocks to use and how to extract the access relationships from the application code. Our approach is ﬂexible in the sense that it can work with any iteration/data block size. Consider, for instance, that a given array is divided into data blocks of size Ld and an iteration space is also divided into blocks of size Li . Note that, in general, Ld may be different from Li . As an example, consider the following simple loop, written in a pseudo language, where two onedimensional arrays are accessed: for j = 2, N-1 b[j] = a[j+1] + a[j-1] + a[j] ; *This work is supported in part by NSF Grants 0702519 and 0720749, Microsoft Research and GSRC. Figure 1(a) shows how the loop iterations (on the left) access data elements (on the right) in this loop (we focus only on array a for (a) (b) (c) s n o i t a r e t I p o o L s t n e m l e E a t a D s k c o B n o l i t a r e t I s k c o B a l t a D s k c o B n o l i t a r e t I s k c o B a l t a D Data Block Mapping Iteration Block Mapping (a) Array a Array b (b) 1 p o o L 2 p o o L Array c 1 p o o L 2 p o o L a y a r r A b y a r r A c y a r r A Fig. 1. Pictorial representation of loop iteration elements, data elements and construction of iteration blocks, data blocks and access relationships. Fig. 2. Pictorial representation of loop to data mapping (a) and corresponding CDAG for a case where two loops access three arrays. illustrative purposes). In this code fragment, we can identify a block with its ﬁrst element; that is, below where two separate loops manipulate ﬁve different data arrays (again, for illustration, we focus only on arrays a, b, and c). Bi,p = {j | max{2, p} ≤ j < min{p + Li , N − 1}} Bd,q = {k | max{1, q} ≤ k < min{p + Ld , N }}, (1) (2) Loop1: for j = 1, N-1 d[j] = a[j+1] + a[j+1] + a[j] ; where Bi,p and Bd,q correspond to pth iteration block and q th data block, respectively, assuming that array a has N elements. If the number of loop iterations is not divisible by Li or Ld , the remaining elements are placed in a new block with fewer iterations or data elements; this would not affect the performance in any signiﬁcant way as in general Li and Ld << N . In the loop shown above, each iteration j accesses three data elements of array a. Note that, the data elements accessed by a given j can belong to the same or different data blocks. In formal terms, we can deﬁne an access relationship ∆(Bi,p , Bd,q ) between data block Bd,q and iteration block Bi,p as follows: 0, (3) if ∃ j , k , R such that j ∈ Bi,p & k ∈ Bd,q & R ∈ R & R(j ) = k else. ∆(Bi,p , Bd,q ) = ( 1, where R refers to the set of array references in the code. Informally, ∆(Bi,p , Bd,q ) takes a value of 1 if there is an iteration in Bi,p that accesses a data element in Bd,q . It should be noted that the access relationships between iteration blocks and data blocks can be represented using a bi-partite graph. For example, assuming Li and Ld are each set to 3, the bi-partite graph in Figure 1(b) represents the access relationships implied by the code fragment above. In the rest of this paper, this graph is referred to as the Code-Data Afﬁnity Graph (CDAG), and is the main data structure built and used by our compiler for optimizing code and data placement. For ease of representation, in the remainder of this paper, we use V1 to represent the set of nodes that contain the iteration blocks, and V2 for the set of nodes that contain the data blocks. Note that the two nodes, Bi,p and Bd,q , of a CDAG have an edge between them if and only if ∆(Bi,p , Bd,q ) is 1. We also associate a weight, ωi,d with each edge ei,d (from iteration block represented by vi ∈ V1 to data block represented by vd ∈ V2 ) of a CDAG, and this weight captures the total number of elements from V2 accessed by the iterations in V1 . An important point about CDAG is that it can take a different shape when the value of Li and/or Ld is changed. For example, Figure 1(c) shows another CDAG for the same code fragment above, this time with Li and Ld values of 6 and 3, respectively. We renumber all loop iterations and data blocks in the application code such that the only ids that we use during the optimization (placement) process are Bi,p and Bd,q . Figure 2 (a) shows loop-iterations-to-data mapping and Figure 2 (b) gives the CDAG that corresponds to the code fragment Loop2: for i = 2, N-1 e[i] = a[i-1] + b[i] * c[i+1] ; One can potentially build a CDAG for the entire application program or divide a program into disjoint code regions such that no two code regions share any data block between them and build a separate CDAG for each such region to optimize code/data placement independently. This is the approach taken in our current implementation. I I I . COD E AND DATA P LAC EM EN T Our code and data placement algorithms for CMP architecture use CDAG. In our placement algorithms, iteration blocks are units of code placement, and similarly, data blocks are units of data placement. Integrated code-data placement decides the iterations blocks that will be mapped to CPUs for execution and data blocks that will be stored in the on-chip memories attached to the CPUs. In this section, we describe two algorithms for this integrated placement problem. A. Depth First Placement Our ﬁrst algorithm, called the depth-ﬁrst placement (DFP) algorithm, performs code and data placement for each core in turn. The DFP algorithm starts with a node which can be an iteration block node (that belongs to V1 ) or data block node (that belongs to V2 ). Without loss of generality, let us assume that it is an iteration block node (vx ∈ V1 ). In the next step, we select a node vy ∈ V2 such that ωx,y ≥ ωx,z for any vz ∈ V2 that is connected to vx . In other words, we proceed from the iteration block node to a data block node whose associated edge has the highest weight among all alternatives. In the next step, we move from vy to vn ∈ V1 such that ωn,y ≥ ωm,y for any vm ∈ V1 that is connected to vy . That is, we proceed from the data block node to an iteration block node whose associated edge has the highest weight among all alternatives. This ping-pong style movements between V1 and V2 continue in this fashion. Each time we move to an iteration block node vi , we add its size |vi | to C , and similarly, each time we move to a data block node vj , we add its size |vj | to C ′ (both C and C ′ are initialized to 0). This process continues until either C ≥ Cideal , where Cideal represents the maximum allowable load on the core or C ′ ≥ C ′ ideal , where C ′ ideal represents the on-chip memory capacity for a node. Once either of these is reached, the data blocks visited so far are assigned                           to be stored in a core’s memory and the iteration blocks visited so far are assigned to the same core for execution. The important point to note here is that the loop iterations and data elements assigned to a core using this approach exhibit a certain degree of afﬁnity, i.e., the iterations mostly use the data elements assigned to the memory attached to the same core. Algorithm 1 : Depth First Placement Algorithm Input: A mesh based CMP, a weighted bipartite graph G = (V , E ) and a vertex vi ∈ V , where V = {V1 (iteration blocks) S V2 (data blocks) }. Output: Placement of code and data on appropriate cores and local memories. 1: Vc = V ′ 2: Select a free core, Cf , that is a neighbor of already processed cores (if any). 3: Create a Stack, S and P ush(S, vx ) 4: while C ≤ Cideal && C ′ ≤ C ′ ideal && not(S.empty()) do vx = P op highest priority(S ), Mark vx as “placed” if vx ∈ V1 then Vc = Vc S{vx }; C = C + |vx |; else V ′ c = V ′ c S{vx }; C ′ = C ′ + |vx |; end if for ∀vy , such that (vx , vy ) ∈ E selected in reverse order of priority do if vy is “non-placed” then P ush(S, vy ) end if end for 11: end while 12: Place Vc on processor Cf and V ′ c in memory of Cf 13: Select a “non-placed” node vi such that, ∀vp , such that vp is marked “placed” and (vi , vp ) ∈ E and ∃vp marked “placed”, ωp,i is the maximum 14: if such a node is found then goto 1. else Terminate. end if c = φ; C = C ′ = 0; 5: 6: 7: 8: 9: 10: After the code and data placements for the ﬁrst core are complete, we move to a neighboring core and carry out its code and data assignment. However, in doing so, our approach takes into account both the topology of NoC in question and the code-data placements that have already been performed up to this point. More speciﬁcally, we always select the core to process next from among the ones that are neighbors to already processed cores, and the CDAG node to start (for the new core) is selected such that it is a neighbor of one of the traversed nodes (during processing the previous core) and the edge that connects it to the already traversed nodes has the highest weight among all alternatives. This ensures that we start our graph traversal for the second core with either (1) a data block node that is frequently accessed by an iteration block node already assigned to a neighboring node, or (2) an iteration block node that frequently accesses a data block node already assigned to a neighboring node. Then, we traverse the bi–partite graph for this second core using a similar ping–pong like strategy explained above. A sketch of our DFP algorithm is given in Algorithm 1. B. Breadth First Placement Like the DFP algorithm, our second algorithm, called the breadthﬁrst placement (BFP) algorithm, also performs code and data placement for each core in turn. However, it traverses the bi-partite graph in a breadth-ﬁrst fashion. It starts with a node which can be an iteration block node (that belongs to V1 ) or data block node (which belongs to V2 ). Let us assume, that it is an iteration block node (vx ∈ V1 ). In the next step, we select a set of nodes V ⊆ V2 such that, for all vy ∈ V , (x, y) is an edge in the CDAG. That is, we proceed from the iteration block to all the data blocks that are connected to that iteration block. In the next step, we start with V and include all iteration block nodes that are connected to the data block nodes in V . In the next step, we consider all the data block nodes that can be reached from I , the set of iteration block nodes. This process continues until we exceed the thresholds of Cideal or C ′ ideal . If this happens, instead of including all the nodes, we include only a subset of them (to maximize locality, we select the ones with the largest weights). Once we are done with the placements for the ﬁrst core, we move to a neighboring core and repeat the procedure explained above. Algorithm 2 presents a sketch of the BFP algorithm. Algorithm 2 : Breadth First Placement Algorithm Input: A mesh based CMP, a weighted bipartite graph G = (V , E ) and a vertex vi ∈ V , where V = {V1 (iteration blocks) S V2 (data blocks) }. Output: Placement of code and data on appropriate cores and local memories. 1: Vc = V ′ 2: Select a free core, Cf , that is a neighbor of already processed cores (if any). 3: Create a Priority Queue, Q and Enqueue(Q, vx ) 4: while C ≤ Cideal && C ′ ≤ C ′ ideal && not(Q.empty()) do vx = Dequeue(Q)and Mark vx as “placed” if vx ∈ V1 then Vc = Vc S{vx }; C = C + |vx |; else V ′ c = V ′ c S{vx }; C ′ = C ′ + |vx |; end if for ∀vy , such that (vx , vy ) ∈ E do if vy is “non-placed” then Enqueue(Q, vy ) end if end for 11: end while 12: Place Vc on processor Cf and V ′ c in memory of Cf 13: Select a “non-placed” node vi such that, ∀vp , such that vp is marked “placed” and (vi , vp ) ∈ E and ∃vp marked “placed”, ωp,i is the maximum 14: if such a node is found then goto 1. else Terminate. end if c = φ; C = C ′ = 0; 5: 6: 7: 8: 9: 10: 5 2 4 7 5 3 4 2 6 1 2 5 2 4 7 5 3 4 2 6 1 2 5 2 4 7 5 3 4 2 6 1 2 (a) CDAG (b) DFP (c) BFP 20 10 25 35 25 35 10 55 20 10 I-1 I-2 I-3 I-4 I-5 D-1 D-2 D-3 D-4 D-5 I-1 I-2 I-3 I-4 I-5 D-1 D-2 D-3 D-4 D-5 I-1 I-2 I-3 I-4 I-5 D-1 D-2 D-3 D-4 D-5 20 10 25 35 25 20 10 25 35 25 35 10 55 20 10 35 10 55 20 10 Fig. 3. (a) Illustration of a simple CDAG. (b) Partitions corresponding to DFP. (c) Partitions corresponding to BFP. The target system consists of two processors, Cideal = 75 and C ′ ideal = 60. C. Example To better illustrate the difference between the DFP and BFP algorithms, we now go over a simple example. Figure 3 (a), depicts a simple CDAG with associated weights and sizes. Sizes of nodes are different in this example to illustrate the most general case. Our DFP scheme is depicted in Figure 3 (b). The algorithm starts from node I–1. The edge with the highest weight from I–1 is the edge to D–1 which is taken. Similarly, at every further node, the edge incident on the target node with the highest weight and is yet to be taken is selected (D–1 to I–2) . At each step, based on whether the node represents an iteration block or data block, corresponding sizes are accumulated in C and C ′ . In our example, when the edge I–5 to D–5 is taken, C ′ accumulates a total of 65 (data block sizes of 35, 20 and 10), which is greater than C ′ ideal . This indicates the end of accumulation of afﬁne code and data for one core. In order to move to the next core, we select a neighboring core to an already processed core. In this simple example, it happens to be the second core. The node from which the new traversal starts is determined as the node connected with the edge with the highest weight from any node that is already processed. In our example, it is the node connected with the highest weight to any node in the partition {I–1, I–2, I–5, D– 1, D–4, D–5}. I–4 is connected to D–5 with a weight of 4 which is the highest. Therefore, we start our next traversal from I–4 and accumulate the rest of the nodes to be placed in the second processor. Note that, in DFP, every partition is formed by alternating between an iteration block and a data block if a partition is completely selected without retracing any path. Therefore, in a given partition, the number of iteration blocks could differ from the number of data blocks by any degree in general but only one in case the entire partition is selected over a single trace. TH E S IMU LAT ION PARAM E T ER S AND TH E IR D E FAU LT VA LU E S . TABLE I Architecture Core Data/Instr L1 Capacity Local On-Chip Memory Link Speed Link Activation Latency Link Activation Energy Packet Header Size (Li , Ld ) 5 × 5 2D mesh two-issue 8KB (per node) 512KB (per node) 1GHz 1 µsec 140 µjoule 3 ﬂits (20, 20) On the other hand, the operation of our BFP scheme is depicted in Figure 3 (c). In this scheme, all the nodes connected to the node being processed are traversed ﬁrst. In our example, starting from I–1, all nodes connected to I–1, namely D–1 and D–2 are traversed in order of corresponding edge weights. Accumulation of sizes happens as in depth ﬁrst placement. The node dequeued from the priority queue is D–2. Therefore, all nodes that are not marked and are connected to D–2 are traversed in the next phase. This continues until D–4 is accumulated and C ′ becomes greater than C ′ ideal . Note that the partition derived here is different from the DFP case and also, in general, that the partitions can have any number of iteration or data blocks and the scheme does not impose any relationship between them. Before moving to our experimental evaluation of these two algorithms and their quantitative comparison to alternate placements, we want to emphasize that it is not clear which one of these two placement algorithms is better than the other. Depending on the program code to be analyzed, one of them may be better than the other. The advantage of BFP over DFP is that it covers all data blocks (resp. iteration block) accessed by an iteration block (resp. data block) in a single shot, whereas the DFP algorithm may not be able to include all those blocks. The drawback of BFP on the other hand is that some of such quickly-included blocks may not be the best candidates (for the current core being processed) in the long run as the corresponding edge weights may not be very high. In our experiments, we evaluate both these algorithms. IV. EX P ER IM EN TA L EVA LUAT ION In this section, we introduce our experimental setting and present the data collected from the evaluation of our proposed placement schemes. To conduct our experiments, we implemented a ﬂit-level network-on-chip simulator (built on top of Orion [21]) and connected it with SIMICS [17], a multi-processor simulator. The network is parameterized in a similar fashion to that in [8]. The link speed is set to 1Gb/sec. Each input port of switch has a buffer that can hold 64 ﬂits, each of which is 128 bits wide (packet size is 16 ﬂits). A. Setup We used all the benchmarks from the SPECOMP suite [4] to evaluate the proposed integrated code-data placement schemes. For each benchmark, after fast-forwarding 1 billion instructions, we collected statistics for the next 2 billion instructions. To compare different approaches proposed to alleviate the code-data placement problem, we implemented several schemes in our experimental framework and quantiﬁed their impact. The schemes tested in this work can be summarized as follows: • Code-Only: In this scheme, the data are distributed across the on-chip memory components in a round-robin fashion, but the code distribution is carried out taking into account the data distribution. In other words, loop iterations are assigned to processing core to maximize data locality (for the round-robin data distribution). • Data-Only: This is the dual of the previous scheme. The code assignment across cores is performed in a round-robin fashion. However, the data-to-memory assignment is done such that data locality is maximized as much as possible based on the roundrobin iteration distribution. • DFP and BFP: These are the implementations of the integrated code-data placement algorithms described in this paper. • Topology Agnostic: This is a previously proposed integrated code-data placement scheme [3]. The fundamental difference between our scheme and this work is that the latter does not take the network topology into account in performing code-data placement. However, to our knowledge, this scheme representes the state-of-the-art in compiler-directed code and data placement in multiprocessor machines. Each loop in the application has been analyzed by the compiler (SUIF [2]) and transformed such that outermost loop parallelism is obtained to the extent allowed by data dependencies, i.e., from each loop nest, the compiler parallelizes the outermost loop that does not carry any data dependency. This strategy tends to minimize inter-processor synchronization and helps reduce execution time. It also represents, in our opinion, the state-of-the-art in loop-level code parallelization. We make experiments with Code-Only and Data-Only schemes to show that, for the maximum performance and energy beneﬁts, code and data placement should be carried out in a synergistic fashion. Also, our experiments with the scheme proposed in [8] are aimed at revealing the importance of considering the CMP topology during code-data placement. All these versions are implemented using the SUIF compiler framework [2]. The additional compilation time increases brought by our DFP and BFP schemes over the CodeOnly scheme were 14.7% and 12.8%, respectively, on average. The longest compilation time we witnessed during our experiments was 1.6 minutes, which is not too high in our opinion, considering that compilation is basically an off-line process. Also, the additional code size increases brought by DFP and BFP (again over the Code-Only scheme) were, on average, 6.6% and 4.7%, respectively. Consequently, we did not observe any degradation in the instruction cache performance. Table I gives the major simulation parameters and their default values. Under these parameters, the execution times for our applications under the Code-Only scheme varied between 55.7 seconds and 1.6 minutes, and their energy consumptions varied between 118 mJ and 809 mJ. The performance and energy numbers presented in the remainder of this section are normalized with respect to the corresponding values obtained under the Code-Only scheme. Unless otherwise stated, the code and data block sizes are equal to 20 (iteration and data elements). B. Results Our ﬁrst set of results give normalized execution latencies and are presented in Figure 4. We ﬁrst observe that our placement schemes generate better results than the Code-Only and Data-Only schemes. In fact, the average latency improvements the DFP algorithm brings over Code-Only and Data-Only are 19.9% and 22.0%, respectively. In galgel, the default (round robin) code distribution performs reasonably well, and therefore, the results obtained using our algorithms and Data-Only are close to each other. Similarly, in mgrid, our approach and Code-Only generate very similar results. Secondly, in general, for this set of applications, DFP generates better results than BFP. The third major observation one can make from these results is that there is more than 10% difference between the average improvement brought by DFP and that obtained using the Topology 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 a m m p u p p a l s p a i a t r f e c a r c e f m d 3 a a g f o t r e g a g l l e k a u q e m g i r d s m w i w p u w i e s E u c e x i t a L n o t y c n e Code Only Data Only DFP BFP Topology Agnostic Fig. 4. Normalized execution latencies. 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 a m m p u p p a l s p a i a t r f e c a r c e f m d 3 a a g f o t r e g a g l l e k a u q e m g i r d s m w i w p u w i e s A e v r e g a D i s t e c n a Code Only Data Only DFP BFP Topology Agnostic Fig. 5. Thread-to-data access distances (average values).     0 0.2 0.4 0.6 0.8 1 1.2 a m m p u p p a l s p a i a t r f e c a r c e f m d 3 a a g f o t r e g a g l l e k a u q e m g i r d s m w i w p u w i e s e n E r y g C u s n o m p i t n o Code Only Data Only DFP BFP Topology Agnostic Fig. 7. values. Normalized energy consumption 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 (10,10) (20,20) (50,50) (100,100) (10,20) (20,10) N o r m a i l e u a V d e z l Execution Latency Energy Consumption Fig. 8. Sensitivity to the iteration block and data block sizes. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 DFP Optimal DFP Optimal Execution Latency Energy Consumption N o r m a i l e u a V d e z l ammp facerec equake applu fma3d mgrid apsi gafort swim art galgel wupwise Fig. 9. Comparison of the DFP scheme with the optimal code-data placement. block sizes tend to blur the afﬁnities between individual iterations and data elements, and this tends to generate results which are more on the sub-optimality side. Another interesting observation from Figure 8 is that (10,20) and (20,10) generate worse results than both (10,10) and (20,20). This result says that, unless there is a reason, we should not work with cases where the iteration block sizes and data block sizes differ. We also made experiments to compare our performance and energy savings to the optimal savings that can be achieved under the given code and data block sizes. To obtain the optimal savings, we used a proﬁle based approach. In this approach, we ﬁrst proﬁled the application code to determine the relationship between code and data blocks, and then formulated an ILP (integer linear programming) based solution, which gives the code and data placements for all cores. The results are shown in Figure 9 for both performance and energy. An interesting observation is that in four applications (apsi, art, galgel, and swim), DFP and the optimal placement scheme produced the same result, and in facerec, the difference between the two schemes was very low. When all twelve applications are considered, we see that the optimal placement is 4.8% better than our scheme from a performance viewpoint and 6.3% from an energy viewpoint. Therefore, we can conclude that our approach in general comes very close to the optimal code-data placement. Also, we want to mention that an ILP based solution may not be feasible in general due to the large number of variables and constraints involved in the code-data placement problem. In fact, we observed during the experiments that in some cases the solution time taken by the linear solver was as high as 18 hours on a 2 GHz machine. Therefore, when both solution time and solution quality are considered together, we believe that our approach strikes a good balance. V. R E LAT ED WORK Automatic computation and data decomposition using compilers has not been effective with large codes, although there are myriad previous works attempting to achieve this [3], [5], [14], [20]. Mapping applications for NoC based architectures using compilers has also been a hot research issue in the recent past [10]. Kuijlman et al [13] present a compiler framework that takes a program with partial work and data placement information, and transforms it into an explicit parallel program optimized for the amount of communication. [7] compares performance impact of alternate code and data mapping strategies on a 64 node IBM RP3, but this technique is very architecture speciﬁc and does not extend easily to chip multiprocessors. Lowenthal and Andrews [15] describe an adaptive system that takes an initial data placement, and changes the placement whenever a monitor indicates that a different placement would perform better. Performance overheads of such monitoring as well as modifying of placement is avoided by a good compiler based approach. Moreover, afﬁnity between code and data has not been considered or its impact on the performance has not been studied well in the previous works. V I . CONC LU S ION S This paper presents an integrated code and data placement scheme targeting two-dimensional mesh based CMPs. The proposed approach uses a novel (compiler based) data structure called the Code-Data Afﬁnity Graph (CDAG) to represent the relationship between loop iterations and array data and then places the sets of iteration blocks to processing cores and sets of data blocks to on-chip memories. We evaluated two different variants of this approach in this paper and compared them against three alternate code and data mapping schemes The results indicate that our CDAG based placement schemes achieve average performance improvements of 19.9% (DFP) and 16.8% (BFP), and average energy improvements of 29.7% (DFP) and 27.8% (BFP). "
2009,An accurate and efficient performance analysis approach based on queuing model for network on chip.,"An accurate and highly-efficient performance analysis approach is extremely important for the early-stage designs of network-on-chip. In this paper, the novel M/G/1/N queuing models for generic routers are proposed to analyze various packet blockings and then the performance analysis algorithm is presented to estimate some key metrics in terms of packet latency, buffer utilization, etc. For single-channel and multi-channel routers, the comparisons between analysis and observed results validate that the proposed approach with mean errors of 6.9% and 7.8% achieve the speed-ups of 240 and 210 times respectively. In our design methodology, this approach can not only effectively direct NoC synthesis process but also be conveniently applied to multi-objective optimizations to find the best mapping solutions.","An Accurate and Efficient Performance Analysis Approach  Based on Queuing Model for Network on Chip  Mingche Lai, Lei Gao, Nong Xiao, Zhiying Wang  School of Computer, National Univ. of Defense Tech. Changsha, China.  {mingchelai, gaolei, nongxiao, zhiyingwang}@nudt.edu.cn  ABSTRACT  An accurate and highly-efficient performance analysis approach is  extremely important for the early-stage designs of network-onchip. In this paper, the novel M/G/1/N queuing models for generic  routers are proposed to analyze various packet blockings and then  the performance analysis algorithm is presented to estimate some  key metrics in terms of packet latency, buffer utilization, etc. For  single-channel and multi-channel routers, the comparisons between analysis and observed results validate that the proposed  approach with mean errors of 6.9% and 7.8% achieve the speedups of 240 and 210 times respectively. In our design methodology,  this approach can not only effectively direct NoC synthesis process but also be conveniently applied to multi-objective optimizations to find the best mapping solutions.  Categories and Subject Descriptors: B.4.3 [Hardware]:  Input/Output and Data Communication - Interconnections.  General Terms: Algorithms, Performance.  Keywords: Network-on-chip, analysis, queuing model.  1. INTRODUCTION  With the rapid development of semiconductor technology, it is  allowed to introduce hundreds of cores on a single chip to fulfill  computational demands. Recently, the traditional bus-based structures have been seen more and more incapable of meeting these  challenges for intolerant wire delays or poor scalability in deep  submicron conditions. Network-on-chips as an on-chip communication concept, its design methodology with clear advantages have been presented in [1]. However, while NoC offers substantial  bandwidth and concurrent communication capability, its performance may be significantly degraded due to the complexity of  design issues. To cope with this situation, the design exploration  with simulation is often considered to be one of the critical  research issues. During optimization loop, the time-consuming  simulation always models the accurate behaviors at the expense of  low efficiency. In this way, the exploration phase only chooses  few alternatives for estimate, and always achieves the relatively  poor results while wasting a plenty of design periods.  An accurate and efficient performance analysis approach is  extremely important for the electronic design automatic methodology of NoCs [2]. It will not only provide the quick estimate of  performance metrics, such as latency and throughput, to direct  architecture designs, but also assist designers to perform mapping  optimization towards specific applications. Related works on  Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, or republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.  ICCAD’09, November 2–5, 2009, San Jose, California, USA.  Copyright 2009 ACM 978-1-60558-800-1/09/11...$10.00.  network performance analysis were mainly concentrated on multiprocessor or micro-network communication fields. In [3], Dally  first used M/M/1 queuing model to analyze average packet latencies of k-ary n-cubes. Although it was useful in some cases, it lost  its accuracy as network traffic increased. The authors of [4] [5]  proposed different methods to exhibit a good degree of accuracy,  but they assumed single-flit or infinite buffers. Moreover, the  packets were expected to be long enough. These assumptions  seriously deviated from the practice of NoCs. Recently, the performance analysis has also been emerged into an important aspect.  Hu [6] firstly proposed a queuing analysis approach to customize  the NoC router design. Given the target applications, nearly 80%  savings in buffers could be achieved without degrading its performance. But this model was restricted in store-and-forward or vir-  tual cut-through switching schemes. In the following, Ogras [7]  presented an analytical performance analysis methodology for  NoCs based on the generic router model. Although the proposed  approach was an innovative one which was developed for wormhole flow control, it suffered from low accuracy under high traffic  rates and did not take account of virtual channels. In [8], Huang  customized the virtual channels based on NoC model according to  bandwidth utilization of each port, but this work was incapable of  calculating many performance metrics such as average latency  and throughput. Ost [9] also proposed a simplified NoC model,  which provided a performance estimate by combining simulation  and analytical methods. It evaluated with high precision the latency and throughput of wormhole switching NoCs, but its efficiency  still needed to be improved due to its detailed simulation.  In this paper, the main contributions are to develop the M/G/  1/N queuing model of routers with wormhole routing and present  the performance analysis algorithm of NoCs. The proposed per-  formance analysis approach not only estimates the latency and  buffer utilization accurately under different traffic conditions by  considering various blockings, but also yields high efficiency by  avoiding detailed simulations. During the optimization loops, besides the single-channel structure, we also provide the analytical  models of multi-channels to improve the network performance.  The accuracy of them is validated during the experiments. The  proposed analysis approach of NoC is also applied to multi-object  optimization to solve application mapping problems. Compared to  other analysis methods [10] [11] it can converge to better results  within a short design period, and thus it is easy to be invoked. The  rest of paper is organized as follows. In section 2, the queuing  models of NoC routers are developed. In section 3, we describe  the performance analysis algorithm of NoCs. Experiments are presented in section 4 and finally we conclude in section 5.  2. Analytical model of NoC routers  In this section, we define the unified NoC representation and application characterization graph as follows. The NoC architecture  can be uniquely described by O(A(R,C),(cid:525)), where network com-  563   munication graph A(R,C) is a directed graph, including the set of  routers R and the set of connections C. For any connection c(cid:281)C,  W (c) gives its channel width. For any router r(cid:281)R, B(o,r) and V  (o,r) give the buffer size and channel number of port o respectively. The communication policy (cid:525) in this paper adopts the deterministic routing and wormhole flow control, which gain popularity  in most of recent NoCs. The application characterization graph  CG(T,F) is also a directed graph, where each vertex ti denotes an  application task and each arc fi,j characterizes the communication  volume from ti to tj. Towards these descriptions, the performance  analysis approach is proposed to address:  (cid:105) Network performance analysis. Given the graphs A(R,C), CG  (T,F) and a particular mapping (cid:550):T (cid:10) ti(cid:314)rj(cid:143) R, we effecttively estimate the packet latency per flow, communication  volume and network throughput under different rates.  (cid:105) Micro-architecture design. By estimating NoC performance,  we analyze the influences of key parameters, e.g. buffer size,  channel bandwidth, pipeline stage, etc. The optimized parameters can be obtained with fast feedback in the early stage.  (cid:105) Application mapping optimization. The task graph is mapped  to a set of routers to achieve low latency, high throughput  and low power consumption. Our analysis approach can be  applied to multi-objective mapping to achieve better effects.  Our basic idea is to analyze various blockings of each input and  then resort M/G/1/N queuing model to calculate the packet latency, buffer utilization, etc. In analytical model, given channel  bandwidth W bytes, the packets with overhead H bytes spend Tnode  cycles traversing across h-stage pipelined router r as shown in  Eq.1, which includes the service time of the waiting and incoming  packets, the residual service time as well as the remaining time  traversing across the router. Let tlink be the delay of link connecting adjacent routers, we compute the packet latency from source s  to destination d in Eq.2. Considering the contentions on each hop,  the first two items calculate the latency of header flit and the third  item denotes the transfer time of its body flits in a pipelined fashion. In the following, we will utilize the M/G/1/N queuing system  to model NoC routers, so that the parameters (cid:534), (cid:306) and (cid:535) in Eq.2 can  be derived to calculate the latency of each flow.  )1),(( ro ),( ro ),( ro h (cid:117)(cid:14) (cid:87) (cid:16)(cid:14) (cid:93) (1) (cid:74) (cid:14) (cid:32) 1 Tnode dsLA ,( ) (cid:32) (cid:166) dsr (cid:111)(cid:143) (( (cid:74) ( ro )1), (cid:117)(cid:14) (cid:87) ( r ro ), r (cid:14) (cid:93) ( ro ), r (cid:14)(cid:14)(cid:16) thL link ) (cid:16) t link (cid:14) ( L ;)1 (cid:16) L (cid:14)(cid:32) 1 (cid:186)WH / (cid:170) (2) 2.1 Analytical model of Single-Channel Router  This section mainly focuses on the model of generic single-channel router for performance analysis with the following hypothesis.  Firstly, the arrival process of header flit follows a Poisson process  and its body flits will come to heel in sequence. This assumption  was commonly used in many previous works [7] [12] and thought  to be meaningful for quite a few classes of applications. Secondly,  the packets at destination node are instantly transferred to local  processors as soon as they arrive. With the wide use of the interleaved memory organization and buffer techniques, local memory  systems provide higher bandwidth than on-chip communication,  and thus packet reception is seldom interrupted by local accesses.  Given the application characterization graph CG and mapping  scheme (cid:550), we start to calculate the traffic rate of each input. Let a  particular transfer path in network be gs,d: map(vs)(cid:314)map(vd), fs,d  represents its injection rate. Assuming that all the tasks have been  Table.1 List of Parameter Notation in analytical model  Description  Param. W  H  L  h  (cid:534)  (cid:306)  (cid:535)  ai,j  voli  Tbodyi,j PSAi,j  Fi,j  PFj  TSAi,j  voli,j  ai,j,k  PFj,k  input channel bandwidth  packet data overhead  length of network packet  number of router pipeline  average queue length (packet) of channel  average service time for packet of channel  average residual service time for packet of channel  traffic arrival rate from input i to output j  traffic arrival rate at input i  blocking delay by body flits when from input i to output j  packet contention possibility when from input i to output j  transfer request possibility from input i to output j  flow control possibility from neighbor j  blocking delay by packet contentions or flow controls  traffic arrival rate at jth channel of input i  traffic rate from jth channel of input i to kth channel of neighbor  flow control possibility from channel k of the neighbor  j  mapped onto target tiles, the traffic rate ai,j as listed in Table 1  along with other parameters can be obtained by enumerating all  the traffic flows that arrive at input i and leave through output j as  shown in Eq.3, where indicator function RD returns 1 if path gs,d  is delivered from input i to output j, and returns 0 otherwise. In  this way, the arrival rate voli of input is derived by the sum of ai,j  with different output directions.  a i , j (cid:32) (cid:166) (cid:5) g ds , f ds , iRD (cid:11) , (cid:117) gj , ds , (cid:12) ; vol i (cid:32) 5 (cid:166) (cid:32) 1 j a i , j ( i (cid:32) ,1 (cid:22) )5, (3) Next we focus on analyzing the average service time of input.  For each arrival packet of input, besides the transfer cycles of  body flits, its average service time also depends on the blocking  delay, which can be further divided into two parts according to the  happening sequence. The first part happens when the arrival  packet at front of the input is blocked by body flits. In wormhole  switch NoCs, the body flits of the packets cannot be interrupted  due to successive transfers. Although a particular packet arrives at  the head of the channel, its request will not be granted immediately until the current transfers to the same port complete. Then, the  second part is mostly due to contentions among header flits of  different inputs. When the previous packets leave router through a  certain output, all the other header flits destined to the same direction apply for the transfers simultaneously. Here, when downstream channel is not full, one header will be granted and the rest  are blocked at respective inputs. Fig.1 illustrates the arbitration  model of generic routers. Let’s motivate traffic flow with a2,3 for  instance. If south input of its north immediate neighbor is not full,  it conflicts with other traffic flows whose rates are a1,3, a3,3, a4,3  and a5,3 respectively and the winner packet will occupy output 3  until transfer completes. Otherwise, its immediate north neighbor  will generate control flows to prevent current packet transfers.  Now, we derive the average blocking delay by taking account  of such effects. Let us consider, for instance, the packets addressed from input i to output j. The first unknown parameter is the  blocking delay caused by body flits. To facilitate the analysis, we  assume that the new packet appearing at the head of the input is  now blocked by the qth flit of current packet which is delivered  from input k to output j. The waiting time for the completion of  current packet is then at least L-q cycles. Here, because the new  564 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers       packet encounters any flit of a particular packet from input k with  the same probability ak,j/L, the average blocking delay by the  body flits of input k can be given by(cid:283)q:1(cid:279)L (L-q)(cid:104)ak,j/L. By  considering the body flits from all the other inputs, the average  blocking delay by body flits is estimated as:   a 1-L L 2 (cid:17189) (cid:17189)   (cid:17268)(cid:17172) k i jk , (cid:17268)(cid:17172) jk , ji , )) ( ( L 1q i k a q-L Tbody (cid:32) (cid:117) (cid:32) (cid:166) (cid:32) (4) Fig.1. Arbitration model of the generic router  Next, we derive the blocking delay TSAi,j caused by packet contentions or flow controls. For the packet in input i to be delivered  to output j, parameter blocki,j gives its blocking possibility due to  contentions or flow controls. Here, the blocked packets staying at  the head of channel keep applying for the transfers, and thus we  can further use blocking possibility to approximate the probability  Fi,j of transfer requests from input i to output j as shown in Eq.5.  Now, let us consider the case that the current packet and other c  ones from different inputs compete for the same bubble on the  right side of Fig.1. When the current packet at the head of input i  is to be delivered to output j, we use the request possibility Fi,j to  calculate the probability (cid:507)(i,j,c) that c packets of other inputs  apply for the transfers towards output j simultaneously. In this  context, only one candidate can be granted at a time, and thus the  conditional possibility of packet blocking due to contentions is  given by c/(c+1). In this section, we take into account different  number of packets to be delivered to output j, and the packet  contention possibility when transferring from input i to output j  can be then calculated as PSAi,j in Eq.6. On the other hand, we  derive parameter blocki,j in terms of contention possibility PSAi,j  and flow control possibility PFj that can be provided from downstream routers. By replacing blocki,j in Eq.5 with the right side of  Eq.7,  the request possibility Fi,j becomes a function of the parameter PSAi,j. We combine Eq.5 and Eq.6 together to calculate the  parameter PSAi,j, and then derive blocking possibility blocki,j.   ji , ji , ji , ji , ji , ji , 1 block L a block block L a F 2 1 ) ( ) 1( ) ( (cid:16) (cid:117) (cid:32) (cid:14) (cid:14) (cid:14)(cid:117) (cid:32) (cid:22) (5) (cid:17189)4 0 ji , cj ), ,( i 1 (cid:32) (cid:39) (cid:14) (cid:32) c c c PSA (6) ) ii , ,( i ) 1( ) 1( cj ), ,( i , (cid:32) c (cid:143) }1,0{ (cid:14)(cid:14) k , , 1 (cid:16) , 1 (cid:16) , , , 4 4 (cid:22) 1 (cid:22) 1 4 4 1 1 4 4 1 1 4 1 4 1 k k k (cid:5) k j i k j i k j i k j i i i F F F F where (cid:31) (cid:31) (cid:122) (cid:16) (cid:16) (cid:32) (cid:39) (cid:166) (cid:22) (cid:22) (cid:22) (cid:22) ) 1)( 1(1 ji , ji , j PFPSA block (cid:32) (7) At this point, because the packets blocked by packet contentions or flow controls need to wait L cycles to reapply for the  transfer, the blocking delay TSAi,j can be gained by Eq.8.  ) 1( ji , ji , 2 ji , ji , ji , block L block L block L block TSA (cid:32) (cid:14) (cid:14) (cid:32) (cid:22) (8) In the scope of this work, the input channel with a finite channel size of N can be modeled using M/G/1/N queue. According to  the hypothesis, the packet arrival process is Poisson with a mean  arrival rate of voli/L, and then the service time follows the general  distribution G with a mean of (cid:306). Using the parameters Tbodyi,j and  TSAi,j derived from the above steps, the service time (cid:306)i,j of packets  transferring from input i to output j is given by Eq.9, which indicates the transmission time over the router. In this way, the average service time as well as its variance contributed by the packets  towards different output j can be calculated by Eq.10. Using the  definition of queuing model [13] and Little’s formula, the parameters of M/G/1/N system are acquired by Eq.11.  Tbody TSA L j i j i j i (cid:14) (cid:14) (cid:32) (cid:87) , , , (9) i j i ji , ji , i i j ji , ji , i vol a D ( vol a E ( (cid:166) (cid:166) (cid:32) 1 (cid:32) 1 (cid:117) (cid:32) (cid:117) (cid:87) (cid:32) 5 2 5 )) E( ( ) , ) (cid:87) (cid:87) (cid:87) (cid:87) (10) ) 1( ), ( ) ( )) EW ( 1( , )1 ( N k (cid:32) 1 N k (cid:32) 1 N k s i s q i q i i k i p kp W EWW E p k (cid:16) (cid:32) (cid:16) (cid:32) (cid:16)(cid:32) (cid:16) (cid:32) (cid:166) (cid:166) (cid:79) (cid:87) (cid:87)(cid:79) (cid:87)(cid:79) (cid:93) (cid:74) (11) Where (cid:534)i is the average packet number of input i, Wq is the average waiting time excluding the service period, and (cid:535) is the average  residual service time for current transfer. In addition, pk is the probability of existing k packets in M/G/1/N system, and pN denotes  the possibility of overflow when the system is being full. In general, we can gain the accurate pk at the expense of computational  overhead, which violates the basic principle of fast analysis. In  this section, the parameter pk is given by Eq.12, where pk * denotes  the probability of k packets in a standard M/G/1/(cid:146) system and its  approximate result is given by Eq.13 as described in [14].  pc 0( Nk ) 1(1 ( ))) ( (cid:173) (cid:174) (cid:175) (cid:32) (cid:16) (cid:117) (cid:16)(cid:16) (cid:31)(cid:100) (cid:87)(cid:79)(cid:87)(cid:79) (cid:32)(cid:166)(cid:16) (cid:32) ) ( )) ( 1( * k Nk E E c p k (12) (cid:11) (cid:12) 1 (cid:16) 1 0 ) 1)( ( 1 , (cid:16) (cid:16) (cid:32) N k kp E c where (cid:87)(cid:79) ] )) )( E ( ED )( (2 exp[ , )1 )0 ( k ) E )( 1)( ( ( 1 3 (cid:16) 1 * k (cid:87)(cid:79)(cid:79) (cid:16) (cid:87)(cid:87)(cid:79) (cid:14) (cid:70) (cid:173) (cid:16) (cid:87)(cid:79) (cid:174) (cid:175) (cid:70)(cid:70)(cid:87)(cid:79) (cid:16) E k p k (cid:32) (cid:116) (cid:32) (cid:32) (13) 2.2 Analytical model of Multiple-Channel Router  Generally in NoC scenario, the head-of-line (HoL) blockings appear to be the critical issue of single-channel router, especially for  communication-intensive applications. Although allocating more  buffer space, it does not obviously reduce the HoL blockings which results that the throughput of links is typically limited to 58%.  In this context, two typical multi-channel structures provide different alternatives for improving the NoC performance. By the  packet multiplex at the input, the packets in other channel can still  progress when a certain channel is congested so that the throughput can be significantly improved.   Fig.2 (a) presents an asymmetrical structure where the individual channels for different outputs are provided at each input. Let  us keep the topology like 2D mesh and then the four channels in  each input correspond to different directions respectively. In this  case, the arrival packet enters the channel according to the traffic  path and will not be blocked by the previous ones that are destinated towards other directions. Then, NoC routers are also used to  adopting the symmetrical multi-channel structure whose simpli2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 565                         fied model is illustrated in Fig.2 (b), where each input is configured with v channels and the packet enters a random one with the  same possibility 1/v. With this structure, it not only eliminates  many HoL blockings by bypass mechanism but also tends to reduce the packet number of queue by averagely decreasing the arrival rate of each channel. In this section, we apply the same M/G/  1/N queuing system for multi-channel routers and then the critical  issue is to derive the average service time of channel.           (a) Asymmetrical structure                (b) Symmetrical structure  Fig.2 Arbitration model of multi-channel routers  First, we extend analytical model in section 2.1 to analyze asymmetrical multi-channel structure, where the input channels accommodate the packets towards different directions respectively.  With this structure, the current packet only conflicts with those at  the same channel of other ports. For instance, the packets of  channel v2,1 conflicts with those of channel v3,1, v4,1 or v5,1. Here,  different from single-channel, we further distinguish the rates of  packets that are delivered to different input channels of downstream neighbor. Let us consider the channel j of input i for instance. Although all packets are addressed towards the same direction j, they suffer from different flow control possibilities due to  their different directions on the next hop. Thus, we denote the traffic rate in the jth channel of input i to be delivered to the kth channel of neighbor as ai,j,k in Eq.14, where the indicator S(gs,d, j, k)  returns 1 only if the packets of channel j are routed towards direction k at neighbor, and S(gs,d, j, k)=0 otherwise.  a f iRD , gj , gS , kj , (cid:11) (cid:12) (cid:11) (cid:12) (cid:166) (cid:166) (cid:16)(cid:122) 5 (cid:32) ,1 (cid:5) g 5 (cid:32) (cid:117) (cid:32) kji , , j ji , ds , ds , ds , kji , , ds , k k a vol (14) Given the traffic rates ai,j,k, the blocking delay of packets delivered to the kth channel of downstream neighbor can be derived  by taking into account body-flit blockings, packet contentions and  flow controls. At first, similar with the single-channel, we can  obtain the parameter Tbodyi,j at channel j of input i to indicate its  average body-flit blocking delay. In the next step, we calculate  the blocking delay TSAi,j,k caused by contentions or flow controls.  Different from single-channel, the probability of transfer requests  (Fi,j) at channel j of input i is derived by summing up the request  probabilities of all the packets delivered to different channels of  neighbor, as shown in Eq.15. With the parameters Fi,j, Eq.6 then  calculates the packet contention possibility PSAi,j from input i to  output j in the same way. On the other hand, we use the righthand side of Eq.16 which considers both contention possibility  and flow control possibility PFj,k to replace the parameter blocki,j,k  in Eq.15. By combining Eq.15 and Eq.6, we can calculate parameter PSAi,j, and then derive the blocking possibility blocki,j,k.  1 F (cid:32) ( a L ) (cid:117) block (cid:166) (cid:16)(cid:122) 5 (cid:32) (cid:16) 5 ,1 kj , , kj , , , 1 j k k i i j i (15) ) 1)( 1(1 kj , , kj , , j i i PF PSA block (cid:16) (cid:16) (cid:16)(cid:32) (16) Now, we use the parameter blocki,j,k to approximate the average  blocking delay of packets from channel j of input i to channel k of  neighbor to be TSAi,j,k in Eq.17.  TSA L block 1/( block ) With the above parameters Tbodyi,j and TSAi,j,k, the expected  packet service time E((cid:306)i,j) as well as its variance D((cid:306)i,j) for any  given channel j of input i can be obtained by considering packets  delivered to different channel of neighbor as shown in Eq.18.  Next, the similar analysis process of M/G/1/N queuing system is  followed and will not be repeated here.  kj , , kj , , kj , , i i i (cid:16) (cid:117)(cid:32) (17) ji , ji , kji , , ji , kji , , j k k ji , ji , kji , , ji , kji , , j k (cid:16)(cid:122) 5 5 k ji , vol EL TSA ( Tbody a D vol L TSA ( Tbody a E 2 (cid:16)(cid:122) 5 (cid:32) ,1 5 (cid:32) ,1 / )) ( ) ( , /) ) ( (cid:87) (cid:87) (cid:87) (cid:16)(cid:14) (cid:14) (cid:32) (cid:14) (cid:14) (cid:32) (cid:166) (cid:166) (18) Next, we also analyze the symmetrical multi-channel structure,  where the arrival packets have the equal possibility 1/v of entering  any given channel. Let the traffic rate from one channel of input i  to output j be ai,j by enumerating all the traffic flows, the arrival  rate into one channel of input i is then derived by the sum of ai,j  on different output directions as shown in Eq.19.  (cid:166) (cid:166) (cid:32) 1 (cid:5) (cid:32) (cid:117) (cid:32) 5 , ds , ds , , , /) gj , iRD ,( ds , j j i i g j i a vol v f a (19) For blocking delay on the given channel, it is also influenced  by body-flit blockings, packet contentions or flow controls.  Note  that the average blocking delay by body-flit can be derived by  considering the traffic rates from other channels, similar to Eq.4.  Then, we only focus on packet contentions and flow controls. In  asymmetrical structure, the packets at the same input are delivered  to different directions and thus will not conflict with each other,  whereas in symmetrical structure they may be blocked by others  of the same input. Here, if the packet at input i is to be delivered  to output j and the channel number of each input is v, then the  packet has to compete with other 4v-1 channels for the target output. For symmetrical structure, we use the Fi,j in Eq.5 to calculate  the possibility p(i,j,v,m) that m packets out of v channels at input i  to be delivered to output j. With p(i,j,v,m), we take into account  different number of packets destined towards output j and then  calculate packet contention possibility when transferring from input i to output j as shown in Eq.20. Here, if n requests of current  input and (cid:153)ni packets from other four inputs are destined towards  output j, only one candidate can be granted at a time and thus the  condition probability of blocking due to contentions should be (n1+(cid:153)ni)/(n+(cid:153)ni).  ))1 ,1 ip ,,,( vjipnvj ,,() ) 1 ip ,,,( nvj ( 4 4 1 1 nn , 4 (cid:32) 1 4 (cid:32) 1 ji , 4 1 (cid:22) (cid:16) (cid:16) (cid:14) (cid:16) (cid:14) (cid:32) (cid:166) (cid:166) (cid:166) (cid:5) n n n n n n PSA i i i i (cid:22) (20) 4 1 4 1 ji , , , , , ) 1( FCmvjip ,( , , ) where , i i i i i Fm-v ji, m m v (cid:31) (cid:31) (cid:122) (cid:32) (cid:22) (cid:22) On the other hand, we derive the parameter blocki,j based on  Eq.21. For symmetrical structure, the flow control becomes valid  only when v channels of downstream neighbor input overflow,  and thus the possibility of flow controls is set to be pN v. We  substitute the right-hand side of Eq.21 into Eq.5, and then  combine Eq.5 and Eq.20 together to calculate parameter PSAi,j as  well as blocki,j.  566 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers                      v N j j j i j i p PF PF PSA block (cid:32) (cid:16) (cid:16) (cid:16)(cid:32) ), 1)( 1(1 , , (21) At this point, we also resort M/G/1/N queuing system to model  the symmetrical multi-channel. The arrival rate of input i is voli/L,  and the expected service time as well as its variance value are  calculated in Eq.22. Similar to the analysis process in Eq.11, we  derive the queuing parameters including (cid:534), (cid:535) and so on.  i 5 j ki , ji , ji , kji , , ki , i 5 j ji , ji , kji , , ki , vol E block L ( Tbody a D ( vol block L ( Tbody a E (cid:166) 3. Performance Analysis Algorithm  (cid:166) (cid:32) 1 (cid:32) 1 (cid:16) (cid:16) (cid:14) (cid:117) (cid:32) (cid:16) (cid:14) (cid:117) (cid:32) 2 )) ( ) 1/( ) )) 1/( ) ( (cid:87) (cid:87) (cid:87) (22) In order to derive the packet latency for each traffic flow, we must  calculate the relevant queuing parameters of every input, such as (cid:534),  (cid:535), (cid:306) and so on. Due to the parameter PFj assumed in Eq.7, the first  step is to obtain the possibility of flow control from downstream  neighbors. In this section, the topology is kept as a grid like 2D  mesh. The dimension-order routing always makes packets follow  the higher dimension first and then move along the lower dimension towards destination. We sort the input ports to be {CL, (CW,  CE), (CN, CS)} by descending the dimensions, and the packets  usually transfer from local input port CL to other ports with lower  dimensions. In other words, the flow controls only come from the  inputs with same or lower dimension at neighbors. Let’s calculate  the queuing system parameters of input ports from the lowest  dimensions, and the pseudo code of our performance analysis  scheme is presented in algorithm 1, which suits for both singlequeue and symmetrical multi-queue routers. For asymmetrical  multi-queue structure, it needs to further calculate the flow control  possibilities of different channels at neighbor in line 16.  Algorithm 1 Calculating Queuing Parameters of Each Input   Input: Array of the inputs Tile[M] [N][5] ; Visited flag of the inputs   visited[M] [N][5] ; DM denotes the array of the directions, where   DM[0] records the direction with lowest dimension, the rest increase   by the dimension; NbSet records the neighbors of current router.  1 void TileTraverse() {  2   InitVisited (visited); // initial visited flags visited[i][j][k] to be false.  3   InitDM (DM);     // sort inputs by the ascending of dimensions.  4   for (k=0;k<5;k++)  5  for (i=0;i<M;i++)  6    for (j=0;j<N;j++)  7      if (!visited[i][j][DM[k] ])  tile[i][j][DM[k] ] .InfoUpdate;  8  }  9  void tile.InfoUpdate() {  10   flowctrl = TrafficCacul (i,j,p); // examining the flow control.  11   if (flowctrl) {  // the set of neighbors sending flow control to the current router.  12    NbSet = choose_neighbor (i, j, p);  13    for (t=0;t<4;t++)  14       if (NbSet[t] .valid = true) {  15   nx =NbSet[t] .x; ny =NbSet[t] .y; ni =NbSet[t] .port;  // Call function CaculFPro to derived the possibility of control flow.  16    nfpro[t] = tile[nx][ny] [ni] .CaculFPro;}  17  } else nfpro[t]=0;  // Calculating the queue parameters of the current input  18    lpro = CaculParam(nfpro);  19    visited (i,j,p) = true;  20    return (lpro);  21 }  22 double tile.CaculFPro() {  23    if (visited(i,j,p)) return (title(i,j,p).lpro);  24     else return (tile(i,j,p).InfoUpdate);   25 }  In this algorithm, line 4 to 7 calculates the queuing parameters  of each input according to the ascending sequence of dimensions.  For each input, function InfoUpdate in line 10 firstly examines  whether the input p of current node <i,j> is affected by flow controls. When there exists the traffic volume towards the input of a  certain neighbor, line 12 to 17 records this neighbor into array  Nbset and calculates its flow control possibility by function  CaculFPro. If the neighbor input has already been visited, the  possibility of flow control is returned immediately, and otherwise  the function InfoUpdate is called recursively to calculate the  queuing parameters of neighbor input. Through analyzing the  queuing system of each input by algorithm 1, we can obtain the  packet latency of any given traffic flow, thereby calculating the  average packet latency of network using Eq.23. The above algorithm needs to travel throughout the inputs according to ascending  order of the dimensions, and thus the complexity of algorithm is  O(MN). By the way, the average number of packets in each input  can also be attained from the M/G/1/N queuing system. As shown  in Eq.24, this information may be used to calculate the buffer utilization which reflects the local congestion of network and provides the sufficient evidences for optimizing or customizing router  structure in design flows.  (cid:166) (cid:166) (cid:166) (cid:166) task i (cid:32) 1 i task j 1 (cid:32) task i (cid:32) 1 task j (cid:32) 1 (cid:32) j i j i j ), map f f t t map LA  map) LA(CG, , , )) ( ( ( (23) N/ kp n utilizatio _ Buffer 1k k(cid:17189) N (cid:32) (cid:32) (24) 4. Experiment Results  4.1 Framework of Analysis Approach  Fig.3 NoC design methodology based on analysis approach  The NoC design methodology based on the proposed performance  analysis approach is illustrated in Fig.3. First, the accuracy of analytical models is validated through comparisons with cycle-based  simulation under various traffic conditions, thereby effectively estimating the key metrics in terms of latency, throughput and buffer utilization. Next, the parameters of components can be adjusted according to the feedback information. At the early stage of  NoCs, since there are a great number of choices on parameters of  each component, the exploration of huge design space by simulation-based approach will become impractical due to time-consuming simulations, and thus our proposed approach is commended to  direct NoC designs. To the best of our knowledge, the proposed  model provides the first analytical approach towards multi-chan2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 567                   nel routers for arbitrary traffic patterns. When the requirement of  network performance cannot be satisfied by single-channel structure, other alternatives of multi-channels are provided to improve  the performance. The advantage of accuracy and high-efficiency  for our approach also suits for the synthesis flows of NoC. With  fast performance feedback in Fig.3, the multi-objective optimizations are performed during NoC mappings of specific applications,  and then the optimum results can be obtained in a short period.  4.2 Accuracy Validation  In this section, a custom cycle-accurate NoC simulator with wormhole flow control is developed in system C to validate the accuracy of our analysis approach. In the experiments, with the packet  overhead of 64 bytes, we adopt the XY deterministic routing and  arrange a 6×6 2D-mesh network by three-cycle routers. Let the  bandwidth and transfer time of link be 128 bits and one cycle respectively. The observed results are obtained by simulating 4×105  cycles after a warmup phase of 4×105 cycles, and then compared  with analysis ones.   In the first phase, the performance of single-channel is analyzed  under different traffic patterns, where any node transfers packets  towards the destinations of a particular set with equal probability,  or few packets are sent to hotspot nodes with higher probability  except for random distribution. During the experiments, our analysis approach only consumes 5.9 seconds averagely when calculating the queuing parameters of all inputs according to algorithm  1, in contrast with 23.7 minutes of the cycle-based simulation. By  altering the traffic patterns, Fig.4 (a) (b) compare the analysis results with observed ones under different destination sets or hotspot possibilities. It can be found that analysis results track the  observed ones closely and achieve the median error of 6.9% with  different traffic rates. Next, another aggressive NoC analysis  method in [7] is also validated in Fig.4 (c) (d). We can see that the  analysis results follow the observed ones only in low rates, but  deviate from the baseline seriously when entering the congestion  regions of network. Especially in the presence of hotspot pattern  with high possibility to hotspots as shown in Fig.4 (d), the analysis results by [7] can hardly reflect the actual trends of packet  latencies. With the same sampled rates, its median error is mea(cid:16) sured to be nearly 16.3%. The analysis by [7] uses the contention  matrix to calculate blocking time according to the packet rates of  channels. Its simple calculation process saves much time to nearly  90 micro-second per solution during our experiments, but brings  inaccurate results due to the lack of detailed modeling on packet  transfers. Moreover, this method assumes infinite buffers for each  port and has not taken account of the effect of flow control. With  the constraints of buffers, the flow control is always produced  towards upstream neighbors to increase the blocking possibilities  of input channels. The analysis in [7] only considers the packet  conflicts among different inputs, thereby resulting in appreciable  errors in high rates.  Another limit in [7] is that it cannot evaluate the performance  of multi-channel which may be preferred in many researches or  industry works. In the second phase, we configure the above simulator to validate the model accuracy of multi-channel structures.  Simulation results in Fig.5 (a) (b) reveal that in the presence of  random pattern, the performance of multi-channels is improved  towards single-channel. The analysis results are slightly less than  observed ones in low rates, but in high rates the analysis results  immediately saturate and exceed the observed ones. With the hotspot pattern, because the packets are destined to specific nodes  with a certain probability, the network of asymmetrical channel is  easy to be saturated as shown in Fig.5 (d). During the analysis  process, the high flow control possibilities around hotspots are  observed so that the throughput of asymmetrical structure can  only achieve 0.42flit/cycle, which is close to the simulation results. To sum up, the analysis of symmetrical and asymmetrical  multi-channels achieve the median errors of 8.1% and 7.4% respectively, but only consume about 10.7s and 9.2s, in contrast with  37 and 32 minutes of the cycle-based simulations.  (a) proposed approach (random)         (b) proposed approach (hotspot)        (c) analysis approach in [7] (random)    (d) analysis approach in [7] (hotspot)   Fig.4 Accuracy validation of the single-channel performance analysis  (a) symm. multi-channel (random)       (b) asymm. multi-channel (random)       (c) symm. multi-channel (hotspot)        (d) asymm. multi-channel (hotspot)    Fig.5 Accuracy validation of the multi-channel performance analysis   568 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers                    4.3 Multi-Channel Comparison  In the NoC scenario, we focus on multi-channel structure when  the requirements for latency and bandwidth cannot be satisfied by  single-channel. Here, the symmetric [15] and asymmetric structures [16-17] as critical building blocks exist two distinct choices  to improve performance, but the existing NoC evaluations to the  best of our knowledge have not performed any quantitative analy-  sis to them. In this section, the latency distributions will be col-  lected to further distinguish them under different traffic patterns.  Fig.6 (a) shows the latency distributions under random pattern.  In the left of histogram, the asymmetric structure outperforms the  symmetric one due to the larger number of packets locating at the  head of asymmetric structure. Here, besides contentions among  different inputs, the conflicts with other channels of the same port  also happen in the symmetric structure and thus result in higher  blocking possibility. After that, with the increasing latency, e.g.  70 or 90 cycles, the symmetric structure offers substantially better  performance than the asymmetric one on the reverse. In the asymmetric structure, the flow imbalance phenomenon produces some  overload channels, and their growing arrival rates increase the  average waiting time of queues so that asymmetric structure often  provides more long-latency packets than symmetric one.  (a)                                                         (b)  Fig.6. Packet latency distributions of different multi-channel structures under random (a) and hotspot (b) traffic patterns.  Next, Fig.6 (b) illustrates the latency distributions under hotspot pattern. With the asymmetrical structure, many traffic flows  addressed to high traffic region lead to the overload of some channels, and then the converse propagations of flow controls with  high possibility always saturate the NoC in advance. For the network of asymmetrical structure, nearly 30 percents of packets  experience longer latency than average one. The packets located  at the tail of asymmetrical structure are the primary results of high  latency, because they transfer through high traffic region of network. In contrast, the distribution of arrival packets among different channels in symmetrical structure has eliminated many highload channels, and thus its latency histogram is pushed significantly towards left so that most of packets experience less than  80-cycle latency. In addition, the buffer utilization is another key  factor to evaluate them. In random pattern, the average packet  number of channels approximates to 0.11 at the rate of 0.30 flit  /cycle, but when rate reaches 0.41flit/cycle, the waiting packet  number of asymmetrical structure achieves to 0.77, in contrast  with 0.62 of symmetrical one. In hotspot pattern, the waiting  packet number of asymmetrical structure even exceeds 200% of  symmetrical one at the rate of 0.41flit/cycle. In a word, the symmetrical structure is preferred to reduce the buffer budget.  4.4 Application Mapping and Case Study  The above analysis approach could be applied to direct the application task graph mapping. Following the methodology in Fig.3,  the proposed approach is integrated into NoC synthesis flow to  search for the best mappings. In order to speedup the exploration  phase, we consider some heuristic-based or evolutionary-based  techniques in [10] [11], where the poor accuracy or low efficiency  of performance evaluation made them difficult to achieve global  optimization within a certain period. In this section, we try to address the multi-objective optimization problem, thereby improving  NoCs performance and saving power consumption. The multiobjective optimization criteria considering both average latency  and communication volume is adopted, where the power consumption is minimized by minimizing the cumulative traffic volume  through all the ports [18]. Given application task graph, the communication volume of a particular mapping is defined in Eq.25,  where function dist indicates the distance between task ti and tj.   task i 1 task j (cid:32) 1 (cid:117) f i , j j ) ( ( t i ), ( t )) ( G , dist map map map Com (cid:32) (cid:166) (cid:166)(cid:32) (25) Some media applications [6] are selected to be mapped to 4×4  mesh for instance. Fig.7 (a) illustrates their task graph where each  circle denotes individual task and each directed edge indicates  communication volume proportion. Here, we choose NSGA-II  algorithm[19] to speedup optimization as follows. Each individual  represents a mapping scheme and every gene records the task id  chosen for a particular node. Initially, with a random parent population P1 of size N, a fast sorting approach sorts the population  based on nondomination. Here, the individual members from better nondominated sets Fi in the order of ranking are firstly chosen  for the next population Pi+1, then we sort the members of last set  Fl by crowded-comparison operation and select the first N-(|F1|  +…+|Fl-1|) ones of Fl to fill the population slots of Pi+1. We use  crossover and mutation methods on Pi+1 to generate new population Qi+1, and then the combined population Pi+1(cid:292)Qi+1 is continued to produce the next population Pi+2 with the same method. In  order to generate optimal mapping, we select the solutions in the  first non-dominated set F1 when no appreciable improvement is  achieved or the evolution algorithm runs for a certain period.   Fig.7. Results of NSGA-II multi-object optimization along with Simulation, MD and proposed analysis approach.  In the experiments, we consider NSGA-II evolutionary algorithm with crossover probability 0.98 and mutation probability 0.01.  To observe the effect of our analysis approach, the simulation  approach [10] and Manhattan distance [11] are also integrated into  our synthesis flow to measure packet latencies, and Fig.7 demonstrates the simulation results of Pareto mappings derived from  multi-object optimization with different approaches. By simulation approach, the search process does not come into convergence  within 24 hours due to its low efficiency, and only achieves poor  results, e.g. Pareto-1 and Pareto-4, whose average latencies are  28.9 cycles and 23.7 cycles respectively as shown in Fig.7. On the  other hand, if Manhattan distance is directly adopted, we can  converge to best solutions rapidly. However, Manhattan distance  approach is used to ignore the blocking situations in high rates,  and thus we observe that Pareto-3 as one of its nondominated  2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 569          solutions corresponds to low communication volume but at the  expense of high latency. With our analysis approach, it only consumes about 74 minutes by exploring 700 mappings to obtain best  results. In both aspects of average latencies and communication  volume, Pareto-2 and Pareto-5 perform better than other results  derived from simulation approach or Manhattan distance. For example, Pareto-5 reduces average latency and communication cost  by 50.1% and 31.7% respectively compared with Pareto-1 result.  In order to validate the accuracy of our analysis approach, we also  prune the design space by selecting the best 200 mappings from  NSGA-II algorithm and then perform the detailed simulations on  them. According to simulation results, 4 best mappings in the first  nondominated set from NSGA-II algorithm along with our analytical approach include 3 of 4 best mappings picked by simulation.  One best mapping through cycle-based simulation corresponds to  similar latency and communication cost with Pareto-5 in Fig. 7.  (a)                                                            (b)  Fig.8. Multimedia task graph and optimized mapping results.  The optimized mapping through NSGA-II algorithm along with  our approach is shown in Fig.8(b), where performance bottlenecks  denoted by red boxes have restricted the latency proportion and  saturated throughput to be about 184% and 12.2 GB/s respectively.  Considering the local input of v12, the blockings of traffic flow  addressed to v7 decrease the mean service rate and then the amount of communication addressed towards node v13 increases the  arrival rate rapidly. With the increasing of service strength (cid:545), this  input overflows at first so that the throughput is saturated in advance. Meanwhile, the contentions at south input of v16 generate  flow controls to v15, and thus the decreasing service rate at south  input of v15 increases the latency from v14 to v15 in the end.   In this context, we consider the analytical model of symmetrical multi-channel to improve NoC performance. In multi-channel  scenario in Fig.9, we also observe that the multi-objective optimization effects by our analysis approach have also achieved a great  improvement compared with simulation approach because of its  high-efficiency. According to the results of our queuing system,  multiple channels have decreased the mean arrival rates of local  channel at v12, and thus the saturated throughput increases to 15.5  GB/s. Then, considering the same traffic rates, we find the latency  proportion drops to 152% due to the elimination of many HoL  blockings. The same cycle-based simulation is performed on 200  best mappings. Although the optimal mapping by simulation is  slightly different from the one derived from NSGA-II along with  our proposed approach, the differences of latency and saturated  throughput are merely 1.5% and 1.9%.  5. Conclusions  We have presented a novel performance analysis approach for  wormhole switching NoCs. The M/G/1/N queuing models of generic routers are developed to analyze the packet blocking phenomenon and the performance analysis algorithm is presented to  estimate the queuing parameters of each node. Towards the single-channel and multi-channel structures, the mean latency errors  of our approach are 6.9% and 7.8% respectively while the estimate efficiencies have been improved by 240 and 210 times compared to simulation-based method. Our proposed approach can  direct the NoC synthesis effectively, including the evaluation of  different multi-channel structures. Furthermore, it can also be  applied to the multi-objective optimizations to improve network  performance and reduce communication volume.  Fig.9. Multi-objective Optimization Effect of Multi-channel Structure.  Acknowledgment  This work is supported by National Basic Research Program  (2007CB310901), Natural Science Foundation (60903039, 6087  3015), and National 863 Program (2007AA01Z101), Program for  Changjiang Scholars and Innovative Research Team in University.  "
2009,A performance analytical model for Network-on-Chip with constant service time routers.,"Performance models for network-on-chip (NoC) are essential for design, optimization and quality of service (QoS) assurance. Classical queueing theory has been often used to provide fast analytical models to estimate average performance. This paper presents a new analytical model that focuses on QoS assurance. It assumes that the NoC has an underlying synchronous behavior with constant service time routers. The comparisons with simulation results show a tangible improvement with regard to the classical M/D/1 models when estimating the worst-case latencies and queue delays. The model can be applied to any network modeled as a queueing system with constant-time routers.","A performance analytical model for Network-on-Chip with constant service time routers Nikita Nikitin Univ. Politècnica de Catalunya Barcelona, Spain nnikitin@lsi.upc.edu Jordi Cor tadella Univ. Politècnica de Catalunya Barcelona, Spain jordicf@lsi.upc.edu ABSTRACT Performance models for Network-on-Chip (NoC) are essential for design, optimization and Quality of Service (QoS) assurance. Classical queueing theory has been often used to provide fast analytical models to estimate average performance. This paper presents a new analytical model that focuses on QoS assurance. It assumes that the NoC has an underlying synchronous behavior with constant service time routers. The comparisons with simulation results show a tangible improvement with regard to the classical M/D/1 models when estimating the worst-case latencies and queue delays. The model can be applied to any network modeled as a queueing system with constant-time routers. 1. INTRODUCTION 1.1 Network-on-Chip modeling The rapid advance of VLSI technology demands eﬃcient and scalable methods for the design of complex systems. In this context it is essential to have tools that can eﬀectively estimate the cost of a system and enable a broad design space exploration. Performance is one of the crucial parameters in design. Simulators are commonly used to estimate the performance of complex systems when the analytical models are too abstract and distant from reality. However, simulators are very time consuming and not scalable. Nowadays, complexity is handled by designing modular and scalable systems. The concepts of System-on-Chip (SoC) and Network-on-Chip (NoC) [3, 8] are often used to denote systems that are fully integrated on a chip through interconnect networks that can serve the communication demands among the diﬀerent components of the system. NoC provides a trade-oﬀ in terms of area and power when compared to the traditional bus or peer-to-peer connections. At the same time NoC requires a thorough design process including topology selection and mapping, link planning, routing, buﬀer allocation and various optimization tasks. The automation approaches for NoC design aim at optimizing Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, or republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.  ICCAD’09, November 2–5, 2009, San Jose, California, USA.  Copyright 2009 ACM 978-1-60558-800-1/09/11...$10.00.  the cost of the solution (generally power, area or traﬃc distribution) under a set of quality-of-service (QoS) and capacity constraints. Many of the design tasks can be eﬃciently solved through iterative optimization processes that enable to change the design solution in case some of the constraints are violated. For guaranteeing the QoS constraints of an NoC, an accurate delay estimation of the transit time of the packages is required. The most common strategy is the use of simulation tools for delay estimation. While simulation provides highly accurate estimations, it is a very time consuming process that can hardly be used during the iterative exploration phase of the design. For this reason, various analytical models have been proposed as an alternative to replace simulation with eﬃcient and reasonably accurate estimations. The basic method of delay estimation by hop-count does not consider the contention latency at the input queues of the routers. This latency has a tangible impact in the transit time for medium and high traﬃc loads. The analytical models for NoC are aimed at predicting the contention delays. They can be classiﬁed into two groups: the probabilistic models and the ones based on queueing theory (QT) [6]. An example of probabilistic model can be found in [7]. In this work we focus on the QT methods for NoC delay modeling. An important aspect of NoC design is that most of the onchip interconnect networks are synchronous. An NoC can be represented by a system of synchronous routers with input queues (FIFOs) (see Fig. 1). When the packet length in the network is ﬁxed, the service times of the routers are equal to a constant value. Thus a network can be modeled as a constant service time system. With this assumption, it is convenient that the models for NoC are suitable for discrete time analysis. 1.2 Previous work The general approach for network modeling using QT considers that a router is a single server in which the input buﬀers are treated as queues. To calculate the transit time of a packet in the network with suﬃcient accuracy, the waiting time in the input buﬀers must be calculated and added to the hop-count delay. In this work we use one of the common routing schemes: the wormhole routing [2]. Multiple analytical models have been proposed for wormhole routers, but most of them are based on the standard M/G/1 and M/M/1 models. In [9], an analytical model is presented for wormhole ﬂow considering ﬁnite buﬀers. The model is not restricted to any topology, extends the M/G/1 router representation and assumes Pois571 son processes at the inputs of every router. However, the authors estimate the average packet latency in the network that is not suﬃcient for the QoS design parameters that need to guarantee individual end-to-end delay constraints. Another simpliﬁed M/G/1-based model can be found in [4]. In this case, the Poisson assumption is still required for the router inputs and, thus, the constant service time cannot be considered. In [12] an M/M/1 approximation of link delay is used for the capacity and ﬂow allocation task that can be applied to general networks. Finally, [5] extends the approximation of the M/M/1 model by an empirical estimation for capacity allocation under the assumption of ﬁnite buﬀers. 1.3 Contribution All the previously mentioned approaches use an assumption that is common to all NoC analytical models: the process at every router input has a Poisson distribution. While this is an acceptable assumption for the traﬃc sources (by deﬁnition of the model), it is known that the service times become correlated with the packet length as the packet propagates over the network [1]. According to this fact the distribution of the ﬂow for the intermediate routers changes. To relax this eﬀect, the widely applied Kleinrock independence approximation allows one to treat the input ﬂows at intermediate routers still having Poisson properties. This approximation is reasonable when the packet lengths have a distribution close to exponential so that the packet service times are nearly exponential as well. However, as simulations show in the common situation of ﬁxed packet length, this assumption makes the analytical model too pessimistic predicting too high waiting times. This paper presents a QT-based analytical model for a constant service time network, i.e. a network modeled as a system with constant-time routers. Each router is treated as a QT server that has ﬁxed service time T for the incoming packets. This is a reasonable assumption since we want to model networks with ﬁxed packet lengths. Unlike the other analytical models for NoC, we do not use the Kleinrock approximation. Instead, we present simple and accurate empirical equations to estimate delays at the input buﬀers. Our contribution is an accurate analytical model for constant service time network. It is important to note that the scope of the presented methodology goes beyond NoC design and can be applied to any queueing system with constant-time servers satisfying the same set of assumptions. 1.4 Paper organization The papers starts in Sect. 2 by introducing the problems that the classical QT methods manifest when modeling networks with constant-time routers. We illustrate our observations with a simple example. An explanation about how to adjust the model is presented. Section 3 presents the main contribution of the paper, starting with a simple 2-input router and generalizing for n-input routers. The extended equations for estimating the waiting times are also discussed. Section 4 presents a network as a system of constant-time routers. It discusses how to estimate the contention delay at a particular channel as well as the full net delay assuming a wormhole routing strategy. Finally, Sect. 5 compares the accuracy of the analytical model with simulations carried out for a wide range of input PE PE R R R PE PE R R R PE PE R R R PE PE PE Figure 1: 3x3 mesh Network-on-Chip example. λ1 W S 1 S1 W S Figure 2: A simple server chain. parameters. A comparison with the classical M/D/1 model is also performed and discussed. 2. MODEL OVERVIEW Modeling a network as a system of routers requires an approach for calculating packet delays depending on the network topology. An example of a 3x3 mesh network is presented in Figure 1. Each router (R) is connected to a processing element (PE) and a set of neighboring routers by two unidirectional links. In our model we focus on the delay estimation (waiting time) at the input buﬀers. Hence, we assume each router to have an input buﬀer from each neighbor and one from the PE. A net is a end-to-end route in the network, from one PE to another, and can be represented as a sequence of routers that a packet must propagate through. Each router may have an arbitrary number of input channels. Consider the simple example in Fig. 2: a chain of two servers with constant service time T and a Poisson arrival process with rate λ1 . The classical QT model for a constanttime server with Poisson input is the M/D/1 model. The waiting time in the ﬁrst input queue WS1 can be estimated using Pollaczek-Khinchin (P-K) formula [6]: . (1) W = λT 2 2(1 − λT ) However, unlike the systems with exponentially distributed service times, the output from an M/D/1 system is no longer a Poisson process: the time between two consecutive outputs is guaranteed to be greater than or equal to the service time value T . In other words, a constant-time server produces a de-randomization of the Poisson process, thus reducing the degree of randomness of the inter-arrival times, which is the main cause of contention delays at the input queue. While WS1 can be accurately predicted with (1), using 572 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers λ1 λ2 W S 1 W S 2 S1 S2 3. QT MODEL W1 W2 S This section presents the main contribution of this paper: the QT model for constant-time routers. 3.1 Deﬁnitions and assumptions Figure 3: Merging two M/D/1 output ﬂows. the same equation to estimate the waiting time at the input queue of S may result in signiﬁcant errors. More precisely, the waiting time W will be equal to zero as the successive arrivals of packets at S occur not earlier than T , which is exactly the time to process a packet by server S. That means that the incoming packet will never wait for his service. This fact illustrates the inaccuracy of applying (1) for the estimation of the waiting time at server S. In the general case, a router may have an arbitrary number of inputs, including constant-time server output ﬂows. The goal of this work is to derive the equations for an accurate queueing delay estimation, as an alternative to the P-K equation. The qualitative importance of an accurate queueing delay estimation is shown in the following example. Consider now two inputs to server S, each one being an output from the constant service time systems S1 and S2 (Fig. 3). Table 1 reports the estimation of the waiting times W1 and W2 by the M/D/1 model and the constant service time model (CTM) of this paper depending on diﬀerent input rates (λ1 and λ2 ). The total delay at the server for the packets of the ﬁrst ﬂow is D1 = T + W1 , where T is the packet service time (assumed to be 1 cycle for the example). The traﬃc rates of the ﬂows (ﬂits/cycle) are speciﬁed in the ﬁrst two columns of the table. The following three columns show the waiting times and the delay of the ﬁrst ﬂow (in cycles) obtained by the CTM model. Next, the estimations for W1 , W2 and D1 obtained with the M/D/1 model are reported. The column SIM displays the delay of the ﬁrst ﬂow obtained by simulation. Finally, the error of D1 with regard to the simulation is reported in the last two columns. One can easily observe the reduction of waiting times produced by the de-randomization (W1 , W2 of CTM vs those by M/D/1). Another important aspect is that the Poisson-input models assume equal waiting times for all input streams regardless their rate. This is not true in the case of constant service time systems. This results into larger differences in delay estimation (see the diﬀerence between W1 and W2 in the last row of the CTM model). We also note that the diﬀerence between our model and simulation is less than 1% in this example, while M/D/1 reveals up to 36% of overestimation. This simple example shows that proposed CTM approach can provide more accurate estimations. This is essential for QoS optimization. Table 1: Modeling results for the example in Fig. 3. CTM M/D/1 SIM Error λ1 λ2 W1 W2 D1 W1 , W2 D1 D1 CTM M/D/1 0.1 0.1 0.07 0.07 1.07 0.13 1.13 1.07 0.1% 6% 0.3 0.3 0.53 0.53 1.53 0.75 1.75 1.54 0.7% 14% 0.5 0.1 0.29 0.47 1.29 0.75 1.75 1.29 0.3% 36% We use the following deﬁnitions: • A router is a basic entity that routes traﬃc in a network. The router is also referred to as server in the nomenclature of queueing theory. • A packet is a data transmission entity. A packet consists of one or more ﬂits that are the minimum transmission units. • An input ﬂow, also referred to as input process, is an arrival process at one of the router input buﬀers. • A traﬃc source (sink) of the net is a processing element that injects (consumes) packets to (from) the network. • The traﬃc rate λk of the net k is the average rate of packet generation at the net source. • The waiting time at the input buﬀer of a router is the average steady-state time the packets spend in the buﬀer before being processed by the router. In the QT nomenclature it is referred to as a queueing delay at the input queue (buﬀer). The following assumptions are considered: • Traﬃc sources generate packets according to a Poisson distribution. • Traﬃc sinks consume packets immediately. • The input buﬀers of the routers have inﬁnite capacity. • The packets have ﬁxed size and the routers take constant time to process them. 3.2 A simple model for a 2-input router We have already stated an important diﬀerence between a system with exponentially distributed service times and one with constant-time service, assuming a Poisson input to both. The output process from the former is also a Poisson process of the same rate and exponentially distributed interarrival times. Thus we may use (1) for M/M/1 systems to estimate the waiting time for any of the routers. The output ﬂow from a constant service time system with Poisson input has a complex distribution discussed in [10] and [11]. The important property due to its deterministic service time is that the time between two successive outputs is not less than the service time T . Because of this fact, the waiting time for all the routers in a chain will be equal to zero except for the ﬁrst one (Fig. 2). The ﬁrst router delay can be successfully estimated with (1), since the packet generators are said to generate packets according to a Poisson distribution. Consider the two-input server example presented in Fig. 3. All three servers S1, S2 and S, have a constant service time T . Both sources generate packets assuming a Poisson distribution with average traﬃc rates λ1 and λ2 . Our goal is to model the waiting times W1 and W2 at the input queue of the server S. 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 573 For example, note that if the ﬂow λ2 were not sending packets, i.e. λ2 = 0, then W1 would be equal to zero as in the single-input server case. This fact supports the idea that the waiting time W1 is generated by the packets of the complementary ﬂow λ2 and its value depends on the traﬃc rate of both ﬂows. To simplify the analysis, we use the concept of mean residual service time R(λ) for an input ﬂow [1]. If incoming packet Pi arrives at the server queue at time ti while some other packet Pj is being processed by the server, then the residual time Ri for the packet Pi is the time left for Pj to ﬁnish its service. The mean residual service time is an average value of residual times for each packet deﬁned by the service time and the ﬂow traﬃc rate. The following equation represents its steady-state value [1]: 1 2 Using the deﬁnition of residual time, the Pollaczek-Khinchin equation can be rewritten as R(λ) = λT 2 . (2) . = W (λ) = λT 2 R(λ) 2(1 − λT ) 1 − λT We generalize the above expression by distinguishing trafﬁc rates in the P-K formula. Let us consider the traﬃc ﬂow of rate λtr that is merged with some complimentary ﬂow of rate λres at the router input. As our experiments show, the waiting time for the packets of ﬂow λtr will depend on both rates. Then we can rewrite (3) as (3) = . λresT 2 (4) i=1,2 i=1,2 (cid:2) W (λtr , λres ) = R(λres ) 2(1 − λtr T ) 1 − λtr T This generalized waiting time can be treated as that of the traﬃc ﬂow λtr experiencing a delay produced by the complementary ﬂow with rate λres , inducing a residual time R(λres ). Using (4) in combination with the standard M/D/1 equation (3) we propose the following empirical expression that was found to provide an accurate estimation for W1 and W2 : Wk = W (λ1 + λ2 ) − W (λ1 ) − W (λ2 ) + W (λk , λj ) = λi ) − (cid:2) W ( W (λi ) + W (λk , λj ), (5) where k ∈ {1, 2} and j is the complementary ﬂow for k . The form of (5) was suggested intuitively resulting from the numerous experimental observations and was further empirically veriﬁed for a large range of input parameters λi and T . The intuition behind this equation can be explained with the following considerations. Expression (5) has three terms: the ﬁrst one is the M/D/1 waiting time (3) that input packets would observe if both inputs were Poisson processes. The second term is the sum of the M/D/1 waiting times for each separate ﬂow. It can be considered as the measure of “de-randomization” introduced by the source constant-time router. In fact this is the waiting time packets of each input process spend at the source router. The last term estimates the impact of the complementary inputs on the k-th input, similarly as it was discussed in (4). An important fact that is not evident and not observed in M/D/1 systems modeling is that the waiting time for the input ﬂows diﬀers when the traﬃc rates are not equal. This phenomenon is also proved by simulation. When two ﬂows interact at the router input, the packets of the ﬂow with greater traﬃc rate have less average input delay. Indeed, if a packet belongs to the ﬂow with the smallest rate it has greater probability to be blocked by a packet of the complementary ﬂow. As a result, in average its waiting time will be greater than that of the packet of complementary ﬂow. An illustration of this fact is presented in Fig. 4. The traﬃc rate ratio λ1 /λ2 ranges from 1 to 10 while their sum is kept constant (λ1 + λ2 = 0.4 ﬂits/cycle). The waiting time W1 , W2 estimations by both models are depicted. One can observe the increasing diﬀerence between W1 and W2 estimated by the CTM model as the rate ratio increases. In contrast, the M/D/1 model provides a pessimistic constant waiting time for both ﬂows that does not depend on the ratio of traﬃc rates. 3.3 Generalization for an N-input router Equation (5) can be generalized for an arbitrary number of inputs N > 2. The waiting time W N k at input k can be calculated as N(cid:2) W N k = W ( λi ) − N(cid:2) i=1 i=1 W (λi ) + W (λk , N(cid:2) i=1,i(cid:2)=k λi ) (6) It is also valuable to notice that this equation holds for the case of one input ﬂow (N = 1). In this case we get W 1 1 = 0 that stands in correspondence with zero delay at all routers in a chain, except for the ﬁrst one. 3.4 Hybrid process at the router input Another important case to consider when modeling a network is a hybrid input process consisting of Poisson ﬂows and constant-time router outputs. It is necessary for modeling the traﬃc coming from two diﬀerent sources: the Poisson processes from the PE’s and the traﬃc coming from constant-time routers. We start again considering a simple two-input server example where one net is an M/D/1 output and another is a Poisson source (Fig. 5). W1 (CTM) W2 (CTM) W1, W2 (M/D/1) 3 2.5 2 1.5 1 0.5 ) l s e c y c ( e m i t g n i t i a W 0 0 2 4 6 Traffic rates ratio 8 10 Figure 4: Estimated waiting time for diﬀerent traﬃc rates ratio. 574 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers     Combining (2), (3) and (4) we obtain the following expressions: W1 = W (λ1 + λ2 ) − W (λ1 ) − R(λ2 ) + W (λ1 , λ2 ), W2 = W (λ1 + λ2 ) − W (λ1 ) + R(λ1 ). (7) (8) This result can be extended to the general case presented in Fig. 6. Consider a complex arrival process at the input queue of server S: an arbitrary number d of M/D/1 output ﬂows (λ1 , .. , λd ) and p Poisson ﬂows (λd+1 , .. , λd+p ). Let us denote the set of all M/D/1 outputs as D and set of all Poisson sources as P . Let also N = d + p be the total number of inputs. As the sum of Poisson processes with rates λk , k = d + 1, .. , d + p is also a Poisson process of the total rate λp = k=d+1 λi , we can treat the source ﬂows as a single input with the total rate λp . This results into packets of all the ﬂows in P experiencing equal waiting time. Finally we present the generalized equations for the waitk estimation. For any input ﬂow λk ∈ D ing time W N λi ) − (cid:2) W (λi ) − W N k,k∈D = W ( (cid:3)d+p N(cid:2) i=1 i∈D (cid:2) i∈P N(cid:2) (9) N(cid:2) λi ), i=1,i(cid:2)=k R(λi ) + W (λk , and for any Poisson input ﬂow λk ∈ P λi ) − (cid:2) W N k,k∈P = W ( W (λi ) + R(λi ). (10) We note that in case P = ∅, equation (9) reduces to (6), thus demonstrating that (9) is the generalized case of the case of pure Poisson input ﬂows, i.e. D = ∅, equation (10) server not having traﬃc source inputs. Also note that in is reduced to (cid:2) i∈D i∈D i=1 N(cid:2) W N k,k∈P = W ( i=1 λi ), (11) that is exactly the waiting time expression for the M/D/1 system. Thus, our equations are consistent with the M/D/1 model and provide a simple and accurate extension for the hybrid case of input processes. Another interesting fact is that we can apply (10) for waiting time estimation at the sources of the nets and at any point in which the input traﬃc can be modeled by a pure Poisson process estimated by the Pollaczek-Khinchin formula (1). We are using the pair (9)-(10) to predict contention delays at the input buﬀers of the network routers and build our delay model around them. As we show in the experimental section of the paper these equations allow accurate estimations for a wide range of input model parameters. 4. NETWORK MODEL 4.1 Router model abstraction We represent a network as a system of connected routers. Given the single router model presented in the previous secW S 1 λ1 S1 λ2 W1 W2 S Figure 5: Merging an M/D/1 output and a Poisson ﬂow. λ1 … λd W S 1 W S d S1 Sd λd+1 … λd+p W i S Figure 6: Hybrid input process at a constant-time router. tion, we now use it to model the behavior of a network. We use the router model under the following assumptions: • The router is regarded as a black-box with constant service time for incoming packets and inﬁnite capacity buﬀers. • The router can only transmit one packet at a time. Simultaneous packet transmission is not considered. • The strategy of processing inputs in order may vary. We discuss it in the experimental section. 4.2 Extension of the model for a network As we have already discussed, (9) and (10) provide the waiting time estimation at the input of an arbitrary router depending on the network topology and traﬃc rates at the inputs. The traﬃc process in a network is a complex process that is the result of merging and splitting the traﬃc ﬂows of individual nets. In this paper we address the waiting time estimation at the input buﬀers in case of merging N ﬂows at the router input but we do not discuss the split process. However, as will be shown in the experimental section, by only considering merging processes we already obtain a signiﬁcant accuracy in the estimation. An important feature of a Poisson process served by a constant-time router is that it accumulates “de-randomization” introduced by the latter. Formally, let us consider N processes that have constant-time outputs, each one having some traﬃc rate λi . Once these processes have been merged at the constant-time router they become a single constanttime output process with the rate λ = i=1 λi that satisﬁes (9)-(10). We represent this fact in Fig. 7. Here two ﬂows λ1 and λ2 that are M/D/1 outputs merge at router S to form a single ﬂow at its output. We use (9) to estimate the waiting times at router S. Now the new ﬂow travels to the router S’, (cid:3)N 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 575 where it merges with the ﬂow λ3 . In order to estimate the waiting times at router S’, we apply (9) again assuming two input ﬂows with rates λ = λ1 + λ2 and λ3 . This fact basically says that the waiting time of a constant service time system output process does not depend on the way it propagates in the network but only on the traﬃc rate at a particular router. As a result, we do not require information about the ﬂow propagation and are able to calculate delays at each router independently. Below we show how independent router delays are joined to form the end-to-end delay of each net. 4.3 Net delay estimation for wormhole routing The estimation of the full delay for a particular net is performed based on the wormhole routing strategy. In wormhole routing, a packet is transmitted by processing the request of its ﬁrst ﬂit, also referred to as a header ﬂit. The header ﬂit notiﬁes the router to be served as soon as it arrives at the router input queue. Once the router has granted the connection to the header ﬂit, the rest of the packet ﬂits follow in a pipeline manner. To introduce the equation for the delay we use following nomenclature: • The routing path Pi of a net i is the sequence of routers traversed by the packets of this net, from source to destination routers (including both). • The packet size S represents the number of ﬂits in a packet. The packet size includes the header ﬂit and is a constant value for all packets in our model. • The header service time H S denotes the time necessary for the router to grant a connection, i.e. ﬁnd the appropriate output channel and establish the connection. H S does not include the waiting time at the queue. • The ﬂit transmission time F T is the time necessary to transmit one ﬂit that is not a header in a pipeline manner. In our model we assume F T = 1 cycle. • The end-to-end average packet delay Di of a net i is the average time the packets of the net spend in the network, starting from the injection at source router and exiting at the output of the destination router. • The average waiting time Wij at router j ∈ Pi of the packets of net i is the waiting time the packet header spends in the router queue before being processed. The end-to-end net delay model for wormhole routing that we use incorporates two terms. The ﬁrst term depends on the topology and geometrical distance between the net endpoints, thus it can be predicted statically. It is usually referred to as a hop-count delay Dhc i of net i. As follows from the wormhole routing strategy, the hop-count delay consists of the time to propagate header (H S ) and the time necessary for the rest of packet ﬂits to reach the destination router: H S + F T (S − 1) i = Dhc (12) (cid:2) j∈Pi The second term of the net delay is the contention delay Dc i , that is the sum of the input buﬀer delays Wij over all routers in the path Pi : λ1 λ2 W S 1 W S 2 S1 S2 λ3 W1 W2 S λ1 + λ2 W12’ W3’ S’ S3 W S 3 Figure 7: Successive ﬂow merge. Dc i = (cid:2) j∈Pi Wij (13) The contention delay occurs when several input packets compete for the same router outputs. It is estimated with the model we present in Sect. 3. Hence, the full end-to-end delay of net i is deﬁned by the following expression: Di = Dhc i + Dc i = (cid:2) j∈Pi (H S + Wij ) + F T (S − 1) (14) Finally we use (14) to calculate the end-to-end delay of every net assuming that (9)-(10) provide the waiting times Wij . The constants H S , F T and S are the input parameters. According to the wormhole strategy, the packet router service time T used in the calculation of Wij is the sum of the header service time and the propagation time for the remaining ﬂits. Formally, T is deﬁned as: T = H S + F T (S − 1). (15) 5. EXPERIMENTAL RESULTS Traﬃc ﬂows in a network are complex ﬂows that can be described as a system of merging and splitting processes at every router. The delays experienced by every input also depend on the priority scheme of the merging inputs. As it was discussed, the equations (9)-(10) provide an estimation of the waiting time in the input buﬀers of constant-time router assuming a ﬁrst-come, ﬁrst-served (FCFS) scheme of merging the arrival processes at the router inputs. In this section we ﬁrst show the accuracy of our equations by analyzing networks characterized by the merge of processes. We present an experimental proof of the fact that our equations are capable of estimating the delay within a wide range of input parameters such as network load and packet size. Then we also compare our model with M/D/1 for diﬀerent priority schemes at the router inputs, namely round-robin (RR) and longest queue (LQ). LQ stands for prioritizing service of the input with the largest number of ﬂits in the buﬀer. Finally we apply (9)-(10) to model arbitrary networks and show that our equations provide a signiﬁcant improvement in the estimation of end-to-end delays, even without a detailed analysis of network ﬂow splitting. An important fact about the experiments is that we investigate worst-case delay errors over the network, i.e. the largest error estimating the net (buﬀer) delays from all nets 576 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers (buﬀers) in the network. Many of the models suggested so far only estimate average net delays. This is not suitable for QoS evaluation with end-to-end delay constraints. We compare our CTM model and the classical M/D/1 model with the simulations performed by an accurate ﬂitlevel simulator written in C++. Even though we use mesh topologies in the experiments, our methodology is applicable to any type of network since the delay estimation is independent from the network topology (discussed in Sect. 4). The simulations on meshes are performed to simplify the benchmark suite and the architecture of the simulator. 5.1 Single-output router networks This is a special type of networks we use to emphasize the accuracy of our model for constant service time networks. As the pair (9)-(10) provides delay estimation for a merging process, we ﬁrst focus our analysis on this type of networks to avoid splitting at the output of the router, i.e. every router sends packets only to one direction. We start with a 3x3 mesh network with uniformly distributed traﬃc and FCFS priority scheme. In this experiment we measure the deviations between the net and buﬀer delay values obtained by simulation and estimation by CTM and M/D/1 models. We show the modeling error dependency on the maximum router utilization (ﬂits/cycle) determined by the network load. 5.1.1 Packet size variations Varying the packet size from 1 to 100 ﬂits and the router utilization from 0.10 to 0.90 ﬂits/cycle, we note that the CTM worst-case error does not exceed 0.25% for net delays and 2% for buﬀer delays, while the errors produced by the M/D/1 model are 9% for net delays and almost 100% for buﬀer delays. In the other experiments we ﬁx packet size to 5 ﬂits per packet. 5.1.2 Changing priority schemes Although our experiments assume a FCFS priority scheme for the router inputs, we show that it can also be a good approximation for other schemes such as RR and LQ. Table 2 presents the relative errors of the worst-case estimation of net and buﬀer delays versus simulation at diﬀerent traﬃc loads. The ﬁrst two columns of the table represent the utilization and the priority scheme. The values in the other columns report the errors between the estimated (Dest ) and simulated (Dsim ) delays, calculated as Table 2: Relative delay error between simulation and analytical models for a 3x3 single-output network. Utilization (ﬂits/cycle) 0.10 0.42 0.84 Priority CTM error (%) M/D/1 error (%) scheme net buﬀer net buﬀer FCFS 0.06 1.67 1.39 95.46 RR 0.05 2.55 1.39 94.22 LQ 0.05 2.58 1.41 95.29 FCFS 0.07 0.76 4.94 75.88 RR 0.29 6.12 5.21 86.18 LQ 0.66 5.24 5.49 84.63 FCFS 0.22 0.60 4.93 57.19 RR 15.48 32.38 19.19 72.19 LQ 12.85 20.80 13.30 68.18 E rr = |Dsim − Dest | Dsim · 100%. (16) The third and fourth columns represent the worst-case errors of the net and buﬀers delays estimated by the CTM model with respect to simulation. The last two columns are the errors of the M/D/1 estimation. One can see a significant improvement in the accuracy of CTM model against the classical M/D/1 model assuming low and medium trafﬁc loads (utilizations). At high loads, the FCFS scheme still provides a high accuracy. For the other schemes, the gap between CTM and M/D/1 tends to reduce. 5.1.3 Non-uniform trafﬁc In this experiment (Table 3), we change the traﬃc distribution to be highly non-uniform. We observe that the M/D/1 model provides an overly pessimistic estimation of the delays for a medium traﬃc load. On the other hand, the CTM model still provides an accurate estimation for the FCFS scheme. The diﬀerence between the CTM and M/D/1 models increases for all priority schemes. Hence, the CTM model is more accurate for the delay estimation assuming a nonuniform traﬃc distribution. 5.2 General networks In this section, we present results for two general networks without the single-output router assumption. Although our model does not consider the splitting of the traﬃc ﬂows, its application improves the delay estimation in comparison with the M/D/1 model, even for general networks with arbitrary conﬁguration. Table 4 represents the results for 3x4 mesh with highly communicating central nodes. The conclusions for this experiment are similar to those for the previous experiments. The relative error is sometimes reduced by several tens of percent. Table 3: Relative delay error between simulation and analytical models for a 3x3 network with nonuniform traﬃc. Utilization (ﬂits/cycle) 0.42 Priority CTM error (%) M/D/1 error (%) scheme net buﬀer net buﬀer FCFS 0.41 1.19 19.91 102.54 RR 5.38 18.45 21.08 105.31 LQ 13.40 37.45 23.45 148.34 Table 4: Relative delay error between simulation and modeling for a 3x4 network with highly communicating central nodes. Utilization (ﬂits/cycle) 0.12 0.50 0.75 Priority CTM error (%) M/D/1 error (%) scheme net buﬀer net buﬀer FCFS 0.34 19.02 1.97 99.92 RR 0.58 27.96 2.23 114.94 LQ 0.68 25.86 2.25 111.41 FCFS 2.01 14.15 7.05 71.41 RR 5.75 34.89 9.39 85.60 LQ 3.93 31.21 8.83 84.74 FCFS 4.60 20.07 10.02 68.64 RR 23.63 68.78 27.71 89.77 LQ 11.71 45.58 15.22 86.50 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 577 The buﬀer delay estimation improvement reaches up to several times in absolute value, while the net delay mainly determined by the hop count at low and medium loads improves up to several tens of percent. This is a signiﬁcant result for designs that have QoS constraints for end-to-end latencies. 6. CONCLUSIONS We have addressed the problem of modeling constant service time systems via queueing theory. A novel performance analytical model for Network-on-Chip has been presented. Unlike the classical approaches based on the M/D/1 model, the new method eliminates the Poisson assumption for packet distributions at the intermediate routers. It provides an accurate empirical model to estimate the input queue contention delays. The relevance of the model is emphasized by the capability to be used as a simple and accurate approximation of the queueing delay for constanttime routers, which is a realistic assumption for synchronous systems. Adjusting the NoC model with these expressions provides a tangible accuracy increase within a wide range of traﬃc loads. The suggested methodology can be applied to any network modeled as a system of constant-time routers. 7. "
2009,A method for calculating hard QoS guarantees for Networks-on-Chip.,"Many Networks-on-Chip (NoC) applications exhibit one or more critical traffic flows that require hard Quality of Service (QoS). Guaranteeing bandwidth and latency for such real time flows is crucial. In this paper, we present novel methods to efficiently calculate worst-case bandwidth and latency bounds and thereby provide hard QoS guarantees. Importantly, the proposed methods apply even to best-effort NoC architectures, with no extra hardware dedicated to QoS support. By applying our methods to several realistic NoC designs, we show substantial improvements (on average, more than 30% in bandwidth and 50% in latency) in bound tightness with respect to existing approaches.","A Method for Calculating Hard QoS Guarantees for  Networks-on-Chip  Dara Rahmati*, Srinivasan Murali¥§, Luca Benini‡, Federico Angiolini¥§,    Giovanni De Micheli§, Hamid Sarbazi-Azad*   *HPCAN, Sharif University of Technology, Tehran, Iran, {d_rahmati@ce.sharif .edu, azad@sharif .edu}  ¥iNoCs Sarl, {murali, angiolini}@inocs.com  §LSI, EPFL, Lausanne, Switzerland, giovanni.dem icheli@epf l.ch  ‡DEIS, University of Bologna, Bologna, Italy, luca.benini@unibo.it  ABSTRACT Many Networks-on-Chip (NoC) applications exhibit one or  more critical traffic flows that require hard Quality of Service  (QoS). Guaranteeing bandwidth and latency for such real time  flows is crucial. In this paper, we present novel methods to  efficiently calculate worst-case bandwidth and latency bounds  and thereby provide hard QoS guarantees. Importantly, the  proposed methods apply even to best-effort NoC architectures,  with no extra hardware dedicated to QoS support. By applying  our methods to several realistic NoC designs, we show  substantial improvements (on average, more than 30% in  bandwidth and 50% in latency) in bound tightness with respect  to existing approaches.1 Categories and Subject Descriptors B.4.3 [Hardware]: Interconnections (Subsystems)  C.1.2 [Processor Architectures]: Multiple Data Streaming Architecture  (MultiProcessor) – Interconnection Architectures  General Terms Algorithms, Performance and Design.  Keywords  SoC, NoC, QoS, Wormhole switching, Real-time guarantees, Performance  analytical model.   1. INTRODUCTION  The Networks-on-Chip [1, 2] paradigm has emerged in recent  years to overcome the scalability limitations of point-to-point  signal wires, shared buses or segmented buses [1, 3], which do  not scale well in power, performance and design complexity [4,  5, 6].  While the scalability and efficiency advantages of NoCs  have been demonstrated in many occasions, their timing  predictability and suitability  to  transport real-time (RT)  communication are still a source of technical concern.  Many applications have strict requirements on latency and  bandwidth of on-chip communication, which are often  expressed as real-time constraints on inter-core traffic flows.   Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, or republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.  ICCAD’09, November 2–5, 2009, San Jose, California, USA. Copyright 2009 ACM 978-1-60558-800-1/09/11...$10.00.  On a NoC fabric this translates to guaranteed QoS requirements  for packet delivery.  Different approaches have been used to  support guaranteed QoS for NoCs:  priority-based switching  schemes [7], time-triggered communication [8], time-division multiple-access [9] and many variations of these ideas. All  these approaches imply hardware overhead and often come with  strict service disciplines that limit NoC flexibility and penalize  average performance to provide worst-case guarantees.  In fact,  NoCs prototypes are often classified as being either best-effort  or QoS, depending on the availability of hardware support for  RT traffic.   Our work takes a new viewpoint. We consider best-effort NoC  architectures without special HW support for QoS traffic. We  only assume that the traffic injected by network end-nodes is  known and characterized in terms of its worst-case behavior.  We then formulate algorithms to find conservative latency and  bandwidth bounds on end-to-end traffic flows transported by a  best-effort wormhole NoC fabric with no special hardware  support for RT traffic. Our approach is inspired by the work by  Lee et al. [10] for traditional multiprocessor networks, which  we extend in several directions.   We propose two different methods for characterizing worst-case  packet injection. The first method, RTB-HB (Real-Time Bound  for High-Bandwidth traffic), is used for NoCs supporting  application workloads where the injected flows have high  demands of average bandwidth and require a guaranteed worsttraffic minimum bandwidth (mBW) and maximum upper bound  latency (UB). In this case we do not assume any restriction on  traffic injection rate: a flow can send packets whenever the  network has buffer capacity to accept them. The second method  considers applications with latency-critical flows which require  low and guaranteed UB values, but have moderate bandwidth  requirements and do not send packets at intervals shorter than a  minimum permitted interval - which obviously implies a  maximum bandwidth (MBW) limitation. This method, called  RTB-LL (Real-Time Bound for Low-Latency traffic) requires a  very simple traffic regulation at network injection points. RTBLL is a significant improvement to the WCFC bound proposed  in [10], while RBT-HB is completely new. Table 1 summarizes  a cross-comparison of  RTB-HB, RTB-LL and WCFC methods.   1This work has been financially supported partly by EU ARTIST-DESIGN  and Predator projects and also partly by Iran Telecommunication Research  Center (ITRC), an affiliation of the Ministry of Communications and  Information Technology.  579 Table 1: Upper bound delay and bandwidth comparison in different methods Methods RTB-HB (HB) RTB-LL (LL) WCFC (W) UBHB ≤ UBW mBWHB ≥ MBWW UBLL ≤ UBW MBWLL ≥ MBWW RTB-LL (LL) UBHB ≥ UBLL mBWHB ≤ MBWLL The remainder of the paper is organized as follows. Section 2 summarizes related work. Section 3 gives definitions and basic concepts. Section 4 describes methods RTB-HB and RTB-LL. Section 5 focuses on experimental results and quantitative comparisons. Section 6 describes the time complexity of the methods. Finally, section 7 concludes the paper. 2. RELATED WORK The body of knowledge on macro-scale RT networks is extensive and an overview of the state-of-the-art is beyond the scope of this work. The interested reader is referred to [11 20]. Here we focus on RT-NoCs, which have often been called QoS-NoCs. QoS is an important issue for many application domains, such as multimedia, aerospace and military applications. Many of these applications have one or more traffic flows that have real time requirements and need hard QoS guarantees. Some NoC architectures provide hard QoS support by using special hardware mechanisms. In [9], Goossens et. al present the Æthereal NoC, which combines guaranteed services with best effort services to guarantee QoS in NoCs. The MARS [21] architecture uses TDMA (Time division multiplexing) mechanism to provide real-time guarantees on packet switched networks. In Shi et. al [7], a priority-based wormhole switching method for scheduling of RT flows is presented. In [8], Paukovits et. al propose the concept of a predictable TimeTriggered Network-on-Chip (TTNoC) that realizes QoS based communication services. Many other works have been published with variations and improvements over these basic ideas [22-33]. However, most NoC architectures are best-effort [34] and do not have special hardware mechanisms to guarantee QoS. Today, there is no available method that can calculate worst-case bandwidth and delay values of a general best-effort NoC design. Our work addresses this open issue. 3. NETWORK MODEL A router model is essential to characterize network latency and bandwidth. We consider the very general reference architecture shown in Fig. 1 where a crossbar handles the connections among input and output channels. For maximum generality, we consider buffering at input and (optionally) output ports. We assume round-robin arbitration in the switches, a commonly used arbitration scheme in many NoCs. Virtual channels can be supported by the proposed methods. Links, which can be pipelined to maximize the operating frequency, connect the output ports to the input ports of adjacent switches. Table 2 summarizes the parameters that we will use in the following to describe the network. For the sake of simplicity, we use a single parameter Freq for the operating frequency of all cores and a single FlitWidth as the data width of the NoC links. Table 2: Network model parameters and symbols Parameter Description Freq Clock frequency of the system a Number of pipeline stages (registers) used to segment NoC links b1 Depth of switch input buffers b2 Number of pipeline stages of the switch crossbar (0 if combinational) b3 Depth of switch output buffers (0 if none) b := b1+b2+b3 Bd Buffer depth parameter, := a+b1+b2+b3 = a+b ts1 Latency overhead for injecting a packet into the network ts2 Latency overhead for ejecting a packet at the destination FlitWidth Width of NoC links, in bytes SWj j-th switch of the network The buffer depth (Bd) parameter will be used frequently in the paper. As can be seen in Fig. 1, Bd is the summation of the number of registers or buffers from the arbitration point (at the entry of the crossbar) of switch j to the arbitration point of switch j+1. b1 is the depth of the input buffer (we assume at least one register), b2 is the number of registers in crossbar switch (if any), b3 is the depth of the output buffer (if any), and a is the number of registers (if any) along a link to compensate the propagation delay of the wires. It is important to note that b2 and a represent latencies that packets will face even in the absence of congestion, while b1 and b3 become most relevant in case of blocking, when buffers fill up; in the absence of congestion, input and output buffers can be traversed in a single cycle instead. Blocking always happens because of arbitration conflicts, either directly, when in front of a switch crossbar, or indirectly, due to full buffers ahead. For simplicity, throughout the paper, we consider the buffering between two adjacent switches to be lumped, so we mention ‘output buffer of switch j’ and ‘input buffer of switch j+1’ equivalently, referring to the same number of intermediate registers between the arbitration points of switches j and j+1, i.e. to Bd. Please also note that the switches along a path are indexed j=1...m, but j=0 can conveniently be seen as a virtual switch inside the source node to model source conflicts (i.e. sending more than one flow from a source node). The parameters ts1 and ts2 model the setup time at NoC sources and destinations to inject and eject packets. Of course, to be able to use finite parameters, we assume that the receiving nodes are able to accept incoming data at the required rates. Figure 1: Switch model and parameters 4. NOC TRAVERSAL DELAY ANALYSIS Table 3 lists the parameters we define to describe traffic flows across the network, while Table 4 summarizes the parameters that we identify to model the performance of such flows. Most 580 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers notably, UBi represents the upper-bound delay for network traversal by a packet of flow Fi , and is a key figure for the interconnect designer. We try to use a notation as close as possible to that used in [10] for ease of comparison. We first present a method called RTB-HB (Real Time Bound for High-Bandwidth traffic), which calculates UBi in a completely worst-case traffic situation. Crucially, this includes the possibility for other system cores to inject unregulated bandwidth, i.e. any amount of traffic at irregular intervals. This is a key property for real-world interconnect analysis methods, as most available IP cores operate on an unregulatedinjection basis. In order to calculate UBi in such a case, we consider all the intermediate buffers along the route full, and we assume arbitration losses at all switches against all other contending flows. Since switches are assumed to feature roundrobin arbitration, even though we assume the current flow to be serviced last, the maximum delay is bounded, i.e. starvation cannot occur. Therefore, the packets sent by the flow source Si are eventually delivered. RTB-HB calculates the interval MIi , i.e. the number of cycles after which the output buffer of Si is guaranteed to be free again for further injection. From this value, the worst-traffic minimum injectable bandwidth (mBWi) can also be easily derived. Please note that this analysis can be applied to most NoC architectures, without any specific QoS hardware or software provisioning. We then move on to the description of another method, called RTB-LL (Real Time Bound for Low-Latency traffic). In this scenario, we assume that traffic injection can be regulated, as possible in some application scenarios. Therefore, we also calculate a minimum permitted interval (mIi) between two consecutive packets from the same source, which can be translated into a maximum permitted bandwidth (MBWi). This approach is similar to previously published method [10] (Real-time wormhole channel feasibility checking or WCFC, which will be briefly described later), but delivers substantially better results in terms of bound tightness. For proper operation, the system must then respect MBWi bounds at runtime. Compared to method RTB-HB, in the calculations for method RTB-LL, it is possible to consider parameters b1 and b3 to represent the buffers delay (b1=1 and b3=1 or 0, when there is no output buffer), instead of the exact buffer size. 4.1 The Proposed Delay Model RTB-HB The goal here is the calculation of the parameters UBi (worstcase latency to traverse the network) and MIi (maximum worstcase interval). In this paper, due to lack of space, we only show the case where Bd <= L. For a Bd > L, we can introduce dummy switches for each port, each with Bd <= L and use the same analysis below. Let us first consider the case Bd = L. To grasp intuitively the analysis, please observe that Bd = L means, in concrete terms, that a packet fills exactly the buffering resources between the arbitration points of two adjacent switches. Considering as an example a network completely full of traffic (an unrealistic scenario just for visualization purposes), and Bd = L globally, the network operates by shuffling packets around in lockstep: all switches re-arbitrate simultaneously every L cycles, and packets trail each other, filling up buffers as soon as they free up. Parameter Fi Li Si Di Pi hi Parameter UBi MIi mIi mBWi MBWi j ui j Ui z0(i,0) zc(i,j) I(x) Table 3: Traffic model parameters Description i-th traffic flow in the network Length of the packets of Fi, in flits Source node of Fi Destination node of Fi Packet of Fi Number of switches (hops) along the path of Fi Table 4: Performance model parameters Description Upper bound delay for a packet Pi of Fi to traverse the NoC Maximum interval until the ability to inject a new packet of Fi, used in method RTB-HB Minimum permitted interval between two consecutive packets of Fi, used in methods WCFC and RTB-LL Worst-traffic minimum injectable bandwidth for Fi, used in method RTB-HB and is equal to: mBWi :=L*FlitWidth/MIi*Freq Maximum permitted bandwidth for Fi , used in methods WCFC and RTB-LL and is equal to: MBWi :=L*FlitWidth/mIi*Freq The time needed for Pi to go from the input buffer of SWj (j>0) or from generating process in Si (j=0) to the input buffer of SWj+1 ( 0≤j≤hi-1) or Dj (j=hi) The time needed for Pi to go from the output buffer of SWj (j>0) or from the output buffer of Si (j=0) to the output buffer of SWj+1this parameter is used for convenience and, mathematically j, as Ui j = ui j+1, j≥0 it can be written based on ui Number of flows contending with Fi at Si Number of flows contending with Fi at SWj at output channel c Index of the x-th flow contending with Fi at Si (or SWj) More formally, when Pi is generated in Si , we consider all intermediate buffers along its route as full of packets from different flows. In the worst case, for Pi to reach its destination, all these packets must leave their buffers. Focusing e.g. on hop j, Pi may have arbitration conflicts with a number zc(i,j) of other flows contending for the output channel c, for example flows Fq and Fr. Since round robin arbitration is assumed, it is enough to consider all contending flows to send a packet before Pi to guarantee that the analysis is worst-case. The order in which contending flows obtain the arbitration is not important for the calculation of the delay of Pi . So Pq should make a one-hop forward progress. While Pq frees the buffers at hop j flit by flit, the flits from Pr will smoothly replace the free buffer spaces. Eventually Pi also goes through. Section 4.3 presents a simple example to visualize this. The parameter ui 0 represents the time needed for Pi to be ejected from Si and be placed in the output buffer of Si (or input buffer of the first switch of Fi ). ui j then represents the time needed for Pi to go from the input buffer of SWj to the input buffer of SWj+1, except for the last switch. At the last switch Pi is ejected, so it is instead the time needed to get into the input buffer of destination Di . To calculate UBi , as shown in Eq. 1, all these contributions must be added up, plus the fixed overhead for packet creation and ejection. UBi = ts1 + ts2 + ∑j ui with j = 0 … hi (1) The time needed for Si to inject the next packet is the time to create such a packet, plus the time needed for this packet to move on to the input buffer of the first switch: j 0 MIi = ts1 + ui (2) To be consistent with the notations from [10] and for convenience, we introduce the uppercase Ui j symbol, which models the hop delay from output buffer to output buffer, instead of from input buffer to input buffer. 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 581 Let us consider a packet of flow Fi initiated at the source Si . For this packet to reach the input buffer of the first switch, any already existing packet at that buffer has to leave, freeing the buffer. This existing packet could be a previous packet from the same flow Fi or any of the contending flows at the output channel of the source. Thus, the worst-case time taken for any existing packet to leave the buffer is given by MAXx(Ui ,U0 I (x)), where I(x) is the index of contending flows at the output channel, with x = 1 ... z0(i, 0). Also, all the other contending flows of Fi may have to send a packet before this flow. Thus, the total delay for a packet from Fi to reach the input buffer of the first switch is given by: 0 = MAX (Ui 0 ,U0 I (x)) + ∑x  U0 ui 0 I (x), with x = 1 ... z0(i, 0) (3) j can be calculated similarly: For the subsequent hops, ui ui j = MAX (Ui j , Uj x = 1 ... zc(i,j), 1 ≤ j ≤ hi I (x)) + ∑x  Uj I (x) with (4) Please note that, if there is no contention for the flow, then the above equation reduces to ui j = Ui j. This is again akin to a packet moving in a pipeline fashion in the network. In order to calculate the Ui j values, let us consider the packet from flow Fi moving from output buffer of the source to the output buffer of the first switch. For the packet to move, any existing packet from the output buffer of the first switch should move to the output buffer of the second switch. Similar to the above calculations, the maximum delay for this is given by MAXx (Ui I (x)). Please note the small difference from the ui j calculations that, in this case, the values of Ui j at a switch (j) depends on the values at the next switch (j+1) on the j values can be obtained using the following path. The Ui equations: j+1 , Uj+1 Ui j = MAXx (Ui with x= 1 .. zc(i,j+1), 0≤ j ≤ hi-1 j+1 , Uj+1 I(x)) + ∑x  Uj+1 I(x) (5) For the case of the last switch, from the output port, the packet can be ejected in Li cycles, with one flit of the packet ejected each cycle. Thus, Uhi i = Li , UhI(X) I(x)=LI(x) Based on Eq. 3 and 4, now the problem of finding UBi and MIi j values, which (Eq. 1 and 2) is mapped onto a summation of Ui can be solved by Eq. 5. Please note that we assume the destination have enough buffers to eject the packets at the rate at which the network delivers them. By applying the above formulae recursively, we can obtain the worst-case delay (UB) and injection rate (MI) for the different flows. The same set of formulae also apply to the case where Bd < L. It is intuitive that the queuing effects are similar for this case as that of Bd = L. The methods can be easily extended to support virtual channels and different message lengths, so in the examples throughout the paper, we have used Li instead of L. But due to lack of space, we omit these extensions in this paper. 4.2 The Proposed Delay Model RTB-LL We present a substantial improvement to the previously published method WCFC [10]. WCFC also calculates upper bound propagation delays and permitted injection intervals for flows in wormhole networks. It considers the arbitration contention that packets will face and, recursively, the delay incurred by other packets sharing some part of their route due to these blockings. With the same notation as above, WCFC proposes [10] the following formulae for calculating UBi and mIi: UBi = ts1 + ts2 + Li + (hi + 1)a + ∑j  ui j with j = 0 ... hi mIi = ts1 + Li + ∑j ui j -  hi b with j = 0 ... hi where ui j = b + ∑x  Uj I i (x) with x = 1 ... zc(i, j) In the WCFC method, the calculations are based on the assumption that each flow injects packets spaced by at least a minimum permitted interval. For applications that can support such an assumption, we present a method that gives significant improvement over the WCFC method, which we call RTB-LL. To improve upon WCFC, a new concept of overlapping flows is introduced. If two or more different flows contend for the same output port at a switch, and they also share the same input port, we call such flows overlapping at the switch. This notion allows us to significantly optimize the bound tightness. When Fi contends with multiple overlapping flows at a switch, it is possible to locally coalesce all such overlapping flows into a single one. This is because the arbitration cannot be lost to multiple of those flows, as they cannot physically produce a contending packet simultaneously given that they enter the switch through the same input port. If there exist e.g. two overlapping contending flows at hop j having delay parameters Uj i1 and Uj i2, then it is possible to consider MAX(Uj i2) as their representative delay, instead of Uj i1 + Uj i2, for calculating the parameters for Fi , and so the main contending flows (i1 and i2) are ignored in the calculations. When Fi overlaps with other flows, in the calculations for Fi the other contending flows should be ignored. By applying these optimizations, we have noticed a significant improvement in bound tightness in RTBLL, as will be seen in next section and as Table 1 summarizes. i1 ,Uj 4.3 Delay Calculation Examples To describe in detail different aspects of the analytical methods RTB-HB, RTB-LL and WCFC for upper bound delay and interval calculation, we apply them step-by-step to an example NoC (shown in Fig. 3) and then compare them. There are 4 message flows from S1 to D1, S2,3 to D3, S2,3 to D2,4 and S4 to D2,4. The NoC contains four switches. For the sake of simplicity, we consider Bd = L in this example. 4.3.1 Method RTB-HB j with j = 0 … 3 As an example, we study the time needed for a packet P0 of flow F1 to get through the network. In general, from Eq. 1: UB1 = ts1 + ts2 + ∑j u1 To start, let us model the time u0 1 needed to move from S1 to input buffer of switch SW1. We start from the most congested network possible, so there exists another packet P1 of the same flow ahead, and this packet needs U0 1 to go from the output buffer of the source (remember that source nodes are tagged with superscript 0) to the output buffer of SW1, so u0 1= U0 1. U0 1 has to be calculated recursively based on the delays of the contending packets and of the packets ahead along the same route. 582 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers Figure 3. A simple example network (a) (b) (c) (d) (e) (f) Figure 4: (a,b,c) packet P0 goes from a process that generates it  (F1 in S1) to the input buffer of SW1. (d, e, f) packet P0 goes from input buffer of SW1 to input buffer of SW2 We observe that two factors contribute to its calculation: first, the possibility of losing arbitrations at SW1; second, the fact that there may be no available buffer space at the output of SW1 (due to arbitration losses ahead), which also effectively stalls packets at the input of SW1. For what concerns the arbitration loss, it can be seen that flow F1 contends with flow F2 at the output of SW1. Thus, a packet P2 of F2 currently in the input buffer of SW1 could be arbitrated before P1. For what concerns the output buffer full condition, in the worst case, there will be a packet P3 in the output buffer of SW1. P3 could belong to either F1 or F2, in which cases, respectively, either U1 1 or U1 2 models the time for such packet to move ahead, from the output buffer of SW1 to the output buffer of SW2. MAX(U1 2, U1 1) models the worst-case delay affecting our flow under study. During the time MAX(U1 2, U1 1), the packet P3 moves on to the output buffer of SW2, leaving the output buffer at SW1 empty. However, in the worst case, an arbitration loss occurs to P1, so it is packet P2 which will smoothly replace P3 (Fig. 4(a)). Before P1 can move on by one hop, we must also consider the time for packet P2 to go from the output buffer of SW1 to the output buffer of SW2 (Fig. 4(b)), which is U1 2. In summary: u0 1 = U0 1 = MAX(U1 2, U1 1) + U1 2 Which traces back to Eq. 3. As mentioned above, this is the delay for P1 to move one hop on, but equivalently is also the delay for P0 to replace it in the previous location (Fig. 4(c)). Now, similarly, P0 needs to move another hop on, from the input buffer of SW1 to the input buffer of SW2, with a delay which is defined as u1 1. It is possible to use the equation u1 1= U0 1 based on the equality described in previous section, but for clarity we always describe uj i based on Uj i . As shown in Fig. 4(d, e, f), in the worst case, packet P0 should wait for a packet P4 of F2. A packet P1, again either from F1 or F2, should be considered at the output buffer of SW1. So again, during the time MAX(U1 2, U1 1), while P1 moves on to the output buffer of SW2, P4 will replace it. P4 itself then takes U1 2 to move on, allowing P0 to eventually get to the input buffer of SW2. Thus: u1 1 = MAX(U1 2, U1 1) +U1 In a similar manner u2 1 can be calculated. Once P0 is in the input buffer of SW3, it is only one hop away from its destination and as there is no contending flow at the destination, the time that is needed to be ejected is equal to L1. For uniformity of presentation we can write: u3 1 = U3 1 = L1 2 Now, the target metric UB1 can be calculated recursively, as a function of a set of Uj i variables for the whole network starting from the last hop of each flow, where they assume a known value. The calculation of all intermediate values, e.g. U1 1, U1 2, U2 1, U2 2, U3 1, and of the relevant metrics UBi and MIi , is shown in Fig. 5. Please note that intermediate values can be calculated once only and then stored, to speed up the recursion. 1 2 1 2, U1 2, U2 1) + U1 1) u0 1= U0 u1 1= MAX(U1 u2 1= MAX(U2 u3 1= U3 U2 1=U3 1= L1 U2 2 = U3 2 =U4 4+U4 2=L4+L2 U1 1 = MAX(U2 1, U2 2)=L2+L4 U1 2 = MAX(U2 1, U2 2)= L2+L4 U0 1= MAX(U1 2, U1 1) + U1 2= 2L2+2L4 UB1=L1+5L2+5L4 ,MI1 = 2L2+2L4 u0 3= MAX(U0 2, U0 3)+U0 u1 3= U1 3=L3 UB3=4L2+L3+4L4 MI3= 4L2+4L4 2 3 1 2 2 2, U1 1) +  U1 2, U0 2, U1 2, U2 3) + U0 1) + U1 1) u0 2= MAX(U0 u1 2= MAX(U1 u2 2= MAX(U2 u3 2= U3 u4 2= U4 4+ U4 U0 2=MAX(U1 2L2+2L4 U0 3= U1 3=L3 UB2=6L2+L3+6L4 MI2 = 2L2+L3+2L4 u0 4= U0 u4 4= U4 2+ U4 U0 4= U4 2+ U4 4= u4 UB4= 2L2+2L4 , MI4= L2+L4 4 1 = 4 4 Figure 5: The complete calculation of UBi and MIi for the example NoC of Fig. 3 in method RTB-HB When considering the source S2,3, it can be noticed that two flows F2 and F3 can originate from it, therefore source conflicts may happen. As Fig. 5 shows, analyzing e.g. the flow F2, in this case u0 2 (the time to transfer of a packet of F2 into the input buffer of the first switch) should include a delay MAX(U0 2, U0 3), which accounts for a packet of either F2 or F3 to move away from the input of SW1 towards the input of SW2 (during which time we must assume, in the worst case, that it is a packet of F3 which replaces it), and then again the time U0 3 for this latter packet to also move on, and finally letting a packet from F2 in. The calculation for u0 3 is the same. 4.3.2 Methods RTB-LL and WCFC Fig. 6 and Fig. 7 show the calculated UBi and mIi values for both WCFC and RTB-LL methods for the same example of Fig. 3. Since flows F1 and F2 are overlapping at SW2, our proposed RTBLL improves the bound tightness compared to WCFC. Considering for the sake of exemplification a NoC variant as in Fig. 8, with another contending flow at SW2, then in RTB-LL the delay u2 3 of F3 at SW2 can be modeled as b + MAX(U2 1, U2 2) instead of the overly pessimistic value b + U2 1 + U2 2 calculated by WCFC. 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 583 Table 5: Network parameters for the study Parameter Value L (flits) 4 a (regs.) 1 b1 (regs.) 1 b2 (regs.) 2 b3 (regs.) 0 ts1 (cycles) 0 ts2 (cycles) 0 FlitWidth (bytes) 4 Freq (MHz) 400 1 2 2 2 + U4 u0 1= 0 u1 1= b + U1 u2 1= b + U2 u3 1= b U1 2 = U2 2 + U2 U2 2 = U3 2 = U4 U2 1 = U3 1 = L1 UB1 = 4a+3b + L1+2L2+2L4 mI1 = 2L1+2L2+2L4 u0 3= U0 2, u1 3= b U0 2 = U1 2 + U1 UB3=2a+b+2L1+2L2+L3+2L4 mI3= 2L1+2L2+L3+2L4 1 4= L2 + L3 4 1 1 3 u0 2= U0 u1 2= b + U1 u2 2= b + U2 u3 2= b u4 2= b + U4 U0 3 = U1 3= L3 U1 1 = U2 1 + U2 UB2=5a+4b+2L1+2L2+L3+2L4 mI2=2L1+2L2+ L3+2L4 u0 4= 0 u4 4= b + U4 UB4=2a+b+L2+L4 mI4= L2+L4 2 2 Figure 6: The complete calculation of UBi and m Ii for the example NoC of Fig. 3 in method WCFC 2 u0 1= 0 u1 1= b + U1 u2 1= b u3 1= b U1 2 = U2 2 =U3 2 = U4 U2 1 = U3 1 = L1 UB1 = 4a+3b + L1 + L2 + L4 mI1 = L1+L2+L4 2+U4 4 = L2+ L4 u0 3= U0 2, u1 3= b U0 2 = U1 2 + U1 UB3=2a+b+L1+L2+L3+L4 mI3= L1+L2+L3+L4 1 4 1 3 u0 2= U0 u1 2= b + U1 u2 2= b u3 2= b u4 2= b + U4 U0 3 = U1 3= L3 U1 1 = U2 UB2=5a+4b+L1+L2+L3+L4 mI2=L1+L2+L3+L4 u0 4= 0 u4 4= b + U4 UB4=2a+b+L2+L4 mI4= L2+L4 1 2 Figure 7: The complete calculation of UBi and m Ii for the example NoC of Fig. 3 in method RTB-LL 3 SW2 1 2 Figure 8: NoC variant where flow F3 contends with two overlapping flows F1 and F2 at SW2 5. STUDIES ON APPLICATIONS The proposed methods RTB-HB and RTB-LL can be used to analyze the scheduling of traffic flows in real-world applications. In this section we present studies on five multimedia and RT applications, comparing RTB-HB and RTB-LL to the WCFC baseline, under the parameters of Table 5. In these applications, we assume that NoC topologies are predefined based on application communication needs, but without any feedback from the proposed algorithms to customize the network structure for better upper bound delay and interval time results. This is a possible extension for future work. In particular, for many applications it is possible to identify a small subset of few flows as critical, and then to optimize the NoC based on feedback loops from RTB-HB and RTB-LL to improve the performance of such critical flows. It is possible to do this without dedicated hardware support or any priority scheme. 5.1 Case Study: A Multimedia Application In this section, we compare the results of applying RTB-HB, RTB-LL and WCFC to D26-media, a real-time multimedia application with 67 communications flows, some of which critical, shown in Fig. 9. The application is mapped onto two NoC topologies, one with 5 ""fat"" (high-radix) switches (shown in Fig. 10) and the other one with 20 ""thin"" (low-radix) switches. Fig. 11 presents the results of the study in terms of latency, interval and bandwidth for the whole set of flows. Fig. 11(a, b) compare the worst-case NoC traversal latency UBi . The RTB-LL model always provides the tightest bounds. Compared to WCFC, the largely improved tightness (more than 50% on average) is due to the analysis of overlapping flows, a novelty of this paper, but without any impact on the accuracy of the bounds, which are still under worst-case assumptions. RTB-HB naturally returns higher worst-case latency, due to the assumption that no hardware traffic injection regulation facilities are available. In fact, due to the different calculation approach, the bounds are on average still 30% lower than in WCFC, despite the less restrictive assumptions. There are, however, a few flows for which WCFC predicts lower delays than RTB-HB, due to the regulated injection assumption. In a zero-load scenario (no contention at all), the minimum theoretical latency to traverse the 5-switch NoC for flows spanning a single hop is 8 cycles (a + b1 + b2 + b3 + L), while RTB-LL gives a minimum upper-bound of 17 cycles in worstcase contention. In general, for all methods, the delays calculated for the 20-switch topology are higher, as a result of longer paths (more hops) per flow, higher probability of contention, and especially for RTB-HB more in-flight packets. This suggests, as intuitively expected, that NoCs with fewer hops guarantee lower delay bounds. Figure 9: Communication graph for D26-media Fig. 11(c, d) shows maximum and minimum injection intervals (MIi and mIi). Intuitively, if traversal delays are lower, new packets can be injected sooner, so MIi (mIi) plots resemble UBi trends: flows with lower traversal latencies can be injected more frequently. Thus, the mIi intervals are always shorter in RTB-LL and the MIi intervals often shorter in RTB-HB when compared to mIi in WCFC. These intervals can be directly translated into minimum and maximum injectable bandwidths (mBWi , MBWi) using the formulae in Table 3; results are shown in Fig. 11(e, f). Maximum injectable bandwidths (MBWi) are on average 35% higher according to RTB-LL compared to WCFC, and 25% higher according to the minimum bandwidth (mBWi) in RTB-HB. The maximum theoretical injectable bandwidth is 1600 MB/s (Freq* FlitWidth); according to RTBLL, even under worst-case assumptions, some flows on the 5switch NoC are guaranteed injection rates of as much as 533 MB/s. In the 20-switch network, the higher contention likelihood affects injectable bandwidth negatively, but the use of more resources has a positive effect on many-hop flows, resulting overall in comparable injectable bandwidths. In 584 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers ARM Imgp roc1 Mem4 Mem5 P1 P3 SDRAM2 DMA Debug Mem1 PE3 SW2 SW5 SW1 SW4 L2C L2CC Imgproc2 SDRAM1 Flash SW3 PE2 Mem3 Mem2 CTRL2 PE1 CTRL1 P2 DSP DSPL2Cc DSPL2C Figure 10 : D26-media application mapped on a 5-switch NoC summary, NoCs with few hops exhibit clearly better upperbound traversal delays, but in terms of injectable bandwidths, the mapping of the flows (i.e. the contention patterns) and the amount of used resources play a decisive role in NoC performance. 5.2 Suitability to Critical Flows Fig. 12 shows the average UBi traversal delay and the average mBWi injectable bandwidth for flows traversing x hops of the 5switch NoC, considering the D26-media application and using RTB-HB. It can be seen that 1-hop flows exhibit reasonably low latencies and high bandwidths, suitable for critical traffic. Therefore, the proposed methodology has a clear applicability to industrial RT applications. Table 6: Studied applications Cores 26 65 35 36 36 NoC switches 5 6 6 6 7 Clock frequency (MHz) 400 300 300 400 400 Traffic flows 67 378 128 144 216 D26-media Pipeline Bottleneck 36core-4 36core-6 5.3 Comparison for Different Applications Fig. 13 shows the implementation results of the 3 different methods to the five applications listed in Table 6. 36core-4 and 36core-6 are different mainly because in the former application each core handles 4 communication flows to as many other cores, while in the latter each core handles 6 such flows. Fig. 13 proves that, for all the applications, RTB-HB and RTB-LL provide tighter average bounds than the reference WCFC method. RTB-LL is strictly tighter than WCFC, while RTBHB, although it provides much tighter bounds on average, can return higher bounds for specific flows since it does not rely on regulated traffic assumptions of any kind. 6. COMPLEXITY OF THE METHODS To estimate the time complexity of the proposed algorithms, implemented for the proposed methods, we calculate the maximum number of operations that are required. As Eq. 1, Eq. 3 and Eq. 5 show, the only operations are additions and comparisons (for the MAX operator); so we may consider one cycle to execute each of these operations. RTB-LL:min,avg,max:17,91,193 RTB-HB:min,avg,max:24,174,392 WCFC  :min,avg,max:17,237,545  RTB-LL:min,avg,max:17,143,357 RTB-HB:min,avg,max:24,329,868 WCFC :min,avg,max:17,1728,5233 (a) (b) RTB-LL:min,avg,max:12,84,180 RTB-HB:min,avg,max:12,139,308 WCFC  :min,avg,max:12,229,532  RTB-LL:min,avg,max:12,132,340 RTB-HB:min,avg,max:12,245,708 WCFC:min,avg,max:12,1717,5216 (c) (d) RTB-LL:min,avg,max:36,124,533 RTB-HB:min,avg,max:21,101,533 WCFC  :min,avg,max:12,81,533 RTB-LL:min,avg,max:19,121,533 RTB-HB:min,avg,max:9,103,533 WCFC  :min,avg,max:1,79,533 (e) (f) Figure 11: (a, c, e) UBi, MIi and mBWi characterized with WCFC, RTBLL and RTB-HB for D26-media mapped onto a 5-switch NoC. (b, d, f) The same metrics mapping on 20-switch NoC. Horizontal axes enumerate the communication flows. We call h the maximum number of switches in a flow, and k the number of flows. We also pessimistically assume the maximum number of contending flows at a switch output to be k. For calculating one Uj i parameter, we need (Eq. 5) at most k comparisons and k additions, thus 2k operations. The number of Uj i parameters to be calculated is hk, so the maximum number of operations is 2hk2. uj parameters (except for j=0) can be derived from the equality Uj i = i , so we only need to calculate the case of u0 i for all flows. In this case, one u0 i (Eq. 3) needs 2k operations; for all u0 i parameters we need 2k2 operations. uj+1 i In RTB-HB the outcome are k UBi and k MIi values. For calculating one UBi value (Eq. 1) we need h+1 additions, so for all k UBi values we need (h+1)k, while in the case of MIi , k operations are needed. The total number of operations is the summation of all the above, or 2hk2+2k2+(h+1)k+k. So the complexity of the algorithm is O(hk2 ). 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 585 [5] J. Henkel, W. Wolf, and S. Chakradhar, “On-chip networks: a scalable, communication-centric embedded system design paradigm,” in Proceedings of the 17th International Conference on VLSI Design (VLSID ’04), vol. 17, pp. 845–851, Mumbai, India, January 2004. [6] S. Furber and J. Bainbridge. “Future trends in SoC interconnect, “ In VLSI Design, Automation and Test, pages 183– 186, 2005. [7] Z. Shi and A. Burns , “Real-Time Communication Analysis for On-Chip Networks with Wormhole Switching, “ Second ACM/IEEE International Symposium on Networks-on-Chip, 2008 [8] C. Paukovits, H. Kopetz, ""Concepts of Switching in the Time-Triggered Networkon-Chip,"" Proceedings of the 2008 14th IEEE International Conference on Embedded and Real-Time Computing Systems, pp.120-12. [9] K. Goossens, J. Dielissen, and A. Radulescu, “The Æthereal network on chip: Concepts, architectures, and implementations,“ IEEE Design and Test of Computers, 22(5):414–421,2005. [10] S. Lee, “Real-time wormhole channels,“ J. Parallel Distrib. Comput. 63 (2003) 299–311 [11] D. Kandlur, K. Shin, D. Ferrari , “Real-Time Communication in Multihop Networks,“ IEEE Trans. on Para. and Distributed Systems, vol. 5, no. 10, Oct. 1994. [12] M. Zhang, J. Shi, T. Zhang, Y. Hu, “Hard Real-time Communication over Multihop Switched Ethernet, “ Int. Conf. on Networking, Architecture, and Storage, 2008 [13] S. Gopalakrishnan, S. Lui, and M. Caccamo, ""Hard Real-Time Communication in Bus-Based Networks, "" In Proc. 25th IEEE Int. Real-Time Systems Symp., 2004. [14] A. Yiming, and T. Eisaka, “A Switched Ethernet Protocol for Hard Real-Time Embedded System Applications,” In 19th Conf. on Advanced Information Networking & Applications, March 2005, pp. 41-44. [15] K. Watson and J. Jasperneite, ""Determining end-to-end delays using network calculus,"" In Proc. 5th IFAC Int. Conf. on Fieldbus Systems and Their Applications (IFAC-FET2003), July 7-8, 2003, pp. 255-260. [16] J. Chen, Z. Wang, and Y. Sun, “Real-time capability analysis for switch industrial Ethernet traffic priority-based,” In Proc. of Int. Conf. on Control Applications, Glasgow, UK, Sep. 2002, pp. 525-529. [17] J. Jaspernite, P. Neumann, M. Theis, and K. Watson, “Deterministic Real-Time Communication with Switched Ethernet,” In Proc. of WFCS’02, Vasteras, Sweden. [18] S. Lee; K. C. Lee, and H. H. Kim, “Maximum communication delay of a realtime industrial switched Ethernet with multiple switching hubs,” In 30th Conf. of IEEE Industrial Electronics Society, 2004. [19] J. Loeser and H. Haertig, “Low-latency hard real-time communication over switched Ethernet,” In Proc. of ECRTS 2004. [20] J. Kiszka, B. Wagner, Y. Zhang, J. Broenink,” RTnet – A Flexible Hard RealTime Networking Framework,” In: 10th IEEE International Conference on Emerging Technologies and Factory Automation, 2005. [21] H. Kopetz, A. Damm, C. Koza, et al., “Distributed fault-tolerant real-time systems: the Mars approach,” IEEE Micro, 1989, 9(1): 25-40. [22] E. Bolotin et al., “QNoC: QoS architecture and design process for network on chip,” Journal of Systems Architecture, vol. 50, no. 2–3, pp. 105–128, Feb. 2004. [23] T. Bjerregaardand, J. Sparsoe, “Arouter architecturefor connection-oriented service guarantees in the MANGO clockless network-on-chip,” in DATE, vol. 2, Mar. 2005, pp. 1226–1231. [24] A. Bouhraoua and M. E. Elrabaa, “A high-throughput network-on-chip architecture for systems-on-chip interconnect,” in Intl. Symposium on Soc, Nov. 2006. [25] F. Felicijan and S. Furber, “An asynchronous on-chip network router with qualityof-service (QoS) support,” in SOCC, Sep. 2004, pp. 274–277. [26] N. Kavaldjiev et al., “A virtual channel network-on-chip for GT and BE traffic,” in ISVLSI, vol. 00, Mar. 2006. [27] A. Leroy et al., “Spatial division multiplexing: a novel approach for guaranteed throughput on NoCs,” in CODES+ISSS, 2005, pp. 81–86. [28] A. Mello, L. Tedesco, N. Calazans, and F. Moraes, “Evaluation of current QoS mechanisms in network on chip,” in Intl. Symposium on Soc, 2006, pp. 115–118. [29] M. Millberg, R. T. E. Nilsson, and A. Jantsch, “Guaranteed bandwidth using looped containers in temporally disjoint networks within the Nostrum network on chip,” in DATE, 2004, pp. 890–895. [30] F. Mondinelli, M. Borgatti, and Z. Vajna, “A 0.13 um 1Gb/s/channel store-andforward network on-chip,” in SOCC, Sep. 2004, pp. 141–142. [31] R. Mullins, A. West, and S. Moore, “The design and implementation of a lowlatency on-chip network,” in ASP-DAC, 2006. [32] A. Radulescu et al., “An efficient on-chip NI offering guaranteed services, sharedmemory abstraction, and flexible network configuration,” IEEE Trans. ComputerAided Design of Integrated Circuits and Systems, vol. 24, no. 1, pp. 4–17, Jan. 2005. [33] E. Rijpkema et al., “Trade offs in the design of a router with both guaranteed and best-effort services for network on chip,” IEE Proc. Computers and Digital Techniques, vol. 150, no. 5, pp. 294–302, 2003. [34] E. Salminen, A. Kulmala, T. Hamalainen, “Survey of Network-on-Chip Proposals,” www.ocpip.org, March 2008. Figure 12. Average Upper Bound Delay (left) and Average Minimum Bandwidth (right) for x-hop flows in D26-media for RTB-HB Figure 13. Comparisons: (left) average UBi (WCFC as reference), (right) average MBWi or mBWi (RTB-LL as reference) For RTB-LL, using the same approach, we can show that the complexity of the algorithm for calculating UBi and mIi is again O(hk2 ). Thus, both algorithms have quadratic time complexity. In practice, the execution time for all our test applications is very small (few seconds on a standard PC) and the modeling of delay and bandwidth parameters does not pose significant runtime issues. 7. CONCLUSION AND FUTURE WORKS We have proposed two different methods to characterize bandwidth and latency for NoC-based real-time SoCs, aiming at guaranteed QoS provisions. The choice of the most suitable method depends on the performance demands of the system and on whether dedicated hardware facilities can be supplied in the NoC. One method is aimed at applications demanding minimum latencies and requires injection regulation, while the other is suitable for applications where packet injection must be flexible to accommodate for higher average injected bandwidths and no hardware regulation is available. We proved that the proposed methods return the worst-case metrics in a much tighter way than existing approaches, rendering them quite applicable for real-world SoC applications. The major next step is to use the results of this work as an input to an iterative procedure to synthesize optimized NoCs whereby the QoS demands of critical traffic flows are met. 8. "
2009,From 2D to 3D NoCs - A case study on worst-case communication performance.,"Advanced integration technologies enable the construction of Network-on-Chip (NoC) from two dimensions to three dimensions. Studies have shown that 3D NoCs can improve average communication performance because of the possibility of using the additional dimension to shorten communication distance. In this paper, we present a detailed case study on worst-case communication performance in regular k-ary-2-mesh networks. Through both analysis and simulation, we show that, while 3D networks achieve better average performance, this may not be the case for worst-case performance mainly due to constraints on vertical channels. Our analysis is based on network calculus, which allows to calculate theoretical delay bounds for constrained flows traversing network elements.","From 2D to 3D NoCs: A Case Study on Worst-Case Communication Performance Yue Qian† , Zhonghai Lu‡ and Wenhua Dou† †School of Computer Science, National University of Defense Technology, China ‡Dept. of Electronic, Computer and Software Systems, Royal Institute of Technology (KTH), Sweden † {yueqian, douwh}@nudt.edu.cn; ‡zhonghai@kth.se ABSTRACT Advanced integration technologies enable the construction of Network-on-Chip (NoC) from two dimensions to three dimensions. Studies have shown that 3D NoCs can improve average communication performance because of the possibility of using the additional dimension to shorten communication distance. In this paper, we present a detailed case study on worst-case communication performance in regular k-ary2-mesh networks. Through both analysis and simulation, we show that, while 3D networks achieve better average performance, this may not be the case for worst-case performance mainly due to constraints on vertical channels. Our analysis is based on network calculus, which allows to calculate theoretical delay bounds for constrained ﬂows traversing network elements. Categories and Subject Descriptors B.4 [Input/Output and Data Communications]: Performance Analysis and Design Aids General Terms Design, Performance Keywords Performance Analysis, Delay Bound, 2D/3D Network-onChip, Network Calculus, Quality-of-Service 1. INTRODUCTION Over the past four decades, chip integration capacity has been continually following Moore’s law. To fully utilize the integration capacity in the billion-transistor era, NoCs have received signiﬁcant attention over the past 10 years due to good scalability. However, scaling on-chip networks over two dimensions to accommodate tens or hundreds of cores are not eﬃcient as increasing the number of cores over a 2D plane soon introduces communication bottleneck due to long Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, or republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.  ICCAD’09, November 2–5, 2009, San Jose, California, USA.  Copyright 2009 ACM 978-1-60558-800-1/09/11...$10.00.  interconnects and distance [24]. Along the development of processing and packaging technologies, enhancing chip density by continuously shrinking the feature size of transistors down to 32 nm and further to 22 nm is facing severe and alarming challenges. As we are approaching the physical limitation, signal integrity, power integrity and dissipation, leakage power, clock distribution and yield issues are becoming increasingly intractable [1]. In the end, a new generation of technology may become technically feasible, but economically infeasible. Under such circumstances, 3D integration technologies [25] emerge, such as Through-Silicon-Vias (TSVs) [27], thinned silicon and silicon-to-silicon ﬁne-pitch interconnections [10], wireless communication between 2D planes and 3D wafer wire-bonding technology [30]. These technologies enable to stack multiple dies on a single chip, creating 3D Integrated Circuits (3D-ICs) and oﬀering an opportunity to be the next performance growth engine [6]. 3D-ICs may enable heterogeneous and new classes of complex applications with signiﬁcantly improved performance, energy eﬃciency, product miniaturization, cost reduction, and modular design for improved time to market. Such technologies are currently available from a number of companies and labs such as IBM [10], IMEC [29], Honda [19], Tezzaron Semiconductor Corporation [23] and MIT Lincoln Laboratory etc. The synergy between the two trends, NoC and 3D-IC, making it possible to scale NoCs over the third dimension and resulting in 3D NoCs, which is now a hot topic today [2]. 3D NoCs overcome the limited scalability of 2D NoCs over 2D planes by using short and fast vertical interconnects of 3D-ICs. Compared with 2D NoCs, 3D NoCs greatly reduce the network diameter and overall communication distance, thus improving communication performance and reducing power consumption. Till today extensive results have shown that 3D networks improve 2D network scalability [31] and performance in terms of delay and throughput [7, 9, 22, 24]. Such studies support the huge potential of 3D NoCs and intuitively match the merits of 3D NoCs in shortening geometry and distance. However, these delay results are for overal l average delay. This has two main insuﬃciencies: (1) In a network with many ﬂows , the delay is averaged over the average delays of all ﬂows. Such averaged overall delay gives overall performance, but does not capture the irregularity of various ﬂows, thus giving only an incomplete picture of the network performance; (2) The improvement in average performance is not suﬃcient for real-time applications 1 1 A ﬂow is a unicast communication stream from a source to a destination. 555 that require guarantees under worst-case conditions. This is why Quality-of-Service has long been a ma jor research direction for building predictable systems since the birth of NoCs [17]. In this paper, we investigate the per-ﬂow worst-case communication performance in 2D and 3D NoCs through a case study. We consider a k2 -node network in 2D and 3D forms. As meshes are one of most popular NoC topologies [7, 16, 17, 24, 31], we use regular mesh topology for both 2D and 3D forms. In its 2D form, the NoC is a k-ary-2-mesh network. In its 3D form, the NoC features four layers with each layer hosting a k 2 -by- k 2 (k mod 2 = 0) mesh network. Layers are interconnected by vertical channels. We consider four layers, since this is moderate considering the heat dissipation and yield problem, though more layers are possible [30]. We focus on the impact of vertical channels for inter-layer connections since they are constrained by process technologies and thus very diﬀerent from horizontal channels on 2D planes. For example, 2D-plane router-to-router channels may use 128 parallel thin wires [21]. The vertical connections are limited by the pads, which means that the vertical channels may be thick, thus allowing higher signaling speed but can allow only a limited number of channels due to area overhead and yield problem [15, 27, 30]. We study the eﬀect of vertical channels together with diﬀerent network sizes and traﬃc burstiness. Rather than only conducting simulations, we mainly perform analysis using our worst-case delay bound analysis technique [26], which combines the network calculus [3, 4] analysis with a network contention-tree model [18]. Then we validate our analytical results against simulation results. Our results show that, while the average performance in 3D NoCs is better than that of their 2D counterparts, the worst-case communication performance in 3D NoCs may be worse than that of their 2D counterparts. The rest of the paper is organized as follows. We ﬁrst discuss related work in Section 2. Then, in Section 3, we describe the case study problem with respect to network, communication pattern and delay bound derivation. Section 4 gives detailed analysis on the case study for the worstcase delay bounds in the 2D and 3D NoCs. In Section 5, we validate our analytical results and show simulation and numerical results to justify our ﬁndings. Finally we draw conclusions in Section 6. 2. RELATED WORK Vertical interconnect techniques enable us to build 3D multi-plane chips. An overview of various options for extending 2D to 3D integration and their trade-oﬀs are discussed with respect to their performance, cost and technology in [30]. A physical model is proposed in [14] for vertical interconnects using TSVs. Dally [5] discussed the performance of k-ary-n-cube networks under constant bisection bandwidth since VLSI communication networks are wire-limited. It investigates the average latency, average-case throughput and hot-spot throughput. His study suggests that, under the same bisection bandwidth, low dimensional networks with wide channels provide lower average latency, less contention and higher hot-spot throughput than high dimensional networks with narrow channels. Recently [7] reported results about performance, power and area tradeoﬀs for mesh-based and tree-based 3D NoCs. They demonstrated that both mesh and tree-based NoCs are capable of achieving better performance when instantiated in a 3D IC environment compared to traditional 2D implementations. The mesh-based architectures show signiﬁcant performance gains in terms of throughput, average latency, and energy dissipation with a small area overhead. In [24], four variants of organizing a NoC, namely, 2D IC - 2D NoC, 2D IC - 3D NoC, 3D IC - 2D NoC, 3D IC - 3D NoC, are studied with respect to zero-load latency and power consumption. In their models, they have considered physical constraints, such as the maximum number of planes that can be vertically stacked and the asymmetry between the horizontal and vertical communication channels of the network. For 3D chip multiprocessors, in the context of data management in large L2 caches, Li et al. proposed a network-in-memory to build a networked nonuniform L2 cache architecture, which improves performance and reduces power consumption due to reducing the number of data movements over conventional 2D designs [13]. We focus on the per-ﬂow worst-case performance in 2D and 3D NoCs. The question we are seeking answer for is: will the worst-case delay in a 3D NoC better than a 2D NoC, given the same number of nodes and asymmetrical horizontal and vertical link bandwidth? Our theoretical foundation is network calculus [3, 4]. In general queuing networks, network calculus provides the means to deterministically reason about timing properties of traﬃc ﬂows. Based on the powerful abstraction of arrival curve for traﬃc ﬂows and service curve for network elements (routers, servers), it allows computing the worst-case delay and backlog bounds. Network calculus has been extremely successful for ensuring performance bounds when applied to ATM, Internet with diﬀerentiated and integrated services, and other types of networks. Systematic accounts of network calculus can be found in books [3, 11]. 3. THE CASE STUDY To deﬁne the problem in detail, we ﬁrst describe the 2D and 3D networks, then the communication pattern, and ﬁnally the task of deriving the worst-case delay bound. 3.1 The 2D and 3D Networks 2 2 2 k × k We consider a general k-ary-2-mesh (k×k mesh, k mod 2 = 0) network. The network has k nodes with each node containing a core and a router. The 2D router has 5 ports (north, south, east, west and local). When this 2D network is transformed into a 3D network, it has four layers with a × 4). The 3D 2 -by- k 2 mesh network on each layer ( k router has 7 ports (north, south, east, west, local, up and down). For example, Figure 1(a) shows an 8-ary-2-mesh network. The 64 nodes are numbered from 1, 2, ..., 64. Figure 1(b) depicts its 3D counterpart, a 4-layer 3D network. The networks use dimension-order routing, which guarantees deadlock free according to the turn model [8]. In the 2D case, the network uses XY routing, i.e., route along the X axis ﬁrst and then the Y axis. In the 3D case, the network uses XYZ routing, i.e., route along the X axis, then the Y axis and ﬁnally the Z axis. The routers use buﬀers to serve traﬃc ﬂows in the FIFO order and they do not drop packets. From the perspective of 3D integration technology, we assume that the 3D routers use TSVs for vertical connectivity. A vertical link can be implemented as a cluster of TSVs. TSVs, which cut across thinned silicon substrates to make inter-die connections after die-bonding, allow ﬁne pitch, high density and high compatibility with the standard CMOS 556 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers Layer 1 Layer 2 Layer 1 Layer 2 Layer 3 Layer 4 Layer 3 Layer 4 (a) (b) Figure 1: (a) An 8-ary-2-mesh NoC; (b) A 4-layer 3D NoC. process. Among the emerging 3D integration technologies, the TSV approach is the most promising one and therefore has been the focus of ma jor 3D R&D activities [25]. Nevertheless, compared with standard 2D processes, currently available processes for TSV fabrication have relatively low yield [15]. Hence, using less number of TSVs is highly desirable for improving the yield of a 3D design. As in [20], we have also taken this factor into consideration while designing experiments in Section 5. 3.2 Corner-to-Corner Communication Pattern The traﬃc pattern we consider is corner-to-corner communication. As the name suggests, a traﬃc ﬂow runs from one corner node to another corner node, traveling the network diameter and contending with other ﬂows for shared buﬀers and links. We call this ﬂow tagged ﬂow for which we will derive its delay bound, and other ﬂows contention or interfering ﬂows. We deﬁne ﬁve corner nodes in a k-ary-2-mesh NoC as nodes I, II, III, IV, V with labels as follows: (1) + 1, k node II : + 1, 2 + 1, node IV : (k + 1) · k 2 node I : 1, node III : k · k 2 node V : k · k. There are four traﬃc ﬂows sent from node I, II, III, IV to node V denoted as fi (i = 1, 2, 3, 4), respectively. With the 64-node example in Figure 1, the ﬁve corner nodes according to Eq. (1) are node I: 1, II: 5, III: 33, IV: 37 and V: 64. The tagged ﬂow runs from corner node 1 to corner node 64 and other three contention ﬂows from node 5, 33, 37 to node 64. In fact, nodes 5, 33 and 37 are also corner nodes from each k 2 -by- k 2 or k-by- k 2 sub-network’s perspective. This traﬃc pattern ensures that at each 3D layer there exists at least one ﬂow interfering with the tagged ﬂow, and these interfering ﬂows also travel sub-networks’ diameter. The tagged ﬂow traverses H2d = 2k − 1 hops in the 2D NoC and H3d = (2 · k − 1) + 3 = k + 2 in the 3D NoC. When k > 3, H3d < H2d . 2 3.3 Task: Computing the Delay Bound s≥0 + Our task is to derive the worst-case delay bound for the tagged ﬂow in the corner-to-corner communication pattern. To do this, we shall compute its equivalent service curve. Before proceeding, we list our notations, assumptions and deﬁnitions in the following. min-plus algebra [3, 11]. (cid:2) represents the min-plus deNotations: We follow the notation conventions in the convolution of two functions f , g ∈ F , the set of widesense increasing functions deﬁned on [0, ∞), (f (cid:2) g )(t) = {f (t + s) − g (s)}; ⊗ represents the min-plus convolution sup of two functions f , g ∈ F , (f ⊗ g )(t) = inf {f (t − s) + g (s)}; ∧ represents the minimum operation, f ∧ g = min(f , g ); = a, if a ≥ 0; a a = 0, otherwise. Assumptions: We assume the linear function αi (t) = γbi ,ri (t) = bi + ri t (i = 1, 2, 3, 4) as the arrival curve bounding ﬂow fi , where bi is the traﬃc burstiness and ri rate. f1 is the tagged ﬂow, and f2 , f3 and f4 are contention ﬂows. A router j provides a latency-rate service curve [28] β γ0,Rj ⊗ δTj (t) = Rj (t − Tj ) , where function δTj (t) = +∞ (t) = for t > Tj and 0 otherwise, and Tj is the maximum service delay, and Rj the guaranteed minimum service rate of router j . We also denote α i as the output arrival curve of fi after traversing a tandem of nodes, α i as the arrival curve of fi at node j , and ˜β as the equivalent service curve (see below for deﬁnition) guaranteed by the tandem of node m {m→n} 0≤s≤t ∗ + j + i j 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 557 to n to ﬂow fi . Equivalent service curve: Let us consider a node or a tandem of nodes serving two ﬂows, tagged ﬂow (f1 ) and contention ﬂow (f2 ), in the FIFO order, as presented in Figure 2(a). The node guarantees a service curve β to both ﬂows. The tagged and contention ﬂows have α1 , α2 as arrival curve, respectively. We deﬁne ˜β1 = (β , α2 ) as the equivalent service curve to the tagged ﬂow as illustrated in Figure 2(b), where (., .) is a function to compute the equivalent service curve. Thus, according to [11], the output arrival curve of 1 = α1 (cid:2) ˜β1 , and its delay the tagged ﬂow can be derived as α bound is H (α1 , ˜β1 ), where H (., .) is the function to compute the maximum horizontal distance between the arrival curve α1 and the service curve ˜β1 . ∗ Router (a) Router (b) Figure 2: (a) The router oﬀers a service curve β to the FIFO aggregate of two ﬂows, tagged (f1 ) and contention (f2 ); (b) The tagged ﬂow f1 receives an equivalent service curve (β , α2 ). As an example, if β (t) = γ0,R ⊗ δT (t) = R(t − T ) and α2 (t) = γb2 ,r2 (t) = b2 + r2 t, applying Corollary 4.5 in [12], the equivalent service curve for f1 can be computed as: ˜β1 = (β , α2 ) = γR·s,R−r2 ⊗ δT + b2 +s , (s ≥ 0), where s is an intermediate argument for computing the least upper delay bound [12]. (2) + R 4. CORNER-TO-CORNER DELAY BOUNDS We derive closed-form formulas to compute the worst-case delay bound for the tagged ﬂow under the corner-to-corner communication pattern in the 2D and 3D networks. 4.1 The Analysis Procedure The delay bound analysis procedure [26] can be summarized as follows: Step 1: Construct a contention tree [18] to model the network contentions produced by interfering ﬂows to a tagged ﬂow. In this step, let the tandem traversed by the tagged ﬂow be the trunk, and let the tandems traversed by the interfering ﬂows before reaching a trunk node be branches. Branches may also have their own sub-branches; Step 2: Scan the contention tree and compute all the output arrival curves of contention ﬂows traversing the branches of the trunk; 4.2 Delay Bound Derivation in the 2D NoC Construct Contention Tree: In Figure 1(a), the tagged ﬂow f1 is multiplexed with f2 , f3 and f4 . We construct a tention in the 2D NoC, where the tandem {1 → 64} tracontention tree shown in Figure 3(a) to model the ﬂow conversed by f1 composes the trunk with the ingress router 1 up to egress router 64 and the tandems traversed by contention ﬂows before reaching the trunk nodes compose the branches. two branches {33 → 39} and {37 → 39}, where branch At router 40, there are two ﬂows f3 and f4 injected from {37 → 39} has sub-branch {33 → 36}. These two branches contain the same nodes {37 → 39}. Thus, we can treat f3 one branch {33 → 39} for optimization. At router 5, f2 is and f4 as an aggregate ﬂow, denoted as f(3,4) , and keep only directly injected into the trunk and no branch extends from the trunk. Compute output arrival curves of contention ﬂows: With the contention tree presented in Figure 3(a), we compute the arrival curves of contention ﬂows, f(3,4) and f2 , to the trunk. In 2D NoCs, all 2D routers are intra-layer and assumed to oﬀer an identical service curve β = γ0, ¯R ⊗ δT (t) = ¯R(t − T ) , where ¯R represents the horizontal rate of each router. We can compute the arrival curve of aggregate ﬂow f(3,4) at router 40 by Theorem 4.15 in [12] as + 40 (3,4) = γb(3,4) ,r(3,4) α = γb3+b4+7r3 T +3r4 T ,r3 +r4 . (3) We know that f2 is injected into the trunk directly with the arrival curve of α2 = γb2 ,r2 . Derive equivalent service curve: The two contention ﬂows, aggregate ﬂow f(3,4) and f2 , form a nested interference pattern to f1 . Following [26], for the nested contention pattern, we can derive the equivalent service curve for the tagged ﬂow f1 as {1→64} ˜β 1 (cid:2) =  (β {40→64} (3,4) ) ⊗ β 40 , α {5→32} , α2 (cid:3) {1→4} ⊗ β , (4) with (cid:4) β β {1→4} {5→32} = β {40→64} = γ0, ¯R ⊗ δ4T , = γ0, ¯R ⊗ δ7T . (5) Compute the delay bound: Finally we derive the delay bound for the tagged ﬂow f1 as ¯D2d = H (α1 , ˜β {1→64} ) 1 b(3,4) ¯R + b2 ∧( ¯R, ¯R · ¯R ¯R+r(3,4) ) ¯R+r2+r(3,4) , ¯R · ¯R+r2 , ¯R · ¯R ¯R b1 + ∧( ¯R, ¯R · Step 3: Compute the equivalent service curve for the tagged ﬂow over the trunk; = 15T + Step 4: Derive the delay bound of the tagged ﬂow. In the following Section 4.2 and 4.3, we shall use this procedure to analyze the delay bounds for our example in Figure 1 and generalize the results. (6) We extend Eq. (6) for a general k-ary-2-mesh NoC. The ¯R ¯R+r2 · . ¯R ¯R+r(3,4) ) 558 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers (a) (b) 64 56 48 40 32 24 16 8 7 6 5 4 3 2 1 39 38 37 36 35 34 33 4 3 2 1 12 20 28 7 6 5 8 16 24 39 38 37 40 48 56 35 34 33 36 44 52 32 60 64 Figure 3: Contention tree for corner-to-corner communication (a) in the 2D NoC; ( ) in the 3D NoC. worst-case delay bound ¯D2d (k) can be calculated as ¯D2d (k) = (2k − 1)T + b(3,4) ¯R + b2 ∧( ¯R, ¯R · b1 ¯R ¯R+r(3,4) ) ¯R+r2 , ¯R · ¯R + ∧( ¯R, ¯R · where (cid:4) ¯R+r2+r(3,4) , ¯R · ¯R ¯R ¯R+r2 · ¯R ¯R+r(3,4) ) , (7) b(3,4) = b3 + (k − 1)r3 T + b4 + ( k 2 − 1)r4 T , r(3,4) = r3 + r4 . (8) 4.3 Delay Bound Derivation in the 3D NoC Due to the speciality of 3D architectures, we classify the service rate of the 3D router as vertical rate ˘R for interlayer communication and horizontal rate ¯R for intra-layer communication, and deﬁne their relationship as ˘R = η ¯R, router provides the vertical service curve as βv = γ0, ˘R ⊗ δT where η > 0 is the vertical to horizontal rate ratio. Thus the and the horizontal service curve as βh = γ0, ¯R ⊗ δT . The traﬃc pattern in the 3D NoC remains the same as its 2D counterpart. But now the ﬂows pass through layer 1, 2, 3 and 4. Routers 28, 32 and 60 serve the ﬂows with the vertical rate ˘R. At layer 4, router 64 forwards the ﬂows to its local core with the horizontal rate ¯R. So the service curves of these routers are = γ0, ˘R ⊗ δT , β 28 = β = β = γ0, ¯R ⊗ δT . To derive the delay bound for f1 in the 3D NoC, we again follow the 4-step procedure in Section 4.1. Construct Contention Tree: Similarly to the 2D NoC, 32 60 β 64 (9) we can construct the contention tree in Figure 3(b) for f1 with the contention ﬂows f2 , f3 and f4 in the 3D network shown in Figure 1(b). Compute output arrival curves of contention ﬂows: With the contention tree built in Figure 3(b), we compute the arrival curve of each contention ﬂow, f2 , f3 and f4 , to the trunk after passing through 6 intra-layer routers of the branches as 2 = α2 (cid:2) β α 3 = α3 (cid:2) β α 4 = α4 (cid:2) β α 32 {5→24} = γb∗ = γb∗ = γb∗ 2 ,r2 = γb2 +6r2 T ,r2 , 60 {33→52} 3 ,r3 = γb3+6r3 T ,r3 , 64 {37→56} 4 ,r4 = γb4+6r4 T ,r4 , = γ0, ¯R ⊗ δ6T . (10) where β = β = β Derive equivalent service curve: The three contention ﬂows, f2 , f3 and f4 , form the nested interference pattern to the tagged ﬂow f1 . We can compute the equivalent service curve for f1 as {5→24} {33→52} {37→56} ˜β {1→64} 1 =  with⎧⎪⎨ ⎪⎩β 64 = γ0, ¯R ⊗ δT , = γ0, ˘R ⊗ δT , β = β = γ0,R(cid:3) ⊗ δ7T , where R β (cid:5)  (cid:2) (β 64 4 ) ⊗ β , α 64 60 , α 60 3 (cid:3) ⊗ β 32 , α 32 2 (cid:6) ⊗ β {1→28} , (11) 60 32 {1→28} (cid:6) = ¯R ∧ ˘R. (12) Compute the delay bound: After obtaining the equivalent service curve to f1 , we derive the delay bound for f1 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 559 10 0.3 0.5 0.7 0.9 1.1 20 30 40 50 60 70 80 90 100 η D y a e l , n u t i e c y c = l (a) k = 8, b = 5 Calculated delay bound in 2D NoC Calculated delay bound in 3D NoC Max. simulated delay in 2D NoC Max. simulated delay in 3D NoC Ave. simulated delay in 2D NoC Ave. simulated delay in 3D NoC 0 4 8 16 24 32 20 40 60 80 100 120 140 160 k D y a e l , n u t i e c y c = l (b) η = 0.5, b = 5 Calculated delay bound in 2D NoC Calculated delay bound in 3D NoC Max. simulated delay in 2D NoC Max. simulated delay in 3D NoC Ave. simulated delay in 2D NoC Ave. simulated delay in 3D NoC 10 1 2 3 4 5 20 30 40 50 60 70 80 Burstiness b, unit = flit D y a e l , n u t i e c y c = l (c) k = 8, η = 0.4 Calculated delay bound in 2D NoC Calculated delay bound in 3D NoC Max. simulated delay in 2D NoC Max. simulated delay in 3D NoC Ave. simulated delay in 2D NoC Ave. simulated delay in 3D NoC Figure 4: Calculated delay bounds, average and maximum simulated delays in the 2D and D NoCs. as ¯D3d = H (α1 , ˜β b ¯R {1→64} ∗ 1 ) = 10T + 4 + b ∧( ˘R, ¯R · ∗ 3 ˘R ˘R+r4 ) + b , ˘R · ∗ 2 ∧( ˘R, ¯R · ˘R ˘R ˘R+r3+r4 ˘R+r3 R(cid:3)+r2+r3+r4 , ¯R · ˘R ˘R ˘R R(cid:3)+r2+r3 , ˘R · ˘R+r4 ˘R+r3 ˘R+r2 ˘R ˘R+r3 , ¯R · ˘R ˘R+r4 · ˘R ˘R+r3 ) + b1 ∧ ⎛ ⎜⎜⎝ ¯R · R(cid:3) ˘R ˘R+r3+r4 ˘R ˘R+r4 · R(cid:3) , ¯R · R(cid:3) · R(cid:3) R(cid:3) +r2 , ˘R · R(cid:3) × 4 3D NoCs. The (13) We extend Eq. (13) for the k worst-case delay bound ¯D3d (k) can be calculated as R(cid:3)+r2 , R(cid:3) +r2+r3 , R(cid:3) +r2 , R ¯R · ˘R · · · · R(cid:3) (cid:6) ⎞ ⎟⎟⎠ . 2 × k 2 ¯D3d (k) = (k + 2)T + b ¯R ∗ 4 + b ∧( ˘R, ¯R · b , ˘R · ∗ 3 ˘R ˘R+r4 ) + ∗ 2 ∧( ˘R, ¯R · ˘R ˘R ˘R+r3+r4 ˘R+r3 R(cid:3)+r2+r3+r4 , ¯R · ˘R ˘R ˘R R(cid:3) +r2+r3 , ˘R · ˘R+r4 ˘R+r3 ˘R+r2 ˘R ˘R+r3 , ¯R · ˘R ˘R+r4 · ˘R ˘R+r3 ) + b1 ∧ ⎛ ⎜⎜⎝ ¯R · R(cid:3) ˘R ˘R+r3+r4 ˘R ˘R+r4 · R(cid:3) , ¯R · R(cid:3) · R(cid:3) R(cid:3) +r2 , ˘R · R(cid:3) R(cid:3) +r2 , R(cid:3) +r2+r3 , R(cid:3) +r2 , R ¯R · ˘R · · · · R(cid:3) (cid:6) ⎞ ⎟⎟⎠ , (14) where b ∗ i = bi + (k − 2)riT , i = 2, 3, 4. (15) 5. EXPERIMENTAL RESULTS 5.1 Experiment Purpose and Setup We performed experiments, both simulation and analysis, for our case study. With analysis and simulation results, we prove the correctness and tightness of the calculated bounds. Also, we show that, in the case study, the 3D average delays are all better than 2D but not for the worst-case delays. With numerical results, we explore the potential of closedform formulas. To simplify our discussions, we assume all ﬂows are bounded by the same linear arrival curve αi (t) = γb,r (t) = b + rt (i = 1, 2, 3, 4). All routers are uniform, oﬀering a latency-rate service curve β j (t) = γ0,R ⊗ δT (t) = R(t − T )+ (1 ≤ j ≤ k2 ). When R = ¯R, it is horizontal service curve, and when R = ˘R, it is vertical service curve. Flits are injected from each IP core to the network at a rate r of 0.1 ﬂit/cycle. T can be considered as the routing delay for head ﬂits. Here we set T = 2 cycles. The horizontal link bandwidth ¯R = 1 ﬂit/cycle, and the vertical link bandwidth ˘R = η ¯R (η > 0). In the experiments, we investigate the impact of vertical link bandwidth, network size and traﬃc burstiness on the network performance. 5.2 Analysis and Simulation Results We construct a simulation environment and design simulations varying the vertical to horizontal link bandwidth ratio η , network size k and traﬃc burstiness b. Each simulation runs to 100k cycles. We investigate both average delay (D 2d for 2D and D 3d for 3D) and observed maximum delay for 2D and Dmax for 3D) experienced by ﬂits of the tagged ﬂow in the simulations. We report results in Figure 4, where we also depict the delay bounds, ¯D2d for 2D and ¯D3d for 3D, calculated by Eq. 7 and Eq. 14, respectively. We can observe, in all cases, that (1) ¯D2d > D and 3d . This is to say that the calculated delay bounds envelop the maximum simulated delays. To quantify the tightness of the delay bounds, we calculate and get 2d / ¯D2d ∈ [0.89, 0.94] and D 3d / ¯D3d ∈ [0.84, 0.97]. On D average, the tightness of the delay bounds for 2D and 3D is 92.5% and 92.0%, respectively. This means that both 2D and 3D bounds are rather tight; (2) Dave 2d , i.e., the 3D average delay Dave 3d is smaller than the 2D average delay D 2d . Next, let us examine the maximum delays in each case in detail. Figure 4(a) investigates the eﬀect of vertical link bandwidth. In this setup, k = 8, b = 5 and η varies from 0.3 to 1.1. Note that the minimum vertical-to-horizontal bandwidth ratio ηmin is 0.3, since there are three ﬂows (f1 , f2 , f3 ) with rate 0.1 ﬂit/cycle passing the vertical link from layer 3 to layer 4, as illustrated in Figure 1(b). Though D 3d < D 2d for all η , the 3D maximum simulated delay D 3d > D 2d when η < 0.6. This tells us that the vertical link bandwidth may limit worst-case performance because of contention from different layers. For the 2D case, varying η has no eﬀect. This is why the three lines for D 2d , D 2d and ¯D2d are ﬂat. Figure 4(b) shows the eﬀect of network size. We scale k from 4 (16 nodes) to 32 (1024 nodes) when η = 0.5 and b = 5. As we can see, increasing the network size increases average and maximum delays due to the increasing distance from the sources to the destination. We can also see that, ave (Dmax 2d ave 3d max 2d ¯D3d > Dmax max max 3d < Dave ave ave ave max max max ave 560 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers                   (a) k = 8 Delay bound in 2D NoC Delay bound in 3D NoC (b) (cid:75) = 0.5 Delay bound in 2D NoC Delay bound in 3D NoC (c) Burstiness b = 5 f lits Delay bound in 2D NoC Delay bound in 3D NoC l e c y c = t i n u , d n u o b y a e l D 100 80 60 40 20 5 4 Burstinessb,unit=flit 3 2 1 0.4 0.6 1 0.8 (cid:75) l e c y c = t i n u , d n u o b y a e l D 1.6 1.4 1.2 160 140 120 100 80 60 40 20 5 Burstinessb,unit=flit 4 3 2 1 5 10 15 k 200 150 100 50 l e c y c = t i n u , d n u o b y a e l D 30 30 25 20 20 k 10 0.6 0.4 1 0.8 (cid:75) 1.6 1.4 1.2 Figure 5: Calculated delay bounds for diﬀerent settings in the 2D and 3D NoCs max max max max k ≤ 8, D for bigger sizes k > 8, D 3d < D 2d ; but for smaller sizes 3d > D 2d . This is because, for smaller-size networks, the bottleneck due to the vertical link bandwidth of η = 0.5 plays a bigger role than in larger-size networks. Figure 4(c) depicts the eﬀect of traﬃc burstiness. We set k = 8, η = 0.4 and b varies from 1 to 5. The increase in burstiness increases delays in the 2D and 3D networks because of increased blocking time. Also, as b increases, the increase in the maximum delay and delay bound in the 3D and ¯D3d , accelerates more than their 2D networks, D and ¯D2d , respectively. This is due to the counterpart, D fact that the bottleneck eﬀect of approaching the narrow vertical link bandwidth lower bound (ηmin = 0.3) becomes more signiﬁcant as higher burstiness increases contention. max 3d max 2d ⎧⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎩ plane from the bottom when 4 ≤ k ≤ 6 and 0.3 < η ≤ 0.8, 4 ≤ k ≤ 8 and 0.3 < η ≤ 0.7, 4 ≤ k ≤ 14 and 0.3 < η ≤ 0.6, 4 ≤ k ≤ 26 and 0.3 < η ≤ 0.5, 4 ≤ k ≤ 32 and 0.3 < η ≤ 0.4. This suggests that the bottleneck eﬀect of vertical link bandwidth is more signiﬁcant in smaller-size 3D networks. In summary, we can conclude that the 3D worst-case delay bound, ¯D3d , becomes worse than the 2D worst-case delay bound, ¯D2d , for lower vertical link bandwidth, smaller topology size and larger traﬃc burstiness. (17) 5.3 Numerical Results After validating our delay-bound formulas in Section 4, we can use them to quickly investigate the inﬂuence of the three parameters, (k, η , b), and their combined eﬀects. In the following, we show numerical results for the tagged ﬂow’s worst-case delay bounds, ¯D2d and ¯D3d , varying two of the three parameters together in each sub-ﬁgure in Figure 5. Combined eﬀect of vertical bandwidth and traﬃc burstiness : Figure 5(a) shows the delay bounds when k = 8, η varying from 0.3 to 1.6 and b from 1 to 5. As η and b increase, the 3D delay-bound plane gradually cuts through the in the ranges ⎧⎪⎨ 2D delay-bound plane from the bottom. When η and b vary ⎪⎩0.5 < η ≤ 0.6 and 3 ≤ b ≤ 5, 0.4 < η ≤ 0.5 and 2 ≤ b ≤ 5, 0.3 ≤ η ≤ 0.4 and 1 ≤ b ≤ 5, ¯D3d > ¯D2d , i.e., the 3D delay-bound is greater than the 2D delay-bound. The biggest diﬀerence occurs at the extreme point, i.e., η = 0.3 and b = 5. Combined eﬀect of network size and traﬃc burstiness : Figure 5(b) draws the delay bounds when η = 0.5, k varying size networks (k ≥ 16), ¯D3d < ¯D2d when 1 ≤ b ≤ 5. But for from 4 to 32 and b from 1 to 5. We can see that, for biggersmaller-size networks (k ≤ 6), ¯D3d > ¯D2d when 1 ≤ b ≤ 5. greater than ¯D2d is sensitive to the value of b (1 ≤ b ≤ 5). For medium-size networks (6 < k < 16), whether ¯D3d is Combined eﬀect of vertical link bandwidth and network size : Figure 5(c) depicts the delay bounds when b = 5, η varying from 0.3 to 1.6 and k from 4 to 32. The 3D delaybound plane gradually cuts through the 2D delay-bound (16) 5.4 Discussions for Optimized 3D Routers In the paper, we have assumed a 7-port 3D router, which is a natural extension to a 5-port 2D router by adding two ports to make connections to the upper and lower layers. With such routers, moving between adjacent layers takes one hop, and moving through multiple layers takes multiple hops. Research based on such 7-port 3D routers can be found in [14, 15, 20, 31]. To explore the third dimension, other “optimized” 3D routers have been proposed in [13, 9, 22]. In [13], a hybrid router is introduced which uses a bus for vertical connections. Thus moving from one layer to any of the other layers takes only one hop. However, such routers inherently suﬀer from the limitation of buses since only one transmission is allowed each time over a vertical bus. In [9], a “true” 3D router is proposed. It is called “true” 3D router because it uses the intersections of the crossbar in routers to directly make layer-to-layer connections like a three dimensional matrix. Such routers can signiﬁcantly minimize vertical traversal to one hop between any layers. However, such routers require huge number of vertical connections and also overwhelmingly complicate the control and arbiter of the routers. Very recently, a multi-layer 3D router (MIRA) is reported in [22]. This router classiﬁes the router components into separable components such as input buﬀers, crossbar and inter-router links, and non-separable components such as arbiter and routing logic. Then the separable components are laid out across multiple layers over the vertical dimension. Such a ﬁne-grained component arrangement saves chip area and can be used to reduce power by dynamically shutting down some inactive layers. However, such routers are too aggressive in the current technology. It is only possible as 3D technology matures with smaller TSV pitches [2]. Due to the above concerns, we have chosen a 2009 IEEE/ACM International Conference on Computer-Aided Design Digest of Technical Papers 561                         conventional 7-port router for our discussions. Such routers are economically feasible and technically mature. For the TSV vertical links, the main concern here is not their absolute bandwidth. Rather it is the bandwidth ratio between vertical and horizontal links. Though the TSV vertical transmission can be fast, the number of vertical connections may be limited due to the area overhead and yield problem. Horizontal connections are slower, but we can use wider links, for example, 128 wires per link [21]. Considering these factors, we have varied the ratio of vertical to horizontal bandwidth, η , from 0.3 to 1.6. In this way, we have experimented on a reasonably wide spectrum of the relative bandwidth. 6. CONCLUSION Through a detailed case study for k-ary-2-mesh networks we have shown that transforming a 2D NoC into a 3D NoC may not improve the worst-case performance while improving the average performance. The worst-case delay is more sensitive to the vertical link bandwidth, the network size and traﬃc burstiness. This suggests that a thorough investigation on not only average but also worst-case performance is necessary when dimensioning the network topology from 2D to 3D. We have assumed large enough buﬀers at routers. This removes the eﬀect of back-pressure but allows to investigate the accumulated eﬀect of traﬃc burstiness, which may result in worst-case blocking time for sharing links. If the buﬀers are not large enough, back-pressure will cause more blocking and worsen buﬀer sharing, thus further increasing average and worse-case delays. While transforming the 2D NoC to the 3D NoC, we have not explored the design space of partitioning the 2D network into diﬀerent layers and then mapping the network layers to silicon planes. Since aﬀecting the network distance between nodes, the partitioning and mapping will inﬂuence both average and worst-case performance. These aspects need to be explored while transforming 2D NoCs to 3D NoCs. 7. "
2010,Efficient trace-driven metaheuristics for optimization of networks-on-chip configurations.,"As industry moves towards many-core chips, networks-on-chip (NoCs) are emerging as a scalable communication fabric for interconnecting the cores. With increasing core counts, there is a corresponding increase in communication demands in multi-core designs to facilitate high core utilization, and a consequent critical need for high-performance NoCs. Another megatrend in advanced technologies is that power has become the most critical design constraint. In this paper, we focus on trace-driven virtual channel (VC) allocation in application-specific NoCs. We propose a new significant VC failure metric to capture the impact of VCs on network performance and efficiently drive NoC optimization. Our proposed metaheuristics achieve up to 38% reduction in the number of VCs under a given average packet latency constraint. In addition, compared to a recently proposed trace-driven VC allocation approach, we obtain up to an O(|L|) speedup, where |L| is total number of links in the network, with no degradation in the quality of results.","Efﬁcient Trace-Driven Metaheuristics for Optimization of Networks-on-Chip Conﬁgurations Andrew B. Kahng, Bill Lin, Kambiz Samadi and Rohit Sunkam Ramanujam ECE Depar tment, University of California San Diego, La Jolla, CA Email: {abk,billlin,ksamadi,rsunkamr}@ucsd.edu ABSTRACT As industry moves towards many-core chips, networks-on-chip (NoCs) are emerging as a scalable communication fabric for interconnecting the cores. With increasing core counts, there is a corresponding increase in communication demands in multi-core designs to facilitate high core utilization, and a consequent critical need for high-performance NoCs. Another megatrend in advanced technologies is that power has become the most critical design constraint. In this paper, we focus on trace-driven virtual channel (VC) allocation in application-speciﬁc NoCs. We propose a new significant VC failure metric to capture the impact of VCs on network performance and efﬁciently drive NoC optimization. Our proposed metaheuristics achieve up to 38% reduction in the number of VCs under a given average packet latency constraint. In addition, compared to a recently proposed trace-driven VC allocation approach [13], we obtain up to an O(|L|) speedup, where |L| is total number of links in the network, with no degradation in the quality of results. 1. INTRODUCTION Networks-on-Chip (NoCs) are emerging as the de facto interconnection fabric of choice for both general-purpose chip multiprocessors (CMPs) [16, 26, 28] and application-speciﬁc multiprocessor systems-on-chip (MPSoCs) [6, 20]. With increasing core counts, there is a corresponding increase in communication demands in multi-core designs to facilitate high core utilization and the corresponding critical need for high-performance NoCs. At the same time, power has become the most critical design constraint in advanced technologies [9, 32], with power affecting virtually all “grand challenges” for NoC design. The design of an on-chip network can be broken into its various building blocks: topology, routing, ﬂow control, router microarchitecture, and link architecture. Among these building blocks, router microarchitecture is of utmost importance due to its signiﬁcant impact on communication latency. As a result, signiﬁcant research effort has been spent to reduce router latency through modiﬁed router architectures and designs [8]. NoCs can be designed for generalpurpose CMPs [16, 26, 28] or application-speciﬁc MPSoCs [6, 20]. The challenges are different in each case. Since general-purpose CMPs are designed to run a wide range of applications, the application trafﬁc characteristics are inherently unknown a priori. Hence, the conﬁgurations of on-chip routers, such as the number of virtual channels, are typically uniform across all routers in the design. On the other hand, since application-speciﬁc MPSoCs are designed to implement speciﬁc functions efﬁciently, the conﬁguration of each router in the network can be non-uniformly optimized to the trafﬁc characteristics of the particular application. With power being a ﬁrst-order design constraint, network resources must be carefully allocated to minimize overall power with no or minimal loss in performance. Though the problem of NoC conﬁguration for application-speciﬁc MPSoCs is not new, prior approaches [4, 10, 11] have been average-rate driven in that the trafﬁc characteristics have been modeled with average data rates. Unfortunately, average-rate models are poor representations of actual trafﬁc characteristics for real applications. Figure 1 contrasts actual vs. average trafﬁc of two real applications from the PARSEC [3] benchmark suite. The actual trafﬁc behavior tends to be very bursty, with substantial ﬂuctuations over time. This motivates a hypothesis that average-rate driven approaches may be misled by average trafﬁc characteristics, resulting in poor design choices that are not well-matched to the actual trafﬁc characteristics. To illustrate the potential suboptimality of average-rate driven approaches, we consider the problem of application-speciﬁc VC allocation. In a typical design of virtual channel routers, a ﬁxed amount of hardware resources (i.e., queues) is set aside to implement the VC buffers. With power now the ﬁrst-order design constraint, the decision that needs to be made is how to allocate these resources such that certain performance criteria are satisﬁed while the number of allocated VCs is kept at a minimum. In particular, we are interested in metrics that reﬂect the performance of the actual application, for example the average packet latency with respect to a given application trace. In particular, we considered the following problem. Given: • Application trace, Atrace • Network topology, T (C, L), where C is the set of processing cores and L is the set of physical links • Deterministic X Y routing algorithm, R • Target latency constraint, Dtarget Determine: • A mapping nV C from the set of links L to a set of positive integers, i.e., nV C : L → Z + , where for any l ∈ L, nV C (l) gives the number of VCs associated with link l, such that l∈L nV C (l) is minimized while average packet latency using routing algorithm R, D(nV C , R), is within a target latency constraint Dtarget P 978-1-4244-819 - /10/$26.00 ©2010 IEEE 4 1 256 Objective: • Minimize P l∈L nV C (l) • D(nV C , R) ≤ Dtarget Subject to: To quantify the limitations of average-rate driven approaches, Kahng et al. [13] have recently proposed two application-speciﬁc VC allocation heuristics as just one facet of the router conﬁguration problem. The authors of [13] have also evaluated an existing average-rate driven VC allocation method [11] on the applications in the PARSEC benchmark suite. The evaluation is based on minimizing the total number of virtual channels allocated to achieve a given average packet latency performance. The results in [13] show that the same average packet latency performance achieved using an average-rate driven optimization method can be matched by their trace-driven heuristics with 35% fewer VCs and a corresponding reduction in buffer (and, power and area) requirements. Despite being quite successful in capturing the application speciﬁcity, simple trace-driven approaches [13] incur signiﬁcant runtime cost compared with average-rate approaches. There are two ways to enhance the runtime of the proposed trace-driven optimization schemes: (1) improve the runtime of trace simulation, and (2) use different metrics to capture the average packet latency such that fewer trace simulations are required to make optimization decisions. In this paper, we focus on (2) and propose efﬁcient tracedriven metaheuristics for the problem of router VC allocation which substantially improve the runtime complexity of the approach proposed in [13] with no degradation in quality of results. The contributions of our work are listed below. • We propose two metrics: (1) signiﬁcant VC failure (SVCF), and (2) queueing delay to capture the impact of addition of a single VC on average packet latency. In addition, we show that these metrics can appropriately account for actual runtime VC resource contentions. • We develop architecture-level optimization techniques based on a trace-driven paradigm that directly incorporates actual application-trafﬁc behavior and workloads into the optimization process. • We evaluate our proposed heuristics on a set of real applications. In particular, we evaluate our methods on the PARSEC benchmark suite, which contains multi-threaded programs that are representative of emerging workloads. • We also compare our proposed heuristics with a recently proposed trace-driven approach [13] and observe an O(|L|) speedup with no degradation in the quality of results, where |L| is the total number of links in the network. The remainder of this paper is organized as follows. In Section 2, we contrast against prior related work. Section 3 describes our proposed efﬁcient trace-driven non-uniform VC allocation heuristics. In Section 4, we propose two efﬁcient metaheuristics using our basic heuristics described in Section 3, and show that they can provide signiﬁcant runtime improvement compared with a recently proposed trace-driven approach [13]. Section 5 shows our experimental setup and testcases and presents our results. Finally, Section 6 concludes the paper. 2. RELATED WORK Among the various components of an input-buffered router, the conﬁguration of input buffers has been shown to have a major impact on both the overall performance of an on-chip network as well as its energy consumption [9, 15, 18, 12]. Therefore, determining ) l s e c y c 0 0 0 0 1 / s t i l f ( c i f f a r T 1600 1400 1200 1000 800 600 400 200 0 0 vips Mean - vips bs Mean - bs 200000 400000 600000 time (cycles) 800000 1000000 Figure 1: Actual versus average communication trafﬁc between two arbitrary nodes in the network, for two different PARSEC benchmark applications. the optimal buffer size and VC allocation is of critical importance in maximizing performance and minimizing of power consumption. For buffer sizing, a number of methods have been proposed in the literature. • Chandra et al. [4] propose a sizing algorithm based on bursty transmission rates of packets. A signiﬁcant drawback of this work is their use of synthetic trafﬁc models, which can potentially impact the relevance of their solution. • Manolache et al. [17] propose a trafﬁc shaping methodology in which packets are delayed at the source to avoid contention between different ﬂows, as to reduce the total amount of buffer usage along intermediate nodes. • Hu et al. [10] propose a probabilistic approach for the sizing of input buffers along the intermediate nodes of a network. Their main goal is to minimize the average packet latency of all packet transmissions in the network while remaining under an overall target buffer area budget. However, in their work [10], their method assumes packets as atomic units of storage (i.e., store-and-forward). On the other hand, modern routers use ﬂit-level ﬂow control to achieve better latency performance and area. For VC allocation, several approaches have also been proposed. • Huang et al. [11] propose a queueing-based algorithm for VC allocation. Their focus is on determining the number of VCs to allocate to each link, with the assumption that the network topology, the mapping of tasks to the NoC, and the choice of deterministic routing are all given. They proposed a greedy algorithm that increases the number of VCs allocated to a given link only if the addition reduces the average packet latency. • Al Faruque et al. [2] proposed a two-step VC allocation approach that aims to minimize the number of VCs required to achieve a certain quality of service (QoS) level. Their VC allocation approach is carried out during the task mapping stage. By assuming a Poisson packet arrival process, they try to estimate the size of each VC for each output port. The main shortcoming of this approach is their reliance on Markovian assumptions for multimedia applications. These assumptions have been shown to be unreliable by other works (e.g., [30]). 257     • In addition to static buffer and VC allocation approaches discussed above, which are decided at design time, several methods have been proposed to dynamically allocate buffers and number of VCs at runtime. Several methods have been proposed [25, 21, 7] for dynamic buffer space allocation. For example, the dynamically allocated multi-queue approach [25] uses linklists to allocate VCs to each port. However, to update the logical pointer to the free list, a 3-cycle delay is incurred at every ﬂit arrival/departure, making this method unsuitable for high-performance applications. • The fully-connected circular buffer approach [21] uses registers to selectively shift ﬂits within buffers. However, this 2 × P crossbar instead of a consolution requires a large P ventional P × P crossbar, where P is the number of ports. It also requires existing ﬂits to be shifted when new ﬂits arrive. Hence, this approach has signiﬁcant latency and power overhead. • Finally, Nicopolous et al. [22] propose a dynamic VC allocation approach called ViChaR in which the number of VCs and the depth of buffers per VC are dynamically adjusted based on the trafﬁc load. However, since there can be as many VCs as there are ﬂit buffers, control logic becomes complicated. In summary, runtime dynamic allocation of buffers seems more desirable for general-purpose and reconﬁgurable design platforms that execute different workloads. However, design-time allocation of VCs appears more desirable for application-speciﬁc NoCs that are intended to implement a speciﬁc application or a limited class of applications. In this paper, we propose efﬁcient VC allocation metaheuristics that can signiﬁcantly reduce the number of VCs needed to achieve a target performance for a given application. 3. TRACE-DRIVEN VC ALLOCATION In this section, we propose a new metric called signiﬁcant VC failure (SVCF) to implicitly capture the impact that VC allocation has on network performance. Using this new metric, as well as an existing queueing delay metric, we propose new efﬁcient heuristics that can signiﬁcantly reduce the number of simulations that are needed in a general trace-driven optimization approach. These heuristics are described in the following three subsections. 3.1 SVCF-Driven VC Allocation We propose to apply the concept of signiﬁcant VC failure (SVCF) to implicitly capture the impact of virtual channels on average packet latency. A signiﬁcant VC failure occurs when a new packet cannot acquire a virtual channel because all virtual channels that use the same output link are already held by packets that are “blocked” from proceeding further by downstream contentions. In this scenario, the output link unnecessarily remains idle until a packet that already holds a virtual channel can proceed. To give a ﬂavor of what we mean by a signiﬁcant VC failure, consider the example shown in Figure 2. Suppose we have three packets with the following (source, destination): (A, F ), (B , D), and (E , D), with all three packets 10-ﬂits in size. Packet (E , D) is injected at time 0, and Packets (A, F ) and (B , D) are injected at time 1. We assume in this example that links only have a single VC (i.e., wormhole conﬁguration) with 10 ﬂits per VC. Link 2 will carry two packets from (A, F ) and (B , D), and Link 3 will also carry two packets from (B , D) and (E , D). We observe that Packet (A, F ) is “blocked” from proceeding because Link 2 is held by Packet (B , D) which itself is “blocked” from proceeding since Packet (E , D) has already held Link 3. Note that, as long as Packet (B , D) is blocked, Packet (A, F ) is also blocked even though it is heading to a different destination. Only when all 10 ﬂits of Packet (E , D) have traversed Link 3, then Packet (B , D) can proceed; however, Packet (A, F ) needs to wait until all ﬂits of Packet (B , D) have traversed Link 2 before it can proceed to its destination, F . However, if we add one VC to Link 2 then Packet (A, F ) can bypass Packet (B , D) while Packet (B , D) is being blocked by Packet (E , D). Each time that Packet (A, F ) tries to acquire a VC, a signiﬁcant VC failure occurs until Packet (B , D) leaves Link 2. On the other hand, when Packet (B , D) requests for a VC on Link 3, the VC failure is not considered signiﬁcant because Packet (E , D) is using Link 3. P(B, D) A B 1 2 P(A, F) P(E, D) E 4 D C F 3 5 Figure 2: An example of signiﬁcant VC failure. Algorithm: SVCF-Driven Input: Application trace, Atrace ; Network topology, T (C, L); Deterministic routing algorithm, R; Target latency constraint, Dtarget Output: VC conﬁguration vector, nV C , which contains the number of VCs associated with each link l ∈ L for l = 1 to |L| 1. 2. 3. NV C = |L|; ncurrent V C [l] = 1; ﬁnd l ncurrent SV CF 5. 6. 7. 8. NV C ++; 9. } ncurrent V C 4. while (NV C ≤ budgetV C ) { = C omputeSV C F (ncurrent ); ∗ that maximizes nSV CF [l ∗ ]; V C ∗ ] = ncurrent V C [l ∗ ] + 1; [l Figure 3: Signiﬁcant VC failure-driven VC allocation heuristic. V C Figure 3 shows the SVCF-driven VC allocation heuristic. The algorithm initializes every link, l, with one VC; this is equivalent to wormhole routing (Line 2). Hence, the total number of VCs in the network, NV C is initialized to the total number of links, |L|. Then, the algorithm proceeds in a greedy fashion: in each iteration the signiﬁcant failures of all the |L| possible links in the current conﬁguration, ncurrent , are calculated using C omputeSV C F (Line 5). We use trace simulations to evaluate C omputeSV C F . Subsequently, one VC is added to the link with the maximum number of ∗ ]. The algorithm stops when the total signiﬁcant failures, nSV CF [l number of allocated VCs exceeds the VC budget, budgetV C . Figure 4 shows the average packet latency of each intermediate conﬁguration using SVCF-driven heuristic and the approach proposed by [13] for two different traces, ferret and blackscholes (bs) from the PARSEC benchmark suite. We observe that our proposed SVCF-driven heuristic can achieve up to 20% and 23% reduction in number of allocated VCs compared with 160 VCs required for uniform-2VC and 208 VCs required for uniform-3VC conﬁgurations, respectively. In addition, we achieve average packet 258 latency values within 9% of those achieved by [13] while providing a speedup of O(|L|). As network size increases, the method proposed by [13] requires signiﬁcantly more computing resource, i.e., O(|L|) simultaneous simulations, compared with only 1 simulation per iteration in our proposed SVCF-driven heuristic. We note that our proposed SVCF-driven heuristic cannot reduce the average packet latency as much as the method of [13], and we attribute this to: (1) the fact that we are not directly minimizing average packet latency, and (2) links with highest SVCF count may not have the heaviest trafﬁc load, and thus cannot reduce AP L as much. 140 160 SVCF-driven - ferret [12] - ferret SVCF-driven - bs [12] - bs s e e c y c ) 100 120 t t y c n e a L ( l 60 80 P e k c a t 0 0 20 40 A e v r e g a 130 135 140 145 150 155 160 Number of VCs 165 170 175 180 Figure 4: Performance of SVCF-driven VC allocation heuristic on f erret and blackscholes traces. 3.2 Queueing Delay-Driven VC allocation In this subsection, we describe another simple VC allocation heuristic in which we use the queueing delays observed at each link to drive the VC allocation. In a conventional input-buffered router, queueing delay is the time a ﬂit needs to wait in the buffers before it gets access to its designated output link. The queueing delay of a ﬂit at link l of a router is measured as the difference between the time a ﬂit enters the input buffer of the router until it departs the router through output link l. The queueing delay of a link l is the sum of the queueing delays of all ﬂits passing through link l. This approach is structurally similar to the SVCF-driven heuristic except that we use queueing delay as the driving metric. However, the queueing delay-driven approach can better capture bottleneck links early in the VC allocation process as shown in Figure 5. We note that our proposed queueing delay-driven heuristic fails to improve average packet latency after certain number of VCs have been allocated. This is because after a few VC allocations the bottleneck shifts from the nodes with heavy trafﬁc to downstream nodes; however, VC failure at downstream nodes causes the queueing delay of the ﬂits residing in the source nodes to increase. Hence, our proposed queueing delay-driven approach will allocate VCs to links in source nodes instead of links in downstream nodes. Figure 5 shows the average packet latency of each intermediate conﬁguration using queueing delay-driven, SVCF-driven heuristic as well as the approach proposed by [13] for canneal trace from the PARSEC benchmark suite. 3.3 Top-k Selection Heuristic In this subsection, we propose an efﬁcient, and yet simple approach for improving the performance of our SVCF- and queueing delay-driven heuristics. The hypothesis is that we can signiﬁcantly improve the quality of solutions obtained by SVCF- and queueing delay-driven heuristics by simultaneously evaluating more than one of their suggested solutions. In other words, we will evaluate the top-k solutions and determine the best solution based on the maximum reduction in average packet latency. Figure 6 shows our top-k SVCF-driven VC allocation heuristic. The algorithm initializes every link, l, with one VC (Line 2). Hence, the total number of VCs in the network, NV C is initialized to the s e e c y c ) 250 SVCF-driven - canneal Queueing delay-driven - canneal [12] - canneal y c n e e a L ( l 150 200 P e k c a t t 100 A e v r e g a 50 0 114 119 124 129 134 139 Number of VCs 144 149 154 159 Figure 5: Comparison of SVCF-driven, queue delay-driven, and [13] VC allocation heuristics on canneal trace. total number of links, |L|. Then, the algorithm proceeds in a greedy fashion: in each iteration, signiﬁcant VC failure values corresponding to each link in the current conﬁguration, ncurrent , are computed using C omputeSV C F , where we use trace simulation to evaluate C omputeSV C F (Line 5). Then, we ﬁnd the top k links that have the highest number of signiﬁcant VC failures (Line 6), and add one VC to each of these k conﬁgurations (Line 8). Next, we run k parallel trace simulations to evaluate the quality of each conﬁguration, and pick the one that minimizes the average packet latency the most (Line 11). In the shown pseudocode (Figure 6), C omputeAP L performs trace simulation on a given VC conﬁguration and reports the average packet latency for that VC conﬁguration. The algorithm stops when the total number of allocated VCs exceeds budgetV C . V C Algorithm: Top-k SVCF-Driven Input: Application trace, Atrace ; Network topology, T (C, L); Deterministic routing algorithm, R; Target latency constraint, Dtarget Output: VC conﬁguration vector, nV C , which contains the number of VCs associated with each link l ∈ L 1. 2. 3. NV C = |L|; for l = 1 to |L| ncurrent V C [l] = 1; 4. while (NV C ≤ budgetV C ) { = C omputeSV C F (ncurrent 5. 6. 7. 8. 9. 10. 11. ncurrent SV CF V C ); ﬁnd top-k l i corresponding to top-k nSV CF [l for i=1 to k { ∗ ∗ i ]; ncurrent V C [l [l ] + 1; AP L[i]=C omputeAP L(ncurrent ∗ i ] = ncurrent V C ∗ i V C [l ∗ i ]); } ﬁnd m ∗ i that minimizes AP L[m ]; ∗ i ] 12. ncurrent V C = ncurrent V C [l ∗ m 13. NV C ++; 14. } Figure 6: Top-k signiﬁcant VC failure-driven VC allocation heuristic. To determine an appropriate value for k , we perform a simple sensitivity analysis in which we run the heuristic for multiple k values with reduced trace length. In our sensitivity experiments, we are interested in the number of allocated VCs to satisfy an average 259             packet latency constraint for a given VC conﬁguration. We perform the sensitivity experiments for k ∈ {1, 3, 5, 8, 10, 15} and assess at which point the increase in k does not improve the quality of the solutions. Figure 7 shows the sensitivity analysis results for all PARSEC traces. The x-axis shows the value of k , and the y-axis is number of VCs required to satisfy the average packet latency of a uniform conﬁguration with 2 VCs per link. From Figure 7, we observe that for all of the traces, except for v ips, k= 5 gives the best tradeoff between quality of results and runtime, i.e., the reduction in average packet latency is within 2% beyond k = 5. For v ips trace, k = 10 gives an additional 8% improvement in average packet latency compared with k = 5; however, in our experiments we assume k = 5 for all the PARSEC benchmark traces. Similarly, we have performed sensitivity analysis for our queueing delay-driven heuristic and have determined that k = 15 offers the best tradeoff between quality of the results and runtime. The results presented are for a mesh network with 16 nodes and 64 links (details of the setup are explained in Section 5.1). C V # 60 50 40 30 20 10 0 0 bs canneal ferret fluid swap x264 vips 5 10 k (top-k selection heuristic) 15 Figure 7: Sensitivity analysis of the k parameter for the PARSEC benchmark traces. 4. EFFICIENT METAHEURISTICS In this section, we propose two efﬁcient and more robust VC allocation metaheuristics by combining the heuristics described in Section 3. 4.1 Hybrid Metaheuristic In our proposed hybrid metaheuristic, we combine the top-k SVCF-driven and queueing delay-driven VC allocation heuristics such that in each iteration we pick the best conﬁguration out of these two heuristics. The key to our hybrid metaheuristic is that SVCF-driven and queueing delay-driven VC allocation heuristics each performs quite well in different VC regimes. In other words, the SVCF-driven heuristic seems to perform well once there are already a few VCs inserted in the network, whereas the queueing delay-driven heuristic performs well in the beginning, i.e., where there are only few VCs in the network. Figure 8 shows our proposed hybrid metaheuristic. The algorithm initializes every link, l, with one VC; this is equivalent to wormhole routing (Line 2). Hence, the total number of VCs in the network, NV C is initialized to the total number of links, |L|. Then, the algorithm proceeds in a greedy fashion: in each iteration, the signiﬁcant VC failures associated with all of the |L| possible links in the current conﬁguration, ncurrent , are calculated using C omputeSV C F (Line 5). In parallel, we also run C omputeQD all of the |L| possible links (Line 6). Subsequently, we ﬁnd the to determine the total queueing delay associated with (cid:4) corresponding top-k and top-k links with the highest number of signiﬁcant VC failure and queueing delay, respectively (Lines 7-8). on ncurrent V C V C (cid:4) Then, we run k + k parallel trace simulations in which we add (cid:4) one VC to each of the suggested k + k conﬁgurations and evaluate their impact on average packet latency (Lines 9-12 and 13-16). Finally, we pick the VC conﬁguration with the lowest average packet latency and set that as the starting conﬁguration for the next iteration. The algorithm stops when the total number of allocated VCs exceeds the VC budget, budgetV C . Algorithm: Hybrid Metaheuristic Input: Application trace, Atrace ; Network topology, T (C, L); Deterministic routing algorithm, R; Target latency constraint, Dtarget Output: VC conﬁguration vector, nV C , which contains the number of VCs associated with each link l ∈ L for l = 1 to |L| 5. 6. ncurrent V C [l] = 1; 4. while (NV C ≤ budgetV C ) { = C omputeSV C F (ncurrent = C omputeQD(ncurrent ncurrent SV CF ncurrent QD ); ﬁnd top-k l i corresponding to top-k nSV CF [l ﬁnd top-k i corresponding to top-k nQD [m for i=1 to k { V C V C m ); ∗ ∗ (cid:4) ∗ ∗ i ]; ]; i ncurrent V C [l [l ] + 1; AP L[i]=C omputeAP L(ncurrent ] = ncurrent V C i i V C ∗ i [l ]); ∗ ∗ ∗ } for i=1 to k (cid:4) { 1. 2. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. ncurrent V C [m [m ] + 1; AP L[i + k]=C omputeAP L(ncurrent ] = ncurrent V C i i V C [m ∗ i ]); } ∗ ﬁnd n i that minimizes AP L[n ]; = ncurrent V C [l ∗ n 18. ncurrent V C ∗ ∗ i ] 19. NV C ++; 20. } Figure 8: Hybrid metaheuristic using top-k SVCF-driven and queueing delay-driven VC allocation heuristics. 4.2 Multi-Stage Metaheuristic From previous subsections, we observe that our queueing delaydriven heuristic performs well starting from an initial conﬁguration (i.e., wormhole conﬁguration), and that our SVCF-driven heuristic performs well when there are already a number of VCs allocated. Knowing this, we propose a 2-stage metaheuristic in which we start with our top-k queueing delay-driven algorithm and will switch to top-k SVCF-driven algorithm once the difference in average packet latency of two consecutive conﬁgurations falls below a certain thershold, s. Figure 9 shows our proposed two-stage metaheuristic which is similar to our hybrid metaheuristic, but uses some constant number less trace simulations with no degradation in results. The algorithm initializes every link, l, with one VC; this is equivalent to wormhole routing (Line 2). Hence, the total number of VCs in the network, NV C is initialized to the total number of links, |L|. Then, the algorithm proceeds in a greedy fashion: in each iteration the algorithm picks either top-k SVCF-driven or top-k queueing delaydriven heuristic based on the average packet latency improvement threshold, s, which is deﬁned as the difference in average packet la260 tency for two consecutive iterations. Based on our previous ﬁndings (cf. Subsection 3.2), we start with queueing delay-driven heuristic ﬁrst (Lines 7-15). Once, the APL improvement threshold falls below the deﬁned value, the algorithm chooses the top-k SVCFdriven heuristic (Lines 19-26). We use trace simulations to evaluate both C omputeSV C F and C omputeQD . The algorithm stops when the total number of allocated VCs exceeds the VC budget, budgetV C . To ﬁnd an appropriate value for s, we have performed similar sensitivity analysis as described in Subsection 3.3, and have chosen s=0.5. Algorithm: Two-Stage Metaheuristic Input: Application trace, Atrace ; Network topology, T (C, L); Deterministic routing algorithm, R; Target latency constraint, Dtarget Output: VC conﬁguration vector, nV C , which contains the number of VCs associated with each link l ∈ L for l = 1 to |L| 1. 2. 4. switch = false; ncurrent V C [l] = 1; 5. while (NV C ≤ budgetV C ) { if (!switch) { ncurrent QD = C omputeQD(ncurrent ); ﬁnd top-k m i corresponding to top-k nQD [m for i=1 to k { V C ∗ ∗ i ]; ∗ ncurrent V C [l [l ] + 1; AP L[i]=C omputeAP L(ncurrent ] = ncurrent V C i i V C ∗ i [l ]); } ﬁnd n ∗ i that minimizes AP L[n ]; = ncurrent V C [l ∗ n ncurrent V C NV C ++; if (AP LNV C −1 − AP LNV C < s) switch=true; ∗ ∗ i ] ∗ V C ∗ i ] 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. } } else { ncurrent SV CF ﬁnd top-k for i=1 to k ∗ (cid:4) { ∗ = C omputeSV C F (ncurrent ); i corresponding to top-k nSV CF [l V C l (cid:4) ∗ i ]; ncurrent V C [m [m ] + 1; AP L[i]=C omputeAP L(ncurrent [m ] = ncurrent V C i i ∗ i ]); i that minimizes AP L[n ]; = ncurrent V C [l ∗ n } ∗ ﬁnd n ncurrent V C NV C ++; } Figure 9: Two-stage metaheuristic using top-k SVCF-driven and queueing delay-driven VC allocation heuristics. 4.3 Runtime Analysis As we have noted earlier, simple trace-driven approaches [13] require relatively larger runtime compared with average-rate approaches. In this paper, we focus on deﬁning new metrics (i.e., signiﬁcant VC failure and queueing delay) that can more efﬁciently 261 capture the impact of VC allocation on performance. The runtime complexities of our proposed heuristics are as follows. Let m be the number of VCs added to an initial VC conﬁguration. The runtime of our SVCF- and queueing delay-driven heuristics, TSV CF /QD , for any given input trace is expressed as follows: TSV CF /QD = m × T (tr) (1) where T (tr) is the average runtime of (cycle-accurate, ﬂit-level) trace simulation simulator over all VC conﬁgurations explored by the algorithm. The above two heuristics do not require O(|L|) simultaneous simulations as in [13], which results in an O(|L|) speedup. The runtime for our proposed top-k SVCF- and queueing delaydriven heuristics to insert m VCs is = m × k × T (tr) Ttop-k SV CF /top-k QC (2) which also results in an O(|L|) speedup (since k is a small constant) when compared with the method of [13]. Finally, the runtime of our proposed hybrid and two-stage metaheuristics to insert m VCs are Thybrid = m × (k + k (cid:4) ) × T (tr) Ttwo−stage = r × k × T (tr) + (m − r) × k (cid:4) × T (tr) (4) (cid:4) where k and k are derived using sensitivity analysis as explained earlier (cf. Subsection 4.1), and r denotes the number of iterations that the two-stage metaheuristic chooses the queueing delay-driven heuristic. (3) 5. EVALUATION AND DISCUSSIONS In this section, we describe our experimental setup, and then we evaluate the performance of our proposed metaheuristics with respect to (1) uniform VC conﬁgurations, and (2) simple trace-driven approach recently proposed by [13]. We show that our proposed approach can achieve the same quality of results with signiﬁcant runtime improvement (i.e., O(|L|)). 5.1 Experimental Setup To determine the average packet latency of a given application trace, we use PopNet [24], a ﬂit-level, cycle accurate on-chip network simulator. PopNet models a typical input-buffered VC router with four pipeline stages. Route computation and VC allocation are performed in the ﬁrst pipeline stage, followed by switch arbitration, switch traversal and link traversal. The head ﬂit of a packet proceeds through all four stages while the body ﬂits bypass the ﬁrst pipeline stage and inherit the output port and output VC reserved by the head ﬂit. Non-uniform VC conﬁgurations are implemented by individually conﬁguring the number of VCs at each router port. The routers are connected in a two-dimensional mesh topology and dimension-ordered routing is employed where packets are ﬁrst routed in the X dimension followed by the Y dimension. The latency of a packet is measured as the delay between the time the header ﬂit is injected into the network and the time the tail ﬂit is consumed at the destination. The AP L value reported by PopNet is the average latency over all packets in the input trafﬁc trace. To evaluate our VC allocation heuristics, we use seven applications from the PARSEC benchmark suite, namely, canneal, blackscholes, ﬂuidanimate, ferret, swaptions, vips and x264 [3]. These benchmarks are multithreaded programs encompassing diverse application domains and representative of emerging future workloads. The network trafﬁc traces were generated by running these programs on Virtutech Simics [33], a full system simulator, Table 1: Processor conﬁguration for generation of PARSEC benchmark traces. Number of Cores Private L1 cache Shared L2 cache Memory latency Network topology Packet sizes 16 32KB 1MB distributed over 16 banks 170 cycles 4×4 mesh 72B data packets, 8B control packets and capturing the program’s memory trace. The GEMS toolset [19] simulate a 16-core tiled CMP architecture arranged in a 4 × 4 mesh, runs on top of Simics and performs accurate timing simulation. We with parameters shown in Table 1. Each tile consists of an in-order SPARC core with private L1 and shared L2 cache. DRAM is attached to the chip using four memory controllers that are at the corners of the mesh. For the purpose of trace collection, the GARNET interconnect model [1] with 8 VCs per link is used. ceives packets. A 4 × 4 mesh has 48 links and 16 injection ports In all seven traces, every node in the mesh both sends and reat each node. The number of VCs for each of these links can be individually conﬁgured. To decouple the VC allocation and buffer space allocation problems, we assume that each VC has a ﬁxed buffer length of 10 ﬂits/VC, which is larger than the maximum packet size of the application. We statically allocate 4 VCs to each of the 16 injection ports in our heuristics to ensure that there is no head-of-line blocking and that the performance bottleneck is shifted to the regular links and not the injection ports. Hence, we start with a wormhole conﬁguration with 112 VCs (1 VC/link + 4 VCs/injection port) and set our VC budget to 256 VCs, equivalent to an uniform conﬁguration with 4 VCs at every link. Every iteration of the addition and deletion heuristics creates at most 48 perturbations which are run in parallel on a computational grid. 5.2 Signiﬁcance Assessment In this subsection, we present the results of our proposed VC allocation metaheuristics on average packet latency reduction and reduction in number of VCs under a target performance. We compare our proposed approaches with uniform VC allocation, and the simple trace-driven heuristics recently proposed by [13] using seven traces from PARSEC [3] benchmark suites. Figures 10 and 11 show that our proposed algorithms can reduce the number of VCs required to achieve the same target latency as uniform conﬁgurations with two VCs per port and three VCs per port, respectively. We also show that our algorithms can achieve higher reductions in the number of VCs compared with the recently proposed trace-driven approach [13]. Figure 10 shows the number of allocated VCs using our hybrid and two-stage metaheuristics to achieve the same average packet latency as that of a uniform conﬁguration with 2VCs per port (uniform-2VC). We observe that both of our proposed metaheuristics can achieve up to 24.4% reduction in number of allocated VCs. On average, our hybrid and two-stage metaheuristics reduce the number of VCs by around 13.5% and 14.5% across all benchmarks with respect to uniform-2VC and uniform-3VC conﬁgurations, respectively. Figure 11 shows the number of VCs required using our algorithms to achieve the same average packet latency as an uniform conﬁguration with 3VCs per port (uniform-3VC). We see high reductions of up to 38% for both hybrid and two-stage metaheuristics, compared to the 208 VCs required by the uniform conﬁguration. Figures 10 and 11 also show our proposed metaheuristics match the solution quality of the approach recently proposed by [13] while reducing the runtime complexity by O(|L|). Figure 12 shows the number of simulations required by our proposed metaheuristics, versus the approach of [13], to achieve the same average packet latency as uniform-2VC and uniform-3VC. In our experiments, we observe up to 90% reduction in the total number of simulations compared to the approach proposed in [13]. 	""   !# !&  !%  !$  !""  !   &  %  $  ""       	    ""%$ Figure 10: Comparison of hybrid and two-stage VC allocation metaheuristics versus the method of [13], and uniform-2VC conﬁguration. 	""    "" !$ !  $   $     	    !%# Figure 11: Comparison of hybrid and two-stage VC allocation metaheuristics versus the method of [13], and uniform-3VC conﬁguration.              "" !        	      Figure 12: Comparison of number of simulations required for our proposed metaheuristics versus the method of [13]. 262 	    	     6. CONCLUSIONS In this paper, we propose efﬁcient trace-driven metaheuristics for optimization of NoC conﬁgurations in today’s application-speciﬁc MPSoCs. Application traces can accurately capture the temporal variability in network trafﬁc and contention between trafﬁc ﬂows, which is not feasible with previously proposed solutions based on average data rates. In comparison with uniform VC allocation, our heuristics achieve up to 38% reduction in number of VCs. These reductions over uniform VC allocation are mainly seen because our VC allocation schemes are able to fully exploit the extra degree of freedom offered by non-uniform VC allocation, using complete knowledge of the application trace. We have also compared our proposed heuristics against a recently proposed trace-driven apVCs while reducing the runtime complexity by O(|L|). Our results proach [13] and have achieved similar reductions in total number of clearly show the beneﬁts of an efﬁcient trace-driven approach in the optimization of NoC conﬁgurations. 7. ACKNOWLEDGMENTS Support from the MARCO/DARPA Gigascale Systems Research Center and NSF CCF-0811866 is gratefully acknowledged. 8. "
2010,Clustering-based simultaneous task and voltage scheduling for NoC systems.,"Networks-on-chip (NoC) is emerging as a promising communication structure, which is scalable with respect to chip complexity. Meanwhile, latest chip designs are increasingly leveraging multiple voltage-frequency domains for energy-efficiency improvement. In this work, we propose a simultaneous task and voltage scheduling algorithm for energy minimization in NoC based designs. The energy-latency tradeoff is handled by Lagrangian relaxation. The core algorithm is a clustering based approach which not only assigns voltage levels and starting time to each task (or Processing Element) but also naturally finds voltage-frequency clusters. Compared to a recent previous work, which performs task scheduling and voltage assignment sequentially, our method leads to an average of 20% energy reduction.","Clustering-Based Simultaneous Task and Voltage Scheduling for NoC Systems Yifang Liu Google Inc. 1600 Amphitheatre Parkway Mountain View, CA 94043 Email: ifnliu@gmail.com Yu Yang Department of ECE Texas A&M University College Station, TX 77843 Email: skyhigh@neo.tamu.edu Jiang Hu Department of ECE Texas A&M University College Station, TX 77843 Email: jianghu@ece.tamu.edu Abstract—Networks-on-chip (NoC) is emerging as a promising communication structure, which is scalable with respect to chip complexity. Meanwhile, latest chip designs are increasingly leveraging multiple voltage-frequency domains for energy-efﬁciency improvement. In this work, we propose a simultaneous task and voltage scheduling algorithm for energy minimization in NoC based designs. The energy-latency tradeoff is handled by Lagrangian relaxation. The core algorithm is a clustering based approach which not only assigns voltage levels and starting time to each task (or Processing Element) but also naturally ﬁnds voltage-frequency clusters. Compared to a recent previous work, which performs task scheduling and voltage assignment sequentially, our method leads to an average of 20% energy reduction. I . INTRODUCT ION The trend towards many-core-based designs entails a large demand for on-chip global communications. Conventional bus structure, whose success is built upon a small number of communicating entities, will be very difﬁcult to keep up with such demand. The new paradigm of Networks-on-Chip (NoC), in contrast, is much more scalable with respect to the complexity and volume of communications, and is gaining substantial popularity. NoC is also amiable to design modularity, which is another means for handling design complexity. Figure 1 illustrates a tile-based multi-core system on a mesh-based NoC architecture. Each tile contains a processing element (PE) and a network router. The PE can be CPU, DSP module, video processor, or embedded memory block. The edges between two neighboring tiles indicate interconnection links. Instead of direct connection like in conventional bus, data are routed through the links and routers toward their destination PEs. In parallel to the communication issue, energy-efﬁciency is a more and more critical concern. In many modern chip designs, the power density is approaching the limit of chip cooling capacity and becomes the major limiting factor to the performance growth. Energy-efﬁciency implies that the energy is spent only when it is very necessary. This philosophy is embodied in the recent popular technology of voltage-frequencyisland (VFI) which is employed at Intel SCC (Single-chip Cloud Computer) [1]. In VFI-based designs, one or a set of circuit blocks may have its own voltage and frequency level, which is adjusted based on its performance requirement. For instance, the 3 different grey-scale levels in the tiles of Figure PE Router PE Router CPU, DSP, MEM, … Tile Fig. 1. Tile-based multi-core system on a mesh-based NoC architecture. 1 represent different voltage-frequency levels. The energyefﬁciency of such systems largely depends on how the voltage and frequency of each block (PE) are assigned. In addition, one must consider that a level shifter is needed when a signal is sent from a low-voltage island to a high-voltage island. The voltage-frequency assignment problem is shown to be NPhard [2] and has been studied together with the ﬂoorplanning problem [3]–[5]. VFI can be easily integrated with NoC-based systems. Recently, a number of works address the voltage-frequency assignment problem for NoC. In [6], the voltage-frequency assignment and partitioning were performed after the tasks were bound to PEs and mapped to tiles. In [7], an enumeration-based method was proposed for pre-mapping voltage-frequency assignment. Both [6] and [7] assumed that task scheduling has been ﬁnished and delay budget has been allocated to each individual task. Therefore, they did not consider task precedence constraints which state that certain tasks must be ﬁnished before another task is started. In practice, the precedence constraints often arise from data interdependencies among the tasks. In this work, we propose a clustering-based simultaneous task and voltage scheduling algorithm for post-mapping energy minimization in NoC designs. In the core, it presents a new clustering algorithm guided by Lagrangian relaxation. In fact, clustering technique has been employed in various electronic design automation problems. For example, a novel clustering based technique, which utilizes equi-slack gate clusters to minimize the leakage power of circuits in nanometer technology, was presented in [8]. The equi-slack gate cluster based 978-1-4244-819 - /10/$26.00 ©2010 IEEE 4 1 277 technique achieves much better results in terms of runtime and leakage power reduction than most of the existing leakage power minimization methods. Another work [9] uses feature extraction based clustering algorithm to enhance the yield by assigning the same body bias to the gates with similar features. While the simultaneous approach allows more ﬂexibility for energy reduction, it poses signiﬁcant difﬁculty to solving problem due to the task precedence constraints in DAGs. We handle this difﬁculty by proposing a new clustering algorithm and combining it with Lagrangian relaxation. One of this work’s main contributions is an innovative way to re-formulate the original scheduling problem. From a new perspective, we transform the complex simultaneous task and voltage scheduling problem into a clearly deﬁned clustering problem. This transform is two-fold. First, Lagrangian relaxation integrates the original objective and constraints into one cost function, which is a linear combination of energy consumption and deadline constraint violations. Then, this cost function is mapped to a summation of distances between tasks and voltages in our task clustering space. By doing this, the difﬁcult simultaneous scheduling problem is transformed to a clustering problem. The clustering problem is solved by a customization of the classical k-means algorithm. It makes use of domain-speciﬁc analysis to deﬁne the centers of the clusters, the distance metric in the clustering space, and the cluster agglomeration procedure. In the experiment, we compare our method with a sequential approach of task scheduling followed by voltage assignment [7]. The results show that our method can achieve 20% energy reduction on average under the same task deadline constraints. I I . PR E L IM INARY An application consists of a set of tasks and data interdependencies among them. It can be described by Communication Task Graph (CTG) G = (P, E ) which is usually a Directed Acyclic Graph (DAG). Each node pi ∈ P represents a task. If a task pi is assigned with supply voltage v , it has an execution time dpi ex (v) and corresponding energy consumption Epi (v). A directed edge (pi , pj ) implies a precedence constraint between pi and pj . This constraint is usually caused by the communication from pi to pj with data of volume φ(pi , pj ). Hence, edge (pi , pj ) requires that task pj cannot start until pi is ﬁnished and data of φ(pi , pj ) has been transferred from pi to pj . A task without any incoming edges is called source task and a task without any outcoming edges is called sink task. Let S be the set of all sink tasks in the CTG. For any task pi in S , there is a deadline Dpi associated with it. For example, Figure 2 shows a CTG with 5 tasks, p0 , · · · , p4 . The communication from p0 to p1 has data volume of 3000. The deadline for sink p4 is 10. The execution time of a task pi is estimated by the product of clock period and the total number of active cycles, i.e. ex (v) = Rpi × π(v) pi d 3000 p1 6000 p0 3000 p2 3000 p3 6000 p4 D4= 10 Fig. 2. A communication task graph. can be calculated as follows: π(v) = Ki v (v − vt )α (2) where α is a technology parameter, Ki is a design speciﬁc constant [10], and vt is the threshold voltage. A task energy consumption which includes the dynamic and static ones is also related to the supply voltage. By using the above notations, the sum of dynamic and static energy consumption associated with each task is deﬁned as follows: Epi (v) = Rpi Ci v 2 + Qpi Ki ve − vt St (3) where Rpi and Qpi are the total number of active and idle cycles for task pi respectively, Ci is the total switched capacitance per cycle, Ki is a design parameter and St is a technology parameter [11]. We assume tile based mesh NoC architecture is used here as depicted in Figure 1. Each tile contains a processing element as well as a router. We denote the set of tiles as T = {T1 , T2 , ..., TN }. Routing in NoC has been shown to have signiﬁcant impact on energy consumption [12]. In this work, we use a commonly adopted routing algorithm [6], which is similar to wormhole ﬂow control and XY routing algorithm in computer networking. Asynchronous communication across different voltage islands is obtained by mixed-clock/ mixedvoltage FIFOs [13]. tile. We use function M : P → T to represent the mapping In NoC we assume that the tasks have been allocated to each function which assigns each task to a speciﬁc tile in NoC. For example, M (pi ) denotes the tile which task pi is mapped to. Under the above assumptions, we deﬁne Execution Task (cid:2) = (P, E (cid:2) ) which can be derived from CTG Graph (ETG) G by the following procedures: for any pair of tasks pi and pj in the same tile, suppose pi executes earlier than pj , then if (pi , pj ) ∈ E in CTG, φ(pi , pj ) = 0; otherwise, we add an edge (pi , pj ) in ETG and let φ(pi , pj ) = 0. In other words, if two tasks are assigned to the same tile, a precedent constraint is imposed since the PE in this tile can only process one task at a time; if the two tasks have communication requirement, this requirement is eliminated as communication in the same PE can be ignored since the volume data is stored in local memory and can be retrieved in negligible time. where Rpi is the total number of active cycles, π(v) is the clock period for a supply voltage v . According to [6], π(v) (1) 278 Using the above notation, the communication energy consumption for any edge (pk , pl ) ∈ E (cid:2) is deﬁned as follows: (cid:2) i∈Q E (pk , pl ) = φ(pk , pl )Ebit i v2 v2 DD (4) s.t. t (cid:2) (cid:2) Min:EAP P = pi pi ∀pi∈P Epi (vM (pi ) ) + φ(pi , pj )E (pi , pj ) ex (vM (pi ) ) + tco (pi , pj ) ≤ t st , ∀(pi , pj ) ∈ E st + d ex (vM (pi ) ) ≤ Dpi , ∀pi ∈ S st + d vi ∈ V , ∀i ∈ T t ∀(pi ,pj )∈E (cid:2) pj (7) pi pi (cid:2) where S is the set of sink tasks and vM (pi ) is the supply voltage for tile where task pi locates. IV. MOT IVAT ION AND MA IN ID EA S Usually, one wants to assign a tile with a voltage level the same as its adjacent tiles if they have similar performance requirement. If they use the same supply voltage, the interface overhead, such as level shifters and FIFOs, can be reduced or avoided. In other words, tiles with similar performance requirement are preferred to be grouped together and assigned to the same supply voltage level. This observation is the main motivation for us to schedule the tasks and voltages by clustering considering performance speciﬁcations. A classic approach for clustering is the k-means algorithm [18]. It starts with k randomly generated clusters. Then, it iteratively assigns every element to the cluster whose center is the nearest to the element according to certain distance metric. The center of a cluster is the geometric mean location of all elements in the cluster in certain coordinate system. After every element is assigned to a cluster, the centers of all clusters are updated. This iteration repeats with assigning elements to the clusters resulted from the previous iteration, followed by clusters’ update according to the new elements’ assignment. The iteration continues till certain convergence criterion is met. Figure 3 shows an example of one iteration in k-means clustering. In Figure 3(a), the elements in black squares are assigned to the clusters closest to them. The line in the middle separates the two clusters. In Figure 3(b), the centers of the two clusters are moved to the mean point of the elements in them, respectively. After the adjustment of the cluster centers, the next iteration begins with the calculation of distances between the elements and the cluster centers. Despite their similarity, there is a gap between classical clustering and the voltage assignment in our case. This gap manifests on two related aspects. On one hand, clustering requires a well-deﬁned distance/coordinate metric which is not obviously available in the voltage assignment problem. On the other hand, two tiles are assigned to the same voltage only if they have similar performance requirements (otherwise, one tile may be unnecessarily assigned with a high voltage and energy waste is induced). However, the performance requirement for each tile is not clear since the task scheduling has not been done yet. We propose to bridge this gap by using Lagrangian relaxation. Lagrangian relaxation converts the complex constraints of an optimization problem into a part of the objective function, which is a set of penalty terms to any violations to the constraints. The converted problem, called Lagrangian where Ebit is a bit energy metric [6], which is the total energy consumed when one bit of data is transferred through the link, buffer and switch fabric. Also assume the bit energy metric is measured under vDD . Q means the set of tiles on the path from tile M (pi ) to tile M (pj ) since each link and router belong to a tile in NoC, vi is the supply voltage for tile i. Similar to [6], the communication latency for any edge (cid:2) is represented as follows: if M (pi ) = M (pj ) (cid:5), otherwise (pi , pj ) ∈ E ⎧⎪⎨ (cid:2) ⎪⎩ 0, + tf if o (cid:4) φ(pi , pj ) W tco (pi , pj ) = μs fi i∈Q (5) where W is the channel width, fi is the operation frequency of tile i, μs is the number of cycles it takes to traverse a single router and outgoing link, tf if o is the latency of the FIFO buffers. Since we use wormhole ﬂow control mechanism, the ﬁrst term and the second term of the above equation correspond to the latency of header ﬂits traversing path Q and latency of serialization for the remaining ﬂits, respectively. The deadline constraint means that for each source-sink path in the ETG, the sum of total execution time and communication delay should not exceed the deadline of the sink at the st and be the starting time, ∀pi ∈ P . Denote path end. Let t by I (pi ) the set of immediate upstream tasks of task pi , i.e. (cid:2) }. Then the following condition must be satisﬁed for each task: task cannot start until all of its parents and the corresponding communication transactions have ﬁnished, i.e. 0, max if I (pi ) = ∅ ex (vpj ) + tco (pj , pi )), otherwise (6) I (pi ) = {pj |(pj , pi ) ∈ E pj ∈I (pi ) st + d pi st = (cid:7) (t pj pj pi t By Equ. (6), we can calculate all tasks’ start time in topological order. If for each task in S , its start time plus the execution time is no greater than its corresponding deadline, ex (vpi ) ≤ Dpi , ∀pi ∈ S , then the deadline constraint i.e., t is satisﬁed. pi st +dpi I I I . PROBLEM FORMULAT ION The simultaneous task and voltage scheduling (S T V S ) problem is stated as follows. Given a NoC architecture with each task has been allocated (cid:2) = (P, E (cid:2) ) derived from a CTG G = to a tile, an ETG G (P, E ), tasks’ mapping function M as well as a set of supply voltage options V , assign each tile i ∈ T a voltage vi and each task pi a start time t st , such that the total application energy consumption is minimized subject to the path deadline constraints, i.e. pi 279 subproblem, attempts to minimize a linear combination of the original objective function and the constraint violations. In our case, the objective (cost) function of the Lagrangian subproblem is a linear combination of energy and deadline constraint violations. Then, we deﬁne the distance metric based on this cost function. By doing so, both energy cost and performance requirement are handled in a uniﬁed manner. Lagrangian relaxation comes with a dual problem which ﬁnds the appropriate values for the penalty coefﬁcients (Lagrangian multipliers) for the Lagrangian subproblem. In Section VII, a subgradient approach for solving the dual problem will be introduced. V. LAGRANG IAN RELAXAT ION The S T V S problem formulated in Section III is solved under the Lagrangian relaxation framework, which is also adopted by other complicate multi-constrained optimization in electrical design automation area [19]. For each constraint in S T V S , we specify a non-negative Lagrangian multiplier λ and obtain the Lagrangian function: Lλ (v , tst ) =(cid:2) ∀pi∈P (cid:2) (cid:2) ∀pi∈S ∀(pi ,pj )∈E (cid:2) (cid:2) Epi (vM (pi ) ) + λij (t pi st + d φ(pi , pj )E (pi , pj )+ ex (vM (pi ) ) + tco (pi , pj ) − t ∀(pi ,pj )∈E (cid:2) pi st )+ pj λi (t pi st + d ex (vM (pi ) ) − Dpi ) pi (8) (a) (b) Fig. 3. An iteration in k-means clustering. (a) cluster assignment. (b) center point moves to the mean of all elements in the cluster. Although variables tst are eliminated in Equ. (10), a legitimate task scheduling solution is still largely speciﬁed by the results from our method. Since our method tries hard to trade the delay slack for energy reduction, the slack for each task, which is deﬁned by the difference between ALAP and ASAP schedules [15], is minimized. In other words, the starting time for each task in close to fully speciﬁed. The overall framework of the clustering method guided by Lagrangian relaxation is outlined in Algorithm 1. Line 2 and 6 indicate the Lagrangian iteration loop. Line 3 solves the Lagrangian sub-problem by performing tile clustering based on tile-voltage distance measurement. Line 4 in every Lagrangian iteration updates multipliers to solve Lagrangian dual problem. Algorithm 1 LR clustering f ramework 3: 1: initialize (vi , λ); 2: for all k ∈ {0, 1, 2, 3, ...} do Perform TILE clustering (assigning vi ’s) on all tiles based on TILE-voltage distance, while the center of each cluster is a voltage option in the candidate voltage set; Update Lagrangian multipliers λ with our sub-gradient calculation technique; If no improvement, stop with the best clustering solution satisfying the timing constraint till k th iteration; 4: 5: 6: end for V I . T ILE CLUSTER ING FOR VOLTAGE ASS IGNMENT We deﬁne TILE-voltage distance l(i, vi ) for any tile i when it is assigned with voltage vi , i.e., (cid:2) Epj (vi ) (cid:2) φ(pk , pj ) v2 v2 i DD + + + (cid:2) ∀Q(pk ,pj )pass tile i ( (cid:2) ∀pj :M (pj )=i ∀pk :(pj ,pk )∈E (cid:2) (cid:2) λij μs fi . (11) λjk )d pj ex (vi ) ∀Q(pi ,pj )pass tile i where Q(pk , pj ) is the set of tiles on the path from tile M (pk ) to tile M (pj ), fi is the operation frequency of tile i. The Lagrangian subproblem is to minimize the Lagrangian function for a speciﬁc set of Lagrangian multipliers and is formulated as: Min: Lλ (v , tst ) vi ∈ V , ∀i ∈ T s.t. (9) According to KKT conditions [16], the Lagrangian subproblem can be reduced as in [14]. After the reduction, variables tst is eliminated and the subproblem becomes: Lλ (v) = Epi (vM (pi ) ) + φ(pi , pj )E (pi , pj )+ (cid:2) ∀(pi ,pj )∈E (cid:2) λij (d pi ex (vM (pi ) ) + tco (pi , pj ))+ (cid:2) (cid:2) (cid:2) ∀pi∈P ∀pi∈S ∀(pi ,pj )∈E (cid:2) In the simpliﬁed Lagrangian subproblem, the execution times and communication delays are independent of each other. Therefore, the subproblem becomes easier to solve. This subproblem will be tackled by a clustering algorithm described in Section VI. Besides the subproblem, one needs to ﬁnd proper values for the Lagrangian multipliers such that the original S T V S problem is solved. This is the so-called Lagrangian dual problem and will be discussed in Section VII. 280 ex (vM (pi ) ) − Dpi ) pi l(i, vi ) = (10) λi (d ∀pj :M (pj )=i T4 T4 T1 T2 T3 T1 T2 T3 (a) (b) T1 T2 T3 T4 (c) Fig. 4. One iteration in TILE clustering. There are four tiles T1 ,T2 ,T3 and T4 . Two supply voltages are available. (a) TILE voltage assignment at the beginning of iteration. (b) T4 ’s distances to the two voltages are re-evaluated. (c) T4 is assigned to a new voltage according to the re-evaluated distances. Based on the distance measurement given in Equ. (11), a clustering procedure carried out on all tiles actually performs the optimization to minimize the Lagrangian function in Equ. (10). In another word, clustering of tiles, using distance measurement in Equ. (11), solves the Lagrangian sub-problem in Equ. (9). Our TILE clustering method is performed in a similar way to classic clustering methods, except that in our case the center of each cluster is always one of the voltage options given by the problem. That is, every voltage option corresponds to a cluster and is always the center of the cluster. Therefore, the number of clusters equals the number of voltage options. Also, the distance from each tile to a voltage option depends on the supply voltages of related tiles. When the clustering that results in the minimum overall distance is reached, the iteration of clustering method terminates. When the clustering procedure ﬁnishes, there may be a few empty clusters, where there is no tile assigned to them. The number of non-empty clusters is the best number of voltages for the problem, and the TILE assignment of the non-empty clusters is the best voltage assignment solution. Given a set of multipliers, all clustering iteration works like an iteration in k-means clustering. First, the distances between every tile and all the voltage options are calculated. Then, based on these distances, each tile is assigned to the cluster whose center - a voltage option - is closest to the tile. An iteration is completed without re-evaluation of the center of each cluster, because the center of each cluster is ﬁxed to a voltage option in our case. In reﬁnement iterations, the tile-voltage distance uses the formula in Equ. (11), accommodating several factors: tasks’ energy consumption, tasks’ communication energy, tasks’ execution time, and communication delay. The example in Figure 4 illustrates the change of a TILE’s voltage assignment in one iteration. Figure 4(a) shows the clustering at the beginning of the iteration, where T4 is in the high voltage cluster. Figure 4(b) re-evaluate the distances of T4 to all voltages, and T4 gets closer to the lower voltage. Figure 4(c) assigns T4 to lower voltage cluster. The clustering algorithm is outlined in Algorithm 2. Line 3 performs distance evaluation between tiles and voltage options; Line 4 assigns tiles to speciﬁc clusters according to the updated TILE-voltage distances. Algorithm 2 implements the clustering step in a Lagrangian relaxation iteration in Algorithm 1. Algorithm 2 T I LE clustering 1: initialize vi to minimize Ei (vi ) + λidexec (vi ), ∀pi ∈ P ; 2: for all k ∈ {0, 1, 2, 3, ...} do evaluate all TILE-voltage distances, i.e., 3: l(i, vi ), ∀i ∈ T , ∀vi ∈ V ; 4: make voltage assignment, i.e., vi ← arg minvi∈V l(i, vi ); If no change of assignment made, stop with the current cluster assignment in the k th iteration; 5: 6: end for V I I . SO LV ING LAGRANG IAN DUA L PROB L EM The goal of the outer loop of the Lagrangian relaxation framework in Algorithm 1 is to solve Lagrangian dual problem, which basically tunes the multipliers λ to maximize the minimal value (optimized by adjusting vi and tst in the sub-problem) of the Lagrangian function, min formal formulation, the dual problem is expressed as: Lλ (v , tst ). In a v ,tst Max: s.t. Lλ (v , tst ), v ,tst min λ ≥ 0. (12) The function Lλ (v , tst ) is a concave function of λ ≥ 0. However, it is non-differentiable. Therefore, the subgradient method is employed to solve the dual problem instead [20]. The method works as follows. First, initial λ values are given. Then, every λ for a constraint is updated to a new value in the subgradient direction. In our case, in iteration k , we ﬁrst solve the Lagrangian subproblem by using the cluster based method; then, we deﬁne the subgradient direction to be the left hand side minus the right hand side of the constraints in Equ.(7). (cid:2) The values of t needed in this computation are calculated by a topological traversal of the ETG and ASAP (As Soon As possible) scheduling method, after we get the supply voltage for each tile in the current iteration. We use a step size ρk for current iteration k , multiply it with the subgradient direction, and add it to the current λ value, that is: ex , ∀pi ∈ P and tco (pi , pj ), ∀(pi , pj ) ∈ E pi st , dpi pi λij = λij + ρk (t st + d ∀(pi , pj ) ∈ E λi = λi + ρk (t st + d pi pi (cid:2) ; pi ex (vM (pi ) ) + tco (pi , pj ) − t ex (vM (pi ) ) − Dpi ), ∀pi ∈ S ; pi st ), (13) This whole process continues until it converges, which means: (cid:2) φ(pi , pj )E (pi , pj ) − Lλ (v , tst ) Epi (vM (pi ) ) + ∀(pi ,pj )∈E (cid:2) ≤ error bound (14) (cid:2) pi∈P 281 ) v ( e g a t l o v l y p p u s 2 1.5 1 0.5 0 3 e g a t l o v 1.4 1.2 1 0.8 0.6 0.4 0.2 0 Ours Previous work 2 1 1 0 0 3 2 1 2 3 4 5 6 7 8 9 Tile_Index Fig. 5. Supply voltage for each tile in auto-industry. Fig. 7. Comparison on voltage assignment from [7] and our method over 9 tiles on an E3S benchmark - consumer. ) v ( e g a t l o v l y p p u s 2 1.5 1 0.5 0 3 2 1 1 0 0 3 2 2.5 2 1.5 1 0.5 0 runtime(s) Fig. 6. Supply voltage for each tile in networking. Fig. 8. Runtime for each benchmark. (cid:8)k It is also known that if the step size ρk satisﬁes when k → ∞, ρk → 0 and i=1 ρi → ∞,then the subgradient method will converge to its optimal value. V I I I . EXPER IMENTS In our experiment, the test cases are from Embedded System Synthesis Benchmark Suite (E3S) [21]. E3S contains some example applications from various areas, such as ofﬁce automation, networking, auto industry, and telecommunication. The number of tasks in the benchmark applications ranges from 5 to 30. These applications are scheduled to 3 × 3 mesh networks respectively. The supply voltage candidates are 0.8v,1.0v,1.2v,1.4v and 1.6v. Our method is compared with the voltage assignment method of [7]. In [7], the delay deadline for each individual task is ﬁrst obtained according to the energy aware scheduling [17]. Then, the voltage assignment for each tile is found by enumeration. Since we only compare the voltage assignment method, we assume that the mapping results are the same for both cases. We implemented both the method of [7] and our method in C++. The experiment was performed on a Windowsbased desktop machine with 2.0 GHz Intel core 2 duo CPU and 2 GB memory. The ﬁnal supply voltage for each tile in two benchmarks is shown in Fig.5 and Fig. 6 respectively. In these ﬁgures, the bottom squares correspond to all tiles and the z values of these tiles represent the assigned supply voltages. From the ﬁgures, we can see different tiles are assigned to different supply voltages. Table 1 lists the energy consumption for all benchmarks both for our method and method of [7]. On average over the ﬁve benchmarks in E3S, our method achieves 20% energy reduction compared to [7]. The largest energy reduction is 33%. The main reason for this difference is that [7] separates the voltage assignment from task scheduling. Without the information on voltage assignment, the task scheduling may make wrong decisions and incur inappropriate deadline constraints to the subsequent voltage assignment problem. Figure 7 provides more details on the supply voltage assignment results for each tile for consumer benchmark from both our method and [7]. The voltage distributions by the two methods differ a lot from each other. This is because our method can handle the energy-performance tradeoff from a global point of view, while the optimization of [7] tends to be restricted to local tradeoff. Our algorithm’s runtime ranges from 0.58s to 2.11s. Figure 8 shows the runtime results for all benchmarks. IX . CONCLUS ION In this work, we propose a new clustering approach for voltage-frequency optimization in NoC-based systems. It minimizes a linear combination of energy and latency penalty enabled by Lagrangian relaxation. We use clustering method to solve the Lagrange subproblem and solve the dual problem by subgradient method. Experiments show our method has signiﬁcant advantage in solution quality over a previous work on the problem of energy minimization under task deadline constraint. "
2010,Evaluation of using inductive/capacitive-coupling vertical interconnects in 3D network-on-chip.,"In recent 3DIC studies, through silicon vias (TSV) are usually employed as the vertical interconnects in the 3D stack. Despite its benefit of short latency and low power, forming TSVs adds additional complexities to the fabrication process. Recently, inductive/capactive-coupling links are proposed to replace TSVs in 3D stacking because the fabrication complexities of them are lower. Although state-of-the-art inductive/capacitive-coupling links show comparable bandwidth and power as TSV, the relatively large footprints of those links compromise their area efficiencies. In this work, we study the design of 3D network-on-chip (NoC) using inductive/capacitive-coupling links. We propose three techniques to mitigate the area overhead introduced by using these links: (a) serialization, (b) in-transceiver data compression, and (c) high-speed asynchronous transmission. With the combination of these three techniques, evaluation results show that the overheads of all aspects caused by using inductive/capacitive-coupling vertical links can be bounded under 10%.","Evaluation of Using Inductive/Capacitive-Coupling Vertical Interconnects in 3D Network-on-Chip Jin Ouyang∗ , Jing Xie, Matthew Poremba, Yuan Xie Department of Computer Science and Engineering, the Pennsylvania State University ∗ jouyang@cse.psu.edu Abstract—In recent 3DIC studies, through silicon vias (TSV) are usually employed as the vertical interconnects in the 3D stack. Despite its beneﬁt of short latency and low power, forming TSVs adds additional complexities to the fabrication process. Recently, inductive/capactive-coupling links are proposed to replace TSVs in 3D stacking because the fabrication complexities of them are lower. Although state-of-the-art inductive/capacitive-coupling links show comparable bandwidth and power as TSV, the relatively large footprints of those links compromise their area efﬁciencies. In this work, we study the design of 3D network-onchip (NoC) using inductive/capacitive-coupling links. We propose three techniques to mitigate the area overhead introduced by using these links: (a) serialization, (b) in-transceiver data compression, and (c) high-speed asynchronous transmission. With the combination of these three techniques, evaluation results show that the overheads of all aspects caused by using inductive/capacitivecoupling vertical links can be bounded under 10%. I . IN TRODUC T ION In recent years a shift of researches from merely technology scaling to massive integration has been witnessed in the semiconductor industry. Three-dimensional integrated circuits (3DICs) bring brand new opportunities to integrate many and heterogeneous components in a single chip, to deliver performance and functionalities hard to rival by 2D chips and offer unique opportunities to continue the Moore’s law [11]. Despite the merits mentioned above, the additional complexities introduced by 3DIC to the fabrication process cast a shadow on the picture. In TSV based 3DIC, forming vertical links to interconnect different layers requires additional and unconventional processing steps involving high aspect-ratio etching, wafer thinning, bonding, etc. Defects that occur during the extra processes cause performance and yield loss, hindering the wide adoption of 3DIC. This hurdle of fabrication has led to the advent of ACcoupling vertical links recently. For this kind of links, either magnetic ﬂux (inductive-coupling [5], [7], [8], [12]) or electric ﬁeld (capacitive-coupling [2]–[4]) serve as the medium through which signals are transmitted vertically. The advantage of inductive/capacitive coupling links is that the transceivers can be implemented by pure 2D process. Additional 3D processing steps to form TSVs are eliminated. In addition, it is possible to improve the performance of inductive/capacitive-coupling links with technology scaling. However, Most reported inductive/capacitive-coupling links This work is supported in part by NSF 0905365, 0903432, and 0702617, and SRC grants. M Flux TX RX E Field TSV TX + RX (a) Inductive -Coupling (b) Capacitive-Coupling (c) TSV Fig. 1. A conceptual view of vertical interconnects based on three different physical media have much larger area than TSV, ranging from hundreds to tens of thousands of square microns. The inferior area efﬁciency of inductive/capacitive-coupling links renders their applicability in high density 3DIC a question. The focus of this paper is to improve the area efﬁciency of inductive/capacitive-coupling links, and evaluate their applicability in the context of 3D NoCs. To achieve this goal, three techniques are proposed: • Serial communication on the vertical links is ﬁrstly proposed to constrain the area overheads. However, serial communication incurs performance penalty since the effective • Data compression is then proposed to recover the perforvertical bandwidth is reduced. mance by reducing the bandwidth requirements for vertical links. Different from previous work, we implement an intransceiver data compression scheme where compression is performed simultaneously with serial communication, incurring no latency overhead nor changes to original NoC. • High-speed asynchronous transmission is lastly exploited to further boost the performance. Inductive/capacitivecoupling vertical links combined with serial transceivers become a natural asynchronous interface capable of running at a frequency much higher than the 2D links. This provides opportunities to further improve the area efﬁciency of vertical links. A comprehensive evaluation of a 3D CMP interconnected by NoC using inductive/capacitive-coupling links is presented, taking into consideration performance, energy, and area. With the combination of serialization, data compression, and asynchronous transmission, experiment results show that the overheads of performance, energy, and area caused by using inductive/capacitive-coupling links can all be bounded under 10%. In addition, the area efﬁciency of these links is also brought to over 90% of TSV. Considering the beneﬁt of reducing fabrication difﬁculties, this is a positive result to support inductive/capacitive-coupling communication as a competitive alternative in real 3D designs. To the best of our knowledge, this is the ﬁrst work to evaluate the utility 978-1-4244-819 - /10/$26.00 ©2010 IEEE 4 1 477 TABLE I. Recent Work on Inductive/Capacitive-Coupling Vertical Links Energy (pJ/b) Data Rate (GB/s) Inductor/Capacitor Size Inductor/Capacitor Pitch Active Area (mm2 ) Total Area (mm2 ) Distance (um) Process Xu05 [12] 17 2.8 150×150um2 200um NA NA 90 .35um Ishikuro07 [5] >390 0.02 >0.6mm2 NA >0.006 NA 1200 .25um Inductive Miura08 [7] 0.14 1 29um (diameter) 30um NA NA 15 90nm TABLE II. [11] Size Height Pitch TSV Characteristics 10×10um2 50um 20um 14mΩ 284fF 60.6ps 0.125pJ Delay Energy RT SV CT SV of inductive/capactive interconnects in 3D NoC and propose to combine all the three techniques above to improve their performance. I I . V ERT ICA L IN T ERCONN EC T ION S IN 3D IC A. Through Silicon Vias TSVs are the most commonly used vertical interconnects. Usually the dimensions of TSV are quite small, resulting in low parasitics which in turn translate into high bandwidth and low energy consumption. The speciﬁcations of TSV depend on the process and can vary diversely. For example, IBM, IMEC, and many more organizations have fabricated TSVs with different pitches ranging from several microns up to tens of microns [11]. In this paper we assume a moderate TSV whose dimensions and RC data is generalized in Table II [11]. The delay and energy results are obtained from Spice simulation based on the methodologies in by using [1]. B. AC-Coupling Vertical Links Table I summarizes most recently demonstrated designs of both inductive-coupling links (column 2-5) and capacitivecoupling links (column 6-8). Due to the different natures of the carrier ﬁelds, the characteristics of inductive-coupling and capacitive-coupling links also differ. The communication distance of inductivecoupling is relatively long. This long communication distance is exploited in [5] to realize an attachable wireless chip probe and most recently in [9] for a memory-on-processor chip where the communication distance is 120um. Capacitivecoupling, on the other hand, has much shorter communication distance which constrains it to be used only in face-to-face stacking. However, the footprints of capacitive-coupling are likely to be much smaller than inductive-coupling, incurring much lower area overhead than inductive-coupling. Existing inductive-coupling and capacitive-coupling designs can achieve a data rate as high as 11Gb/s or energy consumption as low as 0.14pJ/b, which are both comparable to TSV (the ﬁrst and second rows in Table I). In addition, they can be Capacitive Miura09 [8] 1.4 1.5 1.8 11 120um (diameter) NA NA 0.0015 30 180nm 15 45 Sun07 [4] 3 1.8 NA NA NA NA <10 180nm Fazzi07 [2] 0.08 1.7-2.46 8×8-20×20um2 NA NA NA 1 130nm Gu07 [3] 0.27 48×18um2 10 0.39 72×38um2 11 NA 0.0012 0.0021 NA 3 180nm TABLE III. Implementation Results of 128-bit Transceiver with STMicro 65nm technology at 5GHz Transceiver w/o Data Compression Serialization Ratio Energy (pJ/b) 4:1 8:1 16:1 0.3581 0.5987 0.9063 Area (um2 ) 4776 4102 3890 Transceiver w Data Compression Serialization Ratio Energy (pJ/b) 4:1 8:1 16:1 0.7785 0.9528 1.4801 Area (um2 ) 8473 7009 6334 implemented with conventional 2D process without additional processing steps. The metal solenoids and capacitive plates can be formed simply by the top metal of the integrated circuit. However, as Table I shows (the ﬁfth and sixth rows), most reported inductive/capacitive-coupling links have much larger area than TSV, ranging from hundreds of square microns to tens of thousands of square microns. In the remaining evaluations of the paper, the characteristics of inductive/capacitive-coupling links are based on Table I where more conservative processes (90nm or older) are used. However, for the transceivers, and the 3D NoC and the CMP introduced in the following sections, a more contemporary technology node of 65nm is assumed. Hence, our evaluations hereafter can be deemed as the worst-case results, since it is possible to improve AC-coupling links’ performance with technology scaling [8]. Moreover, due to the incompleteness and large variation of reported data on inductive/capacitivecoupling links, we design our evaluations to consider a range of possible metrics of AC-coupling links. I I I . R EDUC ING AR EA OV ERH EAD W I TH S ER IA L I ZAT ION One way to address the large area overhead of inductive/capacitive-coupling vertical links is to adopt serial communication where the data is transmitted on a single link. The serialization ratio is deﬁned as the ratio between the number of parallel and serial links. We adopt the transceiver design proposed in [10] originally for TSV, shown in Figure 2a and 2b. This transceiver effectively implements the start-1 stop-0 serial protocol . Note that the transceiver owns private clock generators (ring-oscillator) which allows for asynchronous transmission. We implement the transceiver with STMicroelectronics 65nm technology. The transceiver can run at as high as 5Ghz using this technology. The ﬁrst half of Table III shows power and area of 128-bit 478 C r a b s s o r B u f S R Ring Oscillator 0 0 0 0 0 ... 0 0 1 (n+2) Bit Ring Counter n+1 Bit Shift Register 1 Load/~Shift Enable Reset Clk ‘0’ ‘1’ To Serial  Link n Bit Data Buffer  Empty (a) S R Ring Oscillator Clk 0 0 0 0 0 ... 0 0 1 (n+2) Bit Ring Counter n Bit Shift Register Enable Reset a k o n e L F S r r m i l i Done (b) Fig. 2. (a) A 7-port 3D NoC router with dedicated vertical ports (Up/Down). (b) Serial transmitter. (c) Serial receiver. transceivers (transmitter + receiver) with different serialization ratios (due to space limits, Table III only lists results for 4:1, 8:1, and 16:1 transceivers). Note that a 128-bit transceiver may consist of multiple narrower sub-transceivers, say, 32 4-bit sub-transceivers. The impact of serialization on the area of an NoC router is evaluated based on the implementation results. We derive the area and energy of the 3D NoC router with ORION 2.0 [6]. Figure 3 shows the total router area including area taken by vertical links, normalized to the router area without vertical links. As a guidance, Figure 3 also plots relative bandwidth reduction with serialization. We notice that with the large pitches of inductive/capacitive-coupling links, up to two times of area overhead is observed without serialization. In addition, we see that with a serialization ratio of 8:1, the area of the router with inductive/capacitive links is only 1.1 times larger than the router with TSV for pitches not larger than 100um. IV. DATA COM PR E S S ION As shown by Fig. 3 and subsequently in Section V, serialization can incur considerable performance penalty. In this section, we propose to use data compression to reduce the performance penalty and develop an in-transceiver data compression design. A. The Concept In this work we carry out zero-pattern compression at the granularity of single 32-bit words. Conceptually, if one word in a ﬂit contains all zeros, this word is omitted for transmission and instead only a few bits to encode this situation are sent. For instance, consider a 128-bit wide ﬂit that contains four 2 1.9 1.8 1.7 1.6 1.5 1 4 1.4 1.3 1.2 1.1 1 0.9 u o R R d e t e r  A r a e 20um(TSV) 40um 2.17 1 4 8 16 32 Serializat ionRatio(n:1) N o r m a i l z  1 0.8 0.6 0.4 0.2 0 d n a B d d e  w i d t h 70um 100um 120um 64 N o r m a i l z Fig. 3. Area overheads when the serialization ratio varies, for different vertical link pitches. The results have been normalized to the case where the area of vertical links is not included. The trend line shows the normalized bandwidth reduction with increasing serialization ratio. 128-Bit Flit in  Crossbar Buffer Word 0 Word 1 Word 2 Word 3 This word contains only zeros 4-Bit Mask Register 1 0 1 1 ... ... n Bit Shift Register in  Transmitter 0 Transmitter i Transmitter 31 Fig. 4. Zero-pattern compression in principle. 32-bit words (Fig. 4). If some word in the ﬂit contains all zeros, it is eliminated and only the remaining three words are sent. Encoding can be done in hardware by generating a 4-bit mask. A “1” in the mask represents a valid word while a “0” indicates the corresponding word is omitted. This mask is sent together with the compressed data, and used by the receiver to recover the data. B. Implementation In this subsection we use an 128-bit 4:1 transceiver to illustrate the implementation of data-compression enabled transceiver. Except for some minor changes, the implementation is similar for other serialization ratios. The synthesis results of the enhanced transceivers with 65nm technology are listed in the second half of Table III. 1) Data Compression Operations: Fig. 5 shows the additional operations needed by data compression during each transmission cycle. In Fig. 5a, simultaneously with loading data into shift register, the transmitter also generates and latches the 4-bit mask into a register. This mask is sent on parallel links, together with the start-bit on the serial link in the second cycle, and each valid data bit is sent one-by-one in following cycles. At the end of the transaction, all valid data bits are sent, and the mask register is reset. In Fig. 5b, when detecting a rising-edge on the serial link, the receiver latches the start-bit into its data register and the mask on the parallel links into its mask register. Then when following bits come in, the mask register is used to rearrange the bits to recover the original data. At the end of the transaction, the decompressed data is delivered and the mask register is cleared. 2) Hardware Details: Supporting data compression only adds a few changes to the transceiver shown in Fig. 2. 479     Send k valid data bits 0. Load  data into  data register Generate  mask 0 1. Send  start-bit on  the serial  link Send mask on  parallel  links 1 2. Send  the 1st  valid data  bit Select valid data  bit to send 2 Cycles (k+2). Reset  transmitter  state Reset  mask register k+2 ... ... (a) Transmitter Operations Receive k valid data bits 0. Risingedge  detected,  latch startbit Latch mask into  register 0 1. Receive  the 1st  valid bit Arrange  the valid  bit to  proper  position 1 ... ... Cycles (k+2). Send data  to input  buffer (k+1). Receive all  valid data  bits Reset  mask register k+1 k+2 (b) Receiver Operations Fig. 5. Operations in a single transaction. The text in shaded boxes indicates additional operations of data compression. 4+1 Data Register Load/~Shift Reset D Flip-Flop D Q 0 1 Load/~Shift 1 0 0 0 1 First ‘1’ Detector Mask Register 0 1 0 1 (a) 1 4+1 Data Register En En En En 4-bit Mask From  Parallel-in  Load/Clear/~Shift Mask Register 0 1 1 0 D Flip-Flop D Q 0 1 1 0 0 0 First ‘1’ Detector From  Serial  Link Done Reset (b) Fig. 6. Data compression hardware details: (a) Compression. (b) Decompression. Speciﬁcally, only the shaded parts in Fig. 2a and 2b are modiﬁed. The modiﬁed shaded part in Fig. 2a is shown in Fig. 6a. For clarity, clock and data signals are omitted. As can be seen, there are two major changes: • The ring-counter is replaced by the mask register, combined with some logic, to control the transmission sequence. • The data register is not a pure shift register, but instead is equipped with a 4-to-1 multiplexer to forward any bits to the head of the register. The data and mask registers are loaded when crossbar buffer becomes ready, as shown. In each following transmission cycle, with a ﬁrst-one detector, the mask register controls the multiplexer to select the next valid bit to be sent. The output from the ﬁrst-one detector is also fed-back to clear the leading “1” in the mask register in each cycle. After all valid bits are sent, the mask register should contain only “0”s and reset the transmitter state. The modiﬁcations to the receiver, as shown in Fig. 6b, are very similar to the transmitter. The difference is that instead of using a multiplexer, the data register demultiplexes the incoming serial data using data enables generated by the mask register. One subtlety with receiver is that the data register needs to be cleared to ‘0’ before receiving the ﬁrst valid bit, to eliminate obsolete bits from last transaction. V. EX P ER IM EN T In this section, inductive/capacitive-coupling vertical links are evaluated in the context of a 3D NoC with a cycle accurate simulator. In the simulator we model a 2-tier, 16-core 3D CMP with a shared L2 cache distributed into 16 banks. as a 3D MESH (4×4 by 2 layers). We choose a mosaic These 32 nodes are interconnected by a 3D NoC conﬁgured ﬂoorplan where each core is surrounded by 5 L2 cache banks in the cardinal directions (except for cores on edges). The NoC router metrics are derived with ORION 2.0 [6]. The area and energy of proposed transceivers is given in Table III, for STMicro 65nm technology and 5GHz frequency. The whole CMP (processor, cache, NoC) is clocked at 1.5Ghz. For synthetic trafﬁcs, we study the impact of serialization and asynchronous transmission; for multi-thread applications, we evaluate all the three proposed approaches. Note: For comparison purpose, we deﬁne baselineT SV as the case that TSV is used without serialization. As discussed in Section III, serialization with TSV only gains negligible area savings, but incurs signiﬁcant performance loss. The two proposed approaches (data compression and asynchronous transmission) to recover performance are only effective when serialization is used, where vertical link bandwidth is the bottleneck. Therefore, none of serialization, data compression, and asynchronous transmission is used in baselineT SV . A. Study with Synthetic Trafﬁcs Fig. 7 shows the average message latencies for four synthetic trafﬁcs with different load ratios and serialization ratios. Note that the performance when the serialization ratio is 1:1 is just the same as baselineT SV . It can be seen from the results using serialization with the vertical links negatively affects the performance of NoC. With the serialization ratio increasing, the message latency under the same load ratio increases, and the saturation load ratio decreases. Within the four trafﬁc 480 170 150 130 110 90 70 50 30 10 s e c y y c l ) Uniform Nearest Neighbor P e k c a t a L t y c n e ( Load Ratio Load Ratio 170 150 130 110 90 70 50 30 10 y c n e e ( c y c l s e ) Bit Complement Tornado 0 . 2 0 0 . 3 0 0 . 4 0 0 . 5 0 0 . 6 0 0 . 7 0 P e k c a t a L t Load Ratio 0 . 2 0 0 . 3 0 0 . 4 0 0 . 5 0 0 . 6 0 0 . 7 0 0 . 8 0 0 . 9 0 0 . 1 0 . 1 1 0 . 2 1 0 . 3 1 Load Ratio 1 1 1:1 16 1 16:1 2 1 2:1 4 1 4:1 8 1 8:1 Fig. 7. Message latencies for different trafﬁc patterns without data compression. 0.1pJ 0.5pJ 1.0pJ 1.5pJ 2.0pJ 1.55 1.55 1.55 Uniform Nearest Neighbor 1.05 1.15 1.25 1.35 1.45 1.05 1.15 1.25 1.35 1.45 N N o r m a i l z e n E d e  r y g 0.95 1 4 8 16 SerializationRatio(n:1) 0.95 1 4 8 16 SerializationRatio(n:1) 1.35 1.45 1.55 1.35 1.45 1.55 Bit Complement Tornado  e n E d e r y g 0.95 1.05 1.15 1.25 1 4 8 16 SerializationRatio(n:1) 0.95 1.05 1.15 1.25 1 4 8 16 SerializationRatio(n:1) N o r m a i l z Fig. 8. Energy consumption normalized to baselineT SV for different trafﬁc patterns. patterns, nearest neighbor shows least performance reduction, while bit complement shows worst performance loss. The energy consumption of the interconnection network normalized to baselineT SV is shown in Fig. 8. Since the energy consumption of inductive/capacitive-coupling vertical links can range from 0.1pJ to several hundred pJ, we study how the energy overhead changes over a range of link energies. This ﬁgure shows that both high serialization ratio and large inductive/capacitive-coupling link energy increase the energy overhead as compared to TSV. In addition, inductive/capacitive-coupling link energy affects the energy Uniform NearestNeighbor 3 2.75 2.5 2.25 2 2 1.75 1.5 1.25 1 a i l z d e a L t n e y c 1.5 2 3 Freq quency(Ghz) N o r m e k c a P t  BitComplement Tornado 4 5 Fig. 9. Message latency reduction with higher transmission frequencies. 1 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 2:1wocomp. 2:1wcomp. 4:1 wocomp. 4:1 wcomp. sap sjas N o r m a i l z d e I  C P 8:1wocomp. 8:1wcomp. sjbb tpc Fig. 10. Effectiveness of data compression in improving IPC. 1C 0.95 0.9 0.85 0.8 0.75 2Ghz 3Ghz z SAP SJAS N o r m a i l z d e I  P 4Ghz 5Ghz SJBB TPC Fig. 11. Impacts of higher transmission frequency on IPC. overhead to a greater extent. In order to constrain the overhead under 10% at 8:1 serialization ratio, the link energy has to be less than 0.5pJ/b. Then, we study the effectiveness of high-speed asynchronous transmission in recovering performance loss. In this evaluation, a moderate load ratio of 0.05, and an serialization ratio of 4:1 are assumed. The message latencies with different transmission frequencies are plotted in Fig. 9 and normalized to the baselineT SV . The y -axis of this ﬁgure only ranges from 1 to 3, as we consider that latencies that are three times higher are already beyond saturation. It can be seen that with the successively increasing transmission frequency, the packet latency is continuously decreasing. At 5Ghz, the average latency overheads is reduced to 25%. B. Study with Multi-Thread Applications In this subsection, four multi-thread benchmarks (sap, sjas, sjbb, and tpc) are simulated. Each of the benchmarks runs 16 threads on the 16 cores. In every run we ﬁrst warm up the cache states by 3 million instructions for each thread, and then collect statistics for the next 5 million instructions. The IPCs of the benchmarks both without data compression 1.4 1.35 1.3 1.3 1.25 1.2 1.15 1.1 1.05 1 0.95 1.4 1.35 1.3 1.3 1.25 1.2 1.15 1.1 1.05 1 0.95 0.5pJ sap 1.5pJ sjas e e n E d e r y g 0.1pJ 1.0pJ 2.0pJ 1 4 8 1 4 8 N o r m a i l z  SerializationRatio(n:1) SerializationRatio(n:1) 1.4 1.35 1.3 1.25 1.2 1 15 1.15 1.1 1.05 1 0.95 1.4 1.35 1.3 1.25 1.2 1 15 1.15 1.1 1.05 1 0.95 sjbb tpc i i l z e n E d e  r y g 1 4 8 SerializationRatio(n:1) 1 4 8 SerializationRatio(n:1) N o r m a Fig. 12. Energy of interconnection network for multi-thread applications without data compression. 481         0.1pJ y g r e n E d e  z i l a m r o N y g r e n E d e  z i l a m r o N 1.3 1.25 1.2 1.15 1.1 1.05 1 1.3 1.25 1.2 1.15 1.1 1.05 1 1.5pJ sjas 2.0pJ 4 8 Serialization Ratio (n:1) SerializationRatio(n:1) tpc 0.5pJ sap 4 8 Serialization Ratio (n:1) SerializationRatio(n:1) sjbb 1.0pJ 1.3 1.25 1.2 1.15 1.1 1.05 1 1.3 1.25 1.2 1.15 1.1 1.05 1 4 8 SerializationRatio(n:1) 4 8 SerializationRatio(n:1) Fig. 13. Energy of interconnection network for multi-thread applications with data compression. NoComp.orAsync. Comp.Only Comp.+Async. d e z i i l a m r o N y c n e i c i f f  E a e r A 1 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 0.45 SAP SJA AS SJBB TPC Fig. 14. Area efﬁciency of the interconnection network when different techniques are successively applied. and with data compression are plotted in Fig. 10 and also normalized to the baseline. It can be seen that serialization does negatively impact the performance, and for a serialization ratio of 8:1, the performance is reduced to around 60% of original performance. With data compression used, this performance gap shrinks, especially for sap and tpc that have relatively high zero-pattern ratios. The energy consumption of interconnection network normalized to baselineT SV is plotted in Fig. 12 without data compression, and in Fig. 13 with data compression. Without data compression, the energy overheads of the benchmarks are similar to that of synthetic trafﬁcs. With 0.5pJ/b link energy, the overhead can be limited under 10%. With data compression, on the other hand, the average energy overhead is reduced to 5% with 0.5pJ/b link energy. Although effective, data compression is not able to recover the performance to satisfaction (only 70% to 75% in the 8:1 case). Asynchronous transmission is then exploited to further reduce the performance gap. For the serialization ratio of 8:1, we improve the transmission frequency to 2, 3, 4, and 5Ghz respectively. The results normalized to the baseline are shown in Fig. 11, which validate that increasing transceiver frequency improves the IPC. At 5Ghz, the performance losses of the benchmarks have been reduced to under 6%. C. Area Efﬁciency For a more comprehensive evaluation, we study the area efﬁciencies of the interconnection network in terms of the performance of multi-thread applications. We deﬁne the area efﬁciency to be (I P C/Router Area). Three cases are compared: (a) no data compression nor asynchronous transmission is used; (b) only data compression is used; and (c) both data compression and asynchronous transmission are used. For all cases, the serialization ratio is 8:1. For asynchronous transmission, the transmission frequency is set to 5Ghz. The inductive/capacitive-coupling link pitch is set to 70um, a moderate value among existing designs. The area efﬁciencies of using inductive/capacitive-coupling vertical links are normalized to baselineT SV . The results are shown in Fig. 14. Without data compression and asynchronous transmission, the average area efﬁciency of the four benchmarks is only 55% of baselineT SV .When data compression is applied, the average area efﬁciency is increased to 67%. Finally, the area efﬁciencies of all four benchmarks are improved to over 90% when both data compression and asynchronous transmission are used, with an average of 92%. V I . CONC LU S ION In this work we propose design methodologies for using inductive/capacitive-coupling vertical links in 3D NoC. To address the area overheads of these links, serial communication is adopted and it is shown that to reduce the overhead under 10%, the serialization ratio has to be at least 8:1. We design and implement asynchronous transceivers that can do in-place zero-pattern compression simultaneously with serialization. As a result of the three techniques, the performance of multi-thread applications are improved to over 94% of the baseline case, and the area efﬁciency is brought to above 90%of TSV. Finally, the energy overheads can be bounded under 10% with a link energy less than 0.5pJ/b "
2010,Design space exploration and performance evaluation at Electronic System Level for NoC-based MPSoC.,"System-on-Chip (SoC) has become a common design technique in the integrated circuits industry as it offers many advantages in terms of cost and performance efficiency. SoCs are increasingly complex and heterogeneous systems that are highly integrated comprising processors, caches, hardware accelerators, memories, peripherals and interconnects. Modern SoCs deploy not only simple buses but also crossbars and Networks-on-Chip (NoC) to connect dozens or even hundreds of modules. However, it is difficult to evaluate the performance of these interconnects because of their complexity. This is a potential design risk. In order to address this challenge, early design space exploration is required to find appropriate system architectures out of many candidate architectures. An appropriate interconnect architecture is a fundamental outcome of these evaluations since its latency and throughput characteristics affect the performance of all attached modules in the SoC. In this paper we show how to perform early design space exploration using our Electronic System Level (ESL) performance evaluation framework SystemQ. We use a heterogeneous MultiProcessor SoC that features a complex NoC as a central interconnect. Based on this example we show the importance of proper abstraction in order to keep simulation efforts manageable.","Design Space Exploration and Performance Evaluation at Electronic System Level for NoC-based MPSoC S ¨oren Sonntag and Francisco Gilabert1 Lantiq Deutschland GmbH Design Platforms & Services Email: {soeren.sonntag|francisco.gilabert}@lantiq.com Munich-Neubiberg, Germany Abstract—System-on-Chip (SoC) has become a common design technique in the integrated circuits industry as it offers many advantages in terms of cost and performance efﬁciency. SoCs are increasingly complex and heterogeneous systems that are highly integrated comprising processors, caches, hardware accelerators, memories, peripherals and interconnects. Modern SoCs deploy not only simple buses but also crossbars and Networks-on-Chip (NoC) to connect dozens or even hundreds of modules. However, it is difﬁcult to evaluate the performance of these interconnects because of their complexity. This is a potential design risk. In order to address this challenge, early design space exploration is required to ﬁnd appropriate system architectures out of many candidate architectures. An appropriate interconnect architecture is a fundamental outcome of these evaluations since its latency and throughput characteristics affect the performance of all attached modules in the SoC. In this paper we show how to perform early design space exploration using our Electronic System Level (ESL) performance evaluation framework SystemQ. We use a heterogeneous MultiProcessor SoC that features a complex NoC as a central interconnect. Based on this example we show the importance of proper abstraction in order to keep simulation efforts manageable. I . INT RODUCT ION Modern Systems-on-Chip comprise a multitude of functional blocks such as processors, hardware accelerators, peripherals, and on-chip and off-chip memories. A powerful interconnect backbone is required to fulﬁll the communication needs of these modules. However, an interconnect is just a means to an end. It should therefore require only little chip area, consume almost no power and it must meet all communication constraints given by the attached modules. Certainly, all of these requirements cannot be met at the same time. Hence, the design of an interconnect is at least a trade-off between performance and chip area. Today’s SoCs comprise several dozens of modules, nextgeneration systems might include up to several hundreds. This makes interconnect design cumbersome since the communication requirements of all modules must be taken into account in order to ﬁnd the best interconnect design for the overall system. Major concerns for the design of an interconnect 1 The author is also afﬁliated with the Parallel Architectures Group of Universidad Polit ´ecnica de Valencia, Spain. Email: fragivil@gap.upv.es are the trafﬁc patterns of the communication between master and slave modules (called terminals). Two main properties are especially important: throughput and latency. Trafﬁc ﬂows with high throughput, i. e. bandwidth, requirements need to be prioritized while not starving low-throughput ﬂows. Lowlatency ﬂows must be scheduled quickly by the interconnect independently of their throughput requirements. In order to tackle all of these requirements Design Space Exploration (DSE) can be used to ﬁnd promising system architectures within a vast design space. DSE must take the trafﬁc requirements of the communication partners into account. Cost functions must be applied to ﬂows in order to minimize overall trafﬁc costs. Furthermore, existing building blocks for the interconnect must be considered. Design constraints need to be incorporated such as achievable clock frequencies, buffer sizes, and the bitwidth of data paths. Putting all parameters together an incredible large design space is created that needs to be explored. At the end of the exploration an optimal interconnect is available. However, in practice there is not one optimal interconnect since many constraints must be met. Thus, a number of interconnects is created via DSE that need to be evaluated extensively. Hence, in a second step abstract performance evaluation is used to assess the interconnects found via DSE in more detail by focusing on the trafﬁc requirements. Realistic trafﬁc patterns must be applied to stress the system and dependencies among ﬂows should be considered, namely contention at arbiters and congestion at frequently used resources. The outcome of the evaluations will be the best interconnect for a given number and type of terminals as well as for a given trafﬁc scenario, i. e. a given application. This is typically hard to achieve since the interconnect cannot satisfy all communication requirements to the same extent. However, there could be a best interconnect for, e. g., overall highest throughput or overall lowest latency. In this paper we show how to perform early DSE and performance evaluation using our ESL performance evaluation framework SystemQ [9]. We use a heterogeneous MultiProcessor SoC (MPSoC) as a case study that features a complex NoC as central interconnect backbone. Many parameters 978-1-4244-819 - /10/$26.00 ©2010 IEEE 4 1 336 of the NoC, such as clock frequency, buffer sizes, and topology will be explored. We emphasize the importance of realistic trafﬁc ﬂows for our performance evaluations while retaining considerably high abstraction levels for our simulations. The rest of this paper is structured as follows: In the next section we discuss related work. In Section III we introduce our DSE approach and present exploration results. Section IV concludes this paper. I I . RE LAT ED WORK Several works exist that address the design space exploration topic or some of its steps. The work in [7] presents a methodology to calculate possible mappings of the terminals of an SoC that achieves good performance and reduced power consumption, but it is limited to 2D-mesh topologies. In [6], a method to provide an optimal NoC for a system trafﬁc pattern represented as a graph is presented. In [5] a whole tool to perform DSE of embedded systems is presented, while the work in [4] presents a process to perform design space exploration of VLIW architectures. Both works require to have some complex estimations of the system trafﬁc pattern, like traces. Finally, in [1] a full design methodology for automatic generation of heterogeneous NoC-based systems is presented. This work is oriented to multi user systems in which the user behavior with a device is gathered to guide the design process of new generations of similar devices. I I I . DE S IGN S PACE EX P LORAT ION The ﬁrst step of a DSE is the deﬁnition of the design space boundaries. These boundaries represent the designer’s desires and objectives, and should be deﬁned in a format easy to understand and to use but powerful enough to represent a wide variety of designs. Starting from those boundaries the DSE process is performed, providing the best candidate within the design boundaries. DSE processes are easy to depict as a pipeline in which each stage expands the design space calculated in previous stages by generating new candidates according to the design space constraints. In order to provide an affordable exploration time, the design space should be cropped of suboptimal candidates as soon as possible, avoiding their expansion in a higher number of suboptimal candidates later on in the pipeline, while keeping candidates that may become optimal in later stages. As the number of elements in an SoC increases, the time required to explore the full design space grows exponentially. For example, while there are only six possible terminal placements for a three terminal SoC, this number quickly grows to more than forty thousand for a small SoC composed of eight terminals. In this context, brute forces approaches are discarded, forcing the use of approaches based on heuristics or other kind of trade-offs between execution time and accuracy. Figure 1 shows a high level diagram of our DSE pipeline, composed of four stages: design deﬁnition, design space initialization, design space exploration and output generation. Design space definition Design space initialization Topologies + placements Design space exploration Generation Simulation Evaluation Output generation Fig. 1. High level view of our design space exploration tool. a) b) Initiator Target Target Initiator Fig. 2. Optimal placement of target and initiator a) for a write transaction and b) for a read transaction. A. Design space deﬁnition The ﬁrst step is the deﬁnition of the design space constraints and parameters. It comprises three main classes: design deﬁnition, design constraints and performance objectives. In this context, the DSE builds the design space by expanding the design deﬁnition with the design constraints, and provides the best candidates that meet the performance objectives. The design deﬁnition class includes all parameters that allow the designer to deﬁne the design space, like the number of terminals, the type of each terminal, the different topology types that should be considered (i. e. 2D mesh, rings, trees, . . . ) or the trafﬁc ﬂows that deﬁne the design communication pattern. Inside this class, the deﬁnition of the trafﬁc ﬂows is the most complex and most important task as it deﬁnes the rules to guide the terminal mapping for different topologies in the design space. The trafﬁc ﬂows also impact the results of the DSE tool since the accuracy of the simulations is heavily dependent on the way trafﬁc generators work. In literature three major trafﬁc generation approaches exist. First, synthetic trafﬁc patterns are used to send generic messages to predeﬁned or random destinations at a given rate [3], [8] but this is too generic for SoC design. Second, benchmarks and traces can be used but hardware architectures and application constraints must match the target design. Third, mathematical models could be used, however it is difﬁcult to ensure that they are representative for given application constraints. Our approach to address this issue is to use fully programmable trafﬁc generators, that allow the designer to specify the trafﬁc requirements of each terminal as accurate as possible, for example providing support to several 337 trafﬁc ﬂows per terminal, (each one with different parameters, like communication frequency or size), or by distinguishing between transaction types. The design constraints class is composed of all the parameters that deﬁne the boundaries of the design space, e. g. frequency ranges, buffer sizes or number of virtual channels. Finally, the performance objectives class deﬁnes the rules that will distinguish between optimal and suboptimal candidates, like throughput or latency requirements. Although the DSE process should run autonomously, we believe that the designer must have a certain degree of control over the DSE decisions. In our approach design constraints and performance objectives are clustered in groups that will be processed individually. In this way, the designer can sort the groups in order to determine which constraints are evaluated ﬁrst and thereby deﬁning a path through the design space. B. Design space initialization In this stage the initial set of candidates is generated according to the design space deﬁnition. Each candidate from the initial set will be later expanded into a new subset of candidates by applying the design space constraints. In our implementation this stage calculates the possible topologies that may accommodate the terminals of the design according to the design space deﬁnition. Then, for each possible topology, the optimal placement of the terminals is calculated according to the design space trafﬁc ﬂows. To perform the placement, each trafﬁc ﬂow is assigned a weight according to the trafﬁc ﬂow communication frequency and the amount of data of each transaction. Then, the terminals are placed in the topology according to the weight of the ﬂows in which they are involved, minimizing the distance (in hops) of the ﬂows with higher weight at the cost of ﬂows with lower weight. In this step the differentiation between read and write transactions is very important. Figure 2 shows the optimal placement of a ﬂow in an unidirectional ring according to the transaction type. In case of a write transaction the distance from the initiator to the target is critical while the distance from the target to the initiator is irrelevant. On the contrary, as read transactions are composed of a short request message from the initiator to the target and a longer response message from target to initiator, the distance from the target to the initiator is the one that becomes critical. This step is critical to the DSE tool speed, as if irrelevant candidates are allowed in the initial set, the later stages of the DSE may waste a considerable amount of time in candidates that will ﬁnally be discarded later on. Figure 3 shows the time spent calculating valid placements for an optimal set of candidates topologies and for a suboptimal one, for an SoC composed of different number of terminals. The optimal set of topologies is composed of those topologies that will have good placements for the design trafﬁc ﬂows, while the suboptimal set was calculated by a brute force approach, and includes all possible topologies deﬁned in the design space. As shown in the ﬁgure, the execution time is greatly reduced when irrelevant candidates are removed as soon as possible. Suboptimal  Optimal  ) s d n o c e s ( e m i T 0 0 0 1 0 0 8 0 0 6 0 0 4 0 0 2 0 20 40 60 80 100 System size (terminals) Fig. 3. Placement time for optimal and suboptimal sets of topologies for different system sizes. C. Design space exploration This stage is the core of the DSE engine. Due to the high number of possible candidates that may form a design space, advance techniques to reduce the number of candidates are required in order to keep the performance of the DSE tool within acceptable levels. A common approach in this cases is the use of genetic algorithms [7]. A good example is the NSGA-II algorithm [2], that enables the exploration of huge sets of multi-parametric spaces at a relatively low cost, while keeping a good accuracy. Those algorithms are carried out in several iterations, in which the best candidates of the previous iterations evolve into a new generation of candidates during a pseudo-random mutation process. Although it is not guaranteed that the best candidate will be found, this method will provide good enough results while signiﬁcantly reducing the number of candidates evaluated, thus becoming a good trade-off solution between accuracy and speed. In our implementation, the DSE engine is divided in three different steps as depicted in Figure 1. The ﬁrst step consists of the generation of new candidates, while the second step is the simulation of those new candidates. Finally, the third and last step is the evaluation of the simulation results. Those steps form a loop, in which each iteration evaluates the set of candidates generated from the candidates that survived the previous iteration. This deﬁnition of the DSE engine allows the exploration of the design space in several iterations, making it well suited for genetic algorithms. The simulation engine plays a vital role in the DSE tool accuracy and speed. The DSE accuracy heavily depends on the number of candidates evaluated. If the simulation time is too high, the number of candidates to analyze must be reduced in order to get an acceptable DSE execution time. Our approach to reduce the simulation cost is based on three pillars. First, we use accurate high level models developed in our ESL framework SystemQ. This framework allows the designer to quickly produce fast cycle-approximate models of any NoC component, together with advanced programmable trafﬁc generators. Those trafﬁc generators alleviate the impact 338   several possible numbers of virtual channels per port (both in the nodes and in the NIs). We also allow the tool to attach up to four terminals per node. Figure 4 depicts the DSE results grouped by topology. The ﬁgure shows the suitability for latency or throughput sensitive scenarios normalized to the best candidate for each metric. Due to limited space we show here only a couple of candidates for each topology. For latency sensitive scenarios, we can classify the candidates in two groups, the ones that provide the best average latency and the ones that provide the lowest maximum latency. While the former candidates are best suited for overall latency, the latter are better for systems with a tight upper bound on communication latency. As illustrated in the ﬁgure, mesh conﬁgurations show a very similar average latency, while the 3×4×3 mesh presents the lowest maximum latency, making this topology the best choice for latency sensitive scenarios. This topology also shows the best throughput of the whole design space. Notice that this topology requires 36 nodes, while the other options, like the 3×3×2 mesh and the bidirectional ring with 18 nodes require half this number of nodes. This maybe an important fact when the implementation cost and the power consumption of the design are evaluated in the later stages of the DSE. IV. CONCLU S ION In this paper we have shown how early design space exploration and performance evaluation can be used to ﬁnd an optimal system architecture for a NoC-based SoC with reasonable effort. We introduced our DSE tool that allows the designer to specify trafﬁc and design constraints. Its output is a number of system architectures ordered by suitability for a given metric like overall maximum latency, average latency or throughput as shown in a case study of a 36-terminal SoC. ACKNOW L EDGM EN T This work has been supported by the project NaNoC (project label 248972) which is funded by the European Commission within the Research Programme FP7. "
2011,A low-swing crossbar and link generator for low-power networks-on-chip.,"Networks-on-Chip (NoCs) are emerging as the answer to non-scalable buses for connecting multiple cores in Chip Multi Processors (CMPs), and multiple IP blocks in Multi Processor Systems-on-Chip (MPSoCs). These networks require an extremely low-power datapath to ensure sustained scalability, and higher performance/watt. Crossbars and links form the core of a network datapath, and integrating low-swing links within these will reduce power significantly. Low-swing links however require significant custom circuit design effort to deliver good power efficiency and high bit rate, in the face of noise. As a result, low-swing links have not been able to make it to mainstream chips which rely on crossbar and link generators from RTL. In this paper, we present a datapath generator that creates automated layouts for crossbars with noise-robust low-swing links within them. To the best of our knowledge, this is the first crossbar generator that (1) creates layouts, instead of generating just synthesizable RTL; and (2) integrates noise-robust low-swing links in an automated manner. We demonstrate our generated datapath in a fully-synthesized NoC router, and observe 50% power reduction on datapath.","A Low-Swing Crossbar and Link Generator for Low-Power Networks-on-Chip Chia-Hsin Owen Chen1 , Sunghyun Park2 , Tushar Krishna1 , Li-Shiuan Peh1 Dept. of Electrical Engineering and Computer Science, Massachusettes Institute of Technology, Cambridge, MA 02139 1 {owenhsin, tushar, peh}@csail.mit.edu, 2 pshking@mit.edu Abstract—Networks-on-Chip (NoCs) are emerging as the answer to non-scalable buses for connecting multiple cores in Chip Multi Processors (CMPs), and multiple IP blocks in Multi Processor Systems-on-Chip (MPSoCs). These networks require an extremely low-power datapath to ensure sustained scalability, and higher performance/watt. Crossbars and links form the core of a network datapath, and integrating low-swing links within these will reduce power signiﬁcantly. Low-swing links however require signiﬁcant custom circuit design effort to deliver good power efﬁciency and high bit rate, in the face of noise. As a result, low-swing links have not been able to make it to mainstream chips which rely on crossbar and link generators from RTL. In this paper, we present a datapath generator that creates automated layouts for crossbars with noise-robust low-swing links within them. To the best of our knowledge, this is the ﬁrst crossbar generator that (1) creates layouts, instead of generating just synthesizable RTL; and (2) integrates noise-robust low-swing links in an automated manner. We demonstrate our generated datapath in a fully-synthesized NoC router, and observe 50% power reduction on datapath. I . IN TRODUC T ION Continued transistor scaling has enabled more compute and storage units to be added on the same chip. However, power limitations have forced designers to go parallel and to realize sustained throughputs with simpler computing blocks connected together. In the processor domain, the power limitations have resulted in the emergence of CMPs, while in the embedded domain, MPSoCs have started becoming popular. These trends put the interconnection fabric into limelight to enable fast and low-power communication between these processing units. On-chip buses are not scalable beyond a few cores, since they are limited by wire-delay and bandwidth [1]. There has been a trend towards using NoCs to manage wires more efﬁciently. For some systems, this network might comprise only a crossbar [2], while for others, an interconnection of packet-switched routers is used [3], [4] with each router comprised of buffers, arbiters, and a crossbar to enable sharing of links. In both kinds of systems, a crossbar is the fundamental building block that connects input ports to output ports. A 1-bit N × M crossbar consists of N × M interconnected wires that are controlled by switches and enable any port to connect to any other port. The outputs of a crossbar connect to links that then connect to an IP block or a router. The crossbar and links thus together form the datapath of a NoC. This datapath has been found to dominate the NoC power consumption. Fabricated chips from academia, such as MIT RAW [5] and UT TRIPS [6], use RTL synthesis to generate the datapath, and the ratio of datapath power consumption and the total on-chip network power consumption are reported to be 69% and 64%, respectively. Intel TERAFLOPs [4] uses a custom-designed double-pumped crossbar with a location based channel driver to reduce the channel area and peak channel driver current [7] and is thus able to reduce datapath power to 32% of the total on-chip network power. Other circuit techniques that have been proposed to reduce this power consumption involve dividing the crossbar wires into multiple segments and partially activating selected segments [8], [9] based on the input and output ports. These circuit techniques present only the capacitance between the input and output port, and disable/reduce other capacitances. They are thus successful in reducing wasteful power consumption. However, they still require complete charging/discharging of the long wires from the input port to the output port and the core-core links, which are signiﬁcant power consumers. Low-swing signaling techniques can help mitigate the wire power consumption. The energy beneﬁts of low-swing signaling have been demonstrated on-chip from 10mm equalized global wires [10], through 1-2mm core-to-core links [11], to less than 1mm within crossbars [12]–[14]. However, such low-swing signaling circuits, which can be viewed as analog circuits, require full custom design, resulting in substantial design time overhead. Circuit designers have to manually design schematic/netlists, optimize logic gates for each timing path, and size individual transistors. Moreover, layout engineers have to manually place all the transistors and route their nets with careful consideration of circuit symmetry and noise coupling. This custom design process leads to high development cost, long and uncertain veriﬁcation timescales, and poor interface to other parts of a many-core chip, which are mostly RTL-based. In the past, designers faced similar challenges while integrating low-power memory circuits with the VLSI CAD ﬂow, with their sense ampliﬁers, self-timed circuits and dynamic circuits. Memory compilers, which are now commonplace, have solved the problem and enabled these sophisticated analog circuits to be automatically generated, subject to variable constraints speciﬁed by the users. This paper proposes to similarly automate and generate low-swing signaling circuits as part of the datapath (crossbar and links) of a NoC, thereby integrating such circuits within the CAD ﬂow of many-core chips, enabling their broad adoption. 978-1-4577-1400-9/11/$26.00 ©2011 IEEE 779 Since crossbars and links are such an essential component of on-chip networks, there have been efforts in the past to automate their generation. Sredojevic and Stojanovic [15] presented a framework for design-space exploration of equalized links, and a tool that generates an optimized transistor schematic. However, they rely on custom-design for the actual layout. ARM AMBA [16], STMicroelectronics STBus [17], Sonics MicroNetworks [18], and IBM CoreConnect [19] are examples of on-chip bus generators; DX-Gt [20] is a crossbar generator; and ×pipes [21] is a network interface, switch and link generator. These tools are aimed at application speciﬁc network-on-chip (NoC) component generation, but they all stop at the synthesizable HDL level, i.e. they generate RTL, and then rely on synthesis and place-and-route tools to generate the ﬁnal design. This is not the most efﬁcient way to design crossbars, as we show later in Section IV, highlighting that a synthesized crossbar design consumes signiﬁcantly more power than a custom low-swing crossbar. Contribution. In this work we present a NoC datapath generator, which is the ﬁrst to integrate low-swing links in an automated manner. It is also the ﬁrst to generate a noiserobust layout at the same time, embedded within the synthesis ﬂow of a NoC router. Our tool takes a low-swing driver as input and ensures (1) a crosstalk noise-robust routing, (2) supply noise-robust differential signaling, and (3) crosstalkcontrolled full-shielded links, in the generated datapath. To the best of our knowledge, our tool provides the following important contributions to the low-power NoC community: 1) It is the ﬁrst automated generation of noise-robust lowswing links within the crossbar, and between routers. 2) It is the ﬁrst automated layout generation of a crossbar for a user speciﬁed number of ports, channel-width, and target frequency. 3) It is the ﬁrst demonstration of a generated low-swing crossbar and link within a fully-synthesized NoC router. 4) Our automatically generated low-swing crossbar achieves an energy savings of 50%, at the same targeted frequency of the synthesized crossbar, at 3-4 times the area overhead. Relative to the entire router, the larger footprint of the crossbar is manageable, at just 30% of the overall router area. The rest of the paper is organized as follows. Section II presents some background on crossbars and low-swing link design. Section III explains our low-swing crossbar and link generator. Section IV provides some evaluation results for some datapaths generated using our tool, and Section V concludes the paper. I I . BACKGROUND In this section we present background on crossbars, lowswing links, and the limitations of the current synthesis ﬂow. A. Crossbar A N × M crossbar connects N inputs to M outputs with no intermediate stages, where any inputs can send data to any non-busy outputs. Figure 1 shows the schematic of a 2-bit Din0<0> Din0<1> Din1<0> Din1<1> Din2<0> Din2<1> Din3<0> Din3<1> Din0<0> Din1<0> Din2<0> Din3<0> Din0<1> Din1<1> Din2<1> Din3<1> > 0 < 0 u o t D > 1 < 0 u o t D > 0 < 1 u o t D > 1 < 1 u o t D > 0 < 2 u o t D > 1 < 2 u o t D > 0 < 3 u o t D > 1 < 3 u o t D > 0 < 0 u o t D > 0 < 1 u o t D > 0 < 2 u o t D > 0 < 3 u o t D > 1 < 0 u o t D > 1 < 1 u o t D > 1 < 2 u o t D > 1 < 3 u o t D (a) Port-sliced organization (b) Bit-sliced organization Fig. 1. 2-bit 4 × 4 crossbar schematic (a) (b) (c) Fig. 2. Logical 4:1 multiplexer (a) and two realizations (b)(c) 4 × 4 crossbar. In effect, a 1-bit N ×M crossbar consists of M N : 1 multiplexers, one for each output. The N : 1 multiplexer can be realized as one logic gate or cascaded smaller N ′ : 1 multiplexers, where N ′ < N , as shown in Figure 2. A customcircuit designer often favors the former implementation due to the layout regularity, as it enables various optimization techniques. However, this implementation suffers from the fact that the intrinsic delay of the multiplexer grows with N . Synthesis tools usually use the latter approach that cascades smaller multiplexers to implement a N : 1 multiplexer with arbitrary N . By using this approach, the intrinsic delay grows with log N instead of N . However, it may lead to higher power consumption since more multiplexers are used. Two gate organizations are possible for many-bit crossbars, as shown in Figure 1. One organization, port-slicing, groups all the bits of a port close to each other. The other organization, bit-slicing, groups all the gates of a bit together. The former approach eases routing (since all bits for an input/output port are grouped together), and minimizes the span of the control wires that operate the multiplexers for each input port. However, using the former approach leaves lot of blank spots that increases area, and folding the crossbar over itself to reduce area is non-trivial. The latter approach, on the other hand, minimizes the distance between the gates that contribute to the same output bit. This design is easier to optimize for area by placing all the bit-cells together and eliminating blank spaces, but requires more complicated routing to ﬁrst spread out and then group all bits from a port. In addition to a crossbar, links and receivers form a datapath. 780 Vdd Transm itter Vswing R Vdd Receiver Cd 1/2Cw 1/2Cw CL Fig. 3. Simpliﬁed datapath Different design decisions for these components would result in trade-offs in area, power and delay. From the perspective of sending a signal, a datapath can be simpliﬁed to three components connected together: a transmitter, a wire, and a receiver, as shown in Figure 3. The corresponding delay and energy consumption can be formulated as follows: Energy = (Cd + Cw + CL )VDD Vswing Delay = ((Cd + Cw + CL )Vswing /Iav ) (1) (2) where Cd is the output capacitance of the transmitter, Cw is the wire capacitance, CL is the input capacitance of the receiver. VDD is the power supply of the circuit, and Vswing is the voltage swing on these capacitors. Iav is the average (dis)charge current. In general, lowering the capacitance, reducing the voltage swing, and increasing the (dis)charging current can help in reducing energy consumption and delay. A transmitter with larger sized transistors would have larger (dis)charging current which would decrease the delay. But it has larger footprint and Cd . Greater wire spacing lowers the coupling capacitance between wires but it takes larger metal area. Increasing wire width could reduce the wire resistance but it also increases capacitance and metal area. B. Low-swing signaling Current on-chip network architectures require both long interconnects for the connection of processor cores, and small wire spacing for higher bandwidth. This trend has significantly increased wire capacitance and resistance. Unfortunately, physical properties of the on-chip interconnects are not scaling well with transistor sizes. To reduce the delay and power consumption caused by these RC-dominant wires, low-swing circuit techniques [22] are now in the spotlight of on-chip networks. In low-swing interconnects, the propagation delay decreases linearly with the signal swing, under the condition that the charge/discharge current is not affected by the reduction in voltage swing. Furthermore, the lower signal swing carries the major beneﬁt of reducing dynamic power consumption, which can be substantial when the interconnect load capacitance is large. The low-swing signaling schemes, however, give rise to noise concerns. Some of the noise concerns in low-swing designs can be mitigated by sending data differentially, which helps eliminate common-mode interference. However, this takes up two wires Library / Module generators HDL RTL synthesis Logic optimization Physical design Layout Fig. 4. Standard synthesis ﬂow which doubles the capacitance and area. Adding shielding wires also helps reduce crosstalk and could potentially lower voltage-swing, but it also adds coupling capacitance and area. Increasing the sensitivity of the receiver helps lower voltageswing on the wires, but it often needs a larger sized transistor or more sophisticated receiver design that has larger footprint and capacitance. Thus low-swing links offer tremendous advantages in terms of power, and latency, but require careful design to ensure robust performance. C. Limitations to current synthesis ﬂow Given a hardware description of a crossbar, the existing synthesis ﬂow, like the one shown in Figure 4, with a standard cell library could synthesize and realize a crossbar circuit. Unfortunately, the existing synthesis ﬂow and standard cell libraries are designed for full voltage-swing digital circuits. New features in certain CAD tools enable low power designs by supporting multiple power domains and power shutdown techniques. However, none of them support analysis and layout for low voltage swing operations. Moreover, place-and-route tools are often too general and cannot take full advantage of the regularity of a crossbar and fail to generate an area-efﬁcient layout. Therefore, a system designer needs to custom-design a low-swing crossbar, which is time-consuming and error-prone. I I I . DATA PATH G EN ERATOR In this section we present our crossbar and link generator for low-swing datapaths. The low-swing property is enabled by replacing the cross-points of a crossbar with low-swing transmitters, and adding receivers at the end of the links to convert low-swing signals back to full-swing signals. The data links that connect transmitters and receivers are equipped with shielding wires to improve signal integrity. As shown in Table I, our proposed datapath generator takes architectural parameters (e.g. the number of inputs and outputs, data width per port, link length), user layout preferences (e.g. port locations, link width and spacing), and technology ﬁles (e.g. standard cell library, targeted metal layers, TX and RX cells), and generates a crossbar and link layout that meets speciﬁed 781 IN PU T S TO PRO PO S ED DATA PATH G EN ERATOR TABLE I Type Architectural parameters User preferences Technology related information System design constraints Proposed datapath generator Number of input ports (N ) Number of output ports (M ) Data width in bits (W ) Link length (L) Input port location Output port location Link wire width and spacing Standard cell library Metal layer information Transmitter and receiver design Second power supply level (if needed) Target frequency, power, area Transmitters and Receivers Layout Tech Files Architectural Parameters User Preferences Building block characterization Layout generation Verification & extraction Design selection Selection .gds, .sp, .lib, .lef, .v Extraction Can be directly fed into synthesis flow Post-characterization for delay, power, area Library Generation Fig. 5. Proposed Datapath Generator’s Tool ﬂow VDD VDD VDD VDD A Ab Din Ab A VSS VSS VDD En Enb VSS Enb Doutb Enb Dout Ab A VDDL VDDL (a) Transmitter VDD Clk Clk P Pb P Dout Din Dinb Pb Doutb Clk VSS (b) Receiver Fig. 6. Schematic of transmitter and receiver TABLE II PR E -CHARAC T ER I ZAT ION R E SU LT S Average current (µA) Input cap (fF) Transmitter 2.6 1.52 (select) 2.87 (data) Receiver 11.0 1.05 (clk) 0.4 (data) A. Building block pre-characterization We treat the 1-bit transmitters and receivers as atomic building blocks of the generator, thus giving users the ﬂexibility of using different kinds of transmitter and receiver designs. Given the transmitter and receiver designs, the generator ﬁrst performs pre-characterization using Spice-level simulators (we used Cadence UltraSim) to obtain average current and input capacitances. The average current is later used to determine the power wire width, while the input capacitances are used to determine the size of the buffers that drive these building blocks. For example, Figure 6 depicts the schematic of a lowswing transmitter design and a receiver design we chose as inputs to the generator. The experiments in both this section and Section IV are performed using the IBM 45 SOI HVT technology, and the pre-characterization results are shown in Table II. user preferences and system design constraints: area, power, and delay. The output ﬁles of our proposed datapath generator are fed directly into a conventional synthesis tool ﬂow, which is similar to how we use a memory compiler. Figure 5 shows the proposed datapath generation ﬂow. The generation involves two phases, library generation and selection. In the library generation phase, the program takes a suite of custom-designed transmitters and receivers, architectural parameters that users are interested in, and technology ﬁles as inputs; Then, it precharacterizes the custom circuits. Next, the tool generates the layout of all possible combinations and simulates them to get post-layout timing, power, and area. This forms the library of components for the selection phase. In the selection phase, the generator takes architectural parameters and user preferences as inputs to ﬁnd the most suitable design from the results generated in the library generation phase, and outputs the ﬁles needed for the synthesis ﬂow. In the following subsections, we walk through a detailed example of generating a datapath with a 64-bit 6×6 crossbar, 1mm links, and receivers in a 45nm SOI HVT technology. B. Layout generation In this step, the generator tiles the transmitters and receivers to form the datapath, taking various aspects into consideration, such as building block restrictions, ﬂoorplanning, routing, and link design. This section details each of these aspects. 1) Building block restrictions: We applied constraints to the transmitters’ and receivers’ pin locations. The reason is twofold. First, the gates of the transistors for low-swing operations are more sensitive to coupling from full-swing wires. Therefore, some constraints on transmitters’ and receivers’ pin location are helpful to avoid routing low-layer full-swing signal wires over these transistors. Second, constraints on pin locations make the transmitter/receiver cells more easily tileable. Without loss of generality, we chose one speciﬁc pin layout, restricted as shown in Figure 7. The power and ground pins’ locations are chosen to be the same as the corresponding pins in standard cells. All other pins are placed relative to the transmitter’s core, which contains noise-sensitive transistors. For example, the Select pin is on the left of the core, the Data-in pin is at the bottom, and the Data-out pin is on the 782 S S e e l l e eee c ccc t t Noise-sensitive Region t u o a t a D Data in 1-bit Crossbar Select Transmitter core (Noise-sensitive) t u o a t a D Data in Fig. 7. Transmitter abstract layout Dout Sel Transmitter Din m u 9 8 4 1 . 39.73um Fig. 8. Example single-bit crossbar layout with 6 inputs and 6 outputs right. Similar constraints are also applied to the receiver cell design. 2) Floorplanning: To achieve higher transmitter cell area density, we chose the bit-sliced organization, which was shown earlier in Figure 1(b). The tool ﬁrst generates a 1-bit N × M crossbar as shown in Figure 8. The transmitters are placed at the cross-points of input horizontal wires and output vertical wires. The tool then places W 1-bit crossbars in a 2dimensional array to form a W -bit N × M crossbar, as shown in Figure 9. The number of 1-bit crossbars on each side is calculated to square the crossbar layout area so as to minimize the average length of the wires each bit needs to traverse. Receivers are placed so that the routing area from the links to the receiver inputs is minimal. Although a port-sliced organization is also effective, it requires a more sophisticated wire routing algorithm to achieve the same cell area density as a bit-sliced organization. A naive approach, as shown in Figure 1(a), would result in lowtransistor density and a W 2 bit-to-area relationship, instead of W which can be readily achieved by using the bit-sliced organization. 3) Routing: For each 1-bit crossbar, the number of metal layers needed to route the power and signals is kept minimal , to maximize the number of available metal layers for output wire routing. No wiring is allowed above noise-sensitive transistors in lower metal layers. While this increases the total crossbar area, it lowers the wiring complexity for Data-out wires from each 1-bit crossbar to crossbar outputs. Since we employed the bit-sliced organization, the Data-out wires are distributed across the entire crossbar. Two metal layers are used to route the Data-out wires to the edge of the crossbar: one is used for outputs in horizontal direction, while the other Differential data wires ) J f ( t i b e p y g r r e n E 120.00 100.00 80.00 60.00 40.00 20.00 0.00 Shielding wires Fig. 11. Selected wire shielding topology P ER FORMANC E O F 1MM 2 L INK O F TWO ORGAN I ZAT ION S TABLE III Wire width 1 2 Wire spacing 2 4 Delay (ps) 70.0 33.7 Energy/bit (fJ) 35.0 30.5 Link area (mm2 ) 0.093 0.176 performance was simulated by transmitting a full-swing signal on the link. A layout of the example datapath generated is shown in Figure 10. C. Veriﬁcation and Extraction We use Calibre from Mentor Graphics to check if the generated circuit obeys the design rules, and to perform layout versus schematic (LVS) veriﬁcation. A schematic netlist is generated for LVS. In order to get a more accurate delay of the circuit, RC extraction is done for the post-characterization of the generated design. D. Post-characterization and selection Post-characterization is performed to determine the actual frequency, power, and area the crossbar can achieve. The selection step chooses the suitable datapath design based on the results from the post-characterization step, and outputs the ﬁles needed for the standard synthesis ﬂow. The Table IV shows the simulation results for the walkthrough examples. At the selection step, for example, if the criteria is to achieve high frequency and have little constraint on the area, the design with doubled link pitch is returned. E. Discussion The proposed generator enables the layout generation of low-swing datapaths for a given set of architectural parameters and design constraints, and outputs ﬁles for integration with the standard synthesis ﬂow. The generator removes additional design effort necessary for a fully custom design by automatically and systematically tiling transceivers and routing wires. When compared to synthesizing a full-swing datapath using commercial tools, our generator adds SPICE simulation overheads to characterize the properties of the generated datapaths such as delay and power during the library generation step. To use the generator with a different technology, the user needs to provide the technology related information as shown 32 64 96 128 Data width (bit)  generated-crossbar synthesized-crossbar Fig. 12. Energy per bit sent of 6-port datapaths with different data width in Table I, and to provide the layout of the transmitters and receivers designed for that speciﬁc process. IV. EVA LUAT ION In this section, we ﬁrst evaluate the crossbars generated by our proposed tool, against the synthesized crossbars. We then present a case study of a 5-port NoC virtual channel router that is integrated through the standard synthesis ﬂow with the low-swing datapath generated by our tool. In all our experiments, we used Cadence Ultrasim to evaluate the performance and power consumption of the RC extracted netlists. A. Generated vs. synthesized datapath Using the transmitter and the receiver design we describe in Section III, we generated low-swing datapaths across a range of architectural parameters and compared the simulation results with datapaths generated by standard CAD tools using only standard cells. We will refer to the crossbar/datapaths generated by our tool as generated crossbars/datapaths, and those generated by standard CAD tools using standard cells as synthesized crossbars/datapaths. Evaluating generated datapaths with different transmitter and receiver designs can be done but is equivalent to evaluating the effectiveness of different low-swing techniques, which is beyond the scope of this work. In our experiments, we assumed a link length of 1mm and speciﬁed a delay constraint of 0.6ns from the input of the crossbar to the output of the link for synthesized datapaths so that the datapath can be run at 1.5GHz. Energy per bit. We simulated the datapaths (crossbar and link) at 1.5GHz and report the results for varying data widths and varying number of ports in Figure 12 and Figure 13, respectively. As shown in Figure 12, for both crossbars, as the data width increases, the energy per bit sent also increases because an increase in the data width leads to an increase in the area of the crossbar. This increase results in longer distance (on average) for a bit to travel from an input port to an output port. Longer distance translates to higher energy consumption. The energy per bit sent also increases with the number of ports, because a bit needs to drive more transmitters. Overall, our simulations showed that a generated datapath, as in our 784         TABLE IV EXAM P L E G EN ERAT ED DATA PATH S Link wire width 1 2 Link wire spacing Max freq (GHz) 2 2.5 4 2.7 Crossbar area (mm2 ) 0.053 0.084 Energy/bit (fJ) 46.4 48.3 ) J f ( t i b r e p y g r e n E 120.00 100.00 80.00 60.00 40.00 20.00 0.00 4 6 8 Number of ports  generated-crossbar synthesized-crossbar Fig. 13. ports Energy per bit sent of 64-bit datapaths with different number of ) 2 m m ( a e r a r a b s s o r C 0.25 0.2 0.15 0.1 0.05 0 0 4x4 gen-crossbar 6x6 gen-crossbar 8x8 gen-crossbar 4x4 syn-crossbar 6x6 syn-crossbar 8x8 syn-crossbar 50 100 150 Data width (bit)  Fig. 14. Crossbar area with various architectural parameters design, results in 50% energy savings (on average per bit sent) compared to a synthesized datapath. Area. Figure 14 shows the area of the generated vs. synthesized crossbars. Due to the bit-sliced organization and larger transmitter size, the generated crossbar area is dominated by the transmitter area. Using this organization results in its crossbar area growing linearly with the data width and quadratically with the number of ports, as captured in Figure 14. On the other hand, as Figure 14 indicates, a synthesized crossbar has a smaller area footprint because the transmitter design we are simulating is differential, and our wire routing is conservative to achieve high immunity to noise. Both of these factors result in increased area footprint, a trade-off for better latency and lower power of low-swing datapath. In addition, the design of low-swing transceivers for on-chip is in its infancy. Future designs may be more area-efﬁcient, and continue to be pluggable into our generator toolchain. Router Processing Unit Fig. 15. Five-port router in a mesh network TABLE V ROU T ER S P EC I FICAT ION S # of input ports # of output ports Data width # of buffers per port Flow control Buffer management Working frequency 5 5 64 16 (1k bits) Wormhole with VC On/Off 1 GHz B. Case Study We synthesized a typical NoC router of a mesh topology integrated with a low-swing datapath using the ﬁles generated by our tool. The router is a 3-stage pipelined input buffered virtual channel (VC) router with ﬁve inputs and ﬁve outputs [23], and with a 64-bit data path. As shown in Figure 15, one input and one output port are connected to the local processing unit, while the remaining ports are connected to neighboring routers. We assumed that the local processing unit resides next to the router, the distance between routers is 1mm, and the target working frequency is 1GHz. Table V shows the detailed router speciﬁcations. We used the same synthesis ﬂow shown in Figure 4 to realize the router design from RTL to layout. Figure 16 shows the ﬁnal layout of the router with the generated datapath. The black region in the ﬁgure is assumed to be occupied by processing units. The low-swing crossbar occupies about 30% of the total router area. The delay of the low-swing datapath is 630ps. The power consumed in the generated datapath is 18% of the total power consumed by the router1 . The power consumption was obtained from UltraSim simulations by feeding a trafﬁc trace through all the ports of the router. The trafﬁc trace was generated from RTL simulations of a 4x4 NoC; every node injects one message every cycle destined to a random node. The ﬁnal synthesized router with the generated low-swing crossbar and links consists of 286,079 transistors. 1 It should be pointed out that this is a textbook NoC router. With a bypassing NoC router, such as that in [14], the NoC power will be largely that of the datapath, since most packets need not be buffered and can go straight from the input port through the crossbar to the output port and link. 785               [8] H. Wang, L.-S. Peh, and S. Malik, “Power-driven design of router microarchitectures in on-chip networks,” in Proc. Intl. Symp. Microarchitecture (MICRO), 2003. [9] K. Lee, S.-J. Lee, S.-E. Kim, H.-M. Choi, D. Kim, S. Kim, M.W. Lee, and H.-J. Yoo, “A 51mw 1.6ghz on-chip network for lowpower heterogeneous SoC platform,” in IEEE Intl. Solid-State Circuits Conference (ISSCC), February 2004. [10] B. Kim and V. Stojanovic, “A 4gb/s/ch 356fj/b 10mm equalized onchip interconnect with nonlinear charge-injecting transmit ﬁlter and transimpedance receiver in 90nm cmos,” IEEE International Solid-State Circuits Conference, Digest of Technical Papers., pp. 66–68, Feb. 2009. [11] D. Schinkel, E. Mensink, E. Klumperink, A. van Tuijl, and B. Nauta, “Low-power, high-speed transceivers for network-on-chip communication,” IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 17, no. 1, pp. 12–21, January 2009. [12] M. Sinha and W. Burleson, “Current-sensing for crossbars,” in IEEE Intl. ASIC/SOC Conference, September 2001. [13] P. Wijetunga, “High-performance crossbar design for system-on-chip,” System-on-Chip for Real-Time Applications, International Workshop on, vol. 0, p. 138, 2003. [14] T. Krishna, J. Postman, C. Edmonds, L.-S. Peh, and P.Chiang, “SWIFT: A SWing-reduced Interconnect For a Token-based Network-on-Chip in 90nm CMOS,” in Proc. Intl. Conference on Computer Design (ICCD), Oct. 2010. [15] R. Sredojevic and V. Stojanovic, “Optimization-based framework for simultaneous circuit-and-system design-space exploration: A high-speed link example,” Computer-Aided Design, International Conference on, vol. 0, pp. 314–321, 2008. [16] “ARM AMBA,” http://www.arm.com/products/system- ip/amba. [17] “Stbus communication system: Concepts and deﬁnitions,” http://www. st.com/stonline/books/pdf/docs/14178.pdf. [18] D. Wingard, “Micronetwork-based integration for SoCs,” in Proc. Design Automation Conference (DAC), May 2001, pp. 673–677. [19] “IBM CoreConnect,” https://www- 01.ibm.com/chips/techlib/techlib.nsf/ productfamilies/CoreConnect Bus Architecture. [20] M. A. Shalan, E. S. Shin, and V. J. M. III, “DX-GT: Memory management and crossbar switch generator for multiprocessor system-on-achip,” in Proc. Workshop on Synthesis and System Integration of MIxed Technologies, April 2003, pp. 357–364. [21] M. Dall’Osso, G. Biccari, L. Giovannini, D. Bertozzi, and L. Benini, “xpipes: a latency insensitive parameterized network-on-chip architecture for multi-processor SoCs,” in Proc. Intl. Conference on Computer Design (ICCD), October 2003. [22] J. M. Rabaey, A. Chandrakasan, and B. Nikolic, Digital Integrated Circuits: A Design Perspective, second edition. Prentice Hall, 2003. [23] W. J. Dally and B. Towles, Principles and Practices of Interconnection Networks. Morgan Kaufmann Publishers, 2004. Processing Unit 0 m m 1 i L n k s t o n o r t h Processing Unit 1 Links to west Links to east Linnkks to east Processing Unit 2 h t u o s o t s k n L i 1mm Processing Unit 3 207um Crossbar m u 2 9 1 m u 0 9 3 Fig. 16. Synthesized router with generated low-swing datapath 394um V. CONC LU S ION In this work, we present a low-swing NoC datapath generator that automatically creates layouts of crossbar and link circuits at low voltage swings, and enables the ready integration of such interconnects in the regular CAD ﬂow of many-core chips. Our case study demonstrates our generated datapath embedded within the synthesis ﬂow of a 5-port NoC mesh router, leading to 50% savings in energy-per-bit. While our case study leverages a speciﬁc low-swing transmitter and receiver circuit, our generator can work with any TX/RX building block and we will release it upon publication. We hope this will pave the way for low-swing signaling techniques to be incorporated within mainstream VLSI design, realizing low-power NoCs and enabling many-core chips. ACKNOW L EDGM EN T The authors acknowledge the ﬁnancial support of the Interconnect Focus Center, one of the six research centers funded under the Focus Center Research Program, a Semiconductor Research Corporation program, as well as NSF CPA-0811375. "
2011,ATree-based topology synthesis for on-chip network.,"The Network-on-Chip (NoC) interconnect network of future multi-processor system-on-a-chip (MPSoC) needs to be efficient in terms of energy and delay. In this paper, we propose a topology synthesis algorithm based on shortest path Steiner arborescence (hereafter we call it ATree). The concept of temporal merging is applied to allow communication flows that are not temporal overlapping to share the same network resource. For scalability and power minimization, we build a hybrid network which consists of routers and buses. We evaluate our ATree-based topology synthesis methodology by applying it to several benchmarks and comparing the results with some existing NoC synthesis algorithms [1], [2]. The experimental results show a significant reduction in the power-latency product. The power-latency product of the synthesized topology using our ATree-based algorithm is 47% and 51% lower than [1], and 10% and 17% lower than [2] for the case without considering bus and the case with bus, respectively.","ATree-Based Topology Synthesis   for On-Chip Network  Jason Cong, Yuhui Huang, and Bo Yuan  Computer Science Department   University of California, Los Angeles  Los Angeles, USA  {cong,yuhui,boyuan}@cs.ucla.edu  Abstract—The Network-on-Chip (NoC) interconnect network of  future multi-processor system-on-a-chip (MPSoC) needs to be  efficient in terms of energy and delay. In this paper, we propose a  topology synthesis algorithm based on shortest path Steiner  arborescence (hereafter we call it ATree). The concept of  temporal merging is applied to allow communication flows that  are not temporal overlapping to share the same network  resource. For scalability and power minimization, we build a  hybrid network which consists of routers and buses. We evaluate  our ATree-based topology synthesis methodology by applying it  to several benchmarks and comparing the results with some  existing NoC synthesis algorithms [1], [2]. The experimental  results show a significant reduction in the power-latency product.  The power-latency product of the synthesized topology using our  ATree-based algorithm is 47% and 51% lower than [1], and 10%  and 17% lower than [2] for the case without considering bus and  the case with bus, respectively.    I.  INTRODUCTION  MPSoC are now integrating more and more processors on a  single die with the increase in transistor budgets enabled by  Moore’s law. As the number of processor cores on a single die  increases, the power consumption and wire delay will also have  a significant increase, which makes the on-chip communication  among cores becomes a critical issue. A scalable, energyefficient on-chip interconnect network is needed to address  these difficulties  in order  to  facilitate  the on-chip  communication.  In  this paper we  investigate  the  topology synthesis  approach for on-chip interconnect network. The limitations of  previous works are discussed in Section II. To overcome these  limitations, we propose an ATree-based [3], [4] algorithm,  named AT_NOC, to synthesize the topology by creating a  series of refinement steps from an initial topology design, in  which any pair of communicating nodes are connected by  links. In each refinement, we pick the router that has the  highest power consumption among the un-refined routers, and  refine the sub-topology of this router to reduce the power  consumption and keep the packet latency lower. Many previous  topology synthesis approaches use a Steiner-tree-based  topology construction (such as [2]). The reason we use an  ATree instead of the Steiner-tree is that an ATree is the shortest  path tree that can reduce the packet latency. By using the  ATree-based algorithm, in the sub-topology of the chosen  978-1-4577-1400-9/11/$26.00 ©2011 IEEE 651 router, the paths from all nodes to the chosen router are the  shortest paths. Additional routers might be added into these  shortest paths at some Steiner points. The locations of these  added routers are chosen to minimize a cost function, which  considers both power and packet latency. In the cost function,  the power numbers of routers with different port sizes are  measured by ORION [5], [6]. In order to predict the packet  latency between any two nodes, we build a latency prediction  model by noting that the latency between two routers is related  to the injection rates of packets at the routers [7]. The latency  prediction model is built on a latency-injection rate table,  which is constructed by a simple simulation. For different  injection rates, we randomly inject packets into the wire and  measure the average packet latency. By looking up this latencyinjection rate table, we can easily predict the packet latency  under different traffic.  In our topology synthesis approach, we apply the concept  of temporal merging [8]. We observe that the communication  traces, which do not happen at the same time, can share the  same resource. A shared bus can be used as an implementation  for connecting  those nodes, which are not  temporal  overlapping.  Figure 1.  Temporal merging based on communication traces  For the example shown in Fig. 1(a), assume that the  application execution is divided into three phases, and the three  numbers in the parenthesis denote the traffic volume in the  three phases. Then, the communication traces from nodes 1,  node 2, and node 3 to node 4 do not overlap, nor do the  communications from node 5 to node 6 and node 7. Without  considering the temporal merging, existing topology synthesis  approaches (such as [1]) may generate a topology shown in  Fig. 1(b) with three routers, of which R1 has four ports and R3        has three ports. By considering temporal merging, we can  connect node 1, node 2, and node 3 with a shared bus, and  connect node 6 and node 7 by another shared bus. Then we can  synthesize a topology as shown in Fig. 1(c), in which both R1   and R3 have two ports. Compare to the synthesized topology in  Fig. 1(b), the topology in Fig. 1(c) has lower power  consumption. Given these observations, communication traces  should be implemented by a shared bus as much as possible for  power consideration. For performance consideration,  the  overlapped working period of communication traces, which  share the same resource, should be minimized.   This paper is organized as follows. The related work and  problem formulation are given in Sections II and III. Then, an  ATree-based topology synthesis method is proposed in Section  IV to minimize the combination of total power and packet  latency. In Section V, the experimental results are described to  show the effectiveness of our algorithm. Our conclusion and  future work are then provided in Section VI.  II. RELATED WORK  The custom on-chip network, which targets a given  application, has proved to be more efficient than the regular  structure on-chip network design in [2]. The reason is that the  communication requirement for each data flow is available in  the design time, so the power consumption and packet latency  are predictable once the links of networks are determined.  Having this knowledge makes custom on-chip networks more  efficient with topology synthesis as shown in [1], [2], [7]-[12].  Among those, [1], [2], [9] use a partition-based algorithm to  reduce the time complexity.   Both [1] and [2] use decomposition and clustering  methodologies to find the best partition of traces. For each  trace partition, [1] uses a K-way merge to construct the on-chip  network topology, while [2] uses a Steiner Tree engine to build  topology. Both of their solution spaces [1] and [2] are limited  by the implementation structure that they choose. A K-way  partition plus K-way merge forces the maximum hop count to  be 2, while using an existing Steiner tree package limits the  location of routers to the Steiner points selected by that  package. This usually results in a highly congested common  backbone for the wire length consideration. The work in [9]  presents a min-cut partition-based algorithm  to group  processing elements, and uses cross-group traffic as the cost of  edge. The work in [10] uses linear programming techniques to  solve the topology synthesis problem. The work in [13]  provides a system-level for on-chip network that provides the  user the most suitable network designs tailored to their  performance requirements and power/area constraints. The  design space of NoC configurations in [13] only includes  several fixed topologies such as torus, mesh, ring, fat tree,  which might lose the opportunity to improve the performance  of on chip network.  Hybrid architecture  is also used  in custom on-chip  networks. In [8],  the authors observe  that  the power  consumption of a crossbar is mainly determined by its size. By  introducing the concept of temporal non-overlapping, the  communication traces, which do not occur at the same time,  can share the same resource. However, the topology generated  by the work in [8] is limited to crossbars and buses only. In  [11] and [12], the topologies are constructed on top of a  standard mesh structure. [11] adds extra long-range links to  reduce the average packet latency, while [12] uses radio  frequency interconnect (RFI) to simplify the topology. The  works in [11] and [12] do not consider bus implementation in  their algorithms.  Srinivasan et al. [7] proposed a three-phase topology  synthesis method including performance-aware floorplan, core  to router mapping, communication traces routing. The target of  [7] is to reduce power consumption with the packet latency  constraints. Instead, our approach simultaneously optimizes the  power consumption and packet latency. [7] formulated the  problem of routing communication traces as a variation of  rectilinear Steiner arborescence problem, and modeled the  problem as a linear programming formulation. Before solving  the communication trace routing, the locations of the routers  have already been determined. However, in our algorithm, we  simultaneously determine the communication trace routing and  locations of the routers. This paper presents an ATree-based  topology synthesis approach. The design space of synthesized  topology that we explore is larger than those of the previous  researches. As we discuss above, the previous research such as  CosiNoC [1] and Rectilinear-Steiner-Tree-based algorithm [2]  limit the structure of synthesized topologies to be K-way merge  or sets of Rectilinear Steiner tree, which might lose the  opportunity to synthesize a better topology in terms of power  and packet  latency. In our ATree-based algorithm, we  iteratively refine the topology by constructing the sub-topology  of the selected router in an ATree [3], [4] fashion, which is  more flexible. In this way, we can achieve power efficient  topologies.  III. PROBLEM FORMULATION  Given  the communication graph among processing  elements and the locations of these elements, the problem of  topology synthesis is to determine the number of routers, the  location of newly added routers, and the connectivity between  them. Power consumption and packet latency are two tradeoff  factors that we need to consider during synthesizing the  topology. The problem can be defined as follows:  Objective Function:  Minimize   α*Power(T) + (1- α)*Latency(T, Gtrace, Route)  ∈ V has location (pi, qj)  Given :  1. A set of processing elements, V, and each element v  2. A trace graph Gtrace describes the communication  flows between elements in V. The traffic volume in  different time windows for edge e is represented by  a vector, f = {ft1, ft2, …, ftn} where fti is traffic  volume at the ith time window  3. A library of routers and links that contains power  and performance information  4. A packet-latency lookup table that is constructed  based on off-line simulation, which can estimate  latency by a given injection rate  652 5. Strategies  for connectivity: buses or wires  connected via routers  Determine:  1. The topology T, which contains the information:  a. The set of routers, R and their location,  (xri, yri) for ri = 1, …, |R|  b. The connectivity between routers and  elements in V, and type of connectivity  a. Route(vi, vj) = {vi, rk, …, rl, vj}, rk, rl ∈ R  (bus/wire)  2. Route(vi, vj) for each communication flow between  element vi and element vj:  Here, α is a user-controllable parameter for trade off  between power consumption and packet latency as we will  discuss in Section V.B. Power(T) means the total power  consumption of topology T, which includes static power and  dynamic power for routers, links, and buses. The total packet  latency of all communication flows is expressed by Latency(T,  Gtrace, Route), which is calculated by the sum of packets’  latencies. The packet latency is determined by 1) the route of  the packet, and 2) the traffic volume of communication traces  on the route, which can be acquired from the routing table.  IV. AT_NOC SYNTHESIS ALGORITHM  Since the topology synthesis problem was proven to be NPhard in [1], we propose an ATree-based algorithm to synthesize  the topology by a series of refinement steps from an initial  topology design, in which any pair of communicating nodes are  connected by links. We can see that the initial topology will  have minimum packet  latency, but have  large power  consumption due to the large port size of the routers (we  assume every processing element has a local router). In our  initial topology design, besides local routers, no additional  routers are added. In each refinement, we gain the power  reduction at the expense of a longer latency. The power  consumption at each refinement is better than the previous one.  As we know, a router contributes more power consumption  than other components in an on-chip network, such as links,  and buses. The problem of minimizing the power consumption  of the on-chip network needs to focus on the power reduction  of the routers. The power consumption of a router is  proportional to the size of the router. As a result, the objective  of refining topology is turned into a reduction of the number of  input/output ports of routers. Therefore, as shown in Algorithm  1, in each refinement, we focus on optimizing a sub-topology,  which consists of one high-radix router and its neighborhoods.  The overview of our  topology synthesis method  is  described in Algorithm 1. We start from an initial network  topology which has good performance and is discussed in  Section IV.A. Then, we go through an iterative improvement.  In line 2, we select a router that has the highest cost among the  un-refined routers. We refine the sub-topology, which consists  of the selected router and its neighborhood in line 4. Then, we  label this selected router as refined in line 7. The refinement  continues until all the routers are already refined or the  653 topology meets the stopping criteria of power reduction. Since  the area of the routers is much smaller than the area of cores  [14], we ignore the impact of the router area in our algorithms.  Algorithm 1 AT_NOC Topology Synthesis  Input: Initial topology T0, the locations of processing elements, and  communication graph Gtrace  Output: Synthesized topology T    5:              R = R ∪ Rsp  1:  S = Ø;  T = T0; R = routers in T0      2:  while ((rsel = getMaxCostRouter(R-S)) != NULL    3:          && ImproveEnough() == false) do    7:              S = S ∪ rsel    4:              (Rsp, T) = RefineSubTopology (rsel, T, Gtrace)     6:              /* additional routers might be added */    8:  end while    9:  return T  A. Initial Topology Construction  As we mentioned in the previous section, our algorithm  starts from an initial topology, which is constructed from the  communication graph, that is, any pair of communicating  nodes is connected by a link. For each node v in this  communication graph, there is a corresponding node v’ and a  local router rv’ connected by a wire (v’, rv’) in the initial  topology. For each edge in the communication graph e(u,v), in  the initial topology we use three links e(u’, ru’), e(ru’, rv’), e(rv’,  v’) to match this flow. An example is shown in Fig. 2. Each  node  in  the  initial  topology has a  local  router. A  communication flow from node 1 to node 3 in Fig. 2(a) has a  corresponding path: node 1, router R1, router R3, node 3 as  shown in Fig. 2(b).  Figure 2.  Construction of an initial topology  B. Refine Sub-Topology of a Selected Router  After constructing the initial topology, the topology is  refined by function RefineSubTopology. This purpose of this  function is to refine the topology by removing some existing  edges of the selected router. Once we remove an edge, all the  traces which originally go through this edge, should be rerouted. In other words, if an alternative route for an edge is  found, this edge can be eliminated. In this way, we can lower  the number of ports by re-routing a direct path between two  nodes. Take the example shown on Fig. 2(b): router R1 has  direct links to routers R3 and R4, and router R4 has a direct  link to router R3. Without considering the latency penalty, it is        better to re-route all the routes on edge (R1, R3) with edge (R1,  R4) and edge (R4, R3) because the number of output ports of  router R1 can be decreased by one, as can the number of input  ports of router R3. Based on this observation, it is natural to  separate the input and output edges when we consider the  possibility of re-route, because it is impossible to find an  outgoing path to replace an incoming edge.  R1 st1 R3 R4 R1 st1 R3 R4 (a) Sub-topology of R3 which  consists of incoming edges (b) Rectilinear minimum steiner  arborescence Figure 3.   The sub-topology of R3 with incoming edges and its rectilinear  minimum steiner arborescence  For function RefineSubTopology, we refine the topology  around the selected router rsel by refining the sub-topology of  its fanin edges and its fanout edges, separately. In other words,  two sub-topologies are constructed: one is for sub-topology of  fanin edges of rsel, and the other is for sub-topology of fanout  edges of rsel. For a topology is shown in Fig. 2(b), the subtopology of router R3 with only incoming edges is shown in  Fig. 3(a).  DEFINITION 1 The sub-topology of a router consists of all the  incoming/outgoing edges of the router, and the vertices which  are attached on these edges. This router is called root node,  and other vertices in this sub-topology are called terminals.  Edges between terminals are also viewed as part of this subtopology. In Fig. 3(a), the root node is R3 and terminal nodes  are R1 and R4.  Using the ATree algorithm proposed in [4], we compute a  rectilinear minimum Steiner arborescence that connecting root  node to all terminal nodes. The motivation of adopting the  rectilinear minimum Steiner arborescence is to minimize the  total wire length and the distance from root node to each  terminal node. In this way, we can simultaneously reduce the  wire power and packet latency. The rectilinear minimum  Steiner arborescence for Fig. 3(a) is shown in Fig. 3(b).  DEFINITION 2 The Steiner point candidates of a sub-topology  satisfy the following properties: 1, intersecting points of this  sub-topology; 2, location is on the rectilinear minimum  Steiner arborescence. In Fig. 3(a), only st1 is a Steiner point  candidate.  The algorithm of refining sub-topology goes through the  following steps:  1) Refine Sub-Topology by Using ATree-Base Method  The details of refining sub-topology are shown  in  Algorithm 2. The first step of the function RefineSubTopology  is to build the sub-topology of the selected router as we  discussed in Definition 1. The set N contains all terminal nodes  in the sub-topology. The set SV contains all the Steiner point  654 candidates, terminals, and the root node. In line 3, we sort all  the vertices in SV in descending order of their distance to the  root node rsel. Then, we build sub-problem solutions by  traversing each vertex. In the end, we reconstruct the topology  by back-tracing the sub-problem solution of the root node. For  all the routes that go through root vertices, our method explores  possible new routes for them in order to reduce power  consumption and improve performance. The possible routes  might consist of original links, new links between local routers  and newly added routers at Steiner point candidates, and the  new shared buses, which combine original links or new links.  Our algorithm explores these possibilities and chooses the one  with minimal cost. As we can see, when the final topology  determined, the route for each communication flow is also  determined.  DEFINITION 3 A vertex v is reachable from u if v is in one of  (directed) paths of u to the root node. P(v) contains the set of  terminal nodes from which v is reachable, excluding v. In Fig.  3, P(st1)={R1, R4}; P(R1)=Ø; P(R4)={R1}; P(R3)={R1, R4}.   In line 6 of Algorithm 2, for each vertex v in SV, let  W=P(v), we evaluate the cost of the topology that connecting  all vertices in W to v, cost(v, W).  Algorithm 2 RefineSubTopology(rsel, T, Gtrace)  Input: the selected router rsel, current topology T, communication  graph Gtrace  Output: the set of newly added routers Rsp , the refined topology Tref  1:  build the sub-topology Tsub of the selected router rsel  2:  N is the set of terminals in Tsub  3:  Sort vertices in SV in descending order of   4:  the distance to root rsel    5:  for each vertex v in SV do    6:              W = P(v), calculate cost(v, W)     7:  end for    8:  Backtrace from the root node to find out the Steiner point     9:  candidates those are included in the sub-topology that has  10:  the minimum value of cost(root, P(root))  11:  Rsp is the sets of the Steiner points candidates in the   12:  min-cost sub-topology   13:  /* new routers are added at these selected Steiner points */  14:  return (Rsp, Tref)  The functions that used to calculating cost(v, W) are below.  Function 2, cost(v, W) is the minimum cost among several  possible topologies which are used to connect v to all terminals  in W. Given v and W, we need to determine Sp(v, W). Sp(v, W)  is a set of nodes, such that for every node n in Sp(v, W), every  terminal node in W has a (directed) path to v through node n.  FUNCTION 1  TopoCost ( v C , ) FUNCTION 2  cost ( v W , ) = min ∀ ∈ s Sp v W ( , ) = ⋅ α + ( RouterCost v C , − α ⋅ 1 LatencyCost ) ( ( v C , ) ) ( TopoCost ⎧ ⎪ ⎨ ⎪⎩ ( ( { } ) + v s , cost s P s W s , ∩ , TopoCost v P s , , s = v ( ) ( ) ( ) ) ) ≠ v Fig. 4 demonstrates how to calculate cost(v, W) for a subtopology of R3 shown in Fig. 3. Let v=R3, then W={R1, R4},  Sp(v, W)={st1, R4, R3}. There are three possible topologies: 1)  R1 and R4 are connected to st1, st1 is connected to R3; 2) R1                                        and R4 are directly connected to R3; 3) R1 is connected to R4,  R4 is connected to R3. In the first case, st1 could be a newly  re-route all the paths that on R1→R3, R4→R3. In the second  added router that will reduce the number of input ports of R3.  Once we add st1 as a newly added router, we might have  higher traffic on the link between st1 and R3, which is used to  case, R1 and R4 are directly connected to R3. The packet  latency will be smaller since there is no contention between  packets from R1 to R3 and packets from R4 to R3. However,  the port size of R3 is increased, which will increase the power  of R3. In the third case, all the packets on edge (R1, R3) are  rerouted with edge (R1, R4) and edge (R4, R3), which reduce  port size of R3 but increase the traffic on the link between R4  and R3. Therefore, we not only consider the power reduction,  but also calculate the performance degradation, which is  captured in Function 1.   Figure 4.  An example of calculating cost(R3, {R1, R4})  Function 1, TopoCost(v, C), evaluates the cost of the case  that v connects with all vertices in C. The cost is calculated as a  combination of power consumption and total packet latency as  shown in Function 1. In Function 1, v is the node where we  place a router, and C is a set of vertices that have direct links to  v. Therefore, we can easily obtain the number of input/output  ports, which determines the power consumption of the router.  The latency cost is the estimated packet latency. In order to  predict the packet latency between any two connecting nodes,  we build a latency prediction model by noting that the latency  between two routers is related to the injection rates of packets  at the routers [7]. We construct a latency-injection rate table by  running simulations. By looking up this latency-injection rate  table, we can easily predict the packet latency based on the  traffic of the direct links between v and C.  In Algorithm 2 we traverse each vertex in SV in the order of  distance to root node. Therefore, when evaluating cost for v, all  the costs of v’s predecessors are already evaluated (because v’s  predecessors have a longer distance to root node). In other  words, our algorithm constructs solutions from the bottom up,  and eliminates  the duplicated calculation by dynamic  655 programming. The time complexity for Algorithm 2 will be  discussed in Section IV.D. In the following sections, we will  propose some heuristics to reduce the time complexity.  2) Refine Sub-Topology by Region  From Fig. 4, we can see that as the number of terminals in  W increases, it is possible that the number of possible  topologies will be large. In order to reduce the complexity, we  partition edges of a router into four quadrants according to the  location of terminals. The categories of groups are southeast,  northwest, southwest, and northeast. Because our algorithm is  ATree-based [3], [4], an edge in one group cannot find an  alternative path to re-route using the edges in different groups,  except those edges which are shared by two groups. For  example, a horizontal edge on the east may be shared by  northeast and southeast groups. Therefore, we propose an  algorithm to first refine the topology for each sub-topology of a  group, and then refine the whole sub-topology of the router.  This heuristic algorithm can help us successfully reduce the  time complexity without losing quality.  3) Sub-Topology Pruning  We propose a heuristic method to further reduce the  number of possible topologies in each quadrant by introducing  the concept of “dominance relation.”  DEFINITION 4 For a vertex v, one predecessor va of v is said to  be dominant to another predecessor vb if the transmission  cycle of the direct link between va and v is the same as the  transmission cycle of the direct link between vb and v, and vb is  closer to v than va.   We calculate the transmission cycle between two nodes by  using ORION [5], [6]. By definition, for a vertex v, a dominant  node va is the farthest node that v can reach in t cycles. We call  va to be t-cycle dominant. Let vb be a non t-cycle dominant  node, and it takes t cycles from v to vb. Let u be a terminal  node, and the transmission cycle of the direct link between u  and v is larger than t cycles. Since va is the farthest node that v  can reach in t cycles, the distance from u to vb must be larger  than the distance from u to va. Both va and vb take t cycles to v.  Therefore, the time needed to transmit a packet from v to u via  va should be less than that from v to u via vb. Therefore,  comparing to non-dominant nodes, choosing a dominant node  as one stop in the re-routing path has a smaller latency. With  this concept, picking up these dominant nodes can reduce the  number of possible topologies without degrading the solution  quality, which also reduces the complexity of our topology  synthesis algorithm.  C. Temporal Merging with Shared Buses  Because a shared bus is useful for reducing the network  resource, we use it in our topology refinement methodology by  making slight changes to the algorithm in Algorithm 2. For  Function 2, we evaluate the value of cost(v, W) by assuming  links are used to connect vertex v and all vertices in W. In order  to support a shared bus architecture, when evaluating the value  of cost(v, W), we consider merging several direct links into  shared buses. As we discussed in Section I, shared buses can be  used to connect those nodes that are not temporal overlapping.  By using shared buses, we can reduce the power consumption,    which will lower the value of cost(v, W). An example is shown  in Fig. 5 where R3 is a root node, and R1 and R4 are connected  to R3 by direct links. By analyzing the communication graph  Gtrace, we find out R1 and R4 are not temporal overlapping. In  Fig. 5(b), we replace the direct links from R1, and R4 to R3  with a shared bus, which might lower the value of cost(v, W).   Figure 5.  Temporal merging by replacing direct links with shared buses  D. Complexity Analysis  In this section, we analyze the complexity of our algorithm  as shown in Algorithm 1. Assume the number of processing  elements on the chip is n. Each processing element has a local  router, and then the number of local routers is n. The routers in  the synthesized topology include the local routers and the  added routers at the selected Steiner points. Since our  AT_NOC algorithm is based on ATree, we can expect that the  number of added routers will be less than the number of local  routers. So, the number of total routers in the synthesized  topology is Θ(n), as is the number of iterations that while-loop  executes. In the while-loop, the function RefineSubTopology, as  shown in Algorithm 2, is executed. The main part of the  function RefineSubTopology is the for-loop. The number of  iteration that for-loop executes is Θ(n). In each iteration, cost(v,  W) will be calculated. The complexity of computing cost(v, W)  is proportional to the size of Sp(v, W). The maximum size of  Sp(v, W) is the number of terminals and Steiner points, which is  Θ(n). So, the complexity of calculating cost(v, W) is Θ(n).  Based on the above analysis, we have the following theorem.  Theorem 1 The complexity of our ATree-based algorithm is  Θ(n3), where n is the number of processing elements on a chip.   We compare the runtime of our algorithm with those of [1]  and [2]. The results are shown in Section V. The results show  that the runtime of our ATree-based algorithm is acceptable.  V. EXPERIMENTAL RESULTS  A. Experimental Setup  In our experiments the processing elements include 8 cores  with L1 caches, 8 L2 cache banks, and 8 memory interfaces.  Each element has a local router to distribute the outgoing  packets. Many previous research efforts have explored multiple  router implementations. The single-stage router was proposed  in [15]. Since we are focusing on the topology synthesis, we  would like to measure the impact of the synthesized topology  on power and packet latency. So, the router implementation  used in this paper is a single-stage router, which might  minimize the impact of the router on power and packet latency.  656 The benchmarks that we use are from PARSEC [16] and  medical imaging [17] including denoising, registration, and  segmentation. All of our benchmarks are written in parallel  fashion. Since the processing elements have 8 cores, the  benchmarks are parallelized with 8  threads. For each  benchmark, we run the parallel program on SIMICS [18] to  obtain the communication graph. In the communication graph,  each processing element  is considered a node. The  communication graph contains  the  information of all  communication messages. The information includes the size of  the message, the source node of the message, the destination  node of the message, the time when the message is sent out.  With the information of all communication messages, we can  obtain the traffic volume between any pair of nodes in the  communication graph. Then, we use the communication graph  as input for the floorplanner to locate all the processing  elements. The floorplanner that we use is Parquet [19], [20].  With the communication graph and locations of processing  elements, we use our ATree-based topology synthesis method  to generate the topology. After topologies are synthesized, we  use ORION [5], [6] to measure the total power consumption of  the synthesized on-chip network. The power consumption  includes the static power and the dynamic power of routers,  links, and buses based on 45-nm technology. For wires and  buses, the power and the latency are measured by using the  model in [21]. Based on the synthesized topologies, we run the  benchmarks on a trace-driven cycle-accurate simulator to  measure the average packet latency.  To evaluate the effectiveness of our ATree-based topology  synthesis algorithm, two topology synthesis methodologies are  used as baselines. The first one is the released version of  CosiNoC, which can be downloaded from [22]. The second one  is the Rectilinear-Steiner-Tree (RST) based algorithm proposed  in [2] with our own implementation.  B. The Trade-Off between Power and Latency  We use the benchmark Blackscholes as an example to show  the trade-off between power and packet latency of the  synthesized topologies generated by using our algorithm. From  Fig. 6, we can clearly see that power and packet latency are two  trade-off factors, and that the topology with bus always  performs better than the topology without bus at every design  point. This shows that using shared bus can effectively reduce  the packet latency.  Figure 6.  Trade-off curve between power and latency        TABLE I.   CosiNoC  RST-based  COMPARISON OF POWER, LATENCY, AND POWER-LATENCY PRODUCT OVER BENCHMARK SETS  PL  AT_NOC without Bus  PLI  vs.  Cosi  53.6%  46.6%  54.6%  59.0%  52.2%  60.4%  46.1%  44.2%  37.7%  50.3%  41.3%  38.5%  38.7%  29.3%  46.6%  4.217  4.259  4.019  4.322  4.260  4.012  4.662  4.421  5.163  3.849  4.075  5.010  5.067  5.565  -  5.782  5.681  5.400  6.018  5.763  5.944  6.231  5.951  7.058  5.185  6.048  6.728  6.753  7.481  -  PLI  vs.  RST  19.7%  17.1%  2.79%  13.9%  21.1%  11.9%  6.91%  15.1%  0.43%  23.7%  2.04%  4.28%  2.65%  -0.8%  10.1%  P  0.679  0.695  0.702  0.649  0.696  0.622  0.735  0.724  0.681  0.645  0.595  0.705  0.721  0.695  -  L  PL  AT_NOC with Bus  PLI  vs.  Cosi  60.9%  50.4%  59.8%  60.6%  55.7%  60.1%  46.7%  40.2%  44.1%  56.4%  50.4%  46.9%  44.2%  38.5%  51.1%  3.552  3.958  3.559  4.157  3.952  4.049  4.602  4.734  4.632  3.379  3.439  4.330  4.614  4.845  -  5.228  5.697  5.074  6.403  5.675  6.507  6.264  6.539  6.801  5.243  5.780  6.143  6.403  6.972  -  PLI  vs.  RST  32.4%  22.9%  13.9%  17.2%  26.8%  11.0%  8.10%  9.06%  10.7%  33.0%  17.3%  17.3%  11.4%  12.2%  17.4%  Benchmark  P  L  PL  P  L  PL  P  L  Blackscholes  Bodytrack  Canneal  Ferret  Fluidanimate  Freqmine  Raytrace  Streamcluster  Swaptions  Vips  X264  Denoising  Registration  Segmentation  Average  1.075  1.076  1.075  1.076  1.076  1.046  1.076  1.076  1.076  1.076  1.019  1.076  1.076  1.076  -  8.444  7.412  8.229  9.804  8.292  9.692  8.034  7.362  7.699  7.199  6.813  7.574  7.689  7.320  -  9.082  7.976  8.850  10.55  8.919  10.14  8.641  7.922  8.281  7.743  6.939  8.147  8.270  7.873  -  1.195  1.203  1.017  1.213  1.213  1.058  1.234  1.234  1.213  1.203  0.863  1.202  1.203  1.202  -  4.396  4.271  4.066  4.137  4.450  4.302  4.058  4.219  4.275  4.197  4.822  4.355  4.328  4.591  -  5.253  5.136  4.134  5.018  5.397  4.551  5.008  5.206  5.185  5.047  4.160  5.235  5.205  5.519  -  0.729  0.750  0.744  0.718  0.740  0.675  0.748  0.743  0.732  0.742  0.674  0.745  0.750  0.744  -  Notes: P stands for power (unit is watt). L stands for latency (unit is cycle). PL stands for power-latency product. PLI stands for power-latency product improvement.  The trade-off parameter between power consumption and  packet latency is determined by user through setting the  parameter α as mentioned in Section III. Increasing the value of  α will lead to lower power consumption and higher packet  latency, and vice versa. By tuning the trade-off parameter α, we  could obtain lower packet latency or lower power consumption.  C. Comparisons on the Results  We compare the topologies of different benchmarks  synthesized by using four different methods: the algorithm  proposed in CosiNoC [1], Rectilinear Steiner Tree (RST) based  algorithm proposed in [2], and the algorithms we proposed in  this paper with and without using a shared bus, respectively.  Table I shows the power consumption and average packet  latency of the topologies synthesized by these four topology  synthesis engines. The total power consumption of the  synthesized topology is measured in terms of watt. The average  packet latency is measured in terms of cycles. Table I shows  that our algorithm performs better than CosiNoC and RSTbased algorithm  in all benchmarks  in  terms of power  consumption. Without  shared buses, our ATree-based  algorithm achieves on average 32% and 37% reduction in  power over CosiNoC and  the RST-based algorithm,  respectively. With shared buses, our ATree-based algorithm  achieves on average 36% and 41% reduction in power over  CosiNoC and the RST-based algorithm, respectively. For  packet latency, our ATree-based algorithm achieves 22% and  23% reduction over CosiNoC for the case without shared buses  and the case with shared buses, respectively. Our ATree-based  algorithm has larger average packet latency than the RST-based  algorithm. The explanation is that in the RST-based algorithm,  the traffic flows are partitioned into several groups. For each  group, a Rectilinear-Steiner-Tree based network topology is  used to connect the communication modules in the group. The  solutions of the RST-based algorithm might comprise multiple  custom network topologies. So, the RST-based algorithm has  higher power consumption and lower packet latency.   To show the effectiveness of our algorithms, we compute  the power-latency product over all the benchmarks, as shown  in Table I. Fig. 7 shows that our ATree based algorithm has a  significant reduction in terms of the power-latency product.  Without considering shared buses, our ATree-based algorithm  achieves an average 47% reduction and 10% reduction over  CosiNoC and the RST-based algorithm, respectively. By using  shared buses, our ATree-based algorithm achieves an average  51% and 17% reduction over CosiNoC and the RST-based  algorithm, respectively.  The execution times of these four topology synthesis  engines over all benchmarks are shown in Fig. 8. For all  benchmarks, CosiNoC has the shortest execution time, and the  RST-based method has the longest execution time. The  execution time of our ATree-based method is between the  execution time of CosiNoC and the RST-based method. For  most benchmarks, the execution time of the ATree-based  method without shared buses is smaller than the execution time  of the ATree-based method with shared buses. The explanation  for this is that when using shared buses to connect the nodes  that are not temporal overlapping, we need to analyze the  communication graph, which will take extra time.  VI. CONCLUSION AND FUTURE WORK  The experimental results show that our algorithm performs  better than CosiNoC and the Rectilinear-Steiner-Tree-based  method  in most of  the cases studied. The reasonable  explanations are: 1) the solution space of our algorithm is not  limited by a fixed type of structure; 2) the power reduction is  guaranteed after each refinement; 3) our algorithm is ATreebased, which results in smaller latency.   Future work includes enhancing the latency prediction  model. In this paper we use traffic volume to predict the packet  latency. It is difficult to capture the complexity of a real traffic  pattern. We believe that in order to have an accurate latency  prediction model, we need to study the traffic patterns in the  communication graph.  657   Figure 7. Comparison of power-latency product over benchmark sets  ACKNOWLEDGMENT  [3]  [4]  The research presented in this paper was partially supported  by the SRC Contract 2009-TJ-1984 and the NSF grant CCF0903541.  Figure 8. Execution time of four topology synthesis engines over benchmark sets  [10] K. Srinivasan, K. S. Chatha, G. Konjevod, “Linear Programming based  Techniques for Synthesis of Network-on-Chip Architectures,” IEEE  Trans. VLSI, 407-420, 2006.  [11] U. Y. Ogras, R. Marculescu, “Application-Specific Network-on-Chip  Architecture Customization via Long-Range Link Insertion,”  in  ICCAD(2005), 246-253.  [12] M. F. Chang, J. Cong, A. Kaplan, M. Naik, G. Reinman, E. Socher, S.  Tam, “Power Reduction of CMP Communication Network via RFInterconnects,” IEEE/ACM MICRO, 376-387, 2008.  [13] Vassos Soteriou, Noel Eisley, Hangsheng Wang, Bin Li, and Li-Shiuan  Peh, “Polaris: A System-Level Roadmap for On-Chip Interconnection  Networks,” In Proceedings of the 24th International Conference on  Computer Design (ICCD), San Jose, October 2006  [14] William J. Dally and Brian Towles, “Route packets, not wires: on-chip  inteconnection networks,” in Proc. DAC, 684-689, 2001.  [15] R. Mullins and et. al. Low-latency virtual-channel routers for on-chip  networks. In Proc. of the 31st ISCA, page 188. IEEE Computer Society,  2004  [16] PARSEC Benchmark Suite: http://parsec.cs.princeton.edu/  [17] J. Cong, V. Sarkar, G. Reinman and A. Bui, “Customizable DomainSpecific Computing”, IEEE Design and Test of Computers, Volume 28,  Issue 2, pp. 5-15, March/April 2011.  [18] Virtutech Simics: http://www.simics.net  [19] Parquet Floorplanner http://vlsicad.eecs.umich.edu/BK/parquet/  [20] S. N. Adya, S. Chaturvedi, J. A. Roy, D. A. Papa, I. L. Markov,  “Unification of Partitioning, Placement and Floorplanning,”  in  ICCAD(2005), 550-557.   [21] L. P. Carloni, A. B. Kahng, S. Muddu, A. Pinto, K. Samadi, P. Sharma,  “Interconnect Modeling  for  Improved System-Level Design  Optimization,” in Proc. ASPDAC, 258-264, 2008.  [22] CosiNoc: http://embedded.eecs.berkeley.edu/cosi/  "
2011,Chemical-mechanical polishing aware application-specific 3D NoC design.,"Three-dimensional (3D) integration with through-silicon vias (TSVs) is promising in the integration of many cores into a single chip. Network-on-chip (NoC) can efficiently manage the complicated 3D interconnections. However, irregular and dense TSV arrays used as vertical links in 3D NoC cause severe TSV height variation during silicon-thinning and chemical-mechanical polishing (CMP) processes. It may lead to TSV bonding failure between silicon layers. In this paper, we propose the first CMP-aware application-specific 3D NoC design that minimizes such TSV height variation and thus reduces the bonding failure, and meanwhile optimizes conventional NoC design objectives such as hop count, wirelength, power consumption, and area. Our 3D NoC design assigns cores to proper silicon layers, determines the 3D NoC topology, allocates routing paths, and then floorplans all cores, routers, and TSV arrays in a CMP-aware manner. The key idea behind this 3D NoC design flow is to determine the CMP-aware 3D NoC topology where TSV arrays with low and uniform metal density are inserted between adjacent layers. Experimental results show that our CMP-aware 3D NoC design achieves, on average, 17.9% lower TSV height variation, 15% lower hop count, 2.3% shorter total wirelength, and 7.8% lower power consumption than the previous state-of-the-art 3D NoC designs.","Chemical-Mechanical Polishing Aware                Application-Specific 3D NoC Design  Wooyoung Jang, Ou He*, Jae-Seok Yang†, and David Z. Pan‡  SoC Platform Development Team, Samsung Electronics, Yongin-City, South Korea   *IBM System & Technology Group, Beijing, China  †CAE Team, Samsung Electronics, Hwaseung-City, South Korea   ‡Department of Electrical and Computer Engineering, the University of Texas at Austin, Austin, USA   wooyoung.jang@samsung.com, heou@cn.ibm.com, js.yang@samsung.com, dpan@ece.utexas.edu   ABSTRACT  In this paper, we propose the first chemical-mechanical polishing  (CMP) aware application-specific  three-dimensional  (3D)  network-on-chip (NoC) design that minimizes through-silicon-via  (TSV) height variation, thus reduces its bonding failure, and  meanwhile optimizes conventional NoC design objectives. Our  3D NoC design assigns cores to proper silicon layers, determines  the 3D NoC topology, allocates routing paths, and then floorplans  cores, routers and TSV arrays by a CMP-aware manner. The key  idea behind this 3D NoC design flow is to determine the CMPaware 3D NoC topology where TSV arrays with low and uniform  metal density are inserted between adjacent layers. Experimental  results show that our CMP-aware 3D NoC design can achieves  lower TSV height variation, higher performance and lower power  consumption than the previous state-of-the-art 3D NoC designs.  1. INTRODUCTION  Network-on-chip (NoC) is an effective solution for on-chip  communication  in  three-dimensional  (3D)  interconnections.  However, the 3D NoC must meet not only application constraints,  but also manufacturing constraints  imposed by  the 3D  technologies. So far, many researchers have addressed the issues  of 3D floorplanning and 3D NoC topology generation with the  consideration of thermal hot spots. Besides the thermal and  related  thermal-mechanic stress effects [2], one particular  challenge is that the wide range of the metal area by throughsilicon-vias (TSVs) and landing pads increases non-uniform metal  density, and thus results in the critical variation of wire thickness  and TSV height during a chemical-mechanical polishing (CMP)  process [8]. The CMP processes can be used for the removal of  extra Cu on silicon after filling TSVs with Cu or depositing Cu on  TSV landing pads, called Cu-CMP and silicon backside thinning,  called silicon-CMP. The uneven Cu-wire thickness changes wire  resistance and coupling capacitance between wires, and thus  results in critical timing variation. Moreover, the uneven TSV  height leads to bonding failure between TSVs and landing pads.  To mitigate the non-uniform metal density, dummy metal or TSV  can be filled in empty spaces, but it may affect RC parasitics  [8][9] and significantly reduce usable silicon area.   In this paper, we propose the first CMP-aware applicationspecific 3D NoC design that minimizes TSV height variation,   thus  reduces bonding  failure, and meanwhile optimizes  conventional NoC design objectives. For NoC vertical links  composed of tens to hundreds of TSVs, the layout of each  individual TSV is not efficient since it results in complex global  routing and TSV manufacturing stress affects more transistors [2].  Therefore, TSVs should be placed as an array type in 3D NoC.  The work is done while Wooyoung Jang was a Ph.D. student at the  University of Texas at Austin.  However, the array with dense TSVs is sensitive to a CMP  process which results in high TSV height variation, and thus leads  to bonding failure. Moreover, if the arrays with different TSV  density are used in the same layer, bonding TSVs on landing pads  is more difficult. Therefore, TSVs in an array should be placed  with a pitch resulting in low CMP variation endured by a bonding  technique and TSV arrays with the same density should be  inserted in each layer. In addition, since the size of the TSV  arrays is too large, TSV arrays should be handled during the  floorplanning stage  in physical design. Based on  these  motivations, the major contributions of this paper include:  1) We show that TSV height variation during silicon-CMP  process is more severe in 3D NoC.  2) We propose a CMP-aware application-specific 3D NoC  design which consists of core-to-layer assignment, topology  synthesis, and floorplanning.  3) We show that the proposed 3D NoC design reduces TSV  height variation with lower design cost, and meanwhile  achieves less hop count, wirelength, and power consumption.  The rest of this paper is organized as follows: Section 2 reviews  related works. Section 3 introduces CMP and Cu-Cu thermocompression direct bonding, and then addresses various TSV  layouts and their CMP variation. Section 4 formulates CMPaware application-specific 3D NoC design problems. Section 5  presents detailed techniques of the proposed algorithms. Section 6  shows experiment results and Section 7 concludes this paper.  2. RELATED WORKS  Several works for 3D ICs have explored thermal floorplanning  [3][6]. A fast thermal-driven floorplanning algorithm with a 3D  floorplan representation and integrated compact resistive network  thermal model was proposed in [3]. Hung et al. presented  interconnect  and  thermal-aware  floorplanning  for  3D  microprocessors in [6]. Recently, researchers have synthesized a  3D NoC topology with the limited number of TSVs. Yan et al.  presented a 3D NoC synthesis algorithm that made use of accurate  power and delay models for 3D wiring with TSVs [14]. In [10]  and [12], 3D NoC topology synthesis algorithms based on a direct  extension of the 2D NoC synthesis procedure was proposed.   However, these previous 3D NoC designs have not considered  CMP variation which may lead to bonding failures and timing  variations. In addition, as routers and TSV arrays are becoming as  large as other cores, the previous 3D NoC designs would suffer  low physical design quality. This is because 3D floorplanning was  first performed without the large routers and the TSV arrays, and  thus there might be not enough spaces to place the routers and  TSV arrays [10][12]. Even if 3D floorplanning is again performed  after deciding a 3D NoC topology [14], their design qualities such  as wirelength, power consumption, and area are severely limited.  978-1-4577-1400-9/11/$26.00 ©2011 IEEE 207                    3.  PRELIMINARIES  3.1 Chemical-Mechanical Polishing Process  One of the most potential sources of yield loss and timing  variation in 3D technologies is TSV bonding on land pads. In a  typical industrial bonding procedure [13], a TSV-wafer is ground  down to a target thickness slightly above the TSV depth (keeping  TSVs unexposed) and further thinned using a CMP process. The  chemical reaction creates a hydroxilated-form material which has  weaker atomic bonds. Then, a mechanical surface abrasion aided  by slurry particles removes the material. Fig. 1(a) shows the  uneven surface of wafer backside after grinding and CMP.  Subsequently, the polished silicon surface is plasma-etched, such  that the TSVs protrude from the wafer  as shown in Fig. 1(b). On  the contrary, TSV Landing pads are commonly fabricated on the  top metal layer in a damascene process and designed to be larger  than TSVs to prevent overlay error. The top metal layer with land  pads is also polished by CMP to remove overburden Cu. Finally,  a wafer or die with landing pads is bonded with a different wafer  or die with TSVs.  (a)                                                      (b)   Fig. 1: Local topography on backside of wafer after (a) grinding and CMP  and (b) Si-recess etch following CMP [13].  3.2 TSV Layouts and TSV Height Variation  Silicon-CMP is just used for finely thinning silicon after  grinding silicon backside since the processing time of CMP is too  long. As silicon-CMP involves simultaneous polishing of silicon,  Cu, and barrier, their removal rates are different according to both  different chemical effects on the materials and different TSV  densities. The different removal rates of these materials results in  different polish times across the wafer backside. For example, in  Fig. 2(a), by the time the silicon and barrier under TSVs used for  a 64-bit link are cleared at a point, the silicon and barrier under  TSVs used for 128-bit links might have been not cleared yet.  Hence, either the silicon and barrier under the 128-bit TSVs are  underpolished at the time the silicon and barrier under the 64-bit  TSVs are cleared or the 64-bit TSVs are overpolished at the time  the silicon and barrier under the 128-bit TSVs are cleared. Fig.  2(a) shows the 128-bit TSVs are underpolished after silicon-CMP.  In [13], IMEC TSV technology showed that within-die thickness  variation after silicon-CMP was 1.5μm for a die size of  10.6×10.6mm2 when TSVs of which the diameter, pitch, and  density are 5μm, 10μm, and 10k/mm2, respectively, were evenly  distributed over the whole chip. The within-die thickness  variation is sensitive to high and irregular TSV density and  directly related to TSV height variation. Consequently, the  uneven TSV height variation can induce TSV bonding failure as  shown in Fig. 2(a). In particular, the bonding failure will be more  severe in a Cu-Cu direct thermo-compression bonding technique  since TSVs must be directly contacted to landing pads without  any micro-bump. Metal fill synthesis is not an efficient solution  for silicon-CMP since dummy TSV insertion would significantly  increases the overall chip area.   Cu-CMP silicon layer 1 silicon-CMP silicon layer 2 A erosion plasmaetch thinning B 128 bits 64 bits TSV 128 bits open open landing pad open TSV (a) A B (b) (c) (d) (e) Fig. 2: TSV layouts and TSV height variation induced by CMP process.  TSVs can be placed with different schemes during placement  and routing [2]. If TSVs are laid out without any constraints  imposed by 3D technology, they can be distributed as shown in  Fig. 2(b). Whereas such layout achieves much shorter wirelength,  TSV height variation induced by silicon-CMP greatly increases  due to uneven TSV density. In Fig. 2(c), TSVs are placed with  globally uniform density distributions. The TSV distribution  provides the least TSV height variation to 3D ICs. However, such  TSV layout is not suitable for NoC vertical links composed of  tens to hundreds of TSVs since it results in so complex global  routing that any wire in the same vertical link may detour with a  long path. The long wires detoured makes system performance  degraded or timing closure difficult. In addition, the layout of  each individual TSV causes manufacturing stresses to more  devices [2]. Therefore, grouping TSVs to an array and then laying  out the array is more desirable for 3D NoC.   In Fig. 2(d), there exist two kinds of TSV arrays. The small  array includes a one-way link and the large array includes a twoway link which may have two times more TSVs than the one-way  link. TSVs in the small array fail to contact landing pads since  TSVs in the large array are less cleared than those in the small  array during silicon-CMP such that the surface in a die is uneven.  In Fig. 2(a) that is the cross section of AB in Fig. 2(d), the 64-bit  TSV array has the strong possibility of failing to contact landing  pads on silicon layer 2 since the 128-bit TSV array is  underpolished. In addition, since the metal density of the 128-bit  TSV is high, its own silicon-CMP variation can be so high that  TSVs in the array have the possibility of failing to contact landing  pads. We can control the local TSV density defined as the size of  a TSV array divided by a TSV pitch. If the 128-bit TSV array has  a wider TSV pitch, its density can be as low as that of the 64-bit  TSV array. However, since it has the penalty of area, we focus on  reducing the size of a TSV array as shown in Fig. 2(e).   4. PROBLEM FORMULATION  In most previous application-specific 3D NoC designs [10][12]  [14], 3D floorplanning is first performed and then a 3D topology  is determined as shown in Fig. 3(a), where their 3D technology  constraint is the number of allowable TSVs. However, there may  be no enough dead space where routers and TSV arrays can be  physically placed after deciding a 3D topology [10][12]. In order  to prevent overlapping routers, TSV arrays, and cores already  floorplanned, additional floorplanning is performed in each layer  [14], but such 3D NoC design flow is not efficient for reducing  wirelength, hop count, and thus energy consumption. Furthermore,  the layout of TSV arrays without considering CMP variation leads  to TSV bonding failure on landing pads.   208     Fig. 3(b) shows the proposed CMP-aware NoC design flow  covering such issues. We first assign n cores to k layers with the  purpose of using fewer TSVs. The number of allowable routers is  inserted in each layer, and then the routers are interconnected to  cores and different routers in the same layer, where the number of  interconnecting any router to cores and other routers is given.  Next, any routers are also interconnected to different routers in  adjacent layers by only one-way vertical links. Since the number  of allowable TSVs between layers is also limited, vertical  interconnections are placed for the minimum hop count. Then,  routing paths without deadlock and livelock are allocated on the  existing interconnections. A TSV pitch for the one-way link is  computed and a TSV array is composed. Finally, all cores, routers,  directed graph, where each vertex vi(cid:1488)V represents a core, a router,  and TSV arrays are simultaneously floorplanned in each layer.  and a TSV array and each directed edge ei,j(cid:1488)E represents  We start to solve the CMP-aware application-specific 3D NoC  issues from a core graph. A graph G(V,E) with n vertices is a  communication relation between vi and vj. vol(ei,j) represents  communication volume between vi and vj and wl(ei,j) represents  wirelengh between vi and vj.   4.1 Core-to-Layer Assignment  Core-to-layer assignment allows cores  to move  from  continuous space to discrete space, forcing each core to exactly  occupy one layer. That is, a set of cores V={v1, v2, …, vn} is  assigned to k layers L={l1, l2, …, lk}, and thus V={Vl1, Vl2,…, Vlk}  is obtained, where Vli={v1 li, v2 li, …, vj li}, where j<n. The area of  cores is represented as {A1, A2, …, An}. To equally assign the area  of cores to layers, an area constraint is defined as:   max min 1 1 n n i i l i i A k A                             (1)       k A        where αmin and αmax are acceptable minimum and maximum area  coefficients (αmin <1< αmax), respectively. We use the thermal  model proposed in [3]. With the area constraint, the objective of  our layer assignment is to minimize communication between  layers and lower temperature as follows:    V u   1 2 i j , 1 1 1 m in s.t. ,l l v u p k k p q p b p q p i j u v vo l e P R R P v V v v                                                (2)  where β1 and β2 are weighting coefficients, Rq is a thermal resistor  in layer q, Pp is the sum of current source in layer p, and Rb is the  thermal resistor of the bottom layer material.  4.2 3D NoC Topology Decision and Routing  Path Allocation  vertices is a directed graph, where each vertex ri(cid:1488)R  represents a  Given the number of allowable routers and TSV arrays and the  number of different routers interconnected to one router in each  router, and each directed edge ci,j(cid:1488)C represents communication  layer, we interconnect a router to cores and different routers in the  same layer. A router communication graph RCG(R,C) with m  between ri and rj. The objective of our 2D topology is as follows:                      , , dist M v M v , M v M v , , , min s.t. i j i j lu i j i j i j vol e v v V bw link vo l e                  (3)  where dist(rp,rq) is distance (hop count) between rp and rq and M()  is a core-to-router mapping function. link(rp,rq) is all links which  any packet in rp passes for reaching rq. Then, we interconnect  routers in adjacent layers, based on the RCG graphs. The  objective of our topology decision among layers is as follows:                  , , , , , , , m in s .t. , , i j p q TSV p q TSV l u q p l v p q i j i j e d ist r r V V link r vo l e r link   r r   bw link r r vo l v v u v       (4) where linkTSV(rp,rq)(cid:1488)link(rp,rq) is a vertical link which any packet   in rp passes for reaching rq. This equation indicates that routers in  different layers are interconnected by only one-way vertical links.  Thus, CMP variation can be greatly reduced and the yield of TSV  bonding can be greatly improved.      4.3 Floorplanning  Based on our predictive CMP model, we compute a TSV pitch  where a used boding technique must endure TSV height variation  in the number of TSVs covering a one-way vertical link. Then  TSV arrays are inserted between any routers in adjacent layers.  As the inputs of our floorplanner, we take a set of cores, routers,  and TSV arrays, {v1, v2, …, vn}. vi is a Wi×Hi rectangle and aspect  ratio Hi/Wi. Each block can be free to rotate and change the aspect  ratio continuously in a given range [ARmin,i, ARmax,i]. A floorplan F  is the assignment of (xi, yi) for each block vi without any overlap  of all cores, routers and TSV arrays, where half-perimeter wire  length estimation is used. We use the thermal model proposed in  [3], which minimizes the maximum temperature difference in the  same layer. Finally, the objective of our floorplan F is as follows:         v                 1 2 p q , p q , 3 p q , max T x y l , , min T x y l , , , , , max min s.t. i u u lu w p q i w l e vol e V w l e th A v v                               (5) where γ1, γ2, and γ3 are weighting factors. T(x,y,lu) is the  temperature of a tile in x, y, and lu at x-axis, y-axis, and layer,  respectively and thw is the maximum allowable wirelength.  Core-to-layer assignment Floorplanning cores (a) Conventional 3D NoC design flow Router insertion Router interconnection to  core/different router 3D topology decision Routing path allocation Core-to-layer assignment Floorplanning cores,  routers, TSV arrays (b) CMP-aware 3D NoC design flow Router insertion TSV array insertion and  router interconnection to  core/different router Routing path allocation 3D topology decision 3D floorplanning Router library Predictive CMP model Router library Floorplanning cores and routers Fig. 3: Application-specific 3D NoC design flows.  209         5. CMP-AWARE 3D NOC DESIGN  5.1 CMP-Aware Core-to-Layer Assignment   Since the number of TSVs required depends on communication  volume between different layers, the communication volume  should be minimized together with thermal consideration. In  addition, the area of each layer should meet the area constraint,  Eq. (1). Fig. 4 shows two different core-to-layer assignment  approaches where eight cores are assigned to four layers. Let a  core graph given as shown in Fig. 4(a) where all edges have the  same weight, all cores have the same power density, and the  number is the area of a core for simple explanation.   The first approach is that 4-way minimum-cut area-balanced  partitioning is performed, and then the partitioned subgroups are  one-to-one assigned to different layers. For example, in Fig. 4(b),  the cores are partitioned to {A, B}, {C, D}, {F, G}, and {E, H}  that have the same area and the minimum cuts. Then, the  partitioned subgroups are one-to-one assigned to any layers,  achieving the minimum hops as shown in Fig. 4(c).   The second approach we propose in Algorithm 1 recursively  performs area-balanced bi-partitioning with the minimum cost  computed from Eq. (2). Fig. 4(d) shows the result of the first bipartitioning where the same area and the minimum cut are  obtained (line 2). Then, any core which communicates other cores  in a different layer is assigned in advance, depending on their  communication gain as shown in Fig. 4(e) (line 5). The  communication gain is computed as the subtraction of the amount  of  intra-layer  communication  from  that of  inter-layer  communication. If the communication gain of any core is greater  or equal to 0, the core is assigned to a current layer. In Fig. 4(e),  core B, C, E, and F communicate cores in a different layer and  their communication gains are 0, -1, 0, and 0, respectively. Thus,  core B, E, and F are assigned to boundary layers. Then, the  second bi-partitioning in each sub-group is again performed for  the minimum cut under the area constraint. Fig. 4(f) shows the  final result where hop count between layers is 7 whereas the first  approach is 8. Therefore, the second one can require fewer TSVs.  The basic idea of Algorithm 1 can be easily extended even if the  number of a given layer is not a power of two.   Fig. 4: Examples of assigning eight cores to four layers.  210 1:  Algorithm 1: Core-to-Layer Assignment by Recursive Bi-Partitioning while the number of partitioned layers is not equal to the target  number of layers do  Find bi-partitions of cores with min. cost computed by Eq. (2);      Compute communication gain (CGi) of core i in layer k;      if CGi ≥0 then          Core i is assigned to layer k;     end if  end while  2: 3: 4: 5: 6: 7: 5.2 CMP-Aware 3D NoC Topology Decision  Since a 3D network topology decision problem is NP-Hard, we  present efficient heuristics in this section. Furthermore, since the  integrated problem makes it difficult to reach guaranteed quality  bounds on the solution, we divide the 3D network topology  decision problem into two distinct subproblems, called router-tocore/router interconnection in the same layer and router-to-router  interconnection between different layers, and then we solve the  respective subproblems. Whereas a bandwidth requirement can be  easily satisfied by finding alternative routing paths or adding  more interconnection resources, satisfying latency constraints is  difficult if cores communicating each other are too wide apart.  Therefore, any master core sensitive to latency should be  interconnected to the same router as its slave core. A TSV array  covering a one-way vertical link is used for interconnection  between different layers and any router is not interconnected to  routers in a different layer if it is already interconnected to the  router with one direction as shown in Eq. (4), which minimizes  TSV density variation, thus reduces TSV height variation  resulting in TSV bonding failure.   5.2.1 2D Router-to-router/core interconnection  Given a core graph,  the number of allowable routers  (max_router), and the number of allowable interconnection to a  router  (max_int), our 2D  topology  synthesis  technique  interconnects possible cores to any routers. The objective of our  2D topology decision is to minimize power consumption in each  layer. Varying the number of routers in NoC designs has a great  impact on power consumption and communication latency. NoC  using few routers leads to longer core-to-router interconnections  and hence, higher interconnection power consumption. On the  contrary, when a number of routers are used, data flows have to  traverse more routers, leading to high router power consumption  and increasing area. Thus, we need to explore NoC designs with  the different number of routers to obtain the best solution, starting  from a design point where each core is interconnected to the  minimum routers to one where cores are connected to the  maximum allowable routers (max_router) in each layer.   The objective of Algorithm 2 is to establish efficient physical  links between a router and a router/core in each layer. First, i-way  minimum-cut partitioning is performed for cores in the same layer  under the max_int constraint (line 2) and then each group is  assigned to one router (line 3). Next, links between the routers are  inserted according to user’s design objective (line 4). We  implement the minimum spanning tree (MST) or point-to-point  (P2P) interconnection. MST first interconnects two vertices  nearby. Similarly, since two routers, rp and rq which heavily  communicates each other should be interconnected with high  priority, we use 1/vol(cp,q) as the distance information. Then, the  breadth-first-search or depth-first algorithms are used for  searching MST. Next, a new router communication graph (RCG)  is generated and then a prohibited turn set for the RCG is build to    Algorithm 2: Topology Decision within Layer  1:   for i= max_router to (the number of core/max_int) do  2:  Find i-way min-cut partitions under max_int constraints;  3:  Assign each group to one router;  4:  Interconnect routers by user’s design objective;  5:  Build router communication graph (RCG);  6:  Build prohibited turn set for RCG to avoid deadlocks;  7:  Find paths for flows across different routers in each layer;  8:  Evaluate latency and and bandwidth;  9:  Go to line 2 if application constraints are not satisfied;  10:  end for  11: Choose the best topology and design point;  avoid deadlocks (line 5-6). Based on the links, paths for flows  across different routers in the same layer are allocated, using  Dijkstra’s shortest path algorithm (line 7). Application constraints  such as communication latency and bandwidth are evaluated (line  8). If they are not satisfied, a different topology for the layer is  again synthesized (line 9). Finally, the best topology and design  point are selected among all generated topologies (line 11).  5.2.2 Layer-to-layer interconnection  After deciding a 2D topology in all layers, any layers must be  interconnected to adjacent layers. Since we use the minimum TSV  arrays, total hop count may increase according to the location of  the TSV arrays. In addition, inserting either both one-way and  two-way links in the same layer or a TSV array with high metal  density results in severe TSV height variation during CMP. Thus,  the objective of our layer-to-layer interconnection is to insert oneway links between layers for locally uniform TSV distribution  insertion candidates, where rp(cid:1488)Vlm and rq(cid:1488)Vln, (m≠n).  and the minimum hop count under performance constraints. In our  technique, if a one-way vertical link for cp,q is established, the  opposite one-way link for cq,p is removed in the list of TSV array  For example, Fig. 5(a) is a core graph assigned to two layers,  where the weight of all edges is 1. After deciding its topology in  each layer, we can insert TSV arrays for the minimum hop count  as shown in Fig. 5(b) and (c). TSV height variation during CMP is  critical in the two-way link with high metal density. Therefore,  Fig. 5(c) is desirable for low and uniform local TSV density.  we defined the cost function as the product of communication  volume vol(ei,j) and wirelength wi.j in Eq. (5). In addition, it is  necessary to place cores, routers, and TSV arrays communicating  within the allowable wirelength.   6. EXPERIMENTAL RESULTS  6.1 TSV Density and Predictive CMP Model  Fig. 6 shows TSV heights measured from the latest 3D ICs of  IMEC after silicon-CMP, where the TSV diameter is 5μm [7].  With these industry measurement data, we model TSV height  variation as follows:  hv  0.8017 ln    s p     1.226                              (6) where hv is TSV height variation, s is the size of TSV array, and p  is a TSV pitch in the array. Based on this model, we can compute  a TSV pitch for the size of a given TSV array, which guarantees  TSV height variation endured by a bonding technique. For  example, if the size of a TSV array including a one-way link (113  wires) for OCP is 11×11, its TSV pitch must be at least 14.58μm  for less than 1μm TSV height variation. On the contrary, if the  size of a TSV array including a two-way link is 16×16, its TSV  pitch must be at least 21.21μm. Thus, their areas are 0.0256mm2  and 0.1151mm2, respectively. Consequently,  two one-way  vertical links can show lower CMP variation or smaller design  area than a single two-way vertical link.   6.2 CMP-Aware Application-Specific 3D NoC   We implement the CMP-aware application-specific (CAS) 3D  NoC and [14] on GSRC Benchmarks with 100, 200 and 300  modules [4]. Wafers are stacked in a face-to-back fashion and we  set a diameter and pitch of TSV to 5μm and 10μm, respectively.   Table 1 shows TSV height variation when various network  interfaces are used. The local TSV density of CAS is more  uniform and lower than that of [14] and CAS has 17.9% lower  TSV height variation than [14]. Using only one-way links results  in increasing hop count since it may not provide the shortest path.  However, our 3D NoC design flow recovers the penalty of the  hop count and even improves total hop count since a topology  Fig. 5. CMP-aware router-to-router interconnection in adjacent layers.  5.3 CMP-Aware Floorplanning  We first compute a TSV pitch for one-way links, based on our  predictive CMP model. The pitch must result in low TSV height  variation endured by a bonding technique. Then, a TSV array is  build and then simultaneously floorplanned with routers and cores  in each layer. The goal of our floorplanning is to generate the  layout that minimizes area, power consumption, and peak  temperature. We modify an existing floorplanning technique [5]  and invoke it with our unique cost function.  The power consumption on the given network can be presented  as the power required by physical links. It is desirable to place  cores,  routers, and TSV arrays nearby  if  they heavily  communicate. This is because the power consumption is directly  proportional to the number of hop and the length of link. Hence,  Fig. 6. Silicon-CMP variation based on IMEC wafer measurement [7].  Table 1: TSV Height Variation Comparison (μm).  Network  protocol  AHB [1]  AXI [1]  APB [1]  OCP [11]  # of wire of  one(two)-way link  137 (274)  204 (408)  99 (198)  113 (226)  Average  [14]  1.651  1.821  1.551  1.603  1.657  CAS  1.372  1.551  1.226  1.302  1.363  Imp. (%)  16.9  14.8  21.0  18.7  17.9  211       decision is first performed.  Table 2 shows total hop count. CAS achieves, on average, 15%  lower hop count than [14]. CAS tends to further improve hop  count in complex NoC with a number of modules and layers. In  addition, when a network is synthesized with limited resources  like MST, CAS further improves hop count. As shown in Table 3,  CAS achieves just 0.3% longer total wirelength than [14] in MST  and even 4.6% shorter total wirelength than [14] in P2P.   I.(%) 16.5  20.0   22.6 19.7  13.1  8.7  11.1  11.0  I. (%) -0.3  0.0  -0.6  -0.3  2.1  4.7  7.0  4.6  n300  n200  M  S  T  the number of layer  n100  [14]  CAS  [14]  CAS  [14]  CAS  Imp. (%)  [14]  n100  CAS  [14]  CAS  [14]  CAS  Imp. (%)  P  2  P  n200  n300  Table 2: Hop Count Comparison.  4  1410  1201  3341  2654  5211  4065  20.5  1193  1077  2051  2041  2638  2626  2.3  5  1470  1254  3366  2931  5158  3912  19.0  1336  1194  2487  2278  3279  2943  9.7  6  1625  1299  3459  2698  5178  4077  21.3  1488  1207  2744  2441  3433  3405  8.0  7  1671  1361  3737  2934  5257  3984  22.4  1629  1416  3136  2788  4163  3234  16.7  8  1927 1650 3927 3043 5230 4118 20.5  1799 1575 3285 2968 4371 3695 12.9  Table 3: Total Wirelength Comparison (mm).  n300  n200  M  S  T  the number of layer  n100  [14]  CAS  [14]  CAS  [14]  CAS  Imp. (%)  [14]  n100  CAS  [14]  CAS  [14]  CAS  Imp. (%)  P  2  P  n200  n300  4  9.6  9.6  22.6  23.2  46.5  47.0  -1.4  47.2  46.5  95.4  89.6  144.6  132.1  7.5  5  8.4  8.5  19.1  19.1  39.5  40.0  -0.9  38.6  38.3  77.7  75.1  129.9  119.6  5.4  6  7.5  7.4  16.6  16.6  34.4  34.1  0.7  32.9  32.3  67.8  65.0  115.5  108.6  4.8  7  7.1  7.1  15.1  15.0  30.5  30.7  -0.2  29.6  28.0  61.3  58.5  102.6  99.4   3.9  8  6.5  6.6  13.8  13.3  27.2  27.3  0.6  26.4  26.2  55.2  52.3  94.5  86.1  6.5  (a) MST  Fig. 7: Power consumption normalized by [14].  (b) P2P  212 (a) [14]                                                       (b) CAS    Fig.  8:  The layout of application-specific 3D NoC designs  Fig. 7 shows power consumption normalized by [14]. The  power consumption of CAS is 8.1% and 7.8% lower than that of  [14] in MST and P2P, respectively. The total area of CAS is  slightly smaller than [14] since CAS has smaller total TSV array  area than [14]. The runtime of CAS ranges from 48-99 seconds in  n300, which is about three times faster than [14].  Fig. 8 show the layouts generated by [14]+MST and CAS+MST,  where blue lines show communication relations and their  thickness indicates communication volume. Yellow rectangles,  red rectangles, and green rectangles are cores, TSV arrays, and  routers, respectively. Whereas Fig. 8(a) includes both one-way  and two-way links, Fig. 8(b) includes just one-way links.  Therefore, TSV heights are less variable, thus TSVs can directly  contact landing pads easily.   7. CONCLUSION  In this paper, we proposed the first CMP-aware applicationspecific 3D NoC design. Our vertical integration managing  architecture, physical design, and manufacturing issues together  enables a reliable and robust 3D NoC with  low power  consumption and high performance. In particular, our CMP-aware  3D NoC approach reduces TSV height variation during the CMP  process, and thus prevents bonding failures and timing variation.   8. "
2011,Co-design of channel buffers and crossbar organizations in NoCs architectures.,"Network-on-Chips (NoCs) have emerged as a scalable solution to the wire delay constraints, thereby providing a high-performance communication fabric for future multicores. Research has shown that power, area and performance of Network-on-Chips (NoCs) architecture are tightly integrated with the design and optimization of the link and router (buffer and crossbar). Recent work has shown that adaptive channel buffers (on-link storage) can considerably reduce power consumption and area overhead by reducing or replacing the power hungry router buffers. However, channel buffer design can lead to Head-of-Line (HoL) blocking which eventually reduces the throughput of the network. In this paper, we explore the design space of organizing channel buffers and router crossbars to improve the performance (latency, throughput) while reducing the power consumption. Our proposed designs analyze the power-performance-area trade-off in designing channel buffers for NoC architectures while overcoming HoL blocking through crossbar optimizations. Our simulation and NoC design synthesis shows that for a 8 × 8 mesh architecture, we can reduce the power consumption by 25-40%, improve performance by 10-25% while occupying 4-13% more area when compared to the baseline architecture.","Co-Design of Channel Buffers and Crossbar Organizations in NoCs Architectures Avinash Kodi†, Randy Morris†, Dominic DiTomaso†, Ashwini Sarathy‡ and Ahmed Louri‡ †Electrical Engineering and Computer Science, Ohio University, Athens, OH 45701 ‡Electrical and Computer Engineering, University of Arizona, Tucson, AZ 85721 kodi@ohio.edu, louri@ece.arizona.edu Abstract— Network-on-Chips (NoCs) have emerged as a scalable solution to the wire delay constraints, thereby providing a high-performance communication fabric for future multicores. Research has shown that power, area and performance of Network-on-Chips (NoCs) architecture are tightly integrated with the design and optimization of the link and router (buffer and crossbar). Recent work has shown that adaptive channel buffers (on-link storage) can considerably reduce power consumption and area overhead by reducing or replacing the power hungry router buffers. However, channel buffer design can lead to Head-of-Line (HoL) blocking which eventually reduces the throughput of the network. In this paper, we explore the design space of organizing channel buffers and router crossbars to improve the performance (latency, throughput) while reducing the power consumption. Our proposed designs analyze the power-performance-area trade-off in designing channel buffers for NoC architectures while overcoming HoL blocking through crossbar optimizations. Our simulation and NoC design synthesis shows that for a 8 × 8 mesh architecture, we can reduce the power consumption by 25-40%, improve performance by 10-25% while occupying 4-13% more area when compared to the baseline architecture. I . INTRODUCT ION In order to address the growing wire delay problems and improve the performance of future multi-cores, a growing number of designs have adopted the ﬂexible and scalable packet switched architecture, called Network-on-Chips (NoCs) [1], [2]. Power dissipation in NoCs is the most important technology constraint and is rapidly affecting performance (latency and throughput) of multicores [3]. With NoC, researchers have shown that 46% of the router power is consumed by the input buffers, while the crossbar occupies more than 54% of the router area [4]. Therefore, with the need for low-power architectures, researchers have initiated several efforts into optimizing and minimizing the power and area overhead while improving performance of NoC architectures [5], [6], [7], [8], [9], [10]. As router buffers consume substantial power, researchers have analyzed several techniques to optimize and minimize the impact of router buffers. Recently, iDEAL (inter-router Dual-function Energy and Area-efﬁcient Links) [11] proposed to reduce the size of the router buffer and to minimize the performance degradation due to the reduced buffer size, the already existing repeaters along the inter-router channels are doubled as buffers along the channel when required. While the single channel combined with static virtual channel (VC) allocation created head-of-line (HoL) blocking, iDEAL design resorted to dynamic buffer allocation to sustain performance which in turn increased complexity. Another approach utilizing channel buffering is the Elastic Channel Buffers (ECB), which replaces the repeaters with ﬂip-ﬂops, and eliminates the router buffers altogether [8]. HoL problem was eliminated by creating two separate subnetworks which reduced power consumption and limited area overhead, however the performance (throughput) was signiﬁcantly affected. Other bufferless networks such as FlitBLESS [9] and SCARAB [10] adopt either deﬂecting or dropping conﬂicting packets, thereby reducing the latency and power, while sustaining throughput at low network loads. However, at high network loads, these networks suffer from excessive deﬂection/dropping leading to an increase in power consumption. The crossbar within the NoC has also received a lot of attention due to area overhead and power consumption [6], [12], [5]. Researchers have proposed segmented and split crossbars to reduce the power and area overhead. While crossbar optimizations have reduced the power consumption and area overhead, there has been no codesign analysis of channel buffer and crossbar organization. In this paper, we propose to uniquely co-design channel buffers and router crossbars with the goals of minimizing power consumption, eliminating HoL blocking, and further improving network performance. HoL blocking can be eliminated with dual inputs per router port and to facilitate this design, we analyze three different channel buffer organizations; they include dual channel (dc), dual channel multiinput (dcM), and single channel multi-input (scM) organizations. With dual input ports, we propose multiple ways of organizing the crossbars to take advantage of the speedup offered with different routing and allocation mechanisms; they include dual input single crossbar (dsx), dual crossbar (dx) and multi-crossbar (mx) organizations. Each of these organizations improve performance from the speed-up and provide varying power savings. We used the Synopsys Design Compiler to evaluate the power, area and router pipeline latencies for various conﬁgurations. Our results indicate that the router pipeline to be within the design tolerances for 2 Ghz router clock at 1.0 V and consuming 25% to 40% lesser power while occupying 5% to 13% excess area for different design conﬁgurations. Cycle accurate network simulation on a 8 × 8 mesh network topology shows 10-25% improvement 978-1-4577-1400-9/11/$26.00 ©2011 IEEE 219 in performance for different synthetic trafﬁc traces when compared to the baseline with identical router buffers. The major contributions of this work are as follows: • We uniquely identify channel buffer organizations that avoid Head-of-Line (HoL) blocking, thereby prevent performance degradation. • While various crossbar organizations reduce the power consumption, we further show techniques to improve performance with minimal adaptive routing. • We evaluate the proposed buffer and crossbar organizations on synthetic (uniform and permutation) and real applications (PARSEC [13] and SPEC2006 benchmarks) showing a performance improvement of 10-25%, power savings of 25-40% with an area overhead of 513%. I I . ADA P T IVE CHANNE L BU FF ER S In this section, we detail the implementation of the dualfunction links and the associated control logic. Figure 1(a) shows a repeater-inserted interconnect, with the conventional repeaters replaced by three-state repeaters (see inset). A single stage of the three-state repeaters comprises of a threestate repeater inserted segment along all the wires in the link. When the control input to a repeater stage is low, the threestate repeaters in that stage function like the conventional repeaters transmitting data. When the control input to the repeater stage is high, the repeaters in that stage are tri-stated and hold the data bit in position. The adaptive dual-function links hence enable a decrease in the number of buffers within the router and saves appreciable power and area. Control Block Implementation: The design shown in Figure 1(a) requires a single control block per inter-router link in order to control all the repeater stages along the link, unlike the design in [8] which uses one control block per stage along the link. Therefore, our proposed control technique is power-efﬁcient and has a lesser area overhead. In addition, the proposed control block outputs one control signal per repeater stage and can thereby tri-state or release each stage independent of the other stages. Figures 1(b) and 1(c) show the control logic and the state diagram for one stage within the control block. The control logic to generate one control signal output, CT RL consists of only one ﬂip-ﬂop and three gates. The ﬂip-ﬂop delays the incoming control signal by one clock, while the gates determine the next state of the control signal based on the inputs received from the router. The control block operates with two logic states : ‘Release’ and ‘Hold’. In the hold state, the control block delays the incoming congestion signal by one clock cycle before transmitting it to each successive repeater stage. Hence each repeater stage is successively tri-stated to hold the data in position, until the congestion signal is released. During congestion, the router may request the control block to release any given repeater stage, by setting the corresponding bit in the ‘release stage’ signal. The control block then moves to the release state and resets the control signal to the particular stage whose release stage bit has been set by the router. In order to reduce the power consumption due Repeater Stage-4  Repeater Stage-1  Bit 1  Output  Port of    Router A  Three-state  repeater  (a)  Input   Port  of   Router  B  Cgn En  Clk  Bit n  4  rel_st  Control  Block  Clk : Clock  En : Enable  Cgn : Congestion  rel_st : release_stage  rel_st = 1  En = 1  RELEASE   CTRL[n]  rel_st[n]  rel_st = 1  Cgn  CTRL[n-1]  vc_en  En  Clk  n : number of link repeater stages   CTRL[n] : control signal for nth stage  CTRL[n-1] : control signal for (n-1)th stage  rel_st[n] : release_stage for nth stage  HOLD  rel_st = 0,  Cgn = 1  (b)  (c)  Fig. 1. (a) A link using three-state repeaters that function as channel buffers during congestion, (b) Control block implementation details and (c) State transition diagram. to the control block, it is enabled by the router only during congestion, using the ‘enable’ signal. The vcen signal is used in conjunction with the switching control to indicate to the control block the onset of a ﬂit into the repeater stage. I I I . CHANNE L BU FF ER ORGAN IZAT ION S In this section, we propose three channel buffer organizations - dual channel (dc), dual channel multi-input (dcM) and single channel multi-input (scM) organizations. Figure 2 shows the conﬁgurations for one link between the upstream and downstream router. Each packet is composed of 4 ﬂits with each ﬂit being 128 bits. (cid:2) A. Dual Channel Organization Figure 2(a) shows the dual-channel buffer conﬁguration. In this conﬁguration, we duplicate the channel buffers to avoid HoL blocking as shown. Each channel has a dedicated input port (register) at the downstream router to read the ﬂit before it will be written into the crossbar. The two inputs are shown as I0 and I 0 . When the ﬂit is read into the register, it activates the control block (CB0) or (CB1) to indicate a full register. As explained before, the control block will then hold ﬂits one cycle after another into different channel buffers associated with the particular control block. To ensure that the channel buffers are ready to store the ﬂit, the DEMUX information is also transmitted to the control block to indicate that a ﬂit will be arriving via the vcen signal. When all the channel buffers are occupied, it will then signal the upstream switching control to indicate a full channel or congestion. The ﬂit read into the register undergoes the standard router pipeline 220 stages of RC (route computation), VC (virtual channel) allocation, SA (switch allocation) and then switch traversal (ST), before moving on to link traversal (LT). Here, we combine RC and VC into a single stage, giving us a 4stage router pipeline. Look-ahead routing can be employed for deterministic routing while adaptive routing schemes require RC to be computed to ﬁnd the best downstream router. Once, the ﬂit is in the ST stage, we transmit the VC allocation information (0 or 1 as there are 2 VCs) along with the ﬂit to the switching control to set the DEMUX to the appropriate channel buffer link. When all the channel buffers are occupied for a particular VC, the switching control will deactivate the channel buffer from receiving any more ﬂits until the control block releases the congestion. The dual channel buffer organization reduces the HoL blocking, providing differentiated classes of service while also ensuring sufﬁcient buffering to improve the throughput. B. Dual Channel Multi-Input Organization Figure 2(b) shows the dual channel multi-input (dcM) organization. Here, with the goal of increasing the throughput, we organize the channel buffers such that we have 4 VCs but with two channel buffers per VC. This organization will reduce congestion for the same input port. As there are 4 VCs, we have 4 separate control blocks to control the channel buffers. All the congestion signal is fed into the switching control that manages the ﬂow of ﬂits into the different channel buffers. We use two sets of 2-to-1 DEMUXes to reduce the area overhead due to aligning the channel buffers as shown. The VC allocation includes two control bits directed to two sets of DEMUXes to direct the ﬂit to the correct VC. The objective of this organization is to relieve congestion while saving power and minimizing the increase in area overhead. The area overhead of this organization is higher due to the stacking of the channel buffers. We reduce area overhead by increasing the number of repeater stages and resizing the repeaters. This results in increase in the power consumption slightly, as more repeater stages are included, however, the resizing reduces the area overhead. C. Single Channel Multi-Input Organization Figure 2(c) shows the single channel multi-input organization. Here, we stack the channel buffers towards the entry point into the downstream router. This organization reduces the congestion only at the entry into the downstream router, however, the HoL blocking is not completely eliminated. The control blocks CB0 to CB3 transmit the congestion signal to the control block CB4. CB4 releases the ﬂit along the single channel buffer only if CB0 to CB3 release the congestion and the head of the line matches the VC identiﬁer. Therefore, this design does not completely eliminate the HoL blocking, however, the design reduces the area overhead as compared to dcM design above. The switching control sends multiple VC allocation information as there can be potentially three in-transit channel buffers. This is needed at the CB4 to determine where each ﬂit held in the channel Upstream  Router  128  D E M U X  Switching  Control  2  Upstream  Router  128  Three-state   repeater  D E M U X  D E M U X  D E M U X  Switching  Control  3  4  Upstream  Router  128  6  Switching  Control  (b)  D E M U X  4  (c)  CB4  CB0  Reg  Reg  I0  I0’  CB1  Downstream  Router  Control Block (CB)  (a)  CB0  CB1  CB2  CB3  Reg  Reg  Reg  Reg  M U X  M U X  I0  I0’  Downstream  Router  CB0  CB1  CB2  CB3  Reg  Reg  Reg  Reg  M U X  M U X  I0  I0’  Downstream  Router  Fig. 2. (a) Dual channel (dc) buffer organization, (b) Dual channel multiinput (dcM) buffer organization and (c) Single channel multi-input (scM) buffer organization. buffer is directed. This design provides a trade-off between performance and area overhead due to the stacking of the channel buffer at the end of the link. IV. CRO S SBAR ORGAN IZAT ION S The dual inputs from the buffer should be utilized to further increase the throughput of the network. To that end, we propose three crossbar organizations with different routing and allocation mechanisms; they include dual input single crossbar (dsx), dual crossbar (dx) and multi-crossbar (mx) organizations. A. Dual Input Single Crossbar Figure 3(a) shows the dsx crossbar (1-bit). Dsx is constructed by placing transmission gates between output lines of a matrix crossbar. These transmission gates allow or block an electrical signal from crossing from one side to the other. For example, if a high voltage signal is placed on the transmission gate, there is a conduction path from one side to another. On the other hand, if a low voltage signal is placed on the transmission gate, the electrical current is blocked creating a segmentation of the crossbar input. By correctly controlling these transmission gates, it is possible to segment the matrix crossbar to allow for multiple ﬂits from the same input port to traverse the crossbar. In Figure 3(c), an example of multiple ﬂits traversing the crossbar at the same time is shown. From the ﬁgure, I0 has one ﬂit traversing the crossbar to O2 and also has another ﬂit traversing the crossbar 221  Router  (RC)  Registers  Reg  Reg  F L I P  + x  - x  + y  - y   Virtual Channel   (VC)   Switch Allocator   (SA)  Crossbar Switch  O0   O1  O2  O3  O4  I0  I0’  I1  I1’  I2  I2’  I3  I3’  I4  I4’  Processing Element (PE)  (a)  Input 1  Input 2  Out 1  p  p  Out 2  I0  I1  I2  I3  I4  Detection Logic  (b)  Out 1  Out 2  Switch Logic  I0’  ’  I1 ’  I2 ’  I3 ’  I4 O0  O1  O2  (c)  O3  O4  Fig. 3. (a) Dual input single matrix crossbar (dsx) organization, (b) Flip logic and (c) Example communication from dual inputs. to O3 . This is accomplished by having the transmission gate off that is between the two output ports and all the other transmission gates along the input to be on. From the ﬁgure, the transmission gate between O2 and O3 for input I0 will be deactivated by placing a value of 0 on the transmission gate. All other transmission gates along I0 will have a value of 1 as this is require for I0 to be connected to O2 and O3 . Switch Allocator Implementation: As each input port has the potential for two different packets traversing across a crossbar, the standard switch allocation found in most routers needs to be augmented. In a separable output-ﬁrst switch allocator, ﬂits will proceed through two stages of arbitration [14]. During the ﬁrst stage, all output ports are combined together (OR logic) into a P bit value, where each bit corresponds to an output port. Then the P bits from each input port are routed to the correct P:1 arbiters. Next, each P:1 arbiter independently selects which input port is granted the right to traverse across the crossbar to the given output port. Afterwards one bit from each of the P:1 arbiters are combined together and progress to the second stage of each input port. In the second stage, the output ports from each input port won compete among the multiple ﬂits inside each input port to see who will traverse the crossbar. To accomplish this, the P bits are logic AND and then OR together with the requesting input port ﬂits to see if there is a match. If there is a match the corresponding bit for the selected requesting ﬂit will be high and will proceed to the V:1 arbiter. Finally, the V:1 arbiter will select a ﬂit to traverse the crossbar. It should be mentioned from the ﬁgure, dsx will have a value of 5 for p and a valve of 2 for V as dsx has 5 input/output ports and 2 incoming ﬂits. We add another V:1 arbiter in series with the ﬁrst arbiter. This second V:1 arbiter is used to select an additional packet for a different output port if the given input port was granted to two or more output ports. The reason the second V:1 arbiter is designed in series and not in parallel with the ﬁrst V:1 arbiter is we do not want the second arbiter to select the same input buffer as the ﬁrst arbiter. Conﬂict Free Allocator: Each of the two V:1 arbiters can select a combination of output ports that will cause a conﬂict. For example (Figure 3(b)), the ﬁrst V:1 arbiter for input 1 can select output 4 and the second V:1 arbiter can select output 2. As this creates a conﬂict, only input 1 will have one packet traverse the crossbar. To compensate for these situations, we add addition logic after the switch allocation to detect if a packet conﬂict arises. Figure 3(b) shows the logic used to evaluate and detect a conﬂict between the two inputs. From the ﬁgure, the conﬂict detection logic is divided into two different stages. In the ﬁrst stage, conﬂict detection takes place by having the two selected output ports from the two inputs enter the detection logic circuitry. After the detection logic, the signal will be an input for four multiplexors which will select the correction conﬂict free combination. The single crossbar design has more overhead; power as well as latency for additional logic. However, single crossbar design with dual input can provide consistently better performance and different routing algorithms can be easily implemented due to full connectivity. B. Dual Crossbar Organization In this organization as shown in Figure 4(a), we split the monolithic crossbar into two, each with smaller number of output ports. This proposed dual crossbar has been well researched in several architectures [6], [15], [16]. The dual 2 × 2 crossbar used in RoCo is aligned along x and y dimensions, thereby reducing the area and power consumption. Another high-radix router [15] has similar functionality with the dualinput port feeding into two separate crossbars. The dual crossbar organization shown here is slightly different from the previous work as we have a single register connected to the crossbars. This makes the VC allocation more restrictive with the direction in which we expect the packet to turn. For example, with dimension order routing (DOR), the lower VC will be always allocated to x direction until there are more hops in the x direction. At the turn router (from x to y), the higher VC should be allocated. Once the turn is completed, lower VC should be allocated. With 2 VC organization such as dual channel (dc), the number of VCs are limited which cannot support minimal or fully adaptive networks. The other two organizations, dcM and scM will be able to leverage additional VCs to support adaptive routing topologies with some restrictions. The dual crossbar organization reduces the power consumption and area overhead while delivering performance proportional to the dual input crossbar. Due to the single register storage, this design limits the VC allocation during turns. C. Multi Crossbar Organization Figure 4(b) shows the multi-crossbar organization which splits the crossbar into 4 smaller crossbars to reduce area and power consumption. The division of the 4 crossbars are along the 4 quadrants: (+x, +y) [North-East], (-x, -y) 222  Router  (RC)   Virtual Channel   (VC)   Switch Allocator   (SA)   Router  (RC)   Virtual Channel   (VC)   Switch Allocator   (SA)  + x  - x  + y  - y  Reg  Reg  Reg  Reg  Reg  Reg  Reg  Reg  I0  I1  I2  I3  I4  I0’  I1’  I2’  I3’  I4’  O0   O1  O4  O2  O3  O4  + x  - x  + y  - y  + x  - x  + y  - y  Reg  Reg  Reg  Reg  Reg  Reg  Reg  Reg  I0  I2  I1  I3  I1’  I2’  I0’  I3’  (cid:3)+x, +y  (cid:3)-x, -y  (cid:3)-x, +y  (cid:3)+x, -y  + x  O0   - x  O1  + y  O2  - y  O3  O4  Processing Element (PE)  Processing Element (PE)  (a)  (b)  Fig. 4. (a) Dual Crossbar (dx) organization and (b) Multi Crossbar (mx) Organization. (cid:2) [South-West], (-x, +y) [North-West] and (+x, -y) [SouthEast]. We adaptively route the packet on the quadrant which hosts the destination, assuming the source is located at the origin. Suppose, the packet arrives from +x direction into I0 , indicating that the quadrant is (x+, y+). This packet can be routed to either O0 (+x direction) or O2 (+y direction) using the North-East crossbar. Similarly, if the packet arrives from +x direction from I 0 direction into the South-East crossbar, then the possible outgoing directions will be O0 and O3 , indicating that the destination quadrant is (x+, y-). Therefore, by limiting the crossbar connections and combining select crossbar outputs, we adaptively provide more opportunities for the output ports to be occupied than a conventional crossbar. The VC allocation is more ﬂexible than the previous approach. The VC allocation is based on how many hops away the packet is from the destination. If the packet is more than one hop away from the destination in either dimensions, then the packet can be allocated to either VC. If the packet is exactly one hop away from the destination in a particular dimension, then always the lower VC should be allocated. With this simple restriction, we can use both the VCs and connect using different crossbars to get to the same direction. The multi-crossbar conﬁguration provides the best of the three worlds - lower area due to split crossbars, lower power dissipation due to shorter path lengths and higher throughput due to selective merging of different output ports. V. PER FORMANCE EVALUAT ION In this section, we evaluate our proposed channel buffer and router crossbar organizations in terms of power dissipation, area overhead and overall network performance and compare to a baseline VC router. We consider each router with a 4-stage router pipeline (baseline and all proposed approaches) as discussed before. Each router has P = 5 input ports (4 for each cardinal direction; North, South, East and West and 1 for the PE). For a fair comparison, we consider two baseline designs with 2 VCs and 4 VCs per input port with each VC having 4 ﬂit buffers in the router for a total of 40 and 80 ﬂit buffers respectively. Each packet consists of 4 ﬂits where each ﬂit is 128 bits for a total of 512 bits per packet. Every combination of channel buffer and crossbar organization was synthesized and optimized using the Synopsys Design Compiler tool using the TSMC 65 nm technology library. The power dissipation and the area in the links and the routers are obtained for each case at a nominal supply voltage of 1.0 V and an operating frequency of 2 GH z. A. Power, Timing and Area Estimation The power per segment of the repeater-inserted link is given by, Psegment = Pd ynamic + Pl eakage + Pshort−ckt where Pd ynamic is the switching power, Pl eakage is the power due to the subthreshold leakage current and Pshort−ckt is the power due to the short-circuit current. Power is also dissipated in the control blocks controlling the dual-function repeater stages, when they are enabled during congestion. In calculating the power values, the inter-router links are assumed to be 1 mm long for the mesh network. The buffer organizations considered are (1) dual channel (dc), (2) dual channel multiinput (dcM) and (3) single channel multi-input (scM); and the crossbar organizations considered are (1) dual-input single crossbar (dsx), (2) dual crossbar (dx) and (3) multiple crossbar (mx). Therefore this provides us with 9 different architectures with different naming conventions, (Eg. dc-dx implies dual channel with dual crossbar) and is compared to the baseline which is the 2 VC router. This keeps the number of buffers the same across different designs. Table 1 shows the power and area overhead of each router design in 65 nm technology. As Figure 5 shows, the majority of the power consumption is in the links. This power is equal in all designs due to the ﬁxed wire length of 1 mm. The baseline input buffers were implemented with 128-bit FIFO registers that were found to have a power of 2.78 mW using Synopsys. Overall, the channel buffers consumed about 40% less power because of the low power three-stage repeaters which were found to have a power of 0.1325 mW each. This difference in power, shown as registers (reg) in Figure 5, is the cause of the large power savings of the channel buffer designs. The dc design with the mx crossbar showed the best reduction at 39.1% compared to the baseline, where as the scM with the dsx crossbar had the least power reduction at 25.1%. The small difference in power between the different channel buffer designs was due to the different number of multiplexers and demultiplexers used. For the crossbars, the power values calculated by Synopsys were lower for the mx crossbar because the total distance for a ﬂit to travel is smaller in the mx compared to the larger dx and dsx crossbars. The large savings in power allowed the channel buffers to have more ﬂexibility with the crossbars while maintaining a signiﬁcantly lower overall power compared to the baseline. The latency for the baseline, dc, dcM, and scM designs was found to be 0.47 ns, 0.37 ns, 0.44 ns, and 0.46 ns, respectively. These latencies which were due to the buffering and all were within our speciﬁed clock period of 0.50 ns. The small differences in the critical paths of the channel buffer 223 ) W m ( r e w o P 80 70 60 50 40 30 20 10 0 Baseline scM-dsx dcM-dsx dc-dsx scM-dx dcM-dx dc-dx scM-mx dcM-mx dc-mx Link Crossbar Reg Control Block Demux Mux TABLE I P OW E R AND A R EA E S T IMAT I ON U S I NG S YNO P S Y S D E S I GN COM P I L E R F O R 6 5 NM T E CHNO LOGY NOD E AT 1 . 0 V AND 2 G H Z C LO CK . Design Baseline dc-dsx dc-dx dc-mx dcM-dsx dcM-dx dcM-mx scM-dsx scM-dx scM-mx Power (mW) Buf + xbar 61.32 + 13.56 39.63 + 16.10 39.63 + 8.19 39.63 + 5.95 39.71 + 16.10 39.71 + 8.19 39.71 + 5.95 39.81 + 16.10 39.81 + 8.19 39.81 + 5.95 % Change -25 -35 -39 -25 -35 -39 -25 -34 -38 Total Area (mm2 ) Buf + xbar 0.248 + 0.0356 0.272 + 0.0471 0.272 + 0.0246 0.272 + 0.0237 0.274 + 0.0471 0.274 + 0.0246 0.274 + 0.0237 0.274 + 0.0471 0.274 + 0.0246 0.274 + 0.0237 % Change +12 +4 +4 +13 +5 +5 +13 +5 +5 Fig. 5. Dynamic power breakdown for different design choices. was the largest. designs was due to the different number of repeaters, demultipexers and multiplexers that a ﬂit had to travel through in each design. The latency of four three-stage repeaters was found to be 0.20 ns and the latency of the demultipexer and multiplexers was found to be 0.08 ns each. Additionally, the latency for the baseline, dx, and mx crossbars alone were 0.35 ns, 0.39 ns, and 0.39 ns respectively. These were due to the critical path of the logic in the VA stage. The latency for the dsx crossbar was larger at 0.47 ns due to the SA stage. The latency for the dsx crossbar was largest at 0.47 ns due to the extra logic needed to switch the vc input ﬂits. Area overhead of the baseline vc2 router obtained from Synopsys is 0.283 mm2 which includes the buffer and crossbar. All proposed designs occupy slightly more area compared to the baseline due to the increase in link width. The total area for each channel buffers design is due to the wires, registers, and control blocks because the repeaters and wires use different metal layers [17], [18]. For area optimization of the channel buffers, the link will not be split into separate channels or inputs until the end of the link. This optimization causes the wire to remain a single 128-bit wire for most of the link. However, an increases in the number of repeaters on the link will occur. This will slightly add to the overall power but allows a signiﬁcant reduction in area. The dc was assumed to be a single 128-bit wire for 0.5 mm then split into two parallel channels for the remaining 0.5 mm causing the total wire length be 1.5 mm. Similarly, the dcM and scM were assumed to be single 128-bit wire for the ﬁrst 0.875 mm. The lengths were determined in order to offer the best area optimization while also limiting the additional power added by the repeaters. In the dual channel buffer, the two registers and control blocks on the two channels reduced the area overhead. The combination of this channel buffer and the mx crossbar had the least area overhead of only 0.295 mm2 . The smaller 2 × 3 and 3 × 2 crossbars in the mx crossbar results in a lower area for all channel buffer designs. The multiple inputs in the dcM along with the size of the dsx crossbar resulted in an area of 0.322 mm2 , which B. Simulation Methodology A cycle-accurate on-chip network simulator was used to and router crossbar designs in a 8 × 8 mesh network. We conduct a detailed evaluation of the proposed channel buffer consider 5 designs out of 9 as they represent the best design choices: dc-dx, dc-mx, dcM-mx, dc-dsx and scM-mx. The proposed designs were compared to a 2 VC and 4 VC router buffer with a standard 5 × 5 crossbar. The network load is varied from 0.1-0.9 of the network capacity. The simulator was warmed up under load without taking measurements until steady state was reached. Then a sample of injected packets were labelled during a measurement interval. The simulation was allowed to run until all the labelled packets reached their destinations. All designs were tested with different synthetic trafﬁc traces such as (1) Uniform Random, where each node randomly selects its destinations with equal probability, (2) Permutation Patterns, where each node selects a ﬁxed destination based on the permutations and (3) PARSEC [13] and SPEC2006 benchmark traces collected using SIMICS simulator with GEMS enabled [19]. For permutation trafﬁc, we evaluated the performance on: Bit-Reversal, Butterﬂy, Matrix Transpose, Complement and Perfect Shufﬂe. We consider six PARSEC applications with medium inputs (blackscholes, facesim, ﬂuidanimate, freqmin, streamcluster, ferret and swaptions) and two workloads from SPEC2006 (bzip and hmmer). For collecting the traces, we assumed a 2 cycle latency to access the L1 cache (64KB, 4-way), a 4 cycle latency to access the L2 cache (4MB, 16way, MOESI cache coherence protocol), and a 160 cycle latency to access the main memory (16 memory controllers, 4 GB main memory). C. Simulation Results and Discussion Figure 6(a) shows the throughput plot for UR trafﬁc. From the ﬁgure, dcM-mx (dual channel multi-input with multiple crossbars) is the best performing network with a saturation throughput of about 0.37 or a 15% improvement over the baseline VC2. This results from the dual input of dcM where multiple ﬂits from the same input port can traverse to separate output ports. In addition, there are four potential ﬂits 224     that are available to traverse the crossbar instead of only two ﬂits found in the VC2 design. Also dcM slightly outperforms the baseline VC4 design, where VC4 has two times more buffer space. The increase in performance is due to the dualinput nature of dcM as both networks have the same number of ﬂits available (4 ﬂits) to traversal the crossbar. scM, dsx, and dc network designs have a saturation throughput of about 0.35 and have a performance improvement of about 10% over VC2 due to the dual inputs found in each router design. Lastly, dx has the least increase in performance over VC2 with a 6% improvement in performance. This reduction in overall performance over the other designs is due to the restricted dual input crossbar found in dx. In dx, two ﬂits can traverse the crossbars from the same input if the two ﬂits are required to traverse to two different crossbars. Figure 6(b) shows the latency plot for UR trafﬁc. From the ﬁgure, dcM has the lowest zero load latency of about 34 clock cycles followed by ScM with a latency of 39 clock cycles. Figure 6(c) shows the throughput plot for complement (CP) trafﬁc. From the ﬁgure, both dcM and dc are able to signiﬁcantly outperform VC2 with an improvement of about 25% and have similar saturation throughput of VC4. This large increase in performance is mainly due to the restrictive natural of the VC allocation found in the proposed networks. In the baseline case (VC2 and VC4), ﬂits are free to occupy any VC, therefore for complement trafﬁc as more packets travel in the same direction, they see more contention. In the proposed crossbar designs, restrictive VC allocation reduces the contention as they can occupy VCs in both directions, thereby relieving congestion and increasing throughput. dsx and dx have about the same saturation throughput as VC2 because both designs do not use the restricted VC allocation found in dcM and dc designs. Between dsx and dx, dsx is able to slightly outperform dx as dx has no restriction for two ﬂits from the same input port wanting to traverse to two different output port. Figure 6(d) shows the latency plot for CP trafﬁc. From the ﬁgure, dcM has the lowest zero load latency of about 35 clock cycles followed by dc with a latency of 36 cycles. Figure 7 shows the saturation throughput for all trafﬁc traces. From the ﬁgure, at least one of our proposed router design is able to out perform both the VC2 and VC4 router design. For Matrix Transpose (MT) trafﬁc, the propose networks dc, scM, and dcM perform the worst. This is due to the restriction in VC allocation causing ﬂits to be stalled in a upstream router which greatly reduces the performance. The best performing networks are dsx and dx. dsx and dx are able to outperform VC2 by about 5% because the dual input crossbars allow for an increase in throughput as more output ports are occupied. For NUR trafﬁc both dcM and scM as the highest throughput and outperforms VC2 by 12%. For BR trafﬁc, dsx is able to outperform V2 by about 5% and dx has the same saturation throughput as VC4. As for perfect-shufﬂe trafﬁc, both dcM and dc have about a 15% improvement in performance over VC2 and about 10% improvement in performance over VC4. PARSEC and SPEC2006 Results: Figure 8 shows the exe0.25 0.27 0.29 0.31 0.33 0.35 0.37 0.39 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 h T r u p h g u o t Offered Load  vc2 vc4 dc_dx dc_mx dcM_mx dc_dsx scM_mx (a)  20 0.28 40 60 80 100 120 140 0.3 0.32 0.34 0.36 0.38 0.4 a L t n e y c c y c ( l e ) s Offered Load  vc2 vc3 dc_dx dc_mx (b)  dcM_mx dc_dsx scM_mx 0.15 0.17 0.19 0.21 t 0.23 0.25 0.27 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 h T r u p h g u o Offered Load  vc2 vc4 dc_dx dc_mx (c)  dcM_mx dc_dsx scM_mx 20 0.18 40 60 80 100 120 140 0.19 0.2 0.21 0.22 0.23 0.24 0.25 a L t n e y c c y c ( l e ) s Offered Load  vc2 vc4 dc_dx dc_mx (d)  dcM_mx dc_dsx scM_mx Fig. 6. Throughput and latency for different design for (a)(b) Uniform Trafﬁc and (c)(d) Complement Trafﬁc. cution time speed-up when normalized to VC2 conﬁguration. The majority of PARSEC benchmarks (blackscholes, facesim, ﬂuidanimate, ferret and swaptions) show performance improvement of 10-12% speed-up when compared to VC2 baseline. It should be noted that the performance jump obtained from the real benchmarks is equivalent and in some cases even more than a VC4 conﬁguration. This clearly shows that with half the number of buffers (and virtual channels) and smaller crossbars, we can obtain the performance equivalent to what can be obtained with twice the number of buffers. For SPEC2006 benchmarks, the performance jump from most of the combinations is above 10% and outperforms the baseline VC2. Clearly, the combined 225           t u p h g u o r h T n o i t a r u t a S 1.3 1.2 1.1 1 0.9 0.8 0.7 0.6 Uniform Non-Uniform Bit-complement Buffterfly Complement Matrix-transpose Perfect-shuffle vc2 vc4 dc_dx dc_mx dcM_mx dc_dsx scM_mx Fig. 7. Throughput at an offered load = 0.5 for all synthetic traces 1.15 1.1 1.05 p u 1 d e e p S 0.95 0.9 0.85 blackshore facesim ferret fluidanimate freqmin streamcuster swaption bzip hmmer VC2 dc_dx dc_dsx VC4 dc_mx scM_mx dcM_mx Fig. 8. PARSEC and SPEC2006 speed-up when normalized to the execution of vc2 router design. effects of channel buffer organizations and crossbar designs improve the performance for both synthetic as well as real applications. V I . CONCLU S ION In this paper, we evaluated different organizations of channel buffers and crossbars with the twin objectives of reducing power dissipation while improving performance at the cost of slight area increase. Our best designs show power savings of 39% while improving performance from 10-20% at the cost of 4-13% area overhead. The dual channel design combined with multiple crossbar organization showed that we can achieve high throughput and minimize power while expending some area. The single crossbar design consumes more area and power while yielding better performance across all trafﬁc patterns. Our dual link designs reduce the HoL blocking of traditional channel buffers and increase throughput with restrictive VC allocation with multiple crossbars. Our results conclude that it is possible to improve performance of channel buffers with some area overhead while saving substantial power when compared to the same number of VC router buffer based NoC architecture. Acknowledgement: This research was partially supported by NSF awards, CCF-0915418, CCF-1054339 (CAREER), ECCS- 1129010, CCF-0953398 and ECCS-0725765. "
2011,Application-aware deadlock-free oblivious routing based on extended turn-model.,"Programmable hardware is gaining popularity as it can keep pace with growing performance demand in tight power budget, design and test cost, and serious reliability concerns of future multiprocessor embedded systems. Compatible with this trend, Network-on-Chip, as a potential bottleneck of future multi-cores, should also support programmability. Here, we address this issue in design and implementation of routing algorithm for two-dimensional mesh. To this end, we allocate paths based on input traffic pattern and in parallel with customizing routing restriction for deadlock freedom. To achieve this, we propose extended turn model (ETM), a novel parametric deadlock-free routing for 2D meshes that generalize prior turn-based routing methods (e.g., odd-even) with great degree of freedoms. This model facilitates design of Mixed-Integer Linear Programming (MILP) approach, which considers channel dependency turns as independent variables and decides for both path allocation and routing restriction. We solve this problem by genetic algorithm and evaluate it using simulation experiments. Results reveal that application-aware ETM-based path allocation outperforms prior turn-based approaches under synthetic and real traffic loads.","Application-Aware Deadlock-Free Oblivious Routing Based On Extended Turn-Model Ali Shaﬁee, Mahdy Zolghadr, Mohammad Arjomand, and Hamid Sarbazi-azad CE Department, Sharif University of Technology, Tehran, Iran. CS School, Institute for Researches in Fundamental Sciences, Tehran, Iran. Email: {a shaﬁei, m zolghadr, arjomand}@ce.sharif.edu, azad@sharif.edu Abstract—Programmable hardware is gaining popularity as it can keep pace with growing performance demand in tight power budget, design and test cost, and serious reliability concerns of future multiprocessor embedded systems. Compatible with this trend, Network-on-Chip, as a potential bottleneck of future multi-cores, should also support programmability. Here, we address this issue in design and implementation of routing algorithm for two-dimensional mesh. To this end, we allocate paths based on input trafﬁc pattern and in parallel with customizing routing restriction for deadlock freedom. To achieve this, we propose extended turn model (ETM), a novel parametric deadlock-free routing for 2D meshes that generalize prior turn-based routing methods (e.g., odd-even) with great degree of freedoms. This model facilitates design of Mixed-Integer Linear Programming (MILP) approach, which considers channel dependency turns as independent variables and decides for both path allocation and routing restriction. We solve this problem by genetic algorithm and evaluate it using simulation experiments. Results reveal that application-aware ETM-based path allocation outperforms prior turn-based approaches under synthetic and real trafﬁc loads. I . IN TRODUC T ION System-on-chip (SoC) designers face many challenges such as rapid evolution of computational complexity, exponential increase in veriﬁcation and test cost, serious reliability concerns, and tight restrictions in power budget. Furthermore, providing support for runtime adaptation, in addition to design-time challenges, can greatly save power and increase user satisfaction [1][2]. Such challenges arise the need for programmability enabling architecture to customize for applications and situations. To this end, researchers have proposed extensible processors [3] and smart memory structures [4] as well as integrating FPGAs for future embedded processors [5]. Compatible with this trend, Network-on-Chip (NoC), as a potential bottleneck of future multi-cores, should also support programmability. For this, researchers have suggested NoCs with programmability realized in different parts of the network such as topology [6] and routing layer [7]. In term of implementation cost, programmability is better adopted by routing layer for popular topologies such as 2D meshes with path diversity in inter-core communication. Programmable routing layer efﬁciently utilizes network resources by smart allocation of routing paths and storing them in programmable routing tables. In this work, we focus on a programmable routing layer for the 2D meshes and address its design issues. Speciﬁcally, we propose a deadlock-free oblivious routing algorithm to evenly distribute the trafﬁc load. Oblivious routing algorithms are still desirable as they support in-order packet delivery and bandwidth guarantee while simplifying router implementation and delay modeling. For deadlock avoidance, we propose extended turn model (ETM), a novel family of routing restriction algorithms, that generalizes prior turn-based approaches (i.e., the turn model [8] and odd-even [9]). ETM offers a large number of deadlock-free routing restrictions, represented with two independent parameters per mesh column (see Section IV). Similar to other turn-based restriction, ETM prohibits a quarter of turns and provides deadlock-free restrictions without relying on virtual channels or violating connectivity. Such a parametric design space, gives the chance to optimize NoCs by tuning these parameters for applications with long-running predictable trafﬁc patterns. Furthermore, ETM improves prior path allocation problem formulations. Speciﬁcally, a prior application-speciﬁc oblivious routing scheme allocates paths over acyclic channel dependency graph to ensure deadlock-freedom. Such an approach is translated to a Mixed Integer Linear Programming (MILP) path allocation method over a acyclic channel dependency graph [10] rather than the original topology graph. This approach increases linearly in term of execution time, considering the number of routing restrictions as the underlying acyclic channel dependency graph. Based on ETM and for 2D mesh, however, we offer a MILP approach for path allocation, which considers channel dependency turns status (prohibited or permitted) as independent Boolean variables and decides for both path allocation and routing restriction in parallel. Considering the N P -hard property of such a problem, we also present a genetic algorithm based solution for design space exploration. To sum up, this paper offers the following main contributions: • We introduce ETM, a general framework for deadlock-free routing restrictions based on turn prohibition. ETM provides a large number of such restrictions including previously suggested turn-based restrictions [8][9]. • We adopt ETM for application-aware routing and present a MILP approach considering both path selection and turn prohibition at the same time. To ﬁnd an efﬁcient solution, we also offer a genetic algorithm. Experiments conﬁrm that extracted solutions outperform prior application-speciﬁc oblivious routing methods [10] in many cases of synthetic and real trafﬁc loads. The rest of the paper is organized as follows. In the next section, we review related work, and prior turn model-based routing schemes are reviewed in Section III. We explain details of ETM in Section IV. In Section V, ETM is applied for designing application-speciﬁc load-balanced routing. In Section VI, we present our evaluation methodology and simulation results. Finally, Section VII concludes the paper and outlines future work in this line. I I . R ELAT ED WORK In many network topologies, including 2D mesh, there are many paths among most of communicating cores. Researchers have proposed many adaptive and oblivious routing algorithms which leverage this path diversity to optimize NoC metrics. For mesh topology, deadlock-free application-aware routings typically rely on turn model [8] and odd-even [9] routing restriction to gain performance [10], guarantee bandwidth [7] and offer resiliency [11]. Due to routing restriction customization, however, we will show that ETM-based routing outperforms such approaches in many cases. 978-1-4577-1400-9/11/$26.00 ©2011 IEEE 213 For efﬁcient resource utilization, customizing routing restriction is proposed in prior work [12][13]. Based on Duatos theory of deadlockfree routing [14], Palesi et.al. suggested Application Speciﬁc Routing Algorithm (APSRA). APSRA leverage randomized search to remove turns and achieve better adaptiveness. Segmented based routing (SR) scheme, on the other hand, reaches deadlock-free routing restriction by considering topology in turn prohibition. This method provides many independent decisions in segmentation process leading to large number of deadlock-free routing restriction. Both APSRA and SR are topology-agnostic but only SR provides supports for oblivious routing. ETM-based routings take advantage of 2D mesh and provide scalable genetic approaches for path allocation with a better heuristic (i.e., load-balancing rather than adaptiveness) for latency optimization. In our proposal, ETM also provides supports for both adaptive and oblivious routing. Furthermore, ETM-based restriction can be easily change in run-time and capture dynamic changes in trafﬁc pattern. In addition to customizing routing restriction, resource ordering is also used to prevent deadlock. Such approach is typically realized using virtual channel (VC) splitting or ordering [15][16]. Static VC allocation, assign VC to each ﬂow relying on two or more VCs to avoid deadlock [17]. Based on physical and virtual channel splitting, Seiculescu et.al. suggested a method to avoid deadlock. In contrast to turn prohibition, this method break cycles by adding physical and virtual channels [18]. Another technique that takes advantage of both turn prohibition and VC addition is presented in [19]. Compared to ETM, VC-based approaches are expensive as they rely on more input buffers. Moreover, the two latter methods are not programmable, as the number of VCs is not known priori. Finally, they count on routing table hence come with hardware overhead. I I I . BACKGROUND The proposed deadlock avoidance solution, ETM, is an extension of two previous techniques [8][9], which are reviewed in this section. The ﬁrst technique is the turn model, a general framework for routing restriction to prevent deadlock. Turn model prohibits one clockwise (Figure 1a left) and one counter clockwise turns (Figure 1a right) per node. Figure 1b shows West-First turn model as an example of such turn prohibitions [8]. In this ﬁgure, two turns, i.e., SW and NW, are prohibited which break east dependency cycles and settle many minimal paths for different source-destination pairs. Comparing with XY routing [20], turn model routing restrictions increase the degree of adaptiveness, but this increase is highly uneven. For example, West-First provides just one minimal path for those source-destination pairs with destination at the west of source while letting others taking advantage of minimal full adaptive routing. Another scheme is odd-even turn model, which provides adaptiveness more evenly. In this model, the prohibited turns differ depending on the column. More precisely, odd-even prohibits east-north and east-south turns in even columns and north-west south-west turns in odd columns. Figure 1c and 1d shows turn restrictions for even and odd columns, respectively. IV. EX TEND ED TURN MODE L In this section we explain Extended Turn Model (ETM). ETM generalizes the previous turn models and offers a larger family of deadlock-free restrictions. Here, without loss of generality, we assume ETM breaks the rightmost edge of dependency cycles to avoid deadlock. The prohibited turns in ETM are determined using the following steps: Fig. 1: (a) basic clockwise (left) and counter clockwise (right) turns in the turn model. (b) West-First turn model. (c-d) odd-even turn model for even (c) and odd (d) columns. (Dashed turns are prohibited). Fig. 2: Turn prohibited in (a) clockwise and (b) counter clockwise with Circles numbers showing CFNs’ and CCFNs’ positions. 1) Excluding the leftmost mesh column, two nodes called clockwise and counter clockwise free node (CFN and CCFN for short) are selected per each column. CFNs and CCFNs are nodes in which all clockwise and counter clockwise turns are permitted, respectively. CFNs’ and CCFNs’ positions are independent and assigned any number from 0 (at the bottom of the column) to n − 1 (at the top of the column) assuming m × n mesh. 2) Mark ES turns and SW turns (see Figure 1) as prohibited for all nodes above and below CFN, respectively. 3) Similarly, mark NW turns and EN turns as prohibited for those nodes above and below CCFN, respectively. Figure 2 shows one such turn restriction for a 4 × 4 mesh. In Figure 2a and 2b, CFNs’ and CCFNs’ positions are 1, 1, 3 and 1, 3, 0 respectively. Theorem 1: The mesh with prohibited turns, based on the ETM construction, is deadlock-free assuming 180◦ turns are not allowed without violating network connectivity. Deadlock-freeness. Assume otherwise and consider a deadlock case where some packets create a dependency cycle C with column R as the rightmost column of the cycle. Assume cycle C enters column R at node n1 , traverses column R through path n1 , n2 , ..., nl and leaves it at node nl . Since 180◦ turns are not allowed, n1 and nl cannot coincide each other. Let construct path P by attaching n0 (the preceding node of n1 in cycle C ) to the beginning, and nl+1 (the succeeding node of nl in cycle C ) to the end of path n1 , n2 , ..., nl . Considering path P while assuming n1 is above nl , then, two cases are possible: 1) Some nodes of P are above the CFN. Therefore, n1 is also 214 A. MILP formulation Inspired by the method in [4], we formulate the problem of ﬁnding the routing paths and prohibited turns for n × n mesh. We consider the network topology as graph G(V , E ) where V is set of nodes and E is set of directed links (u, v) each with capacity c(v , u). Assume that input F is set of ﬂow fi communicating among i-th source-destination pair (srci , dsti ) with trafﬁc rate ri . Note that, such a ﬂow from a source to a destination is not unique. We also deﬁne Boolean variable bi (u, v) that indicates whether ﬂow i passes through directed link (u, v). To represent the turns, we deﬁne Boolean variables T ES (i,j ) indicating whether ES, SW, EN, and NW turns in node (i, j ) is allowed or not, respectively. We also rely on some integer variables C F Ni and CC F Ni , representing the corresponding free nodes positions in the column i. Considering these variables, the problem should satisfy the following constraints: (i,j ) , T SW (i,j ) , T EN (i,j ) , and T NW i X X X srci=u dsti=u X X (srci ,v)∈E (u,dsti )∈E Capacity Router channels: ∀u, v ∈ E Injection channels: ∀u ∈ V Eject channels: ∀u ∈ V Flow conservation source: destination: ∀fi ∈ F ∀fi ∈ F other nodes: X bi (u, v) × ri ≤ c(u, v) ri ≤ cinject (u) ri ≤ ceject (u) bi (srci , v) = 1 bi (u, dsti ) = 1 Fig. 3: Some previous turn model restrictions with their ETM presentation. above CFN. Hence, according to construction of ETM (step 2), the turn n0n1n2 is prohibited. However, this is contradiction, since this turn belongs to dependency cycle C . 2) Some nodes of P are below CFN. So that, nl is also below CFN. According to construction of ETM (step 2), all SW turns below CFN are prohibited, including the turn nl−1nlnl+1 . However, this turn is used in cycle C leading to a contradiction. The proof is almost the same when nl is above n1 but argued based on CCFN. Connectivity: if source and destination lay on the same row or column, they are then trivially connected. Otherwise, there will be a sub-mesh of minimal paths containing at least two paths determined using XY and YX routing. Note that either XY or YX path contains none of the four potentially prohibited turns (i.e., ES, SW, EN, and NW). Therefore, such a path guarantees connectivity. It is clear that ETM contains many deadlock-free routing restrictions including the turn model and odd-even ones. For n × n mesh, any member of ETM is presented as two ordered (n − 1)-tuples for CFNs’ and CCFNs positions. In the ordered (n − 1)-tuple associated with CFN (CCFN), the i-th coordinate denotes CFNs (CCFNs) of column i position 1 . Figure 3 shows ETM presentation of some wellknown turn model restrictions. Based on this presentation, ETM is now including n2(n−1) routing restriction for n × n mesh, as every coordinate of CFNs and CCFNs are independently selected as an integer numbers from 0 and n − 1. V. A P P L ICAT ION -S PEC I FIC ROUT ING As previously explained, ETM provides a large number of deadlock-free routing restrictions. In this section, we explore this large space for a more balanced application speciﬁc routing algorithm. We ﬁrst offer a MILP approach for path allocation and turn prohibition problem in Section V-A. However, this is an N P hard problem [28] and the time needed to solve it grows with its complexity (i.e., number of variables and constraints). To tackle this issue, we utilize a Genetic Algorithm (GA) to offer a fast approximate solution for path allocation and turn prohibition by calculating CFNs’ and CCFNs’ positions (Section V-B). 1Considering column 0 as the leftmost one. (1) (2) (3) (4) (5) (6) (7) Where cinject (u) and ceject (u) represent capacity of injection and ejection channels in node u, respectively. ∀fi ∈ F v /∈ {srci , dsti } X Hop count (u,v)∈E ∀fi ∈ F bi (u, v) = X bi (v , z ) (v,z)∈E bi (u, v) ≤ hopi (u,v)∈E Where hopi is the maximum number of hops allowed for packets of ﬂow fi . According to [10], following the above constraints leads to unsplit paths between source-destination pairs. In order to satisfy deadlockfreedom based on ETM, we further introduce the following constraints: Prohibiting 180◦ -turn prohibition ∀fi ∈ F ∀x ∈ [1, n − 1] ∀y ∈ [0, n − 1] bi ((x − 1, y), (x, y)) + bi ((x, y), (x − 1, y)) ≤ 1 (8) Using eligible turns The constraint for ES turns is formulated as follows. The case for SW, EN, and NW turns are considered almost similar. 215 ∀fi ∈ F ∀x ∈ [1, n − 1] ∀y ∈ [0, n − 2] bi ((x − 1, y), (x, y)) + bi ((x, y), (x, y + 1)) ≤ 1 + T ES (x,y) (9) Turn prohibition T ES (x,y) must satisfy the following condition. T ES (x,y) = if y > C F Nx if y ≤ C F Nx (cid:26) 0 1 To achieve this, we consider the two following constraints with n indicating mesh height. For variables of the other turns, the constraints are almost similar. (C F Nx − y) − (n × T ES (y − C F Nx ) − n × (1 − T ES (x,y) ) < 0 (x,y) ) ≤ 0 (10) (11) Maximum load To ﬁnd the maximum load we need an auxiliary variable l with the following constraints: Router channels: X ri × bi (u, v) ≤ l ∀u, v ∈ E Injection channels: Ejection channels: ∀u ∈ V ∀u ∈ V i X X srci=u srci=u ri ≤ l ri ≤ l (12) (13) (14) Considering all the above constraints, then the optimization object will be: minimize l (15) Equations (8)-(10) discriminate our approach from prior deadlockfree MILP formulation. Speciﬁcally, Kinsy et al. proposed formulating path allocation problem over acyclic Channel Dependency Graph (CDG) to ensure deadlock-freedom. In CDG, every vertex represents an edge in the topology graph and there is a directed edge between two vertices if they represent a pair of arriving-departing edges on the same node in the topology graph. Typically, acyclic CDGs of a 2D mesh are larger than the original topology graph. Therefore, our approach, which is based on topology graph, will have a simpler MILP representation. B. Genetic Algorithm Genetic Algorithm (GA) is a fast parallel search heuristic which relies on the process of natural selection. GA starts with construction of an initial generation, which is a population of candidate solutions represented as chromosomes. Then, based on this (current) generation, it produces the next generation in two phases. First, in order to expand the current generation, GA applies crossover on some randomly selected chromosome pairs or mutates some random ones. Second, it selects bests of the current generation based on a ﬁtness function to produce the next generation. This process continues generation after generation unless it satisﬁes the termination condition. The solution is the best of the last generation. To reduce the N P -hard complexity of the previous path selection algorithm, we use Genetic Algorithm for heuristic design space exploration. Details of this algorithm are as follows. Fig. 4: Breakdown of outcome events for 1000 different random task mappings. GN sat(TM sat) stands for the case that only genetic solution (turn model solution) saturates. Furthermore, GM>TM means that network didn’t saturate for none the routing algorithms but genetic solution lead to greater average message delay. Chromosome presentation: Regarding presentation offered in Section III for each ETM routing restriction, we consider each chromosome as a sequence of length 2(n − 1) of integer numbers from 0 to n − 1. Initial generation: We construct the initial generation by randomly producing each chromosome. Moreover, we add some special chromosomes representing previous turn models such as Odd-Even and West-First. Crossover: We prefer uniform crossover, which typically produces better results comparing with one-point and two-point crossovers [24]. In uniform crossover, each offspring bit is generated by random selection between the two corresponding bits in parent chromosomes. Mutation: GA, randomly selects one position in the victim chromosome, and then changes its value. To escape potential local optimum, the mutation probability increases linearly when the best solutions of consecutive generations show no improvement [25]. Fitness function: Similar to [10], we use weighted Dijkstras shortest path algorithm as ﬁtness objective. To further optimize it, we add a reﬁnement phase triggered after all paths are allocated. In this phase, we repeatedly select on path from most congested links and try to ﬁnd a new path for it. This process is repeated for a speciﬁc number of iterations. Termination condition: GA stops when it cannot improve the best chromosomes after a rather large number of generations. In our simulation, GA is terminated after twenty consecutive generations with no improvement. V I . M ETHODO LOGY AND R E SU LT S We evaluate ETM oblivious routing through simulation for both synthetic and real trafﬁc patterns (i.e., known video and audio benchmarks including VOPD [21], MWD [22], MP3, HDEC, and HENC [7]). We compare ETM-based routing derived from GA with the algorithm proposed in [10] which relies on prior turn model routing schemes (e.g., odd-even, West-First, negative-ﬁrst, etc.) and dimension-order routing. In the case of turn model routing, either ETM or conventional routing, we narrow our simulation for those turns that break dependency cycles in the rightmost edge (e.g., WestFirst and odd-even). The results are reported in terms of delay, average throughput, highest minimum acceptance rate (for fairness), and jitter. We report 216 TABLE I: Average throughput, highest minimum acceptance rate and jitter for different routings under synthetic trafﬁc patterns: BC(Bit Complement), BR(Bit Reverse), BF(Butterﬂy), SH(Shufﬂe), NG(Neighbor), UN(Uniform), TRNS(Transpose), and TR(Tornado) Pattern BC BR BF SH NG UN TRNS TR Average Minimum Throughput Throughput (ﬂt/cyc/node) (ﬂt/cyc/node) Genetic Algorithm 0.0708 0.1102 0.1975 0.1412 0.5714 0.1260 0.1362 0.0832 0.0817 0.119 0.2082 0.1586 0.5712 0.1280 0.1533 0.0934 Jitter (cycles) 194.31 56.73 115.65 714.60 153.42 11523. 292.38 528.43 Average Minimum Throughput Throughput (ﬂt/cyc/node) (ﬂt/cyc/node) Conventional Turn Model 0.0570 0.0645 0.117 0.0934 0.1910 0.12 0.1539 0.116 0.4623 0.1142 0.1372 0.1328 0.1312 0.0730 0.0800 0.0641 Jitter (cycles) 1173.9 536.747 1217.1 946.819 1986.43 9064.8 1679.22 1979.13 Average Minimum Throughput Throughput Jitter (ﬂt/cyc/node) (ﬂt/cyc/node) (cycles) Dimension-Ordered Routing 0.1112 0.102 11.3808 0.0950 0.0730 1934.3 0.1756 0.1206 1774.65 0.1371 0.1158 1526.79 0.5712 0.5714 153.425 0.1557 0.1515 263.67 0.1198 0.0721 1860.15 0.0995 0.0997 17.1022 sX i jitter to represent the variation in end-to-end delay and the quality of node-to-node communication in higher level design. It is desirable to have low jitter for better simplifying network interface design and better abstract node-to-node communication in high level system modeling. To quantify jitter, we rely on the following equation. J itter = 1 |F | × V ari (16) In this equation, |F | and V ari indicate number of communication ﬂow and the variance in i-th communication ﬂow delay, respectively. We carry our simulations using 8 × 8 and 4 × 4 mesh for synthetic and real trafﬁc patterns. When simulating real trafﬁcs, communication cores and hence network size is up to 16 tiles. Evaluated router conﬁguration is a 4-stage with no virtual channels and four ﬂits input buffer capacity which is also the packet size. Figure 5 depicts latency curve for eight famous synthetic trafﬁc patterns [26][27]. These ﬁgures, in most of the cases, conﬁrm that ETM-based routing outperforms both dimension-ordered routing and the best of conventional turn-based solutions. In some cases that dimension-ordered routing exhibits the best result, ETM-based solution still handle the trafﬁc better than conventional turn-based routings. Uniform trafﬁc is only the case which genetic algorithm fails ﬁnding a better solution comparing with prior turn-based routing. This is due to a large number communication ﬂow intensifying the contribution of network contention in average message latency. However, the metric to rank chromosome in presented genetic algorithm approach is based on maximum channel load (i.e., congestion-based metric) to simplify and expedite the algorithm. Table I offers near-saturation average throughput, highest minimum acceptance rate, and jitter near ETM-based routings saturation for ETM-based, the best conventional turn-based, and dimension-ordered routing. Relying on these results, ETM-based approach outperforms conventional turn-based routing in term of average throughput by up to 43.3% (for bit complement) and 13.44%, on average. For minimum acceptance rate, this improvement is up to 4x (for neighbor trafﬁc) and about 78.14%, on average, comparing with conventional turn-based solutions. Finally, results reveal 6.43x reduction in jitter on average and up to 12.94x in the best case (i.e., neighbor trafﬁc). Exceptionally, for the case of uniform trafﬁc, ETM-based solution reduces average throughput, the highest minimum acceptance rate, and jitter by about 6.69%, 5.13%, and 21.3%, respectively. Comparing with dimension-ordered routing, ETM-based approach outperforms in case of ﬁve synthetic trafﬁc patterns while degrading performance and fairness on the other three cases (i.e., bit complement, tornado, and uniform). On average, measured throughput is increased by about 4.63%, the highest minimum acceptance rate reduces by about 3.33%, and jitter reduces by more than 7x. We compare ETM and other turn based restriction in terms of latency and jitter in high trafﬁc rates. For each real trafﬁc pattern, we carry the comparison for 1000 randomly selected task mapping. This helps evaluating our heuristic solution for the case that mapping fails to localized trafﬁc due to IP cores heterogeneity or dynamic mapping [7]. We scale ﬂow bandwidth requirement such that maximum link load for ETM-based routing reaches 0.5 ﬂit/cycle. This scaling can be translated to changing ﬂit size, hence in scaling trafﬁc rates, in practice. Figure 4 shows breakdown of possible outcomes for 1000 random mappings. Since we set the maximum load high, both of ETM-based and conventional routing in many cases saturate (e.g., more than 40% in VOPD benchmark). Furthermore, studied benchmarks have a few high-rate communication ﬂows, ETM-based and conventional approach select almost the same paths in many cases. However, ETM-based routing outperforms conventional turnbased approach for most trafﬁc patterns. For such cases, ETM-based routing latency improvement is 31.8%, 11.4%, 51.9%, 123.7%, and 77.1% for MP3, HDEC, HENC, MWD, and VOPD, respectively (not shown in the ﬁgure); while ETM-based routing reduces jitter by 1.65x, 26%, 2.42x, 4.77x, and 2.06x MP3, HDEC, HENC, MWD, and VOPD, respectively. V I I . CONC LU S ION AND FU TUR E WORK We have introduced ETM, a novel family of deadlock-free turnbased routing. Leveraging this new family, we then customize oblivious deadlock-free routing. Besides, an MILP approach is presented to take care of turn prohibition and path assignment simultaneously. As for future work, it is possible to explore dynamic changing of ETMbased restriction in run-time through changing CFNs and CCFNs up or down the mesh columns. "
2011,Exploring heterogeneous NoC design space.,,"Exploring Heterogeneous NoC Design Space Hui Zhao, Mahmut Kandemir, Wei Ding, Mary Jane Irwin Department of Computer Science and Engineering, The Pennsylvania State University. { hzz105, kandemir, wzd109, mji}@cse.psu.edu Abstract—The Network-on-Chip (NoC) plays a crucial role in designing low cost chip multiprocessors (CMPs) as the number of cores on a chip keeps increasing. However, buffers in NoC routers increase the cost of CMPs in terms of both area and power. Recently, bufferless routers have been proposed to reduce such costs by removing buffers from the routers. However, bufferless routers can provide competitive performance only when network utilization is moderate. In this paper, we propose a novel heterogeneous design that employs both buffered and bufferless routers in the same NoC to achieve high performance at low cost. We evaluate a variety of plans to place buffered and bufferless routers in an NoC based CMP according to performance requirements and power allowances. In order to take full advantage of these heterogeneous NoCs, we also propose novel strategies for buffered-router-aware application thread mapping and a routing algorithm (once the router placement is ﬁxed). Our evaluations show that, by utilizing the techniques we proposed, a heterogeneous NoC does not only achieve performance comparable to that of the NoCs with buffered routers but also reduces buffer costs and energy consumption. I . IN TRODUC T ION In recent years, chip multiprocessor based systems have become the focus of attention in computer architecture design. Designers are pushed by Moore’s Law to integrate a large number of cores in a single chip. In fact, companies such as Tilera and Intel have already developed prototype CMPs with as many as 100 cores integrated in one silicon chip [1], [2], [3], [4]. At this density, traditional buses are no longer able to serve as the backbone of on-chip interconnections and are projected by many to be replaced by Network-on-Chips (NoCs). NoCs evolve from the off-chip networks that connect multi-processor systems. As interconnection networks shift to on-chip environments, designers face new challenges. Routing latency has become a more prominent factor affecting overall performance. At the same time, power consumed by NoCs and the area occupied by NoCs have become more expensive overheads in an on-chip environment. As a consequence, a low cost NoC design that can provide competitive performance has become a focus. Among an NoC router’s components, buffers consume a signiﬁcant fraction of the power and area. Routing latency and design complexity also increase when buffers are employed in a router. Thus, removing buffers to reduce the cost becomes an appealing option. Several recent works have investigated ways to totally or partially remove buffers from a router [7], This research is supported in part by NSF grants #1017882, #0963839, CNS #0720645, CCF #0811687, CCF #0702519 and a grant from Microsoft Corporation. [8], [9]. In particular, Moscibroda and Mutlu [7] proposed a bufferless NoC framework (BLESS) that removes input and output buffers from the router. If contentions occur in an output port of a bufferless router, data packets are deﬂected to neighboring nodes using hot-potato routing. However, several issues remain unaddressed by their bufferless NoC scheme. First, BLESS only works well when the network load ranges from low to medium. If the network utilization is high, network performance degrades sharply with the increase in router output contentions. Second, since data packets cannot be stored in a router’s buffer, they have to keep travelling in the network until they can ﬁnally reach the destination. Third, differentiated service classes are not supported since there are no buffers to keep the data from moving towards the destination. In this paper, we propose a novel heterogeneous NoC architecture that solves these problems by employing both buffered and bufferless routers in a same NoC. We ﬁrst investigate how the use of these two types of routers in the same network can affect NoC performance and cost. We show that, based on user’s performance and power requirements, designers can select an optimal placement plan that can strike a balance between cost/power and performance. We next investigate how application mapping can provide differentiated service among the applications and propose a Buffered Router Aware Mapping (BRAM). Finally, we propose a Buffered Router Aware Routing (BRAR) algorithm that can route data packets along buffered routers in order to further improve performance. We show that our proposed techniques can signiﬁcantly increase network performance under high network loads and meet the cost constraints at the same time. Our contributions can be summarized as follows: ∙ A heterogeneous NoC architecture that employs both buffered and bufferless routers in the same network. Compared to the baseline homogeneous bufferless NoC, our proposed heterogeneous NoC performs better in terms of performance and energy efﬁciency. ∙ An exploration of the buffered versus bufferless router placement design space: Our experiments show that better performance can be achieved with the same buffer count overhead if the router placement plan is carefully designed. ∙ A buffered router aware mapping (BRAM): by mapping application threads close to buffered routers, higher performance can be achieved from reduced number of data deﬂections. 978-1-4577-1400-9/11/$26.00 ©2011 IEEE 787 ∙ A buffered router aware routing (BRAR) algorithm to further improve performance: Our algorithm can intelligently move data along buffered routers in order to stay close to the optimal transmission path. Previous works on reducing NoC buffer costs include [7], [11], [9], [8], [15]. Our proposed scheme is quite different from these related works in the sense that our NoCs are composed of different types of routers. Mishra [16] et. al. proposed heterogeneous buffer structures for VC based NoCs. Our work is different from theirs: we use deﬂection ﬂow control and we remove buffers completely from some routers in order to reduce the NoC cost to the maximum. I I . H E T EROG EN EOU S NOC D E S IGN W I TH BU FFER ED AND BU FFER L E S S ROU T ER S A. Motivation Prior proposed bufferless router designs apply two major techniques to handle contention: deﬂection [7], [17] and retransmission [8], [9]. In a deﬂection (intentional mis-routing) based bufferless NoC scheme, data packets are routed to an available port, which may not be the optimal port selected by the underlying routing algorithm, when contention occurs. Packets to be deﬂected are selected based on priority to avoid deadlock and livelock. Consequently, since data cannot be saved in a buffer, if a packet is not able to use its optimal port, it bounces around in the network until contentions diminish or it becomes old enough to win the arbitration. In comparison, in a retransmission-based bufferless NoC scheme, data packets that fail in port contention are simply dropped and will need to be retransmitted. Thus, extra messages are needed to pass the information about whether a transmission is successful and, if not successful, to retransmit the data. Both schemes have long data latencies when the network load is high. In addition, large amounts of power can be consumed by deﬂected or retransmitted data. This motivated us to investigate the design of a network that has buffers in some of its routers to keep the packets from being deﬂected or dropped. In this way, data packets can avoid travelling extra links on their path toward their destinations. Power consumption can also be reduced when packets are held in buffers in some nodes in the network rather than being routed in a non-optimal direction. B. BLESS: the baseline bufferless routing framework BLESS [7] is a bufferless NoC framework that employs deﬂection routing. In BLESS, data can be routed in ﬂits (ﬂitbless) or worms (worm-bless). We implemented the ﬂit-bless scheme as our baseline architecture. Because there are no buffers in the routers to store ﬂits, data coming from an input port has to be routed out through one of the output ports to avoid being lost. When contention occurs due to multiple incoming ﬂits competing for a same output port, only one ﬂit is allowed to use that output port based on priority policies. Other ﬂits are intentionally mis-routed. In order to guarantee all data ﬂits can ﬁnally reach their destinations, the routers must have at least the same number of output ports and input ports. In addition, since there is no buffer in the routers, a E C A D B F Optimal Deflection Non-optimal Deflection X-Y Routing Fig. 1. Optimal and non-optimal deﬂection. processor can inject a ﬂit into its router only when at least one incoming port is free. Our baseline BLESS router consists of two stages: route calculation (RC) and switch traversal (ST). In our evaluations, we assume each stage takes one cycle, so it takes in 2 cycles in total for a ﬂit to pass through a router. C. A low cost heterogeneous NoC design Based on the fact that the BLESS NoC framework can greatly reduce the cost of a router, but cannot deliver very good performance at high network loads, we propose a heterogeneous NoC design that employs both buffered and bufferless routers in the same on-chip network. Our bufferless routers are similar to the routers in BLESS: input buffers are completely removed from each input port. However, in our buffered routers, we use buffers to store incoming data. There are two pipeline stages in the routers: RC and ST. We use the deﬂection algorithm to route data ﬂits in both types of routers. When several ﬂits are competing for the same output port, the oldest ﬂit will be granted the port. In a bufferless router, an incoming ﬂit will join the arbitration immediately after passing through the RC stage. In a buffered router on the other hand, the ﬁrst ﬂit in the buffer queue is selected to be routed and sent to arbitration if the buffer queue is not empty. A new ﬂit can bypass buffer writing when the buffer is empty. Flits failing in the competition are treated differently by the two types of routers. In a bufferless router, the ﬂit with lower priority will be deﬂected to an available output port. In a buffered router, if the buffer is not full, instead of being deﬂected, the data ﬂit stays in the buffer queue (the head of queue remains in the ﬁrst position). If the buffer is full, then the head ﬂit in the queue needs to be deﬂected like in a bufferless router. The basic principle of deﬂection routing still applies to buffered routers: arbitration is determined based on ﬂit ranking. The beneﬁt brought by buffered routers in our design is to reduce the probability of misrouting. In the next cycle, the head ﬂit in the buffer queue gets a second chance to compete for its desired output port. The possibility that a data packet is routed to a productive output port is increased by storing them in the buffered router. Our design is deadlock and livelock free: a data ﬂit will not be travelling forever in the network or stuck in a buffer. Since we adopt age as our policy for ﬂit ranking, once a ﬂit becomes old enough it will get hold of the requested ports and reach the destination. There are two advantages brought by this mechanism. First, buffers can reduce data transmission latency by keeping a ﬂit close to its optimal path. Figure 1 illustrates a ﬂit that travels from node A to node F. When applying X-Y routing algorithm, the ﬂit will be allocated to the East output port. If there is another ﬂit with higher priority demanding the same output, 788 (a) Placement 1 (P1 4:60) (b) Placement 2 (P2 16:48) (c) Placement 3 (P3 16:48) (d) Placement 4 (P4 24:40) (e) Placement 5 (P5 28:36) (f) Placement 6 (P6 32:32) (g) Placement 7 (P7 36:28) (h) Placement 8 (P8 64:0) Fig. 2. Different placement plans for buffered and bufferless routers on a proposed heterogeneous NoC. The light colored nodes represent bufferless routers and the dark colored nodes represent buffered routers. For each placement, the ratio of buffered routers and bufferless routers is also shown as the number of buffered routers : the number of bufferless routers. Note all routers in P8 are buffered but employ deﬂection routing. this ﬂit will be deﬂected to some other port. If the North output port is available, then this ﬂit can still travel on an optimal path. We call this case an optimal deﬂection. However, if the network load is high, the chances that this ﬂit can pass through port North are decreased and, as a result, the ﬂit travels further away from its destination (either West or South). For each nonoptimal deﬂection, the minimum delay incurred, i.e., the time for the ﬂit to come back to the shortest path can be calculated as 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑑𝑒𝑓 𝑙𝑒𝑐𝑡 = 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑙𝑖𝑛𝑘 ∗ 2 + 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑟𝑜𝑢𝑡𝑒𝑟 , (1) where the 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑙𝑖𝑛𝑘 is the time in cycles used to traverse a link, and 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑟𝑜𝑢𝑡𝑒𝑟 represents the number of cycles spent in the router pipeline. In our baseline NoC framework, the 𝐿𝑎𝑡𝑒𝑛𝑐𝑦 𝑑𝑒𝑓 𝑙𝑒𝑐𝑡 is at least 4 cycles: one cycle to a neighboring node, two cycles to get out of that node, and one cycle to come back to a node on the optimal path. A buffered router can reduce this latency. For example, if the output port to the East or North becomes available in the next cycle, it takes a buffered router 1 cycle of delay to enter the RC stage again compared to 4 cycles when it is deﬂected. Second, buffers in some regions of the NoC can absorb deﬂected ﬂits and stop the trafﬁc contention from spreading to other regions of the network. The functionality of buffered routers is similar to that of a reservoir that stores water to protect the surrounding area from being ﬂooded. In the pure bufferless NoCs, there is no mechanism to control such data ﬂooding. Data communication in one region of the network can easily get affected by that of another region. D. Placement of buffered and bufferless routers on a heterogeneous NoC We assume a 2-D mesh on-chip network that has 8X8 nodes, each with a radix of 5. Our routers employ deﬂection routing as proposed in Section II-C. We place buffered routes symmetrically because our proposed NoC is for general purpose CMPs. Our goal is to investigate the effect of placement of heterogeneous routers on performance, power and buffer overheads. Figure 2 illustrates the placements studied in this work. Since our motivation is to reduce trafﬁc contentions by placing more powerful routers in the network, it does not make much sense to put the buffered routers along the edges of the network. In our ﬁrst category of placements, buffered routers are placed to the center region of the NoC, based on the intuition that the center of the mesh tends to be the hot spot of trafﬁc Processors L1 Cache L2 Cache Memory NoC two-way out of order, 64-entry SPARC 2 GHz processor, instruction window 64 KB private cache, 4-way set associative, 128B block size, 2-cycle latency, split I/D caches shared L2 cache, SNUCA with 1MB banks per core, 16-way set associative, 128B block size, 6-cycles latency, 32 MSHRs 4GB, 260 cycle off–chip access latency 2-stage pipeline, 128 bit ﬂits, 4 ﬂits per packet, Hot Potato routing TABLE I BA S E L IN E CON FIGURAT ION . App 1 App 3 App 5 App 7 apache apsi sjbb swim apache swim apsi barnes App 2 App 4 App 6 App 8 barnes ocean apsi ocean sjbb apsi ocean swim A P P L ICAT ION S FORM ED W I TH A PA IR O F O P ENMP MU LT I - THR EAD B ENCHMARK S . TABLE II congestion. P1, P3 and P7 fall into this category of placements with 4, 16 and 36 buffered routers respectively. Our second category of placements use buffered routers so that the whole network can be divided into several regions in order to mitigate the effect of deﬂected trafﬁc of one region on its neighbors. P2 places 16 buffered routers diagonally, dividing the network into 4 equal sized parts. P4 uses 24 buffered routers to divide the network into two isolated circular regions. In P5, 28 buffered routers are used to build a grid to divide the network into 9 small regions with 4 bufferless routers. In addition, we also studied the placement of P6 where each bufferless router is surrounded by 4 buffered routers. Finally, we studied the two extreme cases of router placements: all routers are bufferless (P0) and all routers are buffered (P8). E. Evaluation We assume an 8X8 CMP connected by a mesh network at 45 nm technology. The memory hierarchy is implemented through a two-level directory cache coherence protocol. Each core has a private L1 cache and the L2 cache is shared among all cores. The detailed conﬁguration is described in Table I. We evaluate the performance and power consumption of our proposed heterogeneous NoCs using a cycle-accurate NoC Mix 1 Mix 3 Mix 5 Mix 7 App 1, 2, 3, 4 App 2, 3, 4, 5 App 3, 4, 5, 6 App 4, 5, 6, 7 4.71% Mix 2 4.95% Mix 4 5.7% Mix 6 7.58% Mix 8 TABLE III App 1, 3, 4, 5 App 2, 4, 5, 6 App 3, 5, 6, 7 App 5, 6, 7, 8 5.17% 7.15% 5.8% 4.18% M IX O F A P P L ICAT ION S MA P P ED TO A 8X 8 NOC . EACH M IX CON TA IN S 6 4 THR EAD S FROM 4 A P P L ICAT ION S RUNN ING W I TH 16 THR EAD S EACH . IN J EC T ION RAT E (M E S SAG E /CYC L E /NOD E ) I S A L SO SHOWN . 789 mix 1 mix 2 mix 3 mix 4 mix 5 mix 6 mix 7 mix 8 avg p0 p1 p2 p3 p4 p5 p6 p7 p8 vc Fig. 3. Normalized performance of different router placements with buffer size=8. p0 p1 p2 p3 p4 p5 p6 p7 p8 vc Fig. 4. Normalized power of different router placements with buffer size=8. average delay (cycles) p1 p2 p3 p4 p5 p6 p7 p8 vc Router Placement Plan Fig. 5. Performance of router placements with different buffer size. average power consumption (w) buf-8 buf-4 buf-2 buf-0 buf-8 buf-4 buf-2 buf-0 1 0.8 0.6 1 0.8 0.6 50 40 30 20 10 0 8 6 4 2 0 p1 p2 p3 p4 p5 p6 p7 p8 vc Router Placement Plan Fig. 6. Power of router placements with different buffer size. 0.9 0.7 0.5 Normalized savings in buffer count 1.5 1.2 0.9 0.6 Normalized NoC Area p0 p1 p2 p3 p4 p5 p6 p7 p8 Router Placement Plan vc (a) Normalized savings in buffer area p1 p2 p3 p4 p5 p6 p7 p8 vc Router Placement Plan (b) NoC area Fig. 7. Normalized area of different router placements. buf-8 buf-4 buf-2 buf0 simulator [18]. We use Orion [13] to evaluate our design’s cost in terms of buffer area. Each router has 5 input ports and 5 output ports. The router pipeline latency is 2 cycles, and it takes 1 cycle to traverse a 128-bit wide link. We assume each data packet contains 4 ﬂits and each ﬂit has 128 bits. In the baseline virtual channel based conﬁguration, we assume there are 4 virtual channels in each router and that the virtual channel is 8 ﬂits deep. Our heterogeneous NoC is conﬁgured as follows: input buffers are completely removed from our bufferless routers, and there are input buffers of 8 ﬂits deep in each input channel of our buffered routers. We used the SPEC OpenMP [14] benchmarks as our application programs. In our settings, each application is run with 16 threads and we collect memory access traces of these application threads. To stress the network with high trafﬁc loads, we map two threads from two applications to each core. Table II lists our applications that are mapped to CMP cores. We created 8 different mixes in our evaluation which are described in Table III. We compare our results with two baseline conﬁgurations: NoC with bufferless routers (called P0) and NoC with buffered routers using virtual channel for control ﬂow (VC). F. Results Figure 3, Figure 4 and Figure 7 illustrate respectively, the performance, power and area overheads of each of the placements shown in Figure 2. We can observe from Figure 3 that NoCs with buffered routers have better performance than NoCs with only bufferless routers. Especially the two end cases of the continuum: BLESS NoC (p0) and VC NoC (vc), where NoCs with virtual channels can improve performance by 30% compared to the BLESS architecture (mix-1 and mix790 MAP1 MAP2 MAP2 DES BRAR Routing DES BRAR Routing MAP1 SRC X-Y Routing SRC X-Y Routing Fig. 8. BRAM mapping with grid placement. Fig. 9. BRAM mapping with diagonal placement. Fig. 10. BRAR routing with grid placement. Fig. 11. BRAR routing with diagonal placement. 3). The heterogeneous NoCs improve performance from 4% (p1) to 15% (p8). However, performance is not solely decided by the number of buffered routers. In other words, more buffered routers do not necessarily bring better performance. For example, Placements 5, 6 and 7 have 28, 32 and 36 buffered routers, respectively. The performance of placement 5 is almost as good as that of the other two. From the above analysis, we can draw the conclusion that the location of buffered routers in our heterogeneous network plays an essential role in the overall performance. Intelligent placements can reduce the data latency more effectively under the same resource constraints. This observation implies that, by cleverly placing buffered routers, one can achieve a better tradeoff between performance and cost. Figure 4 illustrates the power consumption incurred by each of our placements. Under high network loads, ﬂits tend to be deﬂected more frequently and it takes them longer to reach their destination. The power consumed by these deﬂected ﬂits exceeds the power saved from removed buffer writes in the bufferless routers, resulting in more power overhead in bufferless routers. Note that, although the placement P8 does not improve performance signiﬁcantly over placement P5 by employing more buffered routers, it can decrease the power consumption by about 10%. This implies that the design space can be explored in multiple dimensions: designers can select an optimal placement to meet the performance and power requirements at the same time. Figure 7 illustrates the area saved by each of our placements compared to the baseline VC architecture. We see that our heterogeneous NoC design still keeps the advantage of bufferless NoCs in saving area: signiﬁcant amount of buffer area can be saved compared to VC based schemes. In our conﬁgurations, adding buffers to 38% of the NoC routers (24 buffered routers in placement 4) only decrease the buffer savings by about 10%. When we consider the overall area of the NoC, most of our heterogeneous NoCs have an overhead less than 10% over BLESS. The worst case is when all the routers are equipped with buffers, which incurs the area overhead of 18%. One possible concern about heterogeneous NoC architecture is that CMP nodes usually are designed in grids. Employing routers with different structures leads to unbalanced grid sizes. For example, the space for bufferless routers in a grid may not be fully utilized if the unit grid size is chosen uniformly as that of the buffered routers which is larger. This problem can be solved by combining several neighboring heterogeneous core/router pairs into one basic unit. For example, in P6, 4 neighboring nodes (that forms a square) can be selected as the basic building unit for a grid. Since our heterogeneous placements are symmetric, it is not hard to build such grid units from neighboring nodes. To fully explore the design space, we also experimented with different buffer sizes in our buffered routers as shown in Figure 5, Figure 6. Generally the data delay and power consumption increase as buffer size decreases because more deﬂected packets increased network congestion and power. To investigate our heterogeneity aware application mapping and routing techniques to further improve the performance, we selected two placements as our experimental platform in the remainder of this paper: placement 2 (diagonal) and placement 5 (grid). I I I . T ECHN IQU E S TO SU P PORT D I FF ER EN T S ERV IC E C LA S S After exploring the design space of heterogeneous router placements, we next investigate two complementing techniques that take advantage of this heterogeneity: buffered router aware application thread mapping and routing. To support different service classes of applications running on a NoC, we can apply the our BRAM technique to map applications of higher priority close to buffered routers and use the BRAR routing algorithm to route data of such applications through the path near those buffered routers. A. Application Mapping In our heterogeneous NoC, since routers have different capabilities when transmitting data ﬂits, mapping applications to speciﬁc regions in the network could result in a better performance if heterogeneity could be taken into account. Based on this observation, we propose a buffered router aware mapping (BRAM) strategy to map application threads as close as possible to buffered routers. Figure 8 illustrates two mapping strategies for an application that runs on 4 cores: mapping 1 (vertically hashed cores) and mapping 2 (horizontally hashed cores). Mapping 1 has two neighboring nodes that have buffered routers, while mapping 2 has eight. Since buffered routers can potentially reduce transmission latency by keeping data closely to the shortest path, mapping 2 of the application will have better chance to reduce the delay. Figure 9 illustrates how to apply our BRAM technique to a different placement plan (diagonal). To facilitate the BRAM mapping stragegy, we designed an algorithm (Algorithm 1) to calculate the proximity information of each router toward neighboring buffered routers. This algorithm takes, as input, a bitmap indicating the router placement 791 ) t s i l l e F c e y g c a y e a v e ( r A D l ) t s i l l e F c e y g c a y e a v e ( r A D l 40 30 20 10 0 40 30 20 10 0 NoC with bufferless routers Hetero NoC with BRAR Hetero NoC without BRAM or BRAR Hetero NoC with BRAM and BRAR Hetero NoC with BRAM VC App1 App2 App3 App4 App5 App6 ) t s i l l e F c e y g c a y e a v e ( r A D l 40 30 20 10 0 App1 App2 App3 App4 App5 App6 (a) diagonal placement. (b) grid placement. Fig. 12. Performance of BRAM and BRAR on a NoC of 64 nodes. ) t s i l l e F c e y g c a y e a v e ( r A D l 40 30 20 10 0 App1 App2 App3 App4 App5 App6 App1 App2 App3 App4 App5 App6 (a) diagonal placement. (b) grid placement. Fig. 13. Performance of BRAM and BRAR on a NoC of 100 nodes. of a heterogeneous NoC. There are two categories of outputs per router node: a distance vector and a weight. Distance vector indicates the number of hops from one router toward a nearest buffered router in each of the four directions. If, in one of the directions, there is no buffered router between a router and the edge of the NoC, we set the distance vector value of this direction to be the size of the NoC’s X (or Y) dimension. The weight on the other hand is the sum of distance vectors in all directions. Our BRAM mapping is quite straight forward so it is not shown here: when mapping an application to a core, always select the one with the lowest weight, in order to utilize the buffer resources. Figure 12 show our evaluation results when BRAM is applied to diagonal and grid placements (i.e., P2 and P5). In the diagonal placement, performance improvement using BRAM can be as high as 18%, while in the grid placement, the maximum performance improvement is around 9%. The reason why the BRAM works better in the diagonal placement case is that it can fully utilize buffered routers. Without BRAM, the performance of BLESS and that of our heterogeneous NoC would be very close to each other, due to the fact that the buffered routers are separated by more bufferless routers, so the deﬂection within each region surrounded by buffered routers cannot be effectively controlled. BRAM maps applications intentionally close to those buffered routers, fully utilizing the ability of these buffers to reduce the ﬂit latency. In contrast, in the grid placement, without BRAM, the heterogeneous NoC already improves the performance due to the fact that more buffered routers are placed in the network, and deﬂections are already reduced by those routers even without using BRAM. B. BRAR Routing Algorithm With routers having different abilities to move data along the shortest path, another knob that can be used to improve performance is data routing. We propose a BRAR routing algorithm that tries to move data ﬂits along the buffered routers. We use the distance vectors calculated from Algorithm 1 to Algorithm 1 Algorithm to calculate buffered router proximity Input: Bitmap of router placement on a heterogeneous NoC. Output: For each router node in the NoC, this algorithm gives: (1) the distance from the router to a closest buffered router in all directions as Distance[East, West, North , South]. (2) Weight of each node indicating the overall closeness of this node to neighboring buffered routers 𝑁 ← all nodes in the NoC 𝑀 𝑎𝑥 ℎ𝑜𝑝 ← Max(size of dimension X, size of dimension Y) of the NoC. for 𝑖 in 𝑁 do for 𝑑𝑖𝑟 in (East, West, North, South) do 𝑊 𝑒𝑖𝑔ℎ𝑡𝑖 ← 0 𝐻 𝑜𝑝 𝑐𝑛𝑡 ← 0 𝐶 𝑢𝑟𝑟𝑒𝑛𝑡 𝑛𝑜𝑑𝑒 ← 𝑖 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 ← Neighbor of 𝐶 𝑢𝑟𝑟𝑒𝑛𝑡 𝑛𝑜𝑑𝑒 in Direction 𝑑𝑖𝑟 while 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 ∕= 𝑁 𝑖𝑙 ∧ 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 is not a buffered router do 𝐶 𝑢𝑟𝑟𝑒𝑛𝑡 𝑛𝑜𝑑𝑒 ← 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 𝐻 𝑜𝑝 𝑐𝑛𝑡 ++ 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 ← Neighbor of 𝐶 𝑢𝑟𝑟𝑒𝑛𝑡 𝑛𝑜𝑑𝑒 in Direction 𝑑𝑖𝑟 end while if 𝑁 𝑒𝑥𝑡 𝑛𝑜𝑑𝑒 is a buffered router then 𝐻 𝑜𝑝 𝑐𝑛𝑡 ++ 𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒[𝑑𝑖𝑟 ] ← 𝐻 𝑜𝑝 𝑐𝑛𝑡 𝑊 𝑒𝑖𝑔ℎ𝑡𝑖 ← 𝑊 𝑒𝑖𝑔ℎ𝑡𝑖 + 𝐻 𝑜𝑝 𝑐𝑛𝑡 𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒[𝑑𝑖𝑟 ] ← 𝑀 𝑎𝑥 ℎ𝑜𝑝 𝑊 𝑒𝑖𝑔ℎ𝑡𝑖 ← 𝑊 𝑒𝑖𝑔ℎ𝑡𝑖 + 𝑀 𝑎𝑥 ℎ𝑜𝑝 else end if end for end for choose an optimal routing output port. At each node, when the routing logic tries to decide the next node to send a data ﬂit, it checks the Distance vector of current router to ﬁnd out which direction can reach a buffered router in the shortest distance. Algorithm 2 describes our BRAR algorithm, and Figure 10 and Figure 11 illustrate how our proposed routing 792                 strategy work with grid and diagonal placements. For example, in Figure 11, the source node can send ﬂits to either North or East ports. However, the Distance vector of North is 3 which is larger than the Distance vector of East (2 in this case). Our BRAR algorithm consequently chooses East to send ﬂits. The Distance vectors for each router are stored in the router locally, with a storage overhead of a few bytes which is negligible. Note that our BRAR algorithm is not expected to increase the length of a router’s critical path since the extra steps are only lookup and comparison of Distance vectors. The results plotted in Figure 12 show BRAR alone can reduce the delay cycles up to 15% in the diagnal placement. However, BRAR alone does not improve the performance signiﬁcantly when used on the grid placement. This is because the buffered routers in the grid placement are connected in X and Y directions and the X/Y routing algorithm sends all ﬂits to the buffered routers. As a consequence, congestions occur in the buffered routers, leading to longer delays. This problem does not happen in the diagonal placement, because the X/Y routing diverts ﬂits to both X and Y direction before ﬁnding the next buffered router, so congestion in buffered routers is greatly reduced. Algorithm 2 Buffered Router Aware Routing Algorithm Input: Current node, Destination node, Distance vector of Current node. Output: An output port desired to send the data out. 𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑋 ← the X direction from X-Y routing using Current and Destination nodes information 𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑌 ← the Y direction from Y-X routing using Current and Destination nodes information 𝐻 𝑜𝑝 𝑐𝑛𝑡𝑥 ← Distance[𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑋 ] 𝐻 𝑜𝑝 𝑐𝑛𝑡𝑦 ← Distance[𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑌 ] if 𝐻 𝑜𝑝 𝑐𝑛𝑡𝑦 >= 𝐻 𝑜𝑝 𝑐𝑛𝑡𝑥 then select 𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑋 direction else select 𝑂𝑝𝑡𝑖𝑚𝑎𝑙𝑌 direction end if Finally, we evaluated performance when both techniques are applied in our experiments. The performance of our heterogeneous NoC employing these two techniques comes very close to the virtual-channel based NoCs. Most of our heterogeneous NoCz can achieve an average ﬂit delay within 5% range, compared to VC based NoCs. Further, our design signiﬁcantly reduces the buffer area costs. To investigate the scalability of our proposed techniques, we experimented with a larger NoC network, with Figure 13 showing the results. IV. CONC LU S ION Aggressive many-core designs involving dozens or hundreds of processing cores put a limit on the resources that can be accommodated in on-chip networks. Several bufferless NoC designs have been proposed to reduce the cost in area and power, such as BLESS [7], BPS [11] and SCRAB [8]. Removing buffers from all of the NoC routers signiﬁcantly reduces the area cost but cannot deliver satisfying performance in all cases. In this work, we propose a low cost heterogeneous NoC architecture using both buffered routers and bufferless routers. To extensively explore the design space, we evaluated several router placement plans with different number of buffered routers and positions. Our simulation results show that intelligent router placement can achieve signiﬁcant gains in performance under the same resource budget. We also propose two techniques that take advantage of the NoC’s heterogeneous nature in order to further improve performance. BRAM is an application mapping technique that can map applications close to buffered routers to improve performance and BRAR is a routing algorithm that sends data packets along the buffered routers to reduce chances of misroutings. Our simulations show that applying such techniques can reduce data latencies by an average of 15%. In summary, heterogeneous NoC architectures incorporating both buffered and bufferless routers open up a new design space for performance improvement and cost reduction. Our design and evaluation demonstrate that signiﬁcant potential beneﬁts can be possibly explored in this area. [4] [1] "
2012,Functional post-silicon diagnosis and debug for networks-on-chip.,"Networks-on-chip (NoCs) have emerged as a favorable solution to provide higher bandwidth interconnects for large chip multiprocessors (CMPs). In order to enhance the inter-connect's performance, the NoC is often designed to include complex components and advanced features. Along with the increase in complexity and size, ensuring the functional correctness of the NoC can be particularly challenging This challenge pervades the entire verification effort, and particularly post-silicon validation, due to the lack of observability of the networks complex internal operation. We propose a post-silicon validation platform that enhances observability of network activity by periodically taking snapshots of the packets in flight. Each node's local cache is configured to store the snapshot logs in a temporary space allocated for post-silicon validation and released at deployment. Each snapshot log is periodically and locally analyzed by a software algorithm, running on the processor's core, in order to detect functional errors. If an error is detected, the snapshot logs are aggregated and additional debug data is extracted. This includes an overview of the traffic in the network at the time surrounding the manifestation of the error, as well as a partial reconstruction of the routes followed by the packets in flight. In our experiments, we found that this approach allows us to detect several types of functional errors, as well as observe over 50% of the network's traffic on average and reconstruct at least half of each of their routes through the network.","Functional Post-Silicon Diagnosis and Debug for Networks-on-Chip Rawan Abdel-Khalek and Valeria Ber tacco Computer Science and Engineering Depar tment University of Michigan [rawanak, valeria]@umich.edu ABSTRACT Networks-on-chip (NoCs) have emerged as a favorable solution to provide higher bandwidth interconnects for large chip multiprocessors (CMPs). In order to enhance the interconnect’s performance, the NoC is often designed to include complex components and advanced features. Along with the increase in complexity and size, ensuring the functional correctness of the NoC can be particularly challenging This challenge pervades the entire veriﬁcation eﬀort, and particularly post-silicon validation, due to the lack of observability of the networks complex internal operation. We propose a post-silicon validation platform that enhances observability of network activity by periodically taking snapshots of the packets in ﬂight. Each node’s local cache is conﬁgured to store the snapshot logs in a temporary space allocated for post-silicon validation and released at deployment. Each snapshot log is periodically and locally analyzed by a software algorithm, running on the processor’s core, in order to detect functional errors. If an error is detected, the snapshot logs are aggregated and additional debug data is extracted. This includes an overview of the traﬃc in the network at the time surrounding the manifestation of the error, as well as a partial reconstruction of the routes followed by the packets in ﬂight. In our experiments, we found that this approach allows us to detect several types of functional errors, as well as observe over 50% of the network’s traﬃc on average and reconstruct at least half of each of their routes through the network. 1. INTRODUCTION As silicon technology continues to scale, large chip multiprocessor (CMP) architectures are an emerging solution targeting parallel applications and high performance computing. In today’s market, designs such as Tilera CMPs and Intel’s SCC have as many as 48-100 cores on chip. To provide the high communication bandwidth required for these cores to communicate among each other, networks-on-chips (NoCs) are utilized. In a typical NoC architecture, processor Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2012, November 5-8, 2012 San Jose, California, USA Copyright 2012 ACM 978-1-4503-1573-9/12/11 ...$15.00. cores connect to the interconnect through a network interface. Data sent over the network is divided into packets and transmitted between cores through a series of routers following a path determined by the network’s routing protocol. In order to provide more bandwidth, better resource utilization, and higher performance, the NoC designs are becoming increasingly complex. Today, networks often have irregular topologies and advanced routing algorithms and router architectures are often designed with advanced features to boost performance. This growth in complexity and size translates to an increase in the diﬃculty of verifying the functionality of the NoC. Post-silicon functional validation is an important phase in the veriﬁcation process of hardware designs. Tests run at high speeds directly on the ﬁrst few silcon prototypes, which allows a deeper and more thorough validation of the state space. However, this comes at the expense of extremely limited observability and controllability of the design’s internals, making the detection and debugging of errors very challenging. In this paper, we address the limitations of post-silicon validation for the NoC subsystem by introducing a novel debug platform that greatly boosts the observability of the network activity and facilitates the detection and debug of functional errors. While, pre-silicon veriﬁcation, which validates the RTL description of a design, is eﬀective for individual components [6], system-level validation is spotty at best, given the limited scalability and performance of the tools available. In contrast, post-silicon validation oﬀers the high performance necessary to investigate the correctness of system-level functionality in depth and expose complex bugs. Such functional bugs manifest as incorrect traﬃc behavior and network resource utilization or by preventing the network from making correct forward progress, such as deadlocks and livelocks. 2. CONTRIBUTIONS To address the challenges outlined above, we present a post-silicon veriﬁcation platform that aids in detecting and diagnosing functional errors in network-on-chip interconnects in CMPs. We collect information about traﬃc in-ﬂight during network operation, by instrumenting each router to take period snapshots of the packets traversing it at the time. The snapshots are stored in a designated portion of the L2 local cache corresponding to that CMP node. This space is temporarily reserved for post-silicon debug and released afterwards. The logs of each router eﬀectively provide samples of the traﬃc observed within the router throughout a test execution. If a functional error manifests, then it af557 processor core local cache CMP node (P3, @t5) network  interface router BLOCKED X $ (P1, @t2, @t3,…,@t40) $ P3 (P3, @t8) $ $ P1 P3 (P1, @t1) (P2, @t1) $ MISROUTE X (P3, @t3, @t12) $ X LIVELOCK P3 (P3, @t10) $ $ P1 packet P2 P3 Figure 1: Overview of our NoC post-silicon validation platform. We boost observability during post-silicon validation by instrumenting routers to periodically monitor network traﬃc. We show three possible bugs that our solution can detect and the type of information collected. fects the behavior of at least one packet. Therefore, we run a software checking algorithm runs on each core to examine the local logs and identify erroneous behavior. If an error is detected, the logs from all nodes are aggregated and used to reconstruct the paths followed by packets in the network. The reconstructed paths provide an overview of the traﬃc in transit during the time preceding the manifestation of the error (see also Figure 1). Our proposed solution is independent of the speciﬁc NoC design, its topology, routing algorithm and router architecture. It is also applicable to a NoC that uses multiple clock domains. Our solution provides the following main contributions: • A framework that provides observability of the network operations during post-silicon validation by periodically taking snapshots of routers’ contents. The collected data is used to track packets through the network, providing a global overview of the network traﬃc at the time of the error manifestation. Our experimental evaluation shows that our solution can provide observability of over 50% of packets in most cases and reconstruct at least half of their paths. • A post-silicon solution that detects and diagnoses functional errors that prevent the network from making forward progress, including deadlocks, livelocks, starvation and misrouting errors. 3. RELATED WORK Conventional approaches to post-silicon debug augments the design with boundary scan registers (BSRs). Test data can be serially shifted through these BSRs and applied to the component being tested. Test results and traces can be serially read out and transferred oﬀ-chip to be analyzed for debugging. Another common approach uses on-chip trace buﬀers to collect execution traces and then oﬀ-loads them for analysis when they are full; however, this comes at the expense of a large area overhead. In contrast, we propose a post-silicon debug platform targeting speciﬁcally NoCs, enabling us to tailor our solution for eﬀective functional debugging of the interconnect. Similar to the idea of using on-chip buﬀers, we collect information about packets in ﬂight, but we store them in the local caches. Data is collected at a central location only if an error is detected in the local logs. Therefore, our approach also has the beneﬁt of eliminating the need to regularly oﬀ-load data from all buﬀers. Some solutions for post-silicon debugging of NoC designs were proposed in [8], [3] [2]. Vermeulen, et al. describes a transaction-based NoC monitoring framework for systemson-chip, where monitors are attached to master/slave interfaces or to routers. These monitors can ﬁlter traﬃc to observe transactions of interest as well as analyze network performance. [2] proposes adding conﬁgurable monitors to NoC routers to observe router signals and generate timestamped events. The events are then transferred through the NoC for oﬀ-chip analysis or at dedicated processing nodes. This work was later extended in [3] by replacing the event generator with a transaction monitor, which can be conﬁgured to monitor the raw data of the observed signals or to abstract the data to the connection or transaction level. These works propose solutions for increasing NoC observability, but do not demonstrate their use in functional veriﬁcation. [8] focuses on using the monitors for performance analysis of the network operations. [3], [2] provide a high-level description of the types of events and transactions that can be observed, but do not address their use in detecting and debugging errors. We share with them the idea of monitoring traﬃc at the routers to provide observability of the network’s internal operations. However, we propose a complete framework that selects the exact data to be monitored and uses it to detect functional errors and help in debugging. An additional drawback of the above approaches is that, in order to continuously monitor execution, monitored data either needs to be stored in large buﬀers or regularly transmitted over the network for analysis. The former increases area and power overheads and the latter regularly perturbs the network’s normal execution. The authors of [2, 3] also report a high area overhead (17%-24%) for the monitors that will be no longer needed after system deployment. On the other hand, our framework stores the monitored data in the local cache, analyzes it locally, and transmits it over the network only when an error is detected. Finally, our monitoring hardware introduces a much smaller area overhead (9%). Other debugging solutions for NoC-based multi-cores and systems-on-chip (SoCs) include [7]. Debug probes are added between each core under debug (CUD) and its networkinterface. The probes monitor communication transactions, generate signals to control the CUD, and read the CUD’s trace buﬀers. Control and debug data are transferred between the probes and an oﬀ-chip debug controller through the NoC. Similarly in [9, 10], probes are added to monitor incoming and outgoing packets of master IPs in an SoC, which are then used to analyze the initiation and completion of transactions. These proposed platforms do not address debugging functional errors in the interconnect itself, which is the target of our work. 4. POST-SILICON VALIDATION PLATFORM In a typical NoC-based CMP, each processor core and its local cache are connected through a network interface to a router (Figure 1). We assume a general virtual channel worm-hole router architecture, where packets are partitioned into ﬂits, with a header ﬂit marking the beginning of the packet. An incoming packet is ﬁrst queued in one of the router’s input buﬀer and then it is processed in three 558 logging l o c a l  core periodic router  snapshots logging local check global check logging local check lo cal  cac h e core c a c h e temporary  log storage each core analyze its  log and detects bugs central debug unit (CDU) collects  snapshots and builds packet routes domains, a snapshot entry also includes the logical timestamp of the packet. Note, all entries in the same snapshot have the same physical timestamp, we therefore store it only once for the entire snapshot. Overall, every snapshot consists of several entries, one for each packet. Every entry contains a packet ID (counter, source, destination), input port, input virtual channel, output port (if allocated), output virtual channel (if allocated), and its logical timestamp. Figure 4 shows the information logged in each snapshot. In our experimental platform described in Section 5, the size of a snapshot was at most 57B (assuming 20 bits for the physical timestamp, 15 bits for the logical timestamp and 20 bits for packet ID). The collected snapshot entries are sent through a dedicated link to the network interface and stored in a designated portion of the local cache. When available storage is full, the corresponding node transmits a ﬂag through a dedicated link, halting the network temporarily and initiating the local check phase. entry 1 Num of entries: n Packet ID (counter, src, dest) physical timestamp input  input  output  output  port VC port VC logical timestamp entry n Packet ID (counter, src, dest) input  port input  VC output  port output  VC logical timestamp Figure 4: Snapshot format. A snapshot consists of several entries, one for each packet in the router. 4.2 Local Checks Our debug platform targets errors that prevent the network from making correct forward progress. During the local check phase, each core analyzes the snapshot log from its local cache to detect signs of such errors. The algorithm ﬁrst iterates through the snapshots and groups snapshot entries according to the packet ID. Thus, each packet becomes associated with a list of entries that reﬂect how the status of the packet changed within that router. Forward progress can be hindered if a packet is blocked in a router, in the case of a starvation or deadlock bug, or is not advancing correctly towards its destination, in the case of a livelock and a misroute bug. Therefore, we consider each of these cases separately. Livelock. A network livelock exists if a packet is being transferred through routers but not advancing to its destination. Since the checking algorithm running on each core has only access to its local snapshot log, livelocks must be detected locally at the router. For a network with a ﬁnite number of nodes, a livelocked packet will eventually traverse the same router twice. Provided that the epoch length is long enough for the livelock cycle to form, such errors can be detected locally. In Figure 5 (lines 3-7), the algorithm retrieves the physical timestamp of the packet’s snapshot entries. If the diﬀerence in time between two successive snapshot entries is greater than the snapshot interval, then they were captured in non-consecutive snapshots. This is an indication that the packet traversed the router at diﬀerent non-consecutive times and the algorithm ﬂags a livelock. Starvation. A starvation error exists if a packet is temporarily blocked waiting to acquire resources that are given to other packets. Packets traversing the network can only be blocked in a router’s input buﬀers, as this is the only storage available in the network. Therefore, a starved packet must appear in several consecutive snapshots in a router. Hence, the checking algorithm determines the number of consecutive snapshots in which each packet appears (Figure 5, line 9), and based on the snapshot rate, it deduces how long the packet has been waiting and ﬂags a starvation error when this value exceeds a user-set threshold. Deadlock. A network deadlock exists if packets are blocked waiting on each other to free resources in a way that none of them can advance forward. At the network-level, a deadlock can be identiﬁed by the existence of a cyclic dependency of resources, but identifying a deadlock at the router-level by examining only the local snapshot log reduces to the problem of identifying a blocked packet. Similar to the starvation bug, a packet is blocked if it appears in consecutive snapshots. However, a deadlocked packet is permanently blocked, which means it must also be seen in the latest snapshot. Thus, the local check algorithm checks if any of the packets in the snapshots satisfy both these conditions and ﬂags them as deadlocked (lines 10-11 in Figure 5). Note that long starved packets could be misclassiﬁed as deadlocks. Misroute. With deterministic routing, a packet traveling between a source and destination pair should always go through the same route, based on the routing algorithm. A misroute occurs if a packet is routed to a node that is not on this path (irrespective of whether the packet eventually reaches its ﬁnal destination). To detect such errors, we ﬁrst assume that all valid paths between each sourcedestination pair are known, since they can easily be collected theoretically or experimentally beforehand. This information is stored in each local cache in the form of a bit vector that indicates, for each source-destination pair, whether the local router is part of the valid route. Therefore, to detect misroutes, the local check algorithm iterates through the snapshot entries, obtains the source and destination of each entry, and checks it against the valid paths information (lines 13-16 in Figure 5). In the absence of errors, the snapshot data is cleared and the NoC resumes execution. However, if an error is detected, the logs are aggregated at the central debug unit (CDU), which can be any of the network nodes. In-ﬂight packet are dropped and the logs are sent from one cache at a time to the CDU. Sending from one node at a time reduces the complexity of network operations during the transmission of the logs, boosting the likelihood of error-free transmission, since it only uses basic operations. Sampling. To reduce the time spent in the local check phase, we also provide an optimization that trades-oﬀ the ability to detect errors with the execution time of the local check algorithm. Instead of analyzing the entire snapshot log, each core can downsample the information, such that it only looks at a uniformly distributed fraction of the snapshot entries. This sampling rate is another user-deﬁned value, and we evaluate its trade-oﬀs in Section 5.1. 4.3 Global Check The goal of the global check phase is to provide useful information that can facilitate debugging the detected error. It combines the collected snapshots to reconstruct the paths of observed packets, and it gives an overview of the traﬃc that passed through the network during the logging phase. Snapshots entries pertaining to the same packet are grouped together. Packet routes are then reconstructed by sorting these entries in increasing order of snapshots’ physical timstamps, when a global clock is present, or the logical timestamps when the network uses multiple clock domains. 560 1. LocalCheck (snapshotLog){ 2. foreach packet in snapshotLog { 3. 4. 5. 6. 7. foreach ntr in GetSnapshotEntries(packet) { time = PhysicalTimeEntry(ntr); next_time = PhysicalTimeEntry(ntr+1) if (next_time - time > snapshotInterval) FlagError(Livelock)} 8. 9. 10. 11. if (CountEntries(packet) > threshold) if packet in lastSnapshot(snapshotLog) FlagError(Deadlock) else FlagError(Starvation) 12. 13. 14. 15. src = GetSrc(packet) dest = GetDest(packet) if router !InPath(src, dest) FlagError(Misroute) } } Figure 5: Local check algorithm. To detect livelock, the algorithm checks if a packet appears in non-consecutive snapshots. For blocked packets (deadlock and starvation), it checks if a packet appears in several consecutive snapshots. Finally, misroute errors are detected by comparison with the set of valid paths between the packet’s source and destination. We also use each entry’s input port and output port to try to reconstruct the path beyond the router in which the packet was observed. We determine the upstream (downstream) router, based on the input port (output port) ﬁeld and the network topology. Besides reconstructing packet routes, the global check algorithm can highlight the packets that were present in each router at the time the snapshot was taken, exposing interactions that possibly triggered the error. For example, by examining a router’s snapshot log, we can determine a subset of the packets that traversed it and deduce the router’s internal states, such as the buﬀers that were in-use and the virtual channel and output port allocations at the time. 5. EXPERIMENTAL EVALUATION To evaluate our debug platform, we modeled a CMP interconnect with Booksim, a cycle accurate C++ based network simulator [4]. We considered our baseline system to be an 8x8 mesh NoC with input-queued virtual channel routers. Each router has 5 ports, 2 virtual channels and 8 ﬂit-buﬀers. We augmented the simulator so that routers take periodic snapshots of packets and we implemented the local check functions. We simulated two types of workloads: directed random traﬃc (uniform, bitcomp) and applications from the PARSEC benchmark suite [1]. injected bugs no  sampling 50%  sampling 20%  sampling no  sampling 50%  sampling 20%  sampling misroute 19% 14% 2% 6% 0% 0% deadlock 100% 100% 100% 100% 100% 100% live lock 100% 100% 100% 100% 100% 100% starvation 24% 7% 2% 0% 0% 0% snapshot inte rval=10 cycles snapshot inte rval=50 cycles Table 1: Error detection rate for our four types of bugs. The results are reported for two snapshot intervals, with and without local check sampling. 5.1 Error Detection We ﬁrst analyzed our platform’s ability to detect functional errors. We modeled four types of bugs in the baseline system, each representing an error that would prevent the network from making correct forward progress. These include a deadlock and a livelock bug, a misrouting bug, where (cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:3)(cid:7)(cid:10)(cid:8) (cid:11)(cid:12)(cid:8)(cid:13)(cid:14)(cid:13)(cid:15)(cid:10)(cid:1) (cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:3)(cid:7)(cid:10)(cid:8) (cid:16)(cid:12)(cid:8)(cid:13)(cid:14)(cid:13)(cid:15)(cid:10)(cid:1) (cid:15)(cid:6)(cid:17) (cid:18)(cid:2)(cid:19)(cid:10)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:20)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:6)(cid:22)(cid:1)(cid:10)(cid:9)(cid:23)(cid:10)(cid:24) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:4)(cid:3)(cid:7)(cid:5) (cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:1)(cid:2)(cid:3) (cid:4)(cid:5)(cid:3) (cid:1)(cid:6)(cid:3) (cid:6)(cid:5)(cid:3) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2)(cid:8)(cid:9)(cid:3)(cid:7)(cid:10) (cid:6)(cid:28)(cid:8) (cid:28)(cid:3)(cid:27)(cid:15)(cid:7)(cid:14)(cid:8)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:4)(cid:10)(cid:9)(cid:8)(cid:22)(cid:27)(cid:25)(cid:8)(cid:7)(cid:14)(cid:4)(cid:10) (cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:2)(cid:6)(cid:3) (cid:15)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:5)(cid:3) (cid:16)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:21)(cid:6)(cid:3) (cid:22)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:1)(cid:2)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:24)(cid:2)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:21)(cid:21)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:6)(cid:21)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:5)(cid:3) (cid:29)(cid:10)(cid:24)(cid:18)(cid:27)(cid:29) (cid:18)(cid:2)(cid:19)(cid:10)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:20)(cid:8)(cid:6)(cid:28)(cid:8)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:6)(cid:22)(cid:1)(cid:10)(cid:9)(cid:23)(cid:10)(cid:24) (cid:21)(cid:24)(cid:3) (cid:4)(cid:26)(cid:3) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:4)(cid:3)(cid:7)(cid:5) (cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:1)(cid:4)(cid:3) (cid:6)(cid:27)(cid:3) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2)(cid:8)(cid:9)(cid:3)(cid:7)(cid:10)(cid:8)(cid:6)(cid:28)(cid:8) (cid:28)(cid:3)(cid:27)(cid:15)(cid:7)(cid:14)(cid:8)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:4)(cid:10)(cid:9)(cid:8)(cid:22)(cid:27)(cid:25)(cid:8)(cid:7)(cid:14)(cid:4)(cid:10) (cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:1)(cid:1)(cid:3) (cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:5)(cid:3) (cid:16)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:21)(cid:24)(cid:3) (cid:16)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:2)(cid:28)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:1)(cid:24)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:2)(cid:26)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:2)(cid:24)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:5)(cid:3) (cid:5)(cid:18)(cid:25)(cid:5) (cid:18)(cid:2)(cid:19)(cid:10)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:20)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:6)(cid:22)(cid:1)(cid:10)(cid:9)(cid:23)(cid:10)(cid:24) (cid:26)(cid:1)(cid:3) (cid:1)(cid:5)(cid:3) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:4)(cid:3)(cid:7)(cid:5) (cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2) (cid:1)(cid:26)(cid:3) (cid:6)(cid:1)(cid:3) (cid:3)(cid:23)(cid:25)(cid:26)(cid:8)(cid:9)(cid:10)(cid:13)(cid:6)(cid:2)(cid:1)(cid:7)(cid:9)(cid:27)(cid:13)(cid:7)(cid:18)(cid:6)(cid:2)(cid:8)(cid:9)(cid:3)(cid:7)(cid:10)(cid:8)(cid:6)(cid:28)(cid:8) (cid:28)(cid:3)(cid:27)(cid:15)(cid:7)(cid:14)(cid:8)(cid:4)(cid:3)(cid:13)(cid:21)(cid:10)(cid:7)(cid:1)(cid:8)(cid:4)(cid:10)(cid:9)(cid:8)(cid:22)(cid:27)(cid:25)(cid:8)(cid:7)(cid:14)(cid:4)(cid:10) (cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:21)(cid:5)(cid:3) (cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14) (cid:5)(cid:3) (cid:16)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:24)(cid:24)(cid:3) (cid:16)(cid:14)(cid:17)(cid:16)(cid:18)(cid:11)(cid:19)(cid:20) (cid:1)(cid:2)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:24)(cid:6)(cid:3) (cid:18)(cid:8)(cid:23)(cid:14)(cid:18)(cid:11)(cid:19)(cid:20) (cid:1)(cid:21)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:5)(cid:3) (cid:9)(cid:13)(cid:17)(cid:10)(cid:23)(cid:17)(cid:13)(cid:8)(cid:11)(cid:25) (cid:5)(cid:3) Table 2: Diagnosis capability is evaluated by measuring the % of packets observed, the % of each path that we could reconstruct, and the % reconstruction for the erroneous paths. a packet is misrouted once along its path to the destination node, and a starvation bug, where a packet is temporarily prevented from acquiring the resources it needs to progress along its path. The bugs were injected in a randomly chosen router or set of routers by modifying the simulator to model the eﬀect of the bug on the packets in transit at the time. We ran both the random traﬃc and PARSEC workloads, while triggering each bug once during the simulation and repeated each experiment with 11 random seeds. Table 1 shows the detection rate when simulating bitcomp traﬃc over our four bugs and two snapshot intervals (every 10 cycles and every 50 cycles). In addition, we varied the sampling rate of the local check algorithm, which, as explained in Section 4.2, constitutes a trade-oﬀ between detection coverage and the time it takes to complete the local check phase. In these experiments, the threshold for detecting starvation and deadlock was set to 100 snapshots. Results show that deadlock and livelock bugs are always detected, whereas misroute and starvation have a much lower detection rate (0% -24%). This is because, when a packet is deadlocked or livelocked, it remains in this state from when the bug manifests until the end of the simulation, and thus it has a high probability of being captured by the snapshots. On the other hand, misroute and starvation errors are transient and the aﬀected packets can be missed and never observed. This eﬀect is more pronounced when the snapshot interval is increased to 50 cycles. In addition, if sampling is activated during the local check phase, the detection of misroute and starvation decreases, again because of the transient nature of these errors. Whereas, local check sampling does not aﬀect the detection of livelock and deadlock. Finally, we noticed that for the snapshot interval of 10 cycles, the simulations where the traﬃc injection rate was high (close to network saturation), exhibited false positives due to the false detection of starvation bugs. Starvation errors were ﬂagged even before our bugs were injected. This is because the network is highly congested and the chosen detection threshold was small. However, at a snapshot interval of 50 cycles, no false positives were reported. 5.2 Error Diagnosis We also evaluated the quality of information that can be obtained from the snapshots when they are aggregated dur561 (cid:1) (cid:2)(cid:1) (cid:3)(cid:1)(cid:1) (cid:3)(cid:2)(cid:1) (cid:4)(cid:1)(cid:1) (cid:4)(cid:2)(cid:1) (cid:5)(cid:1)(cid:1) (cid:5)(cid:2)(cid:1) (cid:6)(cid:1)(cid:1) (cid:1)(cid:7)(cid:1)(cid:6) (cid:1)(cid:7)(cid:1)(cid:8) (cid:1)(cid:7)(cid:1)(cid:9) (cid:1)(cid:7)(cid:3) (cid:1)(cid:7)(cid:3)(cid:4) (cid:1)(cid:7)(cid:3)(cid:6) (cid:1)(cid:7)(cid:3)(cid:8) (cid:1)(cid:7)(cid:3)(cid:9) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) (cid:9) (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:16) (cid:17)(cid:18)(cid:19)(cid:3)(cid:4)(cid:5)(cid:6)(cid:20)(cid:18)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3) (cid:23)(cid:6)(cid:5)(cid:4)(cid:20)(cid:24)(cid:10) (cid:1) (cid:2)(cid:1) (cid:3)(cid:1)(cid:1) (cid:3)(cid:2)(cid:1) (cid:4)(cid:1)(cid:1) (cid:4)(cid:2)(cid:1) (cid:5)(cid:1)(cid:1) (cid:1)(cid:7)(cid:1)(cid:8) (cid:1)(cid:7)(cid:3) (cid:1)(cid:7)(cid:3)(cid:6) (cid:1)(cid:7)(cid:3)(cid:9) (cid:1)(cid:7)(cid:4)(cid:4) (cid:1)(cid:7)(cid:4)(cid:8) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) (cid:9) (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:16) (cid:17)(cid:18)(cid:19)(cid:3)(cid:4)(cid:5)(cid:6)(cid:20)(cid:18)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3) (cid:25)(cid:18)(cid:6)(cid:2)(cid:20)(cid:21)(cid:24)(cid:8) (cid:18)(cid:20)(cid:8)(cid:9)(cid:22)(cid:24)(cid:10)(cid:26)(cid:6)(cid:18)(cid:27) (cid:9)(cid:22)(cid:24)(cid:10)(cid:26)(cid:6)(cid:18)(cid:27)(cid:8)(cid:28)(cid:8)(cid:29)(cid:30)(cid:31) (cid:9)(cid:22)(cid:24)(cid:10)(cid:26)(cid:6)(cid:18)(cid:27)(cid:8)(cid:28)(cid:8) (cid:30)(cid:31) (cid:1) (cid:3)(cid:2)(cid:1) (cid:5)(cid:1)(cid:1) (cid:6)(cid:2)(cid:1) (cid:8)(cid:1)(cid:1) (cid:10)(cid:2)(cid:1) (cid:11)(cid:1)(cid:1) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) ! (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:16) (cid:23)(cid:3)(cid:18)(cid:4)""(cid:24)(cid:22)(cid:21)#(cid:9) $%&!(cid:1)’ Figure 6: Eﬀective simulation speed of our NoC debug platform with varying local check sampling rates. The baseline system without our debugging functionality is assumed to be running at 1GHz. (cid:1) (cid:2)(cid:1)(cid:1) (cid:3)(cid:1)(cid:1) (cid:4)(cid:1)(cid:1) (cid:5)(cid:1)(cid:1) (cid:6)(cid:1)(cid:1)(cid:1) (cid:1)(cid:7)(cid:1)(cid:3) (cid:1)(cid:7)(cid:1)(cid:4) (cid:1)(cid:7)(cid:1)(cid:5) (cid:1)(cid:7)(cid:6) (cid:1)(cid:7)(cid:6)(cid:2) (cid:1)(cid:7)(cid:6)(cid:3) (cid:1)(cid:7)(cid:6)(cid:4) (cid:1)(cid:7)(cid:6)(cid:5) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) (cid:9) (cid:8) (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:8) (cid:16) (cid:17)(cid:18)(cid:19)(cid:3)(cid:4)(cid:5)(cid:6)(cid:20)(cid:18)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3) (cid:23)(cid:6)(cid:5)(cid:4)(cid:20)(cid:24)(cid:10) (cid:1) (cid:2)(cid:1)(cid:1) (cid:3)(cid:1)(cid:1) (cid:4)(cid:1)(cid:1) (cid:5)(cid:1)(cid:1) (cid:6)(cid:1)(cid:1)(cid:1) (cid:1)(cid:7)(cid:1)(cid:4) (cid:1)(cid:7)(cid:6) (cid:1)(cid:7)(cid:6)(cid:3) (cid:1)(cid:7)(cid:6)(cid:5) (cid:1)(cid:7)(cid:2)(cid:2) (cid:1)(cid:7)(cid:2)(cid:4) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) (cid:9) (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:8) (cid:16) (cid:17)(cid:18)(cid:19)(cid:3)(cid:4)(cid:5)(cid:6)(cid:20)(cid:18)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3) (cid:25)(cid:18)(cid:6)(cid:2)(cid:20)(cid:21)(cid:24) (cid:9)(cid:18)(cid:22)(cid:10)(cid:9)(cid:26)(cid:20)(cid:5)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3)(cid:27)(cid:28)(cid:29) (cid:9)(cid:18)(cid:22)(cid:10)(cid:9)(cid:26)(cid:20)(cid:5)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3)(cid:27)(cid:30)(cid:29) (cid:9)(cid:18)(cid:22)(cid:10)(cid:9)(cid:26)(cid:20)(cid:5)(cid:8)(cid:21)(cid:22)(cid:5)(cid:3)(cid:27)(cid:28)(cid:29)(cid:29) (cid:1) (cid:2)(cid:1)(cid:1) (cid:3)(cid:1)(cid:1) (cid:4)(cid:1)(cid:1) (cid:5)(cid:1)(cid:1) (cid:6)(cid:1)(cid:1)(cid:1) (cid:1) (cid:2) (cid:2) (cid:4) (cid:3) (cid:6) (cid:5) (cid:3) (cid:7) (cid:8) (cid:11) (cid:3) (cid:3) (cid:10) (cid:9) (cid:12) (cid:8) (cid:13) (cid:14) (cid:15) (cid:16) (cid:23)(cid:3)(cid:18)(cid:4)(cid:26)(cid:24)(cid:22)(cid:21)(cid:31)(cid:9)  !""#(cid:1)$ Figure 7: Eﬀective simulation speed of our NoC debug platform with varying snapshot interval. The baseline system without our debugging functionality is assumed to be running at 1GHz ing the global check phase. Table 2 highlights the results for bitcomp random traﬃc at low, medium and high injection rates and two snapshot intervals (10 cycles and 50 cycles) and with a sampling rate of 50%. We particularly looked at 3 measurements. First, we calculated the percentage of packets that were observed in at least one snapshot out of the total number of packets injected in the simulation. Second, we looked at path reconstruction, which is the average percentage of each route we were able reconstruct from the aggregated snapshots. Finally, we measured the path reconstruction of the packets that were detected as faulty (i.e., the packets where the detected error manifested). For a snapshot interval of 10 cycles, the percentage of observed packets is 54% at low injection and increases to 85% at high injection. This increase is due to the fact that at higher injection rates, the network is more congested and routers have more packets traversing them, which allows each snapshot to capture a larger fraction of the packets in ﬂight. As for path reconstruction, we note that on average 52% to 58% of each route was reconstructed from the snapshots. When looking at the path reconstruction of the erroneous packets, we notice that when the bug is detected, we can reconstruct on average 36%- 60% of its path. For the starvation bug at high injection, the path reconstruction of the faulty packet is reported as 0%, since the error was not detected in any of the runs. Even though at higher injection, the network is more congested and starvation is more likely to occur, we maintained the same bug injection rate: one starvation bug injected once during each run. Therefore, with more traﬃc in-ﬂight and given the probabilistic nature of the snapshot algorithm, the erroneous packet that was aﬀected by the bug, was never observed. When the snapshot interval is increased to 50 cycles, the percentage of packets that are observed in the collected snapshots decreases to 20% at low injection and 50% at high injection. Similarly, the overall average path reconstruction decreases to 35%. With higher snapshot intervals, snapshots are taken less frequently and thus more packets are missed. Therefore, the snapshot interval directly inﬂuences network observability. Moreover, the impact of the chosen snapshot interval varies depending on the injection rate. For test cases that have low traﬃc injection, a smaller snapshot interval is required to observe at least 50% of all packets. However, at high injection rate, a larger snapshot value would be suﬃcient to achieve the same result, because of the higher congestion in the network. 5.3 Debug Platform Simulation Speed Our NoC debug platform periodically stops network execution to locally check the collected snapshot logs. We therefore evaluated the eﬀective speed of the baseline system with the snapshot and local check functionalities enabled. To this end, we simulated the system with PARSEC and random traﬃc and ran these simulations on a 2.4GHz Core2 Quad machine. We utilized the x86 timestamp counters to calculate the average execution time, in cycles, of the local check algorithm. In these experiments, we assume that the baseline system (the cores and the NoC) without our NoC debug functionality is operating at 1GHz. We also assume that 30KB of the local L2 cache is reserved for the snapshot log, when simulating random traﬃc workloads and 10KB when simulating the PARSEC benchmarks. Note that the snapshot storage is around 10% or less of a typical L2 cache size of 256KB. In addition, the lower injection rate of the PARSEC benchmarks required us to choose a lower storage size so that the local log ﬁlls up and triggers a local check at least once during the benchmark’s execution. Figure 6 shows the eﬀective simulation speed of the system equipped with our NoC debug solution, using a snapshot interval of 10 cycles and while varying the local check sampling 562 rate. The eﬀective simulation speeds only take into account the overhead of the local checks triggered during each run. For the random traﬃc, we vary the injection rate from low injection (when the network is close to zero-load latency) to high injection (before network saturation). Without sampling, the platform’s eﬀective simulation speed is 38MHz for the random traﬃc and 359MHz for the PARSEC benchmarks on average. However, with sampling, the platform’s eﬀective speed can be increased to an average of 130MHz and 660MHz respectively. Overall, this performance is still several orders of magnitude better that what can be achieved in pre-silicon, all while providing much better observability and debug information than traditional post-silicon solutions. Moreover, performance can be boosted further by sampling. We also evaluated the eﬀect of varying the snapshot interval on the platform simulation speed, for a ﬁxed sampling rate of 20%. With higher snapshot intervals, local checks are invoked less frequently and the overall eﬀective speed of the simulations is higher. This can be observed in Figure 7. For example, when the snapshot interval is increased from 10 cycles to 50 and a 100 cycles, we observe an increase in the simulation speed of bitcomp traﬃc by a factor of 3 and 7, respectively. However, as explained in Section 5.2, a larger snapshot interval reduces the observability of in-ﬂight packets and the ability to reconstruct their paths. A similar trend is observed for the uniform and PARSEC workloads. However, note that for low injection, increasing the snapshot interval might not be feasible, as was the case of the PARSEC benchmark that would never trigger a local check. Since the snapshot interval and the local check sampling rate constitute a trade-oﬀ between the execution speed of our post-silicon validation platform and its ability to detect and diagnose errors, we propose making them conﬁgurable parameters that can be tuned depending on workloads and traﬃc patterns. 5.4 Area We also evaluated the area overhead of the router modiﬁcations that are needed to capture the local snapshots. The router additions are described in Section 4.1 and illustrated in Figure 3. We synthesized the modiﬁed baseline router with the Artisan 45nm target library. The baseline router area was 0.075mm 2 and the area overhead is 9%. 6. PLATFORM PARAMETERS Our solution provides high observability and debug information. However, some of its aspects have limitations. For instance, the snapshot interval may aﬀect the ability to detect transient bugs, such as misroute and starvation. Moreover, depending on when the local logs ﬁll up and trigger a local check, it is possible for the platform to miss a livelock bug, if a livelock cycle does not complete within the logging epoch or a starvation bug if the bug manifests very close to the end of an epoch. Note, however, that good tuning of the several parameters available can overcome most or all of these situations. Moreover, multiple runs of a same test with diﬀerent parameter settings can also boost the detection capabilities of the solution. For instance, misroute and starvation bugs are best detected with a small snapshot interval. Moreover, a larger local check sampling rate improves the platform’s detection accuracy, but decreases the eﬀective execution speed. Finally, the designated portion 563 of the cache reserved for the local logs is another parameter which must be tuned. Benchmarks with lower injection rates may require a smaller storage to trigger the local check frequently enough to detect errors. Note also that although we utilize a portion of the cache to store the logs, this does not hinder the value of our solution. In fact, the smaller available cache space would likely generate more traﬃc and better exercise the network, since conﬂict and capacity misses would be more pronounced. 7. CONCLUSION We presented a post-silicon solution to support the functional veriﬁcation of networks-on-chip by increasing the observability of the network’s internal operation and providing debug information to facilitate the diagnosis and debugging of errors. Our platform targets functional errors that prevent the network from making correct forward progress, such as deadlock, livelock and starvation errors. Routers periodically take snapshots of packets traversing them and log these snapshots in a reserved portion of each processor’s local cache. When the space allocated for the logs is exhausted, a software algorithm running on each cores examines its local snapshot log for incorrect packet behavior. Once an error is detected, the local logs are combined and additional debug information is extracted. Results show that our debug platform can eﬀectively collect information critical to the detection and diagnosis of functional errors during post-silicon validation. Acknowledgments. The authors acknowledge the support of the Gigascale Systems Research Center, one of six research centers funded under the Focus Center Research Program (FCRP), a Semiconductor Research Corporation entity. 8. "
2012,Distributed memory interface synthesis for Network-on-Chips with 3D-stacked DRAMs.,"Stacking DRAMs on processing cores by Through-Silicon Vias (TSVs) provides abundant bandwidth and enables a distributed memory interface design. To achieve the best balance in performance and cost in an application-specific system, the distributed memory interface should be tailored for the target applications. In this paper, we propose the first distributed memory interface synthesis framework for application-specific Network-on-Chips (NoCs) with 3D-stacked DRAMs. To maximize the performance of a selected hardware configuration, the proposed framework co-synthesizes the hardware configuration of the distributed memory interface, and the software configuration, e.g. task mapping and data assignment. Since TSVs have adverse impact on chip costs and yields, the goal of the framework is minimizing the number of TSVs provided that the user-defined performance constraint is met.","Distributed Memory Interface Synthesis for Network-on-Chips with 3D-Stacked DRAMs Yi-Jung Chen Dept of Computer Science and Information Engineering National Chi Nan University Nantou County, Taiwan Email: yjchen@ncnu.edu.tw Chi-Lin Yang Dept of Computer Science and Information Engineering National Taiwan University Taipei, Taiwan Email: yangc@csie.ntu.edu.tw Jian-Jia Chen Institute for Process Control and Robotics Karlsruhe Institute of Technology Karlsruhe, Germany Email: jian-jia.chen@kit.edu Abstract—Stacking DRAMs on processing cores by ThroughSilicon Vias (TSVs) provides abundant bandwidth and enables a distributed memory interface design. To achieve the best balance in performance and cost in an application-speciﬁc system, the distributed memory interface should be tailored for the target applications. In this paper, we propose the ﬁrst distributed memory interface synthesis framework for application-speciﬁc Network-on-Chips (NoCs) with 3D-stacked DRAMs. To maximize the performance of a selected hardware conﬁguration, the proposed framework co-synthesizes the hardware conﬁguration of the distributed memory interface, and the software conﬁguration, e.g. task mapping and data assignment. Since TSVs have adverse impact on chip costs and yields, the goal of the framework is minimizing the number of TSVs provided that the user-deﬁned performance constraint is met. I . IN TRODUC T ION 3D die-stacking uses the low-latency and high-density ThroughSilicon Vias (TSVs) as the vertical interconnects to stack several active devices on the same chip in the third dimension [18]. Since 3D die-stacking provides large bandwidth and the ability of mixing different process technologies, several works have been proposed to stack DRAMs directly on top of Processing Elements (PEs) to attack the memory bandwidth issue of many-core architecture [8], [11], [12], [17]. For example, targeting at Tier-1 server applications that exhibit a high degree of thread-level parallelism, Kgil et al. [8] propose the PicoServer architecture that employs 3D technology to bond one die containing several simple processing cores to multiple DRAM dies. In [11], Loh et al. investigate the performance beneﬁt of 3D-stacked architectures that employ more aggressive and highly parallel memory organizations enabled by the 3D technology. To utilize the abundant bandwidth of stacked DRAMs, the memory interface can be composed of more than one DRAM memory controller (MC) [11], [12]. This forms a distributed memory interface design. Fig. 1 shows a generic distributed memory interface design on a Network-on-Chip (NoC) with stacked DRAMs [12]. The bottom layer is an NoC that is partitioned into regular tiles and connected by a 2D mesh network. Each tile has a PE, an MC, a scratch-pad memory (SPM) module and a router. One or more DRAM layers are stacked Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2012, November 5-8, 2012, San Jose, California, USA Copyright c(cid:2) 2012 ACM 978-1-4503-1573-9/12/11...$15.00 DRAM Layers TSV Bus Network-on-Chip R MC PE Fig. 1. An example of NoCs with 3D-stacked DRAMs. on top of the NoC. Each PE can directly access the DRAM module that is stacked on top of it by its local MC and the vertical TSV bus. PEs can also access DRAMs on top of other PEs by transferring requests and data through horizontal NoC links. Therefore, the time for a PE to access a DRAM module is decided according to the horizontal distance between the PE and the MC to access the DRAM module, and the vertical distance between the MC and the DRAM module. So, NoCs with 3D-stacked DRAMs and distributed memory interface is a Non-Uniform Memory Access (NUMA) design. With the distributed memory interface in 3D-stacked DRAMs, it opens up a new design dimension in the memory subsystem. In a generic distributed memory interface design, each PE has a dedicated MC and all MCs are associated with the same number of TSVs. However, in an application-speciﬁc system, there exists an optimization opportunity to tailor the distributed memory interface design to the need of the target applications. Massive TSVs provide abundant bandwidth but the implementation of TSVs requires extra manufacturing cost and silicon area [16]. Research also shows that chip yields decrease as the number of TSVs in a chip increases [14]. Equipping an MC for each PE eliminates the interferences among memory requests issued from different PEs, and shortens the memory access latencies. However, an MC requires a lot of resource since it is composed of a read queue, a write queue, a command queue and the TSV array that provides vertical lines for control signals and the data bus to the stacked DRAMs. Therefore, for a 3D integrated processor-DRAM system to go into the mainstream market, a systemlevel synthesis tool to design the distributed memory interface of NoCs with stacked DRAMs is necessary. In this paper, we propose the ﬁrst distributed memory interface synthesis framework for application-speciﬁc NoCs with stacked DRAMs. The conﬁguration of the distributed memory interface includes the number of MCs, and the TSV data bus width of each MC. As mentioned earlier, an NoC with 3D-stacked DRAMs and distributed memory interface is a NUMA architecture, therefore, to maximize the performance of a selected hardware conﬁguration of the distributed memory interface, the software conﬁguration, e.g. task mapping and data assignment, should also be synthesized 458 NORMA L I Z ED EX ECU T ION T IM E O F TWO SO F TWAR E CON FIGURAT ION S A P P L I ED TO THR E E D I S T INC T M EMORY IN T ER FAC E CON FIGURAT ION S . TABLE I 4-MC × 128-bit 1 1.19 SW Arch. 1 SW Arch. 2 8-MC × 64-bit 1.01 1 16-MC × 32-bit 1.02 1.01 accordingly. Therefore, our synthesis framework co-synthesize the hardware conﬁguration of the distributed memory interface, and the design of task mapping and data assignment at the same time. The optimization goal of the synthesis framework is to minimize the total number of TSVs allocated in the system provided that the performance constraint is met. We ﬁrst evaluate the proposed framework on a set of synthetic task sets. The experimental results show that, task sets with different bandwidth demands do result in different hardware conﬁgurations of the distributed memory interface. For the tested synthetic task sets, TSVs varies from 1160 to 2256 in a 4 × 4 NoC. The experimental the number of MCs varies from 8 to 16, and the total number of results also show that, compared to a full-blown memory interface conﬁguration (i.e, each PE has a dedicated MC, and each MC has the most TSV resource it can have), the proposed synthesis framework achieves up to 50% of TSV cost reduction while the performance degradation is no more than 1%. We also test the proposed framework on real-world task sets, which are composed of communication and multimedia applications [1], [7]. For the real-world task sets, the number of MCs varies from one to two, and the total number of TSVs varies from 144 to 288 in a 4 × 4 NoC when the performance degradation compared to the full-blown conﬁguration is no more than 1%. The rest of this paper is organized as follows. The motivation of designing the distributed memory interface synthesis framework is described in Section II. System speciﬁcation and formal problem formulation are described in Section III. The proposed distributed memory interface synthesis framework is presented in Section IV. The experimental results are discussed in Section V. We brieﬂy review the related works in Section VI, and Section VII concludes the paper. I I . MOT IVAT ION The target synthesis problem is challenging since many factors interplay with one another when deciding the conﬁguration of the distribution memory interface for the target applications. First, since the target architecture is a NUMA organization, for the same set of applications, different software conﬁgurations would favor different distributed memory interface designs. We quantitatively demonstrate this effect by generating two different software conﬁgurations for a synthetic task set, and applying these two software conﬁgurations to three different distributed memory interface designs. The performance comparison is shown in Table I. For each of the software conﬁguration, the execution time of each hardware/software design is normalized to the best case. We can observe that, for the two software conﬁgurations, the hardware conﬁguration that achieves the best performance differs from each other. This shows that it is critical to co-synthesize both the hardware and software conﬁgurations for NoCs with 3D-stacked DRAMs and distributed memory interface. Second, to synthesize the memory interface, it does not solely depend on the total bandwidth requirement of the target task set. Memory access patterns of the target task set play an important role for deciding MC allocation (e.g., the number of MCs allocated in the system) and the number of TSVs for each MC. In general, compared to a task set that have most of the tasks issue lots of data accesses, the task set that have only a few tasks issue the majority of data accesses may need fewer MCs. To quantitatively demonstrate this, we create two synthetic task sets that have the same total bandwidth requirement, but different memory access patterns. The two task sets both have sixteen distinct execution paths. Task Set One is designed to have tasks on all execution paths issue the same amount Task Set One:  Tasks on All 16 Paths Evenly Issue Data Accesses  Task Set Two: Tasks on 4 Paths Issue 75% of Data Accesses in the Task  Set  4 4 3 2 2 1 0 0 1 08 1.08 1.06 1.04 1.02 1 0.98 0.96 e m i T n n o i t u c e x E d e z i l l a m r o N N e m i T n o o i t u c e x E E d e z i l a m m r o N Fig. 2. Normalized execution times of Task Set One and Task Set Two with various memory interface conﬁgurations. of data request. Task Set Two is designed to have tasks on four of the execution paths to generate 75% of data accesses issued by the task set. We apply the two task sets to several distributed memory interface designs. Fig. 2 shows the results of task set execution times that are normalized to the results of using the memory interface that has 16 MCs and each MC has 128-bit TSV bus (16MCs*128-bit), which is the conﬁguration that utilizes the most resources among all conﬁgurations. The left most bars in Fig. 2 are the results of utilizing the least resources in the memory interface. We can observe that, the conﬁgurations that achieve the execution times that are closest to the 16MCs*128-bit conﬁguration and utilize the least resources are 16MC*32-bit and 4MC*128-bit for Task Set One and Task Set Two, respectively. Both conﬁgurations need total of 512 TSVs for TSV data buses, but different number of MCs. This shows that, the memory access pattern of a task set plays an important role in the design of the distributed memory interface. I I I . SY S T EM S P EC I FICAT ION AND PROB L EM FORMU LAT ION In this section, we present the models used in this paper to describe the application sets and the target NoC platform. We also present the formal problem formulation of the proposed distributed memory interface synthesis framework. A. Application Model In our algorithm, a task set is represented by a data ﬂow graph (DFG), which is assumed as a directed acyclic graph (DAG). A DFG is denoted by G =< V , E >, whereV is the set of tasks and E is the set of directed edges. A task is a kernel function of an application, and a directed edge indicates the transfer of a data block, which is a collection of scalars or arrays [15]. Suppose that the set of the data blocks is D , in which size(di ) indicates the size (in bits) of a data block di in D . We have the following properties of a DFG: • Each vertex vi ∈ V is associated with c(vi ), which denotes the • Each ei = (vk , v(cid:2) ) ∈ E (cid:2) ∅ is associated with d(ei ), which number of cycles that vi executes on the reference PE. indicates the data block that is transferred from task vk to task v(cid:2) . If vk or v(cid:2) is in ∅, edge ei presents the action of storing d(ei ) to the memory or retrieving d(ei ) from the memory . We do not constrain ourself for one application in a DFG, in which there may be more than one vertex without incoming edges. We adopt List Scheduling [2] to schedule tasks allocated on the same PE. In List Scheduling, tasks are scheduled according to their precedence relations and priorities. We assume the priorities are given by system designers in advance. 459         (cid:198) MC R PE R PE PE Layer DRAM PE Layer DRAM Fig. 3. Illustration of trading the transistor budget of an MC in a tile to enlarge the SPM module. B. Architecture Model As shown in Fig. 1, the target architecture is composed of an NoC, and one or more stacked DRAM layers. The two kinds of layers are connected by a distributed memory interface composed of memory controllers (MCs) and TSVs. The NoC composed of m × n regular tiles is modeled by an Architecture Graph N =< T , L >, which is adirected graph, where T = {t1 , ......, tm×n } is the set of tiles and L is the set of links between tiles. Each link li,j ∈ L represents a link connection between ti and tj and is associated with w(li,j ) that denotes the link width of li,j . Here, we assume all links have the same width, which is denoted by w . Link latency is scaled to 1 for the simplicity of presentations. This paper considers a set of homogeneous PEs in the logic layer architecture. Each tile contains the resources for a PE, an SPM module, an MC with a TSV array, and a router. As mentioned in Section I, an MC module requires a lot of resource. If it is not necessary to use an MC, as shown in Fig. 3, we can reconﬁgure the tile to utilize the resources so that the capacity of the SPM can be increased. However, as there is no MC in this case, the PE in this tile needs to access remote MCs for DRAM accesses. Assume C apSP M base is the baseline capacity of the SPM on a tile, and C apSP M add is the SPM capacity that an MC module can be traded for. Therefore, if there is no MC in the tile ti , the capacity of the SPM in ti , which is denoted by C apSP M (ti ), is C apSP M base +C apSP M add . The access latency of an SPM module is denoted by λSP M . We assume the DRAMs are arranged in regular tiles [17], where the number the DRAM tiles is the same as the number of NoC tiles. Let R = {r1 , ..., rm×n } be the set of tiles in the stacked DRAMs. Each DRAM tile ri is located on top of the NoC tile ti . The total DRAM size is denoted by C apDRAM total . The capacity of the DRAM tile ri , which is denoted by C apDRAM (ri ), is equal to C apDRAM total /(m × n). λDRAM denotes the access latency of a DRAM module. In the target architecture, we assume the stacked DRAMs, SPMs, and the off-chip memory share the same address space. The conﬁguration of the distributed memory interface is speciﬁed by the number of MCs allocated in the system, the tile position of each allocated MC, and the TSV data bus width of each MC. In this paper, as shown in Fig. 4, we assume an MC controls a speciﬁc share of stacked DRAM tiles. Fig. 4 shows an example of having ﬁve eligible MC conﬁgurations for a 4 × 4 NoC for selection. We use N MC = {nmc1 , ..., nmcx } to denote the set of eligible MC conﬁgurations based on the NoC architecture. Each nmci in N MC is a binary array of m × n elements. If the j -th binary element in nmci is 1 (i.e., nmci (j ) = 1), an MC is allocated in tile tj when nmci is selected. In this case, the capacity of the SPM on tj , denoted by C apSP M (tj ), isC ap SP M base . Ifnmc i (j ) is 0, no MC is allocated in tj and C apSP M (tj ) is C apSP M base + C apSP M add . We use |nmci | to denote the number of MCs allocated in the system when nmci is selected, which is also the number of 1’s in nmci . As shown in Fig. 4, for a DRAM tile, the tile position of the MC that controls the DRAM tile changes with the MC conﬁgurations. Here, we use mcnmci (rj ) to denote the tile that contains the MC that controls the DRAM tile rj when nmci is selected. For each tile in T of the NoC architecture N , we useB = {b1 , ...bm×n } to denote the vertical bus width of each tile. With larger bj , tj has higher DRAM bandwidth. Due the area constraint, an MC can only have a limited TSV data bus width. We use Bmax to denote the maximum TSV data bus width that an MC can have. 1 MC Config g 8 MC Config 2 MC Config 16 MC Config 4 MC C fi 4 MC Config Fig. 4. Five eligible DRAM partitions and MC allocations in a 4 × 4 NoC with 3D-stacked DRAM tiles. TABLE II VAR IAB L E S U S ED IN TH E SY S T EM MOD E L . G V E D size(di ) c(vi ) d(ei ) N T L w C apSP M base C apSP M add C apSP M (ti ) λSP M R C apDRAM total C apDRAM (ti ) λDRAM N MC nmci ∈ N MC |nmci | (rj ) mcnmci B Bmax Application Model G =< V , E > denotes the data ﬂow graph V = {v1 , ...} is the set of vertexes or tasks in G E = {e1 , ...} is the set of directed edges in G D = {d1 , ...} is the set of data blocks accessed by G Size (in bits) of data block di ∈ D Number of cycles used when vi executes on reference PE Data block that is transferred by ei ∈ E Architecture Model N =< T , L > denotes the target NoC T = {t1 , ..., tm×n } is the set of tiles L= {li,j , ...} is the set of NoC links Width of the NoC links Baseline capacity of an SPM module SPM capacity that an MC can be traded for Capacity of the SPM module at tile ti Access latency of an SPM module R = {ri , ..., rm×n } is the set of DRAM tiles Total DRAM capacity of the target platform Capacity of DRAM tile ti Access latency of a DRAM module N MC = {nmc1 , ...} is the set of eligible MC conﬁgurations A binary array of m × n elements to indicate if each tile has an MC Number of MCs allocated when nmci is selected The tile that contains the MC that controls DRAM tile rj when nmci is selected. B = {b1 , ...bm×n } indicates the TSV data bus width of each tile the maximum TSV data bus of an MC B , the total number of TSVs (NT SV ) allocated in the NoC includes For a selected MC conﬁguration that is composed of ncmi and (1) total number of TSVs allocated for the vertical buses of allocated MCs, and (2) the number of control lines K (nmci ) (i.e., for address and control signals) of allocated MCs. Therefore, (cid:3) tj ∈T NT SV = bj + K (nmci ). (1) Let Nctrl denote the number of control lines required by an MC. Then, K (nmci ) is modeled as K (nmci ) = Nctrl ∗ |nmci |. The variables used to describe the system model in this paper are listed in Table II. C. Problem Formulation For such distributed memory interface platforms, we study an optimization problem to consider the hardware conﬁguration, e.g. number of MCs and TSV data bus width of each MC, and the software conﬁguration design, e.g. task mapping and data assignment. The formulation of the distributed memory interface synthesis problem for NoCs with 3D-stacked DRAMs is deﬁned as follows: 460 (cid:3) (cid:3) dk ∈D and ω(dk )=tj For every DRAM tile tj in R, Given: Dataﬂow graph G =< V , E >, data block set D , architectural graph N =< T , L >, total DRAM size C apDRAM total , the set of eligible MC conﬁgurations N MC , baseline local SPM size C apSP M base , the extra SPM size C apSP M add that an MC can be traded for , the maximum data bus width Bmax that an MC can accommodate, and the performance constraint Tconstraint . Synthesis targets: The synthesis targets include hardware and software conﬁgurations as listed below. • MC Allocation: Select one and only one MC conﬁguration nmci in N MC . • TSV Data Bus Allocation: Determine the value of each bi ∈ B . If no MC is allocated in tile ti , bi is zero; otherwise, bj is a number that is power of two and 8 ≤ bj ≤ Bmax (since modern computer architecture is byte addressable, the lower • Task Mapping: Map each task vi ∈ V to one of the PEs in lower bound of bj should be eight). ti ∈ T . A taskv i can be mapped to one and only one PE, and we use the function φ : V → T to represent the task mapping results. • Data Assignment: Assign each data block di ∈ D to one and only one of the memory modules. A data block can be assigned to either a DRAM tile ri in R, or an SPM module distributed in the PE tile ti ∈ T . We use the function ω : D → R ∪ T to represent the data assignment results. The total size of data blocks assigned to a memory module should be no more than its capacity. That is, for every tj in T , size(dk ) ≤ C apSP M (tj ). (2) size(dk ) ≤ C apDRAM (rj ). (3) dk ∈D and ω(dk )=rj Objective: Minimize the total number of TSVs (NT SV ) allocated in the system. Constraint: Task execution time Texe of the selected conﬁguration nmci , B , φ and ω , is no more thanT constraint . IV. D I S TR IBU T ED M EMORY IN T ER FAC E SYN TH E S I S A LGOR I THM The design space of the distributed memory interface synthesis problem is huge, and all of the synthesis targets of hardware and software conﬁgurations actually interplay with one another. Therefore, we propose a greedy-based synthesis framework to tackle this problem. Fig. 5 shows the ﬂow of our framework, which focuses on the synthesis of the hardware conﬁguration (i.e., MC allocation and TSV Data Bus Allocation). The software conﬁguration (i.e., Task Mapping and Data Assignment) is then designed for each of the investigated hardware conﬁguration. Our framework ﬁrst performs the MC Number Selection stage to determine which MC conﬁgurations are feasible according to the requirements of the target task set. Next, the TSV Reduction stage minimizes the number of TSVs allocated in each feasible MC conﬁguration. For a hardware conﬁguration that is under evaluation, our framework performs the software conﬁguration synthesis process to decide the conﬁgurations of task mapping and data assignment accordingly. To evaluate the performance of a complete system conﬁguration and decide if a conﬁguration is feasible, we simulate the system behavior by scheduling all the operations that utilize shared resource, such as PEs, routers, memory modules, and on-chip links, according to the given task graph and the selected hardware and software conﬁgurations. Details of the synthesis process to decide the hardware and software conﬁgurations are described in the following sections. Data Block Library Target Platform  Specifications Task graph MC Number  Selection Unevaluated MC  Configurations Left No Select an MC Configuration SW Synthesis Task Mapping Task Mapping Data Assignment Feasible? Yes Keep Configuration No All MC Config. Evaluated TSV TSV Reduction All feasible  MC Config.  Evaluated More MCs for  Reduction Select a Feasible MC  Configuration Reduce TSV Data Bus Reduce TSV Data Bus Width of an MC 0 SW Synthesis Task Mapping Data Assignment Data Assignment No Feasible? Yes K Keep Configuration C fi ti No No MCs for  Reduction Output Solution  Fig. 5. Flow of the Distributed Memory Interface synthesis algorithm. A. MC Number Selection & TSV Reduction More MCs are needed only when more PEs with tasks that have large memory footprint and require lots of DRAM accesses. Therefore, the goal of MC Number Selection is to select a set of MC conﬁgurations that can satisfy the requirement of the target task set. To concentrate on the performance impacts of number of MCs, in this step, we assume the TSV data bus width of each MC is set to Bmax so that we can rule out the performance degradation caused by deﬁciencies of TSV data bus widths. As shown in Fig. 5, for each eligible MC conﬁguration, the software conﬁguration synthesis process is invoked to decide the conﬁgurations of task mapping and data assignment accordingly. The software conﬁguration synthesis process is described in Section IV-B. The complete system conﬁguration is then simulated to see if it is feasible. Only the feasible MC conﬁgurations are kept for the TSV Reduction step for further investigation. Since different task sets may have different access requirements, e.g., more MCs but less TSVs for each MC, or the other way around, all feasible MC conﬁgurations are kept for the TSV Reduction step. The goal of TSV Reduction is to minimize the total number of TSVs allocated in the system. As shown in Fig. 5, for each feasible MC conﬁguration, TSV Reduction gradually reduces the TSV data bus width of each MC in the MC conﬁguration. Since the TSV data bus width is assumed to be power of two, when reducing the TSV data bus width of the MC located in tile tj , bj is set to bj /2. The conﬁguration of reduced TSV data bus width is kept if feasible. For each MC conﬁguration, the process of reducing the TSV data bus width of each MC repeats until no feasible conﬁguration with lower number of TSVs can be found. After the TSV Reduction step, our framework outputs the complete system conﬁguration, including the results of MC Allocation, TSV Data Bus Allocation, Task Mapping and Data Assignment. The pseudo code of MC Number Selection and TSV Reduction is shown in Figure 6. 461 MC Number Selection & TSV Reduction: Input: G =< V , E >, D ={d1 , d2 , ..., dk }, N =< T , L >, N MC = {nmc1 , ..., nmcx }, C apDRAM total , C apSP M base , C apSP M add , Bmax , and Tconstraint Output: An MC conﬁguration nmci , TSV data bus conﬁguration B, task mapping function φ, and data assignment function ω . for each nmci ∈ N MC // MC Number Selection Set all TSV data bus width of each MC to Bmax ; Task Mapping(); Data Assignment(); Evaluate execution time T (nmc i); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 if (T (nmc i) ≤ Tconstraint ) add nmci to NM Cf easible ; for each nmci ∈ NM Cf easible // TSV Reduction done = false; while (done == false) done = true; for each tile tj that has MC if (bj > 8) bj = bj /2; Task Mapping(); Data Assignment(); Evaluate execution time; if feasible done = false; calculate NT SV ; else bj = bj × 2; keep conﬁg. if minimum NT SV ; are also updated. Virtual PEs to Physical PEs is then performed to decide the tile position of each virtual PE. Since virtual PEs with large memory footprints tend to have plenty DRAM accesses, the step ﬁrst sorts all virtual PEs according to their memory footprints of each virtual PE. When the MC conﬁguration nmci is selected, only the |nmci | virtual PEs with the largest memory footprints are allocated to the |nmci | mapped on the rest of |T | − |nmci | tiles. We take this as an initial tiles with MCs. The rest of the virtual PEs are then sequentially solution. However, the initial mapping cannot make sure virtual PEs with lots shared data are mapped to the neighboring tiles. To achieve a better mapping, we ﬁrst need to quantify the quality of a virtual PE to ical PEs (i.e., μ : V P E → T ). We can model the total access latency physical PE mapping. Let μ denote a mapping of virtual PEs to physof data shared by two virtual PEs (denoted by Q(μ)) by Eq.(4) [3]. (cid:3) H (μ(vpei ), μ(vpej )) · SB (vpei , vpej ), (4) Q(μ) = vpei ,vpej ∈VP E (cid:3) where H (μ(vpei ), μ(vpej )) is the Manhattan distance between μ(vpei ) and μ(vpej ). SB (vpe1 , vpe2 ) denotes the total number of bits shared between vpei and vpej , which can be modeled by SB (vpei , vpej ) = min{F (vpei , d), F (vpej , d)}, (5) d∈D where F (vpei , d) represents the number of times that vpei accesses data block d [3]. So, smaller Q(μ) indicates that PEs with shared bits are allocated closer to each other. To get a better mapping, starting from the initial mapping μ, the Virtual PE to Physical PE step swaps two virtual PEs on two different tile positions. A swapping is said feasible if both tiles are with MCs or both are without MCs. By performing a feasible swapping, (cid:3) (cid:3) ) is less than the . When Q(μ we can construct a new mapping μ original Q(μ) after swapping, this swapping is considered effective and, therefore, is taken. The process of swapping is repeated until no further lead to better solutions by any feasible swappings. After the procedure, the ﬁnal mapping μ of virtual PEs to physical PEs is derived and, hence, φ is decided. 2) Data Assignment: The goal of the Data Assignment process is to maximize the performance of the selected hardware conﬁguration by minimizing the total time in data accesses. For a data block d, our framework greedily assigns d to the available memory module that achieves the least total access time. As mentioned earlier, to efﬁciently evaluate the total access time of a data block that is assigned to a memory module, we propose models to evaluate the total time in accessing a data block d when it is assigned to DRAM modules and SPMs, respectively. To access a data block in a DRAM module, requests must be sent to the MC that controls the DRAM module ﬁrst. When transferring data to or from a DRAM module, in addition to the delay of the on-chip network, it also needs the wire delay of transferring data through the TSV data bus and wire between the DRAM tile and its correspondent MC. When accessing an SPM module, requests and data can be directly transferred to the SPM module only through the on-chip network. Therefore, the total access time (L(d)) of data block d when it is assigned to an SPM module at tile tj or a DRAM module rj can be respectively modeled by L(d) = LatDRAM (d) +Lat N oC (d, rj ) LatSP M (d) +Lat N oC (d, tj ) if assigned to DRAM if assigned to SPM. (6) LatDRAM (d) and LatSRAM (d) denote the total time of retrieving/storing data block d from/to the DRAM and SPM modules, respectively. LatN oC denotes the time of transferring d through the on-chip network. We ﬁrst present how to model LatDRAM (d) and LatSRAM (d). Assume we select the hardware conﬁguration composed of MC (cid:4) Fig. 6. Pseudo code of MC Number Selection and TSV Reduction. B. Synthesis of Software Conﬁguration To synthesize the software conﬁguration, the process ﬁrst performs Task Mapping to decide a task should executed on which PE. Then, the Data Assignment step is performed to decide a data block should be stored in which memory module. For the Task Mapping process, we adopt the synthesis ﬂow of the task mapping process proposed in [3], which is designed for NoCs with homogeneous memory architecture, in our framework. To accommodate to our target platform that has heterogeneous memory (i.e., not every tile has an MC, and MCs may have various TSV data bus widths), we modify the detailed steps of the task mapping method proposed in [3]. For the Data Assignment step, we greedily assign data blocks to memory modules with the least data access time. Since we have to evaluate the total access times of a data block assigned to all possible memory modules, we respectively propose data access time models for SPM and DRAM modules to perform efﬁcient data access time evaluations. Details of Task Mapping and Data Assignment steps are described as follows. 1) Task Mapping: The goal of Task Mapping is to exploit the execution parallelism in the target task set, and data reusing among tasks. Moreover, this step also exploits the requirements of DRAM accesses of the tasks. To achieve this, similar to [3], the step ﬁrst exploits execution parallelism and data reuse among tasks to decide which tasks should be mapped to the same PE. Since tasks are not actually assigned to physical PEs in this step, we call this step as Tasks to Virtual PEs. Next, we perform the Virtual PEs to Physical PEs step to decide the physical location of each virtual PE according to the DRAM requirements of each virtual PE, and the data sharing behavior among virtual PEs. In the Task to Virtual PEs step, a task is ﬁrst assigned to a virtual PE vpei ∈ V P E , where V P E is the set of virtual PEs and has its size equal to |T |. Initially, all virtual PEs have no tasks mapped to the vpei ∈ V P E that has the least workload is selected. The task them. One task is mapped to a virtual PE at a time. In each iteration, that is ready for scheduling (i.e. the task that has all its precedent tasks scheduled to a virtual PE) and has the most data shared with vpei is then assigned to vpei . When a task is assigned to a virtual PE vpei , the workload and the set of data blocks accessed by vpei 462 Input: G =< V , E >, D= {d1 , d2 , ..., dk }, Data Assignment: N =< T , L >, selected MC conﬁg. nmcs , C apDRAM , C apSP M base , C apSP M add , Bmax , and Tconstraint Lat(d) =∞; Output: Data assignment function ω . for each di ∈ D 1 2 for j = 1 to m × n 3 4 5 6 7 8 if (C apSP M (tj ) > size(di )) calculate Lattmp (di , tj , SP M ) by Eq.(6); if (S izeDRAM (rj ) > size(di )) calculate Lattmp (di , rj , DRAM ) by Eq.(6); if(Lattmp (di , tj , SP M ) < Lat(d) && Lattmp (di , tj , SP M ) < Lattmp (di , rj , DRAM )) assign di to SPM at tj ; Lat(d) =Lat tmp (d, tj , SP M ); C apSP M (tj ) = C apSP M (tj ) − size(di ); else if(Lattmp (di , rj , DRAM ) < Lat(d) && Lattmp (di , rj , DRAM ) < Lattmp (di , tj , SP M )) assign di to DRAM at rj ; Lat(d) =Lat tmp (di , rj , DRAM ); C apDRAM (rj ) = C apDRAM (rj ) − size(di ); 9 10 12 13 14 16 17 Fig. 7. Pseudo code of Data Assignment. conﬁguration nmci and TSV allocation B , and the Task Mapping φ. Ifd is assigned to DRAM rj controlled by MC mcnmci (rj ), the total time of accessing d is LatDRAM (d) = (H (rj , mcnmci (rj )) + 1 + λDRAM ) × size(d)/bk × Nreq (d), (7) where (H (tj , mcnmci (tj )) is the Manhattan distance between DRAM tile rj and the MC at tile mcnmci (rj ), and the constant one is for TSV data bus. Nreq (d) denotes the total number of times that d is requested. Similarly, if d is assigned to SPM at tile tj , LatSP M (d, tj ) is modeled by LatSP M (d) = (λSRAM × size(d)/w) × Nreq (d). (8) (cid:5)(cid:3) v∈V w is the link width of the on-chip network. We assume SPM modules have the same width as the link width. The on-chip access latency LatN oC is related to the data block size, and the distance between the requesting tile, and the tile with the target SPM module or the MC to access the target DRAM module. Note that, for read operations, we need two on-chip data transfers where one for sending the request to the memory module and the other for transferring the data back. Therefore, given task mapping φ and MC conﬁguration nmci , when d is assigned to a memory module at position tj , the latency LatN oC (d, tj ) can be modeled by (cid:6) LatN oC (d, tj ) = H (φ(v), tj ) × OP (v , d) × size(d)/w, (9) where H (φ(v), tj ) has two cases: (1) if d is assigned to a DRAM module rj on top of tj , H (φ(v), tj ) denotes the Manhattan distance between the requesting tile φ(v) and the tile mcnmci (rj ), which has the MC that controls rj , and (2) ifd is assigned to the SPM module at tj , H (φ(v), tj ) denotes the Manhattan distance between the requesting tile φ(v) and tj . If v reads d, then OP (v , d) is set to 2. For a write operation, OP (v , d) is set to 1. OP (v , d) is set to zero when v never accesses d. size(d)/w is the number of packets needed to transfer d. For each data block d in the data block set D , the Data Assignment process evaluates the time spent in accessing d during executing the task set under various assignments. The process repeats until all data blocks are assigned to a memory module. The pseudo code of the Data Assignment process is shown in Fig. 7. D E TA I L CON FIGURAT ION O F TH E TARG E T 3D NOC P LAT FORM . TABLE III Parameter NoC dimension MC conﬁgurations (MC ) Vertical bus width Router latency Link width On-chip DRAM size (C apDRAM total ) Baseline SPM Size of each PE (C apSP M base ) Trading MC for Extra SPM Size (C apSP M add ) On-chip SPM access latency On-chip DRAM access latency Values 4 × 4 1, 2, 4, 8, 16 MCs max 128-bit for each MC (8, 16, 32, 64, 128 bits) 5 cycles 64 bits 16Mb 16Kb 4Kb 1 cycle 8 cycles V. EX P ER IM EN TA L R E SU LT S A. Experimental Setup The proposed framework is applied to a set of synthetic benchmarks generated by the graph generator TGFF [5]. We generate a random DFG and four random data block libraries with different average sizes of data blocks. The DFG has 50 tasks and parallelism degree of 16. Therefore, we have four task sets, which have the same DFG, but distinct data block libraries that lead to different bandwidth requirements. In the four task sets, the average numbers of bits transfer per edge are 8K, 16K, 32K and 64K bits, respectively. The priority of a task is given according to its distance to the root node. Tasks that are closer to the root node have higher priorities. The priorities of tasks that have the same distance to their root nodes are randomly assigned. In addition to synthetic task sets, we also evaluate the proposed framework on two sets of real-world applications: Consumer+Telecom, and Mpeg2 Enc+Mpeg2 Dec. Consumer+Telecom is the mix of consumer and telecommunication benchmark suites from Embedded System Synthesis Benchmark Suites (E3S) [4]. E3S is a collection of task graphs which are built from the Embedded Microprocessor Benchmark Consortium (EEMBC) benchmark suites [7]. Consumer+Telecom has 42 tasks from applications such as JPEG, auto-correlation, FFT, etc. This is a commonly seen workload mix since existing mobile devices usually supports multimedia and telecommunication applications at the same time. Mpeg2 Enc+Mpeg2 Dec is the mix of Mpeg2 encoder and Mpeg2 decoder [1]. Mpeg2 encoder has 19 tasks to encode a macroblock, and Mpeg2 decoder has 4 tasks to decode a macroblock. To fully utilize the computation resource of an NoC, several independent macroblocks can be processed in parallel [19]. Here, we assume that Mpeg2 encoder and Mpeg2 decoder can respectively process 8 macroblocks in parallel. That is, total of 16 macroblocks are processed at the same time. The detailed conﬁguration of the NoC with stacked DRAMs 4 × 4 NoC, and set the on-chip DRAM size to 16Mb. We assume an platform that is used for experiments are listed in Table III. We use a MC can be traded for extra 4K-bit SPM capacity (C apSP M add =4K bits) considering an MC with a read queue and a write queue, each queue with 4 slots, and each slot has 512-bit storage. According to [12], 64-bit TSV bus width with the necessary control lines takes about 4% to 5% of MC area. Assume we allow the MC to have around 10% of area for TSVs, we can set the maximum vertical data bus width of each MC to 128 bits (Bmax=128). Note that each allocated MC has ﬁxed 16 vertical control lines, where 11 of them are for address and 5 of them are for DRAM controls, such as RAS (16 + 128) × 16) TSVs in our system. and CAS lines [12]. Therefore, we can have maximum of 2304 (i.e., In our experiments, we set the performance constraint Tconstraint of each task to Tconstraint = Tbaseline × (1 + Degradation), where Tbaseline is the task set execution time of the full-blown 463 12 16 1500 1500 2000 2500 r r (cid:3) o (cid:3) f S T V s r r (cid:3) o (cid:3) f S T V s Num.(cid:3)DMCs Num.(cid:3)TSVs(cid:3)(with(cid:3)control(cid:3)lines) 0 4 8 0 500 1000 8K(cid:3) 16K 32K 64K Task(cid:3)Sets(cid:3)with(cid:3)Different(cid:3)Average(cid:3)#(cid:3)of(cid:3)Bits(cid:3)Transfer(cid:3)per(cid:3)Edge (a) o T t a (cid:3) l N u m e b o T t a (cid:3) l N u m e b 0.6 0.5 0.4 0.3 0.2 0.1 0 u d e e R V t c i n o Percentage(cid:3)of(cid:3)TSV(cid:3)Reduction 8K(cid:3) 16K 32K 64K e P n e c r t o e g a (cid:3) (cid:3) f S T (cid:3) Task(cid:3)Sets(cid:3)with(cid:3)Different(cid:3)Average(cid:3)#(cid:3)of(cid:3)Bits(cid:3)Transfer(cid:3)per(cid:3)Edge (b)(cid:3) Fig. 8. Synthesis results of task sets with various average number of bits transferred per edge when the performance constraint is set to 1% degradation compared the baseline: (a) Number of allocated MCs and TSVs, and (b) TSV reduction compared to the baseline. memory interface conﬁguration (i.e, each PE has a dedicated MC with maximum number of TSVs), which is also considered as our baseline conﬁguration, and Degradation is the percentage of performance degradation we can tolerate. Note that, the performance constraint can be set to any other user-speciﬁed criteria. In the synthesis framework, as mentioned in Section IV, we need to evaluate the performance of a conﬁguration that is under investigation. To facilitate efﬁcient execution time estimation, we adopt the greedy scheduling method mentioned in [13]. We model the contention in all shared resources, including PEs, MCs, routers, memory modules, TSV buses, and on-chip network links. According to the selected hardware and software conﬁguration, if there is enough resource for a request, the request is served as soon as it can be executed. Otherwise, a request must be postponed until the requested resource is freed. For task computations, they request for PEs that the tasks are mapped to. For data accesses, several shared resources would be requested, including MCs, DRAM or SPM modules, routers, TSV buses, and on-chip network links. B. Experimental Results We ﬁrst discuss the results of synthetic task sets. Fig. 8(a) shows the results of number of MCs and TSVs synthesized by our framework. Fig. 8(b) shows the percentage of TSV reduction achieved by the proposed framework compared to the baseline memory interface conﬁguration. As mentioned earlier, all the task sets have the same task graph. Different task sets have different average data transfer per edge (ranging from 8K bits to 64K bits), and the performance constraint is set to 1% degradation of the execution time of the baseline. As shown in Fig. 8(a), task sets with smaller average number of bits transferred per edge also needs less MCs and TSVs. The 8Kbit task sets need only 8 MCs while the other task sets needs 16 MCs. Although 16K-bit, 32K-bit, and 64K-bit task sets all need 16 MCs, we can observe that the total number of TSVs of each task set differs from one another. For example, with the 16K-bit task set, 5 MCs need only 64-bit TSV data bus width, while the others need 128-bit TSV data bus. With the 64K-bit task set, only one MC needs 64-bit TSV data bus, and all the other MCs need 128-bit TSV data bus. In Fig. 8(b), we can observe that the proposed framework achieves up to 50% of TSV reduction while the task set execution time is within 1% degradation compared to the full-blown distributed memory interface. We next evaluate how co-synthesizing the hardware and software conﬁgurations affect system performance. In this set of experiments, we use the 8K-bit synthetic task set for evaluation. Our framework synthesized a distributed memory interface with 8 MCs for the task 784 648 580 512 512 512 12 16 500 500 600 700 800 C C s V V s Num.(cid:3)DMC Total(cid:3)Num.(cid:3)of(cid:3)TSVs(cid:3)(with(cid:3)control(cid:3)lines) Total(cid:3)Data(cid:3)TSV(cid:3)Width(cid:3)(without(cid:3)control(cid:3)lines) 0 4 8 0 100 200 300 400 16(cid:882)Path(cid:3)issue(cid:3)all(cid:3) data(cid:3)requests 8(cid:882)Path(cid:3)issue(cid:3)75%(cid:3) data(cid:3)requests 4(cid:882)Path(cid:3)issue(cid:3)75%(cid:3) data(cid:3)requests N u m o e b (cid:3) (cid:3) f D M N u m e b r (cid:3) o (cid:3) f S T Fig. 9. Synthesis results of task sets with the same total data bandwidth, but different degree of concentration. set. We evaluate the performance of two conﬁgurations: (1) the hardware and software conﬁgurations synthesized by our framework (i.e. with co-synthesis), and (2) the hardware conﬁguration synthesized by our framework with the software conﬁguration synthesized for the baseline architecture (i.e. without co-synthesis). We ﬁnd the performance of the second hardware/software conﬁguration is 10.8% worse than the results of co-synthesizing, since the average data access time is longer when the software conﬁguration is not optimized for the selected hardware conﬁguration. Our experimental results show that, for the conﬁguration with co-synthesis, the average hop count of each data access is 0.63 hops, while the conﬁguration without co-synthesis has up to 0.83 hops. As mentioned in Section II, task sets with the same total bandwidth requirements but different memory access patterns may need different distributed memory interface designs. In this set of experiments, we show the proposed framework do synthesize conﬁgurations according to the requirements of task sets. We create three new synthetic task sets with the same total bandwidth requirement, but different memory access patterns. All three task sets have the same data ﬂow graph, which has 16 distinct execution paths that can be executed in parallel. The characteristics of the memory access patterns of the three task sets are, (1) all tasks on all executions issue the same amount of data accesses, (2) tasks on eight of the execution paths issue 75% of data accesses of the task set, and (3) tasks on four of the execution paths issue 75% of data accesses of the task set. The synthesis results of the three task sets are shown in Fig. 9. We can observe that, for task sets that have only a few tasks issuing the most of the data accesses, fewer number of MCs and wider TSV data bus width for each MC are synthesized. This shows the proposed framework correctly synthesize the distributed memory interface according to the characteristics of the memory access pattern of the target task set. We can also observe that the total numbers of TSVs for the TSV data buses in the system are all 512 bits for the three task sets. However, more TSVs are allocated in the system when more MCs are allocated since each MC needs TSVs for control signals. For real-world task sets, we test the proposed synthesis framework on Cosumer+Telecom and Mpeg2 Enc+Mpeg2 Dec. For Consumer+Telecom, when the performance constraint is set to 1% degradation, the proposed framework synthesizes a solution that has only one MC with 128-bit TSV data bus, and achieves 93.75% of TSV reductions compared to the baseline conﬁguration. As mentioned earlier, Mpeg2 Enc +Mpeg2 Dec processes 16 macroblocks at the same time. For Mpeg2 Enc+Mpeg2 Dec, when the performance constraint is set to 1% degradation, our framework synthesizes two MCs and 128-bit TSV data bus for each of the MC. This conﬁguration achieves 87.5% of TSV reductions compared to the baseline. Even 464 CPU T IM E O F SYN TH E S I Z ING A SO LU T ION BY TH E PRO PO S ED FRAM EWORK . TABLE IV Task Sets Task Set 8K Task Set 16K Task Set 32K Task Set 64K Telecom+Communication Mpeg2 Enc+Mpeg2 Dec CPU Time (sec) 0.09 0.09 0.09 0.07 0.17 4.28 CPU Time of Our Framework on Various  Number of Tasks ) c e e s n i ( e m m i T U P C 2 1.6 1.2 0.8 0.4 0.4 0 100 Tasks 150 Tasks 200 Tasks 250 Tasks Fig. 10. Execution time of our framework with task sets that have various number of tasks. though Mpeg2 Enc+Mpeg2 Dec has lots of data accesses, the critical path of Mpeg2 Enc+Mpeg2 Dec spends most of its time on task execution. When the performance degradation is set to 0%, our synthesis framework ﬁnds that only 8 MCs, where each of the MC has 128-bit TSV data bus, are needed, not the generic conﬁguration with the most number of MCs and TSVs that a system can have. The proposed synthesis framework can efﬁciently synthesize a feasible solution in a short time. The CPU times of synthesizing various task sets by our framework are listed in Table IV. To show the scalability of the proposed framework, we use our framework to on a 4 × 4 PE conﬁguration. The number of edges ranges from 143 synthesize random task graphs with 100, 150, 200, and 250 tasks to 356. The results are shown in Fig. 10. Our framework does need more time for larger task sets. However, the longest execution time is no more than 2 seconds. V I . R E LAT ED WORK Several research works focus on designing the system architecture with 3D die-stacking technology. Kgil et al. [8] proposed PicoServer, a CMP architecture that employs 3D technology to bond one die containing several simple slow processing cores to multiple DRAM dies sufﬁcient for a primary memory. Since TSVs enables the wide and low-latency DRAM buses and provide sufﬁcient memory bandwidth, in [8], they proposed to remove the large shared L2 cache, and replace by more additional simple processing cores to allow more threads executing in parallel. In [10], Lui et al. showed that stacking DRAM on processor cores achieves lower memory access latency and system energy consumption, when comparing to traditional 2D systems that has DRAM as an off-chip memory. In [17], Woo et al. proposed to re-architect the memory hierarchy, including the L2 cache and DRAM interface, so that it can take full advantage of the massive bandwidth of 3D die-stacking. Loi et al. [12] targeted MPSoCs with stacked DRAMs and propose a distributed memory controller architecture. Since 3D die-stacking is an emerging technology, a complete model on the tradeoffs of using the technology is helpful to system designers. Weerasekera et al. [16] discussed realistic metrics for performance and cost trade-offs both at implementation phase and conceptual level for veriﬁcation in the 3D integration technology. Kim et al. [9] studied the impact of TSV on various aspects of 3D layouts, including the silicon area of TSV, wire length and TSV count. Dong et al. [6] proposed a system-level cost analysis tool to help designers to determine if the 3D integration method is a cost effective technology for a particular IC design. V I I . CONC LU S ION In this paper, we propose the ﬁrst distributed memory interface synthesis algorithm for NoCs with stacked DRAMs. The proposed algorithm simultaneously synthesizes the number of MCs, the vertical bus width of each allocated MC, task mapping and data assignment. The goal of the proposed framework is to minimize system TSV cost while the user-deﬁned performance constraint is met. Compared to the baseline architecture that has every PE with an MC and each MC with the maximum vertical TSV bus width that an MC can have, for the synthetic task sets, the experimental results show that the proposed algorithm achieves up to 50% TSV cost reduction while the performance degradation compared to the baseline is no more than 1% for a set of synthetic task sets. For the real-world task sets, the proposed framework synthesizes the memory interface conﬁgurations that have one to two MCs and total of 144 to 288 TSVs. ACKNOW L EDGM EN T S This work was partially supported by the National Science Council of Taiwan under Grant Nos NSC 101-2220-E-002-017- and NSC 101-2221-E-260-037-, Etron Technology Inc. 101R7500, Excellent Research Projects of National Taiwan University 101R890822, and Industrial Technology Research Institute of Taiwan (ITRI) 101-EC17-A-01-05-0337. benchmark consortium. "
2012,Accurate on-chip router area modeling with Kriging methodology.,"Networks-on-chips (NoCs) have emerged as an effective interconnection solution for modern MPSoCs. However, NoCs are characterized by a wide range of parameters and early performance estimations have become keys. We propose an approach to build static cost models (e.g. area) of NoC components. The modeling relies on Kriging theory, which catches the complex interactions between parameters on the basis of few low-level results. Experimental results show that the produced model has a good level of accuracy and a predictable behavior.","Accurate On-Chip Router Area Modeling with Kriging methodology Florentine Dubois ST Microelectronics and TIMA laboratory, CNRS/Grenoble INP/UJF Grenoble, France ﬂorentine.dubois@st.com Valerio Catalano Marcello Coppola ST Microelectronics Grenoble, France valerio.catalano@st.com marcello.coppola@st.com Frederic Petrot TIMA laboratory, CNRS/Grenoble INP/UJF Grenoble, France frederic.petrot@imag.fr ABSTRACT Networks-on-chips (NoCs) have emerged as an eﬀective interconnection solution for modern MPSoCs. However, NoCs are characterized by a wide range of parameters and early performance estimations have become keys. We propose an approach to build static cost models (e.g. area) of NoC components. The modeling relies on Kriging theory, which catches the complex interactions between parameters on the basis of few low-level results. Experimental results show that the produced model has a good level of accuracy and a predictable behavior. Categories and Subject Descriptors B.8.2 [Performance and Reliability]: Performance Analysis and Design Aids; I.6.5 [Model Development]: Modeling methodologies General Terms Design, Experimentation, Performance, Measurement Keywords networks on chip, spidergon stnoc, performance estimation, response surface method, kriging theory, design space exploration 1. INTRODUCTION To handle the increasing demand for functionalities and performance, the number of processing elements integrated in System-on-Chips (SoCs) keeps growing. In this context, Networks-on-Chips (NoCs) [7] have emerged as a promising interconnection solution in both general-purpose architecture and embedded ﬁelds. NoCs are able to handle highbandwidth and scalability needs under tight performance constraints. However, they are usually characterized by a vast number of architectural and implementation parameters (e.g. topology, FIFOs depths), resulting in a huge dePermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2012, November 5-8, 2012, San Jose, California, USA Copyright 2012 ACM 978-1-4503-1573-9/12/11 ...$15.00. sign space (i.e. set of all possible conﬁgurations). Moreover, the eﬀects of the conﬁguration on performance, power or area are very complex to fully characterize as all those properties are tightly inter-correlated. The ﬁnal conﬁguration must then ensure an acceptable tradeoﬀ between the diﬀerent evaluation metrics. In this context, the optimization loop (operation in which the designer improves iteratively the system conﬁguration until the performance constraints are met) becomes a critical step in SoCs design; indeed, the design space exploration should be performed as quickly as possible to improve the overall SoC’s time-to-market. However, the performance evaluation complexity and design modiﬁcations cost increase drastically in low-level contexts (e.g. RTL, gate level). Deﬁning high-level performance evaluation methods that can be applied early is then mandatory to explore quickly and at low-cost the design space [8, 20]. NoCs high-level evaluation methods have been widely studied during the last few years. Two approaches have emerged: the ﬁrst trend is to develop a speciﬁc architecture model; examples are Orion 2.0 [15] or the work of Balfour et al [3]. Those approaches give highly-accurate performance estimations but the eﬀects of the technology used in the implementation are diﬃcult to characterize. A second approach is the development of analytical models. Those methods are based on mathematical approaches and give very fast evaluations of performance with low modeling cost. Such works are numerous in the literature; as examples we give the article of Hu et al [10] and Nikitin et al [19] for mean and worst latency estimations, Menoli et al [18] for power and area estimations and ﬁnally Hu and Marulescu for automatic buﬀer depths computation [9]. However, the accuracy of the results is generally low as those models are limited to information available at high-level. An improved approach to overcome this last issue is to construct an analytical model based on low-levels synthesis and simulations results. The outcome of this approach is to get the same advantages than purely theoretical approaches, but with a higher accuracy. Moreover, the underlying architecture is generally considered as a black-box. Ipek et al [11] propose a mechanism to evaluate CPUs performance based on artiﬁcial neural networks (ANNs). Several subsets of conﬁgurations are simulated and used to train the neural networks which are then able to estimate performance for all conﬁgurations with a high-accuracy. This method is effective in huge design spaces but presents a high-complexity. Chan and Parameswaran model the relationship between a router power consumption and signals switching by a lin450 ear regression [5]. Bona et al [4] propose to construct an industrial component (STMicroelectronics’s STBus) power model; their method uses the simulation results of an initial subset of conﬁgurations to apply several interpolation and regression methods and the diﬀerent produced models are then compared. The power estimation is general; however the proposed sampling strategy is speciﬁc to the STBus family. A similar approach is given in [12, 14], with the Multivariate Adaptive Regression Splines (MARS) method. MARS estimates the target function as a weighted sum of basic functions and is a ﬂexible and eﬀective method to model complex target functions. However in this last work, the design space is limited to a small subset of parameters. In this paper, we propose a ﬂow based on the same principle and which relies on Kriging theory [21] to interpolate cost models. Kriging theory has the particularity to model the target function as if it was the realization of a stochastic process. It was already successfully applied in NoC context to perform an automatic research of an optimal platform conﬁguration according to multiple ob jectives [17]. Our method adopts a divide and conquer strategy: the diﬀerent components are modeled one-by-one independently of each-others, and the results are then combined to obtain a global estimation. The main contributions of this article are given below. • We present a fully-automated and general ﬂow which constructs evaluation metric predictors for any parametric components typically found in NoC design. The ﬂow takes into account conﬁguration constraints and is eﬀective in vast design spaces and in the presence of highly non-linear parameters; • The produced cost model is an analytical expression which gives an evaluation for all possible conﬁgurations with a good accuracy. The method does not require any assumption on the underlying architecture and is eﬀective over a basis of very few training conﬁgurations. Moreover, our results show that the model has a predictable behavior and correctly catches the complex interactions among parameters and their importance in the target function; • An error estimation can be derived to give further information about the results accuracy to the designer; • As an example, we model the area of a highlyparametric on-chip generic router with diﬀerent methods and provide a discussion on the results according to accuracy and modeling complexity. The proposed method is applicable to static NoC properties. Dynamic properties require the introduction of traﬃc and/or latency data and are considered out of the scope of this paper which aims at presenting the modeling ﬂow and the Kriging theory. This extension is thus let to later research. For some examples on how the extension could be driven, the reader can refer to [4, 14, 16]. The paper is organized as follows: Section 2.1 presents a generic router architecture that will be used as an example to present the eﬃciency of the method. The section 2.2 describes the ﬂow and the modeling method proposed. Some experimental results are given in section 3 and section 4 concludes the paper. Figure 1: Router architecture (rd = 4, nv = 2) Router Port Parameter Router degree Flit size Parameter FIFO buﬀer depth Number of VCs Values 1 to rd 16,24,32,64 bits Values 0 to 32 1 to nv Table 1: Generic router parameters 2. MODELING FLOW In the following, we model as an example the area of a generic on-chip router architecture; however the extension to other static performance metrics and components is straightforward. We choose to model the logic gates area, as it provides a preliminary estimation of the area after place and route at lower cost and is often used as a metric to compare platforms in industrial contexts. However, this operation is long (from some hours to some days depending on the platform size) and exploring the diﬀerent possibilities of conﬁgurations with this method remains too costly. Providing a highlevel and accurate estimation of the logic area can then effectively lead designers in their design space exploration at very low cost. The main ob jective of the ﬂow is thus to obtain a fast estimator with a good accuracy in very vast design spaces. 2.1 Generic NoC router 2.1.1 Router Architecture NoCs components are characterized by a great ﬂexibility and are thus diﬃcult to model as a whole. We present in this section a general virtual-channel (VC) router architecture that will be used to illustrate the methodology. The router was chosen as it is parametric enough to cover many of possible behaviors and irregularities in typical NoC design spaces and as it can demonstrate the eﬀectiveness of the proposed model for a very large number of possible conﬁgurations. The router architecture is shown in ﬁgure 1; parameters 451 considered in the method are micro-architectural parameters that have an inﬂuence on the component implementation and which are of interest at system-level. The router implements wormhole routing and incoming ﬂits are handled according to a credit-based ﬂow control. Routing and arbitration schemes are dependent on the technology. The router degree, the number of virtual channels implemented in each port and the ﬂit size are all conﬁgurable. One FIFO buﬀer is allocated for each virtual channel in both input and output ports and their size are additional micro-architectural parameters. Connectivity between input and output ports is provided by one central crossbar per implemented virtual channel. Those parameters and an overview of their usual possible values are summarized in Table 1, where rd and nv are constants determined by the technology. As we wish to model the design space as a whole, a model of this component should also take into account that conﬁgurations are sub ject to a set of constraints. In other words, all combinations of parameters are not allowed which lead to a highly irregular design space. Examples of such constraints are that at least one input and one output ports are activated (global constraint), or that the input FIFO buﬀer depth is at least one if the port is activated on the associated virtual channel (port local constraint). 2.1.2 Router Area Model As the router design space is huge, we study its architecture to reduce modeling complexity. However, this study is not mandatory; the ﬂow would be generic enough to model a whole component as a black-box, but the size of the initial conﬁgurations set would be very large to obtain a good accuracy for a highly parametric component like the considered router model. outputi ) be the ith input (resp. Let inputi (resp. output) port, switch be the switch logic according to the notation of ﬁgure 1 and Area(p) be the function that returns the area used by p; in particular Area(p) = 0 if p is a non-activated port or if the corresponding conﬁguration is not allowed. The area can then be estimated as: A = Area(inputi ) + Area(outputi ) + Area(switch) (1) According to this last equation, the total router area can be modeled as the sum of three more speciﬁc area models: input port model (a), output port model (b) and switch model (including routing and arbiters logic) (c). For each model, considered parameters are the ones which have an inﬂuence on the corresponding implementation part. Some parameters may be shared among two models: examples are port activation parameters that are used in both port and switch models. Those three models are built independently of each other with the ﬂow deﬁned in next part and the ﬁnal router model is then derived according to equation 1. 2.2 Modeling methodology The generic modeling ﬂow proposed in this paper is schematized in ﬁgure 2. It is composed of four main steps and takes as input a parametric RTL model of the considered architecture, the varying parameters and their possible values, and a set of constraints which describes forbidden conﬁgurations; input parameters selection is further discussed in section 2.2.1. The model constructed can represent a 452 (cid:32) (cid:124) rd(cid:88) i=0 (cid:123)(cid:122) (a) (cid:125) (cid:124) (cid:123)(cid:122) (b) (cid:33) (cid:125) (cid:124) (cid:123)(cid:122) (c) (cid:125) Figure 2: Modeling ﬂow whole component, or only a part of its architecture. The main steps are: • Choose an initial data set (2.2.2): A small subset of allowed conﬁgurations are chosen in the design space. • Initial data set implementation ﬂow (2.2.3): Each conﬁguration in the initial data set is synthesized through an implementation ﬂow and its area extracted (in kgates). • Model construction (2.2.4): An interpolation method is applied to the initial data set to construct a model able to estimate the area for all possible conﬁgurations. • Model validation (2.2.5): Estimation model hypothesis and accuracy are validated to ensure the model correctness. In the following, we describe precisely each step of the ﬂow. 2.2.1 Inputs parameters selection The list of parameters given as inputs to the modeling ﬂow is a key choice as it directly inﬂuences ﬁnal results. As described above, all system-level parameters that inﬂuences the gate instantiations of the architecture of interest should be considered in the ﬂow to catch the maximum of information on the target function (e.g. area). On the other hand, parameters with very few or no inﬂuence on the resulting area will increase modeling complexity with no signiﬁcant gain on the ﬁnal accuracy. Moreover, additional input parameters may lead to a larger initial data set (depending on the algorithm used to choose its size) and thus to additional synthesis runs. The designer should then carefully choose the considered parameters and in particular ignore those whose are uncorrelated to the architecture instantiation or known to have a negligible inﬂuence on the property of interest (e.g. area). 2.2.2 Initial data set The ﬁrst step of the ﬂow is the choice of an initial subset of conﬁgurations which will be used to apply an interpolation method. The sampling algorithm and the number of points are very important to ensure the model accuracy. Indeed, the initial data set must be large and distributed enough to cover all parts of the design space; a bad repartition in space may decrease largely the ﬁnal accuracy. We choose to use the Latin Hypercube Sample design (LHS) [13, 22] to generate the initial data set. LHS is a cheap statistical method which distributes evenly points in the design space and ensures that all portions of parameters ranges are represented. The initial data set size is left to the user choice. We propose to sum the number of possible values for all parameters as this is a minimum for LHS design; however, this is an experimental choice and the designer may choose higher values to increase accuracy. Usual LHS design implementation does not take into account constraints, and may thus choose forbidden conﬁgurations. A second substep is then the research of a neighbor valid conﬁguration for all invalid points. This ensures that all conﬁgurations in the initial data set are valid without breaking the evenness of the distribution. Forbidden conﬁgurations are thus ignored in the interpolation method to limit the process complexity. 2.2.3 Initial data set implementation ﬂow During the second step, every initial conﬁguration is run through an implementation ﬂow to obtain the associated evaluation metric of interest. In our example, the router RTL model is parameterized according to the current conﬁguration, and a synthesis is then performed to evaluate logic area (in kgates). The implementation parameters used are considered as constants. To estimate other metrics (e.g. static power), other tools can be added as following steps. 2.2.4 DACE stochastic process model The methodology used to model cost functions of NoC components is an interpolation method proposed by D. Jones et al in [13] and which relies on Kriging theory. This approach is usually called DACE stochastic process model, according to the name of the paper that popularized it [21]. DACE approach models the ob jective function as if it was the realization of a stochastic process. The main diﬀerence between DACE method and linear regressions is that DACE approach makes simplistic assumptions about regressors and focuses on correlation between errors, whereas linear regression methods focus on regressors and their coeﬃcients and make simplistic assumptions about errors. DACE is then able to catch the complex interactions between parameters and to estimate their importance in the target function behavior. More formally, let assume that we have a set of points x1 , x2 , . . . , xn of dimension k and y a column of values of a deterministic function at those points. In our context, the points corresponds to the initial conﬁgurations set, k corresponds to the number of considered parameters and the deterministic function is the target cost function (area in our Symbol k n x ∈ M1,k x(h) x1 , x2 . . . , xn y ∈ Mn,1 ˆy(x) (x) θh ≥ 0, ph ∈ [1, 2] R ∈ Mn,n R(i, j ) = corr((xi ), (xj )) r(x) ∈ Mn,1 r(i) = corr((x), (xi )) 1 ∈ Mn,1 , 1(i) = 1 µ = 1(cid:48)R−1 y 1(cid:48)R−1 1 σ 2 = (y−1µ)(cid:48)R−1 (y−1µ) n s2 (x) Description Numbers of parameters Initial conﬁgurations set size Conﬁguration row Value of parameter h in conﬁguration x Initial conﬁgurations set Column of initial conﬁgurations areas Estimated area at x Error at x Correlation distance parameters Correlation matrix Column of correlations at x Column of 1 Estimated mean of stochastic process Estimated standard deviation of stochastic process Predictor mean square error at x Table 2: Mathematical Symbols example). All symbols used in this section are summed up in table 2. The general model expression is: ˆy(xi ) = µ + (xi ) (2) As said above, the regressors are replaced by a simple constant µ and the error (x) depends on the distance between the points of the initial data set and the current point. The main assumptions are to suppose that (x) follows a normal law of mean 0 and that the correlation between errors is not zero. The errors correlation is assumed to be an exponential function applied to a weighted distance. The exponential function is usually chosen for its good mathematical properties [21]. The distance equation is thus: k(cid:88) dist(xi , xj ) = θh |xi (h) − xj (h)|ph h=1 The correlation between errors is then: corr[(xi ), (xj )] = e −dist(xi ,xj ) (3) (4) The distance is a function of parameters θh and ph . θh represents the activity of the parameter h (the bigger θh , the more the function is modiﬁed if we modify parameter h) while ph represents function’s smoothness in the direction of the parameter h. The best predictor equation is: ˆy(x) = µ + r(x) (cid:48) −1 (y − 1µ) R (5) 453 The estimation is in fact a smooth interpolation between values of the nearest points of the initial data set. An estimation of the predictor’s error can be then derived: (1 − 1R−1 r)2 1(cid:48)R−11 s2 (x) = σ2 −1 r + 1 − r (cid:33) (6) (cid:32) (cid:48) R The only remaining question is how to choose the weights θh and ph . A method proposed in [13] is to maximize the likehood to optimize the accuracy: likehood = 1 2 (σ2 ) n (2π) − n 2 (7) 2 (cid:112)|R| e n Dependence on θh and ph are made through the matrix R and σ2 . To sum up, the ﬁnal model is obtained by chosing parameters θh and ph through the maximization of equation 7 before computing R. Final area estimation is eventually given by equation 5. This method was chosen because it does not make any assumption on the target function expression; moreover it is known to give good results on nonlinear and multimodal functions with few training points. However, the ﬁnal accuracy is largely dependent on the initial data set, which has to give enough information to catch the function behavior. 2.2.5 Model Validation Model validation is based on the method described in [13]. The main issue is to validate the assumption that the error term (x) follows a normal law of mean 0. We use cross-validation, which consists of subtracting a point from the initial conﬁgurations set before estimating its value with a new model constructed from the remaining n − 1 points. The estimated value is then compared to the eﬀective one. This method has several advantages, among which the fact that it allows to estimate a model accuracy without the need of a test set. As in [13], we denote with the subscript −i the equations obtained when the conﬁguration i is subtracted from the training set. To validate the model, we compare the eﬀective error and the estimated one according to the next equation: y(xi ) − ˆy−i (xi ) s2−i (xi ) (cid:113) (8) In the following, we call the results of this equation standardized residuals. If the model is valid, the results should be similar to a random sample of n independent normal variables [13]. We check this assumption graphically by performing the quantile-quantile plot (QQ plot) on the standardized residuals for all initial conﬁgurations. If the points roughly lie on a line which crosses the point (0,0), then we can validate the model. Figure 3: Output port QQ Plot with a maximum router degree (rd ) of 5 and a maximum number of virtual channels per port (nv ) of 2. Its associated design space size is about 5e+28 conﬁguration possibilities. The respective design space sizes of the input port, output port and switch models are (a) about 9e+11 possibilities (b) about 2.6e+14 possibilities, (c) about 1.2e+16 possibilities. The corresponding initial conﬁgurations set sizes are respectively (a) 500 points, (b) 620 points and (c) 590 points. The synthesis (step 2) was performed with Synopsis Design Compiler version E-2010.12 [2] with worst-case timing libraries (low power, low leakage) and a target frequency of 600MHz in 32 nm technology. Model construction (step 3) and validation (step 4) were performed with MATLAB tool [1]. 3.1 Model validation The output port model validation is given in ﬁgure 3; the results are similar for the input port and switch models. Most of the points observed in the QQ plot globally lie along a line which crosses the point (0,0). A few extreme points deviate from the line though, meaning that the predictor error is not accurately estimated for those conﬁgurations. However, the relative error between the value estimated during cross-validation and the eﬀective one is small (less than 2%), which means that the model predicts accurately the area at those points. We thus suppose that the model accuracy is little aﬀected by those extreme points; the experimental results given in the next section corroborate this hypothesis. Moreover, the number of points in the initial conﬁgurations set represents a few points in a huge design space; this is enough to obtain a good model precision but the predictor may inaccurately estimate isolated points error. Increasing the initial set size would improve the model accuracy and probably reduce those deviations. The assumption that the standardized residuals of the output port model globally follow a normal law with mean 0 is thus validated. 3.2 Results and Discussion 3. EXPERIMENTAL RESULTS 3.2.1 Metrics The area of the generic router architecture implemented with the Spidergon STNoC technology [6] was modeled with the proposed ﬂow. The Spidergon STNoC technology is a ﬂexible and software-programmable on-chip communication network developed by STMicroelectronics [6]; The Spidergon STNoC router corresponds to the model presented in section 2.1 To compare diﬀerent router models, we need to deﬁne a set of metrics that will be used to give fair quantitative information about predictors. In this section we focus on the model accuracy, however other properties like the process complexity will also be considered in the next section. To validate a model, a test set is created by choosing randomly nerr conﬁgurations (nerr = 600) independent of the 454 Method MAX (kgates) RMSE DACE MARS Quadratic Analytical 5.6744 7.5375 60.8704 105.1696 0.9481 1.1076 10.489 33.9934 Table 3: Output port model Method MAX (kgates) RMSE DACE MARS Analytical Quadratic 24.5677 45.5985 66.8089 209.3518 4.6744 8.1622 12.8829 36.7238 Table 4: Router model Average relative error (%) 2.22 4.63 27.02 44.3 Average relative error (%) 10.14 20.21 38.21 95.33 model initial conﬁgurations set. Each conﬁguration in the test set is then synthesized and the area extracted before being compared to the estimation given by the target model. We use the following usual metrics to compare two models, as proposed in [22]; yi (resp. ˆyi ) represents the eﬀective area (resp. area estimation) of the ith point in the test set: (a) the maximum error, which represents the local predictor error: M AX = max{|yi − ˆyi |}i∈1,...,nerr (b) the root mean square error (RMSE) which represents the global predictor error (the lower the better): i=1 (yi − ˆyi )2 (cid:115) (cid:80)nerr nerr RM SE = (9) (10) In addition to those two usual metrics, we use (c) the average absolute error and (d) the average relative error to provide additional information about the predictor behavior and accuracy. 3.2.2 Results and Discussion The model proposed in this paper is compared to three other models found in the literature. The two ﬁrst models are based on the same principle as our ﬂow, except that the modeling method (step 3) changes. The two comparison models are (1) the method proposed in [12] which uses Multivariate Adaptive Regression Splines (MARS) (2) The method proposed in [4] which uses the well-known quadratic regression (denoted ”quad” in ﬁgures). This last paper also proposes other regression and interpolation methods, however they are not taken into account here as their accuracy collapsed in our context. Finally, we add a model named ”Analytical” adapted from [18] for the Spidergon STNoC router and which is based on the construction of an analytical model directly derived from the router architecture. To give a global overview of the models accuracy, we show the results for the output port model in table 3 and the global router model in table 4. Values for the input port and switch models are similar. According to those results, the DACE process has the lowest errors both locally and globally for both output port and router models. Moreover, the output port model predicted error is good (average 0.98 kgates of diﬀerence with the eﬀective error). The MARS 455 model is the second best model in our experiments. The quadratic model estimates correctly the output port area but its accuracy collapses for the router general model. This is due to the fact that this model is globally good (low RMSE in output port model) but locally inaccurate (high maximum absolute error in output port model). The analytical model, ﬁnally, is not accurate for small areas, but this tendency is compensated in the ﬁnal router estimation. We show in ﬁgure 4(a) and 4(b) the absolute average error per area domain. The x-axis corresponds to area ranges; range 1 contains the smallest areas, and the bounds increase at each range until the highest possible areas. The number of ranges is chosen to roughly have the same number of values in each range. Those ﬁgures corroborate the conclusion made earlier; moreover we can observe that the DACE absolute error does not present large diﬀerences between successive points (maximum 1.8 kgates diﬀerence between two successive router ranges, compared to 5 kgates for MARS method) and is always lower than the other models errors. The errors would decrease for all models if some points were added in the initial conﬁgurations set; however the results were considered as a good balance between the number of training conﬁgurations and the ﬁnal accuracy. To further compare MARS and DACE models, we show in ﬁgure 4(c) the average relative error per area domain for the router model. DACE process errors do not present signiﬁcant diﬀerences between diﬀerent domains, whereas MARS and Analytical errors increase largely in low areas domain. To understand this observation, we show in 4(d) the relative error frequency for the best three router models. The x-axis represents a range of relative errors and the y-axis provides the number of relative errors which belong to this range (in % over the number total of experiences). Most of relative errors are between 10% and 20% for all models. However, DACE errors are mostly below 30% and the maximum is about 49% whereas Analytical and MARS models have a few relative errors above 80%. This is due to the fact that those two last models sometimes return aberrant values (negative areas) in low areas domain, probably because of a lack of information in some design space regions. In contrast, the DACE model correctly catches the target function behavior and the parameters eﬀects. According to these experiments, we can conclude that DACE process model gives accurate area estimations both locally and globally for all input port, output port and switch models (and thus also for the global router model) with few points. Moreover, this model does not present any irregularities in its errors distribution and has thus proven its stability in very large design spaces. Those results were expected though, according to the approach adopted by DACE and the NoC context: NoC cost functions are characterized by a set of linear parameters (e.g. ﬂit width, FIFOs depths) and some highly non-linear parameters (e.g. instantiation parameters), resulting in great irregularities in their dimensions. In addition, some optimizations performed in the synthesis process may modify the overall expected results. MARS and quadratic methods both try to pro ject the cost function on an analytical expression constructed over global information and thus may fail in catching those last irregular behaviors, resulting in great local inaccuracies. On the other hand, DACE model gives an estimation based on two information: a distance function which characterize the typical inﬂuence of each parameter in space (equation 3) and the values (area in our (a) Output port model average absolute error - all errors and a zoom on DACE and MARS errors (b) Router model average absolute error - all errors and a zoom on DACE and MARS errors (c) Router model average relative error - all errors and a zoom on DACE and MARS errors (d) Router model inaccuracy (%) Figure 4: Absolute and relative models errors per area domain and error frequencies 456 case) of the neighbor points, resulting in diﬀerent behavior of the estimator depending on the current location in space. This method is thus very eﬀective in modeling nonlinear and multimodal functions in very vast space, and is able to better handle local irregularities thanks to information given by neighbor conﬁgurations of the initial set. DACE process does not need information about the architecture details of the target component, but requires to compute a maximization in k-dimension and its complexity is thus higher than similar methods like MARS or quadratic. Considering 620 conﬁgurations, to obtain the ﬁnal model with the DACE method, a 64-bits Xeon @3GHz with 8GB DDR takes about 9 minutes to compute the multidimensional minimization. In the same conditions, MARS method is computed in average in 1 minute (but twice less accurate), and quadratic regression in few seconds (even less accurate). In addition, DACE modeling time remains negligible compared to the time required for the synthesis (about two days in this example). DACE method complexity is thus a good trade-oﬀ between model accuracy, execution time and exploration space size. Once the model is built, estimating the area for any conﬁguration is almost instantaneous for all proposed methods. 4. CONCLUSION This paper presents a fully-automated ﬂow that constructs cost models applicable early in the design ﬂow for typical NoC parametric components. The proposed methodology could be seamlessly integrated in any commercial design ﬂow (e.g. Arteris, Arm, Sonics, ST). The proﬁt for architects are faster SoC architecture exploration time (from several hours to minutes). The method starts from a subset of possible conﬁgurations which is run through an implementation ﬂow to obtain corresponding evaluation metrics. An interpolation method is then applied on the results to construct a predictor able to estimate the cost function for all possible conﬁgurations. The method used is based on Kriging theory, which accurately catches the complex interactions between parameters even in the presence of highly non-linear parameters and without assumption on the underlying architecture. As an example, we construct the logic area model of a general router architecture. Experimental results show that the produced model is accurate both globally and locally and presents a predictable behavior on the basis of very few points. Our future ob jectives include the extension of this approach to power estimation. 5. "
2012,TRACKER - A low overhead adaptive NoC router with load balancing selection strategy.,"The effectiveness of an adaptive router in a Network on Chip (NoC) is evaluated by the selection metric it uses and its impact on overall performance. In this paper, we propose a flit flow history based load balancing selection strategy that can be used in any adaptive routers for output port selection. Using this selection strategy, we propose an adaptive router TRACKER, that keeps track of flow of flits through all its ports and updates this tracked information to its neighbors in a cost effective manner. Routers make use of these flit flow estimates to compute a novel selection metric for output port selection of incoming flits. TRACKER outperforms the baseline adaptive router architectures using odd-even routing model with conventional selection metrics like count of free virtual channels, count of fluid buffers and buffer occupancy time at reachable downstream neighbors.","TRACKER: A Low Overhead Adaptive NoC Router with Load Balancing Selection Strategy John Jose, K.V. Mahathi, J. Shiva Shankar and Madhu Mutyam PACE Laboratory, Depar tment of Computer Science and Engineering Indian Institute of Technology Madras, Chennai-36, India {johnjose, mahathi, jss, madhu}@cse.iitm.ac.in ABSTRACT The eﬀectiveness of an adaptive router in a Network on Chip (NoC) is evaluated by the selection metric it uses and its impact on overall performance. In this paper, we propose a ﬂit ﬂow history based load balancing selection strategy that can be used in any adaptive routers for output port selection. Using this selection strategy, we propose an adaptive router TRACKER, that keeps track of ﬂow of ﬂits through all its ports and updates this tracked information to its neighbors in a cost eﬀective manner. Routers make use of these ﬂit ﬂow estimates to compute a novel selection metric for output port selection of incoming ﬂits. TRACKER outperforms the baseline adaptive router architectures using odd-even routing model with conventional selection metrics like count of free virtual channels, count of ﬂuid buﬀers and buﬀer occupancy time at reachable downstream neighbors. Categories and Subject Descriptors C.2.1 [Network Architecture and Design]: communications] [Network Keywords NoC, adaptive routers, selection metric, load balancing 1. INTRODUCTION Over the last decade, technological innovations in SoCs have been focusing on empowering the computational eﬃciency of computing cores. Apart from high speed computing cores, eﬃcient and reliable communication is also essential for achieving high performance and throughput in multicore processors. Diminishing feature sizes and shrinking wire widths ampliﬁed the imbalance between gate delays and on-chip wire delays [1]. NoC architectures are proposed in multicore systems to replace design speciﬁc global on-chip wiring with general purpose on-chip interconnection network. Instead of dedicated point-to-point bus based communication, NoCs employ a grid of routers organized across the chip, connected by communication links [1, 2]. (c) 2012 Association for Computing Machinery. ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or afﬁliate of the national government of India. As such, the government of India retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. IEEE/ACM International Conference on Computer-Aided Design (ICCAD) November 5-8, 2012, San Jose, California, USA Copyright c(cid:13)2012 ACM 978-1-4503-1573-9/12/11 ...$15.00. In a 2D mesh topology, the processing cores are organized as rectangular tiles. Each core is attached to a local router which connects the core to the neighboring cores through a well structured set of routers and links. When a core wants to communicate with another, it creates a packet containing the required data. In NoCs with wormhole switching, each packet is serialized into a sequence of ﬂow control units called ﬂits. The head ﬂit contains the necessary control information needed to process and route the packet. Flits move across the routers in a hop by hop manner. A baseline router in a 2D mesh topology consists of ﬁve input ports and ﬁve output ports; one for each direction and one for the local tile. A 5 × 5 crossbar manages the inter-router connections [2]. Every input port of a router is associated with a set of ﬂit buﬀers called virtual channels (VCs). The use of VCs reduces the average network latency of a ﬂit at the expense of area and power consumption [4]. Once a packet reaches a router, the VCs provide storage space for it. The control logic in the router performs a set of necessary services on the packet such as determination of next hop route, arbitration and allocation of VC in the next router, allocation and traversal of the crossbar switch. The credit signals to and from a router carry the availability of buﬀer space information. Flits residing in various VCs on the same input port arbitrate among themselves and winning ﬂits from various input ports will undergo switch arbitration and allocation and then the ﬂits are forwarded through the crossbar switch to respective output ports. Buﬀering within the routers and handshaking between routers enable the smooth ﬂow of the packets. Thus the communication among various cores is achieved by generating, processing, and forwarding data packets and control signals through the network infrastructure. Adaptive routers choose the best route for incoming packets from a set of available paths by employing a proper selection metric that captures the dynamically varying network congestion status [2]. We propose a new selection metric based on ﬂit ﬂow analysis that could be used with any adaptive routers. Our key focus is to enhance the link utilization of the network by balancing the traﬃc ﬂow across all links. Instead of using the conventional metrics like availability of free VCs [4, 5], buﬀer ﬂuidity values [9] and buﬀer occupany values [10] across downstream nodes, we introduce a new selection metric, cumulative ﬂit count in the past, on the possible future links. Routing decisions are taken in such a way that less frequently used links are preferred. Our proposed adaptive router TRACKER has no impact on its critical path, with negligible impact on router area and power. 564 2. SCOPE OF SELECTION STRATEGY High performance NoC designs demand low latency, load balancing and deadlock-free adaptive routers. Physical limitations in the inter-router link capacity and count of VCbuﬀers lead to resource contention at higher packet injection rates. When an adaptive router identiﬁes more than one possible output port for an incoming ﬂit, the output port selection function chooses one of these output ports for the ﬂit by using an appropriate metric that captures congestion [5]. The eﬀectiveness of a selection strategy depends on the choice of a metric used to represent the congestion and the accuracy level of the metric in representing the real magnitude of congestion. Our preliminary study on various synthetic traﬃc patterns on 4× 4 mesh employing the odd-even adaptive routing shows that, on an average, in 27% of the cases the routing function returned multiple admissible output ports. Thus, at least one for every four routing decisions, the selection strategy determines which output port is to be selected. The percentage value is even higher for larger mesh networks. A well formed selection strategy can have a signiﬁcant impact in choosing the best possible path for a packet thereby increasing the throughput of the system. 3. RELATED WORK The minimal odd-even routing (MOE) [3] is one of the simple and the most commonly used deadlock free adaptive routing algorithms used in mesh NoCs. The MOE routing by itself does not use any output port selection and hence it makes a random selection from available ports. To enhance the adaptivity, selection functions are employed on top of the MOE routing. Proximity Congestion Awareness [6] makes use of the load information of neighboring switches for channel selection decisions. Path-Based Randomized Oblivious Minimal Routing [8] proposes a load balancing routing scheme by random channel selection. Congestion Aware Deterministic Routing [7] estimates the congestion level in the network based on past ﬂow pattern and computes optimized routing paths for all traﬃc ﬂows deterministically. This is suited only for systems which generate repetitive traﬃc patterns. The count of free VCs (F V C ) in the adjacent downstream router is also explored as a selection metric [4, 11]. The Neighbors-on-Path (N OP ) [5] strategy explores the free VC status of reachable neighbors of adjacent routers of current node. The ﬂuidity based approach [9] explores ﬂit movement by counting the number of ﬂuid buﬀers. Forwarding a ﬂit to a router with more ﬂuid buﬀers facilitates easy ﬂow of ﬂits through them. During congestion, if desired output port is not available ﬂits occupy buﬀers for longer time. BOFAR [10] tries to capture the history of buﬀer occupancy over a reasonable time interval. 4. MOTIVATION Ma jority of the existing adaptive routers [4, 5, 11] use availability of free VC buﬀers across downstream nodes as the selection metric. Even though this sounds to be a simple and meaningful approach, careful analysis exposes its ineﬃciency. Our experimental observations on various trafﬁc patterns show that the real congestion status of a router cannot be fully represented by the count of free buﬀers on it or its downstream routers. At higher injection rates close to saturation, since almost all VCs in routers are full, the eﬀective value of the selection metric is close to zero. When there is a tie in the value of the captured metric, a random port from the candidate ports is chosen, which makes the channel selection strategy itself meaningless. In ﬂuidity approach [9] a buﬀer is said to be ﬂuid when a ﬂit is moving out from it in the current clock cycle. Nodes with more ﬂuid VCs are treated as less congestion prone. This is a more realistic representation of congestion than a F V C or N OP metric. One of the drawbacks of ﬂuidity based output selection is its inability to distinguish the level of congestion if both neighbors of a node are either equally ﬂuid or equally non-ﬂuid. Congestion cannot be deﬁned only based on the feedback data obtained from the current and the previous clock cycle updates. Congestion is formed over a period of time due to cumulative and chain reaction eﬀects. Unfortunately none of the baseline architectures except BOFAR [10] captures this. Cumulative buﬀer occupancy time proves to be more realistic selection metric than the instantaneous count of free buﬀers and the ﬂuidity information of downstream nodes. But capturing, computing, and propagating the cumulative buﬀer occupancy time as mentioned in [10] involves signiﬁcant hardware and wiring overhead. If links are not fairly and evenly used, it leads to uneven ﬂow distribution, making certain paths heavily used leading to resource contention and delay in packet movement. Congestion can also be formed due to unregulated traﬃc ﬂow. None of the baseline models explores the relation of congestion with the link utilization. Existing selection metrics are not addressing congestion from this angle. Uniform usage of links ensure the balanced ﬂow across all possible paths and prevent premature aging of links. With a proper feedback mechanism that captures ﬂit ﬂow rate, we can reduce congestion by regulating ﬂit load across the links. Through this paper we make an eﬀort to realize this. 5. TRACKER ROUTER ARCHITECTURE TRACKER is a typical VC router [2] which keeps track of ﬂow of ﬂits through all its outgoing ports and exchanges this ﬂit ﬂow information with its neighbors. It makes use of this ﬂit ﬂow information to compute the proposed selection metric, i.e., cumulative ﬂit count (C F C ). C F C indicates the contention level of an output port of neighboring router. Higher the C F C , higher the number of ﬂits passed through that output port in the recent past. When there is a choice in selecting an output port, we opt for an output port which has the least C F C . Processing of C F C values is done in parallel with the route computation. Control signals for VC allocation and switch allocation are generated to facilitate the ﬂit forwarding along the chosen path. The architecture of the selection logic of a TRACKER router (router 5 as per Figure 1) is shown in Figure 2. The ﬁgure emphasizes the interaction and control wiring associated with west neighbor of router 5. For each router, a ﬂit tracking circuit and a ﬂipﬂop (FF) are attached on each output port. At the end of every clock cycle, the ﬂit tracking circuit updates its FF. FF of a port is set if a ﬂit ﬂows through the port, else it is reset. Special control wires connecting a router and its neighbors (shown as 3-bit value to/from west port of the router) carry the FF states. Once a router receives the FF values, the C F C kept in the corresponding 4-bit Status Register (SR) segment is updated by adding the FF values to them. 565 Figure 1: Illustration of Usage of Selection Metric in TRACKER Router. Figure 2: Internal Architecture of Selection Logic in TRACKER. Figure 3: Status Registers and Control Network in TRACKER. After every T clock cycles, called the Refresh Interval (RI), SR value is multiplied with a weight factor of α=0.25 to prevent the overﬂow of SR and to preserve the history of accumulated C F C . Even though the best value of α is not 0.25, a ﬂoating-point multiplier can be replaced with a simple shifter if the value of α is 0.25. Hence to realize the multiplication of α and incrementing the SR, a shifter and an incrementer circuit are attached to each segment of SR. After exploring with various values of RI, we consider the best performance-power combination with RI= 16 cycles and conduct the experimental analysis. Now let us examine the working of ﬂit forwarding in a TRACKER router. As per Figure 1, assume a ﬂit F, sourced at node 4 and destined to node 15, reaches node 5. The MOE route function [3] chooses east port (link to node 6) and north port (link to node 9) as possible output ports for the ﬂit F. In the meantime FF state values from node 9 and node 6 reach node 5. From the FF states the corresponding C F C values are updated in the respective segments of SR. A ﬂit from node 5 destined to node 15, upon reaching node 9 has two possible output ports, north and east ports (shown by thick arrows) of node 9. Hence the mean-CFC for F along the north port of node 5 is the average of C F C through east and north ports of node 9. Similarly the mean-CFC for F along the east port of node 5 is computed. In this case, the north port of node 6 is not a reachable port (shown by dotted arrow) for a ﬂit coming from node 5 due to M OE turn restriction [3]. The output port of node 5 with smaller mean-CFC is given higher priority at port selection for F. For every incoming ﬂit, TRACKER chooses the link with the minimum traﬃc in the past, thereby ensuring the load balance across the links. Every router forwards at most three FF states to a neighbor. For example (as per Figure 1), node 9 tracks the ﬂit ﬂow through all its four outgoing ports (connected to nodes 13, 8, 5, and 10) and updates the respective FF states, but only FF state of ports connected to nodes 13, 8, and 10 are forwarded to node 5 and that of nodes 8, 5, and 13 are forwarded to node 10. Thus in every clock cycle, each node gets the FF state associated with reachable ports of its neighbor. Figure 3 shows the control network that carries FF values between node 5 and node 9. Each port of a router has a SR of size 4n bits, where n is the number of segments in the SR. This n is same as the number of FF values a router receives from its neighbor associated with that port. Port selection by C F C is not aﬀected by the status of the available VCs on the downstream router. If a node along the port chosen by the mean-CFC comparison is not having any free VCs, the ﬂit stays back in the current router in the present clock cycle and makes an attempt in the next cycle. If we choose mean-CFC only for neighbors with available VCs, an extra cycle delay may be avoided in the current router. But results show that such greedy local decisions increase the overall packet latency and decrease the link utilization fairness. 6. EXPERIMENTAL ANALYSIS We now compare the performance of MOE adaptive router using the proposed selection metric and other baseline selection metrics discussed in Section 3. We also examine the sensitivity of the network to various design parameters considered in the TRACKER router architecture. 6.1 Experimental Setup We use Booksim [2], a cycle accurate network simulator, that models a two-cycle router micro-architecture in suﬃcient detail. The simulator is modiﬁed to model an adaptive router that uses MOE routing. Performance values are collected with diﬀerent selection metrics: free VCs in downstream nodes (F V C ); free VCs in reachable nodes at twohop distance (N OP ); count of ﬂuid VCs on reachable nodes at two-hop distance (F ON ); cumulative buﬀer occupancy time of ﬂits that move out through reachable output ports of downstream nodes (BOF ); and our proposed metric, cumulative ﬂit count through reachable output ports of downstream nodes (C F C ). We evaluate our proposed technique using ﬁve standard synthetic traﬃc patterns: uniform, tornado, bit-compliment, transpose, and bit-reverse for 4 × 4 mesh networks. Since bit-compliment, bit-reverse, and transpose traﬃcs are not deﬁned for 5 × 5 mesh, we use only uniform and tornado traﬃcs for evaluating 5 × 5 mesh networks. Average packet latency and link utilization values are collected for diﬀerent traﬃc patterns under various injection rates. We use 4 and 8 VCs per router port in 4 × 4 and 5 × 5 mesh networks, respectively. We consider variable length packets with 3-ﬂit buﬀer per VC. We consider 60% single-ﬂit packets and the rest larger packets of size up to four ﬂits. α for computation of C F C is ﬁxed at 0.25 and RI is set to 16 cycles. BOF design is done with RI of 128 cycles. 566 Figure 4: Average packet latency for uniform and tornado traﬃc patterns (packet size ranging from 1 ﬂit to 4 ﬂits). 6.2 Evaluation of Average Packet Latency Figure 4 contains a set of load-latency graphs for C F C and other selection metrics with variable sized packets. In all the plots we can see that, at low injection rates, almost all the selection metrics experience the same average packet latency. This is because of the fact that the network is free from congestion. But as load in the network increases, the eﬀect of selection metric adopted becomes more visible. Similarly the plots clearly show that C F C metric extends the injection rate at which the network saturates. This makes TRACKER the best design choice for high injection rate applications. Even though we plot the load latency results only for two synthetic traﬃc patterns, we analyzed the performance of various metrics for bit-compliment, transpose, and bit-reverse traﬃc patterns also. On 4 × 4 mesh networks with variable size packets, at saturation load CFC achieves an average latency reduction of 43%, 17%, 41%, and 21% with respect to F V C , F ON , N OP , and BOF , respectively. Our technique extends the saturation injection rate by up to 1.5% in tornado and bit-compliment traﬃc. The eﬀect of C F C is more predominant in these two patterns as the source and destination are diagonally oriented and the possibility of having multiple paths to spread the traﬃc is high. In load latency plot for 5 × 5 mesh networks (Figure 4), we can see that C F C metric has the least pre-saturation latency. As N OP metric makes the network saturate much faster than other metrics, it is excluded for comparison. At saturation load, the average packet latency reduction of CFC is 33%, 52%, 35%, respectively, over F V C , F ON , and BOF techniques. Performance gap between CFC and the other techniques increases with mesh size, thereby exposing the ineﬀectiveness of other techniques in capturing the real congestion in larger networks. Even though the latency plot of F ON and BOF are close to that of C F C in certain cases, they fail to perform consistently across all traﬃc patterns. Consistent performance of TRACKER across all traﬃcs and all network sizes makes C F C an excellent metric for selection functions in adaptive routers. 6.3 Evaluation of Link Utilization Fairness Another observation we made is the increase of Link Utilization Fairness (LU F ) by using C F C as the selection metric. We compute the total number of ﬂits ﬂowing through each link for each simulation instance (traﬃc pattern, injection rate) and then compute the LUF as follows: LU F = Average number of ﬂits per link Standard deviation of ﬂits per link If the standard deviation of ﬂits per links reduces, the LU F improves. Higher the LU F , better is the load distribution across links. We compute the ratio of average packet latency to the corresponding LU F for various injection rates under varying traﬃc patterns and network size. Lower the ratio, more eﬀective the metric is. Figure 5 shows that C F C metric is consistently having the least latency to LUF ratio for all network sizes. At higher loads, when more ﬂits are injected into the network, TRACKER exhibits better LU F . Results in larger networks show that TRACKER scales well. The combination of reduced average packet latency, increased saturation injection rate along with increased LU F makes C F C metric as a promising alternative for conventional selection metrics. Increase in LU F leads to uniform wear and tear and hence can increase the lifetime of links. 6.4 Sensitivity to Various Design Parameters We also examine the sensitivity of the network to various design parameters considered in the TRACKER design. A key design factor in computing C F C is the weight factor α which determines how signiﬁcant is the ﬂit ﬂow history through a link in the previous RI period. For real representation of congestion, ﬂit ﬂow updates in the current RI period should be given dominance over cumulative past ﬂit ﬂow estimates. If α is 0, then it results in loss of ﬂit ﬂow history at the beginning of a new RI period. In such cases C F C cannot represent the real congestion in the initial few cycles of an RI period, leading to poor port selection decisions. Upon experimenting with diﬀerent values of α ranging from 0.05 to 0.45, we ﬁnd that diﬀerent traﬃc patterns require diﬀerent value of α to give best average packet latency. Even though we compromise on average packet latency and saturation throughput, we use α = 0.25 to keep router power and area within acceptable limits. Another parameter whose eﬀect is explored is the RI for SRs. High RI requires wide SRs, to keep C F C value without saturating, which incurs more power and area overhead. For low RI values, C F C value is insuﬃcient to distinguish between candidate paths for a ﬂit in a given router. These factors prompt us to choose an RI value large enough to capture the variations of ﬂit ﬂow and small enough for minimum design overhead. Considering these factors we ﬁx the RI value as 16 cycles. We study the eﬀect of the compute interval (CI) of C F C metric. We examine the results by reducing the frequency of updation of C F C to once in 4, 8, 16, and 32 cycles under varying RI. But results show that it leads to degradation of LU F since a constant value of C F C for few cycles sets the priority of output ports of a router to be constant within this CI. So during this interval all ﬂits destined to a quadrant move through one path only, which disturbs LU F . All the results presented in this paper are based on CI of 1 cycle. 567 Figure 5: Ratio of Latency to LUF for various network sizes under uniform and tornado traﬃc patterns. Table 1: Comparison of width of SRs and control network for various selection metrics. Metric Width of SR FVC FON NOP BOF CFC 4 16 12 24 12 Width of Control Network 4 16 12 24 3 Metric Table 2: Overhead comparison of various selection metrics with respect to FVC selection metric. Router Power Link Area Overhead (%) Overhead (%) 5.44 9.03 3.57 6.02 9.3 12.05 3.59 1.50 FON NOP BOF CFC 6.5 Hardware Overhead We use Orion 2.0 [12] for area and power computation of the baseline routers and TRACKER. We assume 65 nm technology at 1 GH z operating frequency and NoC channel delay of one cycle [13]. Since all the baseline architectures use some sort of combinational circuits for comparison of selection metric values across candidate paths, signiﬁcant hardware overhead diﬀerence between these techniques is due to width of control network and size of status registers used. Our power overhead comparison is focusing on these two parameters only. Apart from a standard credit channel, all the selection metrics require some additional control wiring to transmit congestion information. Table 1 shows the diﬀerence in width of control network and size of SRs. A general comparative study on the overheads associated with various selection metrics is given in Table 2. All power and area overhead values in the table are with respect to MOE router with 128-bit ﬂit channel and 4-bit credit channel using F V C selection metric. 7. CONCLUSION An adaptive router based on the ﬂit ﬂow analysis of downstream router is proposed. Our model makes the best use of the link bandwidth and spread traﬃc across less frequently used links to balance the load. TRACKER, without much additional overhead, gathers non-local ﬂit ﬂow history from neighbors and route ﬂits accordingly. The light weight monitoring logic and minimal extra control network ensure that the power and area overhead in the proposed design is negligible compared to the latency reduction and increased link utilization achieved. In larger networks, across all traﬃc patterns examined TRACKER has the least average packet 568 latency in pre-saturation loads. Our experimental results showed that cumulative history of ﬂit ﬂow rate can be used as an eﬀective selection metric in future NoC router designs. 8. ACKNOWLEDGMENT This work is supported in part by grant from Defence Research and Development Organization (DRDO) under IITMDRDO MoC. Travel support from the Indian Institute of Technology Madras and Indian Association for Research in Computer Science (IARCS) is greatly acknowledged. 9. "
2013,PROTON - an automatic place-and-route tool for optical networks-on-chip.,"Optical Networks-on-Chip (ONoCs) are considered a promising way of improving power and bandwidth limitations in next generation multi- and many-core integrated systems. Today, most related research acknowledges the key role of the physical layer in assessing ONoC topologies (e.g., insertion loss), but overlooks the placement and routing stage in the design process, hence applying physical design considerations to topology logic schemes. Such a mismatch is fundamentally due to the lack of mature CAD tools for placement and routing of optical NoCs. The objective of this work is to bridge this gap: We propose PROTON, a fast tool for automatic placement and routing of ONoC topologies, which can support designers in quantifying the degradation of design quality metrics when moving from topology logic schemes to their physical implementation. This gap is especially relevant for Wavelength-Routed ONoCs (WRONoCs), where logic schemes typically make unrealistic assumptions about the placement of initiators and targets. For this reason, we put PROTON to work with the most promising WRONoC topologies and explore their physical design space given the placement and routing constraints of a 3D stacked system. We also compare automatically generated layouts with handcrafted ones reported in the literature for the same topologies and target system, and prove an insertion loss improvement by up to 150x. With PROTON the exploration of the physical design space of ONoC topologies is possible as well as their scalability analysis considering the layout.","PROTON: An Automatic Place-and-Route Tool for Optical Networks-on-Chip Anja Boos∗ , Luca Ramini† , Ulf Schlichtmann∗ , Davide Bertozzi† ∗ Institute for Electronic Design Automation, Technische Universit ¨at M ¨unchen {anja.boos, ulf.schlichtmann}@tum.de †Engineering Department, University of Ferrara {luca.ramini, davide.bertozzi}@unife.it Abstract—Optical Networks-on-Chip (ONoCs) are considered a promising way of improving power and bandwidth limitations in next generation multi- and many-core integrated systems. Today, most related research acknowledges the key role of the physical layer in assessing ONoC topologies (e.g., insertion loss), but overlooks the placement and routing stage in the design process, hence applying physical design considerations to topology logic schemes. Such a mismatch is fundamentally due to the lack of mature CAD tools for placement and routing of optical NoCs. The objective of this work is to bridge this gap: We propose PROTON, a fast tool for automatic placement and routing of ONoC topologies, which can support designers in quantifying the degradation of design quality metrics when moving from topology logic schemes to their physical implementation. This gap is especially relevant for Wavelength-Routed ONoCs (WRONoCs), where logic schemes typically make unrealistic assumptions about the placement of initiators and targets. For this reason, we put PROTON to work with the most promising WRONoC topologies and explore their physical design space given the placement and routing constraints of a 3D stacked system. We also compare automatically generated layouts with handcrafted ones reported in the literature for the same topologies and target system, and prove an insertion loss improvement by up to 150x. With PROTON the exploration of the physical design space of ONoC topologies is possible as well as their scalability analysis considering the layout. I . IN TRODUC T ION Today, for the ﬁrst time the integration of a fully functional photonic system on a VLSI electronic die can be realistically envisioned. However, despite the arguments in favour of optics for interconnects on the silicon chip and the promising integration route, there is essentially no practical use today. This is in conﬂict with the vast amount of works in the literature addressing system level redesign around an optical interconnection network and the associated power and performance beneﬁts [18], [19], [20], [21]. In fact, these contributions just foster the optical network-on-chip concept, but are not capable of bridging the gap with an actual interconnect technology of practical relevance. Clearly, further research contributions are needed closer to the physical layer. On one hand, there are still open challenges for the reliable manufacturing and safe runtime behavior of optical components within industrial products. For instance, integrated sources should sustain the working temperatures of a CMOS chip. The problem is also common to passive silicon structures, which in addition suffer from large sensitivity to dimensional variations, calling for trimming or active tuning. Finally, it is worth mentioning the energy improvements that are still required in CMOS compatible receiver circuit design to drastically reduce the energy/bit contribution of the optoelectronic conversion [13], [15]. On the other hand, even assuming industry-standard technology maturity of ONoC building blocks such as laser sources, modulators, detectors and switching elements, the key for the success of optical networks-on-chip consists of a suitable support to exploit the new interconnect technology for system-level design [16], [17]. In this respect, there is today a relevant gap in terms of design technology, which currently prevents any realistic roadmap for industrial uptake. In this domain, and similarly to digital electronic design in nanoscale technologies, the key concern for the design of an optical interconnection network consists of its predictability. This can be deﬁned as the deviation between the topology logic scheme and its physical implementation in terms of physical parameters such as number of crossings, and the waveguide length. Such parameters are associated with the losses that optical signals experience across the physical paths of the topology. If we deﬁne the critical path of an optical network as the physical path with the largest optical loss, then we derive that such critical path determines the minimum power requirement on the laser source, given a speciﬁc detector sensitivity. It is therefore of the utmost importance to preserve the predictability of optical losses across design layers to avoid ONoC topologies that map inefﬁciently to the physical layer. The main source of deviation of real topology layouts from the associated logic schemes consists of an hardly predictable increase of waveguide crossings. There are three main reasons for this. On one hand, logic schemes often make unrealistic assumptions on the positions of initiators and targets on the actual ﬂoorplan [7]. Alternatively, some logic schemes are optimized for hardwired positions of the network interfaces, which might not be veriﬁed in the system at hand [9]. On the other hand, multilayer photonics is still far from becoming a mainstream solution due to its manyfold manufacturing challenges [22] (e.g., sensitivity to process variations in physical gap design). Therefore, single layer photonics might be the reference solution for some time, which increases the risk of additional crossings when routing intricate connectivity patterns. In order to cope with these challenges, designers today have no other choice than placing and routing ONoCs manually, thus basing the insertion loss minimization goal entirely on their intuition and experience. This is due to the lack of automatic placement and routing tools for ONoC design. This paper takes on this challenge and proposes PROTON, a 978-1-4799-1071-7/13/$31.00 ©2013 IEEE 138 CAD tool for the automatic placement and routing of optical switching elements and waveguides respectively. Thanks to the ﬂexibility of its objective function, PROTON paves the way for the automatic physical design space exploration of optical NoC topologies. To the best of our knowledge, this is the ﬁrst physical synthesis EDA tool for optical interconnection networks. Similar to electronic NoCs [14], automatic placement and routing are need-to-have features for the physical design of those topologies that show a clear discrepancy between the logic design and the physical layout. This concern is especially critical for wavelength-routed ONoCs, which fundamentally consist of add-drop optical ﬁlters, and therefore end up in multistage interconnection networks that map inefﬁciently to a 2D surface. Without lack of generality, this paper will address these topologies, in that they represent the most challenging benchmark for an automatic placement and routing tool. The rest of this paper is structured as follows: In Section II we introduce the state-of-the-art and highlight the key motivation of our work. Section III describes PROTON’s placement and routing algorithm. Experimental results are presented in Section IV before we conclude with Section V. I I . S TAT E -O F - THE -ART AND BACKGROUND 3-D stacking is a promising scenario for the cost-effective integration of heterogeneous technologies. By using 3Dstacking optical NoCs can be integrated with electronic components in such an environment. A. Target Architecture Fig. 1: Target architecture [5] Since the architecture inﬂuences the ﬁnal results of placement and routing we have to make speciﬁc assumptions about the target system. We focus our work on a 3-D stacked multicore processor, consisting of an electronic and an optical layer vertically stacked on top of each other as can be seen in Figure 1. Similar to Tilera architecture [11] the electronic layer is composed of an array fabric of 32 homogeneous processor cores, which are grouped into clusters. We assume that cores are aggregated into 4 clusters of 8 cores each. Furthermore each cluster has its dedicated gateway to the optical layer (vertically stacked with a corresponding hub in the optical layer). This accommodates three kinds of communications: (a) between any two pairs of clusters; (b) from a cluster to a memory controller of an off-chip photonically integrated DRAM DIMM [1]; (c) from a memory controller back to a cluster. We assume core size and die size to be 1.33mm × 1.33mm and 8mm × 8mm respectively. Hubs (i.e., the optical components of an electro-optical and opto-electronic network interface) are positioned above the middle of each cluster. Hence, they are placed along a square in the middle of the optical layer (see Figure 1). The 4 memory controllers are located pairwise at the opposite sides of the chip, as proposed in conventional chip multiprocessor architectures [11]. Since we need to connect 8 initiators (4 hubs, 4 memory controllers) with 8 targets (the target interface of the same 4 hubs and 4 controllers), we use a Wavelength-Routed Optical NoC. B. Wavelength-Routed Optical NoCs WRONoCs rely on the principle of Wavelength-SelectiveRouting, in which switching functionality is obtained using wavelength ﬁlters throughout the network. In particular, each source-to-destination path among initiators and targets uses a different wavelength. This mechanism enables contention-free full connectivity without the need for any path setup/teardown overhead. Furthermore there is no time spent for routing/arbitration functionality. Hence, WRONoC topologies are an appealing solution for a processor-memory network in mixed criticality systems. To provide global connectivity in our optical layer an 8x8 WRONoC is required. Below we present the most important 8x8 WRONoC topology logic schemes and their key features. • The 8x8 λ-Router was proposed by Scandurra et al. in [7]. As shown in Figure 2 the network interconnects 8 initiators with 8 targets, which are spread at the rightmost and leftmost side of the topology respectively. The 8x8 λ-Router features 28 2x2-optical ﬁlters (composed by 2 input and output ports) and 8 distinct wavelengths to meet all the communication requirements between 8 initiators and 8 targets. • Based on the wavelength assignment proposed in [9], the 8x8 generic wavelength-routed optical router (GWOR) is obtained starting from its lower basic cell, the 4x4 GWOR. In total 24 2x2-ﬁlters and 7 different wavelengths are necessary to build the 8x8 GWOR. • Unlike previous topologies, the 8x8 Optical Crossbar [2] uses 64 1x2-optical ﬁlters (1 input port and 2 output ports) to interconnect 8 initiators with 8 targets. Similarly to the 8x8 GWOR topology the Optical Crossbar uses 7 distinct wavelengths. C. Logic Scheme vs. Physical Layout In recent literature the ONoC topologies are typically proposed by their logic schemes or they are tied to speciﬁc ﬂoorplanning assumptions [9]. There might be a profound difference between the logic topology and its physical implementation [5], which raises the design predictability concern for ONoCs as well. Insertion loss and laser power analysis are important steps to tackle such a concern and to assess the actual feasibility of connectivity patterns from a physical-layer standpoint. Figures 2 and 3 show a comparison between the 8x8 λ-router logic scheme and its physical implementation obtained after manual design with the goal of minimizing 139 n0 n1 n2 n3 Fig. 4: Path p connects Hub0 and Hub1 and consists of four nets n0 ,. . . ,n3 , which connect a Hub and a PSE or two PSEs. (a) (b) Fig. 5: Minimizing (a) propagation loss or (b) crossing loss can result in an increase of crossing loss or propagation loss respectively. I I I . P LAC EM EN T AND ROUT ING A LGOR I THM O F PROTON Given dimensions and positions of hubs and memory controllers, width and height of PSEs, dimension of the optical layer and routing path information PROTON creates a valid physical layout of any optical NoC, e.g. all PSEs are placed overlap-free inside the die area and are connected by waveguides. Let a path be the connection between two hubs, one hub and one memory controller or two memory controllers. As shown in Fig. 4 one path consists of several nets n0 , . . . , nk , which are deﬁned as two-pin connections between one hub and one PSE, one memory controller and one PSE or two PSEs. Since insertion loss is the main qualiﬁer of optical NoCs an optimal physical layout of the optical layer minimizes maximum insertion loss ilmax over all paths. Thus, the objective function is given as minimize (1) with P , x and r describing the set of all paths, positions of all PSEs and positions of all waveguides respectively. The insertion loss of path p mainly depends on propagation loss plp (x,r) and crossing loss clp (x,r). Decreasing crossing loss can result in an increase of propagation loss and vice versa. An example is given in Fig. 5. We assume PSE0 is connected to PSE1 and PSE2 is connected to PSE3. In Fig. 5(a) propagation loss is minimized, e.g. the length of waveguides is minimal, which results in one crossing. In Fig. 5(b) crossing loss is minimized, which avoids crossings as far as possible. The length of the waveguides increases compared to the routing solution shown in Fig. 5(a). Hence, minimizing propagation and minimizing crossing loss mostly are contradictory objectives. Our algorithm aims to ﬁnd a trade-off by minimizing a weighted sum. ilmax (x,r) = maxp∈P ilp (x,r) ilp (x,r) = α · plp (x,r) + β · clp (x,r) 0 with α + β = 1. where α, β ∈ R+ Due to the complexity of the placement and routing problem our algorithm is separated into two steps: During the ﬁrst step suitable positions for PSEs are found considering the distances between two PSEs and the (approximated) number (2) Fig. 2: Logic scheme of 8x8 λ-Router Fig. 3: Layout of 8x8 λ-Router designed manually [6] waveguide crossings [6]. Note that Figure 3 as a sketch does not satisfy real dimensions of optical ﬁlters, hubs and memory controllers. Due to the ﬁxed positions of hubs and memory controllers, which are determined by our target architecture, there is a huge deviation between the logic scheme and the corresponding physical layout. The number of crossings on the critical path increases from 7 in the logic topology to 64 in the actual layout. As a consequence the insertion loss and the corresponding laser power may worsen so much that an appealing logic topology may become overly expensive or impractical. Even if the manual design is the preliminary step to implement optical NoC topologies at physical level, it is clearly error prone and time consuming especially when the number of initiators and targets scales up (e.g. 16x16 λRouter). Hence, we have developed PROTON, an automatic placement and routing tool for optical Networks-on-Chip design. D. Topology Speciﬁcation In order to process any optical NoC topology, PROTON uses a Topology Speciﬁcation Format, which deﬁnes the physical path that is taken by each optical signal at a speciﬁc wavelength. Let us consider the 8x8-λ router as a case study. As illustrated in Figure 2 each initiator uses 8 distinct wavelengths to reach all 8 destinations, each one following a different routing path. The 8x8 λ-Router is broken down into those 64 routing paths. As shown in Figure 4, each of them connects one initiator and one target by passing several optical ﬁlters. In the following, optical ﬁlters are called photonic switching elements (PSEs). 140 of waveguide crossings. After this the waveguides are routed by minimizing the length of the waveguides and/or the number of crossings. The rest of this section is organized as follows: In Section III-A we describe the iterative algorithm for placing all PSEs. In Section III-B the algorithm for routing the waveguides is introduced. Finally, we describe the calculation of maximum insertion loss in Section III-C. A. Placement During the placement step PROTON places all PSEs at suitable positions by minimizing maximum insertion loss ilmax , which can be approximated by the weighted sum of propagation loss and crossing loss. Propagation loss is directly proportional to the length of waveguides. Hence, minimizing the length of waveguides minimizes propagation loss. To ensure differentiability we use a quadratic net model and obtain cost functions ˜W Lp (x) representing the quadratic length of waveguides for each path p. Let net nij = (i, j ) be the net between module i and module j , where a module can be a PSE, hub or memory controller. Assuming the center of module k to be located at (xk , yk ), the cost functions ˜W Lp (x) are calculated as ˜W Lp (x) = (xi − xj )2 + (yi − yj )2 (3) (cid:88) nij =(i,j )∈Np where Np is the set of all nets contained in path p. Since crossing loss is directly proportional to the number of crossings and because the routed waveguides are not available during placement the number of crossings has to be estimated for a given placement. For each net nij = (i, j ) connecting module i and module j let lij be the straight line connecting the center points of module i and j . For each pair of nets nij = (i, j ) and nrs = (r, s) we estimate the probability of a crossing. If lines lij and lrs do not cross the probability of ﬁnding two non-crossing routing paths is high. If lij and lrs cross on the other hand a crossing of the routed waveguides is probable. In the following we specify a continuous, mostly differentiable function describing this observation. Around every line lij that approximates the routed waveguides of net nij we deﬁne an ellipse eij as shown in Fig. 6. The length of the ellipse is the distance a of the center points of module i and module j . The width of the ellipse is assumed to be αa with factor 0 < α ≤ 1. As can be seen in Fig. 7, this ellipse is the contour line of a gaussian function fij (x, y) having its maximum at the center point of line lij . (cid:16) xi+xj , yi+yj 2 2 fij (x, y) = aeb11 (x−xc )2−2b12 (x−xc )(y−yc )+b22 (y−yc )2 (xc , yc ) = (cid:17) (cid:113) where a, b11 , b12 and b22 are given as a = d1 = d2 = (cid:1) ln (cid:0) T OL (xi − xj )2 + (yi − yj )2 (xi − xc )2 + (yi − yc )2 ln (cid:0) T OL 1 (xi − xc )2 + (yi − yc )2 α2 (cid:1) a a (4) (5) (6) (7) 141 Module i eij lij y yi yc yj Module j xi xc xj x Fig. 6: Net nij between module i and module j is approximated by line lij . Around lij we deﬁne the ellipse eij . Fig. 7: The ellipse eij around lij is a contour line of a gaussian function, which function values are high close to lij and low elsewhere. (cid:34) β =arccos xmin =yi < yj ? xi : xj ymin =min(yi , yj ) (cid:112)(xmin − xc )2 + (ymin − yc )2 ) |xmin − xc | b11 =d1 cos2 (β ) + d2 sin2 (β ) b12 =(d1 − d2 )sin(β )cos(β ) b22 =d1 sin2 (β ) + d2 cos2 (β ) (cid:35) (8) (9) (10) (11) (12) (13) a The function value fij (xc , yc ) at the center point of the line is the distance between module i and module j . Furthermore the function values of all points at the boundary of the ellipse (and especially of the end points fij (xi , yi ) and fij (xj , yj )) are T OL. For our experiments we assume a tolerance of T OL = 2 . If a line lrs is close to line lij the probability of a waveguide crossing is high. For each net nij the crossing probability of all other nets nrs is approximated using the endpoints and the center point of line lrs . If one of the two endpoints or the center point is close to lij , we assume that the probability for a crossing is high. Thus, using the weights of Simpson’s rule [4] the probability of a crossing of nij and nrs is calculated as , yr + ys 2 + fij (xs , ys ) (14) Since the placement algorithm not only minimizes maximum insertion loss but also creates a valid layout some side con(cid:18) cij (xr , yr , xs , ys ) = fij (xr , yr ) + 4fij · 1 6 (cid:18) xr + xs 2 (cid:19) (cid:19) straints have to be added to the minimization problem. Let wk and hk be width and height of module k respectively. The following constraint ensures a non-overlapping placement of module i and module j . (cid:113) −(cid:113) gij (x) ≥0 with (xi − xj )2 + (yi − yj )2 gij (x) = i − (cid:113) w2 i + h2 w2 j + h2 j (15) Every PSE has two input and two output pins positioned on the four sites - north, east, south, west - of the PSE. Constraint (15) deﬁnes circles around modules i and j that are not allowed to overlap each other. The circle ensures routability at the four sides of each module where the pins are positioned. Furthermore the constraints 0 ≤ xi ≤ wc 0 ≤ yi ≤ hc (16) (17) force all modules to be placed inside the footprint area [0, wc ] × [0, hc ] where wc and hc are the width and height of the optical layer. Now the placement problem can be formulated as the optimization problem α((xi − xj )2 + (yi − yj )2 ) minimize x max p∈P ni j=(i,j )∈Np (cid:88) (cid:88)  3 2 3 3 2 1 2 3 2 1 1 0 2 1 3 2 3 3 2 4 3 4 S1 4 3 4 3 2 3 4 2 1 2 3 4 2 1 4 1 0 1 2 3 8 Net n1 Net n2 Net n3 (a) (b) Fig. 8: (a) Routing is done by spreading wavelike over the chip area. (b) A penalty factor (e.g. penalty factor = 5) penalizes an already used bin. (a) (b) Fig. 9: A (a) constant penalty factor can increase the number of crossings compared to an (b) adaptive factor. routing in VLSI design. Since for photonic layer design all devices and waveguides are placed on the same layer, crossings mostly are unavoidable to route all waveguides. For routing we use a modiﬁed version of Lee’s algorithm [3], which is a well-known routing algorithm in VLSI design. Lee overlays the chip area by a grid. All net pins are mapped to the next grid bin. An example is given in Figure 8(a). Nets n1 , n2 and n3 are routed one after the other starting with pin Si that has to be connected to target pin Ti for i = 1, 2, 3. A zero is assigned to the bin containing the starting pin of net n1 . To all (four) neighbour bins 1 is assigned. Spreading wavelike over the chip numbers in ascending order are assigned to the neighbour bins of the previous neighbours until the target bin is found. The shortest way back to the starting pin is determined and all grid bins that are passed by n1 are marked as used before routing the next net. Lee blocks these bins and treats them as obstacles. Since crossings should be avoided but are allowed for optical NoCs, we enable the following nets to use these bins but penalize a usage as can be seen in Figure 8(b). As penalty factor we choose an adaptive value, which depends on the number of nets that still have to be routed. Using a constant value can increase the number of crossings as illustrated in Fig. 9. Here obstacles are marked with patterns and penalty factor is chosen to be 10. After routing n1 the second net avoids a crossing by routing around n1 . When routing n3 there is no opportunity to avoid a crossings with n1 and n2 . Assuming a factor of 5 for net n2 and a factor of 10 for net n3 routing results in only one crossing (between n1 and n2 ). Hence, an adaptive penalty factor can improve the results and is used for our experiments. cij,rs nrs∈N ,nrs (cid:54)=nij + β subject to 0 ≤ xi ≤ wc ∀i = 1, . . . , n 0 ≤ yi ≤ hc ∀i = 1, . . . , n gij (x) ≥ 0 ∀i, j = 1, . . . , n, i (cid:54)= j. (18) For solving the optimization problem we chose an interior point method introduced by W ¨achter et. al. [10]. This method works iteratively and needs a convex and differentiable objective function and constraints. As a concatenation of differentiable functions the crossing estimation and constraint (15) are differentiable except for all points with xi = xj and yi = yj for any i (cid:54)= j. (19) Equation (19) means that center points of module i and module j share exactly the same position. Since all those points do not fulﬁll constraint (15) and therefore are non-valid points of our optimization problem, they are not relevant in practice. When choosing a starting point with xi (cid:54)= xj or yi (cid:54)= yj for all i (cid:54)= j. (20) The case described in (19) never occurred during our experiments. B. Routing After all PSEs are placed at suitable positions, they are connected by waveguides. First all paths are split into nets as shown in Fig. 4. Routing waveguides in optical NOCs design is similar to 142 Parameters Propagation loss [15] Bending loss [15] Crossing loss (optimized by Elliptical Taper) Drop loss (optimized by Elliptical Taper) Value 1.5 dB/cm 0.005 dB 0.52 dB 0.013 dB TABLE I: Loss parameters C. Maximum Insertion Loss Calculation After routing PROTON counts the number of crossings as well as drops and determines the length of waveguides for each path. Together with loss parameters shown in Table I propagation, crossing and drop loss are calculated as dB · W Lp plp (x,r) =1.5 clp (x,r) =0.52dB · #CRp cm dlp (x,r) =0.013dB · #DRp (21) (22) (23) with W Lp , #CRp and #DRp describing length of waveguides in cm, number of crossings and number of drops in path p respectively. Maximum insertion loss is calculated as ilmax (x,r) = maxp∈P (plp (x,r) + clp (x,r) + dlp (x,r)) (24) If the technology improves in the future only loss parameters have to be adapted. Thus, PROTON is a ﬂexible and technology independent tool for the design of ONoCs. IV. EX PER IM EN TA L RE SU LT S The algorithm is implemented in C++ and all experiments are executed on an Intel Core 2 Quad CPU with 8GB RAM running at 2.33GHz. For solving the optimization problem we use the IPOPT library [12] which is one of the leading libraries in nonlinear optimization. This section is structured as follows: In Section IV-A we compare our tool to a manually created layout. In Section IV-B a study about the calibration of PROTON and the best topology selection is given. As shown in Section IV-C the tool is able to place overly loose as well as overly tight topologies. In Section IV-D the scalability of PROTON is proven. A. Manual vs. CAD In this section, as a case study, we implement the 8x8 λRouter and the 8x8 GWOR using two relevant methodologies: Manual design [6] vs. CAD tool. As insertion loss is the most important physical metric that must be quantiﬁed to determine the laser power that guarantees a predeﬁned bit error rate at receivers, we assess the worst case ilmax for each topology. Our study therefore assumes the loss parameters listed in Table I. Crossing loss and drop loss were obtained by 2DFDTD method. Since every path meets at most one drop and drop loss is very small compared to crossing- and propagation loss it is considered to be negligible. For similiar reasons we did not consider bending loss in our calculations. Moreover, in both methods, we optimize the number of crossings so that the only one objective function being optimized is the crossing loss. We also take for granted the die size of 8mm × 8mm (see above section). Figure 10 shows the insertion loss deviations between manual layout and the automatically generated for both topologies, by assuming the 47.58 40.73 22.62 25.84 Manual design PROTON 50 40 30 20 10 B d n i x a m l i 8x8 λ-router 8x8 GWOR Fig. 10: Insertion loss contrasting manual design vs. PROTON s t t a W n i r e w o p s r e s a L 50 40 30 20 10 44.44 Manual design PROTON 10.49 0.162 0.298 8x8 λ-router 8x8 GWOR Fig. 11: Lasers Power contrasting manual design vs. PROTON standard elliptical tapers at every waveguide crossing [8]. As can be seen manual design and CAD tool feature the same trend. In particular, λ-Router provides lower insertion loss than GWOR in both cases, 40.73 dB vs. 47.58 dB in the manual layout, while 22.62 dB vs. 25.84 dB in the CAD tool. This also optimizes the insertion loss by 65x over the manual layout for λ-Router topology, while by 150x for the GWOR one. The beneﬁt of this effect can be seen when quantifying the laser power requirements. In fact, once the maximum insertion loss across all wavelengths and optical paths is obtained and the detector sensitivity (S) is known, we ﬁnally evaluate the lower limit of optical laser power (P) to reliably detect the corresponding photonic signal at the receiver end. In our evaluation we make the practical assumption that such a worst case ilmax dictates the power needed by all laser sources. For laser sources we assume a laser efﬁciency (PLE) of 20% and a coupling laser-link (PCW) of 90%, while for detectors we consider a sensitivity (S) of −17dBm with a BER = 10−12 . As shown in Figure 11 in both cases λ-Router is clearly most efﬁcient than GWOR due to the lower insertion loss. We note 10.49 Watts vs. 44.44 Watts in the manual layout, while 0.162 Watts vs. 0.298 Watts in the CAD tool. Thanks to the lower insertion loss that CAD tool exhibits with respect to the manual layout, the lasers power requirements are optimized by 98.5% in the λ-Router topology and by 99.3% in the GWOR one. Because the topology is too complex to determine an optimal physical layout manually we obtain much better results using CAD tools. Furthermore PROTON needed only a few seconds while creating the manual design took the authors of [6] approximately one week per topology. 143 B. Best topology selection PROTON minimizes the weighted sum of propagation loss and crossing loss as can be seen in equation (2). Thus, the tool can be calibrated by choosing different values for α and β . Table II shows the results for 8x8 λ-Router, 8x8 GWOR and 8x8 Standard-Crossbar when varying those weights. All topologies are placed on a die area of 8mm × 8mm. Elliptical tapers are assumed for all crossings. The ﬁrst two columns contain the varied weights α and β . The column ilmax gives the maximum insertion loss. The number of crossings and the waveguide length in µm of path p with ilp = ilmax can be seen in column CR and WL respectively. At last CPU time in seconds is presented. As can be seen in the table, maximum insertion loss is high when the number of crossings is high. Thus, insertion loss mainly depends on the number of crossings. Comparing all three topologies λ-Router is the one with lowest ilmax , followed by GWOR and Standard-Crossbar. Hence, λ-Router is the optimal topology to be chosen in terms of maximum insertion loss. PROTON acts very fast on all three topologies with a maximum runtime of 6.3 min. CPU time mainly depends on the number of PSEs and nets. Since number of nets for 8x8 GWOR is lower than for 8x8 λ-Router and 8x8 StandardCrossbar PROTON needs lowest run time for 8x8 GWOR. C. Loose vs. Tight In this section we show PROTON’s ability to work with dense as well as loose die areas. In Figure 12 results for 8x8 λ-Router placed on small and large chip areas are shown. For all experiments we assume a square die area. Chip width and height vary from 4mm to 20mm. Positions of hubs and memory controllers are scaled dependent on the chip width and height. Parameters α and β are chosen considering parameters in Table I. If the die area is too small crossings can hardly be avoided. Enlarging the die area causes a decrease of crossings and ilmax consequentially. When a certain area is reached the number of crossings is optimized and the tool will only scale the layout when the area is increased further. Hence, the length of waveguides will grow insigniﬁcantly while the number of crossings and ilmax is almost constant. Figure 13 shows CPU time compared to chip width. Since CPU time only depends on the number of nets and PSEs it is almost constant when varying chip width. Only when minimizing crossing loss for chip width of 4mm PROTON needs 120 iterations instead of 100 iterations for placing all PSEs overlap-free inside the chip area. When only minimizing propagation loss, the estimation of the number of crossings can be neglected. As can be seen in Figure 13 this is the most time consuming part of the placement algorithm. Minimizing propagation loss needs only 5% of the time when minimizing propagation and crossing loss. D. Scalability In this section we characterize the impact of system scale and we show that PROTON can handle large topologies. As a case study we test the 16x16 λ-router as the best topology of min plp (x, r) min clp (x, r) min αplp (x.r) + β clp (x, r) x a m l i 60 50 40 30 20 5 10 15 20 chip width in mm Fig. 12: maximum insertion loss for different chip densities min plp (x, r) min clp (x, r) min αplp (x.r) + β clp (x, r) s n i e m i t 100 50 0 5 10 15 20 chip width in mm Fig. 13: CPU time in seconds for different chip densities our exploration. We sketch a future generation of our target system, which now consists of 96 cores in the tiled-based electronic layer, while preserving 8 cores for each cluster. For this purpose 12 gateways (or 12 hubs) are needed in the optical plane to directly connect to the corresponding cluster of the electronic plane. Moreover thanks to the beneﬁts of photonic integration deeper into the DRAM DIMM [1] we kept the same number of memory controllers. Hence, the 16x16 λrouter uses 120 PSEs. Note the new die size of 12mm × 16mm. Results are shown in Table III. In the ﬁrst column the objective function is given. The second and third columns show the number of crossings and the waveguide length of path p with ilp = ilmax respectively. CPU time can be seen in the last column. All lengths are given in µm and the times in minutes. Although the number of paths is 5.2x higher compared to 8x8 λ-Router maximum insertion loss increases less than 2.6x. Figobjective function pl(x.r) αpl(x.r) + β cl(x, r) cl(x, r) ilmax 90.2 57.8 60.6 CR 155 101 107 WL 63616 34948 33156 time 5.9 228.8 272.9 TABLE III: Results for larger topology 144 Weights α 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 β 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 8x8 λ-Router CR WL 73 12402 32 9324 46 11682 44 10413 26 13392 42 13203 30 10539 44 13824 39 12366 39 12681 41 8676 ilmax 39.8 18.1 25.7 24.5 15.5 23.8 17.2 25.0 22.1 22.2 22.6 CPU 77 76 79 76 76 76 76 77 77 78 78 ilmax 45.2 23.4 24.5 25.6 25.1 29.8 28.8 26.7 24.7 22.0 25.8 8x8 GWOR CR WL 81 20178 42 10161 44 10476 46 11088 44 14589 54 11241 52 11889 48 11610 44 12258 38 14886 43 23094 CPU 47 50 50 50 53 51 50 51 52 50 51 ilmax 8x8 Standard-Crossbar CR WL CPU 70 25821 351 45 11052 352 55 25362 352 41 24516 359 41 23499 356 46 10782 382 48 18513 352 48 22842 353 53 20007 354 42 19269 351 45 25578 353 40.3 25.0 32.4 25.0 24.8 25.6 27.7 28.4 30.6 24.7 27.2 TABLE II: Results for variation of propagation and crossing loss weights "
2013,Performance evaluation of multicore systems - from traffic analysis to latency predictions (embedded tutorial).,"As technology scaling down allows multiple processing components to be integrated on a single chip, the modern computing systems led to the advent of Multiprocessor System-on-Chip (MPSoC) and Chip Multiprocessor (CMP) design. Network-on-Chips (NoCs) have been proposed as a promising solution to tackle the complex on-chip communication problems on these multicore platforms. In order to optimize the NoC-based multicore system design, it is essential to evaluate the NoC performance with respect to numerous configurations in a large design space. Taking the traffic characteristics into account and using an appropriate latency model become crucially important to provide an accurate and fast evaluation. In this tutorial, we survey the current progresses in these aspects. We first review the NoC workload modeling and traffic analysis techniques. Then, we discuss the mathematical formalisms of evaluating the performance under a given traffic model, for both the average and worst-case latency predictions. Finally, the advantages of combining the analytical and simulation-based techniques are discussed and new attempts for bridging these two approaches are reviewed.","Performance Evaluation of Multicore Systems: From Trafﬁc Analysis to Latency Predictions (Embedded Tutorial) Zhiliang Qian1 , Paul Bogdan2 , Chi-Ying Tsui1 and Radu Marculescu3 1Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong 2Department of Electrical Engineering, University of Southern California, Los Angeles 3Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh ABSTRACT As technology scaling down allows multiple processing components to be integrated on a single chip, the modern computing systems led to the advent of Multiprocessor Systemon-Chip (MPSoC) and Chip Multiprocessor (CMP) design. Network-on-Chips (NoCs) have been proposed as a promising solution to tackle the complex on-chip communication problems on these multicore platforms. In order to optimize the NoC-based multicore system design, it is essential to evaluate the NoC performance with respect to numerous conﬁgurations in a large design space. Taking the traﬃc characteristics into account and using an appropriate latency model become crucially important to provide an accurate and fast evaluation. In this tutorial, we survey the current progresses in these aspects. We ﬁrst review the NoC workload modeling and traﬃc analysis techniques. Then, we discuss the mathematical formalisms of evaluating the performance under a given traﬃc model, for both the average and worst-case latency predictions. Finally, the advantages of combining the analytical and simulation-based techniques are discussed and new attempts for bridging these two approaches are reviewed. 1. INTRODUCTION With technology scaling down, more and more components can be integrated on a single chip. As a result, the modern computing systems led to the advent of Multiprocessor System-on-Chip (MPSoC) and Chip Multiprocessor (CMP) designs. Network-on-Chips (NoCs) have been proposed as a modular and scalable solution for future on chip communications [1]. The design of NoC begins with a speciﬁcation of performance requirements together with some cost constraints. These performance metrics drive the choice of NoC design parameters, such as the routing algorithm, the buﬀer sizing and the ﬂow control scheme etc [2]. When exploring the NoC design space, it is of the utmost importance to provide an accurate and fast evaluation with respect to diﬀerent conﬁgurations. Both the traﬃc variation over time and the latency models are required to capture the router delay behaviors under various traﬃc scenarios. Traditional NoC performance evaluations are predominantly based on the Poisson traﬃc characteristics [3], i.e., the packet interarrival times are exponentially distributed. Typically, the packet service time at each router is also assumed to be exponentially distributed. However, recent researches have demonstrated these assumptions may not hold for many NoC applications [4, 5, 6]. New approaches incorporating these considerations are required to provide more accurate latency/throughput estimations. The purpose of this embedded tutorial is to present recent advances in performance evaluations of NoC-based multicore systems. Towards this end, we ﬁrst identify the NoC dynamics as being highly dependent on the traﬃc patterns variation [5]. Second, we discuss several types of workload models that are able to capture the burstiness and long range dependency (LRD) in traﬃc behavior [5, 7]. Then we discuss the NoC latency prediction models. According to the modeling methodology, NoC performance estimation tools can be categorized into analytical-based and simulation-based models. Analytical techniques for both the average [8] and the worst-case [9, 10] performance metrics are needed to cater for diﬀerent application requirements. In addition to the analytical-based and simulation-based approaches, an open research direction is to combine these two techniques together to exploit the advantages of the high ﬁdelity in simulations and fast speed in mathematical models. Towards this end, we survey several new attempts that utilize machine learning techniques [11] and hardware modeling [12] to accelerate the performance estimation. 2. NOC TRAFFIC ANALYSIS 2.1 NoC workloads To evaluate an NoC design, the most appropriate trafﬁc patterns to use are those generated directly by running the intended applications on the platform that models both the processor cores and the NoC infrastructure. Executiondriven workload is such an approach which emulates the processors in addition to the NoC itself. Although accurate, the execution-driven workload requires a full-system implementation and suﬀers from long evaluation time. Trace-based workload is an eﬃcient alternative under realistic applications. It only evaluates the network model while treating the according to the collected trace. The benchmarks adopted in execution-driven and trace-based workloads usually include multi-threaded applications such as Spec2000/2006 , Splash-2 , Parsec [13] as well as the MPSoC applications such as MMS (Multimedia system)[14], PIP (Picture in picture), MWD (Multi-window detect), MPEG (MPEG decoder) and VOPD (Video ob ject plane decoder) [15]. One limitation of these two types of workload is that it is often diﬃcult to achieve a thorough coverage of all the expected traﬃc as the number of benchmarks is limited. Also, the simulation time is too long to be used in the optimization loop [11, 13]. Consequently, carefully designed synthetic workloads using statistical-based packet injection method [4, 7] are widely adopted due to its higher ﬂexibility and versatility. 2.2 Statistical trafﬁc models for LRD trafﬁc The statistical traﬃc models are important in two aspects: 1) They can help analyze and characterize NoC applications. 2) They can be used to generate new traﬃc traces which possesses features that are not covered by existing applications. Two types of statistical techniques have been developed to take the traﬃc self-similarity (i.e., LRD) into consideration. The ﬁrst one utilizes Hurst parameter H to capture the temporal dependencies [4, 7]. H parameter of an application is ﬁtted by applying the variance-time or R/S statistics [4] techniques on the application traﬃc traces, while Fractional Gaussian Noise (FGN) model is utilized [4] to generate a new synthetic trace. The second method is based on the characterization of the traﬃc using a Markov-modulated Poisson process (MMPP) [8, 16] or a more generalized Markov arrival process (MAP) which models LRD as the superposition of several simple processes. 2.3 Non-stationary NoC trafﬁc modeling The single exponent (e.g., Hurst parameter H ) or MMPP based traﬃc modeling usually focus on matching the ﬁrst and second moments (i.e., the mean and variance) as well as the ﬁrst-order autocorrelations (i.e., ρ1 ) of the time series Xt based on the assumption that Xt is wide-sense stationary (WSS) [4]. These techniques correspond to monofractal traﬃc analysis. On the other hand, the state-of-the-art NoC traﬃc analysis [5] reveals highly nonlinear and nonstationary behaviors in the traﬃc due to the heterogeneous traﬃc sources and continuous changes in the pool of applications running on a multicore platform. Consequently, the traﬃc variation cannot be characterized by a single Hurst exponent, but rather by a series of interwoven time scales deﬁned by several such exponents. Towards this end, a mean ﬁeld (MF) traﬃc modeling technique [5] is proposed to analyze the multifractal spectrum by characterizing the higher order moments in the traﬃc. 3. NOC ANALYTICAL MODELS 3.1 Average-case performance models For the NoCs with best-eﬀort service, the design goal is to provide the highest performance at a given cost, i.e., maximizing the average-case performance metrics within the design constraints. Three types of techniques are used to model the average latency in NoC: the probabilistic models, the network calculus models [17], and the queuing-theorybased models [2, 8, 16]. Among these three techniques, the queuing-theory-based models have gain the most popularity in the average-case performance prediction because of its higher accuracy. A variety of queuing models haven been developed to compute the NoC latency based on various traﬃc models, such as the M/M/1/K [18], M/M/c/K [3], M/G/1/K [19], G/G/1 [8], GE/G/1/K [20] and MMPP/G/1 [16] models. Some of these models target at homogeneous virtual channel architectures [19, 21] while others are designed for routers with heterogeneous virtual channels [3]. Moreover, some models are developed for the cases where packet length is smaller than the buﬀer size [2, 19], while the others are derived for packets with extreme long length such that it can span a set of router buﬀers [3]. 3.2 Worst-case performance models In real-time systems with guaranteed service, the worstcase delay is of particular concern since it is essential to guarantee that tasks will always be ﬁnished before the deadline. Two types of mathematical formalisms are used to derive the delay bounds in QoS NoCs. The ﬁrst type is based on the framework of network calculus (NC) [10]. The second type is based on real-time bound (RTB) formulations [9]. Network calculus is based on the min-plus algebra to obtain the output function from the convolution of the input arrival function and the system transfer function. On the other hand, the real-time bound (RTB) formulation is based on the fact that, the worst-case packet transfer scenario happens when all the intermediate buﬀers along the route are full, and the target ﬂow loses arbitration at all routers against the other contending ﬂows [9]. 4. BRIDGING ANALYTICAL MODELS AND SIMULATIONS 4.1 FPGA-based acceleration engine Instead of evaluating the NoC using software program, the recent trend is to use hardware for acceleration. However, diﬀerent from the traditional approaches which implement the real NoC on hardware (ASIC or FPGA), these new approaches try to abstract the router model at a higher level (for example the mathematical models in [12] or the behavioral models in [22]) and implement the abstracted model on hardware so as to reduce the evaluation time. 4.2 Learning-based performance evaluation Most NoC latency models are based on the classical queuing theory and treat each input channel as a queuing system. These models provide good estimations when the underlying assumptions, such as the Poisson distribution at all traﬃc sources [2] or a single ﬂit buﬀer size [3], hold. However, in real applications, these assumptions may not hold and the accuracy of the analytical model is compromised. In order to relax some of the assumptions above, in [11], a machinelearning based technique is used to model the NoC latency. Given the target NoC platform, a learning-based method is used to create an estimation model by training with datasets obtained from the latency proﬁles ﬁrst. Support vector regression (SVR) and cross validation (CV) are utilized to obtain the channel and source queuing models, respectively. In the prediction stage, the learned model is applied to the new traﬃc patterns to evaluate the latency performance. Compared to the analytical models, better accuracy is achieved in the learning-based model. 83 5. CONCLUSIONS In this paper, we have summarized a few representative approaches for NoC performance evaluation ranging from traﬃc modeling to analytical and simulation-based models for latency predictions. We have also discussed the state-ofthe-art approaches that attempt to bridge the analytical and simulation-based approaches so as to provide both fast and accurate estimations. As NoC has already become a practical solution for handling future multicore communications, the performance evaluation is essential in exploring the NoC design space to obtain the most suitable architecture. One of the promising research directions in future is to further combine the advantages of several performance evaluation methods for better speed and accuracy tradeoﬀs. 6. "
2014,High-radix on-chip networks with low-radix routers.,"Networks-on-chip (NoCs) have become increasingly widespread in recent years due to the extensive integration of many components in modern multicore processors and SoC designs. One of the fundamental tradeoffs in NoC design is the radix of its constituent routers. While high-radix routers enable a richly connected and low diameter network, low-radix routers allow for a small silicon area. Since the NoC consumes a significant portion of the on-chip resources, naïvely deploying an expensive high-radix network is not a practical option. In this work, we present a novel solution to provide high-radix like performance at a cost similar to that of a low-radix network. Our solution leverages the irregularity in runtime communication patterns to provide short low-latency paths between frequently communicating nodes, while infrequently communicating pairs rely on longer paths. To this end, it leverages a flexible topology reconfiguration infrastructure with abundantly available links between routers (in accordance to a high-radix topology) that are decoupled from scarcely available router ports (similar to a low-radix topology). Network links are bound to router ports at runtime to form connected and deadlock-free topologies. Binding selections are based on the traffic patterns observed, which are synthesized through a distributed statistics-collection framework. Our experiments on a 64-node CMP, running multiprogrammed workloads, show that we can reduce average network latency by 19% over an area- and power- comparable mesh NoC. The latency improvements for non-uniform synthetic traffic are above 30%.","High-Radix On-chip Networks with Low-Radix Routers Animesh Jain, Ritesh Parikh and Valeria Bertacco Department of Computer Science and Engineering, University of Michigan {anijain, parikh, valeria}@umich.edu Abstract—Networks-on-chip (NoCs) have become increasingly widespread in recent years due to the extensive integration of many components in modern multicore processors and SoC designs. One of the fundamental tradeoffs in NoC design is the radix of its constituent routers. While high-radix routers enable a richly connected and low diameter network, low-radix routers allow for a small silicon area. Since the NoC consumes a signiﬁcant portion of the on-chip resources, na¨ıvely deploying an expensive high-radix network is not a practical option. In this work, we present a novel solution to provide high-radix like performance at a cost similar to that of a low-radix network. Our solution leverages the irregularity in runtime communication patterns to provide short low-latency paths between frequently communicating nodes, while infrequently communicating pairs rely on longer paths. To this end, it leverages a ﬂexible topology reconﬁguration infrastructure with abundantly available links between routers (in accordance to a high-radix topology) that are decoupled from scarcely available router ports (similar to a lowradix topology). Network links are bound to router ports at runtime to form connected and deadlock-free topologies. Binding selections are based on the trafﬁc patterns observed, which are synthesized through a distributed statistics-collection framework. Our experiments on a 64-node CMP, running multiprogrammed workloads, show that we can reduce average network latency by 19% over an area- and power- comparable mesh NoC. The latency improvements for non-uniform synthetic trafﬁc are above 30%. IN T RODUC T ION I . As a result of increasing integration of components into CMP and SoC architectures, networks-on-chip (NoCs) have become the dominant choice for on-chip interconnects, due to the highly concurrent communication paths and better scalability they provide. Moreover, to keep up with the communication demands of the cores/IPs on-chip, NoCs are increasingly incorporating bulky and power-hungry resources, required to meet target latency and bandwidth goals. A key design choice in this context is the radix of the network routers, that is, the number of I/O ports that a router provides to connect to adjacent routers High-radix routers (>5 I/O ports) enable low-diameter topologies, allowing all processing nodes to be reached in just a few hops from any source. However, router components, such as the crossbar and the allocators, grow in area quadratically with the radix of the router. In addition, high-radix routers lead to increased signal propagation latencies, and slower operating frequencies. A popular alternative are topologies deploying low-radix routers (<5 I/O ports), such as meshes: they can operate at higher frequencies and use less area and power. For example, a radix-7 router requires a 4.1% greater cycle time than a radix-5 router. Unfortunately, low-radix topologies could lead to large network diameter and prohibitively high hop counts. They are especially problematic for applications that do not have sufﬁcient memory-level parallelism (MLP) to hide their higher latency. To overcome the limitations above, in this work we present HiROIC (High Radix On-chip Networks at Incremental re-Conﬁguration Cost). With HiROIC we want to provide the best of both classes: the effective network diameter of high-radix topologies and the low resource requirements of low-radix networks. HiROIC exploits the nonuniformity of communication patterns to provide short, low latency paths only between heavily communicating nodes, while it forces low volume source-destination pairs to use longer paths. With the increasing integration of application-speciﬁc components [4], the location and quantity of heavily used routing paths is likely to be highly unbalanced both across and within applications. In such designs, only a small subset of accelerators will be active at any point in time, and this subset will actively communicate with memories banks distributed across the chip. Being able to optimize the latency between selected nodes (active accelerators and memory banks) at runtime, will greatly beneﬁt such designs. We therefore envision great potential for the deployment of HiROIC in upcoming CMP and SoC designs. HiROIC leverages routing and topology reconﬁgurations to optimize connectivity for high-volume source-destination pairs. At the heart of HiROIC is the concept of port-link decoupling: network links are connected to routers’ ports only at runtime, and the binding is modiﬁed dynamically based on the changes in trafﬁc patterns imposed by the application. Our NoC design includes low-radix routers, but abundant links, as in high-radix topology, so to potentially provide short paths between any source-destination pair. In HiROIC, computation is partitioned into epochs of execution, with port-link binding ﬁxed during each epoch. At the end of an epoch, the mapping is re-evaluated based on the observed trafﬁc patterns, and modiﬁed if there is space for improvements. While HiROIC’s wiring overhead is greater than conventional topologies (e.g., meshes), we observe that wires do not constitute a timing bottleneck in conventional router pipelines [10]. Note that, in typical NoCs, routers have one local port connecting to the processing node(s). Since this connection is essential, HiROIC uses a ﬁxed port-link binding for local ports. In the rest of this paper we exclude the local port(s) when reporting the radix of the router. ) % n i ( c i f f a r t k r o w t e n 100 80 60 40 20 0 Region of interest Region of interest > 60% 75 60 45 30 15 0 ) % n i ( c i f f a r t k r o w t e n 0 20 40 60 80 100 0 2 4 6 8 10 12 cumulative source-destination pairs(in %) – high to low traffic sharing Fig. 1: Network activity shared by the most exercised source-destination pairs. The plot on the right is an enlargement of the one on the left. The top 10% source-destination pairs are collectively responsible for more than 60% of the total network trafﬁc. It is essential for HiROIC to have a high variation between highusage source-destination pairs and other source-destination pairs. To this end, we conducted a study whose ﬁndings are plotted in Figure 1. The plot shows the contribution of trafﬁc ﬂowing between each sourcedestination pair. Our testbed consisted of an 8x8 mesh CMP running a multiprogrammed mix of applications from the SPEC CPU2006 suite. Source-destination pairs are sorted by decreasing trafﬁc activity during the execution, and the plot on the left indicates what fraction of network trafﬁc (Y axis) was carried out by a given fraction of sorted pairs. The plot on the right is an enlargement of the contribution by the top 12% source-destination pairs: less than 10% of them share as much as 60% of the trafﬁc load on average. Beyond the tenth percentile of utilization, this disparity is no longer obvious. Thus, HiROIC’s goal is to leverage the 10% most used pairs to provide short and high-bandwidth paths between them. This, in turn, minimizes the effective network hop count. Contributions. In summary, the novel contributions of this work are: • A router architecture to mimic the high-radix routers’ connectivity while consuming resources comparable to a low-radix router. • A distributed, deadlock-free reconﬁguration algorithm to predict an application’s future communication needs and optimize the network topology to provide short paths between high-trafﬁc sourcedestination pairs. In our evaluation with non-uniform multiprogrammed workloads from the SPEC CPU 2006 suite, HiROIC’s 64-node layout reduces average network latency by 19% compared to a baseline mesh NoC. For non-uniform synthetic trafﬁc, latency improves from 30% to 38%, depending on physical topology and trafﬁc injection rate. I I . R E L AT E D WORK Much of the research targeting performance improvements in NoC designs has focused on: i) reducing the number of pipeline stages within the router [14], and ii) increasing the clock frequency of the router’s operation [2]. Other works strove to optimize the router design for speciﬁc topologies and ﬂow control [9]. Our work leverages an orthogonal approach to improve performance – decreasing the average packet’s hop count. Previous works that leveraged application-driven conﬁguration for the NoC targeted the design phase of the NoC, with no ability to reconﬁgure at runtime. These solutions would characterize all applications that were expected to run on the system and then, based on the analysis, optimize the design’s: i) topology [17], ii) routing [12], etc. In contrast, HiROIC adapts dynamically to changing application patterns and reconﬁgures the topology at runtime. Runtime reconﬁguration solutions have also been proposed to optimize either power or performance. To reduce NoC leakage power, 978-1-4799-6278-5/14/$31.00 ©2014 IEEE 289             Glue logic links links router ports ports xbar ports ports Examples links links links links links Fig. 2: Router architecture and port-to-link binding. The router in the ﬁgure can connect its four router ports to eight available neighboring links, by assigning the multiplexers’ select signals accordingly. On the right we show 3 such possible bindings. researchers have proposed power-gating network resources at a coarse or ﬁne granularity, during periods of inactivity. Other examples include [8], which reconﬁgures routing at runtime to provide better management of hotspots, and [7], which improves performance by adapting the channel’s bandwidth. All these techniques provide valuable beneﬁts and can be deployed concurrently with HiROIC, which targets dynamic topology reconﬁguration, to attain additional gains. There is also a body of work related to runtime topology reconﬁguration whose goal, however, has been reliability. In these solutions, for instance Ariadne [1] and uDIREC [13], the topology changes because of a runtime fault, and the authors propose reconﬁguration techniques to update the routing function. HiROIC’s key contribution is a dynamic topology reconﬁguration solution; upon each reconﬁguration we also must perform a routing reconﬁguration, based on the solution in [1]. I I I . ME T HODO L OGY Our solution leverages port-link decoupling to mimic high-radix topologies, while utilizing an amount of resources comparable to a low-radix topology. To optimize the topology for high-volume communication patterns, we perform the following steps: i) we collect trafﬁc statistics over execution intervals (epochs) to predict future trafﬁc behavior, ii) we trigger topology reconﬁgurations when we observe pattern changes, and iii) we set port-link bindings at each router based on the new topology planned. In conventional networks, router ports have ﬁxed one-to-one mapping with links. In contrast, we propose to provide more links than those available in low-radix topologies, eliminating the traditional ﬁxed connections. At runtime, router ports are bound to a subset of the available links, based on the application’s communication demands. The internal micro-architecture of the router is not modiﬁed, with the exception of the necessary updates to the routing tables, based on the selected conﬁguration. Figure 2 shows on the left the schematic of a four-port HiROIC-enabled router with the opportunity to bind to eight links. The glue logic in the hashed area comprises multiplexers to complete the bindings. The right side of the ﬁgure presents three examples of port-to-link bindings for the router. HiROIC’s Execution Flow. In HiROIC, the NoC’s execution is partitioned into epochs. During each epoch, our distributed trafﬁcstatistics collection framework monitors the density of communication between all source-destination pairs. Our goal is to identify the pairs that transfer the majority of the trafﬁc (see also Figure 1) so as to minimize their hop count. In the rest of this paper, we will refer to any such pair as the Frequently Communicating Pair (FCP). At the end of each epoch, we analyze the composition of the FCP set and determine whether a topology reconﬁguration should occur to improve on the current port-link binding. Figure 3 provides an overview of this process. Note that our approach strives to predict application’s demands based on the trafﬁc observations during the current epoch. This is a valid approximation, as long as our epochs are short compared to the frequency of major phase changes in the application’s behavior. We observe that, in practice, applications’ phases are at least hundreds of thousands of cycles long ; thus, in our evaluation we set the epoch 12 13 14 15 Epoch starts h c o p e h t N 8 4 0 9 5 1 10 11 6 2 7 3 n o i t a r u d h c o p E Statistics collection framework FCPs during completed epoch 0 6 15 9 Topology reconfiguration phase  12 13 14 15 A) Invoke topology reconfiguration B) Create port-link bindings for FCP h c o p e h t ) 1 + N ( 8 4 0 9 5 1 10 11 6 2 7 3 C) Topology configuration for  non-FCP D) Topology & routing updates  propagate through the NoC links active to optimize FCPs connectivity links to connect all other nodes Fig. 3: HiROIC execution ﬂow. Application’s execution is partitioned into epochs. During each epoch, HiROIC monitors the NoC’s trafﬁc patterns. At the end of the epoch, the data is used to determine whether a topology reconﬁguration is appropriate. If so, the new conﬁguration aims at minimizing the distance between FCPs. length to 10,000 cycles, so to be able to quickly respond to signiﬁcant trafﬁc pattern changes. In the next sections we present a distributed, fast and low-overhead implementation of this collection and reconﬁguration process. Note that this reconﬁguration process operates mostly in the background, with minimal impact to mainstream network operation and only during transitions between topologies. IV. TO PO L OGY R E CON FIGURAT ION Considering the complexity of the decision and reconﬁguration process, at ﬁrst a software implementation would seem a prudent choice. However, it would require collecting all trafﬁc statistics at a central processing node, where a dedicated software routine ranks source-destination pairs by trafﬁc density, determines if a topology reconﬁguration should occur and what the new setup should be; then the new binding information should be distributed to the NoC routers. The cost in latency and dedicated resources of this approach makes it impractical in the context of the epoch sizes we target. Thus, we opted to implement HiROIC using lightweight, distributed hardware components implementing an approximation of the ideal algorithmic solution, for the beneﬁts of design simplicity and to attain low-latency reconﬁgurations. The hardware components added to each router are shown in Figure 4. In addition we leverage a minimalistic topology-generator network to control the distributed construction of new topologies. We describe this solution below and provide insights on the hardware additions in the next section. Port-link bindings for FCPs. During each epoch, we collect trafﬁc statistics at each router in the trafﬁc directory unit. This unit counts the packets received from each source, and thus allows us to determine the frequently communicating pairs (FCPs) in a distributed fashion. The selection is made by comparing the number of packets received from each source against a network-wide threshold, called H T th , which varies dynamically. Once the FCP set for each router is determined, the next step is to enable the NoC’s links that facilitate low-latency communication for those critical pairs. These links are selected by traversing the network, router by router, and building low-latency paths connecting the FCPs. The traversal is performed router by router, starting from the router connected to processing node 0, and with each router providing some (or none) of the FCP. At any particular time, the router providing the information about the FCPs to connect is referred to as the controller router. For each FCP entry from a controller router, HiROIC attempts to enable all the links between the source and the controller router. This is achieved by using the low-overhead topology-generator network, and a small logic block that activates the appropriate select signals on the multiplexers, so to enable the links on the shortest path between the relevant source and destination routers. The controller router chooses ﬁrst a FCP entry and then performs the port-link binding to enable the adjacent link on the shortest path from the source node. The port-link binding activity is then transferred to the neighboring router on the shortest path by using the link just enabled. 290       In turn, the neighbor router performs the port-link binding along this designated shortest path. This process continues until the source node is reached. The control is then transferred back to the controller router, which moves on to perform port-link bindings for the next FCP entry. Once the controller router has completed all the bindings for its FCP entries, the control moves to the next router. This completes the ﬁrst phase of the topology reconﬁguration algorithm. Port-link bindings for non-FCPs. In our distributed algorithm, we use aggressive settings for the H T th threshold, thus it is often the case that we can enable all the links required to provide shortest paths for the FCPs, and still have several disconnected ports in a number of routers. Therefore, the second phase in topology reconﬁguration binds the free router ports to links that are still available. This is also achieved by traversing the network, router by router. Each router chooses among locally-available port-link bindings in a greedy fashion until it has bound all its ports, or it has run out of binding options. While this greedy approach does not lead to an optimal mapping with maximum port-link bindings, it still provides very good solutions, as our experiments show that 94% of the routers are able to bound all their ports to links. Note that this kind of greedy approach to binding ports to links may not always result in a fully connected network. We ran several Monte Carlo simulations to evaluate the frequency of this situation and found that disconnected networks are in practice a rare event, occurring only 5 times in 1,000 topology reconﬁgurations. Fortunately, this situation can be easily detected when we apply the routing reconﬁguration algorithm to the new topology: if any destination router is not reachable in at least one routing table, the network is disconnected. When this situation occurs, HiROIC broadcasts a 1-bit disconnect signal to all the routers through the topology-generator network. Upon reception of the signal, all routers revert the topology back to a baseline low-radix topology (a 2D mesh in our evaluation). To perform this step quickly, HiROIC maintains a register at each router storing port-link bindings corresponding to the baseline topology. Overall, since this is a rarely occurring situation, it does not signiﬁcantly affect HiROIC’s overall adaptivity to application’s communication needs. Routing in the new topology. After the generation of the new topology is complete, all routing paths must be updated. To this end, we leverage Ariadne’s route-reconﬁguration algorithm [1]: Ariadne was proposed for reconﬁguration around faulty components and, due to the increasing reliability concerns with shrinking transistor sizes, we assume the Ariadne functionality to be already present on-chip. Ariadne leverages the up*/down* algorithm [16] for routing in irregular networks, while proposing a quick and lightweight distributed implementation to update routes upon each topology change. Ariadne is reported to reconﬁgure a 64-node network in only ∼4K cycles, and it is therefore an ideal ﬁt for HiROIC, if reconﬁguration is triggered once every few epochs. A. Topology Conﬁguration Performance The time required to complete topology reconﬁgurations is driven by three factors: i) time to build a new topology (∼500 cycles), ii) time to calculate new routes (∼4K cycles), and ii) time to drain packets that were in ﬂight during the reconﬁguration – so to avoid deadlocks, lost or dropped packets (∼200 cycles). We propose to hide the latency imposed by the ﬁrst and second factor by using duplicate routing tables and link-to-port conﬁguration registers. We can use this shadow set of storage to compute topology and routing tables in the background, while communication proceeds in the old topology. We then copy over the new conﬁguration and routes, once their generation is complete. In addition, to switch topology conﬁgurations quickly and still avoid lost and dropped ﬂits, we assume a router design where the size of the input buffers is a multiple of the number of ﬂits possible in a packet. With this assumption, any time we need to switch to a new topology, we advance communication for a few cycles, until each packet sits entirely in one router. This goal can be accomplished by forbidding packets to access new buffers by temporarily disabling the virtual channel allocation (VA) unit. In the worst case scenario, where each packet is waiting for traversal of the packet at its downstream router, it will take 64*3=192 cycles for a 64-node system with 3-stage routers to complete this task. At that point, we can switch to the new conﬁguration. Reconﬁguration-induced deadlocks. HiROIC’s reconﬁguration algorithm can cause routing deadlocks even if both the old (before topology reconﬁguration) and new (after topology reconﬁguration) routing functions are independently deadlock-free [11]. Such deadlocks can be CC Exceptionhandling unit Thresholdupdate unit CC source No of packets 1 125 2 20 3 200 4 10 ports CC Reconf.  trigger Traffic  directory Constraint  checker CC increase threshold to  boost FCN set HTTH += ∆HTTH at end of  epoch Yes Exception? No for 10  consecutive  epochs? Yes No HTTH -= ∆HTTH decrease threshold to   shrink FCN set Fig. 4: HiROIC hardware additions. HiROIC augments each router with ﬁve components (shown in dark green): i) a trafﬁc directory to count packets received from other routers, ii) a reconﬁguration trigger unit, iii) constraint checkers to check whether a port is already bound to a link, iv) an exception-handling unit to detect execution anomalies, and v) a thresholdupdate unit to adjust the packet threshold according to application needs. The right side of the ﬁgure shows the threshold-update algorithm. easily detected by identifying packets that are requesting illegal turns under the new topology. We eject such packets to the network interface at the local router port, and then re-inject them into the network upon buffer availability. Ariadne [1] utilizes a similar technique to overcome reconﬁguration-induced deadlocks. V. HARDWAR E ADD I T ION S As mentioned earlier, our implementation consists only of simple adders, comparators and storage structures, distributed in the NoC. As illustrated in Figure 4, HiROIC’s hardware implementation consists of ﬁve components at each router: i) a directory to maintain per-destination trafﬁc statistics, ii) a reconﬁguration-trigger unit, iii) a distributed constraint checker (CC), iv) an exception-handling unit and v) a thresholdupdate unit. Below, we discuss each unit in detail, along with the steps of the topology construction. Finally, a minimalistic topology generator network is used to control the distributed construction of new topologies. A trafﬁc directory is placed at each router so that it can track all those source-destination pairs that have it as destination. HiROIC utilizes this information to determine the FCP set at the end of each epoch. This solution requires packets to carry their source node IDs, but this is a common practice in commercial NoC designs . To approximate a centralized, global computation of the FCP set (see Section III), we compare entries in the trafﬁc directory against a threshold value (hightrafﬁc threshold, or H T th ), stored at each router and managed dynamically through the threshold-update unit. All entries in the directory are compared against this threshold value: if the number of packets received from a given source is higher than the threshold, than the corresponding pair is included in the FCP set. The complete FCP set corresponds to the union of each router’s FCP set – although we never compute this union and we keep the set distributed through all routers. The ideal H T th depends on the epoch’s length and on the communication load of the application, and thus it must be adjusted dynamically. Our experiments across a range of workloads show that sourcedestination pairs transferring more than ∼256 packets within a single epoch of 10,000 cycles, are well above any dynamically generated hightrafﬁc threshold, irrespectively of network load. Thus, we set trafﬁc directory entries to be 8-bits wide (note that this design parameter depends on epoch’s length). In our experiments, we use a network with 64 routers, thus the trafﬁc directory at each router consists of 64*(8+6) = 896 bits, where 8 bits store the number of packets received from a given source, and 6 bits represent the source router tag. Constraint checker. It is not always possible to enable the shortest paths between all FCPs. This is because HiROIC’s architecture is limited by: i) the number of available router ports, and ii) the ﬂexibility provided by the glue logic binding links and ports. Therefore, a check is performed after enabling each link to determine that these constraints are not violated. If any constraint is violated for any port-link along the path of an FCP, then all the links bound for that path are released. Constraint checking is fairly straightforward: a port-link binding cannot be performed if the concerned port is already bound to another link. Reconﬁguration-trigger unit. A reconﬁguration event involves proce291 dures that require signiﬁcant activity. Fortunately, applications do not change phase as quickly as our target epoch length (see Section III). Thus, we trigger reconﬁguration only when the application’s communication patterns have changed signiﬁcantly, and the current topology no longer provides low-latency paths for the current FCP set. Since ours is a distributed solution, we monitor for communication pattern changes locally, and each router is capable of triggering a reconﬁguration if it detects signiﬁcant changes. Speciﬁcally, we check for the following two conditions: i) the set of FCP entries should have at least three new members compared to the last reconﬁguration, and ii) the FCP set should contribute at least 50% to the total router’s trafﬁc. The ﬁrst condition ensures that changing the topology will signiﬁcantly perturb the system, while the second condition guarantees the existence of non-uniform trafﬁc patterns. We have calibrated these decision parameters through design space exploration and by taking into consideration hardware implementation costs. (for instance 50% of total trafﬁc can be checked with a shift-and-compare operation, while other fractions may require far more complex computations). The exception-handling unit monitors i) network congestion and ii) number of FCP entries per router, and then uses this information to update the H T th threshold value. Congestion is a limiting issue in irregular topologies at medium-to-high trafﬁc because they fail to appropriately balance trafﬁc. At the onset of congestion, the beneﬁts of shorter paths with irregular topologies are diminished, as packets have to wait longer for free channels and buffers. Our analysis shows that, in these situations, a baseline topology (such as 2D mesh in our case) may better balance trafﬁc, and thus leads to less congestion. HiROIC leverages a local congestion detection metric (maximum buffer occupancy - called BFM in [6]): the network is considered congested if the BFM value is above a certain threshold (we found 20 to strike a good balance in our evaluation setup). Upon detecting congestion, the exception-handling unit broadcasts a 1-bit signal, similar to the disconnection signal, to all the routers. Once again, the routers revert to their baseline topology on reception of this signal. The exception-handling unit also provides feedback to the thresholdupdate unit. By maintaining a suitable H T th value, HiROIC ensures that the topology is reconﬁgured for an optimal number of FCP entries. Our experiments show that reconﬁguring the topology for up to 50 FCP entries, results in increasing improvements over the baseline topology. Beyond 50 FCPs, the topology reconﬁguration algorithm is unable to provide optimized paths for all FCPs, and this results in diminishing returns. However, controlling precisely the number of FCP entires in the network requires collection and sorting of usage statistics at a central node. For a distributed and fast implementation like ours, we control the number of FCP entries approximately by using only local criteria. The expectation is that by controlling the number of FCP entries per router, the number of FCP entries can be controlled globally. Also, by using a consistent H T th value throughout the network, HiROIC ensures that all selected FCPs have higher usage than all other source-destination pairs. We experimentally determined that if the number of FCP entries at any router is more than four, then topology reconﬁguration will provide little beneﬁt due to excessive FCP entries. Consequently, increasing H T th , which in turn reduces the number of FCP entries, will likely result in performance improvements. In practice, we want to keep the number of FCPs in each router within a close range of 4-5 pairs, and we keep pushing the threshold until we stabilize on that size. Such a simple scheme provides a suitable trade-off between topology optimality and simplicity of the hardware implementation. Thus, the exceptionhandling unit at any router broadcasts a “H T th increase” ﬂag globally, if the number of locally selected FCP entries are greater than four. A threshold-update unit is deployed at each router and controls the high-trafﬁc threshold by monitoring the broadcasts from the exceptionhandling units. Notice that H T th affects directly the FCP set: the higher the threshold the fewer the pairs included in the FCP set. In addition, a suitable H T th depends on the application: a communicationlight workload will have a lower suitable H T th , compared to a communication-heavy workload. Therefore, HiROIC can adapt to the needs of the application by tuning this value. Increases to the high-trafﬁc threshold value arise when there are changes in the workload communication density, from light to heavy, and they are triggered by the exception-handling unit. The opposite trend, trafﬁc becoming lighter, is detected when HiROIC does not observe any exception for a number of consecutive epochs, indicating that we should include more pairs in the FCP set. We set the parameters of our algorithm by sweeping a range of values and selecting the most ﬁtting ones: we initialize the H T th at a moderately high value of 96 packets to prevent over ﬁtting. HiROIC gradually adapts to the network’s demands by varying H T th in quanta of 8 packets. If we also do not observe an exception for 10 consecutive epochs (indicating a decrease in trafﬁc), then we decrement H T th to optimize for more FCPs. The topology-generator network serves two purposes: i) transfer of control between routers during the building of a new topology, and ii) network-level broadcasts to notify all routers about exceptions detected locally at any router. For the former, the topology generator network employs 1-bit links per channel of the underlying NoC to communicate port-link binding signals. For the latter, the topology generator network deploys two 1-bit wires organized as a unidirectional ring that visit all routers in the NoC. Any router can broadcast exception detection ﬂags using these wires. The ﬁrst 1-bit wire is used to broadcast the “disconnection” or “congestion” ﬂag. Both ﬂags are identical in their effects and therefore they can be broadcasted on the same wire. The second 1-bit wire is used to broadcast the “H TT H increase” ﬂag. All routers have distributed controllers that snoop and forward these broadcasted ﬂags. V I . P HY S I CA L TO PO L OG I E S The key idea behind HiROIC is to emulate a router with more links than available ports. We refer to a particular arrangement of physical links and ports, independently of any binding, as a physical topology. In physical topologies, links are available in accordance to a high-radix topology (e.g., 3D torus), while ports are those of a low-radix router (e.g., 2D mesh routers). Naturally, HiROIC’s efﬁcacy greatly depends on the arrangement of links and ports within the physical topology. In our evaluation, we consider two such topologies: both use routers with only four ports (plus a port connecting the local node), as in a mesh. We argue that due to the similar router structure and considering powergating of idle links, both topologies have power and area characteristics similar to a 2D mesh network. Therefore, all performance analysis is against a 2D mesh topology. Notice that a traditional 2D mesh has a one-to-one binding between ports and the links, as depicted in Figure 5(a). We implement HiROIC with the following physical topologies: routers used for illustration x-dimension i n o s n e m i d y (a) 2D mesh topology (b) x-y plane of 3D torus  topology (c) x-y plane of 4-ary 4-fly  flattened butterfly topology Fig. 5: Organization of links and routers in proposed physical topologies. We consider two topologies for links: a 3D torus and a ﬂattened butterﬂy. Routers are organized as in a 2D mesh. For simplicity of illustration, the ﬁgure shows the x- and y- dimension connections only for the bold colored routers. 3D torus routers have two connections in each dimension, while a 4-ary 4-ﬂy ﬂattened butterﬂy has three per dimension. Adaptive 3D Torus. Because of its high-radix(6) routers, the average hop count between the nodes of a 3D torus is substantially lower than that of a 2D mesh. We propose a HiROIC-enabled adaptive 3D torus physical topology that organizes links as in a 3D torus, while maintaining radix-four routers. Adaptive Flattened Butterﬂy. A ﬂattened butterﬂy further reduces the average hop count compared to 3D tori. For our 64-node NoC, a 4ary 4-ﬂy ﬂattened butterﬂy arranges the routers in three dimensions, with direct links between routers on the same (x, y), (y, z) or (z, x) dimensions, as shown in Figure 5(c). Our second physical topology is an adaptive ﬂattened butterﬂy (radix=9) topology with radix-four routers. All routers are augmented with glue logic that incorporates multiplexers to bind ports and links at runtime. The size and the number of multiplexers depend on the number of links a particular router port can bind to. To understand the trade-off between multiplexer overhead and binding ﬂexibility, consider the scenario in which an adaptive 3D torus router is provided full ﬂexibility to connect any port to any link. In such a scenario, each output port can connect to any of the six links, requiring six 4:1 multiplexers. On the other hand, each input port can be bound to any of the four incoming links, resulting in four 6:1 multiplexers. Such a degree of multiplexing typically leads to layout challenges, in 292 addition to area and power overhead. Glue logic Link 6 mux Link 5 Glue logic Link 6 Link 5 mux Link 1 m u x Link 4 Router x u m x u m Router mux Link 4 Link 1 x u m Link 2 Link 3 mux a) Link 2 Link 3 b) Fig. 6: Glue logic for an adaptive 3D torus router. Glue logic select signals are set in accordance to the new port-link bindings. We experimentally concluded that increasing port-link binding ﬂexibility beyond a certain degree is not beneﬁcial, considering the extra logic overhead. We therefore decided to limit the number of links a port can choose from: in our adaptive 3D torus topology, each output port can connect to one of three output links (one in each dimension). Of course, this restriction prohibits some port link bindings: with reference to the example of Figure 6(a), the router can only make two connections from the set of links 1, 2 and 6. With these restrictions, each output link can connect to one of two ports, and therefore six 2:1 multiplexers are sufﬁcient for the output glue logic. For the input glue logic, each input port can bind to one of three links, resulting in four 3:1 multiplexers, as shown in the Figure 6(b). Similarly for the adaptive ﬂattened butterﬂy topology, we restrict each router’s output port to connect to one of six output links (two in each dimension). This restriction results in the addition of one 6:1 and three 3:1 multiplexers for the input glue logic, while using six 2:1 and three 4:1 multiplexers for the output glue logic. The restrictions on port-link bindings act as constraints in the topology reconﬁguration algorithm (Section V). First, each router can never connect to more links than its number of ports (four in our physical topologies). Additional constraints are speciﬁc to the topology and arise from the limited ﬂexibility of the glue logic, as described above. As it is common in constraint satisfaction problems, some input conditions might not result in a solution satisfying all the constraints. In order to improve the chances of a valid solution, we relax the constraints that are not vital for correct functionality. Particularly, our reconﬁguration algorithm accepts topologies with routers having fewer than four enabled ports. We are therefore able to achieve fully-connected and valid topologies on 99.5% of the reconﬁguration events, as reported in Section IV. Obviously, these relaxed constraints can result in routers with fewer active ports, and thus they can increase the average hop count. To estimate the effect of constraint relaxation, we conducted Monte Carlo simulations to determine the fraction of routers that do not bind all of their four ports upon a topology reconﬁguration. Table I indicates that, even after binding ports and links for 50 FCPs on an adaptive 3D torus, 94% of the routers bind all their ports. This result provides empirical evidence that our relaxed constraint has minimal impact on port utilization. (a) Adaptive 3D torus Number of pre- % of routers selected links completely bound 10 96.46 20 95.67 30 95.18 40 94.65 50 94.36 (b) Adaptive ﬂattened butterﬂy Number of pre- % of routers selected links completely bound 10 97.71 20 97.18 30 96.53 40 96.32 50 95.68 TABLE I: Topology conﬁgurations allowing unbound router ports – analytical study. The Monte Carlo analysis uses up to 50 FCPs, then binds the remaining ports. The table shows that ∼95% routers still bind all their 4 ports. V I I . E X P E R IM E N TA L R E SU LT S We evaluated HiROIC on a cycle-accurate trace-driven multi-core simulator [5]. Table II shows the characteristics of the processors and the NoC we evaluated. We ran all experiments considering a 64-cores CMP as a baseline. The application traces were obtained using the PIN instrumentation tool. The simulator further incorporates a detailed model of the NoC with 3-stage pipelined routers. We implemented our scheme on top of an adaptive 3D torus and an adaptive ﬂattened butterﬂy, as discussed in the previous section. All our comparisons are with respect to a baseline 2D mesh. Finally, we use an optimized version [15] of the up*/down* [16] routing algorithm for the HiROIC-enabled NoC, while the baseline system uses XY routing. Cores coherence L1 cache L2 cache Memory (a) Processor @2GHz 2-wide fetch/commit 64-entry ROB 4-hop MESI, 64B block Private: 32KB/node ways:4 latency:2 Shared: 256KB/node ways:16 latency:6 Distributed: 1GB/bank banks:4 latency:160 (b) Network @2GHz Topology 8x8 mesh, 128 bit links Pipeline 3-stage VC ﬂow ctrl VCs 4 VCs/port, 8 ﬂits/VC Routing up*/down*,XY RoutingAriadne [1]: new Update up*/down* routes multi-programmed: SPEC CPU 2006 10M cycles Simulation Workload TABLE II: Experimental CMP: conﬁguration of processor and network. A. Synthetic Trafﬁc Our ﬁrst set of experiments injects the NoC with synthetic normal random trafﬁc. Normal random trafﬁc is the most adverse trafﬁc pattern for topology optimization, since it does not create any imbalance on the network. Since all nodes share similar amounts of trafﬁc, the FCP set should ideally be empty and topology reconﬁguration should never be triggered. However, since we use a distributed approximation for our algorithm, we may observe some reconﬁguration invocations. For the set of decision parameters discussed in Section V, however, we do not observe any reconﬁguration invocations in this experiment, leading to our adaptive topologies behaving exactly as a 2D mesh. 100 ) l l s s e e c c y y c c ( ( y y c c n n e e t t a a l l t t e e k k c c a a p p . . g g v v a a 2-D Mesh 2-D Mesh Number of FCPs= 15 Adaptive 3-D Torus Adaptive Flattened Butterfly 80 60 40 20 0 0.1 0.2 0.3 0.4 0.5 Injection rate for FCPs Fig. 7: Average network latency under directed trafﬁc. The plot compares the average network latency for three topologies under directed trafﬁc with increasing injection rate for the FCPs. HiROIC provides low-latency paths between FCPs, resulting in signiﬁcant overall latency improvements. HiROIC is expected to provide latency improvements when some source-destination pairs transfer more trafﬁc than others. We created synthetic directed trafﬁc to gain more insights into the strengths and limitations of our scheme. Our synthetic directed workloads consist of 20 phases, each of which lasts 50 epochs and has a number of frequently communicating pairs (FCPs). The new FCP set is randomly selected after each phase. Correspondingly, HiROIC triggers a new reconﬁguration after each phase change. Other network nodes produce trafﬁc at low injection rate (0.005 ﬂits/node/cycle). Figure 7 compares the average latency of the topologies under consideration with directed trafﬁc using 15 FCPs. On the x-axis we sweep the injection rate for the FCPs. To compare latency improvements, we deﬁne three trafﬁc load levels for the FCPs: low, medium and high. Low trafﬁc corresponds to 0.1 ﬂits/node/cycle, and it is the lowest injection rate used in our experiments. The medium and high injection rates are deﬁned as the injection rates where the network latency for the 2D mesh is 1.5× and 2× that of the low-load latency. We observe that the latency improvement over 2D mesh for adaptive 3D torus is 22.7%, 29.3% and 36.9% for low, medium and high injection rates, respectively, while the corresponding latency improvements for adaptive ﬂattened butterﬂy are slightly better at 30.8%, 35.6% and 37.8%. This experiment proves HiROIC’s potential in providing signiﬁcant reduction in network latency in the presence of trafﬁc imbalance. In order to study the limitations of HiROIC, we swept the number of FCP entries for a ﬁxed directed load of 0.3 ﬂits/node/cycle (corresponding to medium load). Since irregular topologies realized by HiROIC suffer from congestion at medium-to-high trafﬁc, our scheme reverts back to a 2D mesh topology upon congestion detection. Therefore, increasing the number of trafﬁc-heavy FCPs beyond a certain point, should result in ineffective topology reconﬁgurations. Figure 8 shows that beyond 25 FCPs, HiROIC’s improvements over 2D mesh start diminishing. However, the optimal number of FCP entries varies depending on the network load: a heavily loaded network saturates HiROIC’s beneﬁts with a smaller number of FCPs. 293             Injection rate for FCPs= 0.3 flits/node/cycle 2-D Mesh 2-D Mesh Adaptive 3-D Torus Adaptive Flattened Butterfly 100 80 60 40 20 0 5 10 15 20 25 k r o w t e n e g a r e v A ) s e l c y c n i ( y c n e t a l 2D Mesh Adaptive 3D Torus Adaptive Flattened Butterfly  40 40 35 30 25 20 15 10 5 0 ) ) l l s s e e c c y y c c ( ( y y c c n n e e t t a a l l t t e e k k c c a a p p . . g g v v a a LL HH LH Types of workloads Average Fig. 9: Average network latency under multi-programmed workloads. The results are presented for 2D mesh, adaptive 3D torus and adaptive ﬂattened butterﬂy topologies under three different types of workloads. HiROIC is most effective for workloads in the LH category due to high trafﬁc imbalance. including routing tables, is already available at each router for faulttolerance. If not, Ariadne can be implemented at < 2% overhead [1]. For a ﬂattened butterﬂy router, the area overhead is slightly higher because of the additional multiplexers in the glue logic. However, the overall area overhead is still small (∼4%) and should not drive the selection of the physical topology. The main sources of power overhead in HiROIC are the glue logic and the additional link wires in the physical topology. On the other hand, HiROIC saves power by reducing the hop count of many packets – all those using an FCP – and we believe that these savings are larger than the additional power costs. V I I I . CONC L U S ION HiROIC provides performance similar to high-radix (> 5 ports) NoC topologies using resources comparable to low-radix topologies (<= 5 ports) by optimizing for critical high-volume communication paths at runtime. In HiROIC, links are deployed abundantly for rich connectivity as in high-radix topologies, while the number of router ports is kept low. Router ports bind to links at runtime in accordance to a distributed trafﬁc analysis heuristic implemented at each router. Our experiments with multi-programmed workloads on a 64-node CMP, show that HiROIC reduces average network latency by 19% compared to an area- and power- comparable mesh. When using non-uniform synthetic trafﬁc, the latency reduction is in the 30-38% range. Acknowledgements: This work was partially supported by NSF grant #0746425 and CFAR, within STARnet, a Semiconductor Research Corporation program sponsored by MARCO and DARPA. [2] [9] "
2015,Optimizing 3D NoC Design for Energy Efficiency - A Machine Learning Approach.,"Three-dimensional (3D) Network-on-Chip (NoC) is an emerging technology that has the potential to achieve high performance with low power consumption for multicore chips. However, to fully realize their potential, we need to consider novel 3D NoC architectures. In this paper, inspired by the inherent advantages of small-world (SW) 2D NoCs, we explore the design space of SW network-based 3D NoC architectures. We leverage machine learning to intelligently explore the design space to optimize the placement of both planar and vertical communication links for energy efficiency. We demonstrate that the optimized 3D SW NoC designs perform significantly better than their 3D MESH counterparts. On an average, the 3D SW NoC shows 35% energy-delay-product (EDP) improvement over 3D MESH for the nine PARSEC and SPLASH2 benchmarks considered in this work. The highest performance improvement of 43% was achieved for RADIX. Interestingly, even after reducing the number of vertical links by 50%, the optimized 3D SW NoC performs 25% better than the fully connected 3D MESH, which is a strong indication of the effectiveness of our optimization methodology.","Optimizing 3D NoC Design for Energy Efficiency:  A Machine Learning Approach   Sourav Das, Janardhan Rao Doppa,   Dae Hyun Kim, Partha Pratim Pande  School of EECS, Washington State University  Pullman, WA, USA  Email: {sdas, jana, dkim2, pande}@eecs.wsu.edu  Abstract— Three-dimensional (3D) Network-on-Chip (NoC) is  an emerging technology that has the potential to achieve high  performance with low power consumption for multicore chips.  However, to fully realize their potential, we need to consider novel  3D NoC architectures. In this paper, inspired by the inherent  advantages of small-world (SW) 2D NoCs, we explore the design  space of SW network-based 3D NoC architectures. We leverage  machine learning to intelligently explore the design space to  optimize the placement of both planar and vertical communication  links for energy efficiency. We demonstrate that the optimized 3D  SW NoC designs perform significantly better than their 3D MESH  counterparts. On an average, the 3D SW NoC shows 35% energydelay-product (EDP) improvement over 3D MESH for the nine  PARSEC and SPLASH2 benchmarks considered in this work. The  highest performance improvement of 43% was achieved for  RADIX. Interestingly, even after reducing the number of vertical  links by 50%, the optimized 3D SW NoC performs 25% better  than the fully connected 3D MESH, which is a strong indication of  the effectiveness of our optimization methodology.   Keywords— Small-World, 3D NoC, Discrete Optimization,  Machine Learning.  I. INTRODUCTION   Three-dimensional (3D) ICs are capable of achieving better  performance, functionality, and packaging density compared to  the traditional planar ICs [1]. On the other hand, network-onchip (NoC) enables integration of large numbers of embedded  cores in a single die. 3D NoC architectures combine the benefits  of these two new paradigms to offer an unprecedented  performance gain [2]. With freedom in the third (vertical)  dimension, NoC architectures that were previously impossible  or prohibitive due to wiring constraints in planar ICs are now  realizable in 3D NoC, and many 3D implementations can  outperform their 2D counterparts. However, existing 3D NoC  architectures predominantly follow straightforward extensions  of regular 2D NoC designs, which do not fully exploit the  advantages provided by the 3D integration technology [2].   In this paper, we consider the design space of 3D smallworld (SW) NoC architectures, where the vertical connections  mostly work as long-range shortcuts for SW networks. The key  challenge is to place the long-range shortcuts optimally to  achieve the desired goal. We formulate an objective function  called communication cost and leverage machine learning to  intelligently explore the combinatorial space of 3D SW NoC  architectures to optimize this objective. Eventually, it helps us  to achieve low latency and less energy consumption. We show  that the proposed 3D SW NoC outperforms the state-of-the-art  NoC architectures on multiple benchmarks. We also  Krishnendu Chakrabarty  Department of ECE, Duke University   Durham, NC, USA  Email: krish@ee.duke.edu  demonstrate the efficacy and robustness of our optimization  methodology by producing 3D SW NoC architectures that can  perform as well as or better than the fully connected 3D MESH  with significantly less number of vertical links.   The rest of the paper is organized as follows: Section 2  describes the related work. We present problem formulation,  proposed solution, and the optimization algorithm in section 3.  In Section 4, we present the experimental results and related  analysis. Finally, Section 5 concludes the paper by summarizing  the salient features of this work.  II. RELATED PRIOR WORK  Most of the existing 3D NoC architectures utilize a  conventional mesh [2][3][4]. However, it is well-known that  mesh-based architectures suffer from high network latency and  energy consumption due to its multi-hop communication links.  To exploit the reduced distance along the vertical dimension of  3D IC, NoC-bus hybrid architecture was proposed in [5] that  uses Dynamic Time Division Multiple Access (dTDMA) to  reduce the network latency. To reduce energy consumption of  the system, the 3D Dimensionally Decomposed (DimDe) NoC  router architecture [6] was developed. Reducing the number of  input ports, an improved version of 3D NoC router architecture  was developed in [7]. All of these architectures have buses in the  Z-dimension; and hence, with increase in the network size, they  are subject to traffic congestion and high latency under high  traffic injection loads.   Despite recent advances in TSV technologies, TSVs are still  subject to manufacturing defects and wearout [8], so researchers  have developed NoCs with partial vertical connections [9]. To  compensate for the loss in performance due to TSV failure, fault  tolerant router and NoC architectures with redundant vertical  links [10] were proposed. However, these designs give rise to  additional area and power overheads.   The Sunfloor 3D was developed for synthesizing application  specific 3D NoCs [11]. The design of application-specific 3D  NoC architectures was also investigated in [12][13].  Later, more  general-purpose 3D NoC was proposed in [14] using an ILP  based algorithm to insert long-range links to develop low  diameter and low radix architecture. However, the reduction in  energy consumption was found to be limited.   Photonic interconnects offer high bandwidth and low power  for future multi-core chip design. A number of hybrid  3D/photonic NoC  architectures  [15][16]were designed  considering these benefits. However, on-chip photonics still  suffer from performance variation due to thermal issues [17]. In  addition, the challenges of integrating two emerging paradigms,  978-1-4673-8388-2/15/$31.00 ©2015 IEEE 705       namely 3D IC and silicon nano-photonics, are yet to be  adequately addressed.   In this work, we focus on designing a robust 3D NoC  architecture that combines the benefits of 3D ICs and the  robustness of the SW architecture. We present a detailed design  methodology and a machine learning based optimization  algorithm  for  developing  energy-efficient  3D NoC  architectures. We also perform comparative performance  analysis with respect to conventional 3D MESH and other  irregular architectures. Finally, exploiting  the  inherent  robustness of SW network in the presence of link failure, we also  show that our proposed 3D NoC outperforms traditional NoCs  even in the presence of significant TSV failures without the need  of any extra resources.  III. OPTIMIZATION OF 3D NOC  In this section, we first describe our design problem and then  present a high-level overview of the proposed machine learning  based optimization methodology. Next, we provide the specific  details of all the main components of our method for 3D NoC  optimization.  Problem Description: The goal of on-chip communication  system design is to transmit data with low latencies and high  throughput using the least possible power and resources. In this  context, the design of SW network based NoC architectures [18]  is a notable example. It has been shown that either by inserting  long-range shortcuts in a regular mesh architecture to induce a  SW effect or by adopting power-law based SW connectivity, it  is possible to achieve significant performance gain and lower  energy consumption compared to the traditional multi-hop mesh  networks [18][19]. In this work, we advocate that the concept of  small-worldness should be adopted  in 3D NoCs  too.  Specifically, the vertical links in 3D NoC should enable the  design of long-range shortcuts necessary for a SW network.  However, the appropriate placement of the planar and the longrange links along the vertical dimension are crucial for  maximizing the performance benefits. Hence, our goal is to  optimize the placement of the planar and vertical links in a 3D  NoC where the overall interconnection architecture follows the  power-law based connectivity [19]. The probability of having a  direct link between nodes in a SW network varies exponentially  with the link length, i.e., p(ℓ) α ℓ-α . The parameter α governs the  The effectiveness of the learned E depends on a small subset of  critical training examples that successfully teach how to avoid  different local optima during the meta-search phase. The  STAGE algorithm tries to quickly identify this critical set in an  adaptive manner.  We initialize E, training set Z, and initial design d0. The  following high-level algorithmic steps of STAGE are repeated  for several iterations.   Base search using A guided by O: From d0, run the search  procedure A until a local optima is reached thereby leading to a  search trajectory (d0, d1,..., dT).  Improve E: For each design di on the search path, add (ϕ(di),  yi) to Z, where yi is the best value along the search. Re-train E  using a regression learner R with the updated training set Z.  Meta search guided by E: Continue from dT and optimize  E by performing a hill-climbing search to produce the best  predicted starting state 𝒅̂ . If 𝒅̂ is the same as dT (no search  progress), set d0 to a random design. Otherwise, set d0 = 𝒅̂ .  At the end, we return the best design found over all the  iterations.  B. Instantiation for 3D NoC Optimization  In this section, we provide all the details needed to apply the  STAGE algorithm to our 3D NoC optimization problem.  Design Space: Our design space depends on a set of network  resources, which are given as input to the optimization  algorithm. These resources are defined as follows. 1) Cores (C):  A set of all cores C = {C1, C2,...,CN}, where N is total number of  cores. We assume that every core is connected to at least one  router; 2) Planar Dies (P): A set of all dies P. For N = 64, we  consider four dies with each die containing 16 cores. For core  placement, we follow a greedy algorithm to minimize (fij*dij),  where fij and dij are the communication frequency and Cartesian  distance between the cores respectively. In this step, we form  clusters with 16 cores in each die; 3) Link Distribution (L): The  link length distribution L = {l1, l2,...,lk}, where k depends on the  size and topology of the network; li's are determined based on  the SW connectivity parameter α. For higher values of α, lk  decreases; and 4) Communication Frequency (F): The  communication frequency among different cores F = {fij | 1≤i,  j≤N, i≠j}.We assume that F for each application is given as an  input to perform application-specific network optimization.  The set of all physically realizable SW NoC designs with the  given link distribution L forms our design space.    Objective Function O: We define O as the communication  cost of the given 3D NoC, which is the product of hop count,  frequency of communication, and link length summed over  every source and destination pair, i.e.,  𝑁 𝑁 𝑂 = ∑ ∑ (𝑟 ∗ ℎ𝑖𝑗 + 𝑑𝑖𝑗 ) ∗ 𝑓𝑖𝑗                                          (1)  𝑖=1 𝑗=1,i≠j where fij, and dij are defined as above; hij is hop count between i-  and j-th node, and r denotes the number of router stages. From a  practical point-of-view, r is the number of cycles a message  spends inside a router to move from input to output port. An  NoC design with low O will have low latency and energy  consumption, and hence, low energy-delay-product (EDP).  Network Constraints: To explore only physically feasible  3D NoC designs, we enforce some constraints on the placement  of vertical links and router configurations. If TSVs are  707 considered as the vertical links, we only allow placing them  point-to-point (regularly) between the routers. Such constraints  may put additional limits on the performance of NoC designs.  However, efficient optimization can overcome such limitations.  The SW network has an irregular connectivity. Hence, the  number of links connected to each router is not constant. For fair  comparison between our SW network and 3D MESH, we  assume that both of them use the same average number of  connections, <kavg> per router. This also ensures that the 3D SW  NoC does not introduce additional links compared to a 3D  MESH. For a 64-core system, <kavg> is 4.5 considering all the  routers, including the peripheral ones. In addition, the maximum  connectivity per node, <kmax>, is set to be 7 for the SW network  as found in [23].   Starting States and Successor Function: For starting  states, we randomly generate a SW network that satisfies the  network constraints. The successor function S takes a network  as input and returns a set of next states, and allows the search  procedure to navigate the NoC design space. S generates one  candidate state for each link connecting two nodes in the input  network. It simply removes that link and places a link with the  same length between two nodes in the network that are not  directly connected.   The STAGE algorithm can benefit if we can specify the  starting state distribution using some domain knowledge.  Therefore, we also consider a starting-state distribution named  α-Greedy. We formulate the starting state (design) construction  as a sequential decision-making task, where we select the next  link to be placed at each step. In α-Greedy distribution, we select  a link greedily with probability α based on communication  frequency and a random link with probability (1–α). We start  with α=1 (completely greedy) and gradually reduce α to increase  the randomness.   Local Search Procedure A: We employed a stochastic hillclimbing procedure, where the next states are sampled  stochastically.  Feature Function ϕ: The main challenge in adapting  STAGE to our NoC domain is to define a set of features ϕ for  each network that can drive the learner. We divide the whole  network into several overlapping subgraphs or regions, and  define a set of features that can be categorized into three types:  1) Average hop count (h), which calculates the average hop  count  for each  region or sub-network; 2) Weighted  communication which is defined as the sum of the products of  hop count and communication frequency over all sourcedestination pairs for a particular hop count (∑ ∑  ℎ𝑘 ). The highest value of k depends on the network size and  topology. If the value of this feature is small, it indicates that  highly communicating cores are placed  in  the same  neighborhood; and 3) Clustering coefficient (Cc), which  captures the connectivity of one core with its neighbors [24].  While the hop count takes into account mainly long-range  communication, the clustering coefficient focuses more on local  connectivity among the immediate neighbors. We found these  features to sufficiently capture the network characteristics,  efficient to compute, and allow to learn highly accurate  evaluation function, E.   Regression Learner: The quality of our optimization  methodology depends on the accuracy of the evaluation function  E.  In this work, we employ the support vector regression (SVR)  𝑁 𝑗=1,𝑗≠𝑖 𝑁 𝑖=1  𝑓𝑖𝑗 ∗ learner to learn E from the training data generated while running  the STAGE algorithm.  Our training data consists of a set of input-output  𝑛 , where each xi ϵ Rm is a feature vector and yi ϵ  pairs {(𝑥𝑖 , 𝑦𝑖 )}𝑖=1 R is the corresponding output. The ε-SVR algorithm tries to learn  a function E such that the deviation of the predicted output E(xi)  from correct output yi is less than the error tolerance ε.   Without loss of generality, we assume E is a linear function  of the form E = <w, x> + b, and present the ε-SVR formulation  in primal form:   𝑚𝑖𝑛:      1 2 𝑆 . 𝑡:        { 𝑛 𝑖=1 ‖𝑤‖2 + 𝐶 ∑(𝜉𝑖 + 𝜉𝑖 ∗)                                        (2)  𝑦𝑖 −< 𝑤 , 𝑥𝑖 > −𝑏 ≤ 𝜀 + 𝜉𝑖 < 𝑤 , 𝑥𝑖 > +𝑏 − 𝑦𝑖 ≤ 𝜀 + 𝜉𝑖  𝜉𝑖 , 𝜉𝑖 ∗ ≥ 0   ∗                              (3)  In supervised learning, the goal is to learn a function that will  perform well on unseen examples (generalization) and not the  one that minimizes the error on the training data (over-fitting).  This problem is generally addressed by adding a penalty term to  discourage complex functions. In Equation (2), the first part is  the penalty term (regularizer) and the second part is the training  error.   C is the regularization parameter that provides the  tradeoff between minimizing  the  training error and  generalization to unseen data, and ξi and 𝜉𝑖 ∗ are slack variables  to handle infeasible constraints. Linear functions won't suffice  for complex problems such as ours. Therefore, we employ the  radial basis function (RBF) kernel (𝐾(𝑥 , 𝑥 ′ ) = 𝑒 𝛾‖𝑥−𝑥 ′‖ ) to be  able to learn non-linear functions, where γ is a tuning parameter.  We selected the RBF kernel over other kernels because of its  flexibility and predictive power. Additionally, to find the best  learned function, we need to search over different values of (ε,  C, γ). We employ LibSVM [25] to learn the regression function  and select the best combination of (ε, C, γ) over training set Z  via the inbuilt v-fold (v=5 in this work) cross-validation  approach.  2 IV. EXPERIMENTAL RESULTS AND ANALYSIS  In this section, we present the performance of our optimized  3D SW NoC architecture. For this performance evaluation, we  consider three metrics: latency, energy consumption, and  energy-delay-product (EDP). The EDP is defined as the product  of network latency and energy consumption, and unifies both of  them into a single parameter. We also present a comparative  performance evaluation of the 3D SW NoC with respect to other  existing regular and irregular counterparts.  A. Experimental Setup  To evaluate the performance of different NoCs, we use a  cycle-accurate NoC simulator that can simulate any regular or  irregular 3D architecture. Our system consists of 64 cores and  64 network routers equally partitioned in four layers. The length  of each packet is 64 flits and each flit consists of 32 bits. The  routers are synthesized from an RTL level design using TSMC  65The learned evaluation function E becomes highly accurate  after a small number of iterations, and produces good starting  states to help the local search procedure A in producing  optimized network architectures with lower objective O  (communication cost). We denote the final optimized NoC as  3D SW_optimized.   2) Characteristics of the Design: Random vs. Optimized  Now we investigate why the STAGE based optimization  algorithm is suitable for developing energy-efficient NoC  architectures. In Section 3.3, we described the details of the  feature definition (ϕ), to represent each network. So, we will see  how the design features change before and after optimization.  Here we specifically consider the role of the weighted  communication feature mentioned in Section 3.1.1. Fig. 3 shows  the weighted communication feature, which reveals the  percentage of total communication that is constrained between  two nodes separated by k hops (k ≥ 1). Careful observation of  Fig. 3 shows that for 3D SW_optimized, the traffic constrained  within one, two, and three hop communication increases  compared to 3D SW_random.  Moreover, the amount of traffic  that has to traverse beyond three hops decreases.  Hence, the inter-node communication that takes place in less  than three hops becomes more frequent. Since the average hop  count of the optimized network is calculated to be 2.94, any  communication below this average hop count can be considered  as efficient. Essentially, optimized network becomes more  efficient for the same objective function.  The inset in Fig. 3 shows the percentage of communication  versus the number of hops, where the area under the curve  denotes the weighted communication feature mentioned in  section 3.2.  We can see that the 3D SW_optimized curve shifts  towards the left, which means that on an average any message  in the optimized network traverses less hops compared to the  initial network.  Hence, it spends less time inside the network  and occupies less network resources. Therefore, the STAGEbased optimization algorithm guides the search to converge to  an efficient architecture.  C. Effect of Optimization on 3D SW NoC  In this section, we evaluate and compare the performances  of the 3D SW_optimized and the un-optimized 3D SW_random  architectures. For comparison purpose, all the values are  normalized with respect to 3D MESH.  1) Network Latency   Fig. 4.a demonstrates the effect of optimization for 3D SW  NoC. The optimization improves the network latency on an  average of 3% over the un-optimized version, and 5.5% over  the conventional 3D MESH. The optimization process  redistributes the links among the cores such that cores that have  to frequently communicate with each other are either directly  connected or need to traverse a small number of hops. This  results  in  reduced average hop count and weighted  communication for 3D SW_optimized NoC. A new set of  benchmarks with higher injection rates will highlight the  benefits of this work even more, which is the focus of our future  work.  Fig. 2. Best objective value O and error rate of the evaluation function E  for the STAGE algorithm over iterations  46 45.5 45 44.5 44 43.5 43 42.5 7 6 5 4 3 2 1 0 0 20 40 60 Number of iterations 80 e B t s O e u a v l E r r o r r a t o e f a u a v e l t i n o F n u c t i E n o Error O Fig. 3.  Effect of optimization algorithm on weighted communication  features.  0 10 20 30 40 50 1 2 3 4 5 6 7 8 Number of hops, k,  required for communcication % o f t o t a l r f n e u q e y c 3D SW_random 3D SW_optimized 0 10 20 30 40 50 1 2 3 4 5 6 7 8 3D SW_random 3D SW_optimized FFT Radix LU Canneal BT DEDUP Fluid Water Vips Fig. 4.b: Normalized energy consumption per message of 3D SW before and after optimization  Fig. 4.c: Normalized energy-delay-product (EDP) of 3D SW before and after optimization  Fig. 4.a: Normalized network latency of 3D SW before and after optimiztion  1 0.96 0.92 0.88 FFT Radix LU Canneal BT DEDUP Fluid Water Vips N o r m a i l z d e N e t w o r k a L t n e y c 3D Mesh 3D SW_random 3D SW_optimized 1 0.75 0.5 0.25 0 N o r m a i l z d e e n E r y g c n o s u m p t i n o 3D Mesh 3D SW_random 3D SW_optimized 1 0.75 0.5 0.25 0 FFT Radix LU Canneal BT DEDUP Fluid Water Vips N o r m a i l z d e E D P 3D Mesh 3D SW_random 3D SW_optimized 709                                   d e z i l a m r o N k r o w t e n y c n e t a l 1 0.96 0.92 0.88 FFT Radix LU Canneal BT DEDUP Fluid Water Vips Fig. 5.a: Normalized network latency of different 3D NoCs  d e z i l a m r o N y g r e n e d e z i l a m r o N 1 0.75 0.5 0.25 0 n o i t p m u s n o c FFT Radix LU Canneal BT DEDUP Fluid Water Vips Fig. 5.b: Normalized energy consumption per message of different 3D NoCs  1 0.75 0.5 0.25 0 P D E FFT Radix LU Canneal BT DEDUP Fluid Water Vips Fig. 5.c: Normalized EDP for different 3D NoCs  3D MESH mrrm rrrr 3D SW 3D MESH mrrm rrrr 3D SW 3D MESH mrrm rrrr 3D SW 2) Energy Consumption   Energy consumption per message depends on the energy  consumed by the router as well as the planar and vertical links.  The STAGE-based optimization algorithm reduces average  hop count and communication cost, which contributes to the  minimization of the router and link energy consumption  respectively. Fig. 4.b plots the energy consumption profile  before and after optimization normalized to these values for the  3D MESH. On an average, an optimized 3D SW NoC shows  33% and 17% energy consumption improvement over the 3D  MESH and 3D SW_random respectively. Fig. 3 helps us in  understanding the reasons behind the improvement in energy  consumption. The area under the 3D SW_optimized curve is less  than  that of  the un-optimized counterpart. Hence 3D  SW_optimized reduces the utilization of network resources for  any message. As a result, both the router and link energy  decrease and the overall energy consumption profile improves.  3) Energy-delay-Product (EDP)  From the EDP profile shown in Fig. 4.c, we observe that the  average EDP of 3D SW NoC is reduced by approximately 35%  and 19% compared to 3D MESH and 3D SW_random  respectively. The improvement in the energy-delay product is  direct consequence of the improvement in network latency and  energy consumption of the 3D SW_optimized NoC.   D. Comparative Performance Evaluation    In the previous sections, we showed that 3D SW_optimized  significantly outperformed 3D SW_random. In this section, we  compare 3D SW_optimized with several existing 3D NoC  architectures. Henceforth, we refer 3D SW_optimized as 3D SW  for simplicity. For this comparative performance evaluation, we  consider 3D MESH and two recently proposed irregular 3D  NoCs, namely, mrrm and rrrr [29]. Both the mrrm and rrrr  NoCs have point-to-point vertical connections as in 3D MESH  and 3D SW. However, their die-level planar connection pattern  varies. For rrrr, all the four dies have randomly connected  interconnection patterns. On the other hand, mrrm has random  connection patterns in the middle two dies whereas the first and  the fourth dies follow mesh-based regular connectivity.  To  build mrrm and rrrr, we follow the method suggested in [29]  and keep the number of links equal to that of 3D MESH and 3D  TABLE II.   COMPARISON OF AVERAGE HOP COUNT AND COMMUNICATION  COST OF 3D NOC ARCHITECTURES  NoC architecture  3D SW  mrrm  rrrr  3D MESH  Avg. hop  count  2.94  3.07  3.03  3.81  Communication  cost, O  43.08  47.27  47.39  55.5  SW. All the performance metric values are normalized with  respect to the 3D MESH.  1) Network Latency  Fig. 5.a shows the network latency of all the 3D NoCs.  Among all the NoCs, 3D MESH and 3D SW exhibit the highest  and the lowest latency respectively. The other two architectures  namely mrrm and rrrr perform somewhere in the middle. As in  the case of 3D SW NoC, both mrrm and rrrr have irregularities  in the horizontal planes. However, the number and the length of  the links are not optimized for these architectures. For rrrr, the  link distribution has large number of long-range links that help  communication among long-distant cores at the expense of nearby communication. In the case of 3D SW NoC, the link  distribution follows the power law and the connection pattern is  optimized  to facilitate both  the nearby and  long-range  communications.   The mrrm architecture maintains the link distribution in  between rrrr and 3D SW NoC. Hence, its network latency lies  in between rrrr and 3D SW. Finally, 3D MESH NoC suffers  from higher average hop count compared to other 3D  architectures due to multi-hop communication pattern; hence, it  suffers from the highest network latency. Table 2 lists the  communication costs and average hop counts for all these NoCs.  As expected, 3D SW and 3D MESH exhibit the lowest and  highest communication cost and hop count respectively,  whereas mrrm and rrrr reside in between these two. The effect  of these communication costs is eventually reflected in the  latency characteristics.  2) Energy Consumption   Fig. 5.b shows the energy consumption per message for  different 3D NoCs. Among all these, 3D MESH has highest  energy consumption followed by mrrm, rrrr and 3D SW NoC.  710                   1.02 1 0.98 0.96 0.94 r e p y g r e n e . g v A y c n e t a l k r o w t e n . g v A e g a s s e m 0 5 10 15 20 25 30 35 40 45 50 % of vertical link failure (a)  1.2 1 0.8 0.6 P D E e g a r e v A 1.2 1.1 1 0.9 0.8 0.7 0.6 0 5 10 15 20 25 30 35 40 45 50 % vertical link failure 0 5 10 15 20 25 30 35 40 45 50 % vertical link failure (c)  Fig. 6.  3D SW NoC performances normalized to fault free (fully vertical connected) 3D MESH Vs. the percentage of vertical link failure rate. (a)  Average normalized network latency;  (b) Average energy consumption per message; and (c) Average EDP   (b)  Higher network latency gives rise to higher network resources  utilization and hence, higher energy consumption per message.  For 3D MESH, the router energy consumption is significantly  higher due to multi hop communication, so it performs the  worst among all of them. The mrrm and rrrr NoCs are capable  of reducing the router energy consumption compared to mesh  and performs better than 3D MESH. However, due to their  random  link distribution,  they  suffer  from higher  communication cost and average hop count compared to the  optimized SW NoC. Hence, they consume more link energy  and router energy. With the least communication cost, 3D SW  NoC consumes the lowest energy possible among all these  architectures.   3) Energy-delay-Product (EDP)   The energy-delay-product is directly affected by network  latency and energy consumption. The architecture that performs  best in terms of latency and energy consumption is expected to  have lower EDP compared to the others. Fig. 5.c presents the  EDP profile of different 3D NoCs. As expected, 3D SW NoC  has the lowest EDP profile followed by mrrm, rrrr and 3D  MESH. On an average, 3D SW has 35% lower EDP profile  compared to 3D MESH while the highest improvement of 43%  was found for RADIX.  V. ROBUSTNESS OF 3D SW NOC ARCHITECTURE  In this section, we analyze the robustness of the 3D SW NoC  architecture under vertical link failure. The reason behind  studying the scenario of vertical link failures is that despite the  recent advancements in the TSV technology, TSVs are still  subject to failure due to voids, cracks, and misalignment [30].   In this case, after building and optimizing the 3D SW NoC,  the vertical links are randomly removed to simulate the link  failure scenario. This principally tests the robustness of the SW  interconnection network. Starting from the fault free 3D SW  NoC, we increase the link failure percentage with a step size of  5% till 50% of the vertical links are randomly removed. In Fig.  6, we show the average network latency, energy consumption,  and energy-delay-product (EDP) for all the benchmarks by  varying the amount of failed links. All parameters are again  normalized to the values of fault-free fully connected 3D  MESH. The figures show the worst, best and average  performance levels for the same amount of link failures over  1000 different runs.   From these figures, we observe that as the link failure  percentage increases, the network latency, energy consumption,  and EDP increase gradually. The difference between the worst-  and best case scenarios also increases progressively. This occurs  due to the fact that with increasing vertical link failure, we have  fewer routing resources than what is required to achieve  optimum performance. In addition, for the case of 50% vertical  link failure,  the average network  latency and energy  consumption almost equal the corresponding values for a  fully  connected fault-free 3D MESH. For this case, it is also quite  striking that EDP matches with that of the fault-free 3D MESH  as well. In the worst case, the network latency shows 2% higher  value whereas, the energy consumption and EDP record 13%  and 15% higher values respectively compared to fault free 3D  MESH. These results therefore show that even with significantly  fewer number of vertical links, the 3D SW NoC  performs as  well as the fully connected fault free 3D MESH on  average. It  has been observed in [19][20] that SW networks display  remarkable resilience to high rates of link failures since  the  average distance between nodes in a SW network increases by a  small margin with the rate of failures. Hence, the effect of  vertical link failures on the performance is minimal.  A. Optimization Quality with less Resources  We also analyze the quality of the proposed optimization  algorithm in the presence of limited resources. To do so, we  consider the 3D SW NoC with 50% vertical links and optimize  the placement of the links following our STAGE algorithmbased methodology. We show that the optimized NoC with  reduced vertical links can still maintain a high-level of  performance if the limited resources (vertical links in this case)  are utilized optimally. For the rest of the work, we denote this  optimized architecture as 3D SW_partial and compare its  performance with respect to the fully connected 3D MESH.  Fig. 7 shows the latency, energy, and EDP for 3D  SW_partial with respect to the fully connected 3D MESH. We  observe that on an average, 3D SW_partial still shows 2.5%  lower latency compared to the fully connected 3D MESH. In  comparison to the results for the fully connected 3D SW NoC  shown in Fig. 5.a, 3D SW_partial incurs only 3% higher network  1 0.9 0.8 0.7 0.6 0.5 FFT Radix LU Canneal BT DEDUP Fluid Water Vips Network latency Energy consumption EDP Fig. 7.  Network latency, energy consumption and EDP per message of the 3D SW_partial. All the values are normalized to that of fault free  (fully connected) 3D MESH  711                 [4] H.G. Lee et al., “On-Chip Communication Architecture Exploration: A  Quantitative Evaluation of Point-to-Point, Bus, and Network-on-Chip  App latency. The reason for this behavior is that the optimization  algorithm ensures the most suitable link placement considering  the available resources. As a result, the latency penalty remains  low. Similarly, 3D SW_partial shows 24% and 25% lower  energy and EDP respectively compared to the fully connected  3D MESH. In addition, by comparing these energy and EDP  values with Fig. 5.b and 5.c for the fully connected 3D SW, we  see that 3D SW_partial pays only 12% and 13% penalty  respectively over its fully connected counterpart.  This result carries the promise of highly energy-efficient  design with reduced resources. For 3D SW_partial NoC, we  have reduced 50% of the vertical links, which are predominantly  long-range shortcuts and still, on an average, we incur no more  than 15% penalty. The algorithm optimizes the link distribution  among the cores such that the overall communication cost is  minimized. Hence, the 3D SW NoC with reduced number of  vertical links utilizes its resources very efficiently to compensate  for the resource reduction.  If we compare the performances of 3D SW NoC with 50%  vertical link failure without any optimization (Section 4.5) with  the optimized 3D SW_partial, then we find that the later  performs better in every performance metric compared to the  former. On an average, for latency, energy, and EDP metrics,  3D SW_partial shows improvements of 2.5%, 27%, and 26%  respectively compared to its un-optimized counterpart. Hence,  the optimization algorithm plays a crucial role in minimizing the  performance penalty due to the limited resources. We can  emphatically conclude that the proposed 3D SW NoC along  with the optimization methodology is robust enough to  compensate for the performance loss due to vertical link  reduction. Overall, the performance penalty is small compared  to the proportion of resource reduction.  VI. CONCLUSIONS   We proposed a robust design optimization methodology to  improve the energy efficiency of 3D NoC architectures by  combining the benefits of SW networks and machine learning  techniques to intelligently explore the design space. We showed  that the optimized 3D SW NoC architecture outperforms  existing 3D NoCs. The optimized 3D SW NoC on an average  achieves 35% EDP reduction over conventional 3D MESH. We  also demonstrated  the efficacy and robustness of our  optimization methodology by producing 3D SW NoC  architectures that can perform equally or better than the fully  connected 3D MESH with significantly less number of vertical  links. For the case of 50% reduction in vertical links, the  optimized 3D SW NoC achieves 25% lower EDP compared to  fully vertically connected 3D MESH NoC.  ACKONWLEDGEMENT  This work was supported in part by the US National Science  Foundation (NSF) grants CCF-0845504, CNS-1059289, and  CCF-1162202, and Army Research Office grant W911NF-121-0373.  "
2015,PARADE - A Cycle-Accurate Full-System Simulation Platform for Accelerator-Rich Architectural Design and Exploration.,"The power wall and utilization wall in today's processors have led to a focus on accelerator-rich architecture, which will include a sea of accelerators that can achieve orders-of-magnitude performance and energy gains. The emerging accelerator-rich architecture is still in its early stage, and many design issues, such as the efficient accelerator resource management and communication between accelerators and CPU cores, remain unclear. Therefore, a research platform that can enable those design explorations will be extremely useful. This paper presents the first cycle-accurate full-system simulation Platform for Accelerator-Rich Architectural Design and Exploration (PARADE). PARADE can automatically generate dedicated or composable accelerator simulation modules, simulate the global accelerator management, a coherent cache/scratchpad with shared memory, and a customizable network-on-chip-all at cycle-level. In addition, PARADE provides visualization support to assist architects with design space exploration. Finally, a few case studies are conducted to confirm that PARADE can enable various system-level design space explorations in the accelerator-rich architecture.","PARADE: A Cycle-Accurate Full-System Simulation Platform for Accelerator-Rich Architectural Design and Exploration IN TRODUC T ION Jason Cong, Zhenman Fang, Michael Gill, Glenn Reinman Center for Domain-Speciﬁc Computing, University of California, Los Angeles E-mail: {cong, zhenman, mgill, reinman}@cs.ucla.edu Abstract—The power wall and utilization wall in today’s processors simulator in the near future to facilitate the research of acceleratorhave led to a focus on accelerator-rich architecture, which will include a rich architectures. sea of accelerators that can achieve orders-of-magnitude performance and This paper presents the ﬁrst cycle-accurate full-system simulation energy gains. The emerging accelerator-rich architecture is still in its early Platform for Accelerator-Rich Architectural Design and Exploration stage, and many design issues, such as the efﬁcient accelerator resource management and communication between accelerators and CPU cores, (PARADE). First, we model each accelerator quickly by leveragremain unclear. Therefore, a research platform that can enable those ing high-level synthesis tools. In addition, we provide a ﬂow to design explorations will be extremely useful. This paper presents the automatically generate either dedicated or composable accelerator ﬁrst cycle-accurate full-system simulation Platform for Accelerator-Rich Architectural Design and Exploration (PARADE). PARADE can automatsimulation modules that can be integrated into PARADE. Second, we provide a cycle-accurate model of the hardware global accelerator ically generate dedicated or composable accelerator simulation modules, simulate the global accelerator management, a coherent cache/scratchpad manager (GAM) that efﬁciently manages accelerator resources. Third, with shared memory, and a customizable network-on-chip—all at cyclewe provide a cycle-accurate model of the coherent cache/scratchpad level. In addition, PARADE provides visualization support to assist with shared memory between accelerators and CPU cores, as well as architects with design space exploration. Finally, a few case studies are conducted to conﬁrm that PARADE can enable various system-level customizable network-on-chip, by leveraging the existing widely used cycle-accurate full-system simulator gem5 [3]. Finally, we add visualdesign space explorations in the accelerator-rich architecture. ization support to assist architects with design space exploration. We achieve cycle-accuracy for PARADE by leveraging the existing cycleaccurate gem5 simulator for the CPU and cache memory hierarchy, and high-level synthesis (HLS) and register transfer level (RTL) simulation for the accelerator. In addition to performance simulation, PARADE also models the power, energy and area using existing toolchains including McPAT [15] for the CPU and HLS and RTL tools for the accelerator. To demonstrate the utility and power of PARADE, we further conduct a few case studies of the system-level design and evaluation for the accelerator-rich architecture. First, we illustrate how to customize a user’s own accelerator using the Denoise [7] benchmark. Second, we study the performance and energy beneﬁts of accelerator-rich architectures using dedicated and composable accelerators for a variety of application domains. Furthermore, we analyze how the performance gains are achieved at system-level using the representative benchmark BlackScholes [6]. Finally, we demonstrate how the visualization tool can be used to assist architects in the design of a better system by a case study that illustrates eliminating a potential inefﬁciency in the non-uniform cache access (NUCA) design. In summary, this paper makes the following contributions: • The ﬁrst cycle-accurate full-system simulation platform PARADE that simulates the whole system of the accelerator-rich architecture accurately, including X86 out-of-order cores, dedicated or composable accelerators, global accelerator manager, coherent cache/scratchpad with shared memory, and network-on-chip. • A fully-automated ﬂow to generate the dedicated or composable accelerator simulation modules and applications that use those accelerators, by leveraging the high-level synthesis tools. • A visualized simulation tool that assists architects in designing better systems and evaluating system-level issues. • Case studies that conﬁrm the utility and power of PARADE and show some architectural insights such as how to design the NUCA system for accelerator-rich architectures. The remainder of this paper is organized as follows. Section II presents an overview of the accelerator-rich architecture and its programming model. Section III proposes the PARADE simulation platform and describes the details of the simulation components for performance, power, energy and area modeling. Section IV conducts several case studies to conﬁrm the utility and power of PARADE. Section V discusses related work. Finally, Section VI concludes the paper and discusses possible future work. I . The power wall and utilization wall have limited the scaling of conventional general-purpose processors because most parts of future chips cannot be simultaneously powered up. This unpowered material is referred to as dark silicon [9]. Accelerator-rich architectures [6], [7], [17] have been proposed to address this by designing systems that trade dark general-purpose cores for a collection of specialized but transiently powered accelerators. These accelerators can be customized to provide orders-of-magnitude increased performance and energy efﬁciency when compared to performing the identical task in a conventional general-purpose CPU. Accelerator-rich architectures are still in the early stages of development, but are gaining more and more attention [6], [7], [17], [11], [4]. Many design issues, especially system-level issues, remain difﬁcult to evaluate. This has resulted in these topics being underemphasized in current research. Examples include accelerator resource management and arbitration, rapid accelerator design space exploration, communication between accelerators for the purposes of composition and virtualization, and how CPUs and memory hierarchies impact accelerator performance. Therefore, a research platform that can enable such design explorations will be extremely useful. Existing work on such research platforms can be classiﬁed into four main categories. The ﬁrst is the virtual prototyping platform [26], [25] to quickly model traditional multi-processor system-on-chip (MPSoC) architectures. These platforms are usually limited to systemon-chip (SoC) design and are difﬁcult to apply to modeling a generalpurpose accelerator-rich architecture (ARA) that has a large number of accelerators, complex network-on-chips (NoCs), and complex coherent cache memory hierarchies. The second is FPGA prototyping, e.g., [16], [5], [4], [11], which utilizes the existing ﬁeld programmable SoC and implements the accelerators in FPGA. The two main drawbacks are the limited system scale due to limited FPGA resources and tedious FPGA implementation efforts. These drawbacks make FPGA prototyping very hard to efﬁciently design and evaluate an ARA. The third is RTL simulation [17], [22], [20], which shares similar drawbacks of FPGA prototyping. The fourth one is the ﬂexible cycle-accurate full-system simulation used in [6], [7] targeted for the ARA, which currently lacks modeling details and is not accessible to the community—mainly because developing such a simulation platform usually takes multiple person-year efforts [10]. Our goal is to contribute to the community with such an open-source 978-1-4673-8388-2/15/$31.00 ©2015 IEEE 380 M $ $ C A A C $ $ C A A C $ M $ $ $ C A C C C A C C C A A GAM A C $ $ C C C C C C $ $ C A A C $ $ $ M Router $ C A A C $ $ C A A C $ C $ Core LLC Banks DMA SPM A B B A B B A B B A B B Dedicated/Composable  Accelerators $ M M Memory Controller Fig. 1: An overview of an accelerator-rich architecture. Application  source code Accelerator  library API Compiler Application static binary Dynamically linked  accelerator library (by HW developer) Linker Application executable binary Application calls an accelerator Decompose  accelerators &  estimate delay Query GAM  accelerators &  their wait time  Decide which accelerators to use Reserve accelerators & execute  OR take CPU software path Notify CPU accelerator job done  by Light-Weight Interrupt (LWI) a) Accelerator library-based programming b) Hardware execution mechanism Fig. 2: The library-based accelerator programming model and its underlying hardware execution mechanism. I I . OV ERV I EW O F ARA ARCH I T EC TUR E AND I T S PROGRAMM ING MODE L We ﬁrst give an overview of the accelerator-rich architecture (ARA) and its programming model as proposed in [6], [7]. A. Accelerator-Rich Architecture Figure 1 presents an overview of an accelerator-rich architecture. In addition to a number of CPU cores, there is a sea of heterogeneous accelerators. Each accelerator can be either a fully self-contained accelerator designed to act as a dedicated device, or an accelerator building block (ABB) that implements a small functionality with the intention that the ABBs will be used collectively to compose a more sophisticated functionality. To achieve high performance, each accelerator uses a software-programmed scratch-pad memory (SPM) and communicates with the rest of the cache memory hierarchy using a direct memory access (DMA) engine. A hardware global accelerator manager (GAM) is included to efﬁciently manage these accelerators. Furthermore, to provide high bandwidth to the accelerators, there are a number of last-level cache (LLC) banks and memory controllers that are coherent and shared by both the CPU cores and accelerators. Finally, all the components are connected by a customizable networkon-chip (NoC). B. Programming Model To minimize the programming efforts of using the acceleratorrich architecture, a library-based accelerator programming model is provided. As shown in Figure 2.a), there are a number of accelerator library APIs available to the users. When a user writes an application, he/she just needs to call the library APIs in the source code and then the compiler will compile it to a static binary. During linking, the dynamically linked accelerator libraries provided by hardware developers will be linked together with the static binary to generate the ﬁnal executable application binary. We also provide the accelerator virtualization support so that multiple hardware accelerators or ABBs can be composed into one large virtual accelerator library that is needed by the software programmer. A detailed example of the application programming will be provided in Section IV-B. Fig. 3: An overview of the PARADE simulator. Figure 2.b) describes the hardware execution mechanism of the application. Initially the application is running on the CPU. Whenever the application calls an accelerator library, the CPU will query the GAM about the wait time for all possible accelerators used by the application. At the same time, the GAM will decompose the virtual accelerator library into basic hardware accelerators (or ABBs) and estimate the computation delay by each hardware accelerator. Based on this information, the CPU will decide whether to use the accelerators and which accelerators to use. If it estimates that it will beneﬁt from the accelerators, it will ask the GAM to reserve them and then execute on the reserved accelerators; otherwise, it will stay on the CPU software path. Once the accelerator ﬁnishes its job, it will notify the CPU through a lightweight interrupt (LWI) [6]. I I I . TH E PARADE S IMU LATOR To enable efﬁcient system-level design exploration of the accelerator-rich architecture, we simulate the whole system with cycle accuracy, and support booting unmodiﬁed operating systems. To contribute more beneﬁts to the community with manageable efforts, we design and implement PARADE based on the existing widely used open-source architectural simulator gem5 [3] that provides ﬂexible system-level conﬁgurations to the core architecture, cache coherence protocols, network-on-chip topology, and DRAM models. Figure 3 presents an overview of the PARADE simulator. • The main elements that we contribute in PARADE are the accelerator simulation modules that can be automatically generated through a high-level description of the accelerator, and the reusable global accelerator manager to manage the accelerator resources. • We also make some necessary extensions to the gem5 simulator to support lightweight interrupt (LWI) [6] in the core and coherent cache memory hierarchy with accelerators. • To further assist architects with design space exploration, we also provide visualization support for the simulation. • Finally, we also model the power, energy and area using the integration of various existing tools such as McPAT [15], CACTI [19], DSENT [24], and CAD tools. A. Automatic Generation of Accelerator Simulation Modules To achieve high performance and low power, accelerators usually customize the computation using deep pipelines and customize the data access for great locality and bandwidth using software-managed scratch-pad memory (SPM). Further data parallelism can be achieved by duplicating the accelerator pipeline. In PARADE, we assume a three-stage accelerator execution model. First, all input data of the accelerator is loaded into the SPM before the computation. Second, the computation is done using all local data in SPM. Third, all output data in the SPM are written to the shared last-level cache (LLC) 381 Accelerator  source code High-level  synthesis C function  to accelerate RTL model Simulation  module generator RTL  synthesis Timing info e.g., II, clk Application  data flow Accelerator  chaining info Simulation  module info Program  generator input output tool Simulation  module Handles accelerator  communication, task  buffer, interrupts, … Generated  application Fig. 4: The automation ﬂow to generate dedicated or composable accelerators, as well as the applications using the accelerators. and memory. To achieve better performance, different tasks fed into the pipeline further overlap their computation and communication. Stage 1 and stage 3 are simulated using the cache memory hierarchy explained in Section III-C. For stage 2, PARADE uses a high-level synthesis [28] based model to calculate the computation latency of the accelerator pipeline. This model can be replaced with other opensource models such as Aladdin [23], or a regression model, or RTL co-simulation. To enable a quick design of new accelerators, we provide an automation tool chain to generate the accelerator simulation modules in PARADE. Figure 4 describes the automation ﬂow to generate dedicated or composable accelerator modules. The only input that users need to provide to the simulation module generator is the high-level C source code for the accelerator that is compatible with high-level synthesis tools. Then the C code will be automatically synthesized into RTL code using high-level synthesis tools such as AutoPilot [28]. Through RTL synthesis tools such as the Synopsys Design Compiler [1], it can get accurate timing information such as clock frequency, pipeline initialization interval (II), pipeline depth, area, and power for target ASIC design. The simulation module generator will automatically encode the timing information into the accelerator simulation module. In addition, it will also generate the SPM mapping, which is used to model the possible conﬂict between read or write ports within the same SPM bank. In PARADE, the number of SPM banks, SPM bank size, number of read/write ports, read/write latency, are all conﬁgurable. Finally, the accelerator simulation module also includes the code to functionally execute the accelerator so as to dynamically 1) accumulate the total computation latency (roughly ’pipeline executed iterations’ * ’pipeline II’ + ’pipeline depth’), and 2) generate the memory access addresses that are needed for cache memory hierarchy simulation. In addition to the automatic generation of each accelerator simulation module, we also generate the applications that utilize the accelerators automatically. As shown in Figure 4, to use the accelerators, users can write the application in a data ﬂow language that provides the chaining information of the accelerators. Then our program generator will automatically generate the application that can run on PARADE, by taking care of all issues such as querying and reserving accelerators, allocating SPMs, handling accelerator commands and communication, freeing accelerators and notifying CPU cores through lightweight interrupts. A detailed example of how to customize and utilize a user’s own accelerator will be provided in Section IV-B. B. Global Accelerator Management A hardware global accelerator manager (GAM) [6], [7] is provided in the accelerator-rich architecture to efﬁciently manage the available accelerator resources. It is also an interface between the CPU cores and accelerators. In addition to the SPM and direct memory 382 access (DMA) engine, PARADE also simulates the following key components inside the GAM. • Hardware Accelerator Resource Table. The GAM maintains a resource table to track the available hardware accelerators (or accelerator building blocks, i.e., ABBs), and the waiting time of those that are currently in use. When the CPU core requests the use of hardware accelerators, the GAM will query the resource table to determine which ones are available. • Composed Virtual Accelerator Table. To avoid the overhead of composing the same virtual accelerator from the same hardware accelerators or ABBs repeatedly, the GAM maintains a composed virtual accelerator table. • Task List for Virtual Accelerator. To enable efﬁcient data parallelism, the GAM splits the requested computation (data) from the virtual accelerator into a number of tasks (data chunks). Each task maintains a ﬂag marking which virtual accelerator it belongs to, a bit ﬂag identifying whether it is runnable or not. When the GAM adds a task to the task list, it will prescreen all its memory access addresses to see whether the addresses are resolvable by its local TLB. If yes, the task is marked as runnable; otherwise it is marked as not runnable and the GAM will issue a TLB miss to the requesting CPU core. • Centralized TLB. To avoid sending duplicate TLB miss requests to the CPU core, the GAM maintains a centralized TLB that caches the virtual-to-physical address translations for sharing by all accelerators. • Data Flow Interpreter. In our accelerator-rich architecture, the applications are written in a data ﬂow language (explained in Section IV-B using an example). The GAM provides a data ﬂow interpreter to map the application onto the available hardware accelerators (or ABBs). It ﬁrst creates a task list for each computation node (i.e., virtual accelerator) in the data ﬂow graph, and the task list for earlier computation node is given higher priority. Then it will iterate the task lists from high priority to low priority and will assign the available hardware accelerators to each runnable task. For each task list, it will try to compose as many runnable tasks as possible to enable efﬁcient data parallelism, as long as the memory pressure does not exceed the peak value and there are available hardware accelerators. When the hardware accelerators ﬁnish their execution, they will notify the GAM for reinterpreting again. C. Coherent Cache Memory Hierarchy and NoC Simulation To enable system-level design and exploration at the cache memory hierarchy and network-on-chip (NoC), PARADE leverages the existing gem5 [3] simulator and makes some necessary changes. First, the cache hierarchy is simulated by the Ruby [3] component in gem5 that supports various cache coherence protocols. To add coherent accelerators, we simulate a direct memory access (DMA) engine for each accelerator. The DMA engine is plugged into the Ruby component: it can read data from the last-level cache (LLC) and memory to SPM, and write data from SPM to the LLC and memory. In addition, two DMAs can communicate with each other directly so as to support efﬁcient data exchange between accelerator chains. Second, the NoC is simulated by the Garnet [3] component in gem5 that supports various network topologies. We make extensions to the NoC interface so that the accelerators and the GAM can be easily connected to the NoC. In addition, we make extensions to support control signal communication between CPU cores and accelerators through NoC. Finally, we use the simple yet accurate enough DRAM controller model [13] in gem5 to simulate the DRAM system. D. Discussion of Cycle Accuracy Cycle accuracy is an important metric for architectural simulators since they have to reﬂect the right performance trend when L1D_0 LLC_0 L1D_2 LLC_2 core_0 acc_0 router_0 router_1 router_2 GAM mc_0 acc_1 router_3 L1D_1 LLC_1 L1D_3 LLC_3 Fig. 5: An example of the visualized accelerator-rich architecture. evaluating microarchitectural designs. However, it is impractical for us to validate the accuracy of PARADE against a real machine since currently there are no commodity accelerator-rich architecture machines. Instead, we try to keep each component of the simulated architecture as accurate as possible. For the CPU, cache hierarchy, NoC, and DRAM parts, we leverage the existing cycle-accurate gem5 simulator that has already validated the accuracy of these components. For the newly added accelerator part, we utilize the timing information from widely used high-level synthesis tools (as explained in Section III-A) where cycle-accuracy for regular-logic accelerators is already widely accepted in the community [28]. In this sense, our PARADE simulator is cycle-accurate. In our future work, we also plan to validate the accuracy of PARADE against a similar FPGA prototyping. E. Visualization Support To further assist architects with design and exploration, we provide the visualization support for PARADE. The visualization tool shows the NoC topology, including the routers and links between them. For each router, it also shows the cores, accelerators, GAM, L1 cache controller/accelerator DMA engine, LLC cache controller, and DRAM controllers that are connected to it. An example of the visualized accelerator-rich architecture is shown in Figure 5. The visualization tool takes the access trace from PARADE and shows the utilization for each component as shifts in color. For each certain period, e.g., 1000 cycles, the ﬁgure shows the access frequency for the L1 cache/accelerator DMA, LLC and DRAM, router utilization and link utilization between routers. The color goes from light green to dark red when the utilization increases, with dark red colors demonstrating that the component is heavily used and could be a system bottleneck (e.g., accelerator 0 is heavily accessing LLC 0 in Figure 5). As a result, architects can use this tool to observe and detect potential system bottlenecks dynamically with much less effort. In Section IV-F, we conduct a case study to demonstrate that the visualization tool can ﬁnd some potential bottlenecks that cannot be observed only by examining ﬁnal simulation results. F. Power, Energy and Area Simulation In addition to the performance simulation, we also provide the power, energy and area simulation for each architecture component by leveraging existing tools. For accelerators, PARADE uses highlevel synthesis tools such as AutoPilot [28] together with RTL synthesis tools such as the Synopsys Design Compiler [1] for ASICs to get power and area data. Energy can be computed as power multiplying simulated execution time. For CPU cores, PARADE generates necessary statistical data and feeds the data into McPAT [15] to get power and area information. Similarly, for SPM and caches, PARADE uses the CACTI [19] simulator. For NoC, PARADE uses the recent DSENT [24] simulator. For DRAM, PARADE uses the simple yet accurate enough DRAM model [13] integrated with gem5 that uses Micron DRAM models. As a result, PARADE can be easily used 383 to evaluate the system performance, energy efﬁciency, and resource area utilization. IV. EVALUAT ION R E SU LT S In this section we conduct a few case studies of the systemlevel design and evaluation for accelerator-rich architectures using PARADE to demonstrate the utility and power of PARADE. First, we present the experimental setup for the evaluations. Second, we illustrate how to customize a user’s own accelerator using a simple Denoise [7] example. Third, we perform a detailed analysis of the performance and energy gains of dedicated accelerators (dedicated ARA) for a variety of application domains. Fourth, we compare the dedicated versus composable accelerator-rich architectures. Fifth, we demonstrate how the visualization tool can be used to assist architects to better design the system by a case study for the NUCA design. Finally, we also present the simulation speed of PARADE. A. Experimental Setup TABLE I: Basic parameters of the simulated X86 architecture. Technology node 32nm CPU 1 8-issue X86 OoO core @ 2.0GHz Accelerators refer to Table II and Section IV-E Coherence protocol 2-level MESI L1 cache private, 32 KB, 2-way associate, 2 cycles L2 cache shared, 2 MB, 32 banks, 8-way associate, 20 cycles NoC topology 4*8 Mesh DRAM 4 512MB 1600MHz DDR3 Simulated OS Linux kernel 2.6.22.9 In this section we describe the experimental setup. Table I summarizes the basic parameters of the baseline X86 architecture and the accelerator-rich architecture, which are targeted for a 32nm technology node. The baseline X86 architecture simulates an 8-issue out-of-order core with private 32KB L1 cache at 2GHz. There is a 2MB shared L2 cache (i.e., LLC) for all cores and accelerators, which is divided into 32 banks for bandwidth consideration. We use a small L2 cache size to avoid unintended cache warm-up effects (i.e., all data are already in the LLC cache) after application initialization. We maintain a coherent cache hierarchy for all the cores and accelerators using the MESI protocol. There are 4 DDR3 memory controllers where each DRAM is 512MB. All the components are connected through a 4*8 mesh NoC. We run our simulator on an Intel Xeon E7-4807 processor (1.87GHz) with 128GB DRAM. To evaluate the performance and energy results of the dedicated and composable accelerator-rich architectures, we use a wide range of applications [6], mainly from four diverse important domains: medical imaging, computer vision and navigation, as well as commercial benchmarks from PARSEC [2]. A brief description of each application, together with its input size, is listed in Table II. We also list the number of dedicated heterogeneous accelerators designed for each application in Table II. B. Customize Your Own Accelerator 1/vuut 5Xi=0 (xc   xi )2 (1) First we demonstrate an example of how to customize a user’s own accelerator using the Denoise [7] application. The core computation of Denoise is shown in Equation 1. Without loss of generality, we show how to customize composable accelerators for Denoise. We divide it into four main composable accelerator building blocks (ABBs) as shown in Figure 6: ABB1 and ABB2 perform the polynomial add and multiply computation; ABB3 calculates the square root; ABB4 performs division. We feed the C code of each ABB’s function into TABLE II: Benchmark descriptions [6] with input size, and the number of dedicated heterogeneous accelerators. Domain Application Algorithmic Functionality Input Size # Dedicated Accelerators Medical Imaging Deblur Denoise Registration Segmentation BlackScholes StreamCluster Swaptions LPCIP Desc Total variation minimization and deconvolution Total variation minimization Linear algebra and optimizations Dense linear algebra, spectral methods, and MapReduce Stock option price prediction using trivial ﬂoating point math 256K datasets Clustering and vector arithmetic 64K 32-dimension streams Computation of swaption prices using Monte Carlo (MC) simulation 8K datasets Log-polar forward transformation of image patch around each feature 128K features from 1 image of size 640*480 Procedural generation of texture image from patch; Texture Synthesis uses random number generation and random memory access 16 images of size 512*32 Robot Localization Monte Carlo Localization using probabilistic model and particle ﬁlter 128K sensor datasets Calculate sums of absolute differences and integral Disparity Map 2 images of size 64*64 image representations using vector arithmetic EKF SLAM Partial derivative, covariance, and spherical coordinate computations 128K sensor datasets 1 image of size 128*128*128 4 3 7 1 1 4 4 1 Commercial from Parsec [2] Computer Vision 5 1 4 2 Computer Navigation ABB1, Type = Poly Input: Mem, Output:ABB2 Function:(x0-y0),(x1-y1), … M e m ABB2, Type = Poly Input: ABB1, Output: ABB3 Function: x0*y0+x1*y1+…. ABB3, Type = Sqrt Input: ABB2, Output: ABB4 Function: sqrt(x) ABB4, Type = Divide Input: ABB3, Output: Mem Function: 1/x M e m Accelerator Data Flow for Denoise (Equation 1) Fig. 6: Customized accelerators for Denoise (Equation 1). 94X 130X 0 10 20 30 40 D b e l u r D o n e i e s R g e i s r t a i t n o S g e m n e t a i t n o B l S k c a o h c l s e S r t a e m C l u s t e r S w p a i t n o s P L C I _ P D c s e T x e t u r n y S _ e t s e h i s R o b o t _ L a c o i l a z i t n o D i s a p t i r _ y M p a E K L S _ F A M Medical Imaging Commercial Vision Navigation p S e e o p u d f d e d i a c t e d A R A Fig. 7: Performance speedup of dedicated ARA compared to CPU software baseline. our simulation module generator, and it will automatically produce detailed timing information and generate the simulation modules for the ABB. To automatically generate the application that invokes these ABBs, we provide the accelerator chaining data ﬂow as shown in Figure 6 that speciﬁes the input and output of each ABB. Note that the initial input and ﬁnal output of the whole Denoise application reside in shared memory. As demonstrated, our automation tool chain makes customizing a user’s own accelerator very efﬁcient. C. Performance Speedup of Dedicated ARA Figure 7 presents the performance speedup of dedicated accelerators for the medical imaging, commercial, vision, and navigation domains compared to the CPU software baseline version. To be fair, the software version only uses one core, and there is only one copy of the hardware accelerator for each virtual accelerator in the application. In addition, both versions do not optimize the data access locality. Depending the application, the speedup varies from 6.5X to 130X. To get a better understanding of where the performance speedup comes from, we further conduct a detailed analysis for a representative benchmark BlackScholes that achieves 94X speedup. Figure 8 shows the performance breakdown for both software baseline and dedicated ARA versions of BlackScholes; note that the Y-axis is in log scale. Figure 8(a) compares the execution cycles of the total execution, computation only, and non-overlapped communication. The computation part achieves a speedup of 155X due to the customized 234-stage deep accelerator pipeline. The non-overlapped communication part achieves a speedup of 64X that lowers the whole speedup to 94X. To further analyze how the communication part achieves such a speedup, Figure 8(b) compares the number of total cache memory accesses and Figure 8(c) compares the bandwidth of cache memory access for both versions. First, as shown in Figure 8(b), the huge number of L1 instruction cache accesses are totally removed in the accelerator-rich architecture, as expected. Second, the total number of SPM access in accelerators is signiﬁcantly reduced (42X) compared to the L1 data cache access in the software version. We further investigate this reduction and ﬁnd out the main reason is that in the software version, there are a lot of registers spilling out to the L1 data cache since the X86 architecture has a limited number of registers, while BlackScholes has a large number of local variables. This leads to a large number of L1 data cache accesses that usually does not draw an architect’s attention in traditional CPU architecture. But actually it plays a key role in performance improvement in the accelerator-rich architecture when the number is signiﬁcantly reduced. Third, there are few LLC cache and DRAM access reductions because we do not optimize either version. However, the achieved bandwidth for LLC cache and DRAM access has been greatly improved, 65X and 94X respectively, as shown in Figure 8(c). This high degree of memory-level parallelism (MLP) achieved in the accelerator-rich architecture also plays a key role in performance improvement and comes primarily from the accelerator accessing memory in bursts, as described in Section III-A. D. Energy Efﬁciency of Dedicated ARA Figure 9(a) presents the energy savings of dedicated accelerators for the medical imaging, commercial, vision, and navigation domains compared to the CPU software baseline version. We present the energy savings with and without DRAM being considered because DRAM consumes signiﬁcant power and energy. Depending on the application, the energy saving varies from 11X to 251X without counting DRAM energy. With DRAM energy, the energy savings become smaller, ranging from 8X to 170X. To get a better understanding of where the energy is spent in the accelerator-rich architecture, we further conduct a detailed breakdown analysis for a representative benchmark, Deblur. As shown in Figure 9(b), the consumed energy is divided into four parts: CPU core and accelerators, LLC cache, NoC, and DRAM. We ﬁnd 384       1 10 100 1,000 10,000 100,000 1,000,000 10,000,000 100,000,000 1,000,000,000 Total Computation Non-overlapped Communication E c e x u i t n o c y c l s e BlackScholes-SW BlackScholes-dedicated-ARA (a) Execution cycles 10,000 100,000 1,000,000 10,000,000 100,000,000 L1D/SPM L1I LLC Memory # o f s e s s e c c a BlackScholes-SW BlackScholes-dedicated-ARA (b) Number of cache/memory access Fig. 8: Performance breakdown for BlackScholes. 1 10 100 1,000 10,000 100,000 L1D/SPM LLC Memory B d n a w i d t h ( M B / ) s BlackScholes-SW BlackScholes-dedicated-ARA (c) Bandwidth of cache/memory access 0 20 40 60 80 D b e l u r D o n e i e s R g e i s r t a i t n o S g e m n e t a i t n o B l S k c a o h c l s e S r t a e m C l u s t e r S w p a i t n o s P L C I _ P D c s e T x e t u r n y S _ e t s e h i s R o b o t _ L a c o i l a z i t n o D i s a p t i r _ y M p a E K L S _ F A M Medical Imaging Commercial Vision Navigation E n y g r e s v a i g n s o f d e d i a c t e d A R A Energy w/o DRAM Energy w/ DRAM 151X, 112X 251X, 170X (a) Energy savings of dedicated ARA (b) Energy breakdown for Deblur Fig. 9: Energy savings of dedicated ARA compared to CPU software baseline. 14% 12% 7% 67% Energy breakdown for dedicated ARA (Deblur) Core_Acc LLC NoC DRAM that DRAM consumes most of the energy in the accelerator-rich architecture, which is around 67% of the total energy. This suggests that future research needs to focus more on the DRAM element, and some techniques such as low-power DRAM and data locality optimizations could help. E. Dedicated vs. Composable ARA Figure 10 compares the performance speedup and energy savings of the composable ARA and dedicated ARA for the medical imaging domain, compared to the CPU software baseline. To be fair, we keep the area of both the composable ARA and dedicated ARA the same for the domain. As a result, the composable ARA is composed of 44 accelerator building blocks (ABBs). These ABBs are distributed evenly into the 4*8 mesh NoC; each group forms an ABB island that is connected to the NoC router. Under this assumption, the composable ARA can compose more copies of virtual accelerators compared to the dedicated ARA. Therefore, the composable ARA can achieve better performance and saves more energy. Our current ABB distribution strategy might be suboptimal, and we use a greedy strategy to compose as many virtual accelerators as possible. It is interesting to apply different strategies and compare the beneﬁts, and we will explore this topic in our future work. F. Case Study for NUCA Optimization In this subsection we conduct a case study using our visualization tool to identify a performance bottleneck in the static non-uniform cache access (NUCA) design. In the baseline NUCA design for LLC, we use higher signiﬁcant bits to determine which NUCA bank a given block maps to, as shown in the upper part of Figure 11. Therefore, a LLC Bank 0 LLC Bank 1 offset nuca set id tag Optimized  NUCA valid offset set id nuca tag valid line 0 line 1 line 2 line 3 line 0 line 1 line 2 line 3 Baseline  NUCA Fig. 11: Comparison of baseline and optimized NUCA design. chunk of consecutive cache lines will go to the same LLC cache bank, and this pattern will iterate over all the LLC cache banks. Using the visualization tool, we ﬁnd that from time to time, each LLC cache bank and its associated router become the bottleneck (shown in the dark red color) because all cache access trafﬁc goes to the same bank during that certain period. It is difﬁcult to ﬁnd this bottleneck by merely looking at the ﬁnal results because all LLC cache banks and routers will have similar utilization in aggregate, with each transiently becoming the bottleneck as the accelerator iterates over memory. As a result, we optimize the NUCA design for LLC by simply selecting lower signiﬁcant bits for NUCA bank selection as shown in the lower part of Figure 11. Therefore, the consecutive cache lines go to different LLC cache banks, making the trafﬁc even and much less for each cache bank during any given period. Although this may lead to higher link utilization in the NoC, experimental results show that it can always improve the performance. As shown in Figure 12, the speedup can be up to 9% and the average speedup is around 3%. A system consisting entirely of CPUs rarely exhibits the high volume 385                 0 10 20 30 40 Deblur Denoise Registration Segmentation Medical Imaging p S e e p u d Dedicated-ARA Composable-ARA 72X (a) Speedup of composable ARA (b) Energy savings of composable ARA Fig. 10: Performance speedup and energy savings of composable ARA and dedicated ARA compared to CPU software baseline. 0 20 40 60 80 Deblur Denoise Registration Segmentation Medical Imaging E n y g r e s v a i g n s w / A R D M Dedicated-ARA Composable-ARA 88X 0% 2% 4% 6% 8% 10% D b e l u r D o n e i e s R g e i s r t a i t n o S g e m n e t a i t n o B l S k c a o h c l s e S r t a e m C l u s t e r S w p a i t n o s P L C I _ P D c s e T x e t u r n y S _ e t s e h i s R o b o t _ L a c o i l a z i t n o D i s a p t i r _ y M p a E K L S _ F A M Medical Imaging Commercial Vision Navigation p S e e o p u d f A C U N p o i t m i a z i t n o Fig. 12: Performance speedup of NUCA optimization. of bursty demand on memory to expose the signiﬁcance of this type of optimization, but the increased performance of accelerators results in memory demand where small choices such as this become very important. Note that except in this subsection, all the results are measured using the optimized NUCA design. G. Simulator Speed Finally, we evaluate the simulator speed for PARADE. As shown in Figure 13, the left Y-axis and blue bars show the simulation speed for the baseline gem5 simulator, which is measured in simulated kilo instructions per second (KIPS). Since gem5 simulates the whole system, including the out-of-order pipeline, cache memory hierarchy and NoC, the simulator speed ranges from 14 to 53 KIPS and the average speed is around 32.5KIPS. Since we can not measure the KIPS value for accelerator simulation (no instructions for accelerators), we measure the simulator speedup of PARADE compared to gem5, shown as the right Y-axis and the orange squares in Figure 13. For all cases except StreamCluster, PARADE runs faster than gem5. For StreamCluster, the software version is mainly communication dominated where the non-overlapped communication occupies 85% of the whole execution time. In the accelerator version, the number of L1D/SPM accesses, LLC accesses, and memory accesses all increase, which leads to the slight simulation time increase. Similarly, this also leads to different simulator speedups for running different benchmarks on PARADE. In general, this speed is good enough for design space exploration using PARADE since it is at least faster than the state0 1 2 3 4 5 6 7 0 10 20 30 40 50 60 70 D b e l u r D o n e i e s R g e i s r t a i t n o S g e m n e t a i t n o B l S k c a o h c l s e S r t a e m C l u s t e r S w p a i t n o s P L C I _ P D c s e T x e t u r n y S _ e t s e h i s R o b o t _ L a c o i l a z i t n o D i s a p t i r _ y M p a E K L S _ F A M Medical Imaging Commercial Vision Navigation P E D A R A s p e p u d e g m 5 K I S P gem5-SW_KIPS PARADE-dedicated-ARA-speedup 15X Fig. 13: Simulation speedup of PARADE compared to gem5. of-the-art gem5 simulator. V. R ELAT ED WORK We ﬁrst summarize the research platforms used in some recent representative accelerator-related work in Table III. We categorize them use into four main types: full-system cycle-accurate simulation [6], [7], [14], [27], [11], virtual prototyping [12], [21], RTL simulation [17], [22], [20], and FPGA prototyping [16], [5], [4], [11]. TABLE III: Research platforms used in accelerator-related work. Research Platforms Representative Related Work Cycle-accurate full-system simulation Virtual prototyping RTL simulation FPGA prototyping ARC [6] CHARM [7] Walker [14] Conservation Cores [27] DySER [11] H.264 [12] Convolution Engines [21] AccStore [17] Sonic Millip3De [22] PPA [20] TSSP [16] LINQits [5] PARC [4] DySER [11] The works most related to PARADE are ARC [6] and CHARM [7] that use cycle-accurate full-system simulations. They use a heavily modiﬁed Simics and GEMS [18] simulator to model the dedicated and composable accelerator-rich architectures. Compared to them, PARADE has some key differences. First, both ARC and CHARM mainly focus on the design of the accelerator-rich architecture and describe little about the simulator they are using. In PARADE, we present more details about how to automatically generate the dedicated or composable accelerator simulation modules, and provide a visualization tool to help architects with design 386                   "
2015,A universal ordered NoC design platform for shared-memory MPSoC.,"Shared memory is the predominant programming model in today's MPSoCs. However, existing SoC on-chip communication standards like AMBA relies on the interconnect for ordering. This is a problem as the number of actors increases, as traditional simple interconnects like buses and crossbars do not scale, yet scalable distributed NoCs are inherently unordered. Without built-in ordering capability from NoC, cache coherence protocols have to rely on external ordering points which can forward the requests so that every cache observes the requests in the same order. Such ordering points incur significant scalability issues though, such as indirection latency or communication hotspots in the network. In this paper, we propose a universal ordered NoC platform for shared-memory MPSoC designs to provide coherence request ordering in addition to communication. The proposed solution is based on a separate light-weight ordering network to establish the global request order which the receiving NIC leverages for delivering requests. The proposed solution provides a comprehensive support for general network topologies and various levels of memory consistency, while adhering to existing cache coherence protocol standards. The full-system simulation with heterogeneous MPSoC Rodinia benchmarks shows that it reduces the request latency by 37.6% and 35.7% over ordering points in 2D-mesh and butterfly fat tree topologies, respectively. This translates to overall runtime improvements of 17.8% and 12.0% in each topology, for a 36-node and 32-node MPSoC respectively.","A universal ordered NoC design platform for shared-memory MPSoC Woo-Cheol Kwon∗ Li-Shiuan Peh† Department of EECS, MIT Cambridge, MA 02139 Email:∗wckwon@csail.mit.edu, †peh@csail.mit.edu Abstract—Shared memory is the predominant programming model in today’s MPSoCs. However, existing SoC on-chip communication standards like AMBA relies on the interconnect for ordering. This is a problem as the number of actors increases, as traditional simple interconnects like buses and crossbars do not scale, yet scalable distributed NoCs are inherently unordered. Without built-in ordering capability from NoC, cache coherence protocols have to rely on external ordering points which can forward the requests so that every cache observes the requests in the same order. Such ordering points incur signiﬁcant scalability issues though, such as indirection latency or communication hotspots in the network. In this paper, we propose a universal ordered NoC platform for shared-memory MPSoC designs to provide coherence request ordering in addition to communication. The proposed solution is based on a separate light-weight ordering network to establish the global request order which the receiving NIC leverages for delivering requests. The proposed solution provides a comprehensive support for general network topologies and various levels of memory consistency, while adhering to existing cache coherence protocol standards. The full-system simulation with heterogeneous MPSoC Rodinia benchmarks shows that it reduces the request latency by 37.6% and 35.7% over ordering points in 2D-mesh and butterﬂy fat tree topologies, respectively. This translates to overall runtime improvements of 17.8% and 12.0% in each topology, for a 36-node and 32-node MPSoC respectively. I . IN TRODUC T ION In the past decade, as single-core scaling hits a wall with diminishing performance gains and rising power consumption, we have witnessed a major transition to multi-core chips to continue performance scaling. The trend towards multi-core is now mainstream in system-on-chips(SoCs), with multiprocessor systems-on-chips (MPSoCs) having emerged in widespread use in networking, signal processing, and multimedia chips, from mobile processors like Qualcomm Snapdragon series to Intel Xeon D SoC family and Freescale QorIQ network processors. While shared memory is the dominant programming model for these MPSoCs due to ease of programming and legacy codebase, it also imposes a major challenge to the designers as MPSoCs scale in complexity. Existing SoC on-chip communication standards such as AMBA 4[5]1 , OCP 3.0[1], 1Recently new cache coherence protocol AMBA 5 CHI has been proposed, targeted towards scalable many-actors MPSoCs. However, publicly-available information is very limited, and coherence request ordering model seems similar to AMBA 4 and HyperTransport[4] require the interconnect to order coherence requests, which worked thus far, as on-chip interconnect solutions were built with simpler topology structures that inherently support ordering, such as the AMD opteron HT bus[10], Intel haswell ring[14], and ARM CCI500 crossbar[6]. This no longer holds as MPSoCs scale to large numbers of actors. The most prominent trend in recent MPSoC design is increasingly large number of actors being integrated onto a single chip with continuing scaling of CMOS and vast expansion of SoC application domains. Although a shared bus or simple crossbar can provide adequate request ordering for cache coherence protocols, they are becoming performance bottlenecks due to inherent scalability problems. As a result, scalable packetized network-on-chip(NoC) is gradually superseding traditional interconnects to cope with ever-increasing bandwidth demands. However, such NoCs with distributed routers are inherently unordered. Without built-in ordering capability from NoC, the cache coherence protocol has to rely on indirection to serialization or ordering points which can forward the requests to other processors in order. This indirection adversely affects performance. It increases the network latency for delivery of coherence requests to other processors. Furthermore, it concentrates broadcasting trafﬁc at the ordering points, which may become communication bottlenecks in the network. Alternatively, we can switch from the snoopy coherence prevalent in today’s MPSoCs to directory-based protocols which can work atop unordered NoCs, like the designs in [28]. In a directory-based protocol, coherence requests are ﬁrst sent to serialization points called directory, which track sharing status of each cache line, and forward intervention or invalidation requests accordingly. Since the directory handles coherence requests ordering, it only requires the interconnect to provide point-to-point ordering for each source-destination pair. However, it cannot avoid the performance degradation due to indirection latency, not to mention the area overhead imposed by keeping cache line information in the directory. Most critically, it requires redesign of existing SoC cores and cache controllers, which adds complexity in both design and veriﬁcation, impacting the already tight design-to-market time. In this paper, we propose that the scalable NoC should support coherence request ordering, in addition to communications. We propose an ordered NoC design platform (OrderedNoC) for shared-memory MPSoC to provide efﬁcient request ordering inside the NoC, and to support a wide range of cache coherence and memory consistency models. It universally 978-1-4673-8388-2/15/$31.00 ©2015 IEEE 697 applies to irregular MPSoC topologies, while adhering to myriad existing cache coherence protocol standards so that existing cores and IPs can be readily plugged into the platform. Experimental results show that the proposed solution can be applied to a variety of MPSoCs, ranging across different network topologies and request ordering semantics. The full-system simulation with heterogeneous MPSoC Rodinia benchmarks show that it reduces the request latency by 37.6% and 35.7% over ordering points in 2D-mesh and butterﬂy fat tree topologies, respectively. This translates to overall runtime improvements of 17.8% and 12.0% in each topology, for a 36-node and 32-node MPSoC respectively. The rest of this paper is organized as follows. Section 2 presents relevant background and motivation, and Section 3 reviews related work. Section 4 presents the proposed design. Section 5 reports experimental results, and Section 6 concludes. I I . BACKGROUND AND MOT IVAT ION A. Cache coherence and memory consistency The intuitive view of shared memory expects that read requests will always observe the latest write value to the memory. However, implementation of this intuitive shared memory is not straightforward in the presence of multiple caches. While caches are an indispensable part of processors due to high off-chip DRAM access delay, they create a serious design challenge for MPSoCs: cache coherence problem. If a variable is replicated into multiple local caches, processors can observe different values for the same variable. Further, if two or more processors attempt to write the same memory location simultaneously, processors might observe write values in different orders from each other. Thus, we need well-deﬁned rules specifying correct shared memory behavior so as to provide a basis in writing parallel programs. These rules are often described in two separate concepts: cache coherence and memory consistency. Cache coherence deﬁnes memory access ordering for the same memory location by two constraints: (1) write must be eventually seen by other processors; (2) writes to the same location must be seen in the same order by all processors. In contrast, memory consistency speciﬁes memory access ordering across different memory locations. Table I summarizes various memory consistency models classiﬁed according to their ordering requirements. The most straightforward memory consistency model is sequential consistency, in which memory operations are observed in the same total order by all processors as all four types of program order are enforced. While sequential consistency corresponds to intuitive understanding of shared memory behavior, it hinders compiler and hardware optimizations from exploiting out-of-order instruction execution, and thus leads to severe performance degradation. B. Motivating case study The 36-core MIT SCORPIO chip recently fabricated on 45nm SOI process [13] forms the motivation of our proposed 2Although cache coherence protocols usually require a total ordering for the same memory location, Read-After-Read ordering can be possibly relaxed since reordering does not make any semantic difference. Ordered-NoC platform for MPSoC. SCORPIO demonstrated that ordering can be embedded within a scalable mesh NoC, delivering 24% better performance than directory-based ordering at low power and area overheads, and allowing for plugand-play with Freescale PowerPC cores and Cadence memory controller through AMBA AXI and ACE communication standard. In SCORPIO, for every memory request, the network interface controller(NIC) broadcasts notiﬁcation of the request on a separate ordering network called notiﬁcation network. The receiving NIC then reorders and delivers the requests in the notiﬁcation order. The notiﬁcation is represented as a bit-vector in which each bit indicates if corresponding processor has sent a memory request into the main network. The notiﬁcation broadcast from each node has a ﬁxed route along XY-routing path in 2D-mesh, and the routing can be done in bufferless manner, since two incoming notiﬁcations can be merged if the broadcasting paths are overlapping. This bufferless routing can guarantee a ﬁxed bound for broadcast latency from each node, which enables synchronization of notiﬁcation broadcasts. NIC issues notiﬁcations only at the start of each time window, which is set greater than the maximum broadcast latency. Consequently, all nodes receive the same set of notiﬁcations at the end of each time window. By applying a common ordering rule to received notiﬁcations, each NIC can locally constitute the same ordered list of source processor ID(PID)s which are associated with the source nodes of each notiﬁcation. The main network is designed to provide point-to-point ordering, which guarantees in-order delivery of requests from the same source. Accordingly, each coherence request can be identiﬁed by its source PID. Although the coherence requests from different sources can arrive in any order, they can be reordered at each NIC according to the global order settled by notiﬁcations. While SCORPIO pointed at the promise of embedding ordering within the NoC, it was heavily tailored for a speciﬁc target chip and has several limitations that make it not applicable universally to most MPSoCs. Firstly, its bufferless notiﬁcation network is designed only for 2D-mesh topology; Heterogeneous processors in MPSoC platforms have nonuniform block sizes and bandwidth requirements, which renders 2D-mesh suboptimal in many target applications. Instead, the platform-speciﬁc optimal topology should be generated according to communication analysis at the design phase[24]. Secondly, SCORPIO indiscriminately reorders every coherence request in a strict total order, which often results in unnecessary ordering latency and performance loss. For example, if only read requests with different cache line addresses arrive, they could have been served immediately without waiting to be ordered. Speciﬁcally, the SCORPIO notiﬁcation network was designed to provide a total order, aiming for sequential consistency. While sequential consistency is functionally sufﬁcient for any memory consistency model, it imposes superﬂuous ordering and increased latency for the relaxed consistency models that are prevalent among existing commercial cores. In short, as MPSoCs scale to many IP blocks, a universal NoC platform that can support ordering across a wide spectrum of shared memory models at high performance is needed. In this paper, we propose such a generalized NoC platform that encapsulates ordering, and efﬁciently supports a wide range of memory models, so as to interface readily with existing cores, 698 Memory Consistency Model Cache Coherence Sequential Consistency TSO, Intel x86/x64, Sun Sparc v8 Processor Consistency Sun PSO Weak Ordering, Release Consistency, IBM 370/Power, ARM Total Ordering for the same address2 (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Program Order Write Atomicity (cid:88) RAR,WAR,WAW RAR, WAR, WAW RAR, WAR (cid:88) (cid:88) Memory Fence (cid:88) (cid:88) (cid:88) (cid:88) TABLE I: Ordering requirements according to memory consistency models cache and memory controllers, and other IP blocks. I I I . R E LATED WORK Snoopy cache coherence on unordered networks Commercial cache coherence protocol standards such as AXI Coherence Extensions(ACE) [5], OCP Coherence Extension [1], AMD Hypertransport [9], and home snoop in Intel Quickpath Interconnect(QPI)[15] require the interconnect to support request ordering for correct operation. While an ordering point can provide such request ordering support over unordered point-to-point interconnects, they add unnecessary latency. Hence, there have been several proposals to enable direct coherence request snooping. Timestamp snooping[21] and INSO[3] assign a global logical order to each coherence request, and the interconnects process them in the logical order. Recently, SCORPIO[13] introduced request ordering based on notiﬁcations by decoupling ordering function from the main network. These prior works can provide only total request ordering, whereas Ordered-NoC aims to selectively relax ordering requirements according to target memory consistency model. Source snoop such as that in QPI[15] also allows out-of-order snooping for lower latency, but it requires a separate home agent for conﬂict resolution, which requires each transaction to wait for the acknowledgment from the home agent with increased latency. In contrast, Ordered-NoC can resolve ordering conﬂicts without the intervention of separate agents thanks to a chip-wide global request order. Token Coherence protocol[20] is an alternative solution for request ordering on unordered network. To access a particular cache line, the requesting processor should collect at least one token for read, and all tokens for write. Similar to our approach, it can avoid both indirection latency and total ordering overhead. However, Token Coherence requires reimplementation of cache controllers to bookkeep the number of tokens for each cache line, whereas Ordered-NoC can be readily applicable to standard cache coherence protocols. NoC for heterogeneous SoCs There has been a plethora of NoC studies for a heterogeneous multi-core system or MPSoC. Application-speciﬁc communication requirements and nonuniform IP block sizes render homogeneous NoC routers suboptimal, and naturally lead to heterogeneous architectures. Substantial research has proposed design ﬂows for optimized topology generation based on bandwidth and latency characterization[24]. In topology design, ﬂoorplan issues have been considered to facilitate timing closure[25], [26]. Design methodologies for optimized router architectures for application-speciﬁc communication patterns have also seen substantial research [23], [12]. Ordered-NoC provides a general framework to build request ordering functionality into the NoC for heterogeneous NoC. It is orthogonal to the optimization of the main network for communications, whether it be topology, router micro architecture, etc. Ordered-NoC can embed the ordering network and network interface controllers in any conventional NoC, interfacing seamlessly existing IP blocks and supporting any shared memory semantics. As offchip memory trafﬁc is dominant in today’s MPSoC, researches have proposed optimized topology and router architectures for higher DRAM utilization[16], [27], [11]. There have also been prior NoC studies on ordering to guarantee in-order packet delivery for multi-path routing [22], [18], or for concurrent split memory transactions[17], [11]. Heterogeneous NoC designs to facilitate cache coherence protocols have been proposed as well, such as reconﬁgurable NoC for localized snooping[29] and efﬁcient broadcast support for acknowledgments[19]. Ordered-NoC goes beyond optimizing a NoC for shared memory communications; It advocates instead the embedding of request ordering in the NoC for supporting shared memory coherence and consistency semantics. IV. ORD ER ED -NOC D E S IGN Our proposed Ordered-NoC platform supports ordering within the NoC, in a general manner so that existing IP cores, cache and memory controllers that run a variety of memory semantics can be plugged unchanged. In addition, it supports heterogeneous, irregular MPSoC layouts by enabling ordering to be embedded within any NoC topology. The tenet behind our Ordered-NoC platform lies in a separate ordering network that maintains ordering amongst requests, while the main network handles the traditional communication function of NoCs. This split enables the main network to deliver coherence requests in any order. The NIC issues notiﬁcations on the ordering network in synchronization with a time window, which is the maximum notiﬁcation broadcast latency of the ordering network. By the end of each time window, all nodes receive the same set of notiﬁcations. Each NIC applies the same ordering rule to the received notiﬁcations, and thus shares a common global request order. OrderedNoC selectively reorders the requests from the main network according to the memory semantics. If any inconsistent request ordering is detected at each NIC, it performs necessary recovery actions. By sharing a common request order, each NIC can resolve ordering conﬂicts in a distributed manner without the intervention of separate home nodes or agents functioning as ordering points. We will next dive into how our OrderedNoC platform enables the selective enforcement of ordering between speciﬁc memory transactions, thus supporting diverse memory semantics, then go into how it functions atop any NoC topology, including irregular ones. A. Reordering requests Figure 1 shows the microarchitecture of the NIC for reordering coherence requests. Outgoing coherence request from 699 those inconsistencies found, NIC is required to take relevant recovery actions. We present two different schemes. Recover-Total-Order The ﬁrst scheme is to restore correct behavior according to the global request order so that memory operations take the same effect as the request snooping at each NIC is performed in the total order. In this scheme, we allow an out-of-order snooping only for read requests, which means that only read requests can be snooped ahead of other preceding requests. Under this scheme, out-of-order snooping for read requests can be viewed as prefetching for reduced latency. If prefetched value is known to be outdated, then NIC should wait for updated value while dropping the obsolete one. When receiving the response, NIC inspects the SSV of the response to check if the response is sent from the latest data owner. In other words, the response is conﬁrmed to be valid if there is no preceding write request for the cache line which is not snooped in the SSV from the response(Accordingly, the SSV only needs to provide the snooping status for preceding requests.). Otherwise NIC discards the response since the data will be overwritten by new data owner who issued that write request. Since we do not allow out-of-order snooping of write request, new data owner cannot serve any preceding request with newer value. Further, we can guarantee that all subsequent requests after a write request (until a next write request) are served by new data owner, by prohibiting snooping incoming requests for the same cache line before completing all preceding outgoing requests. If new response arrives while there is already another response stored in the oRB, then NIC compares SSVs of two responses from the earliest bits to later. Because the later owner always has longer consecutive snooped requests, we can distinguish the newer response. Additionally, since NIC is required to deliver the response to the processor only when the local request reaches the head of the sROB, the global request order provides a logical point at which each memory operation takes effect. Thus, we can guarantee sequential consistency as all memory operations appear in the global request order. Figure 2 gives a walk-through example, which features 3 processors with MOESI cache coherence protocol3 with sROBd = 3. For convenience of explanation, the RHQ is omitted, and the requests remain in the sROB even after the retirement. In the example, we denote read(write) request from processor i by Ri (Wi ). The ﬁgure also shows cache states of each processor for two cache line addresses. The request for the second address is shown as shaded in the sROB. (R3 is for the second cache line, and the others are for the ﬁrst). (a) Each processor sends a coherence request to the main network, and NIC issues a corresponding notiﬁcation at the start of notiﬁcation time window to the ordering network. All notiﬁcations arrive until the end of time window, and each NIC settles on the same request order 2 → 1 → 3 as shown in the ﬁgure. (b) R3 is the ﬁrst request arriving at processor 1 and 2, while R1 is the ﬁrst for processor 3. They are snooped without waiting for preceding requests. The SSVs are (0, 0) (an upper half for preceding requests) since there were no earlier snooped requests. Processor 2 is at M(Modiﬁed) state 3 In our example, it is assumed that processor at O(Owner) state takes responsibility for generating data response when receiving read request from other processors. Fig. 1: Microarchitecture of Network Interface Controller(NIC) the local processor is kept at the outgoing request buffer (oRB) until it receives the data response and completes coherence operation. The response is also stored into oRB until it is ready for the delivery after ordering conﬂict is resolved. The global request order by the ordering network is maintained by storing the corresponding source PID for each notiﬁcation in the request order queue(ROQ). Snoop reorder buffer (sROB) is a circular buffer holding incoming requests until the delivery of the request to the processor. Each entry of sROB is paired to each PID in the ROQ in order from the top to the bottom (from the oldest to the most recent).When the oldest entry from sROB retires, the corresponding top (oldest) PID from the ROQ is also removed. If an incoming request arrives at the NIC on the main network, its source PID is matched against the ROQ and moved into a corresponding entry of sROB. Once stored in the sROB, a request can be delivered for snooping in any order, subject to the ordering requirements. Requests are retired in-order from the sROB as a snooped request can only release its entry when it reaches the head of the sROB. B. Resolving ordering conﬂicts Since out-of-order snooping is allowed independently at each NIC when not constrained by the memory semantics, each cache controller may end up with inconsistent cache data from each other. To address this, Ordered-NoC makes a slight modiﬁcation to coherence protocol that does not interfere with internal states or behaviors of cache controllers; when coherence request is delivered from sROB to the cache controller, NIC extends the request with a bit-vector(called the snoop status vector (SSV)) indicating the snoop status of coherence requests for the same cache line. The length of the SSV is 2 · (sROBd − 1) bits where sROBd is the depth of sROB; a half for preceding requests and the other half for subsequent ones to cover all requests within the maximum reordering boundary. The SSV can be obtained from the current snoop status of sROB. For the requests already retired from sROB, it can search for the same cache line address the request history queue(RHQ), which stores up to sROBd − 1 recently retired requests for future look-up. When the cache controller returns a data response, the SSV received from the request is carried over to the response. When other NICs receive the response, they extract the SSV, and compare it against the snoop status of local sROBs to resolve any inconsistency. Once 700 (a) (d) (b) (e) (c) (f) Fig. 2: Walk-through Example for Recover-Total-Order for the second cache line, and changes the state to O(Owner) as it snoops R3 . Similarly, processor 3 changes M(Modiﬁed) state for the ﬁrst cache line to O(Owner) as it snoops R1 . (c) Note that R1 is received by NIC 2, but it is kept at sROB until local request W2 is completed since W2 has smaller request order and two requests have the same cache line. Processor 3 sends the data response to processor 1. NIC 1 receives the response but discards it since there was a preceding write W2 with the ﬁrst cache line address, which is not snooped in the SSV, (0, 0) at the response. On the other hand, NIC 3 can accept the response from processor 2, since there is no previous requests with the second cache line address. (d)(e) The response for W2 arrives at NIC 2 and is delivered to processor 2. After the retirement of W2 , NIC 2 can deliver R1 for snooping. (f) The response from processor 2 arrives at NIC 1. As the SSV shows that the last write W2 is serviced, the response is conﬁrmed to be valid and delivered (two steps are shown in the same ﬁgure). Note that R3 was immediately served at NIC 2 without reordering latency. Still, ﬁnal memory operations have the same effect as all coherence requests are snooped in the global request order, 2 → 1 → 3. Reorder-On-the-ﬂy We have seen how Recover-Total-Order scheme can guarantee strong memory consistency models like sequential consistency and total store order(TSO) without reordering of every coherence request in a total order. However, it still imposes considerable ordering restrictions. Although it allows out-of-order snooping, the response must wait until all preceding requests are received. It also enforces in-order snooping of write requests and generates redundant responses. We can further enhance the performance for the relaxed memory consistency by addressing these issues. The second scheme aims to provide utmost ﬂexibility in the request ordering as the actual snoop order is determined on the ﬂy by the data owner at the time. When receiving the response, local snooping status is readjusted by the SSV from the received response as follows. There are two types of requests which need readjustment in the snoop order. First, NIC identiﬁes unsnooped requests by the local processor which are known to be already snooped by the previous owners. NIC marks those requests in the sROB as snooped, and skips the delivery. On the other hand, there can be the requests that are already snooped by the local processors, but not snooped by the previous owner. To maintain the same snoop order, NIC changes them unsnooped, and resends those requests to the processor after returning the response. Figure 3 revisits the previous walk-through example. Now it features only the ﬁrst cache line address. (a)(b) The global request order is established as 2 → 1 as before. Processor 1 and 3 snoop W2 and R1 respectively. (c) The response from processor 3 arrives at NIC 1. Processor 3 next snoops W2 . (d) NIC 1 can deliver the response from processor 3 immediately. Recall that in the previous walk-through, NIC 1 discarded the ﬁrst response expecting that a valid response would arrive later. On the contrary, every response is valid now, and NIC is responsible for readjusting its local snoop order accordingly. In the example, NIC 1 changes the snoop status of W2 to unsnooped , and resends it to the processor, since the response from processor 3 demands to reorder W2 behind R1 . (e) NIC 2 delivers the response for W2 . This time, the SSV indicates that R1 is already processed by the previous data owner. Accordingly, R1 is marked as snooped without actual snooping. Note that the ﬁnal snoop order is 1 → 2, which is set by the ﬁrst data owner, processor 3. C. Ordering network construction The role of the ordering network is to broadcast notiﬁcations to all nodes within a guaranteed latency, which provides synchronized time window for global request ordering. Figure 4 illustrates the ordering network construction process atop the main network. We assume the design phase to produce any irregular NoC topology which is optimized according to various factors such as proximity and communication trafﬁc analysis. Given the underlying main NoC topology(Figure 4a), we independently construct a bufferless broadcast tree to deliver notiﬁcation bits for each node. The broadcast tree is carrying only a 1-bit notiﬁcation signal (with an additional ﬂow-control signal to stop further notiﬁcation injections). The tree is constructed by running a shortest-path tree algorithm for each node as a root, as shown in Figure 4b for two nodes J and K, to obtain the minimum broadcast latency. The ﬁnal 701 (a) (b) (c) (d) (e) Fig. 3: Walk-through Example for Reorder-On-the-ﬂy V. EX PER IM EN TA L R E SU LT S We illustrate the generality of the Ordered-NoC platform by applying it to a diverse range of MPSoC designs and memory models, then evaluate its impact on memory access latency and overall application performance against the stateof-the-art. A. Methodology We used the C++-based multi-processor simulation tool GEM5 [7] along with the cycle-accurate network model Garnet [2] modiﬁed to model the proposed Ordered-NoC. For workloads, we use the heterogeneous computing benchmark suite, Rodinia [8]. Simulations are run to completion for each application, with statistics gathered at the end of the parallel portions. Our baseline models include both directory and ordering points-based protocols. In all system conﬁgurations, each processor has local private L1/L2 caches with MOESI cache coherence protocols. Different system conﬁgurations then differ only in how the coherence requests are ordered and delivered to other processors. In the directory-based baseline protocol, the sharer information of each cache line is stored in distributed directories at the static home nodes. When a cache miss occurs at the local L2 cache, the coherence request is delivered to the static home node, and the directory either forwards the request to the data owner (the processor having O(Owner) state in the local cache) or generates invalidations to all the sharers. Both directory and ordering points-based protocols use a directory for request ordering, but in ordering points-based protocols, the directory contains no storage for the sharer information, and thus just broadcasts forwarded coherence requests and invalidations. We use SCORPIO as another baseline to illustrate how Ordered-NoC reduces the performance overhead of total ordering by applying request ordering selectively. To show the generality of our proposed Ordered-NoC platform, we applied it to MPSoC designs running atop two (a) Given main network topology (b) Notiﬁcation broadcast from node J and K trees Fig. 4: Construction of ordering network atop given main network topology. The ordering network is the sum of individual broadcast trees rooted at each node. ordering network is the sum of all individual broadcast trees by iterating this process for all nodes. The latency bound is given as the maximum latency of all broadcast trees. In the main network, the requests from different sources are allowed to pass through the routers in an out-of-order manner. Without a proper measure, out-of-order requests may occupy all the virtual channels in the router, while the NIC waits for the request with smaller request order, and thus blocks all virtual channels, which leads to a deadlock. To address this, we add an escape virtual channel(EVC) to ensure the request with the smallest request order at the time can always proceed to the next router. For this purpose, the main network router should track the global request order from the ordering network with the PID order queue (the same structure as the request order queue inside NIC in Figure 1), while observing PIDs of coherence requests that have already passed through the router. It matches the PID of passing requests against PIDs in the PID order queue and remove it from the queue, and vice versa. EVC is reserved for the request having the PID that sits on the top of the PID order queue. Accordingly, NIC sets aside a separate register for EVC in the request buffer. 702 (a) 36-core(2D-Mesh) (b) 32-core(Butterﬂy Fat Tree) Fig. 6: Snooping Latency Breakdown for TSO (a) 36-core(2D-Mesh) (b) 32-core(Butterﬂy Fat Tree) Fig. 7: Snooping Latency Breakdown for Relaxed Memory Consistency ing latency(Ordering). As shown in Figure 6a, Ordered-NoC leads to reduction in memory latency of 18.1% and 14.9% in each topology for TSO when compared against total ordering. With relaxed memory consistency, Ordered-NoC results in even higher latency reduction of 25.0 % and 21.7 % over total ordering4 . This shows that Ordered-NoC can ﬂexibly conﬁgure to the desired level of request ordering, and yet serve memory requests quickly. Especially, in a butterﬂy fat tree topology, where SCORPIO cannot provide request ordering for cache coherence, the latency reduction over ordering points reaches 12.3 and 14.7 cycles for each memory consistency model, which are 35.7% and 41.5% reduction. In 2D-mesh topology, the latency reduction is 13.4(37.6%) and 16.9 cycles(44.5%) over ordering points. Figure 8 shows overall performance improvement by Ordered-NoC in terms of normalized runtimes (against the Directory baseline). In general, Ordered-NoC tends to have relatively smaller performance impact compared to the snooping latency reduction, because it is relevant to only L2 cache misses. The ﬁgure graphs normalized runtimes for relaxed memory models, where ONoC-A represents Recover-TotalOrder scheme, and ONoC-B Reorder-On-the-ﬂy. The overall runtime reduction is 17.8% and 12.0% compared to ordering points in each topology. The reduction over total ordering is 10.3% and 7.2%, respectively. As expected, the system performance improvement is highly sensitive to the cache miss rate. For example, streamcluster has 37.3 L2-cache misses per thousand instructions, whereas bfs merely has 1.2. Therefore, in streamcluster, Ordered-NoC gives 31.7% and 21.4% runtime reduction over ordering points in each topology, which are considerably higher than 6.4% and 4.1% in bfs. Considering that the input and working set sizes in the experiments are markedly limited due to the limitation of simulation times, we believe that Ordered-NoC will show more signiﬁcant performance improvement in realistic workloads that will have much larger cache footprint. 4As SCORPIO can be applied only for 2D-mesh, for butterﬂy fat tree topology, total ordering(TO) is implemented by Ordered-NoC by only allowing strict in-order snooping. (a) 2D-Mesh for 36-core (b) Butterﬂy Fat Tree for 32-core Fig. 5: NoC Topologies for evaluation different topologies (2D-mesh and butterﬂy fat tree) and supporting two alternative memory models, total store order(TSO) and relaxed memory consistency. In TSO, each write request is required to complete after invalidating all the sharers to provide write atomicity, or the cache coherence protocol should operate on a strict total request order. Accordingly, RecoverTotal-Order scheme is applied in Ordered-NoC. In relaxed memory consistency model, we assume basic cache coherence with the support of atomic writes and memory fences, while writes can complete before receiving the acknowledgments for invalidations, hence, Ordered-NoC’s Reorder-On-the-ﬂy scheme can be applied. Table II summarizes the detailed system conﬁgurations. Processing cores Operating System Cache line size L1 cache L2 cache Cache coherence Request Ordering Topology Latency Virtual Networks Virtual Channels Link channel width Directory Processor Conﬁguration in-order core with X86-64 ISA Linux Kernel v. 2.26.28.4 64 Bytes Split 32KB I&D, 4-way, 1-cycle access latency Exclusive uniﬁed 64KB per each core 4-way, 4-cycle access latency MOESI protocol with private L2 cache Directory(Dir) , Ordering Points(OP) Total ordering(TO) by SCORPIO, Ordered-NoC On-Chip Network 2D-mesh (6 × 6) for 36-core Butterﬂy fat tree for 32-core 1-cycle pipeline for router 1-cycle for link traversal 2 4 per Virtual Network 16 Bytes 10-cycle access latency Memory Interface Memory 2 memory controllers (10-cycle latency) 100-cycle access latency for off-chip DRAM TABLE II: Target System Conﬁguration B. Results Figures 6 and 7 compare average snooping latency of coherence requests of each system conﬁguration. In a directorybased protocol(Dir), when a L2 cache miss occurs, the request is ﬁrst sent to the directory(Req. Delivery). After a directory look-up(Directory), it is forwarded to the sharers to receive a data copy, or to invalidate upon writes (Forwarding). For the request ordering system based on ordering-point(OP), the request is forwarded to all nodes without incurring a directory look-up latency. In total ordering(TO) and OrderedNoC(ONoC), the coherence request is directly delivered avoiding forwarding latency, but each NIC imposes additional order703 [15] [11] M. Daneshtalab, M. Ebrahimi, P. Liljeberg, J. Plosila, and H. Tenhunen. Memory-efﬁcient on-chip network with adaptive interfaces. ComputerAided Design of Integrated Circuits and Systems, IEEE Transactions on, 31(1):146–159, Jan 2012. [12] R. Das, O. Mutlu, T. Moscibroda, and C. R. Das. Application-aware prioritization mechanisms for on-chip networks. In Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, pages 280–291, New York, NY, USA, 2009. ACM. [13] B. K. Daya, C.-H. O. Chen, S. Subramanian, W.-C. Kwon, S. Park, T. Krishna, J. Holt, A. P. Chandrakasan, and L.-S. Peh. Scorpio: A 36-core research chip demonstrating snoopy coherence on a scalable mesh noc with in-network ordering. In Proceeding of the 41st Annual International Symposium on Computer Architecture, pages 25–36, 2014. [14] P. Hammarlund et al. Haswell: The fourth-generation intel core processor. IEEE Micro, 34(2):6–20, 2014. Intel. An introduction to the intel quickpath interconnect. Intel White Paper, 2009. [16] W. Jang and D. Z. Pan. An sdram-aware router for networks-on-chip. In Proceedings of the 46th Annual Design Automation Conference, 2009. [17] W.-C. Kwon, S. Yoo, J. Um, and S.-W. Jeong. In-network reorder buffer to improve overall noc performance while resolving the in-order requirement problem. In Design, Automation Test in Europe Conference Exhibition, 2009, pages 1058–1063, April 2009. [18] M. Lis, M. H. Cho, K. S. Shim, and S. Devadas. Path-diverse in-order routing. In Green Circuits and Systems (ICGCS), 2010 International Conference on, pages 311–316, June 2010. [19] M. Lodde, J. Flich, and M. Acacio. Heterogeneous noc design for efﬁcient broadcast-based coherence protocol support. In Networks on Chip (NoCS), 2012 Sixth IEEE/ACM International Symposium on, pages 59–66, May 2012. [20] M. M. K. Martin, M. D. Hill, and D. A. Wood. Token coherence: Decoupling performance and correctness. In Proceeding of the Annual International Symposium on Computer Architecture, pages 182–193, 2003. [21] M. M. K. Martin, D. J. Sorin, A. Ailamaki, A. R. Alameldeen, R. M. Dickson, C. J. Mauer, K. E. Moore, M. Plakal, M. D. Hill, and D. A. Wood. Timestamp snooping: An approach for extending smps. In ASPLOS, pages 25–36, 2000. [22] S. Murali, D. Atienza, L. Benini, and G. De Michel. A multi-path routing strategy with guaranteed in-order packet delivery and faulttolerance for networks on chip. In Proceedings of the 43rd Annual Design Automation Conference, 2006. [23] S. Murali, L. Benini, and G. De Micheli. An application-speciﬁc design methodology for on-chip crossbar generation. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, 26(7):1283– 1296, July 2007. [24] S. Murali and G. De Micheli. Sunmap: A tool for automatic topology selection and generation for nocs. In Proceedings of the 41st Annual Design Automation Conference, pages 914–919, 2004. [25] S. Murali, P. Meloni, F. Angiolini, D. Atienza, S. Carta, L. Benini, G. De Micheli, and L. Raffo. Designing application-speciﬁc networks on chips with ﬂoorplan information. In Computer-Aided Design, 2006. ICCAD ’06. IEEE/ACM International Conference on, pages 355–362, Nov 2006. [26] S. Pasricha, N. Dutt, E. Bozorgzadeh, and M. Ben-Romdhane. Floorplan-aware automated synthesis of bus-based communication architectures. In Proceedings of the 42nd Annual Design Automation Conference, pages 565–570, 2005. [27] C. Seiculescu, S. Murali, L. Benini, and G. De Micheli. A dram centric noc architecture and topology design approach. In VLSI (ISVLSI), 2011 IEEE Computer Society Annual Symposium on, pages 54–59, July 2011. [28] D. Wentzlaff et al. On-chip interconnection architecture of the tile processor. IEEE Micro, 27(5):15–31, 2007. [29] H. Zhao et al. A hybrid noc design for cache coherence optimization for chip multiprocessors. In Proceedings of the 49th Annual Design Automation Conference, 2012. (a) 36-core with 2D-Mesh (b) 32-core with Butterﬂy Fat Tree Fig. 8: Normalized runtime V I . CONC LU S ION In summary, we motivated the need for an ordering layer in NoCs that can allow actors in shared-memory MPSoCs to plug-and-play readily. We proposed such a universal OrderedNoC that works with any memory coherence and consistency model and NoC topology. We demonstrated how Ordered-NoC delivers better performance than other alternatives. ACKNOW L EDGM ENT This work was supported by the Center for Future Architectures Research (C-FAR), one of six SRC STARnet Centers sponsored by MARCO and DARPA. avaiable at "
2015,The (Low) Power of Less Wiring - Enabling Energy Efficiency in Many-Core Platforms Through Wireless NoC.,"During the last decade, we have witnessed a major transition from computation- to communication-centric design of integrated circuits and systems. In particular, the network-on-chip (NoC) approach has emerged as the major design paradigm for multicore systems-on-chip (SoC). The major challenges in traditional wire-based NoCs are the high latency and power consumption of the multi-hop links. By inserting single-hop long-range wireless links in place of multi-hop wired links, the overall system performance can be significantly improved. We should adopt novel architectures inspired by the on-chip wireless links to design high-performance multi-core chips. In this regard, the small-world network-inspired wireless NoC (WiNoC) has emerged as an enabling interconnection infrastructure to design hig-hbandwidth and energy-efficient multicore chips. In this paper we present the various challenges and possible solutions for designing energy-efficient massive multicore chips enabled by the WiNoC paradigm.","The (Low) Power of Less Wiring: Enabling  Energy Efficiency in Many-Core Platforms  Through Wireless NoC (Invited Paper)  Partha Pratim Pande, Ryan Gary Kim, Wonje Choi  Zhuo Chen, Diana Marculescu, Radu Marculescu  School of EECS, Washington State University,  Pullman, WA, USA  Email: {pande, rkim, wchoi1}@eecs.wsu.edu  Department of ECE, Carnegie Mellon University   Pittsburgh, PA, USA  Email: {tonychen, dianam, radum}@cmu.edu  Abstract— During the last decade, we have witnessed a  major transition from computation- to communication-centric  design of integrated circuits and systems. In particular, the  network-on-chip (NoC) approach has emerged as the major  design paradigm for multicore systems-on-chip (SoC). The  major challenges in traditional wire-based NoCs are the high  latency and power consumption of the multi-hop links. By  inserting single-hop long-range wireless links in place of multihop wired links, the overall system performance can be  significantly improved. We should adopt novel architectures  inspired by the on-chip wireless links to design highperformance multi-core chips. In this regard, the small-world  network-inspired wireless NoC (WiNoC) has emerged as an  enabling  interconnection  infrastructure to design highbandwidth and energy-efficient multicore chips. In this paper  we present the various challenges and possible solutions for  designing energy-efficient massive multicore chips enabled by  the WiNoC paradigm.   Keywords— NoC, VFI, Dynamic V/F, Wireless, Multicore,  Low-power.  I. INTRODUCTION   Data centers and high performance computing clusters  (HPCs) are necessary for solving compute- and dataintensive applications. Emerging many-core processors  present a power and area-efficient platform for designing  Data Center-on-a-Chip (DoC) consisting of thousands of  embedded cores. However, the design of today’s highperformance massive multicore chips is dominated by power  and  thermal  constraints.  Indeed,  increased power  consumption not only raises the chip temperature and cooling  cost, but also decreases chip reliability and performance.  Consequently, it is imperative to come up with new  interconnection architecture and power management  strategies.   The  small-world network-enabled wireless NoC  (WiNoC) has emerged as an enabling interconnection  infrastructure to design high-bandwidth and energy-efficient  multicore chips [1]. In this WiNoC architecture, long-range  communication predominately takes place through the  wireless shortcuts, whereas the short-range data exchange  occurs through conventional metal wires. This results in  performance advantages  (lower  latency and energy  dissipation) mainly stemming from using the wireless links  as  long-range  shortcuts between  far apart cores.  Incorporating suitable power management strategies will  further enhance the improvement in energy efficiency of  WiNoC-enabled multicore chips.   Multiple Voltage Frequency Island (VFI) partitioning  presents one such power management strategy for multicore  chips [2]-[6]. Indeed, by  tailoring  the voltages and  frequencies of each VFI domain, we can achieve significant  energy savings subject to specific performance constraints.  Most of the existing VFI-partitioned designs use the  conventional multi-hop mesh-based NoC architecture.  However, for DoC-scale systems,  the  inter-VFI data  exchanges  through  traditional mesh NoCs  introduce  unnecessary latency and energy overheads. The multi-VFI  platform represents a natural fit for the WiNoC architecture  where the synchronous buffers in some of the NoC routers  can simply be replaced with mixed-clock/mixed-voltage  FIFOs as needed. In this paper, we discuss how by integrating  the WiNoC and VFI paradigms in a synergistic manner, we  can design energy-efficient multicore platforms without  introducing noticeable performance penalty. Ultimately this  will pave the way for designing an energy-efficient WiNoCenabled DoC (WiDoC).  II. VFI DESIGN METHODOLOGY  Generally speaking, VFI in multicore systems is desirable  from  two perspectives: 1) Reducing  the overall  communication cost; and 2) Improving the energy efficiency  by producing better opportunities for voltage and frequency  (V/F) scaling. From the perspective of the overall network  cost, the communication between two cores within the same  VFI is significantly cheaper than communication between  two cores residing in two different VFIs. In the first case, the  exchange of data requires fewer hops and no mixed clock and  voltage interfacing. Thus, it is desirable that the subsets of  cores that heavily communicate with each other get clustered  into the same VFI. From the perspective of energy efficiency,  it is also desirable to cluster together those cores that have  similar utilizations. This way, cores running similarly  behaved workloads can share the same V/F pair; this can help  reduce the number of such distinct pairs without violating the  performance constraints.   A. VFI Clustering  There are three primary ways of implementing VFI-based  clustering, namely: 1) clustering based on communication, 2)  clustering based on core utilization and 3) hybrid clustering  that takes both utilization and communication into account.  978-1-4673-8388-2/15/$31.00 ©2015 IEEE 165       The utilization-based VFI clustering minimizes the intra-VFI  core utilization variation. Communication-based clustering  encapsulates the inter-core communication within clustering  with best effort. Hybrid clustering uses both communication  and utilization to achieve the best of both worlds.  B. V/F Tuning  After VFI partitioning, we can determine the static V/F  level of each VFI such that it minimizes the power  consumption under a certain performance constraint. Power  and performance models, such as those proposed in [7], can  be used to accomplish this. However, the application  characteristics, core utilization and traffic information, tend  to vary throughout the runtime of every application.  Therefore, static V/F tuning, although simple, tends to be  suboptimal. Hence, we should take advantage of the temporal  variations in the application by dynamically tuning the V/F  of each VFI.  C. VFI Interfaces  In this VFI-enabled system, each island can work with its  own voltage and frequency. As such, communication across  different VFIs is achieved through mixed-clock/mixedvoltage (MCMV) first-input first-output (FIFO) interfaces.  This provides the flexibility to scale the frequency and  voltage of various VFIs in order to minimize the overall  energy consumption [8], [9].  III. WINOC ARCHITECTURE SUPPORTING VFI   The goal of on-chip communication network design is to  transmit data with low latencies and high throughput using  the least possible power and resources [10]. Modern complex  network theory [11] provides a powerful method to analyze  network  topologies. Between  a  regular,  locally  interconnected mesh network and a completely random  Erdös-Rényi topology, there are other classes of graphs, such  as small-world and scale-free graphs. Small-world graphs  have very short average path length, defined as the number of  hops between any pair of nodes. The average shortest path  length of small-world graphs is bounded by a polynomial in  log(N), where N is the number of nodes, making them  particularly interesting for efficient communication with  minimal resources [12]. NoCs exhibiting small-world  Fig. 1: WiNoC: Small-world network architecture with short- and longrange links.  166 characteristics can perform significantly better than locally  interconnected mesh-like networks [13], yet require far fewer  resources than a fully connected system. These properties of  small-world networks make them desirable for VFI-based  systems. Moreover, WiNoCs are particularly attractive for  creating these small-world networks since the long-distance  shortcuts typically found in these types of networks can be  realized using high-bandwidth,  low-energy, wireless  interconnects while the local links can be designed with  traditional metal wires.  A. Small-World Connectivity   The topology of the WiNoC is a small-world network  where the links between routers are established following a  power law distribution. More precisely, the probability P(i,j)  of establishing a link between two routers i and j, separated  by a Euclidean distance lij, is proportional to the distance lij  raised to a finite power as in:                               (1)   The frequency of traffic interactions between cores i and  j, fij, is also factored in, so that frequently communicating  cores have a higher probability of having a direct link  inserted between them. This frequency is the percentage of  traffic generated by core i that is destined for core j. This  approach implicitly optimizes the network architecture for a  non-uniform traffic scenario.    Getting into details, the parameter 𝛼 governs the nature  of connectivity, e.g., a larger 𝛼 increases the probability of a  locally connected network with a few, or even no long-range  links. By the same token, a zero value of 𝛼 generates an ideal  small-world network following the Watts-Strogatz model –  one with long-range shortcuts that are independent of the  distance between the cores. It has been shown that a value of  𝛼 less than D + 1, D being the dimension of the network,  ensures the small-world property; with 𝛼 = 1.8, the average  hop count is minimized with a fixed wiring cost [14]. As  long metal wires are costly both in terms of power and  latency, we propose to use wireless links to connect the  routers that are far apart. In practice, depending upon the  available wireless resources, we can only allow a limited  number of long links in the WiNoC to be wireless, while the  others would remain wireline. This way, we can make the  distant cores “socialize” with each other, and hence reduce  the communication costs when running real applications.     To get some intuition, Fig. 1 represents such a WiNoCbased VFI system with 16 cores where each core is associated  with a router (not shown for clarity). This architecture has  many short-range (local) links, as well as a few long-range  links schematically represented by the arching interconnects.  As mentioned above, depending on available resources, a  limited amount of these shortcuts will be implemented by  using millimeter (mm)-wave wireless links operating in the  10-100 GHz range [1]. We note that the long-range wireless  links can play important roles in achieving various goals, e.g.,  optimizing for performance, exchanging control signals  between multiple VFIs for efficient power management, etc.  Moreover, unlike other interconnects such as RF-I or normal        metal wires [15], the mm-wave wireless links can establish  communication channels between any pair of nodes by virtue  of their broadcasting capability.  The power law connectivity-based WiNoC is basically an  irregular network topology. We assume an average number  of connections, 〈𝑘〉, from each NoC router to the other routers.  We propose that the value of 〈𝑘〉 be chosen to be four so that  the WiNoC does not introduce any additional router overhead  with respect to a conventional mesh. Also, an upper bound,  kmax, need to be imposed on the number of ports attached to a  particular router so that no router becomes unrealistically  large in the WiNoC [16]. Due to the nature of the VFI  clustering, additional constraints need to be applied to the  connectivity of the WiNoC routers. The distribution of links  should be divided into the VFI intra-cluster connections  needed  to ensure each cluster’s connectivity and  communication, and the VFI inter-cluster connections to  enable communication between different clusters [17].   B. Wireless Link and Core Placement  To  help  facilitate  predominantly  long-distance  communication, we use mm-wave wireless  links  to  communicate among distant cores. It is possible to create  three non-overlapping channels with on-chip mm-wave  wireless links. By extending the wireless frequency range to  sub-THz, the number of non-overlapping channels can be  extended even further. Using these wireless channels, we  overlay the wireline small-world connectivity with the  wireless links such that a few routers get an additional  wireless port. Each of these wireless ports will have a  wireless interface (WI) tuned to one of the three wireless  channels. One WI is replaced by a gateway WI that has all  three channels assigned to it; this facilitates data exchange  between the non-overlapping wireless channels. The WI  placement is most energy-efficient when the distance  between them is at least 7.5 mm for the 65 nm technology  node [1]. The optimum number of WIs is twelve for a 64 core system size [16].   The overall performance of the WiNoC also depends on  the placement of the wireless links and physical locations of  the cores.  As examples, we describe two possible strategies.  One such strategy is to minimize the traffic -weighted hop  count, while another is to maximize the wireless uti lization.  The first methodology physically arranges the cores in their  specific VFI configurations in order to minimize the distance  of highly communicating cores (minimize hop-count).  Effectively, the objective is to minimize the average traffic  weighted hop count. In the second methodology, we aim at  increasing the amount of traffic going through the wireless  links (maximize wireless usage). The wireless nodes are  placed near the center of each VFI cluster. This allows most  of the cores to have wireless access opportunities while  maintaining the minimum distance requirement for energy  efficient wireless transmissions compared to corresponding  wireline links. Then the physical core placement uses this  knowledge and the idea of logically near, physically far (by  using the wireless links) to place highly communicating  cores closer to the WIs. It is shown in [18] that, for a 64-core  system divided in to four equal VFI clusters, the maximized  wireless usage methodology improves the overall EnergyDelay-Product (EDP) of the system compared to the  minimized hop-count strategy.  C. Routing and Flow Control  As the WiNoC has an overall irregular topology, it is  essential to design and optimize suitable deadlock-free  routing mechanisms for it. Routing in irregular networks is  more complex, because routing methods are typically  topology agnostic. Hence, it is necessary to investigate  suitable routing mechanisms for small-world networks.  Routing in irregular networks can be classified into two  broad categories, viz., rule- and path-driven strategies [19].  Rule-driven routing is typically done by employing a  spanning tree for the network. Messages are routed along  this spanning tree with specific restrictions to achieve  deadlock freedom. Because deadlock freedom is taken into  account first for these routing strategies, minimal paths  through the network for every source-destination pair cannot  be guaranteed [19]. Conversely, for path-driven routing,  minimal paths between all source-destination pairs are first  guaranteed and then deadlock freedom is achieved by  restricting portions of traffic from using specific resources  such as the virtual channels [19].   The first routing strategy for WiNoC that we consider is  an up/down tree-based routing algorithm, belonging to the  rule-based classification. This routing strategy utilizes a  multiple tree roots (MROOTS)-based mechanism [20].  MROOTS allows multiple routing trees to exist, where each  tree routes on a dedicated virtual channel. Hence, traffic  bottlenecks can be reduced in the upper tree levels that are  inherent in this type of routing. An allowed route never uses  an up direction along the tree after it has been in the down  path once. In addition, a packet traveling in the downward  direction is not allowed to take a shortcut, even if that  minimizes the distance to the destination. Hence, channel  dependency cycles are prohibited, and deadlock freedom is  achieved [20].  The second routing strategy is an adaptive layered  shortest-path routing (ALASH) algorithm [21], which  belongs to the path-based classification. ALASH is built  upon the layered shortest path (LASH) algorithm, but has  more flexibility by allowing each message to adaptively  router paths, letting the message choose its own route at  every intermediate router.   The LASH algorithm takes advantage of the multiple  virtual channels in each router port of the NoC routers in  order to route messages along the shortest physical paths. In  order to achieve deadlock freedom, the network is divided  into a set of virtual layers, which are created by dedicating  the virtual channels from each router port into these layers.  The shortest physical path between each source -destination  pair is then assigned to a layer such that the layer’s channel  dependency graph remains free from cycles.  We have demonstrated that ALASH provides similar or  better performance compared to MROOTS, while offering  an improved temperature profile for WiNoC [16].  In the WiNoC, data is transferred via a flit -based,  wormhole routing. Between a source-destination pair, the  167 among these three paradigms. When implementing VFIs, we  can cluster highly communicating cores to aid the WiNoC  and cluster cores with similar application characteristic  variations to aid V/F tuning. WiNoCs can be designed to take  into account the shape and characteristics of the VFI in order  to reduce the overall system performance degradation  inherent in VFIs. Lastly, V/F tuning can take advantage of  the application slack present in both VFIs and WiNoCs to  optimize the energy with low performance penalties.   V. CONCLUSION  In this paper we have discussed that by incorporating  WiNoCs, VFIs and VF tuning in a synergistic manner, it is  possible to design energy-efficient DoC-scale multicore  chips without introducing significant performance overhead.  Through the use of VFI-WiNoCs, it is possible to save  significant full-system energy-delay product (EDP) over  traditional non-VFI Mesh architectures. As such, we have  highlighted the importance of an integrated design approach  involving VFI, V/F tuning and wireless NoC to achieve  energy efficiency for multicore chips. In this paper we  outline the methodologies for building a WiNoC-enabled  DoC. We conjecture that this will open up new research  directions in energy-efficient large-scale parallel computing  without the area overhead inherent in these systems.   ACKONWLEDGEMENT  This work was supported in part by the US National  Science Foundation (NSF) grants CCF-0845504, CNS1059289, CNS-1128624 and CCF-1162202 as well as Army  Research Office grant W911NF-12-1-0373.  "
2015,Uncore RPD - Rapid Design Space Exploration of the Uncore via Regression Modeling.,"A regression-based design space exploration methodology is proposed that models the impacts of the memory hierarchy and the network-on-chip (NoC) on the overall chip multiprocessor (CMP) performance. Designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the cache configuration and memory hierarchy which determine the amount and pattern of the traffic on the NoC. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by designing memory and NoC-specific regression models and leveraging recent advances in uncore simulation. To show the utility of our methodology, UncoreRPD, two case studies are presented: i) analyzing and refining regression models for an 8-core CMP and ii) performing a rapid design space exploration to find best performing designs of a NoC-based CMP given area-constraints for CMPs of up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can refine uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the NoC design space by up to four orders of magnitude.","Uncore RPD: Rapid Design Space Exploration of the Uncore via Regression Modeling Karthik Sangaiah, Mark Hempstead, and Baris Taskin Department of Electrical and Computer Engineering Drexel University, Philadelphia, PA USA Email: ks499@drexel.edu, {mhempstead, taskin}@coe.drexel.edu Abstract—A regression-based design space exploration methodology is proposed that models the impacts of the memory hierarchy and the network-on-chip (NoC) on the overall chip multiprocessor (CMP) performance. Designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the cache conﬁguration and memory hierarchy which determine the amount and pattern of the trafﬁc on the NoC. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by designing memory and NoC-speciﬁc regression models and leveraging recent advances in uncore simulation. To show the utility of our methodology, UncoreRPD, two case studies are presented: i) analyzing and reﬁning regression models for an 8-core CMP and ii) performing a rapid design space exploration to ﬁnd best performing designs of a NoC-based CMP given area-constraints for CMPs of up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can reﬁne uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the NoC design space by up to four orders of magnitude. IN TRODUC T ION I . Given the current trend of an increasing number of cores in chip multi-processors (CMPs), some CMPs have the potential to have over 100 cores in the near term future. Intel has already produced the 80-core Intel Teraﬂops processor [1], while Tilera has developed a 100-core CMP [2]. As a means to scale performance within power and area budgets for a large number of cores, designers have increasingly relied upon using network-on-chip (NoC) topologies to manage communication trafﬁc between cores. However, efﬁciently designing NoCs for CMPs with large number of cores is an ongoing problem for system designers [3]. Thus, as a solution to this growing need for effective NoC design techniques, a rapid design space exploration methodology, Uncore RPD, is proposed to pinpoint the best use of hardware resources for NoC-based CMPs. System designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the memory hierarchy, which determine the amount of pattern of the trafﬁc on the NoC. A particular measure of the codependent impacts of the memory hierarchy and NoC on overall performance is shown in Figure 1. In this motivational experiment on four arbitrarily selected benchmarks from the PARSEC and SPLASH-2 benchmark suites, the parameters of the NoC, shared caches and application data size are ﬁxed, while the private L1 cache size is increased from 978-1-4673-8388-2/15/$31.00 ©2015 IEEE 365 32kB to 128kB. As the private caches increase, the NoC trafﬁc generated from the application is reduced. Hence, it is essential to model the memory hierarchy in the context of NoC design, as NoC utilization can vary drastically based on application and the memory hierarchy. The memory hierarchy and NoC design space has grown to over 100 million conﬁgurations for homogeneous CMPs. Traditional cycle-accurate simulators, such as Gem5 [4], suffer from large simulation time, which makes it prohibitive to explore the CMP core-uncore design space with millions of conﬁgurations. In an effort to quickly simulate designs in this growing design space, researchers have recently discovered efﬁcient techniques to speed up uncore-based simulation, such as in Sniper [5] and SynchroTrace [6]. Despite the signiﬁcant speedup in simulation time, it is computationally infeasible to exhaustively simulate every design with simulation. Thus, it is pragmatic to apply a technique, such as regression modeling, to characterize the design space with a reduced sample of fast simulations. Statistical regression models have been applied to the single core microarchitecture [7, 8], multiprocessor model [9], shared caches [7, 10, 11], accelerators [12], and GPUs [13]. This paper is the ﬁrst to accurately and efﬁciently apply statistical regression modeling [8] to design the memory as well as the NoC design space of the “uncore” in a CMP system. Through the use of a lowdiscrepancy sampling technique, SOBOL, systematic biases in the model are improved by 4× over previously researched sampling techniques. Furthermore, by leveraging advances in the NoC-based CMP simulation through SynchroTrace [6], the proposed statistical regression methods can simulate CMPs up to 64 cores in the order of minutes to 24 hours. By utilizing regression modeling [8], the exploration time of the design space is reduced by up to four orders of magnitude compared to fast, contemporary uncore simulators, with median prediction errors of CMP performance as low as 1.4%. This paper makes the following contributions: 1) A regression modeling strategy based on cubic splines is used to model the memory and NoC design space. An 8-core NoC-based CMP regression model is assessed for accuracy and modeling biases. A low-discrepancy sampling technique, SOBOL, is investigated for a more accurate memory and NoC design space exploration. A large scope design space exploration areaconstrained case study of up to a 64-core NoC-based CMP is examined, to prove the efﬁciency of the proposed design space exploration methodology. 4) 2) 3) (a) Blackscholes (b) Water-Spatial Fig. 1. Codependent Relationship of NoC Trafﬁc to Cache Conﬁguration (c) Ocean (d) Barnes I I . BACKGROUND AND R ELAT ED WORK The proposed NoC-based CMP design space exploration methodology includes i) fast simulation of memory and NoCfocused CMP simulation through using SynchroTrace [6], ii) a reduction in the number of simulations required to characterize the design space by leveraging regression modeling strategies by Harrell [14] (introduced to the computer architecture literature by Lee et al [15]), and iii) a lowdiscrepancy sampling technique, SOBOL [15], to aid in the ﬁdelity of the statistical regression models in characterizing the uncore design space of memory and NoC. A. NoC-based CMP Simulation Enhancements to traditional execution-based simulators to model NoC-based CMPs [4–6, 16, 17] are a well-tread research area, but these enhancements are not efﬁcient enough for design space exploration. Sniper [5] is a multi-threaded execution-driven simulator that obtains speedup through interval simulation, achieving simulation performance by an order of magnitude over full-system simulators such as Gem5 [4]. SynchroTrace [6] is a trace-driven simulation framework comprised of synchronization-aware traces that drive a timing model, interfaced with the cache and NoC simulators from Gem5 [4]: Ruby and Garnet, respectively. The synchronizationaware traces are generated from the native execution of multithreaded applications. Both Attackboard [17] and Netrace [16] create dependency-tracking network traces for NoC simulators. Although they are fast for benchmarking single design NoCs, these network traces are unreliable for design space exploration of NoCs, as they require multiple full-system simulation runs for their methodology. Additionally, Synfull [18] generates network traces based application and cache coherence behavior. However, the traces are required to be generated per memory conﬁguration, and generating the traces require full-system simulation. In the context of a memory hierarchy and NoC design space of over 100 million conﬁgurations in homogeneous CMPs, these execution- and trace-based simulation techniques alone are not scalable. For the proposed design space exploration methodology, SynchroTrace is leveraged for its speedup (up to an 18× speedup over the Gem5 fullsystem simulator) while maintaining 97% accuracy in design space exploration of the uncore [6]. B. Regression and Computational Modeling Techniques A recent hot research area has been in modeling techniques to reduce the total number of simulations required to estimate the power and performance of large design spaces. These techniques include statistical regression models [7, 8, 12], 2D wavelet models [10], artiﬁcial neural networks [10, 11], and ranking algorithms [19]. Statistical regression models have been applied to the single core microarchitecture [7, 8], multiprocessor model [9], bus-based CMPs [11], shared caches [7, 10, 11], accelerators [12], and GPUs [13]. SVRNoC [20] leverages a learning-based support vector regression model to compute NoC-speciﬁc performance metrics, such as the channel average waiting time and the trafﬁc ﬂow latency. However, this model does not attribute the affects of the memory hierarchy on the NoC. ArchRanker [19] applies a ranking algorithm to ﬁnd the best design in a design space. Overall, ArchRanker reduces the total number of executiondriven simulation samples required to rank the design space in terms of performance, but ArchRanker only models a design space of up to 8 cores with a ﬁxed NoC interconnect. Varying the NoC parameters, which is a necessity in uncore design space exploration, is not performed in ArchRanker [19]. I I I . R E STR IC TED CUB IC S PL IN E MODE L FOR NOC -BA SED D E S IGN S PAC E EX PLORAT ION The overall goal of using the restricted cubic spline models is to characterize the performance of the overall memory and 366 TABLE I. M EMORY AND NOC PR ED IC TOR S Predictor Core Count L1 Hit Latency (Cycles) L1 Cache Size (kB) L1 Associativity L2 Cache Size (kB) L2 Associativity NoC Buffer Depth (Flits) NoC Virtual Channels NoC Channel Bandwidth (Flits) NoC 2D Mesh Rows Design Space Predictor Values 2,4,8,16,32,64 2,3,4,5,6 8,16,32,64,128 2,4,8,16 128,256,512,1024,2048 2,4,8,16 1,2,3,4,5,6,7,8 1,2,3,4,5 2,4,8,16,32 1,2,4,8 NoC design space using a small set of samples. To create the models for NoC-based CMPs, it is necessary to determine i) the relevant memory and NoC design conﬁgurations, ii) the codependent relationship between the conﬁgurations, iii) the number of samples required to generate the model, and iv) the sampling technique. For reference, the design conﬁgurations used in the memory and NoC case studies of Section V are shown in Table I. Prior to presenting a NoC-based CMP restricted cubic spline model, a general restricted cubic spline model and its motivation are described in the next section. A. Overview of Regression Modeling Methodology Assume there are P predictors (design conﬁguration parameters) describing the uncore design space, with X as the set of independent predictors (also called a vector of predictors). Then, X = {X1 , X2 , . . . XP }. Let Y be deﬁned as the response variable to the set of predictors X . In the context of design space exploration, a predictor X2 , for instance, can represent L2 cache size, while Y represents overall system performance. The response variable Y is assumed to be constant for a given set of predictors X . β represents a set of regression coefﬁcients (weights) with β = β0 , β1 , . . . , βP . Thus, for a given observation i, using an initial weighted sum linear regression of the predictor values Xi,P of observation i, the predicted value ˆyi is: ˆyi = β0 + β1Xi ,1 +β2Xi ,2 . . . βP Xi ,P (1) To ﬁt a linear regression model to all design conﬁguration observations, N , the best-ﬁtting approach can be used by minimizing the sum of squared errors of the actual performance values Yi to the predicted performance values ˆyi . Equation 1 is the predicted output for one observation i. This term is the predicted output for all N observation i’s. N(cid:88) (Yi − β0 − P(cid:88) E rror(β0 , β1 , . . . , βP ) = βj Xi,j )2 (2) i=1 j=1 However, this linear regression model cannot accurately model predictors with nonlinear relationships with the response (i.e. NoC bandwidth to system performance). Polynomial models can be considered but have an undesirable property: an established ﬁt in one region may impact the ﬁt in another region. Thus, to address these issues, restricted cubic spline models [14] are used. Generally, splines are used as 367 a ﬂexible modeling technique to capture piecewise functions throughout the prediction space. The piecewise functions can be linear or model polynomials. The prediction space is divided into intervals by knots, k knots t1 , . . . , tk , which are the endpoints that connect the piecewise functions. The number of knots, k , can be tuned based on the number of available conﬁgurations for a given design parameter set X ; an increase in knots typically leads to a better overall ﬁt to the model. Since the cubic spline models have low modeling accuracy near the tails of the model, restricted cubic spline models, with linear tails, are used for better overall accuracy. Once the regression coefﬁcients are computed for a restricted cubic spline model, the predicted response (i.e. performance) ˆyi for a set X of design conﬁgurations and k knots t1 , . . . , tk , can be computed easily by merely evaluating the following linear equation: ˆy = β0 + β1X1 + β2X2 + · · · + βk−1Xk−1 where X1 = X and for j = 1, . . . , k − 2, Xj+1 =(X − tj )3 + − (X − tk−1 )3 + (tk − tj )/(tk − tk−1 ) + (X − tk )3 + (tk−1 − tj )/(tk − tk−1 ) (3) (4) with (u)+ = u if u > 0, and (u)+ = 0, otherwise. B. Codependent Relationship between Predictors The memory and NoC predictor have codependent impact on performance, as motivated in the example shown in Figure 1. An example of this includes the interaction of the L1 cache size on the NoC channel bandwidth, for NoC-intensive benchmarks. If these predictors impact on the response cannot be separated, an additional regression coefﬁcient and predictor term must be added. This scenario is deﬁned as an interaction [14], with a newly constructed predictor term X1X2 for each signiﬁcant codependent relationship. The added complexity to the regression model is as follows: ˆy = β0 + β1X1 + β2X2 + β3X1X2 (5) To discover if the memory and NoC each have signiﬁcant impacts to performance, a Spearman correlation algorithm is run across the sampled simulation data. This algorithm produces the strength of each predictor in its relationship to performance. If the top 3 most signiﬁcant predictors are a mix of the memory hierarchy and the NoC, these predictors are assigned the codependent impacts of the memory hierarchy and NoC in the model creation. Figure 2 is an example of the Spearman coefﬁcient response of the predictors for the Ocean benchmark. In this example, it is seen that out of the top 3 highest responses, the highest predictor strength to performance relationship is a NoC predictor (NoC channel bw), and the other two of the top three are the L1 cache size, and the number of NoC virtual channels. This high-level memory/NoC relationship is maintained in the proposed restricted cubic spline model by accounting for these top 3 interactions in the model creation for Ocean. C. Sampling Techniques A general sampling strategy posited by Harrell [14] is to sample 20× the number of predictors. The results of the case studies of Section V show that a sample size of 20× the number of predictors is largely sufﬁcient for design space exploration of the uncore, as well. In regards to the sampling strategy, the uniform-at-random sampling technique is recommended by Harrell (and adopted by Lee et al. [8]) due to its computational ease and lack of user-induced bias. However, in the context of memory and NoC design space exploration, uniform-at-random sampling neglects to represent the low cache and varying NoC region with enough samples. Consequently, the regression models constructed with uniformat-random sampling all have a systematic bias. Hypothetically, this systematic bias will manifest itself as overestimated performance for low performing designs (i.e. low cache and low NoC), as the uniformly sampled space will feature higher cache sizes where sensitivity to NoCs are lower. In effect, this bias renders these uniformly sampled models unusable for design space exploration, as low performing designs may be predicted as having a desirable performance. To resolve this systematic bias, Uncore RPD leverages a low-discrepancy sampling technique, SOBOL [15, 21]. SOBOL is a deterministic quasirandom sequence that can sample “more uniformly” than uniform-at-random sampling and can be constructed for N -dimensions. The overall beneﬁt with this technique is that the sequence will produce a sample set that can guarantee sampling of the more critical design spaces. Thus, this low-discrepancy sampling technique will resolve the issue of systematic bias in overpredicting performance for poor designs. IV. EX PER IM EN TA L M ETHODO LOGY The simulation platform, experimental methodology, and case studies are introduced in this section. Using the proposed design space exploration methodology, Uncore RPD, 8-core CMP models are constructed and assessed for accuracy and modeling biases. Following this assessment, a regression model is constructed for varying a number of cores to rapidly explore the large uncore design space of CMPs of up to 64 cores. A. Memory/NoC Simulation Platform and Design Space A number of L1 and L2 cache sizes, associativities, and NoC parameters that include buffer depth, number of virFig. 2. Spearman Correlation of Cache and NoC Predictors to CPI for Ocean 368 tual channels, channel bandwidth, and 2D mesh dimensions are explored in the design space exploration experiments. The quantitative values of the design space are listed in Table I. The regression models are generated using the statistical computing tool R. Uncore simulation is performed with SynchroTrace [6]. These predictors model a subset of the wide memory and NoC design space including varying conﬁgurations of private and shared caches, as well as the NoC. For design spaces with a ﬁxed core count, there are 1.6 million design conﬁgurations available, and 9.6 million design conﬁgurations in the design space when core count is varied. The area of these design conﬁgurations is calculated with Cacti 6.5 [22] for the caches and Orion 2.0 [23] for the NoC using the 65nm technology. Multi-threaded applications from the Splash-2 [24] and PARSEC-2.1 [25] benchmark suites were used in the design space exploration case studies. The synchronization-aware traces (for SynchroTrace) of these multi-threaded applications were captured on the Linux Kernel 2.6 in CentOS 6 with the standard POSIX Thread API. B. Case Studies Descriptions Memory and NoC-focused restricted cubic spline models are generated for 8-core NoC-based CMPs and assessed for model accuracy and bias in Section V-A. Regression models that incorporate a core count as a conﬁguration parameter (predictor) are evaluated in Section V-B. These models are then used to extrapolate a high performing design region, given area constraints from a design space of a CMP of up to 64 cores. A single model may not be accurate for all benchmarks in each case study as applications individually affect how the memory hierarchy or the NoC may be used. Speciﬁcally, each individual application may have a high variety in application characteristics; some benchmarks may have a larger working set than other, contributing pressure onto local cache sizes, while other benchmarks may have poor spatial locality and thus contribute L1 cache misses and NoC trafﬁc. Thus, individual benchmark-speciﬁc models are necessary. V. EX PER IM EN TA L R E SU LT S In this section, the results of the design space exploration case studies are detailed. A. Regression Models for 8-Core Chip Regression models are designed and reﬁned for nine 8thread benchmarks from Splash-2 [24] and PARSEC 2.1 [25] across the design space of nine memory hierarchy and NoC predictors. Regression models are created using existing sampling strategies of Harrell [14]. Speciﬁcally, the number of samples required for the models are 20× the number of predictors (i.e. 180 samples for the nine predictors examined), and the sampling strategy is uniform-at-random sampling over these predictors. The 180 samples per benchmark are then simulated through SynchroTrace, and individuals models are created for each of the Splash-2 and PARSEC 2.1 benchmarks. The models are assessed for accuracy, in comparison to a validation set of 18 samples and evaluated for systematic model biases. Fig. 3. 8-Core Prediction Error without Memory and NoC Interactions Fig. 4. 8-Core Prediction Error with Memory and NoC Interactions 1) Regression with Existing Sampling Strategies: The performance prediction error of the nine Splash-2 and PARSEC 2.1 benchmarks are presented in Figure 3. As shown in Figure 3, the model for the blackscholes benchmark is the most accurate, with a median performance prediction error of 1.4%. All of the benchmarks have median performance predictions of less than 6.9%, with the exception of LU. It is evident that the model for the LU benchmark, which has a median performance prediction of 24.0%, has a much higher prediction error than the other eight benchmarks. During the simulations of the LU benchmark, it was discovered that LU injects NoC trafﬁc at a much higher rate than the other eight benchmarks: an order of magnitude more than Barnes, FFT, and FMM. Thus, LU has NoC parameters that are more sensitive (compared to the other benchmarks) with respect to performance, and this sensitivity is prevalent only for the small cache design spaces. Thus, the error may justify increasing the number of samples for this benchmark to better represent this critical region. An investigation on the impact of the number of samples on model performance is left to future work. For the two most NoC-intensive benchmarks, Ocean, and LU, modeling the codependent impact of the cache and NoC predictors on performance further increases the accuracy of the regression model. As the cache and NoC can have a codependent on performance, an additional coefﬁcient must be made explicit to account for this interaction. For reference, the strategies to model the memory and NoC codependent impacts on performance is presented in Section III-B. The prediction error for LU, and Ocean are improved by a notable margin. For LU model, the worst performing model, the median performance prediction error for the LU barely improves to 23.8%. However, the ﬁrst quartile and third quartile prediction errors reduce from 12.9% to 9.6% and 45.0% to 40.7%, respectively. For the Ocean model, the maximum error reduces from 29.6% to 12.9%, while the median error reduces from 7.5% to 6.1%. 2) Correcting Model Bias through Low-Discrepancy Sampling: The modeling error of the eight benchmarks, illustrated Figure 4, is sufﬁcient given the range of overall system performance in the total design space. However, a systematic bias in the model must be addressed prior to a design space exploration using the regression models. For all of the benchmarks, the highest variety in outliers or in the third quartile– max value range are from the same design conﬁgurations in the validation set. This error is attributed to overpredicting the performance of the low performing designs (high CPI). It is necessary to remove this model bias, as these models will predict higher performance for low performing design conﬁgurations, and as a result, incorrect design conﬁgurations may be in the desired high performing subset design space. Figure 5(a) illustrates the residuals of the uniform-atrandom sampling-based regression model for FFT by grouping the CPI prediction for each of the 180 design points into sets of 20. At each of the ﬁtted values, the residuals are presented in as values: ﬁrst quartile, median, and third quartile. The residuals of this model show that the designs with the highest CPIs (lowest performance) have a large positive error; in other words, the design conﬁgurations with high CPI are overpredicted in performance using the initial regression models. This trend can be observed by focusing on the high tail of Figure 5(a). The error can be attributed to the sampling technique leveraged from the work of Harrell [14]. The efﬁcacy of the low-discrepancy SOBOL sampling (Section III-C) is demonstrated in comparison to that of uniform sampling [14] in Figure 5. As shown in Figure 5(b), the high tail of the low performing region of the uniformat-random sampling in Figure 5(a) has notably deceased. Speciﬁcally, the high-CPI model bias in the uniform-at-random 4× improvement in residual error for the highest CPI designs sampling is corrected with SOBOL sampling for FFT, with a sampled. Thus, by leveraging low-discrepancy sampling, in lieu of uniform-at-random sampling, a signiﬁcant model bias is removed, and the regression model maintains ﬁdelity even within the low-performing design region. 369 TABLE II. S I ZE O F O PT IMA L D E S IGN SUB S PAC E O F S EL EC T ED B ENCHMARK S Benchmark Cholesky FFT FMM LU Water-Spatial Size of Optimal Performing Design Subspace 917 1418 3063 145 1260 benchmarks are less than 10% with a third quartile error of approximately 20% or less. 1) Optimal Design Space with an Error Margin: To discover the optimal design in the design space, all of the area values of the 2.4 million design conﬁgurations are computed and ﬁltered through the area constraint (50% of 576mm2 ). The remaining designs are processed through the regression model as to predict the performance of each design conﬁguration, including the highest performing design conﬁguration. A design space of interest can be constructed by discovering the optimal performing design and the design conﬁgurations that fall within the regression model error margin of the best design. Thus, the amount of prediction error for each model affects the size of the targeted subspace containing the optimal design conﬁgurations under area constraints. For example, the model for LU has a third quartile error of 18.2%. The best predicted design for LU in this design space is a 16-core CMP with a 128kB L1 cache, 256kB L2 cache, and a relatively large NoC with a 16 byte channel length. The performance of the optimal design is predicted to be 1.5 CPI. The designs that are within 18.2% of 1.5 CPI are added to the design space of interest. Overall, as shown in Table II, the proposed regression modeling methodology enables a ﬁltered optimal design space, on the order of 100s to 1000s of design conﬁgurations, to be discovered out of the total 2.4 million design conﬁgurations. 2) Analyzing the Area-Constrained Design Space: For this case study, the prediction results of the LU and Cholesky benchmarks are examined in the context of this areaconstrained large design space exploration. The proposed methodology, Uncore RPD, enables designers to rapidly visualize the uncore design space. Figure 7 illustrates the large design space for LU given the area constraint; every design under the area constraint is evaluated for predicted performance and is categorized by number of cores of the simulation. Figure 8 illustrates the design space for LU with a categorization of total cache area. Through these two ﬁgures, it is evident that for the LU benchmark i) all of the optimal designs (i.e. within the error margin of the highest performing design) are of 16 cores for a design space of up to 64 cores, and ii) the optimal designs contain cache sizes varying between 100mm2 and 200mm2 with varying NoC resources. This rapid design space exploration describes a relatively heterogeneous result for Cholesky: i) as shown in Figure 9 the optimal design region is dominated by a mix of 8-core CMPs and 16-core CMPs, and ii) by correlating the cache size to the optimal performing designs, Figure 10 depicts that highest performing designs have total cache sizes between 100mm2 and 200mm2 with varying NoC resources. In the context of 2.4 million design conﬁgurations in a subset of the uncore design space, it is infeasible to character(a) FFT - UAR (b) FFT - SOBOL Fig. 5. CPI Residuals of FFT with Uniform-at-Random and SOBOL Sampling [Top Line - Third Quartile, Middle Line - Median, Bottom Line - First Quartile] B. Area-Constrained Design Space Exploration of Large Multi-threaded Programs In this section, a case study on area-constrained design space exploration of a wide memory and NoC space with a varied number of cores is explored. The overall goal of this experiment is to determine a design subspace that encompasses the highest performing designs given uncore area constraints. Within this design subspace, there are designs that sacriﬁce area and/or power for increased performance. This case study explores the ﬂexibility of varying the number of cores, and thus seeks to discover if fewer cores with a larger uncore or a large number of cores with a smaller uncore is optimal. This case study examines the design conﬁgurations in Table I, including a varying number of cores from two to 64. The area constraint is based on the area of the Intel SCC [26]: 576mm2 . To assess the uncore, a constraint of 50% of the total chip area is designated for the uncore. Regression models are developed sampling 180 designs over the entire design space, including the varied number of cores. For this experiment, the number of rows on the 2D mesh of the NoC are kept ﬁxed to a respective core count, i.e. 64 cores has an 8 mesh rows, while 4 cores have 2 mesh rows. Thus, nine design parameters are investigated, with a total number of design conﬁgurations reaching 2.4 million. The prediction accuracy of the regression model is detailed in Figure 6. It is notable that the median error of all of the 370 Fig. 6. Regression Modeling Error for Varying Number of Cores Fig. 9. Filtered Design Space for Cholesky using Regression Modeling Fig. 7. Filtered Design Space for LU using Regression Modeling Fig. 10. Cache Area of Filtered Design Space for Cholesky using Regression Modeling ize the entire design space solely using simulation. Overall, as presented in this case study, the proposed regression modeling methodology, Uncore RPD, enables designers to rapidly investigate the large uncore subspace by reducing the amount of simulations required to characterize the design space by over four orders of magnitude. 3) Simulation Statistics: The compute time required to perform the area-constrained design space exploration case study is presented in Table III for Gem5 [4], SynchroTrace [6], and the proposed Uncore RPD. This table aggregates the total compute time for capturing traces, simulation, and time associated with regression modeling to characterize the design space of 2.4 million uncore design conﬁgurations. This time can be divided up by the number of simulations and compute nodes available in a research computing cluster. Design space Fig. 8. Modeling Cache Area of Filtered Design Space for LU using Regression 371 exploration with Gem5 does not require traces or further modeling, but the total compute time is on the order of 1000 years. SynchroTrace requires generating traces once for each thread count (i.e. a trace for each 2, 4, 8, 16, 32, and 64 threads per benchmark) and has a total compute time on the order of 100 years. Uncore RPD requires the same trace generation step to leverage SynchroTrace, but the proposed methodology can characterize the design space sufﬁciently with only 180 designs and minimal compute time for model creation and prediction. In practice, using the previously generated traces, the Uncore RPD methodology was executed fully on LU benchmark in approximately an hour to simulate the samples and generate the model using a cluster with 2432 compute cores. V I . CONC LU S ION S In this work, Uncore RPD, a rapid regression-based uncore design space exploration methodology is presented. Effective regression modeling reduces the number of simulations required to describe the design space of the memory and NoC for CMPs. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by extending previous work on microarchitecture-focused regression models and recent advances in uncore simulation. SOBOL, a low-discrepancy sampling technique, is implemented to reduce systematic bias, and the model is further reﬁned through modeling the codependent impact of the memory and NoC on overall system performance. To show the utility of our methodology, two case studies are presented: i) analyzing and reﬁning regression TABLE III. UNCOR E D E S IGN S PAC E EX PLORAT ION TOTAL COM PUT E T IM E FOR LU Simulation Methodology Gem5 SynchroTrace Uncore RPD Trace Capture Time N/A 21 hours 21 hours Simulation Time 1370 years 274 years 180 hours Model Creation and Prediction Time N/A N/A 5 seconds Total Time 1370 years 274 years 207 hours models for an 8-core CMP and ii) performing a rapid design space exploration to ﬁnd best performing designs of a NoCbased CMP given area-constraints for CMPs up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can reﬁne uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the memory and NoC design space by up to four orders of magnitude. V I I . ACKNOW L EDGM ENT S This material is based on work partially supported by the NSF Graduate Research Fellowship under Grant No. 1002809. Any opinion, ﬁndings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views of the National Science Foundation. "
2015,Variation-Aware Adaptive Tuning for Nanophotonic Interconnects.,"Short-reach nanophotonic interconnects are promising to solve the communication bottleneck in data centers and chip-level scenarios. However, the nanophotonic interconnects are sensitive to process and thermal variations, especially for the microring structures, resulting in significant variation of an optical link's bit error rate (BER). In this paper, we propose a power-efficient adaptive tuning approach for nanophotonic interconnects to address the variation issues. During the adaptive tuning process, each nanophotonic interconnect is adaptively allocated just enough power to meet the BER requirement. The proposed adaptive tuning approach could reduce the photonic receiver power by 8% - 34% than the worst-case based fixed design while achieving the same BER. Our evaluation results show that the adaptive tuning approach scales well with the process variation, the thermal variation and the number of communication nodes, and can accommodate different types of NoC architectures and lasers.","Variation-Aware Adaptive Tuning for Nanophotonic Interconnects , Rui Wu1 ∗ , Chin-Hui Chen2 , Cheng Li2 , Tsung-Ching Huang2 , Fan Lan3 , Chong Zhang1 , Yun Pan4 , John E. Bowers1 , Raymond G. Beausoleil2 , and Kwang-Ting Cheng1 1Department of Electrical & Computer Engineering, University of California, Santa Barbara, CA, US 2HP Labs, Hewlett-Packard Company, Palo Alto, CA, US 3College of Electrical Engineering, Zhejiang University, Hangzhou, Zhejiang, China 4Department of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, Zhejiang, China ∗ ruiwu@ece.ucsb.edu Abstract—Short-reach nanophotonic interconnects are promising to solve the communication bottleneck in data centers and chip-level scenarios. However, the nanophotonic interconnects are sensitive to process and thermal variations, especially for the microring structures, resulting in signiﬁcant variation of an optical link’s bit error rate (BER). In this paper, we propose a power-efﬁcient adaptive tuning approach for nanophotonic interconnects to address the variation issues. During the adaptive tuning process, each nanophotonic interconnect is adaptively allocated just enough power to meet the BER requirement. The proposed adaptive tuning approach could reduce the photonic receiver power by 8% - 34% than the worst-case based ﬁxed design while achieving the same BER. Our evaluation results show that the adaptive tuning approach scales well with the process variation, the thermal variation and the number of communication nodes, and can accommodate different types of NoC architectures and lasers. I . IN TRODUC T ION Nanophotonic interconnects provide high bandwidth, low energy consumption and low latency compared to traditional electrical interconnects. It becomes increasingly promising that the nanophotonic interconnects could replace the electrical links in short-reach applications, such as data centers, interchip, and intra-chip communications [1]. The microring resonator is widely used in many optical network-on-chip (NoC) architectures [2]–[7], because of its functional versatility, power efﬁciency, and compact footprint. However, the microring resonator is very sensitive to fabrication process variation and runtime thermal variation. As a result of the process and thermal variation effects, the resonance wavelength of the ring resonator deviates from the desirable carrier wavelength, which leads to performance degradation or even failure. This wavelength mismatch problem has been extensively studied: many power-efﬁcient tuning and channel arrangement schemes have been proposed [8]– [10]; several feedback-based wavelength stabilization circuits have also been implemented [11], [12]. Existing work on thermal and process variations mainly focuses on the tuning of the resonance wavelength [13]–[17]. However, the process variation induced variations of quality factor (Q) and extinction ratio (ER) of the microring resonator have not been well studied. We have fabricated batches of microring modulators and ﬁlters on 8 inch silicon-on-insulator (SOI) wafers at the CEA LETI foundry. The optical transmission spectra of the fabricated microring devices across the wafer are measured, from which the quality factor and the extinction ratio are extracted. We notice signiﬁcant variations of Q and ER from both our fabricated microring resonators and literature [18], [19]. Meanwhile, the Q and ER are very important to determine the BER and power budget of an optical link [18]. Our simulation results show that the variations of Q and ER lead to signiﬁcant variation of BER of the links. If the link design is targeted at the average performance of the devices, some of the links do not satisfy the BER requirement. Therefore, the variation effects of Q and ER must be carefully addressed. A naive worst-case based ﬁxed design can guarantee that most of the links satisfy the BER requirement. However, such a ﬁxed design leads to excessive power consumption. In this paper, we propose a power-efﬁcient adaptive tuning approach that tunes each link individually and allocates just enough power to meet the BER requirement. The adaptive tuning approach relies on on-chip fast BER estimation circuitry to monitor the link BER, and adaptively tunes either the laser or the photonic receiver to reach the target BER. We evaluate the power savings gained by the adaptive tuning approach with respect to different NoC architectures, variation values, and link conﬁgurations. Overall, the paper makes the following contributions: • • • • Characterizes the process variations of microringbased photonic devices using measured data. Demonstrates that the BER of the optical links could vary signiﬁcantly due to the process variations of microring devices. Proposes an adaptive tuning approach that reduces the power consumption than the worst-case based ﬁxed design with reasonable time and area overhead. Evaluates the adaptive tuning approach and demonstrates its scalability with respect to different levels of variations and various topologies. I I . BACKGROUND Nanophotonic interconnects mainly consist of light sources, waveguides, photonic modulators and photonic receivers (Fig. 1). On-chip laser arrays and off-chip comb lasers are common choices for the light source [20]. In this work, we consider a distributed feedback (DFB) hybrid silicon laser as an example 978-1-4673-8388-2/15/$31.00 ©2015 IEEE 487 W ;ĂͿ ߣ Žŵď>ĂƐĞƌ DŽĚƵůĂƚŽƌƐ ߣଵ ͙ ߣே W ZĞĐĞŝǀĞƌƐ ߣଵ ͙ ߣே λ λ ... 1 N KƉƚŝĐĂů&ŝďĞƌ tĂǀĞŐƵŝĚĞ ;ďͿ &>ĂƐĞƌ ͙ &>ĂƐĞƌ ߣଵ ߣே Dhy DŽĚƵůĂƚŽƌƐ ߣଵ ͙ ߣே ZĞĐĞŝǀĞƌƐ ZĞĐĞŝǀĞƌ ߣଵ ͙ ߣே tĂǀĞŐƵŝĚĞ Fig. 1. Schematics of wavelength-division multiplexing (WDM) nanophotonic interconnects using (a) an off-chip comb laser or (b) an on-chip DFB laser array. 0 -5 -10 -15 -20 dŚƌƵ ƌŽƉ /ŶƉƵƚ dŚƌƵ dŚƌƵƉŽƌƚYĨĂĐƚŽƌ͗ϭϮϴϵϭ dŚƌƵƉŽƌƚĞǆƚŝŶĐƚŝŽŶ͗ϭϳ͘ϱĚ ƌŽƉƉŽƌƚĞĨĨŝĐŝĞŶĐǇ͗Ͳϭ͘ϱϲĚ ƌŽƉ ) B d ( n o s s i i m s n a r T l a c i t p O d e z i l a m r o N 1319 1319.5 1320 1320.5 1321 1321.5 1322 1322.5 W ave length (nm) Fig. 2. The optical transmission of the through port and drop port of a microring (blue and green: measurement; red: model). The inset shows a microscopic image of a fabricated microring modulator. of the on-chip single-wavelength laser [21], and a Gaussian shape comb laser for the off-chip laser [20]. Silicon waveguides are widely used to guide the light on SOI platforms. At the transmitter side, compact and energy-efﬁcient microring modulators perform the on-off keying modulation of the light signal. At the receiver side, the light signal is redirected by the microring ﬁlter and sensed by the photodetector (PD). The microring structure is critical in the nanophotonic interconnects, and a basic model is introduced here. When an integer number of the incident light wavelength ﬁts the microring perimeter, the microring is on-resonance. At the onresonance state, the through port power reaches its minima and the drop port power reaches its maxima. The optical transmission spectrum of the through port and the drop port can be described by the Lorentzian shape models [22] (Fig. 2): Tthru (λ) = 1 − Tdrop (λ) = (1) Athru 1 + (2Q · (λ − λr )/λr )2 1 + (2Q · (λ − λr )/λr )2 Adrop where λr is the the microring’s resonance wavelength; Q is the microring’s quality factor; Athru is a parameter that is related to the microring’s extinction ratio: ER = 1/(1 − Athru ). Furthermore, we denote the optical transmission at the on(off-) resonance state as Ton = T (λ = λr ) (Tof f = T (λ = λr + ∆λ)), where ∆λ is the wavelength detuning for the offresonance state. In this way, when the microring functions as a modulator, the optical transmission at logic “0” and logic “1” are T0 = Tthru,on and T1 = Tthru,of f , respectively. When the microring functions as a ﬁlter, the input port to drop port insertion loss (the drop port efﬁciency) is Tdrop,on . Microring structures could also be used to build optical routers [23], [24]. For instance, in the ﬁve-port optical router reported in [23], the west-to-east insertion loss could be expressed as Tdrop,on · T 4 thru,of f · TW G loss . Based on the theoretical device models above, we obtain the equation for the bit-error-rate (BER), a widely used ﬁgure of merit for communication quality: erfc (cid:18) z √2 (cid:19) , z = Plaser Yi T1 − T0 σ1 + σ0 I Li · Rpd BER = 1 2 (2) where Plaser is the laser output power; I Li is the insertion loss of the photonic component i along the optical path; Rpd is the responsivity of the photodetector; σ1 (σ0 ) is the standard deviation of the logic “1” (“0”) corresponding noise. I I I . VAR IAT ION CHA L L ENG E S Similar to deep submicron electronic devices, the nanophotonic devices (e.g., microring modulators, microring ﬁlters, grating couplers, photodetectors) also suffer from signiﬁcant process variations [19]. In this work, we mainly focus on the severe variation effects in microring based devices, while our variation-aware analysis and design can also accommodate variations in other types of devices. The microring structure is very sensitive to runtime thermal variation and fabrication-induced process variation. Due to the thermal variation effect, the optical transmission spectrum redshifts as the temperature rises. Due to the process variation effect, the device geometry and the waveguide sidewall roughness vary in the fabrication process. Consequently, the λr , Q and ER deviate from the designed values. Both thermal and process variation effects will cause the mismatch between the resonance wavelength and the carrier wavelength. Many tuning schemes and circuits have been proposed to address the wavelength mismatch problem [8], [9], [11], [12], [25]. However, few tuning schemes take into account the variations of the Q and the ER. Here we characterize the variations of the Q and the ER based on measured results. Fig. 3 plots our wafer-scale inter-die measured data of the fabricated microring devices, together with the intra-die variation testing result reported in [18]. Both the inter-die and intra-die measured results show wide distribution ranges of Q and ER, which may have great impact on the communication BER. From the histograms, one can see that the distribution of the parameter A and the Q approximately follow normal distributions. The electrical tuning is usually utilized to compensate for the wavelength mismatch because it’s more power efﬁcient than the thermal tuning [13], [26]. However, the Q and the ER degrade signiﬁcantly when the tuning voltage is applied to the microring resonator (Fig. 4). The severe degradation of Q and ER caused by the electrical tuning may greatly deteriorate the communication BER, which also needs to be carefully considered during the link analysis. 488       ) % ( e g a t n e c r e P 18 16 14 12 10 8 6 4 2 0 KƉƚŝĐĂůWŽǁĞƌyϭ͘Ϯ tŽƌƐƚͲĐĂƐĞ ďĂƐĞĚ DĞĂŶǀĂůƵĞ ďĂƐĞĚ -20 -15 log BER -10 dĂƌŐĞƚZ͗ϭϬͲϭϮ Fig. 5. The BER distribution in the presence of process variations and the electrical tuning. The blue line represents the link conﬁguration based on the means of the device parameters. The red line enhances the link optical power by 1.2X Fig. 6. (a) The laser output power as a function of the driving current of a DFB laser [21] (dots: measurement, line: model); (b) The sensitivity and power consumption versus supply voltage of an adaptive photonic receiver (data from [11]). each optical link individually to meet the BER requirement. At a given BER and data rate, the minimum required optical modulation amplitude (OMA) is determined by the receiver sensitivity Psense : Plaser Yi I Li · (T1 − T0 ) = Psense (3) If the I Li , T1 , and T0 vary due to process and thermal variations, we could tune either the laser output power Plaser or the receiver sensitivity Psense to satisfy the above equation. Intuitively, we could tune the DFB laser’s output power by varying its driving current (Fig. 6 a). However, for interconnect schemes using an off-chip comb lasers, it’s inefﬁcient to tune the laser’s output power. This is because a comb laser has a ﬁxed optical spectrum distribution; and individual wavelength cannot be tuned independently. Fortunately, we notice an effective mechanism to trade off the power consumption for the receiver sensitivity (Fig. 6 b). The supply voltage of the receiver circuitry, i.e. the transimpedance ampliﬁer (TIA), has a signiﬁcant impact on the gain, bandwidth, and noise performance [11]. As the TIA supply voltage increases, the circuitry consumes more power and the receiver achieves a better sensitivity (Fig. 6 b). Another beneﬁt of tuning the receiver is allowing the sharing of onchip lasers [27]. In summary, for optical links using on-chip DFB lasers, we could tune either the laser output power or the receiver sensitivity. For links using off-chip comb lasers, we could only tune the receiver sensitivity. Fig. 3. (a)(b) Histograms of parameters A and Q of our inter-die measurement results; (c) Scatter plot of our inter-die measurement and Peng’s intra-die measurement in [18]; (d) Mean and standard deviation (std) of the three measured data sets. ) B d ( n o s s i i m s n a r t l a c i t p o d e z i l a m r o N 0 -5 -10 -15 -20 20 15 10 ) B d ( R E 5 0 -0.5 -1 Resonance wavelength shift (nm) 1317.5 1318 1318.5 Wavelength (nm) 1319 Fig. 4. The measured spectra series of a microring modulator at different bias voltages. The Q and the ER are important to determine the microring’s optical transmission and the BER (Eq. 1 and 2). The large variations of Q and ER may result in signiﬁcant variation of the BER. We perform Monte Carlo simulations of a simple singlewriter single-reader (SWSR) link [2]. The process variation statistics of our fabricated devices are used (the ﬁrst line in Fig. 3d), which has better ER and uniformity than the Peng’s devices in [18]. The simulation results in Fig. 5 show that the BER has a wide distribution range. About half of the links do not satisfy the BER requirement if the link design is based on the mean parameter values of the devices. Naively, a worstcase based ﬁxed design could guarantee that most of the links satisfy the BER requirement (the red line in Fig. 5). However, such a ﬁxed design requires excessive power consumption. For instance, in our simulation the laser output power needs to be increased by 20% to guarantee that 99% of the fabricated links satisfy the 10−12 BER requirement. IV. ADA P T IV E TUN ING A P PROACH Instead of the power-consuming, worst-cased based ﬁxed design, we propose an adaptive tuning approach that tunes 489           ^ƚĂƌƚ ^Ğƚ/ŶŝƚŝĂůd/Žƌ >ĂƐĞƌsŽůƚĂŐĞ ZƵŶZdĞƐƚ Zф dĂƌŐĞƚ͍ EŽ /ŶĐƌĞĂƐĞd/Žƌ >ĂƐĞƌsŽůƚĂŐĞ zĞƐ ŶĚ Fig. 7. The adaptive tuning ﬂow. Fig. 8. The two fast BER estimation methods: (a) offset the voltage; (b) offset the sampling time. The data in the left two ﬁgures are from [30]. Fig. 7 illustrates the ﬂow of the adaptive tuning approach. At the beginning, a speciﬁc writer-reader communication pair is activated. The TIA supply voltage or the laser driving voltage is set to a relatively low value based on the bestcase device parameters. Then an on-chip BER testing circuitry performs the BER test. The TIA or laser voltage is gradually increased until the BER is below a pre-set target (eg. 10−12 ). Finally, the just enough TIA or laser driving voltage is stored in the ﬂash memory as a lookup table (LUT). At runtime, the laser or the TIA voltage is conﬁgured based on the corresponding data stored in the LUT. This adaptive tuning ﬂow could be activated before shipment, after deployment, or whenever an abnormal error rate is observed by higher level blocks (e.g., by using parity check) during operation . It should be noted that when the electrical tuning is applied, the TIA or laser power should also be increased accordingly at runtime to compensate for the degradation of Q and ER. One of the key enabler in the adaptive tuning scheme is the fast on-chip BER testing circuitry. The brute-force BER testing method is unaffordably time-consuming (over 100 seconds for 10−12 BER at 10Gbps data rate) for the proposed adaptive tuning. Fortunately, there are fast BER estimation methods that leverage voltage offsetting or sampling time offsetting [28], [29]. As illustrated in Fig. 8, the BER decreases when the received power decreases or when the sampling time deviates from the ideal sampling point. Therefore, the voltage offsetting method or the sampling time offsetting method could be leveraged to accelerate the BER test. These two methods use an additional comparator that intentionally decreases the received power or deviates the sampling time. By comparing the additional comparator’s output with that of the normal data comparator, eye closure could be detected much faster. For instance, if our target BER is 10−12 , the BER after voltage or sampling time offsetting can be intentionally increased to about 10−10 . It takes only several seconds to estimate such an increased BER for a 10 Gbps link. There are two overheads associated with the adaptive tuning approach: the hardware overhead and the tuning time overhead. The hardware overhead, mainly in the BER monitor, includes an additional comparator with offset control and a small logic circuit, which takes about 30 µm x 30 µm area for 490 a 65 nm CMOS technology [28]. For a multi-receiver link, its hardware cost can be amortized by sharing the BER monitor, as the multiple receivers on one link cannot receive signal simultaneously. In this way, for a 64-cluster crossbar with 64 WDM channels, the total area cost of the BER monitors is only 1.0% of the chip area (366.1 mm2 in [27]). The tuning power overhead is avoided at runtime as the BER monitor circuit is switched off after the tuning process is complete. The tuning time overhead for a link is proportional to the number of communication pairs times the BER estimation time. For a WDM link, all wavelength channels could be tuned concurrently. For instance, assuming the BER estimation time is about 5 s, the tuning time for a many-writer singlereader (MWSR) link with 64 clusters (e.g., Corona [3]) is 320 s, which is reasonable for a one-time overhead. Overall, the hardware and time overheads are reasonable for practical applications. V. EVA LUAT ION S In this section, we perform simulations and analysis of several common photonic NoC architectures to evaluate the power saving gained by the proposed adaptive tuning approach. Several representative types of link structures are identiﬁed (as illustrated in Fig. 9) for experiments among the common photonic NoC architectures: • Single-writer single-reader (SWSR): The SWSR point-to-pint link is used in the three-stage Clos network [2]. The Clos network uses SWSR optical links for stage-to-stage communication and electrical routers for routing. • Many-writer single-reader (MWSR): The MWSR optical links can be used to construct optical crossbars for optical NoC. For instance, the Corona architecture replicates the MWSR channel 64 times to fully connect the 64 clusters [3]. For the adaptive tuning, each possible communication pair is individually tuned and the just enough TIA supply voltages are stored in a LUT. Single-writer many-reader (SWMR): Similar to the MWSR structure, the SWMR links can also be used • ^t^Z >ĂƐĞƌ Dt^Z >ĂƐĞƌ ^tDZ >ĂƐĞƌ t t t t t͙ Z ͙ Z ༃ Z Z Z ༄ DtDZ >ĂƐĞƌ     t t ͙ t t ༄ ༃ Z Z ͙ Z Z t >ĂƐĞƌ DĞƐŚ͗ >ŝŶŬZĞƉƌĞƐĞŶƚĂƚŝŽŶ ^ ͙ ^ Z Fig. 10. The simulated TIA power consumption for the ﬁxed design and the tunable design. DĞƐŚ͗ dŽƉŽůŽŐǇ ༄ ༃͗^ŚŽƌƚĞƐƚƉĂƚŚ ༄͗>ŽŶŐĞƐƚƉĂƚŚ Fig. 11. The average receiver power consumption at different process variations and for different link structures. ༃ Fig. 9. Four types of link structures. Notions: W: writer or photonic modulator; R: reader or photonic receiver; S: photonic switch or router. In a WDM system, the laser represents a multi-wavelength light source; each microring represents a microring array for multiple wavelength channels in crossbar structures. For instance, the Fireﬂy architecture uses a SWMR-based crossbar for inter-cluster communication and a concentrated mesh for intracluster [5]. Additionally, the SWMR structure is used in an optical bus-based NoC architecture to broadcast the optical signal [4]. • Many-writer many-reader (MWMR): LumiNOC leverages the MWMR structure for subnet design, where each cluster is connected with a writer and a reader such that any cluster can communicate with any other cluster [6]. Optical router based mesh: Microring-based optical routers are used in mesh-based NoC architectures in a manner of circuit switching. For instance, Petracca et al. proposed a non-blocking mesh NoC architecture using 4x4 optical routers [7]. • power-efﬁcient and the electrical tuning range (1 nm in Fig. 4) can cover the channel spacing (0.9 nm), we therefore adopt the electrical tuning with the channel remapping (or reshufﬂing) technique to compensate for the wavelength mismatch [8], [9]. Other than speciﬁed for parameter sweeps, the number of clusters is set to 16; the maximum temptation variation is set to 17◦C [13]; the laser type is on-chip DFB laser. The length of the longest communication path is set to 4 cm to accommodate the chip area (366.1 mm2 in [27]). The waveguide loss is assumed to be 0.74 dB/cm [32]. The ﬁxed design uses the same TIA supply voltage for all photonic receivers; the yield target is set to 99%. The adaptive tuning leverages the sensitivity-adaptive photonic receiver illustrated in Fig. 6 b, and conﬁgures each TIA’s supply voltage individually depending on the present communication pair. Each writer (or reader) in the many-writer (or reader) structure is assumed to have the same probability to write (or read). The average power consumption of a TIA for the ﬁxed design and the tunable design are reported in the simulations. Fig. 10 shows the Monte Carlo simulation result of a SWMR link, where the ﬁxed design has to set the TIA power as high as 1.32 mW while the adaptively tunable design achieves an average TIA power of 1.05 mW. A. Experimental Setup B. Process and Thermal Variations We perform Monte Carlo simulations to calculate the power consumptions by the ﬁxed design and by the adaptively tunable design. The process variation statistics of parameters A and Q in the ﬁrst line of Fig. 3 d are used to generate random instances of microring devices. The standard deviation of resonance wavelength caused by the process variation is 0.44 nm [13]. The channel spacing is set to 0.9 nm (160 GHz) to match the grid of the laser [31]. Since the electrical tuning is From Fig. 3 (c)(d), one can see that the process variation statistics are very distinct for different fabrication processes. In order to evaluate the performance of the adaptive tuning approach at different process variation levels, we sweep the standard deviation of the parameter A, which is an important factor to determine the link’s BER. Fig. 11 shows that the average receiver power by the adaptive tuning is decoupled from the process variation. 491 	    	 Fig. 12. The average receiver power consumption at different temperature variations and for different link structures. Fig. 14. The average receiver power consumption for different laser types and for different link structures. The numbers denote the ratios of the average receiver power by the tunable design to the ﬁxed design. [20]. In the simulations, we assume that the output power of the comb laser at its center wavelength (the maxima) equals the DFB laser output used in previous simulations plus the ﬁberto-chip coupling loss. The simulation results conﬁrm that the adaptive tuning leads to greater power savings for comb lasers based links (Fig. 14). In summary, the adaptive tuning approach scales well with the process variation, the thermal variation, and the number of clusters, especially for comb lasers based links and for link structures with non-uniform path lengths. V I . CONC LU S ION Microring resonator based nanophotonic interconnects are very sensitive to process and thermal variations. In this paper, we model the microring based photonic devices and their variation effects using the measured data. Taking into account the process and thermal variation effects, our simulations show that the BER of optical links has signiﬁcant variation. Since the worst-case based ﬁxed design consumes much excessive power, we propose a novel power-efﬁcient adaptive tuning approach. The proposed approach could tune each link individually and allocate just enough power to meet the BER requirement. This approach offers good power efﬁciency with reasonable area and time overhead. Our simulation and analysis demonstrate that the proposed adaptive tuning approach scales well with respect to different process variations, thermal variations, numbers of clusters, and laser types. Particularly, the adaptive tuning could save more power for link structures with non-uniform communication path lengths and/or using comb lasers. ACKNOW L EDGM EN T R. Wu, J. E. Bowers, and K.-T. Cheng acknowledge the Semiconductor Research Corporation (SRC) for the support. "
2016,Energy-efficient and reliable 3D network-on-chip (NoC) - architectures and optimization algorithms.,"The Network-on-Chip (NoC) paradigm has emerged as an enabler for integrating a large number of embedded cores in a single die. Three-dimensional (3D) integration, a breakthrough technology to achieve ""More Moore and More Than Moore,"" provides numerous benefits e.g., better performance, lower power consumption, and higher bandwidth, by utilizing vertical interconnects and 3D stacking. Energy-efficient and high-bandwidth vertical interconnects enable the design of an energy efficient 3D NoC for massive manycore platforms. Existing 3D NoCs are deficient for meeting ever-increasing performance requirements of manycore processors since they are simple extension of regular 2D architectures and they do not fully exploit the advantages provided by 3D integration. Moreover, the anticipated performance gain of a 3D NoC-enabled manycore chip will be compromised due to the potential failures of through-siliconvias (TSVs) that are predominantly used as vertical interconnects in a 3D IC. In this paper, we present the various challenges and possible solutions for designing energy-efficient and reliable manycore chips enabled by the 3D integration.","Energy-Efficient and Reliable 3D Network-onChip (NoC): Architectures and Optimization  Algorithms   (Invited Paper)  Sourav Das, Janardhan Rao Doppa, Partha Pratim Pande  School of EECS, Washington State University  Pullman, WA, USA  Email: {sdas, jana, pande}@eecs.wsu.edu  Krishnendu Chakrabarty  Department of ECE, Duke University   Durham, NC, USA  Email: krish@ee.duke.edu  Abstract— The Network-on-Chip (NoC) paradigm has  emerged as an enabler for integrating a large number of  embedded cores in a single die. Three-dimensional (3D)  integration, a breakthrough technology to achieve “More  Moore and More Than Moore,” provides numerous benefits  e.g., better performance, lower power consumption, and higher  bandwidth, by utilizing vertical interconnects and 3D stacking.  Energy-efficient and high-bandwidth vertical interconnects  enable the design of an energy efficient 3D NoC for massive  manycore platforms. Existing 3D NoCs are deficient for  meeting  ever-increasing performance  requirements of  manycore processors since they are simple extension of regular  2D architectures and they do not fully exploit the advantages  provided by 3D  integration. Moreover, the anticipated  performance gain of a 3D NoC-enabled manycore chip will be  compromised due to the potential failures of through-siliconvias  (TSVs)  that are predominantly used as vertical  interconnects in a 3D IC. In this paper, we present the various  challenges and possible solutions for designing energy-efficient  and reliable manycore chips enabled by the 3D integration.   Keywords— NoC, 3D Integration, Machine Learning,  Energy Efficiency, VFI, Adaptive Routing, Reliability.  I. INTRODUCTION   3D integration provides higher device density, wider interdie bandwidth, and heterogeneous integration. Higher device  density continues “More Moore” and enables more  functionality and/or smaller form factor. The heterogeneous  integration of multiple planar dies fabricated with different  technologies enables the design of a complete System-onChip (SoC) composed of digital logic, DRAM, analog, and  RF circuits [1][2][3].  On the other hand, NoC is an enabling solution for  integrating large numbers of embedded cores in a single die.  Permission to make digital or hard copies of all or part of this work for personal or  classroom use is granted without fee provided that copies are not made or distributed  for profit or commercial advantage and that copies bear this notice and the full citation  on the first page. Copyrights for components of this work owned by others than ACM  must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,  to post on servers or to redistribute to lists, requires prior specific permission and/or a  fee. Request permissions from Permissions@acm.org.  ICCAD '16, November 07-10, 2016, Austin, TX, USA.  © 2016 ACM. ISBN 978-1-4503-4466-1/16/11…$15.00   DOI: http://dx.doi.org/10.1145/2966986.2980096   3D NoC architectures combine the benefits of these two  paradigms to offer an unprecedented performance gain even  beyond  the Moore’s  law regime. Existing 3D NoC  architectures predominantly follow simple extension of  regular 2D NoCs [3][4][5]. However, this does not fully  exploit the advantages provided by 3D integration. In this  context, design of small-world network-based NoC  architecture [6][7][8] is a notable example. It has been shown  that either by inserting long-range shortcuts in a regular mesh  to induce small-world effects or by adopting power-law  based small-world connectivity, it is possible to achieve  significant performance gain and lower energy dissipation  compared to traditional multi-hop mesh networks [8]. In this  paper, we advocate that this concept of small-worldness  should be adopted in 3D NoCs. More specifically, the vertical  links in 3D NoCs should enable the design of long-range  shortcuts necessary for small-world networks. By exploiting  the vertical connections in a 3D IC, the multi-hop long-range  planar links can be placed along the shorter Z-dimension, and  hence, overall system performance can be significantly  improved. The key challenge is to place the long-range  shortcuts optimally to achieve the desired goal. In addition,  another challenge is that, the anticipated performance gains  of 3D NoC-enabled manycore chips may be compromised  due to potential failures of the through-silicon-vias (TSVs)  that are used as vertical interconnects. TSVs in a 3D IC can  fail due to voids, cracks, and different kinds of fabrication  challenges [1][9]. Additionally, the workload induced stress  increases the resistance of the TSVs, which leads to different  mean-time-to-failure (MTTF) for different TSVs [9] [10]. To  address these problems, we advocate a machine-learninginspired predictive design methodology for energy-efficient  and reliable manycore architectures enabled by 3D  integration. This paper presents advantages and challenges  involved in adopting machine learning as an enabling  technique to design high performance and robust 3D NoCs.  II. 3D NOC ARCHITECTURE-SPACE EXPLORATION  We can adopt novel architectures inspired by complex  network theory in conjunction with the 3D integration to  design high-performance manycore chips. Between a regular,  locally interconnected mesh network and a completely  random Erdös-Rényi topology, there are other classes of        Fig. 1:  Conceptual view of small-world (SW) connection based 3D  SWNoC. The horizontal plane (each die) has SW connectivity and  the regular TSVs enable long-range short-cuts.  graphs, such as small-world and scale-free graphs [6][7].  Small-world graphs have a very short average path length,  defined as the number of hops between any pair of nodes. The  average shortest path length of small-world graphs is  bounded by a polynomial in log (N), where N is the number  of nodes, making them particularly attractive for efficient  communication with minimal resources [7][8]. NoCs  incorporating  small-world connectivity can perform  significantly better than locally interconnected mesh-like  networks [8], yet they require far fewer resources than a fully  connected system. Our goal is to use the “small-world” (SW)  approach to build a highly efficient 3D NoC. In this 3D  SWNoC (shown in Fig. 1), each core is connected to a router  and the routers are interconnected using both planar and  vertical links. The topology of this 3D NoC is a small-world  network, where the links between routers are established  following a power-law model [7] [11].  When we design the small-world (SW) connectivity for a  2D die, there are some physically long wires. Adding a third  dimension allows us to place the cores and associated routers  in the 3D space in such a way that the physically long links  are placed in the vertical dimension. While creating the SW  network, we should map the tasks among the cores in such a  way that physically long distant and highly communicating  cores are placed along the vertical dimension (TSV-based  vertical links act as long range short-cuts for enabling the  small-world connectivity), as shown in Fig. 1. There are two  advantages of placing the physically long links in the vertical  dimension. First, the energy consumption arising out of the  interconnect reduces due to the reduction of length and  number of repeaters needed in a planar long wire. Secondly,  the network latency reduces, and it in turn minimizes the  probability of traffic congestion, which eventually reduces  the NoC router power consumption significantly.  A. Network Optimization  Starting from the above-mentioned power-law based  connectivity [7][11], we should optimize the location of the  horizontal and vertical links, and the core position to achieve  lower latency and energy consumption. To perform this  optimization, we define an objective function, O, as the  summation of the product of hop counts, physical distance,  and frequency of traffic interaction among the cores. We term  O as the ‘communication cost’ and try to achieve its  minimum value for a given set of cores, routers and  Fig. 2: Overview of STAGE based optimization. On each  iteration, STAGE performs base search on objective function , O,  and meta search to improve internal evaluation function, E.  applications following the physical design constraints [12].  To achieve this, one could employ search algorithms  including hill-climbing and simulated annealing [13] that are  very popular in the design community for this task. However,  we propose to leverage machine-learning techniques that are  shown to outperform these local search algorithms to  intelligently explore the design space [14].   Design Optimization using Machine-learning: We employ  an online learning algorithm called STAGE [14] that was  originally developed to improve the performance of local  search algorithms (e.g., hill climbing) with random-restarts  for combinatorial optimization problems. The key insight  behind STAGE is to leverage some extra features of the  optimization problem to learn an improved evaluation  function E that can estimate the promise of a design d as a  starting point for the local search procedure π. It employs E  to intelligently select promising starting states that will guide  π towards significantly better solutions.   Overview of STAGE: The STAGE algorithm repeatedly  alternates between two types of search as shown in Fig. 2: 1)  Base search, where π is run with the original objective O until  it reaches a local optima and new training data is generated to  improve E; and 2) Meta search, where it performs search with  the learned evaluation function E to select good starting states  to improve the performance of the local search procedure π.  We want to learn E such that the estimated value of design d  is equal to the expected best objective (O) value seen on a  search trajectory that starts from design d and follows the  local search method π guided by O. In the initial exploration  phase, E may not lead to good solutions but as the iterations  progress, E will improve with the training data generated  from the search experience in base search mode. The  effectiveness of the learned E depends on a small subset of  critical training examples that successfully teach how to  avoid different local optima during the meta-search phase.  The STAGE algorithm tries to quickly identify this critical  set in an adaptive manner.   The main challenges in applying STAGE to 3D NoC  design optimization problem are as follows: 1) We need to  define additional features of the optimization problem that  can be exploited to learn improved evaluation functions for  efficient design space exploration; 2) Defining appropriate  search spaces by leveraging the domain knowledge can  potentially  improve  the effectiveness of  the STAGE      algorithm. We need to identify good starting state distribution  (subset of initial 3D NoC design solutions) and search  operators (actions to get successor states from a given state)  to navigate the design space. We have explored γ-greedy for  starting state distribution for improving over random starting  state distribution; and 3) We need to find a good knowledge  representation for the evaluation function E that is expressive,  can be trained quickly, and allows to make fast predictions.  We picked regression trees as it satisfies all the requirements.  To implement this, the WEKA machine-learning toolkit [15]  was employed to train regression trees over training set and  the hyper-parameters were tuned using small validation data.  Advantages of STAGE: Past work in the search community  concluded that many practical optimization problems exhibit  a “globally convex” or “big valley” structure, where the set  of local optima appear convex with one global optimum in  the center [14]. The main advantage of STAGE over popular  algorithms including simulated annealing (SA) [13] and  genetic algorithm (GA) [16] is that it tries to learn the solution  space structure, and uses this information cleverly to improve  both convergence time and the quality of the solution for a  given time. This aspect of STAGE is very advantageous for  large system sizes to improve the design-test cycle before  mass manufacturing and for dynamically adapting the  designs for new application workload.  B. Performance of STAGE-based NoC Optimization  To evaluate the performance of STAGE based NoC  optimization algorithm, we compare it with the well-known  combinatorial optimization algorithms, viz., simulated  annealing (SA) [13] and genetic algorithm (GA) [16]. We  consider a 64 core system comprised of 64 routers (each  router is connected to nearby core as seen from Fig.1), and  arranged in 4 planar dies. Four SPLASH-2 benchmarks [17],  FFT, RADIX, LU, and WATER, and five PARSEC  benchmarks  [18], DEDUP, VIPS, FLUIDANIMATE  (FLUID), CANNEAL, and BODYTRACK (BT) were used  for characterizing  the NoC. Fig. 3 shows  the best  communication cost of the optimized network explored by  the STAGE, SA, and GA algorithms as a function of time.  For comparison purpose, we consider two parameters, viz.,  the quality of the solution and the convergence time. To make  the comparison fair, we consider the same NoC configuration  and set of applications, and apply STAGE, SA , and GA  algorithms to optimize it. We used a machine configured with  Intel Core i7-4700MQ processor and 8 GB RAM running at  a clock frequency of 2.4 GHz.  Fig. 3 shows the cost of the best solution obtained at any  particular time for SA, GA, and STAGE. We consider the  best explored cost, Obest, as the quality of the optimization  algorithm. It is evident that STAGE reaches Obest very fast  (within 5 minutes). During the optimization process, the  learned function E predicts an initial network configuration  79 77 75 STAGE GA SA t s e b O , t s o c 73 t s e B 71 69 0 10 20 30 Time in minutes 40 50 Fig. 3: Performance comparison among the machine-learningbased optimization algorithm (STAGE), the Simulated Annealing  (SA), and the Genetic algorithm (GA)  to start the local search procedure that can lead to lower  communication cost (O). Note that the best O-value decreases  monotonically as the set of explored designs increases over  the iterations. We also performed the same experiment with  the γ-Greedy starting state distribution as mentioned above.  However, the communication cost O and the prediction error  have similar characteristics as the random distribution for the  benchmarks and system sizes considered in this work.  Therefore, we present and discuss our results with a random  starting-state distribution.   It is also seen that, both the SA and GA show similar trends  in the cost function optimization. Both of them reach Obest  more gradually compared to STAGE, and even after 50  minutes their respective Obest does not reach the same solution  as STAGE. It should be noted that we have to optimize the  link locations for various applications. Hence, this additional  time needed by SA and GA will be a significant overhead  when we have to optimize and reconfigure the SWNoC in the  field. We can conclude that STAGE algorithm is more  efficient in designing an optimized SWNoC with better  performance.  C. Performance Evaluation of 3D SWNoC  To characterize the potential benefits of the optimized 3D  SWNoC, we compare its performance with respect to 3D  mesh, and two recently proposed irregular 3D NoC  architectures, viz., mrrm and rrrr [19]. Both the mrrm and  rrrr NoCs have point-to-point vertical connections as in 3D  mesh and 3D SWNoC. However, their die-level planar  connection pattern varies. For rrrr, all the planar dies have  randomly connected interconnection patterns. On the other  hand, mrrm has random connection patterns in the middle  two dies whereas the first and the fourth dies follow meshbased regular connectivity. For fair comparison, the total  number of links are kept equal to that of 3D mesh and 3D  SWNoC. In addition, all the NoC architectures are also  designed with TSV based vertical links. We considered the  3D mesh mrrm rrrr 3D SWNoC P D E d e z i l a m r o N h s e m D 3 t . r . w 1 0.9 0.8 0.7 0.6 FFT RADIX LU CANNEAL BT DEDUP WATER FLUID VIPS Fig. 4: Energy-delay-product (EDP) values for different irregular 3D NoCs. All the values are normalized with respect to 3D mesh                  energy-delay-product (EDP) as the relevant metric. All the  EDP values are normalized with respect to the 3D mesh.  For 3D SWNoC, initially we developed a power-law based  random connectivity only in the planar dies. Next we applied  STAGE algorithm to place the long-range links in such a way  that the regular vertical links act as short-cuts for small-world  connectivity. In addition, the planar link locations were also  optimized to minimize the communication cost. Fig. 4 shows  the energy-delay-product (EDP) for these architectures  consisting of 64 cores normalized with respect to the EDP of  the 3D mesh incorporating a few popular SPLASH-2 and  PARSEC benchmarks as mentioned above. As the figure  shows, all the irregular architectures perform better than the  3D mesh. The 3D SWNoC architecture outperforms the  mrrm and rrrr architectures. The mrrm and rrrr architectures  have random distribution of interconnects instead of the  power-law-based distribution. For rrrr, the link distribution  contains a large number of medium- and long-range links  with the expense of short-range links. As a result, the nearby  communication suffers from long latency and power  dissipation. In mrrm, only two layers have a link distribution  very close to 3D SWNoC and the other two layers use a  regular multi-hop mesh structure. The power-law-based 3D  SWNoC architecture balances both nearby and long distant  communication and hence, its performance is superior to  both- rrrr and mrrm. In addition, long-range links are  generally traffic attractors, so they lead to higher traffic  congestion for some nodes if they are not optimized properly.  For the proposed 3D SWNoC, the long range link locations,  and the overall interconnection pattern is optimized in such a  way that the network achieves the lowest communication cost  and hence, ensures  lower network  latency, energy  consumption, and EDP profiles compared to other NoCs.  III. RELIABITLY ANALYSIS OF 3D SWNOC   One of the major contributors to the drastic performance  improvement for manycore 3D systems is the presence of  vertical links (VLs) that help in stacking multiple dies to  facilitate low latency communication among the cores.  Failure of a single VL affects the neighboring VLs by  increasing their traffic densities, causing a cascade of failures  and hence, reduces the lifetime of the chip.   A. TSV Reliability  In  the current state-of-the-art  technology, VLs are  predominantly designed with TSVs [1][10]. In the presence  of high current-induced stress, the resistance of the TSVs can  increase thereby causing significant delay, and it may  eventually compromise the timing specification of the design  [9][10]. From the 3D NoC perspective, depending on the  overall  interconnection  architecture  and  application  (a)  60 45 30 15 0 n o i t a z i l i t u f o % characteristics, the traffic densities of the VLs vary.  As a  result, the workload-induced stress for the TSVs exhibit a  non-homogeneous  distribution. From  the  physical  perspective, higher workload makes the electro-migration  effects more pronounced at the landing pad of the TSVs. With  the increase in utilization of TSVs, the resistance and delay  of the TSVs also increase and at a certain point, the delay  increases beyond the acceptable limit. This scenario can be  considered as the failure of TSV and the corresponding time  is termed as the mean-time-to-failure (MTTF). In general,  10% increase in resistance can be considered as failure of a  TSV [10][20]. The resistance of TSVs is modeled as shown  in (1) and (2) below [10]-  𝑡           𝑅(𝑡) − 𝑅0 = 𝐴 ln ( 𝑡0 )                                               (1)  2 𝑡𝑐𝑢𝜋𝑟𝑇𝑆𝑉 𝜌𝐵 4𝜋𝑡𝐵 𝛼𝐹 where, 𝐴 =                                   (2)    and 𝑡0 =  The parameter A is called the aging coefficient and t0 is the  time when a void (created at the TSV-pad junction) becomes  greater than the TSV cross section. The parameters R(t) and  R0 refer to the  resistance values at times t=t and t=0,  respectively. The other parameters- 𝜌𝐵 , 𝑡𝑐𝑢 , 𝑡𝐵 , and 𝑟𝑇𝑆𝑉  denote the TSV barrier resistivity, copper thickness, barrier  thickness, and radius of the TSV respectively. The parameter  αF denotes the portion of the vacancy flow, which leads to  electro-migration and generates the void under the TSV.  While the aging coefficient is independent of the stress  condition, the parameter t0 depends on the stress condition.  More specifically, the vacancy flow parameter αF depends  on the amount of current flowing through TSVs and can be  expressed as- αF ∞ i-n, where i is the amount of current  through TSV cross-sectional area and the exponent n has  value 2.0±0.2 from the experimental results verified by  Black’s equation [10][20][21]. Note that the time, t, in the  above equation denotes the active utilization of the TSVs.  Hence, reduction of utilization of a TSV results in a slower  increase of its resistance, thereby leading to higher MTTF.   B. Reliability Improvement Methodologies  From the above observations, we can infer that to  maximize the lifetime of TSV-enabled VLs, we can follow  two approaches. First, to reduce stress, the active utilization  can be reduced. Second, the operating voltage level and  hence, the energy consumption, can be minimized to reduce  the amount of current (i) passing though the TSVs. Hence,  the MTTF is expected to increase. Note that the MTTF values  also depend on the operating temperature of the chip.  However,  if the total power dissipation in the VLs can be  minimized, then the overall temperature also decreases and  thereby improving the reliability of the TSVs.  (b)  15 F T T M 10 d e z i l a m r o N 5 0 1 5 9 13 17 21 25 29 33 37 41 45 1 5 9 13 17 21 25 29 33 37 41 45 VL number VL number Fig. 5: Effect of non-homogeneous TSV-based VL utilization for 3D SWNoC with CANNEAL benchmark. (a) VL utilization (in percentage of cycles that  VL actively transmit signals to total simulated cycles), and (b) normalized MTTF values for individual VLs (normalized w.r.t. the lowest MTTF value)            1) Adaptive Routing for TSV MTTF Improvement  The main reliability concerns for a 3D NoC comes from  the fact that some of the VLs have lower MTTF values  compared to others. Hence, to improve the reliability of the  NoC, the traffic carried by the TSVs with very low MTTF  value needs to be decreased [22]. However, as the total  amount of traffic for a particular application cannot be  reduced, hence, reducing the amount of traffic for a particular  VL will increase the workload for others. As a result, the  MTTF of those other VLs may decrease. For the 3D NoC  architectures with multiple planar layers, the traffic density in  the middle layers is generally higher than in the top and  bottom ones. Hence, the VLs between these layers experience  much higher traffic density. As a result, the MTTF of these  VLs are significantly lower, and ultimately, they influence  the lifetime of the whole system.   As an example, in Fig 5, we show the traffic densities and  the MTTFs of all the VLs in the 3D SWNoC for the  CANNEAL benchmark (One of the highest traffic injected  and skewed benchmark suites from PARSEC). It is evident  that the traffic densities of VLs 17 to 32 are much higher than  for the others, and as expected, their MTTFs are significantly  lower. These VLs are located between the second and third  dies in a four-die 3D SWNoC. Hence, the region consisting  of TSVs ranging from 17 to 32 is the critical region that  affects the overall reliability of the system. In addition, VLs  numbered 22, 26, and 27 have much higher utilization than  the other VLs in the critical region. The net result is that the  MTTFs of the VLs in the critical region and especially, for  VLs 22, 26, and 27, are an order of magnitude less than that  of the other TSVs. Our target is to redistribute the traffic load  in such a way that the lower MTTF values in the critical  region will increase. We may have to sacrifice the VLs with  higher MTTFs to some extent. However, the increase in  MTTF for the critical VLs is more significant than the  reduction in MTTF of other VLs. Hence, the average MTTF  of the whole system will still improve. Redistribution of the  traffic can be incorporated in the routing algorithm.  2) Power Management for TSV MTTF Improvement   Another possible solution to enhance the MTTF values of  the TSV-based VLs is to incorporate a suitable power  management strategy, which in turn improves the overall  reliability of the 3D NoC. To improve the energy-efficiency  of manycore systems, voltage-frequency island (VFI)-based  power management techniques have shown promise in the  past [23]. The key idea behind VFI-based power management  is to cluster the cores and network elements with similar  functional and structural behavior; and to tune the voltagefrequency (V/F) level using a VFI controller depending on  the communication and computational requirements of each  cluster. The VFI-based power management is effective for  reducing the energy dissipation of manycore systems within  given performance constraints. By incorporating VFI-based  power management in a 3D NoC, it is possible to enhance the  lifetime of the VLs and hence, that of the whole system.  Machine learning (ML) techniques have been used for  system-level dynamic power management [24][25]. These  works mainly studied per-core DVFS, but they can be  adapted to dynamic VFI as well. The main drawbacks of  existing ML-based power management methodologies are as  3D SWNoC Adaptive VFI 2 1.5 1 0.5 0 e m i t e f i L d e z i l a m r o N Fig. 6: Lifetime of 3D SWNoC with different reliability  improvement techniques viz. adaptive routing and VFI-based  power management technique. The value is normalized w.r.t. 3D  SWNoC without any other reliability improvement techniques.  follows: 1) They learn independent control policies while  ignoring the structural dependencies between different  controllers; 2) The effectiveness of reinforcement learning  (RL) approaches depend on the reward function, which can  be hard to design to meet practical performance requirements.  Online RL methods learn very slowly and are accompanied  with weak guarantees of learning near-optimal control  policies for large state spaces. If we have a viable oracle  policy, imitation learning is known to be a significantly better  framework compared to RL [25]; 3) The hardware overhead  of RL-based policies is also high as they employ look-up  tables.  In  this context, we can  leverage  the structural  dependencies of a VFI-enabled 3D NoC to design an  efficient VFI controller via Imitation Learning (IL) that  improves the energy efficiency and hence, the lifetime of  VLs of the 3D NoC, as well as the lifetime of the overall  system. Inspired by the recent success of imitation learning  approaches for solving sequential decision-making tasks  [25] [26], we formulate and solve the problem of learning  VFI controller in the framework of imitation learning.  In  traditional imitation learning, expert demonstrations are  provided as training data, and the goal of the learner is to  learn to imitate the behavior of an expert performing a task  in a way that generalizes similar tasks or situations. In the  case of our VFI controller learning problem, the expert  corresponds to an oracle controller that provides the  supervision on how to make good control decisions for V/F  tuning. The oracle controller utilizes information about the  state of the system to minimize the overall EDP (Energy  Delay Product) for a given VFI-enabled 3D NoC.    C. Adaptive routing vs. Power Management  Fig. 6 shows the improvement in lifetime by adopting  adaptive routing and VFI-based power management in 3D  SWNoC. It is seen that both the Adaptive and VFI increase  the lifetime of 3D SWNoC. On average, Adaptive and VFI  improve the lifetime of 3D SWNoC by 27% and 55%  respectively. Similarly, the maximum improvements we  obtained are 87% and 47% respectively for the LU  benchmark. Reducing the power dissipation of overall  system and for TSV-enabled VLs improved the MTTF  values of individual TSVs (as well as the VLs) more than the  case when MTTF values are improved via reducing the  effective TSV utilization. As a result, VFI always shows      Fig. 7: Overall performance-reliability trade-offs establishment  algorithm for this study  better lifetime profile than the Adaptive case. Hence, we  conclude that efficient voltage-frequency scaling via VFIbased power management methodology can significantly  improve the performance of 3D SWNoC both in terms of  energy efficiency and overall system lifetime.  Figure 7 shows the various components (including VFIbased power management and adaptive routing) that can be  used in evaluating the reliability/performance trade-offs of  3D NoCs. We have considered 3D SWNoC as the testbed  for establishing  the reliability-performance  trade-offs.  However, the proposed methodologies (adaptive routing and  power management) are equally applicable to any other 3D  NoC architecture.   IV. CONCLUSION  In this paper, we highlight that 3D integration enables the  design of small-world network-based energy-efficient and  high-performance manycore chips. Machine Learning plays  an important role in designing an efficient 3D NoC  architecture. However, reliability issues associated with  workload-induced stress and possible TSV  failures  compromise the performance gain that can be achieved with  the TSV-enabled 3D NoCs. The judicious incorporation of  VFI-based power management and adaptive routing  techniques can simultaneously improve both the energy  efficiency and reliability of such TSV-based 3D NoCs. Once  again, machine learning plays an important role in designing  the power management policy. We envision that our work  will open up a new direction in using machine learning for  design optimization and power management of manycore  chips in the near future.  ACKNOWLEDGEMENT  This work was supported in part by the US National Science  Foundation (NSF) grants CNS 1564014, CCF-0845504,  CNS-1059289, and CCF-1162202, and Army Research  Office grant W911NF-12-1-0373.   "
2016,Design technology for fault-free and maximally-parallel wavelength-routed optical networks-on-chip.,"The recent interest in emerging interconnect technologies is bringing the issue of a proper EDA support for them to the forefront, so to tackle the design complexity. A relevant case study is provided by wavelength-routed optical NoCs (WRONoCs), which add communication performance guarantees to the typical latency, throughput and power benefits of an optical link, thus providing an appealing technology for the photonic integration of high-end embedded systems. Typically, only abstract WRONoC models are considered to figure out architecture-level performance, and logic connectivity patterns for the quantification of the required signal strength (i.e., static power). However, this design practice overlooks the needed refinement step, where key physical parameters are assigned such as wavelengths of the optical channels, and size of the optical filters. This step is unfortunately not decoupled from the architectural evaluation, since its main constraint (i.e., avoiding routing faults) turns out to be a key limiter for both the network scale and the achievable communication parallelism. By proposing a formal methodology to select WRONoC parameters while avoding the routing fault concern, this paper aims at maximizing the levels of connectivity and/or of bit parallelism that WRONoCs can achieve, while relating their upper bounds to the uncertainty of the manufacturing process.","Design Technology for Fault-Free and Maximally-Parallel Wavelength-Routed Optical Networks-on-Chip Andrea Peano Luca Ramini Marco Gavanelli University of Ferrara - Via Saragat 1, 44121 Ferrara, Italy University of Ferrara - Via Saragat 1, 44121 Ferrara, Italy andrea.peano@unife.it luca.ramini@unife.it University of Ferrara - Via Saragat 1, 44121 Ferrara, Italy marco.gavanelli@unife.it Maddalena Nonato Davide Ber tozzi University of Ferrara - Via Saragat 1, 44121 Ferrara, Italy University of Ferrara - Via Saragat 1, 44121 Ferrara, Italy maddalena.nonato@unife.it davide.ber tozzi@unife.it ABSTRACT 1. INTRODUCTION The recent interest in emerging interconnect technologies is bringing the issue of a proper EDA support for them to the forefront, so to tackle the design complexity. A relevant case study is provided by wavelength-routed optical NoCs (WRONoCs), which add communication performance guarantees to the typical latency, throughput and power beneﬁts of an optical link, thus providing an appealing technology for the photonic integration of high-end embedded systems. Typically, only abstract WRONoC models are considered to ﬁgure out architecture-level performance, and logic connectivity patterns for the quantiﬁcation of the required signal strength (i.e., static power). However, this design practice overlooks the needed reﬁnement step, where key physical parameters are assigned such as wavelengths of the optical channels, and size of the optical ﬁlters. This step is unfortunately not decoupled from the architectural evaluation, since its main constraint (i.e., avoiding routing faults) turns out to be a key limiter for both the network scale and the achievable communication parallelism. By proposing a formal methodology to select WRONoC parameters while avoding the routing fault concern, this paper aims at maximizing the levels of connectivity and/or of bit parallelism that WRONoCs can achieve, while relating their upper bounds to the uncertainty of the manufacturing process. Categories and Subject Descriptors B.8.2 [PERFORMANCE AND RELIABILITY ]: Performance Analysis and Design Aids; G.1.6 [NUMERICAL ANALYSIS]: Optimization—Constrained optimization Keywords WRONoC, Parallelism, Answer Set Programming Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and /or a fee. Request permissions from permissions@acm.org. ICCAD ’16, November 07-10, 2016, Austin, TX, USA c(cid:13) 2016 ACM. ISBN 978-1-4503-4466-1/16/11. . . $15.00 DOI: http://dx.doi.org/10.1145/2966986.2967023 Networks-on-chip (NoCs) are today the mainstream communication architecture for all large-scale systems-on-chip (SoCs) in 45nm and below [5]. However, the uptake of the networking paradigm for on-chip communication started only when proper EDA support enabled to tackle the complexity challenge. This resulted in tools and methodologies that enabled design, veriﬁcation and test of NoCs across multiple levels of abstraction and complexity [1]. After a decade of research, NoC toolﬂows became capable of automatically transforming a high-level functional description of a NoC into a detailed geometric description [18]. Today, methodologies and tools for designing chip-level communication architectures are again on the rise. The reason is that industry is urgently exploring beyond-silicon and beyond-CMOS device, interconnect and memory options, as well as heterogeneous, ”More-than-Moore” integration and packaging technologies, in order to maintain Moore’s-Law scaling of integration value. In particular, silicon photonics stands out as the most promising technology to overcome the limitations of electronic interconnects as the system scale increases. The intrinsic capability of light to transport information over large distances at very high data rates and low latency, with minor dynamic power dissipation, holds promise for scalable and power-eﬃcient optical networkson-chip (ONoCs) to interconnect future many-core system architectures. A relentless research eﬀort is currently underway to improve the maturity of CMOS-compatible silicon photonic technology, especially to cut down on its signiﬁcant static power overhead. However, awareness of the historical trend followed by electronic NoCs leads to think that the industrial uptake of ONoCs will be not only an issue of technology maturity. In fact, this will also coincide with a turning point for the Electronic Design Automation (EDA) ﬁeld, since designing with emerging interconnect technologies calls for (radically?) diﬀerent abstractions, algorithms, methodologies, and tools drawing from the interdisciplinary work of chemists, device physicists, electrical engineers, computer scientists, applied mathematicians, operations researchers, and optimization experts [8]. A number of ONoC design issues is currently increasing the need for EDA support. On the one hand, the development of automatic synthesis approaches of optical circuits is still in the early stage, since they need to build on top of the speciﬁc basic primitives of the target emerging technology [4]. On the other hand, EDA support is required by the reﬁnement step of abstract ONoC models into their actual implementations, which calls for eﬀective solving strategies for the novel optimization problems that arise [21]. This paper tackles one such novel design challenges that are emerging in the context of the latter category, and which has to do with the reﬁnement step of wavelength-routed optical NoCs (WRONoCs). Among the plethora of proposed protocols for optical on-chip communication, wavelength routing has unique characteristics, since it can deliver contention-free all-to-all connectivity. The key principle consists of allocating a reserved wavelength channel to each initiator-target pair, which selects a deterministic routing path across the network. Since optical technology supports the concurrent propagation of multiple optical channels, tuned to diﬀerent wavelengths, on the same waveguide (named wavelength division multiplexing, WDM), wavelength routing does not require any form of arbitration nor path selection. The predictable and guaranteed communication performance of WRONoCs comes at the cost of static power overhead, due to the use of multiple laser sources. WRONoCs currently deal with an unsolved design concern: the selection of their wavelength channels and of the optical ﬁlters that build up their optical paths. This is typically and incorrectly viewed as a further reﬁnement step during the implementation ﬂow, since the existence of the above parameters is just taken for granted during the architectural evaluation, which simply assumes the contention-free delivery of optical packets to their destination. Topologies are then diﬀerentiated based on their loss of optical power. Unfortunately, the reﬁnement step which selects the actual network parameters cannot be decoupled from WRONoC performance evaluation for two reasons. On the one hand, parameters of wavelength channels and of the ﬁlters that selectively route them to destination should be chosen in such a way that routing faults are avoided. This constraint limits the level of connectivity that can be achieved, which means that large-scale topologies may turn out not to be feasible under the routing fault-free condition. On the other hand, even when the connectivity of the target number of nodes is feasible, the routing fault concern limits the achievable level of communication paral lelism. Overal l, without proper emphasis on the topology reﬁnement step, system designers may consider WRONoC conﬁgurations for their architecture that later turn out to be practical ly infeasible, in terms of levels of connectivity and/or paral lelism. Last but not least, WRONoC topology reﬁnement is the ﬁrst design step where the parameters of the manufacturing process at hand become visible. In fact, a high level of uncertainty in that process forces the designer to conservative design choices to meet the routing fault freedom constraint, which penalizesa the quality metrics to a signiﬁcant extent. To our knowledge, this paper for the ﬁrst time proposes a formal methodology to select WRONoC physical parameters while maximizing communication parallelism for a speciﬁc level of network connectivity. The paper aims at capturing the dependencies between the characteristics of the manufacturing process and the achievelable WRONoC performance, hence resulting in design curves that bridge the gap between the system level designer and the technology provider. 2. RELATED WORK Among communication protocols, wavelength routing eliminates the need for electrical resource reservation, and the corresponding latency and area overhead. A number of wavelength-routed topologies has been proposed so far. While they all deliver the same performance (contentionfree all-to-all connectivity), they have diﬀerent connectivity patterns, which leads to diﬀerent physical properties, such as kinds of micro-ring resonators, and optical power losses. The λ−router [3] resembles multi-stage interconnection networks due to the cascaded stage organization. The GWOR topology [20] is built around a basic and symmetric 4x4 routing fabric, with precise generalization rules. The snake topology [16] exhibits a circuitous pattern inspired by pipes. The topology presented in [2] consists of a wavelength-routed optical ring. Finally, a hierarchical topology featuring regularity, vertex symmetry, and constant node degree is presented in [9]. Wavelength routing has been compared with other methods in terms of performance and power. For 16-node systems, the static power overhead associated with the use of multiple laser sources is still lower than or comparable with the overhead for implementing optical arbitration [17]. For larger system sizes, the static power overhead is the price to pay for performance predictability. To our knowledge, the reﬁnement step that selects the physical parameters of the above topologies has never been addressed before. Such parameters are typically kept as generic in high-level evaluations (e.g., wavelength channels λi , optical ﬁlters tuned to λi ), thus taking for granted that wavelengths in the band 1500-1600nm and the associated micro-ring resonators in the typical range 5 ÷ 20µm exist, and combined together yield topologies that do not incur the routing fault concern presented later. As we prove in this paper, this assumption is not always justiﬁed, thus motivating this work, that lowers the abstraction layer for WRONoC design. Wavelength routing design has been brought to this stage only in the context of generic ﬁber-based optical networks connecting large regions, where the routing and the wavelength assigment problem has been stated, but in completely diﬀerent terms due to the diﬀerent target environment [13]. For instance, in that domain wavelength conversion is an aﬀordable option, unlike an on-chip environment. 3. BACKGROUND AND MOTIVATION 3.1 Wavelength-Selective Routing Wavelength-routed optical NoCs (WRONoCs) rely on the principle of wavelength-selective routing, which associates a wavelength channel to each source-destination pair. In particular, master M 1 uses n wavelengths λ1 to λn to reach slaves S 1 to Sn, respectively. However, instead of allocating an additional set of wavelengths for the communications of master M 2 to all the slaves, the initial set of n wavelengths is reused across masters. This wavelength reuse requirement gives rise to two design constraints for WRONoC topologies, which are engineered to make such reuse feasible: • Optical channels originating from diﬀerent masters and tuned to the same carrier wavelength should never overlap in WRONoC waveguides. • Each slave should receive wavelength channels from diﬀerent masters on diﬀerent carrier wavelengths, in order to avoid any signal conﬂict at the receiver side. Overall, wavelength-selective routing ends up delivering contention-free all-to-all connectivity, since signal contention for resources is avoided at design time rather than solved at run time. Therefore, no arbitration of ONoC resources is needed. λ2 in0 λ2 in1 λ1 λ1 cross out0 λ1 in0 out1 λ1 in1 λ2 n o i s s i m s n a r T out0 out1 λ1 λ1 bar λ1 λ Figure 1: (Top) Optical input signals that are oﬀ- vs. onresonance with the MRRs of an add-drop ﬁlter. (Bottom) Transmission characteristic of an MRR. 3.2 Filtering of Wavelength Channels The building blocks of the most common WRONoC topologies consist of add-drop ﬁlters (ADFs). They add or remove narrow-band wavelengths of light from a broader optical signal being carried along a bus waveguide. They use micro-ring resonators (MRR) for this purpose, as illustrated in Fig.1. Essentially, when the input optical signal is onresonance with the MRR, the signal is deﬂected (bar function), otherwise it keeps propagating unaﬀected (cross function). The resonance eﬀect can be achieved by a proper sizing of the MRR radius. In fact, an MRR acts as a wavelength selecting ﬁlter with a periodic transmission characteristic, as pictorially illustrated at the bottom of Fig.1. One important parameter is the distance between resonance peaks, which is called the free spectral range (FSR), and gives information about the periodicity of the spectrum. The FSR depends on the ring radius: larger rings have denser peaks, while smaller rings have peaks that are far apart from one another. In order to carry out the bar and cross functions with λ1 and λ2 , respectively, we need λ1 to be on-resonance with the MRRs, and λ2 to be oﬀ-resonance. From PDN λ1 λ2 λ3 wavelength-routed topology λ3 λ1 λ2 Modulation stage Master Mr λ1 λ2 to slave Sk λ1 to slave Si λ2 to slave Sj (a) Drop function of a WRONoC. λ3 from master Mj λ1 from λ2 from master Mi master Mk λ1 λ1 λ2 λ2 wavelength-routed topology (b) Add function of a WRONoC. Receiver stage Slave Sr Filters PDs Figure 2: Logical tasks performed by a WRONoC. 3.3 Wavelength Routing Operation The wavelength-selective routing function fulﬁlled by each WRONoC can be logically viewed as consisting of two subfunctions: • Drop function (Fig.2a). Each master receives from the power distribution network (PDN) a wavelengthdivision multiplexed (WDM) optical signal consisting of multiple carriers with wavelengths λ1 to λn . Each carrier is modulated and delivered to the network for routing to a speciﬁc and distinct slave. Then, the ﬁrst task the network should perform consists of resolving the individual wavelength-channels from the multiplexed compound signal, so that each resolved component can be routed to a diﬀerent destination. In practical terms, this task can be accomplished by using add/drop optical ﬁlters, which are tuned to a speciﬁc wavelength, and therefore split the associated optical channel from the compound signal. • Add function (Fig.2b). Resolved wavelength channels from the diﬀerent masters and heading to the same slave should be recombined together into a WDM optical signal propagating onto the output waveguide of that slave. This way, a selective ﬁltering stage can eject the desired wavelength channel and feed it to a photodetector (PD) stage. In practice, this task can be accomplished by using diﬀerent inputs of add/drop optical ﬁlters. In a WRONoC topology, the add and drop functions are tightly intertwined: as the WDM input signal from a given master propagates down the topology, its wavelength channels are progressively and selectively resolved and coupled with channels tuned on diﬀerent wavelengths and originating from diﬀerent masters. This process is illustrated in Figure 3 for the λ-router WRONoC topology case study [14]. (1,2,3,4)A (1,2,3,4)B λ1 (1)A(2,3,4)B λ3 (1)C(2)A(3)B(4)D (1)A(3)D(2,4)B (1)B(2,3,4)A (1)C(2,3,4)D λ2 (1)C(2)A(3,4)D (1)B(2)D(3,4)A λ4 (1)D(2)C(3)A(4)B (1)A(2)B(3)D(4)C (1,2,3,4)C (1,2,3,4)D λ1 (1)D(2,3,4)C λ3 (1)D(3)A(2,4)C (1)B(2)D(3)C(4)A Figure 3: The tightly-intertwined add and drop functions at work in a λ-router WRONoC topology. Numbers refer to wavelength identiﬁers (IDs), while letters refer to master/slave IDs. Therefore, (1, 2)A refers to wavelength channels λ1 and λ2 originating from initiator A. 3.4 WRONoC Reﬁnement A WRONoC topology is ultimately speciﬁed by two key design parameters: a) the number of wavelength channels used by each initiator; b) the number and kind of add-drop ﬁlters in the topology; In order to understand the relation between these parameters, let us provide an abstract representation for a generic WRONoC topology. The topology can be viewed as the combination of basic primitives, which are 1x2 selective ﬁlter operators (SFOs), with one input and two outputs. This operator selectively ejects a predeﬁned wavelength channel from one of its outputs, while forwarding the other channels to the other output. In a WRONoC topology, the WDM input signal from any master undergoes the drop function by going through n − 1 SFOs, when assuming the connectivity of n masters with n slaves. This process is pictorially illustrated in a wavelength resolution graph (WRG), reported in Fig.4a for a generic 4x4 WRONoC topology. On each row, properly tuned SFOs eject wavelength channels λx , λy , λz , λt from the bundle, thus prompting them for the next add phase. The resolution pattern may diﬀer in each row, as illustrated in the ﬁgure, therefore the drop order of wavelength channels for master A can be diﬀerent from that of master B , and so on. The ﬁnal topology needs to map the SFOs to real devices. All WRONoC topologies reported in the open literature so far make use of the 2x2 add-drop ﬁlters (ADFs) previously illustrated in Fig.1. Therefore, technology mapping implies the pairwise grouping of the 1x2 SFOs into compact 2x2 ADFs. The grouping presented in Fig.4b, completed by the assignment step of the exact ADF resonant wavelengths (Fig.4c), gives rise to the λ-router WRONoC topology of Fig.3. While wavelength assignment can be made based on diﬀerent criteria, the only (obvious) requirement is that each component of the input WDM signal is ﬁltered only once on each row. Further details on this synthesis process are reported in [19], which proves that by varying the technology mapping and performing a legal wavelength assignment onto it, each WRONoC design point can be materialized. Overall, the synthesis of an n × n WRONoC topology requires: a) a number of wavelength channels which is equal to the number of targets n. Each initiator uses a diﬀerent wavelength channel to reach each target. b) several kinds of ADFs, each tuned to a diﬀerent resonant wavelength, depending on the wavelength assignment step in Fig.4c. For what this paper is concerned, it is worth recal ling that although the steps in Fig.4b and Fig.4c enable to diﬀerentiate a topology with respect to al l other ones, the exact value of the wavelength channels λi and the exact size and resonant wavelengths of the MRRs inside the ADFs are stil l speciﬁed as symbols, and left unspeciﬁed. This is the level of abstraction which is typical ly used in the literature for WRONoC evaluation, and this is the starting point of this paper. As a result, this paper moves from the assumption that the topology connectivity pattern has been speciﬁed by the system designer, and addresses the further reﬁnement step which is needed for the complete deﬁnition of the topology. Therefore, the paper searches for: a) the exact value of the n wavelengths used by each initiator, which are typical ly chosen in the frequency band 1500nm-1600nm. b) the exact radius length of the MRRs inside ADFs, determining the FSR and the periodic resonant wavelengths characteristics. 3.5 The Routing Fault Concern The two design decisions above are tightly interrelated. In fact, a wavelength channel must be positioned in the frequency band of interest so to be a resonant wavelength of one kind of ADFs, the one that drops (adds) that channel from (to) the input (output) WDM signal. This is pictorially illustrated in Fig.5(a) by means of an example, together with a possible inconvenient. Without lack of generality, wavelength channel λ2 is placed on one peak of the transmission characteristic of the larger MRR with radius R2 , while a smaller MRR with radius R1 is selected for tuning on the λ1 channel. The two MRRs have diﬀerent FSRs, since they depend on the MRR’s radius length. Therefore, two resonant peaks from the two MRRs might overlap, as illustrated in the ﬁgure. As a consequence, if λ1 were chosen to coincide with the overlapped peaks, a routing fault would occur in the network: channel λ1 would incorrectly perform the bar function when entering an ADF tuned to λ2 , instead of the correct cross function. While the problem can be easily solved in the example of Fig.5(a) by selecting another resonant wavelength of the small MRR, it can become a serious concern when increasing the network size. In fact, the proliferation of ADFs and of wavelength channels may limit the availability of non-overlapped transmission peaks, which causes the topology to be practically infeasible. Even for a ﬁxed network size, the routing fault concern turns out to be a fundamental limiter for communication parallelism. In fact, the examples seen so far assume that each initiator sends one bit at a time to each target on a speciﬁc wavelength channel. In fact, optical interconnect technology requires serialization of bit-parallel electronic words, which is only partially compensated by the high transmission rates of at least 10 Gbit/s. Communication parallelism could be increased by allocating multiple wavelength channels to each I/O connection, provided that they are allocated to the resonant peaks of the same ADF, in order to properly perform the add and drop functions. Fig.5(b) extends the routing fault concern to a higher communication parallelism. In the ﬁgure, the 6 (7) resonances of R1 (R2 ) are shown, however at most 4 bits of parallelism can be guaranteed. Denote by Λr = {λr,j } the resonances of the MRR with radius length Rr (we will also use λrj for brevity). Since λ1,2 conﬂicts with λ2,2 and λ1,6 conﬂicts with λ2,7 , routing fault prevention impedes selecting any of these four; now at most 4 (5) peaks in R1 (R2 ) can be used at the same time. In this case, the minimum parallelism that can be sustained by both wavelength channels is 4. The above problems are further exacerbated by the uncertainties of both the manufacturing process and of the device parameters (see section 3.6), which cause even resonant peaks that are just close enough not to be available for the routing of any wavelength channel. This paper tackles the problem of selecting both ADF sizes and wavelength channels in such a way that the connectivity is guaranteed (i.e., al l wavelength channels are placed in non-overlapped peaks) and the communication paral lelism is maximized, while avoiding routing faults. The approach proposed hereby is not topology-speciﬁc, in the sense that it holds for any generic WRONoC topology. 3.6 The Role of Parameter Uncertainty This section addresses the eﬀect of two important parameter uncertainties that can not be ignored when designing WRONoCs for routing fault avoidance; this way, we try to capture the fundamental dependency of architecture performance on the manufacturing process. The ﬁrst uncertainty is due to the MRRs’ fabrication process. Depending on the lithography, up to 10 nm of variation is expected for MRRs using rib-waveguides that underwent a full CMOS process ﬂow [10], i.e., given the tolerance Rtol = 10nm and the nominal radius Rr , the manufactured MRR will be between R− Rtol identiﬁes the maximum gap between the nominal value r = Rr − Rtol and R+ r = Rr + Rtol ; A B C D λx λy λz λz λt λy (x,y,z,t)A (x,y,z,t)B λi ≡λiλi ≡ (y,z,t)A (z,t)A (t)A (x,y,t)A (x,y)A (x)A (a) Generic wavelength resolution graph. A B C D λi ≡ λiλi ≡ λiλi λi (b) Technology mapping example. A B C D λi ≡ λiλi ≡ λiλi λi λ1 λ1 λ1 λ1 λ4 λ4 λ3 λ3 λ3 λ3 λ2 λ2 (c) Technology mapping example. Figure 4: Three-step synthesis methodology of a WRONoC topology. λ T r n a s m i s s i n o YES NO YES λ2 λ T r n a s m i s s i n o λ1,1 λ2,1 (a) (b) λ1,2 λ2,2 λ1,3 λ2,3 λ1,4 λ2,4 λ1,5 λ1,6 λ2,7 λ2,5 λ2,6 λ1 R1 R2 Figure 5: The routing fault concern: (a) constraining wavelength channel selection; (b) limiting parallelism. at design time and the actual one. The transmission response of the manufactured MRR will vary according to its actual radius. Figure 6 shows the optical spectrums for R1 and its maximum variations, say Λ− 1 , Λ1 , and Λ+ 1 ; in particular, the most noticeable eﬀect is that the resonances are shifted from the nominal ones to the left (right) for a negative (positive) radius variation. The greatest peak-to-peak λ Λ− Λ1 Λ+ 1 1 σ1,2 σ1,1 T r n a s m i s s i n o Figure 6: Relation between Rtol and σ for a radius R1 . distance (nm) between the nominal λ1,j and its variations is σ1,j . Since a small radius variation slightly aﬀects the FSR in general σr,j 6= σr,h for j 6= h (σ1,1 6= σ1,2 in the ﬁgure). To translate the variation Rtol into the many σr,j we developed a two-step procedure: i) an Electromagnetic Model [15] (EM) computes the three transmission responses Λ− r , Λr , Λ+ r , then ii) the responses are passed to a synthesizer that processes them and returns the σ values. This process is shown within the block I of Figure 7. The other uncertainty is due to the variation of the central operating wavelength of the laser, caused by variation in temperature and driving current; we set this value to ∆λ = 0.5nm1 . Since laser selectivity is independent from radius variation, ∆λ is considered in addition to σ and accordingly this quantity is processed in the block I of Figure 7. Given R1 , R2 , Rtol , and ∆λ, the resonances λ1,j and λ2,h may vary within the intervals I1,j = [λ1,j − σ1,j − ∆λ, λ1,j + σ1,j + ∆λ] I2,h = [λ2,h − σ2,h − ∆λ, λ2,h + σ2,h + ∆λ] In the most conservative hypothesis, λ1,j and λ2,h should never conﬂict, i.e., I1,j Table 1: TR with Ropt = {5, 1, 8} µm, Rtol = 0.01 µm, and ∆λ = 0.5 nm r Rr [µm] |{λr,j }| λi,1 hσi,1 + ∆λi, λi,2 hσi,2 + ∆λi, · · · [nm] 5 6 6 7 1496.4h3.5i, 1521.3h3.6i, 1547.1h3.6i, 1573.8h3.6i, 1601.4h3.6i 1500.5h3.0i, 1521.3h3.0i, 1542.7h3.1i, 1564.8h3.1i, 1587.5h3.3i, 1610.8h3.3i 1503.4h2.6i, 1521.3h2.6i, 1539.6h2.7i, 1558.4h2.7i, 1577.7h2.7i, 1597.4h2.8i 1505.6h2.2i, 1521.3h2.2i, 1537.3h2.2i, 1553.7h2.2i, 1570.4h2.0i, 1587.5h2.0i, 1604.9h2.0i and r ′ 6= r for which λrj is conﬂicting with some elements in row r ′ (∃λr ′ g | Irj I 1 2 3 4 5 6 7 8 R Rtol ∆λ r r r Rr EM R+ EM Λ+ R− EM Λ− Λr σ synthesizer λ ± σ + λ ± σ + ∆λ r ∆λ ∀Rr ∈ R TR s COP solver II R∗ (s), Λ∗ (s) P (s) Figure 7: Solving architecture Ropt = {5, 0.25, 30} yields 104 rows and about 1850 resonances (28 in the longest row). Once TR is computed, the optimal sets of radius lengths R∗ and of wavelength channels Λ∗ are chosen in order to maximize the parallelism. These choices are made on discrete sets; this highlights a combinatorial structure of the problem, meaning that the number of possible choices increases exponentially with the table size and the number of resonances. Since not any combination is feasible, due to routing fault prevention, we are faced with a Constrained Optimization Problem (COP). A COP consists of an input, a set of decision variables, a set of constraints, and an ob jective function. The inputs are the lookup table TR and the number s of ADF types. The core decisions concern which resonances should be selected from TR . To model this decision we use the boolean variable xrj ∈ {0, 1} to state whether λrj is selected. The COP is formally deﬁned as follows: P (s) = max : min {qr | qr > 0} s.t. r∈1..|R| (1) xrj ∀ r ∈ 1..|R| (2) qr = Xλrj ∈Λr sr = (0 1 sr = s Xr∈1..|R| qr = 0 qr > 0 ∀ r ∈ 1..|R| (3) (4) The ob jective function (1) maximizes the parallelism in the selected row (Rr ) with the least parallelism, since the global network parallelism is bounded by the channel with lowest parallelism. In practice, we maximize the minimum parallelism that can be sustained by all of the wavelength channels. Constraints (2) deﬁne the number qr of selected elements in row r . Constraints (3) deﬁne whether row r (the radius Rr ) is selected (sr = 1) or not (sr = 0). Constraints (4) impose to select exactly s rows (ADF’s radius lengths). Finally, the following logical constraint is imposed for any λrj 20 ) s ( P 10 0 0 4x4 GWOR 4x4 λ-Rout. ideal worst 8x8 GWOR 8x8 λ-Rout non-idealities 4x4 GWOR 4x4 λ-Rout. 8x8 GWOR A 8x8 λ-Rout 10 15 5 s Figure 8: Maximum parallelism P (s) as a function of the number of ﬁlter types, with fabrication options Ropt = {5, 1, 25} when both Rtol and ∆λ are 0. The chart in Figure 8 shows a ﬁrst analytical result: the bit parallelism is larger than one (P (s) > 1), i.e., wavelength routing is feasible, only for a very limited range of the s parameter (i.e., for overly small network sizes), when worstcase conditions are considered. To make the outcome more tangible, let us associate actual topology conﬁgurations to their values of s. In fact, s = 2 and s = 4 correspond to a 4x4 GWOR and a 4x4 λ−router, respectively, since they use diﬀerent numbers of MRRs types3 . While the GWOR enables 7-bit parallelism, the larger number of MRR types limits the λ−router parallelism to zero, which means the topology is infeasible. Both 8x8 topologies (with s = 6 and s = 8, respectively) turn out to be infeasible. In the ideal case, the higher number of MRR types of the λ−router is reﬂected into a relative drop in achievable parallelism by 9.5% for a 4x4 WRONoC, and by 25% for an 8x8 one with respect to GWOR. In this latter case, GWOR has a potential parallelism of 16 bits: the improvement with respect to the worst-case variations is impressive, which denotes the key limiting role played by the non-idealities of the manufacturcision, can clearly increase the WRONoC parallelism. The engineering curve with P (20) = 1 in the chart draws the required values of Rtol and ∆λ to guarantee the minimum working parallelism of 1 bit, i.e., the topology is feasible. 6. CONCLUSIONS In this paper we target the typically overlooked reﬁnement step of WRONoC topologies that completely speciﬁes their physical parameters. This signiﬁcantly impacts the achieved levels of connectivity and/or communication parallelism, due to the constraint of avoiding routing faults. Our optimization framework demonstrates the huge gap existing between ideal fabrication assumptions and the consideration of worst-case process parameter variations. In principle, even 32x32 WRONoCs can achieve 14-bit parallelism, while in practice worst-case variations limit even the 1-bit parallelism case to WRONoCs smaller than 8 nodes. We show that the resolution in setting the radius of MRRs is the highest-impact technology parameter. Finally, our optimization framework can support the designer in placing uncertainty requirements to the technology provider in order to materialize a predeﬁned level of parallelism. In future work, we will consider statistic distribution of parameter variations in order to limit the severity of process uncertainty and to introduce the notion of yield. 7. ACKNOWLEDGMENTS We thank the CINECA award under ISCRA (pro ject IsC37), for the availability of HPC resources and support. 8. "
2016,BoostNoC - power efficient network-on-chip architecture for near threshold computing.,"While near threshold design space provides a promising approach towards energy-efficient computing, it is plagued by sub-optimal performance. Application characteristics and hardware non-idealities of conventional architectures (optimized for the nominal voltage) prevent us from fully leveraging the potential of NTC systems. Further, the popular approach of increasing the computational core count to compensate for the performance loss severely burdens the on-chip communication fabric with an increased communication demand. In this work, we quantitatively analyze the performance bottleneck createdby a conventional NoC architecture in many-core NTC systems. To reclaim the performance lost due to a sub-optimal NoC, we propose BoostNoC--- a power efficient, multi-layered network-on-chip architecture. BoostNoC improves the system performance by nearly 2x over a conventional NTC system. Further, we improve the energy efficiency by 1.4x with the use of drowsy routers.","BoostNoC: Power Efﬁcient Network-on-Chip Architecture for Near Threshold Computing Chidhambaranathan Rajamanikkam Rajesh JS Koushik Chakrabor ty Sanghamitra Roy USU BRIDGE LAB, Electrical and Computer Engineering, Utah State University {chidham, rajesh.js}@aggiemail.usu.edu {koushik.chakrabor ty, sanghamitra.roy}@usu.edu ABSTRACT While near threshold design space provides a promising approach towards energy-efﬁcient computing, it is plagued by sub-optimal performance. Application characteristics and hardware non-idealities of conventional architectures (optimized for the nominal voltage) prevent us from fully leveraging the potential of NTC systems. Further, the popular approach of increasing the computational core count to compensate for the performance loss severely burdens the on-chip communication fabric with an increased communication demand. In this work, we quantitatively analyze the performance bottleneck created by a conventional NoC architecture in manycore NTC systems. To reclaim the performance lost due to a sub-optimal NoC, we propose BoostNoC— a power efﬁcient, multi-layered network-on-chip architecture. BoostNoC improves the system performance by nearly 2× over a conventional NTC system. Further, we improve the energy efﬁciency by 1.4× with the use of drowsy routers. 1. INTRODUCTION Modern many-core chip design is plagued by barriers of prohibitive energy constraints and restrictive power budgets. Near threshold computing (NTC) comes as a saving grace to the energy-efﬁcient computing paradigm by aggressively operating all computing platforms with a supply voltage close to the transistor threshold voltage. However, the tremendous increase in energy efﬁciency comes at the cost of a steep performance loss and performance variability (due to process variation) [5]. Further, traditional many-core architectures designed to perform at nominal voltages yield sub-optimal performance at NTC. While a majority of existing literature focuses on optimizing the computing cores, research on the on-chip communication’s impact at NTC has taken a back seat. In this context, we meticulously evaluate the application level and hardware performance characteristics of manycore NTC systems to speciﬁcally isolate the impact of the onchip communication fabric—network-on-chip (NoC). NTC circuits typically employ more devices to exploit application parallelism and compensate for the performance loss of a single device. [5]. A direct consequence of this approach is the increased communication demand on the NoC owing to simultaneous interaction of many cores. This heightened communication demand, along with the following three Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. ICCAD ’16, November 07-10, 2016, Austin, TX, USA Copyright 2016 ACM. ISBN 978-1-4503-4466-1/16/11...$15.00 DOI: http://dx.doi.org/10.1145/2966986.2967009 . Figure 1: Limitation due to application characteristics. prominent factors, delivers a severe blow to the on-chip communication latency and performance. First, we see an increase in the inter-core packet hop distance by virtue of an increase in the computational core count. Second, the supply voltage scaling to near threshold results in a massive reduction of the NoC operational frequency. Finally, the unavoidable effects of process variation (PV) presents a tremendous challenge in NTC systems. In this work, we demonstrate that the traditional on-chip communication fabric creates a severe performance bottleneck in NTC systems. In addition, we seek a solution to regain the lost performance without compromising on the energy efﬁciency of the system. Contemporary research on NoC topology and architectures such as clustered NoC [17], hierarchical NoC [12] and tile based NoC [7, 18], have aimed to reduce the inter-core packet hop distance. While these works are an important step forward, they do not adequately address the challenges of reduced operational frequency and PV induced performance variation posed by the NTC regime. Hence, to improve the NoC performance without compromising on the energy efﬁciency, we propose BoostNoC— a power efﬁcient, multi-layered NoC architecture that efﬁciently caters to the demands of many-core NTC systems. BoostNoC is made up of two architecturally homogeneous layers contrasted in their design characteristics. While one layer is optimized for power, the other is optimized to boost the NoC performance under high communication loads. To the best of our knowledge, this is the ﬁrst work to exploit the unique opportunity presented by the variation in communication load across epochs to efﬁciently boost the NoC performance in NTC regime. We make the following contributions in this paper: • We analyze the factors affecting performance in many core NTC systems and isolate the impact of the on-chip communication (Section 2). • We explore the detailed design of a power efﬁcient multilayerd NoC architecture called BoostNoC to improve the performance under high communication load in many core NTC systems (Section 3). Bottleneck Estimation Interconnect Memory Ideal system 1 System Comparison Ideal system + NoC Latency (1 cycle/hop) Ideal system + Memory Access Latency (∼45ns) Table 1: Test conﬁgurations used to quantitatively analyze the cause of performance bottleneck in many-core NTC systems. • We study the trafﬁc characteristics and network utilization of our BoostNoC architecture and determine that the use of drowsy routers can further improve the energy efﬁciency (Section 4). • Using a rigorous cross-layered circuit-architectural analysis (Section 5), we evaluate the performance, energy efﬁciency and peak power improvement of BoostNoC architecture. Our analysis reveals that BoostNoC delivers up to 1.4× higher performance per watt compared to a conventional NoC operating at NTC and nearly 3× that of a NoC operating at super threshold computing (STC) (Section 6). 2. MOTIVATION In this section, we quantitatively assess the performance bottlenecks in a NTC many-core system. The performance of a many-core NTC has two major contributing factors: application level and hardware performance characteristics. To understand application level characteristics, we study the performance scalability of various applications under an idealized hardware1 in Section 2.1. To carefully understand the impact from hardware performance characteristics, we decouple two of its major components: off-chip memory latency (Section 2.2.1) and on-chip interconnect latency (Section 2.2.2). Our rigorous experimental data clearly demonstrates that on-chip interconnect latencies are the most dominant performance bottlenecks in a NTC many-core system. 2.1 Application Performance Characteristics Application speedups from parallel execution are bound by the prevailing fraction of serial code and do not improve linearly with an increase in the computational core count. Since the fraction of serial code varies across applications, it is critical to understand this application level bottleneck when we comparatively analyze STC and NTC systems. Figure 1 shows the effective application speedups obtained when a representative set of parallel workloads (SPLASH2 benchmarks) are executed on ideal hardware by scaling the processor count from 1 to 128 cores. The evaluation methodology used for this analysis is presented in detail in Section 5. We observe that only a couple of applications in this diverse set of benchmarks, can effectively scale beyond 60 cores. Benchmarks like radiosity, cholesky and barnes, have nearly ideal speedup indicating very little overheads due to the serial portions of the code. Other applications like water.sp and raytrace have large portions of serial code. Deploying these applications in NTC systems with hundreds of cores will result in decidedly sub-optimal performance. 1 Ideal hardware signiﬁes a system with no hardware performance penalties. The associated hardware penalties related branching, memory access, on-chip communication, among others, are all considered to be 1 cycle. 2.2 Hardware Performance Characteristics To quantify the impact of notable hardware characteristics such as memory access latency and inter-core communication on system performance, we consider a popular tile based 128-core architecture as our baseline NTC system [11, 18]. The 128 cores are organized as 32 tiles (8 × 4) interconnected by a mesh network, with each tile consisting of 4 cores. The test conﬁguration parameters are shown in the Table 1 (Section 5 presents a detailed discussion of the methodology). 2.2.1 Memory Access Figure 2a illustrates the performance degradation due to off-chip memory access latency in a 128-core NTC system. Our analysis proves that memory access is not a prominent cause for performance bottleneck in NTC systems. We observe that the average performance degradation due to memory access latency is a mere 0.7% and the highest degradation suffered is 1.5% for the fft application. The baseline is considered to be an 128-core NTC system with ideal memory access latency as shown in Table 1. 2.2.2 On-Chip Communication Figure 2b shows that the system performance degrades signiﬁcantly due to the on-chip communication (networkon-chip) latency in a 128-core NTC system. Compared to an ideal system, the average performance degradation is a signiﬁcant 50%, while radiosity and fft suffer from nearly 90% degradation in performance. Our evaluations reveal that the following three factors play a decisive role in the degradation in NoC performance. • Increase in communication demand: When comparing the volume of packets injected in a 128-core NTC system to an isopower 16-core STC system 2 , we found that the volume of injected packets increased by more than 3× in the NTC system. The rise in core count results in the increase of both inter-core, as well as, cores-memory communication. • Diverse latency distribution in NTC: Figure 3a illustrates the distribution of communication latency in a 128-core NTC system. We observe that, on an average, more than 30% of the packets have a latency greater than 10 cycles. A similar analysis in the STC system showed that a mere 5% of the packets have a latency greater than 10. This diversity in latency distribution is the resultant of increased inter-core packet hop distance owing to a rise in the core count. • Reduced NoC operational frequency: Figure 3b shows that the packet latency degrades by more than 6×, on average, in a tile-based 128 core NTC system. Applications such as fft and radiosity, suffer a latency degradation of nearly 16×. The increase in inter-core packet hop distance, along with the added detriment of reduced operating frequency, considerably increase the average packet latency. 2.3 SIGNIFICANCE The degradation in performance due to application (Section 2.1) and hardware characteristics (Section 2.2) help us characterize the demand in NTC systems. Our ﬁndings clearly demonstrate that the on-chip communication is a severe bottleneck in many-core NTC systems. Hence, we propose BoostNoC, a novel power-efﬁcient NoC architecture for NTC systems to efﬁciently reclaim the lost performance. 2While scaling the 16-core STC system to a 128-core NTC system we ensure that both systems have a constant power budget. (a) Performance degradation due to off-chip memory access. (b) Performance degradation due to a NoC. Figure 2: Quantitative analysis of hardware characteristics to identify the cause of sub-optimal system level performance in manycore NTC systems. (a) Distribution of packet latency. (b) NTC packet latency normalized to its STC counterpart. Figure 3: Characterizing the loss in NoC performance in NTC. Figure 3a presents the distribution of packet latency (in cycles) and Figure 3b shows the degradation in packet latency in NTC systems. 3. BOOSTNOC ARCHITECTURE In this section, we provide a detailed description of the BoostNoC architecture. Section 3.1 presents the design overview and we establish the insight behind our approach in Section 3.2. In Section 3.3, we detail our two layers, and analyze the intricacies of switching between the layers in Section 3.4. Section 3.5 reveals the required hardware control mechanism. 3.1 Design Overview We envisage a multi-layered NoC architecture, where the layers are architecturally homogeneous but optimized to contrasting design considerations. Our work in this paper demonstrates a novel incarnation of this concept—BoostNoC— that exploits the temporal nature of communication demand in NTC systems. The temporal nature refers to the variation of communication load across different epochs due to the inherent application characteristics. Figure 4 illustrates the framework of our novel BoostNoC architecture. BoostNoC combines two architecturally homogeneous layers that are optimized to contrasting design parameters. Based on the communication load, BoostNoC dynamically switches between the layers. While one layer is optimized for power efﬁcient data transmission, the other layer is used to bolster the NoC performance. We detail the technicalities of BoostNoC in the following sections. 3.2 Temporal Communication Demand Figure 5 shows the on-chip communication network utilization trend of 4 representative applications, running on a 128-core NTC system. The x-axis represents consecutive intervals during the application runtime. In most benchmarks, we see discernible patterns in the communication demand that ﬂuctuates between epochs. In few epochs the cores are highly voluble3 creating a high load on the communication fabric, while in other epochs most cores are quiet (low communication demand). This temporal variation of network utilization can be correlated to the volume of injected packets experiencing long inter-core packet hop distance4 . Figure 6 illustrates this correlation for the fft benchmark. We see a sharp rise in network utilization in epochs with a high volume of long distance packets. Our novel BoostNoC architecture aims to exploit this temporal variation in communication demand by trading off chip area to bolster the NoC performance and energy efﬁciency. 3.3 BoostNoC Layers Two architecturally homologous layers of NoC routers are interconnected in a mesh topology to frame the BoostNoC architecture. The two layers share the links between the routers as shown Figure 4. The two layers are: • Frugal power usage layer (FruPUL): The routers in this layer are optimized to operate in the near threshold voltage regime to provide power-efﬁcient operation at a low communication load. • Boost performance layer (BoPeL): The routers in this layer are optimized to operate at the nominal voltage to bolster the NoC performance under a high communication load. The objective of BoPeL is to drain the in-ﬂight packets at a quicker rate and offset the latency degradation caused by voluminous long distance communication. At any given time, only one layer plays an active role in the communication fabric and the other layer is turned off. FruPUL is the default active layer as the cores are consid3 high volume of inter-core communication 4 Considering the tiled architecture, we deﬁne packets needing more than 3 hops to reach their destination as long distance communication. Figure 4: BoostNoC Architecture. The ﬁgure also shows the functional diagrams of the router and layer controllers. (a) barnes (b) cholesky (c) radiosity (d) raytrace Figure 5: Temporal variation of communication load for 4 diﬀerent benchmarks. The plots illustrate network communication load (in %) during consecutive intervals of 20000 cycles for the whole application runtime. We see discernible patterns in all applications. (a) Communication load - fft (b) Volume of long distance communication. Figure 6: Correlation between communication load and volume of long distance communication for the ﬀt application. Figure 6b shows the volume of long distance packets in consecutive epochs of 20000 cycles. The x-axis represents the application runtime in cycles. Figure 7: Operational phases of the switchover mechanism. ered to be operating in the NTC regime. During epochs with high communication loads, BoPeL is activated (and FruPUL deactivated) to meet the demand and boost the NoC’s performance. The layer switchover mechanism and the cost associated with it are discussed in Section 3.4. 3.4 Switchover Mechanism The switchover between the layers is the crux of the BoostNoC architecture. The primary constraint while switching between the two layers is to maintain lossless communication of packets while incurring minimal switching overheads. Figure 7 illustrates the process of switching between layers. Keeping the deﬁned constraints in mind, we envisage four operational phases of the switchover mechanism explained below in conjunction with Figure 7. • Pre-initiate: During normal NoC operation, one of the layers is active and the other is powered off. In this interval, the aggregate buffer occupancy of the routers in the active layer is carefully monitored. The buffer occupancy information serves as an indicator of the communication load on the network. It is the cardinal parameter behind the decision making process involved in switching between the layers. In Figure 7, we observe that FruPUL is active and the communication load is being monitored. When the load increases, the decision to switch to BoPeL is made. • Initiate: Based on the decision, BoPeL is signaled to switch on. During the same time, all the routers in FruPUL are instructed to process the in-ﬂight ﬂits in each router and forward them to the input buffers of their respective downstream routers. The ﬂits already present in each router ’s input buffers maintain status quo. We call this process ﬂit safeguarding. The process of ﬂit safeguarding is allowed to continue and complete until BoPeL (the other layer) is switched on and ready to handle trafﬁc. • Transfer: Once BoPeL signals ready, the packets in the input buffers of routers in FruPUL (one layer) are transferred to the corresponding routers in BoPeL (the other layer). The novel buffer content transfer mechanism overcomes the need to drain packets from the network and is elaborated in Section 3.5.1. • Terminate: On receiving a signal from FruPUL that the buffer content transfer is successful and that all its buffers are empty, the layer is signaled to be powered off. Simultaneously, BoPeL is waved to begin normal operation. 3.5 Hardware Control Mechanism BoostNoC architecture requires speciﬁc hardware enhancements to carry out its functions in an orderly fashion. We Algorithm 1 Layer Controller Operation ⊲ Number of routers 5: 8: 9: 10: 11: 1: Initialize: Router s = N ; 2: Acknowledge: ack_ LX 3: WaitForAcclimatizationPd(); 4: for k = 1 → Router s do Evaluate BufferOcupancy(k); 6: end for 7: for k = 1 → Router s do Evaluate RouterLocation(k); if (Bu f f erU s age > U s age th resho ld) then RouterRequested++; end if 12: end for 13: if (RouterRequested > Router s i gn i f i cant) then Enable req act iv_LX ; 15: end if 16: for k = 1 → Router s do Enable in it_ f s(k); 18: end for 19: WaitFor res pact iv_LX ; 20: if (res pact iv_LX ) then Enable in it_tr ansbu f (); 22: end if 23: WaitFor res p_bu f em pty; 24: if (res p_bu f em pty) then Enable term_LX (O LD ); Enable begin_comm; 27: end if 25: 26: 14: 17: 21: adopt two hardware control mechanisms known as Layer Controller and Router Controller to efﬁciently resolve and regulate the layer operations in the NoC. Each controller plays a deﬁnitive role to efﬁciently boost the NoC performance in NTC systems. Layer Controller (LC): The role of the layer controller is to monitor the network communication load by aggregating the information sent from individual router controllers. It functions like the brain of BoostNoC, and plays a central role in the decision process to switch between layers. Algorithm 1 shows the basic operation of the LC. As an initial setup, LC acknowledges the active layer (ack_LX ) and records the buffer occupancy of the routers in that layer (lines 1-6). It then continually monitors the information sent by individual router controllers during each epoch and based on the rules set in lines 7 − 15, it decides if a switchover in layer will yield a better outcome. Once the decision is made to switch between layers, LC signals to turn on the alternate layer (reqactiv_LX ) and instructs the individual router controllers (RC) to trigger ﬂit safeguarding (init_fs). On receiving a response from the newly activated layer (respactiv_LX ), it instructs all RCs to begin inter-layer buffer content transfer (init_transbuf ) and waits for all RCs to signal for transfer completion (resp_bufempty). At this point, the LC terminates the old layer (term_LX ), activates the new layer (begin_comm) and goes back to monitoring the communication load. Router Controller (RC): RCs are distributed agents with a three-fold functionality: (a) to sense local changes in the network, (b) to report gathered information to the LC and (c) to actuate responses when directed by the LC. Each individual RC reports its buffer occupancy to the LC at regular intervals (report_bufoc) and waits for a decision. On receiving the init_fs signal, the RC performs buffer content transfer as detailed in Section 3.5.1, reports successful transfer back to the LC and waits for begin_comm to restart communication in the active layer. Figure 8 illustrates the sequence of handshake signals between LC and RC, highlighting the operation of BoostNoC. LC, additionally ensures that once a layer is activated, it stays active for a set minimum period known as acclimatization period. The acclimatization period is added to amortize the cost associated with the layer switchover and to avoid the effect of thrashing between layers. 3.5.1 Inter-Layer Buffer Content Transfer The router controller (shown in Figure 4) plays a critical role in the inter-layer transfer of packets. The router in FruPUL is connected to its counterpart in the BoPel using a bi-directional physical link controlled by the RC. The router in each layer consists of n buffers. Once the process of ﬂit safeguarding is complete, RC evaluates the buffer occupancy of the active layer. The buffer contents of the active layer are serially copied to the buffers of the router in the alternate layer by selecting the appropriate MUX and DeMUX signals. A counter keeps track of all transactions between the two layers and once the value matches the buffer occupancy estimated before the process, the RC signals the successful completion of buffer transfer. This process happens simultaneously in the entire network. The serial transfer and transaction tracking between the two layers ensure a lossless transition between the two layers during a switchover. The cost associated with the switchover directly correlates to the buffer occupancy at the start of the process and the worst case switchover overhead depends on the buffer size of the routers. 4. DROWSY ROUTERS IN BOOST LAYER In this section, we study the trafﬁc characteristics and network utilization of the BoostNoC and propose the use of drowsy routers in BoPeL to further improve the energy efﬁciency. Breaking down the layer switching rule in Algorithm 1, we can rationalize that when the communication load on the network is high, BoPeL is activated. Figure 9 exhibits an interesting trend in trafﬁc when BoPeL is active. In most benchmarks, only a small number of tiles are responsible for the high communication load, indicating that the other routers are usually idle for long duration. On an average, nearly 60% of the routers are idle when operating in BoPeL. We exploit this phenomenon to improve the energy efﬁciency of the NoC by replacing the input buffers in this layer with drowsy SRAMs. 4.1 Design Details The routers in the BoPeL operate at the nominal voltage and hence have a signiﬁcantly high power consumption. By Figure 8: Handshake communication between Layer and Router controller. Parameters STC NTC Conﬁguration Conﬁguration Architecture Intel Xeon Processor E5 Series Cores 16 128 Voltage 1.0V 0.35V Frequency 2.3GHz 200MHz Technology 22nm 22nm Table 2: STC and NTC system conﬁguration parameters. Chen et al. showed that the maximum delay deviation due to within-die PV is a colossal 200% for the NTC regime at 22nm and thus cannot be discounted [3]. We therefore used this delay variation to model PV-affected NTC core. NoC Simulation: We model a 8x4 2D mesh NoC mimicking a 32 tile-based NTC system on the Booksim Simulator [8]. The router has a 4-stage pipeline of route computation, virtual channel allocation, switch allocation and switch traversal. We simulate the traces collected from Splash2 benchmarks and observe the NoC behavior and study various trafﬁc characteristics. We implement the BoostNoC architecture with functionality detailed in Section 3 and evaluate the performance of the NoC. Our evaluation carefully considers the impact of PV on the NoC performance. 5.2 Circuit Layer To estimate the design footprint and hardware overheads of our architecture, we augment the open source NoC router RTL [1] with the hardware control mechanisms discussed in Section 3.5. We synthesize the NoC router RTL using the 32nm standard cell library using Synopsys Design Compiler. We use the DSENT power modeling tool [19] to determine the NoC leakage and dynamic power estimates considering the PV parameters evaluated in the device layer. The network and router conﬁguration are identical in Sniper, Booksim, as well as, DSENT to maintain uniformity. 5.3 Device Layer We obtain the 22nm PTM model for HSPICE simulations and customize it in order to generate leakage and dynamic power behavior at STC and NTC regimes [22]. NTC circuits are highly susceptible to process variation. Our HSPICE evaluations model the effect of PV based on VARIUS-NTV [16] and we use these results while scaling from STC to NTC. The details of our scaling methodology follows. 5.3.1 Power Scaling from STC to NTC Scaling the entire power from the STC to the NTC region presents a methodological challenge. HSPICE simulation of an entire NoC architecture is computationally intense. To manage the complexity, we scale the STC power to NTC using the following three categories [4]. • Combinational logic: This is scaled using the STC/NTC characteristics of the canonical 31 fanout-of-4 inverter-chain as the representing circuit [15]. • Storage elements: We scale the on-chip SRAM power by investigating the power scaling trend from the STC 6T SRAM cell to the NTC-friendly 10T SRAM cell [20]. • Interconnect: We estimate the interconnect power to be 50% of the dynamic power based on previous work [4]. Since scaling the supply voltage equally affects both interconnect power and dynamic power, we assume that their relative weight remains unchanged for STC and NTC. Figure 9: Percentage of idle routers in the BoPeL. Figure 10: BoostNoC cross-layer methodology. introducing drowsy SRAMs as buffers in the router, we add an additional low power operation mode to improve the energy efﬁciency. In this mode, a low voltage is supplied to the inactive routers, thereby reducing the leakage current. The idle routers are periodically put into drowsy mode and are woken up when the upstream router requests credit information. A single cycle cost is added to wake up a router in the drowsy state [6]. The decision to put the idle routers into the low power mode can be made by the router controller based on buffer utilization changes. We evaluate the improvement in energy efﬁciency due to drowsy routers in BoPeL in Section 6. 5. METHODOLOGY Figure 10 presents the comprehensive cross-layer methodology we use to evaluate the efﬁcacy of BoostNoC architectures using three metrics: peak power, performance and energy efﬁciency. Architectural simulations are performed to assess the performance (Section 5.1), while the circuit layer analysis contributes valuable information regarding the design footprint and power characteristics (Section 5.2). Section 5.3 presents the procedure for device level analysis to obtain process variation parameters and STC to NTC scaling data. 5.1 Architectural Layer Multi-core Simulation: We model an Intel Xeon E5 series processor on Sniper multi-core simulator [2] with the conﬁguration shown in Table 2. The STC system models 16 cores interconnected using a NoC (4 × 4 2D mesh topology). The NTC system models 128 cores in a tile based architecture interconnected using a 8 × 4 2D mesh NoC, with each tile housing 4 cores [11]. We use highly parallel large-set workloads from the Splash2 benchmark suite to assess the performance of these systems and collect traces of the communication. We use booksim 2.0 [8] to simulate and evaluate the NoC behavior. Splash2 benchmark suite consists of parallel and welldiversiﬁed applications that can scale to 128 cores [21]. (a) Normalized system level performance. (b) Normalized packet latency. Figure 11: (a) System level performance improvement of our proposed schemes normalized to AlwaysNTC scheme. (b) Normalized reduction in packet latency of BoostNoC compared to AlwaysNTC scheme. 6. EXPERIMENTAL RESULTS In this section, we discuss the results obtained from our simulation of the BoostNoC architecture considering the within die PV. Section 6.1 summarizes the different schemes that we use in our simulations. We evaluate the effectiveness of our proposed architectures using three metrics performance (Section 6.2), peak power (Section 6.3) and energy efﬁciency (Section 6.4). We end our results section by presenting the design footprint in terms of area overhead in Section 6.5 6.1 Evaluation Schemes The four schemes evaluated in our simulations are: • Always NTC: The NoC and the cores are both operated in the NTC regime throughout the application runtime. In theory, this scheme is extremely energy efﬁcient at the cost of a substantial drop in performance. Moreover, the with-in die process variation signiﬁcantly affects the performance/power characteristics of both the cores, as well as, the NoC in this scheme. • Always STC: In this scheme, the cores are operating in the NTC regime, while the NoC is operating at nominal voltage. This conﬁguration provides the best performance while taking a signiﬁcant hit in energy efﬁciency. The cores substantially suffer from the effect of process variation. However, the NoC exhibits lower variation in performance/power characteristics as it operates at the STC regime. • BoostNoC: Our proposed BoostNoC architecture, discussed in Section 3, uses two layers (FruPUL and BoPeL) to provide the best of both worlds. The architecture sacriﬁces chip area to deliver better performance and energy efﬁciency. The process variation affects both cores and NoC signiﬁcantly. Since NoC operates in FruPUL layer during most of the application runtime, the effect of process variation is high compared to an always STC scheme. • Drowsy routers in BoPeL or drowsy BoostNoC: This scheme uses drowsy routers in the BoPeL to further improve energy efﬁciency. 6.2 Performance Analysis Figure 11a shows the normalized system level performance of the BoostNoC architectures considering within-die process variation. The performance is normalized to the PV-free always NTC scheme. Our results demonstrate that on an average, the BoostNoC improves the performance by nearly 2×. Benchmarks with a high communication demand such as fft and radiosity show even higher performance improvement (around 3×). However, applications with low communication demand (barnes and water.sp) are less sensitive to the Figure 12: Normalized peak power of BoostNoC architectures compared to PV-free AlwaysNTC (Lower is better). boost in operating frequency and hence deliver only 4% improvement in the system level performance. Our evaluations also show that the performance of drowsy BoostNoC nearly matches that of the BoostNoC. The small difference in performance between the two schemes is due to the overhead suffered while transitioning from low power drowsy state to the ON state. Figure 11b illustrates the packet latency reduction due to BoostNoC. These results signify the communication performance as compared to the PV-free always NTC NoC. Drowsy BoostNoC data is omitted from the plot as the performance is fairly identical to the BoostNoC architecture. On an average, our scheme improves the packet latency by nearly 40% compared to a conventional always NTC scheme. As expected, always STC performs better than BoostNoC. Our results demonstrate that applications with high communication loads signiﬁcantly beneﬁt from the BoostNoC architecture. 6.3 NoC Peak Power Analysis Figure 12 compares the peak power dissipated in all our different simulation schemes. The values obtained are normalized to PV-free always NTC peak power which is expected dissipate the least power. BoostNoC suffers from a 30% rise in the peak power on an average, due to the switchover to BoPeL which operates at the nominal voltage. A key observation from Figure 12 is the difference in peak power between BoostNoC and drowsy BoostNoC schemes. By putting the idle routers into a low power mode, we obtain modest improvements in peak power without signiﬁcantly compromising the performance of the NoC. 6.4 NoC Energy Efﬁciency Analysis Figure 13 compares the normalized energy efﬁciency of the schemes. In a sense, performance delivered per watt is an accurate measure for comparison of the schemes as it accounts and energy efﬁciency of the NoC in many-core NTC systems. 8. CONCLUSION In this paper, we demonstrate that on-chip communication creates a severe performance bottleneck in many-core NTC systems. We therefore propose — BoostNoC — a novel power-efﬁcient, multi-layered NoC architecture. BoostNoC effectively switches between the FruPUL (power efﬁcient) and BoPeL (performance optimized) to boost the system performance by 2×. Our analysis shows that BoostNoC with drowsy routers improves the energy efﬁciency of the NoC by 1.4×. Acknowledgments This work was supported in part by National Science Foundation grants (CNS-1117425, CAREER-1253024, CCF-1318826, CNS-1421022, CNS-1421068). Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views of the NSF. 9. "
2017,Energy-efficient and robust 3D NoCs with contactless vertical links (Invited paper).,"3D integration, a breakthrough technology to achieve ""More Moore and More Than Moore,"" provides numerous benefits such as better performance, lower power consumption, and wide bandwidth by vertical interconnects and 3D stacking. These vertical interconnects enable design of high performance 3D Network-on-Chip (NoC) as a communication backbone for massive manycore platforms. However, existing 3D NoCs are still bottlenecked due to simple extension of 2D architectures without fully exploiting the advantages of the 3D integration. Moreover, the anticipated performance gain of 3D NoC-enabled manycore chips will be compromised due to potential failures of through silicon vias (TSVs) that are predominantly used as vertical interconnects. To address these problems, we explore a holistic design methodology starting from the physical layer to the overall interconnection architecture where the vertical data exchange takes place through contactless links using near field inductive coupling (NFIC).","Energy-Efficient and Robust 3D NoCs with  Contactless Vertical Links (Invited Paper)  Sourav Das, Srinivasan Gopal, Deukhyoun Heo, Partha Pratim Pande  {sdas, sgopal, dheo, pande}@eecs.wsu.edu  School of EECS, Washington State University, Pullman, WA-99163  Abstract— 3D integration, a breakthrough technology to  achieve “More Moore and More Than Moore,” provides  numerous benefits such as better performance, lower power  consumption, and wide bandwidth by vertical interconnects  and 3D stacking. These vertical interconnects enable design of  high performance 3D Network-on-Chip  (NoC) as a  communication backbone for massive manycore platforms.  However, existing 3D NoCs are still bottlenecked due to simple  extension of 2D architectures without fully exploiting the  advantages of the 3D integration. Moreover, the anticipated  performance gain of 3D NoC-enabled manycore chips will be  compromised due to potential failures of through silicon vias  (TSVs) that are predominantly used as vertical interconnects.  To address these problems, we explore a holistic design  methodology starting from the physical layer to the overall  interconnection architecture where the vertical data exchange  takes place through contactless links using near field inductive  coupling (NFIC).   Keywords— 3D NoC, NFIC, Robust, MTTF, Small-World.  I. INTRODUCTION   3D integration provides higher device density, wide interdie bandwidth, and heterogeneous integration. Higher device  density continues “More Moore” and enables more  functionality and/or smaller form factor. The heterogeneous  integration of multiple planar dies fabricated with different  technologies achieves a complete System-on-Chip (SoC)  composed of digital logic, DRAM, analog and RF circuits,  and sensors [1] [2]. On the other hand, NoC is an enabling  solution for integrating large numbers of embedded cores in  a single die. 3D NoC architectures combine the benefits of  the aforementioned  two  technologies  to offer an  unprecedented performance gain even beyond the Moore’s  law regime. With an additional degree of freedom introduced  by the vertical integration, architectures that were impossible  or prohibitive due to wiring constraints in planar ICs are now  feasible, and many 3D implementations can outperform their  2D  counterparts. Existing  3D NoC  architectures  predominantly follow simple extension of regular 2D NoCs  [2] [3]. However, this does not fully exploit the advantages  provided by 3D integration. The vertical connections enable  design of more energy-efficient NoC architectures. In this  context, design of small-world network-based NoC  architecture [4] is a notable example. It is shown that either  by  inserting  long-range shortcuts  in a regular mesh  architecture to induce small-world effects or by adopting  power-law based small-world connectivity it is possible to  achieve significant performance gain and lower energy  dissipation compared to mesh networks [4] [5]. We advocate  that this concept of small-worldness should be adopted in 3D  NoCs. More specifically, the vertical links in 3D NoCs  should enable design of long-range shortcuts necessary for  small-world networks. By exploiting the vertical connections  in a 3D IC, the multi-hop long range planar wired links can  be placed along the shorter Z-dimension instead of the X-Y  planes, and hence overall system performance can be  significantly improved. Despite the proposed architectural  innovation, the anticipated performance gain of a 3D NoCenabled manycore chips will be compromised due to the  probable failures of TSVs that are predominantly used as  vertical interconnects in 3D ICs [4]. As an alternative,  inductively coupled wireless link is another 3D integration  technique that offers attractive benefits over conventional  TSVs [3]. TSVs suffer from bandwidth limitations due to  their inherent low-pass frequency response [6]. TSVs exhibit  large bandwidth reduction with just 10% of misalignment  errors. In contrast, inductively coupled links can afford much  more bandwidth compared  to TSVs. Furthermore,  inductively coupled channels are highly resilient  to  misalignment [8]. Unlike TSV-based 3D IC, thermal  management using microfluidic-based cooling  in  the  contactless counterpart does not require sophisticated CAD  algorithms as the inductors and the cooling channels are  fabricated  in separate  layers, viz. metal and silicon  respectively. Current state-of-the-art research shows that  inductively  coupled  channels  outperform  TSV  implementations in terms of energy-per-bit metrics, and can  be expected to scale far more competitively with more  advanced technology nodes [7]. These advantages can be  achieved by avoiding increased fabrication cost associated  with the TSV-based 3D integration.   In this paper, we highlight the advantages and various  design challenges associated with near-field inductive  coupling (NFIC)-based 3D integration. Subsequently, we  discuss how these NFIC-based vertical interconnects can  enable design of a robust 3D NoC architecture.   II. ENERGY-EFFICIENT AND HIGH-BANDWIDTH  CONTACTLESS VERTICAL COMMUNICATION USING NFIC  This section describes the three major components  involved  in a high bandwidth contactless vertical  communication link: (1) the NFIC channel, (2) the transmitter  and, (3) the receiver circuits respectively. Fig. 1 (a) shows the  block diagram of the 3D NFIC-based high bandwidth vertical  communication link. NFIC channel makes use of the  transitions in transmit current (IT) in transmitter inductor to      Fig. 1: (a) 3D NFIC Link Architecture (b) Multiple configurations to achieve a certain BER at a given data rate and communication distance. induce a voltage pulses (VR) in the receiver inductor by means  of mutual coupling [6].   High-speed links based on contactless AC coupled NFIC  channels can achieve excellent bit error rate (BER) with low  power consumption [8], without requiring any carrier  modulation [10]. BER is a function of NFIC channel,  transmitter and receiver configurations. Multiple possible  configurations of these parameters satisfy the link BER  specifications at a given data rate and communication range  in a 3D IC as shown in Fig. 1 (b). However, energy-areaoptimized design can only be accomplished by balancing the  inter-dependencies of these parameters.   The challenges of implementing an energy-efficient NFIC  link are governed by the intertwined trade-offs between  channel gain, power, data rate, area and communication  range. Fig. 2 shows the necessary relationships among  various parameters. An increase in transmit current (IT)  and/or an increase in receiver pre-amplifier’s (Pre-amp) gainbandwidth could enhance receiver sensitivity for an  improved BER, resulting in increased power consumption.  Channel gain is directly proportional to inductor diameter and  inversely proportional to communication range. To extend  the communication range, an increase in the inductor  diameter translates to an increased link area. The adverse  effect of increasing inductor diameter for high data rates is  inter symbol interference (ISI). The achievable bandwidth is  limited by the self-resonance frequency (SRF) of the  inductors to avoid excessive ringing in the received voltage  pulse causing ISI [19].  In this context, for optimum NFIC link parameters we  introduce a unified link performance metric (J-1). The J-1  metric captures the effects of speed, power and area for a  given communication range.  Hence, our aim is to maximize  the metric (J-1), as shown in (1).  × BWD ( Tbps mm2 )                   (1)  Data Rate (Gbps)                      (2)  BWD (Tbps/mm2) =  Data Rate (Tbps)                        (3)  This performance metric J-1 incorporates both energy and  area parameters using energy efficiency (pJ/b) and bandwidth  J-1 =  (cid:4674)Energy bit Energy bit (pJ/b)  =   b )(cid:4675)(cid:2879)(cid:2869) ( pJ Power (mW) Area (mm2 ) Channel  Gain Power Power Data Rate Da ta r ate Area Comm. Range Block Level Variable Tx Driver Current Swing Rx Pre-Amp  Gain-Bandwidth Inductor Area Parameter Channel Gain System Level Consequence Link Power Link BER Channel Gain Link BER Link Power Communication  Range Link Area Max. Data Rate Fig. 2: 3D NFIC channel’s inter-twined multi-variable trade-offs density (BWD) (Tbps/mm2) for different data rates.  Maximizing the metric J-1 ensures high energy efficiency  (low power at high bandwidth) and high bandwidth density  (minimal area overhead achieving higher bandwidth).  A. NFIC Channel Design for Link Optimization   NFIC channel design for holistic link optimization is  accomplished in two stages - (i) Geometric Programmingbased convex optimization for fast evaluation of the metric J1 introduced in (1) to find a set of local optima and (ii)  Statistical link analysis to find the global optimum by using  NFIC channel’s S-parameter network. Design of on-chip  inductors with appropriate bandwidth-area trade-off is a  major technical challenge in radio-frequency (RF) circuit  design as it requires large electro-magnetic simulations (EM)  with 3D substrate definition for accurate results in silicon.  Our proposed methodology, however filters out the large set  of local optima making EM solver’s computational data and  time more compact. At the same time, accuracy is also  preserved by using statistical link analysis on the actual  physical NFIC channel.   Geometric programming (GP)-based convex optimization  for inductor based circuits and high speed links has been  explored [11]. We advocate this method to a multi-variable  3D IC environment, which includes transmitter, receiver and  the NFIC channel parameters for evaluating the possible  optimized design space. This method provides mapping from  block-level parameters (Tx current swing, inductor geometry,  Rx pre-amp gain bandwidth) to NFIC link metrics. This  NFIC Channel  Physical Layout  NFIC Channel  S-parameter Network S21 Port 1 (Tx) S11 S22 Port 2 (Rx) S12 a1 b1 b2 a2 Fig. 3: Electro Magnetic simulation to extract S-parameter network of  physical NFIC channel (b) Extracted NFIC Channel gain across frequency   PRBS Generator @ 32Gbps TX NFIC Channel S-paramter network RX DCD = 5% UI RJ= 5% UI ΔIT Swing σn  = 3mV Voff = 3mV RJ= 5% UI DFE Coefficients (a) W/o DFE W/o DFE W/ DFE W/ DFE ) V ( e g a t l o V BER = 10-12 BER = 10-11 BER = 10-10 time (ps) ) V ( e g a t l o V (b) BER = 10-12 BER = 10-11 BER = 10-10 time (ps) Fig. 4: (a) Statistical link BER simulation set-up (b) BER contours without (W/o) and with (W/) DFE  mapping is required  for the physical design of NFIC channel.  The 3D EM solver generates the scattering parameter (Sparameter) network of the NFIC physical channel. The  measure of NFIC channel gain across various frequencies is  extracted through the S-parameter network as shown in Fig.  3. Statistical link BER simulation using Advanced Design  Systems (ADS) is employed on the S-parameter network of  the NFIC channel to estimate the link BER [12]. The  statistical link BER analysis incorporates transmitter current  swing, receiver sensitivity and aperture time in the presence  of distortion effects, random and deterministic noise sources.  The entire link budget simulation set up is shown in Fig. 4(a).  The main sources of noise and jitter include 5%-unit interval  (UI) duty cycle distortion (DCD) in data and clock with  random jitter (RJ) of 5% UI at the Tx driver. We employ  decision feedback equalization (DFE) for ISI cancellation  and  link BER performance  improvement [12]. This  simulation incorporates DFE with noise and offset of 3mV  and 5% UI random jitter at the receiver front end. The BER  contour plots shown in Fig. 4(b) demonstrate that DFE  improves the link BER performance with a ~ 67% larger eye  opening at a BER of 10-12, without additional Tx power or  increasing inductor area.   B. Transceiver Circuits  To determine the transmitter power and delay, the entire  chain of serializer, local clock buffering, pre-driver and  output driver need to be considered. The major constraints  in the transmitter circuits are: (a) the maximum peak-to-peak  differential output swing, which is equal to the nominal  supply voltage, and (b) the 20%–80% transition time of the  serializer and driver circuits is limited to one-third of a bit  period to avoid excessive ISI [12].   The total power of the receiver includes pre-amp,  hysteresis buffer, DFE buffer and the deserializer. The  receiver front-end constraints are: (a) pre-amp gain and  hysteresis buffer meeting the required sensitivity, and (b) its  bandwidth commensurate with the specified data rate. With  the above gain bandwidth requirements, Rx front-end power  can be evaluated. The power of deserializer latches can be  evaluated from its settling time constraints. The DFE is  based upon adaptive setting of the decision threshold of the  hysteresis latch depending on the previous output state.  Our methodology helps us to determine an optimum  bandwidth at which both energy efficiency and bandwidth  density can be maximized for a given technology. Fig. 5 (a)  shows the energy efficiency for different data rates and  inductor areas. The optimum value of the unified metric J-1  defined in (1) is shown in Fig. 5 (b) for different data rates.  The optimum value (maximum) of J-1 is ~1.7 NU  (normalized units of (pJ/b)-1×Tbps/mm2). This value is  obtained at ~18 Gbps data rate with an energy efficiency of  240 fJ/b and a bandwidth density of 40.8 Tbps/mm2 for a  communication range of 12 µm in 28nm CMOS FD-SOI  process. Compared to our results, normalized J-1  metric of  state-of-the-art NFIC-based 3D NoC  for  the same  communication range of 12 µm is about ~0.1 NU with  energy efficiency of 1.4 pJ/b and normalized bandwidth  density of 13.9 Tbps/mm2 at 8 Gbps in 65nm CMOS process  [9]. Fig. 5 (c) shows the variation of the metric J-1 for various  data rates for  three possible channel configurations  depending on their D/Z ratios. Here D is the diameter of the  inductor and Z is the vertical communication range for a  target BER of 10-12. The configuration with reduced area  (D/Z ~ 1.8) has reduced metric J-1 due to large power  consumption from the Tx current driver. Although the  configuration with increased coupling coefficient (D/Z ~ 4)  helps in significant energy savings (>80%), it comes at the  cost of increased chip area. The proposed NFIC link  achieves simultaneous reduction in power and area for D/Z  ratio of 2.6. To characterize the NFIC link, we also show the  recovered NRZ signal eye diagrams at the Rx front-end  output without and with DFE in Fig. 6 (a) and (b),  respectively. These eye diagrams show an improved  differential peak-to-peak voltage of 1.66V compared to  1.12V without the DFE at ~17.6 Gbps data rate.   ) s t i n U d e z i l a m r o N ( c i r t e M 1 J 2 1 0 0   65 nm CMOS   28 nm CMOS FD-SOI JOpt -1 [9]TVLSI 2016 (Normalized) 5 10 15 20 Data Rate (Gbps) 25 ) s t i n U d e z i l a m r o N ( c i r t e M 1 J 30 2.4 1.8 1.2 0.6 0 0 NFIC link (D/Z ~ 4) w/ increased coupling coefficient NFIC link (D/Z ~ 1.8) w/ increased Tx current drive NFIC link (D/Z ~ 2.6) w/ equalization 5 10 15 20 Data Rate (Gbps) 25 30 (a)                                                                                      (b)                                                                (c)  Fig. 5: (a) Energy efficiency vs. data rate and area, (b) SPACE optimization for global optimum data rate, and (c) J-1 vs. data rate for variable D/Z configurations  with BER = 10-12                        1.12 V 0.76 UI (a) 0.83 UI 1.66 V (d) Fig. 6:  NRZ recovered eye diagrams with hysteresis: (a) without  DFE correction; (b) with DFE correction.  (b) III.  RELIABITLY ANALYSIS OF VERTICAL LINKS   The achievable performance of the 3D manycore chip will  be affected by the failure of the vertical links (VLs). Both  TSV and NFIC suffer from reliability issues. TSVs in a 3D  manycore chip fail due to formation of voids and cracks,  misalignment in bonding and landing pads, electromigration  of TSV materials and so on [14] [15]. The main concern  about the NFIC-based link design is the misalignment  between the Tx and Rx inductors. In this section, we discuss  the reliability issues of both the NFIC- and TSV-based VLs  from the 3D NoC design perspective.  A. Misalignment Tolerance of NFIC-links  To demonstrate  the  interdependency between  the  performance and resiliency of NFIC-based links, we show  the channel loss as a function of the degree of misalignment  between the Tx- and Rx- inductors in Fig. 7. The parameter  Δx/D represents the percentage of misalignment, where Δx is  the amount of misalignment between the Tx and Rx  inductors (Tx center axis to Rx center axis), and D refers to  the inductor diameter. From Fig. 7, we can see that as the  amount of misalignment increases, channel loss and link  power overhead  increase gradually. For a +/-20%  misalignment, channel loss is only ~ 3dB more, and  associated link power overhead is less than 20% to  compensate for additional channel loss.   B. Reliability Challenges with TSV-based Vertical Links  The major challenge associated with TSV-based 3D NoC  is the failure of TSV-enabled vertical links (VLs). The two  main TSV reliability issues are the electromigration of TSV  material (due to workload-induced stress) and the cross-talk  noise among individual TSVs in a bundle [16]. To  characterize the reliability of TSVs, we consider the lifetime  of TSV-enabled VL as the relevant metric. The lifetime of a  TSV is termed as the mean-time-to-failure (MTTF) and  popularly defined as the time when the delay of TSV-based  link increases by 10% [15].  In a TSV-enabled link, due to high current densityinduced stress, TSV material undergoes electromigration at  the junction of TSV and the landing pad. Consequently, the  ) B d ( s s o L l e n n a h C 0 -1 -2 -3 -4 -5 -6 -40 -20 Rx  coil D∆ x Tx  coil Misalignment (Δx/D) (%) 20 0 60 50 ) % ( d a e h r e v O 40 30 r e w o P 20 k n L i 10 0 40 Fig. 7:  Misalignment tolerance and link power overhead.  Fig. 8: Placement of different types of TSVs in a 3x3 grid. (left)  Based on the through current direction, the worst-case crosstalk  capacitance for the center TSV. Here, Cc is the amount of crosstalk  for a single transition between two adjacent TSVs.  (right) The  aggregation of worst case Cc values for each TSV and three types  of TSVs categorized based on the Cc experience.  resistance and delay of TSVs increase. In a 3D NoC, the  active utilization (and hence the workload induced stress)  among TSV-enabled VLs varies widely depending on the  types of NoC architecture and applications [16]. Higher  workload makes  the electromigration effects more  pronounced and consequently, the MTTFs for these types of  TSVs are lower compared to others. As a result, the MTTF  distribution also vary widely across the VLs [16].   In addition, delay of a TSV-based link is significantly  affected by the crosstalk capacitances. Effective value of  crosstalk noise in a TSV bundle depends on two important  factors, viz., the exact location of the TSV (which  determines the proximity to other TSVs), and the bit patterns  (through current). In general, TSVs are placed in grid-based  pattern, e.g. 3x3, 3x4, 4x4 etc., and the center TSV faces the  highest amount of crosstalk noise. Depending on the amount  of crosstalk noise experience, TSVs in a bundle can be  categorized in three types viz. Type_1 (center TSV of a 3x3  grid), Type_2 (adjacent members of Type_1) and Type_3  (corner TSVs of a 3x3 grid). Fig. 8 explains the worst-case  crosstalk effect for the center TSV of a 3x3 grid and three  different types of TSVs. Among all of them, Type_1 TSVs  undergo the highest amount of crosstalk and followed by  Type_2 and Type_3. Consequently, the MTTFs of Type_1  TSVs are lower compared to others.   IV. ROBUST NOC ARCHITECTURE DESIGN USING NFIC  In this section, first, we briefly describe the testbed NoC  architecture to explore the reliability concerns of 3D NoCs.  Subsequently, we elaborate the design methodology of a  robust NoC architecture by incorporating NFIC-based VLs.                       A. Small-world Network-enabled 3D NoC  3D NoC combines the benefits of 3D-intergration and  NoC paradigm to design high performance and energyefficient manycore systems. However, mesh-based NoCs  employ multi-hop communications, and thereby suffer from  high latency and energy consumption [3]. In this context, a  small-world network inspired 3D NoC (3D SWNoC)  balances the local and long-distant communications by  selectively incorporating a limited number of long-range  links in the network. The 3D SWNoC outperforms all other  existing alternative architectures [4] [5]. In this work, we  consider the 3D SWNoC as a suitable architecture for  exploring the benefits of NFIC-based link design.   In a 3D SWNoC, the VLs act as the long-range shortcuts  and induce the small-world effect in the network. To ensure  the best achievable performance from 3D SWNoC, the VLs  need to be designed as true long-range shortcuts where  routers from non-adjacent layers can also communicate  directly through VLs. NFIC-based links can bypass the  intermediate layers to establish direct links between nonadjacent  layers with high energy efficiency without  interfering  the  intermediate  communications  [13].  Consequently, NFIC-based links can enable true long-range  communications for energy efficient 3D SWNoC design.   In addition, small-world-enabled networks are robust  against any kind of link failure and the performance of 3D  SWNoC degrades marginally compared to other mesh-based  counterparts [4] [5]. The inherent robustness of small-world  networks can be complemented with NFIC-based links to  design robust NoC architectures.    B. NFIC- and TSV-enabled Robust 3D SWNoC  In this section, we analyze how the resiliency of NFIC  links (as explained in Section III.A) and the robustness of  small-world network (Section IV.A) can be combined to  design reliable 3D NoC architectures.    1) NFIC- and TSV-enabled Hybrid 3D NoC Architecture  As explained in Section III.A, the only reliability concern  of NFIC links is the misalignment of Tx and Rx inductors  that can be addressed by paying an additional power  overhead. Hence, we can exploit the resiliency of the NFICbased  links  to design  robust NoC  architecture.  Consequently, we propose to adopt the NFIC-based links in  a TSV-enabled 3D NoC to design NFIC-TSV hybrid NoC  architecture. Our target is to achieve the maximum reliability  Fig. 9: NFIC- and TSV-enabled hybrid 3D SWNoC architecture.  To ensure maximum robustness against vertical link (VL) failure  of the NoC, selective VLs are designed with NFICs.  of TSV-based 3D NoC architecture by introducing a certain  number of NFIC-enabled VLs. Fig. 9 shows an example of  the proposed hybrid 3D SWNoC architecture.   In order to achieve the maximum reliability for a given  NFIC-budget, we need to determine the failure prone TSVs,  and then replace them with NFIC-based links. For ease of  referencing, the hybrid TSV- and NFIC-enabled NoC  architecture is denoted NFIC_x%. Here, the term x% refers  to the percentage of NFIC-enabled VLs present in the NoC,  while the other (100- x)% VLs are designed with TSVs. To  allocate the NFIC-based links, we follow an efficient spareVL allocation algorithm proposed in [14]. In our work,  instead of allocating spares, we explore the TSV-enabled VL  with the lowest MTTF, and redesign it with NFICs until the  upper bound of the NFIC-budget is reached.    2) MTTF Distribution of Vertical Links   To measure the reliability of the hybrid 3D SWNoC, we  consider the MTTF distribution of TSV- or NFIC-enabled  VLs as the relevant metric. In this case, the MTTF  distribution indicates the percentage of total VLs that have  MTTF less than a particular value. Consequently, lower  value for any MTTF distribution, at any instant of time,  indicates more reliable and robust 3D NoC, which is  expected to have longer lifetime compared to an NoC  configuration having higher value for MTTF distribution.   3) Reliability of Hybrid 3D NoC  To evaluate the performance and reliability improvement  of TSV- and NFIC-enabled hybrid 3D NoC, Fig. 10(a) and  Fig. 10(b) show the MTTF distribution of VLs for two  benchmarks, viz. CANNEAL  [17] and FFT  [18],  respectively, as examples. The horizontal axis indicates the  (a)  Fig. 10: MTTF occurrence distribution for (a) CANNEAL, (b) FFT benchmark with different percentage of TSV-enabled vertical links are  replaced with NFIC-based (denoted as NFIC_x%) designs. The MTTF is normalized with respect to the lowest MTTF of the system.  (b)    V. CONCLUSION  In this paper, we have highlighted various advantages  and design challenges associated with NFIC-based 3D  integration. Specifically, we have focused on suitability of  near field inductive coupling (NFIC) links in designing  energy-efficient and  robust NoC architecture as a  communication backbone for manycore chips. Compared to  conventional TSV-based design, NFIC-enabled 3D NoC  architecture is more robust and energy-efficient solution.   ACKNOWLEDGEMENT  This work was supported in part by the US National Science  Foundation (NSF) grants CNS-1564014, CCF-1514269, and  CCF-1162202.  "
2017,A case for low frequency single cycle multi hop NoCs for energy efficiency and high performance.,"As the number of cores in a multi-core system increase, network on-chip (NoC) latency and transmission energy scale unfavorably, since they are directly proportional to the number of hops traversed. Designers often have to trade-off energy to get lower latency (for instance long-distance bypass links with high-radix multi-stage routers) or latency to get lower energy (e.g., scaling down voltage and frequency of NoC routers and links). This work offers an alternate design-space for latency-energy optimization that has previously been unexplored, by harnessing the fact that lower frequency links can actually be used to transmit over longer on-chip distances within a cycle. We leverage a recently proposed micro-architecture that enables the construction of single-cycle multi-hop paths on the fly over a regular mesh network, and augment it with support for dynamic voltage and frequency scaling by decoupling router frequency from link frequency. In essence, we enable packets to traverse only wires from the source to the destination (as if it had a dedicated connection) only getting buffered at routers if necessary (at turns or due to contention). We address the synchronization challenges of multi-hop bypass setup signals in a multi-frequency domain and propose novel static/dynamic router and link frequency assignment techniques. Across synthetic as well as full-system benchmarks, we demonstrate reduced energy with similar or better run-times.","A Case for Low Frequency Single Cycle Multi Hop NoCs for Energy Efﬁciency and High Performance Monodeep Kar and Tushar Krishna School of Electrical and Computer Engineering Georgia Institute of Technology Atlanta, Georgia 30332–0250 monodeepkar@gatech.edu, tushar@ece.gatech.edu Abstract—As the number of cores in a multi-core system increase, network on-chip (NoC) latency and transmission energy scale unfavorably, since they are directly proportional to the number of hops traversed. Designers often have to trade-off energy to get lower latency (for instance long-distance bypass links with high-radix multi-stage routers) or latency to get lower energy (e.g., scaling down voltage and frequency of NoC routers and links). This work offers an alternate design-space for latencyenergy optimization that has previously been unexplored, by harnessing the fact that lower frequency links can actually be used to transmit over longer on-chip distances within a cycle. We leverage a recently proposed micro-architecture that enables the construction of single-cycle multi-hop paths on the ﬂy over a regular mesh network, and augment it with support for dynamic voltage and frequency scaling by decoupling router frequency from link frequency. In essence, we enable packets to traverse only wires from the source to the destination (as if it had a dedicated connection) only getting buffered at routers if necessary (at turns or due to contention). We address the synchronization challenges of multi-hop bypass setup signals in a multi-frequency domain and propose novel static/dynamic router and link frequency assignment techniques. Across synthetic as well as full-system benchmarks, we demonstrate reduced energy with similar or better run-times. I . IN TRODUC T ION Chip-Multiprocessors (CMP) with more than 100 cores are soon going to become an integral part of Exascale computing and the network-on-chip (NoC) connecting these cores will be critical to the overall performance of the system. Energyefﬁciency and latency of NoCs are two key aspects that need to be addressed in such designs to achieve scalability. The biggest scalability challenge for NoC energy is that wire capacitance (hence energy) is an order of magnitude higher than transistor capacitance, meaning that the data movement energy dominates, especially for long distances across the chip [1]. The biggest scalability challenge for NoC latency is that it is directly proportional to the number of hops traversed [2], even with highly-optimized single-cycle routers [3]. Energy consumption has become a ﬁrst order design metric today with the end of Dennard’s scaling. The NoC power already contributes 10-30% [4] of the chip power budget for existing designs and is expected to increase its share with increasing number of cores. Dynamic voltage and frequency scaling (DVFS) is one of the most popular and well-studied techniques for adaptively balancing performance and energy efﬁciency, and is used extensively in processors today, espeFig. 1. (a) Example of single-cycle multi-hop traversal in a SMART NoC (b) A SMART NoC with a lower clock frequency. (c) Energy delay product of a SMART network against uniform scaling of frequency (all routers have same frequency). (d) Qualitative comparison of Mesh, SMART, traditional DVFS, and SMARTDVFS (this work) cially with the integration of fast on-chip voltage regulators. For the same reason, DVFS for NoCs has also garnered a lot of interest recently [5]–[11], [11]–[14]. The key challenge with DVFS though is that it, by deﬁnition, trades-off performance (latency, throughput) for energy-efﬁciency, and is thus used sparingly during moments of low activity. To reduce on-chip latency, the fundamental solution is to reduce the number of hops traversed. High-radix topologies [2] add additional links between distant routers to reduce latency by bypassing intermediate routers. The challenge with this approach, though, is that the multi-ported routers from where these express links originate and terminate add huge energy and area overheads [5]. This is because the energy and area of structures such as the crossbar inside the router scale quadratically with the number of ports; not to mention additional buffers and arbitration logic at each new port. More buffers and wires in the NoC also increases leakage [15]. A recent NoC microarchitecture called SMART [16], [17] proposes to address the aforementioned dependence on hops by exploiting the fact that although interconnect scaling has plateaued compared to logic in modern technology nodes, repeated wires are fast enough to transmit across 10+mm at 978-1-5386-3093-8/17/$31.00 ©2017 IEEE 743 a GHz. Since frequency of NoC routers today and in future will be limited due to the power wall, we can construct singlecycle multi-hop bypass paths across multiple routers. Fig. 1(a) shows an example of a 2-hop path being traversed in one-cycle. The challenge with SMART, however, is that the number of hops that can be bypassed scales down as clock frequency or tile size goes up, limiting its applicability only to domains with small tiles and slow clocks. Moreover, SMART does not directly address the energy challenge of long distance traversal since the same number of routers and links are still traversed as a conventional mesh (albeit in one cycle rather than multiple). In this work, we leverage the idea of asynchronous bypasses in SMART to introduce a new design-space exploration point to DVFS. Compared to a baseline Mesh, traditional DVFS lowers energy at the cost of performance (latency and/or throughput) while traditional SMART improves performance at the same energy, as Fig. 1(d) shows. What if we could get both? We make the following observation: scaling the frequency (i.e., lower energy) in a SMART network can potentially allow packets to bypass more number of hops in one clock cycle (i.e., higher performance), as Fig. 1(b) demonstrates. This design-space of leveraging frequency scaling to dynamically change the distance traversed within a cycle is ripe for optimization, and to the best of our knowledge has not been explored before. Fig. 1(c) illustrates that there could be a potential sweet-spot providing the lowest EDP with increasing frequency, which in turn can enable design points with both lower latency and lower energy than those afforded by just SMART or DVFS alone (Fig. 1(d)). This paper presents a methodology to enable DVFS over SMART NoCs. This introduces new challenges not present in conventional NoC DVFS schemes: • The cycle time for a multi-hop traversal will be longer than that in the baseline design. Moreover, a reduced frequency increases the time spent in each router upon an unsuccessful bypass. Both of these can in fact end up hurting performance of SMART, requiring careful optimization. • Setting up single-cycle multi-hop bypass paths is non-trivial in a domain where multiple-frequency islands exist, multiple nodes operating at different frequencies may want to setup paths, and there is no unique deﬁnition of a cycle. We address both challenges. We also present a simple policy for dynamic voltage-frequency assignment for the SMART DVFS NoC utilizing the multi-hop bypass requests as a proxy of network trafﬁc. Across a suite of synthetic trafﬁc workloads and full-system PARSEC simulations, we demonstrate the same (or better) performance at lower energy and lower EDP, giving an overall win-win. I I . BACKGROUND AND R E LAT ED WORK A. Single-Cycle-Multi-Hop Networks Wire Delay: Single-cycle Multi-hop Asynchronous Repeated Traversal (SMART) NoCs [16], [17] exploit the observation that global repeated wires are fast enough to send signals across 10+ mm within 1ns. SMART NoCs augment mesh routers with a bypass mux (that acts as a repeater) and enable ﬂits to traverse multiple routers asynchronously in one cycle before getting latched, as Fig. 1(a) shows. A ﬂit is the smallest unit of a packet, and equals the link width. The maximum number of hops that can be traversed in a cycle is a designtime parameter known as HPCMAX (maximum hops per cycle), which depends on (a) the underlying repeated wire delay at the particular technology node, (b) the clock frequency, and (c) the tile size. The authors in SMART [17] observed a HPCMAX of 9 to 11 at 45nm at 1GHz with 1mm × 1mm tiles. Operation of a SMART NoC: 1) Cycle 0: Local Switch Allocation (SA-L). Each router performs arbitration among the locally buffered ﬂits just like a regular mesh router. 2) Cycle 1: SMART Setup Request (SSR) and Global Switch Allocation (SA-G). For every winning ﬂit, the router sends a SSR to all the neighboring routers within a HPCMAX neighborhood in the particular output direction (North/South/East/West) the ﬂit wishes to go out from. These requests are sent over a separate set of control wires that span up to HPCMAX hops in each dimension, and are log2 (HPCMAX ) bits wide. The SSR carries the number of hops that the ﬂit wishes to bypass, up to HPCMAX . All intermediate routers perform arbitration among the incoming SSRs as well as the local winner (which would have sent its own SSR). If any of the SSRs for the ﬂit wishing to bypass this router win the arbitration, the bypass mux is enabled. SSRs are prioritized based on distance, with the local ﬂit getting highest priority and the furthest one the least (known as Prio=Local [17]). This means that in case of SSR contention, the bypassing ﬂit would be stopped (by disabling the bypass mux) and the local ﬂit sent out instead on the output link. 3) Cycle 2: Single-cycle Multi-hop Traversal. The ﬂit is sent out from the router and in the best case bypasses all intermediate routers (as Fig. 1(a) and 1(b) show) till the HPCMAX boundary (or destination router). In case of contention, it might get buffered mid-way and re-arbitrate for a multi-hop path in the subsequent cycles. SMART bypasses are opportunistic, subject to contention. No explicit acknowledgement (ACK) is required. All ﬂits use XY routing. Flits wishing to turn ﬁrst request bypass paths along the X dimension till the turning router, and then along Y. B. DVFS in NoC All the existing works on DVFS on NoCs [5], [8], [9], [12]–[14], [18]–[20] try to perform DVFS on lightly loaded routers to minimize the performance penalty of DVFS. DVFS for NoCs also introduce additional design challenges: Bi-Synchronous FIFOs: Bi-synchronous FIFOs enable writes and reads at different frequencies, and are a standard modules required for clock-domain crossings at the router interfaces. However, these introduce additional delays. Multiple Voltage Supply Lines: The existing works on DVFS in NoC assume the use of multiple supply lines for accessing different voltages. However, use of multiple voltage rails requires multiple voltage converters and power distribution 744 (cid:1)(cid:2) (cid:1)(cid:3) (cid:1)(cid:4) (cid:1)(cid:5) (cid:1)(cid:6) (cid:14)(cid:15)(cid:11)(cid:16) (cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:19)(cid:2)(cid:20) (cid:14)(cid:15)(cid:11)(cid:16) (cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13)(cid:19)(cid:2)(cid:22) (cid:14)(cid:4)(cid:11)(cid:16) (cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:19)(cid:2)(cid:22) (cid:14)(cid:4)(cid:11)(cid:16) (cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13)(cid:19)(cid:2)(cid:23) (cid:1)(cid:17)(cid:18)(cid:4) (cid:19)(cid:2)(cid:20) (cid:1)(cid:17)(cid:18)(cid:21) (cid:19)(cid:2)(cid:20) (cid:1)(cid:17)(cid:18)(cid:4) (cid:19)(cid:2)(cid:22) (cid:1)(cid:17)(cid:18)(cid:21) (cid:19)(cid:2)(cid:22) (cid:1)(cid:17)(cid:18)(cid:4)(cid:3)(cid:19)(cid:2)(cid:20) (cid:1)(cid:17)(cid:18)(cid:21)(cid:3)(cid:19)(cid:2)(cid:20) (cid:3) (cid:14)(cid:15)(cid:11)(cid:16) (cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:19)(cid:2)(cid:20) (cid:14)(cid:15)(cid:11)(cid:16)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:19)(cid:2)(cid:23) E = ( (cid:11)(cid:12)(cid:12)(cid:13)(cid:1)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18) (cid:19)(cid:13)(cid:7) (cid:11)(cid:12)(cid:12)(cid:13)(cid:1)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18) (cid:19)(cid:13)(cid:7)(cid:8)(cid:4) (cid:20)(cid:30)(cid:22)(cid:13)(cid:11)(cid:12)(cid:12)(cid:13)(cid:1)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:13)(cid:19)(cid:13)(cid:31)(cid:30)(cid:32)(cid:17)(cid:13)(cid:7)(cid:18)(cid:17)(cid:27)(cid:15)(cid:17)(cid:26)(cid:28)(cid:29) (cid:1)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9) (cid:14)(cid:15)(cid:11)(cid:16)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9) (cid:1)(cid:1)(cid:2)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:1)(cid:1)(cid:2)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:1)(cid:1)(cid:2)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:1)(cid:1)(cid:2)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:14)(cid:15)(cid:11)(cid:16)(cid:3)(cid:2)(cid:10)(cid:8)(cid:10)(cid:11)(cid:12)(cid:10)(cid:13) (cid:7) (cid:7)(cid:8)(cid:5)(cid:9) (cid:7)(cid:8)(cid:10)(cid:9) (cid:7)(cid:8)(cid:4)(cid:9) (cid:7)(cid:8)(cid:6)(cid:9) (cid:20)(cid:21)(cid:22)(cid:13)(cid:11)(cid:12)(cid:12)(cid:13)(cid:1)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18) (cid:19)(cid:13)(cid:23)(cid:24)(cid:25)(cid:25)(cid:17)(cid:18)(cid:17)(cid:26)(cid:16)(cid:13)(cid:7)(cid:18)(cid:17)(cid:27)(cid:15)(cid:17)(cid:26)(cid:28)(cid:29) Fig. 2. Synchronization issue of SSR in a SMART router with arbitrary frequency per router. networks with the area overhead. Our proposed scheme limits the number of unique voltage rails required. DVFS Assignment Policy: As the router associated with a tile/core serves not only the ﬂits injected from that core, but also those from other cores, the DVFS policy of the NoC fabric has to be different from the one for the core. Prior research on DVFS in NoCs has explored various heuristics for Voltage Frequency Island (VFI) assignment. One set of works use NoC metrics to tune voltage and frequency, such as target throughput [12], [21], buffer utilization [22], energy consumption [19], and errors [23]. Another set uses runtime performance of applications for V-F assignment by observing system-level metrics such as coherence messages [6], L1/L2 misses [7], and memory-access density [9]. I I I . MOT IVAT ION AND CHA L L ENG E S A. Performance implications of higher HPCMAX For a SMART NoC, the average network latency of a ﬂit is given by the following equation [17]: T = H H P C tr + H H P C tw + TC (1) where H is the total number of hops, tr is the router pipeline delay, tw is the wire (between two routers) delay, T C is the contention delay at routers. H P C is the achieved hops per cycle, and can be anywhere from 1 (in case the ﬂit has to stop at every router due to contention) to H P C MAX (if it successfully bypasses all intermediate routers). A key insight that the SMART paper presents is that most real workloads do not experience heavy link contention since L1 and L2 caches ﬁlter most requests into the network [4]. As a result, ﬂits are often able to achieve a high H P C , close to H P C MAX . Thus a higher H P C MAX can provide the performance beneﬁts of an all-to-all connected topology, however far the communicating cores may be on chip, via longer bypass paths. B. Energy implications of higher HPCMAX The total energy consumed for sending a ﬂit assuming that it wins both the SA-L and SA-G stages (i.e., no contention) can be represented by the following equation. H ) · [EBU F + ESA−L + H P CM AX · ESSR+ H P C H P C · (ESA−G + EXBAR + ELIN K ) +E BU F ] (2) where the ﬁrst term represents the average number of multihop traversals for a ﬂit while the second term represents the energy spent for each multi-hop traversal. Notice that a multihop traversal only needs to pay buffering costs at the end points. We can clearly see that as the HPC increases, the energy per ﬂit reduces. This in turn makes a case for increasing HPCMAX for lowering energy. C. Implications of lower frequency in SMART Sections III-A and III-B motivate the beneﬁt of higher HPCMAX in SMART NoCs. Recall that H P C MAX is the maximum hops per cycle, and is directly dependent on tile size and operating frequency. Tile sizes and underlying wire delay are design-time and technology parameters which cannot be changed at runtime. One possible way of achieving higher HPCMAX is to lower the NoC clock frequency. Let us examine the performance and energy implications of such a design. In Fig. 2, Router R0 is sending a ﬂit to R4 . Assume that there is no other contending ﬂit. At a NoC frequency of F, suppose the HPCMAX is two. The ﬂit thus has to stop at R2 . The timeline for this traversal is shown in Fig. 2(a). The total traversal takes 7 cycles at frequency F. Now suppose we lower the NoC frequency to F/2. The HPCMAX becomes four. R0 can directly setup a SMART path till R4 without stopping at R2 . The timeline for this traversal is also shown. The latency for this traversal is 4 cycles at frequency F/2, which is 8 cycles in terms of F. The reason for the corresponding increased delay in each router due to the larger clock period. From an energy point of view, this design point can provide a quadratic reduction as the supply voltage in the routers can be lowered. This example demonstrates that in SMART, the performance penalty of lowering frequency is much lower than a baseline mesh, where halving the frequency would have doubled the latency. This enables us to get a lower energy point at close to the same network performance, making it a valuable design point for the DVFS controller, enabling it to scale down frequency more aggressively than it can in a traditional design. D. Synchronization of SSRs If conventional DVFS, as presented by prior works [5], [6], [9]–[11], [23], is applied to a SMART NoC, each individual router can potentially operate at a different voltage-frequency level. In a conventional NoC, such a scenario involves clockdomain crossings at every router through bi-synchronous FIFOs. How would this translate to a SMART NoC with multihop paths? On the datapath, a ﬂit can asynchronously pass through multiple routers on the bypass path; a bi-synchronous 745 SSR signals. The DVFS policy can either aggregate standard network performance metrics like buffer utilization or requestresponse delay over an epoch, or SSRs as a metric representing the network trafﬁc, as we discuss in Section V-C. Per direction VF scaling: Section III-C demonstrated that frequency scaling in SMART can increase the waiting time of ﬂits inside routers. Section III-D highlighted that the frequency of a multi-hop path is limited by the slowest clock on that path. Taking these observations into account, we propose a DVFS enabled SMART NoC with the following properties. 1) We decouple router frequencies from link frequencies. Local arbitration takes place at the router frequency, while multi-hop traversal takes place at the link frequency. This provides a new tuning knob to control the HPCMAX while keeping the router wait-time low. Moreover, router supply voltage can be different than the link driver and receiver voltage. We ﬁnd that lowering router voltage when its frequency is lowered reduces energy, while keeping link voltages high when link frequencies are lowered enables higher HPCMAX values. Together this helps us optimize for both performance and energy, rather than trade one off for the other. 2) We propose to use unique link frequencies for all links along a direction (North/South/East/West) in each row and column of the SMART NoC. The proposed top level architecture is shown in Fig 3. Apart from the local injection/ejection ports, each router has 4 input and 4 output ports and the frequencies of 4 direction of traversals are denoted as FWE , FEW , FNS and FSN . The router frequency is denoted a FR . For example, in any row, all the ﬂits traversing from west to east will synchronized with respect FWE , different from FR . Same frequency along each direction ensures that the SSRs do not have the synchronization issue discussed in Section III-D. If a ﬂit wants to turn, it has to stop and cannot bypass through the router. Each row and column has two frequency controllers that set the clock for two traversal directions. Section V-C discusses how the frequencies of the individual directions are determined. Unlike SMART, where HPCMAX is a design-time parameter, in our design HPCMAX is a runtime parameter that depends on the link frequencies. To account for the maximum possible, SSR wires span the entire row or column in all directions. The width of each SSR wire is log2 (k) for a k×k mesh. B. Micro-Architecture of proposed DVFS SMART router The microarchitecture of our router is shown in Fig. 4. Input Port (VC Buffers and Arbiter): We add a level shifter to each input port due to potential difference in voltage between the router and the link. If an incoming ﬂit cannot bypass the router (based on the result of its SSR arbitration), it is latched at the input buffers. The input buffers are bisynchronous FIFOs where the data is written at the link frequencies and read out at the FR . The input arbiter operates at FR and selects a winner from among the Virtual Channels (VCs) of the corresponding input port. Credit signals are sent at FR and do not need to be re-synchronized. Fig. 3. Architecture of proposed Single-cycle Multi-hop DVFS NoC with decoupled router frequency and per-direction link frequency FIFO is only needed at the router where the ﬂit stops. The control path however introduces a design challenge. SMART requires all routers along the HPCMAX path to arbitrate during SA-G and setup their bypass muxes accordingly. If every router operates at a different frequency, the bypass muxes may not get set correctly before the ﬂit starts its traversal. Fig. 2(b) illustrates this. It shows ﬁve routers in a 1D SMART network, where each router is operating at a different frequency. A SSR is launched by R0 at a frequency of F. Notice that R2 has the lowest frequency (F/5X). R0 needs to wait till R2 completes its SA-G calculation and sets up its bypass mux before it can launch the ﬂit, as Fig. 2(b) shows. In other words, R0 has to wait at least for a period of 1/FMIN , where FMIN is the minimum frequency among the routers within HPCMAX distance of the source router, to ensure that the SSR is ‘seen’ by all the routers. This synchronization issue limits the throughput of the path to that of the lowest router frequency in the bypass path. Moreover, since SMART does not send any explicit ACKs, it is not obvious how R0 would know many of its cycles to wait before sending the data ﬂit. Our proposed microarchitecture addresses these issues. IV. PRO PO S ED N E TWORK ARCH I T EC TUR E A. Control path In coherence with existing works on DVFS on NoC, we have considered two scenarios, i) where the V-F states of every router change together and ii) individual/a cluster of routers have its own V-F states. Both these are described next. Uniform VF scaling: The V-F state of every router in the SMART network is same and determined by a centralized DVFS controller. In this case, as all routers operate at the same frequency, no issues arise due to synchronization of 746 Fig. 4. Micro-Architecture of proposed DVFS router supporting SMART bypasses. The operating frequencies (FR vs. FWE ) for each module are shown. Output Port (Arbiter, Crossbar, Buffer): The output mux (inside the crossbar) is controlled by the output arbiter logic also operating at FR and steers the winning input ﬂit to the corresponding output ports. Although the inputs ﬂits from different directions are traversing at different link frequencies, they are internally synchronized with respect to FR before being steered to the output port. The ﬂit at the output port is written at FR into a bi-synchronous FIFO and read out at frequency of the corresponding direction. Bypass Path: The arbiter for the SSRs (i.e., SA-G) operates at the corresponding link frequency and is also interfaced with a level shifter. Each router has dedicated SSR arbiter per direction. The output of the SSR arbiter drives the mux at the corresponding output port. If the incoming SSR wins the arbitration, the select line of the bypass mux is made high at the next link cycle so that the ﬂit can bypass. (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:7)(cid:11)(cid:12)(cid:1)(cid:13) (cid:14)(cid:15)(cid:16)(cid:1)(cid:17)(cid:7)(cid:9)(cid:18)(cid:19)(cid:20)(cid:7)(cid:8)(cid:21)(cid:20) (cid:12)(cid:22)(cid:23)(cid:24)(cid:12)(cid:1)(cid:25)(cid:26) (cid:14)(cid:14)(cid:1)(cid:7)(cid:4)(cid:2)(cid:7)(cid:5)(cid:27)(cid:28)(cid:4)(cid:7)(cid:12)(cid:6)(cid:2)(cid:29)(cid:7)(cid:1)(cid:30)(cid:31)(cid:30)(cid:7) (cid:14)(cid:16)(cid:32)(cid:33)(cid:7)(cid:27)(cid:4)(cid:7)(cid:1)(cid:30)(cid:31)(cid:30)(cid:7)(cid:1)(cid:30)(cid:31)(cid:34)(cid:7)(cid:1)(cid:30)(cid:31)(cid:35)(cid:31) (cid:1)(cid:30)(cid:31)(cid:36)(cid:31)(cid:7)(cid:1)(cid:30)(cid:31)(cid:26) (cid:37)(cid:38)(cid:39)(cid:27)(cid:28)(cid:28)(cid:7)(cid:23)(cid:19)(cid:27)(cid:40)(cid:21)(cid:5)(cid:41)(cid:7)(cid:42) (cid:1)(cid:30)(cid:31)(cid:34)(cid:7)(cid:1)(cid:30)(cid:31)(cid:35)(cid:31) (cid:1)(cid:30)(cid:31)(cid:36)(cid:31)(cid:7)(cid:1)(cid:30)(cid:31)(cid:26) (cid:12)(cid:21)(cid:18)(cid:4)(cid:7)(cid:17)(cid:6)(cid:27)(cid:43)(cid:5)(cid:6)(cid:28)(cid:18)(cid:19)(cid:44)(cid:7) (cid:7) (cid:12)(cid:21)(cid:18)(cid:4)(cid:7)(cid:9)(cid:27)(cid:4)(cid:5)(cid:45)(cid:46)(cid:5)(cid:41)(cid:7) (cid:42)(cid:7)(cid:16)(cid:28)(cid:38)(cid:19)(cid:45)(cid:7)(cid:34)(cid:7)(cid:1)(cid:35) (cid:30) (cid:24) (cid:17) (cid:47) (cid:8) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:35) (cid:24) (cid:17) (cid:47) (cid:8) (cid:36) (cid:24) (cid:17) (cid:47) (cid:8) (cid:26) (cid:24) (cid:17) (cid:47) (cid:8) (cid:48) (cid:24) (cid:17) (cid:47) (cid:8) (cid:49) (cid:24) (cid:17) (cid:47) (cid:8) (cid:50) (cid:24) (cid:17) (cid:47) (cid:8) (cid:51) (cid:24) (cid:17) (cid:47) (cid:8) (cid:52) (cid:24) (cid:17) (cid:47) (cid:8) (cid:30) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:34) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:35) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:36) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:26) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:48) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:49) (cid:34) (cid:24) (cid:17) (cid:47) (cid:8) (cid:1)(cid:30)(cid:31)(cid:36) (cid:1)(cid:30)(cid:31)(cid:35) (cid:1)(cid:30)(cid:31)(cid:34) (cid:1)(cid:30)(cid:31)(cid:30) (cid:1)(cid:30)(cid:31)(cid:26) (cid:1)(cid:34)(cid:31)(cid:26) (cid:1)(cid:35)(cid:31)(cid:26) (cid:27) (cid:45) (cid:2) (cid:9) (cid:7) (cid:21) (cid:16) (cid:6) (cid:40) (cid:27) (cid:6) (cid:4) (cid:18) (cid:18) (cid:4) (cid:19) (cid:2) (cid:7) (cid:42) (cid:1) (cid:30) (cid:30) (cid:31) (cid:7) (cid:14)(cid:16)(cid:32)(cid:33)(cid:7)(cid:53)(cid:3)(cid:4)(cid:39)(cid:3)(cid:4)(cid:7)(cid:9)(cid:27)(cid:4)(cid:45)(cid:46)(cid:5)(cid:41)(cid:42) (cid:1)(cid:30)(cid:31)(cid:30)(cid:7)(cid:1)(cid:30)(cid:31)(cid:34)(cid:7)(cid:1)(cid:30)(cid:31)(cid:35)(cid:31)(cid:7)(cid:1)(cid:30)(cid:31)(cid:36)(cid:31)(cid:7)(cid:1)(cid:30)(cid:31)(cid:26) (cid:27) (cid:45) (cid:2) (cid:9) (cid:7) (cid:21) (cid:16) (cid:6) (cid:40) (cid:27) (cid:6) (cid:4) (cid:18) (cid:18) (cid:4) (cid:19) (cid:2) (cid:7) (cid:42) (cid:1) (cid:30) (cid:31) (cid:26) (cid:2) (cid:1) (cid:47) (cid:27) (cid:2) (cid:33) (cid:1) (cid:16) (cid:14) (cid:14) (cid:14) (cid:7) (cid:4) (cid:7) (cid:32) (cid:7) (cid:4) (cid:7) (cid:4) (cid:6) (cid:12) (cid:1) (cid:46) (cid:7) (cid:7) (cid:6) (cid:2) (cid:1) (cid:1) (cid:29) (cid:7) (cid:30) (cid:31) (cid:26) (cid:7) (cid:30) (cid:31) (cid:26) (cid:34) (cid:31) (cid:26) (cid:7) (cid:35) (cid:31) (cid:26) (cid:31) (cid:44) (cid:41) (cid:19) (cid:5) (cid:28) (cid:40) (cid:6) (cid:27) (cid:26) (cid:5) (cid:19) (cid:34) (cid:43) (cid:23) (cid:30) (cid:27) (cid:1) (cid:28) (cid:6) (cid:17) (cid:28) (cid:27) (cid:39) (cid:38) (cid:37) (cid:7) (cid:21) (cid:7) (cid:42) (cid:31) (cid:12) (cid:7) (cid:4) (cid:18) (cid:21) (cid:18) (cid:7) (cid:7) Fig. 5. Cycle by cycle activity for ﬂit traversing from R0,0 to R0,4 followed by R0,4 to R2,4 through the proposed NoC. C. Example Operation We demonstrate the operation of the SMART DVFS NoC using examples. In Fig. 5, router R0,0 wants to send a ﬂit to router R2,4 . Let us assume that all routers are operating at FR , the frequency for west to east direction (i.e., FWE ) on Row 0 is FR /4, and the frequency from south to north (i.e., FSN ) on Column 4 is FR /2. For simplicity, assume no contention. Fig. 5 shows the operations that take place during each “cycle” of the router and link clocks for this traversal. 1) The ﬂits at R0,0 performs local arbitration (SA-L) at FR . 2) At the rising edge of the next link cycle (FWE ), the winning ﬂit sends a SSR to the east direction. The SSR performs global arbitration (SA-G) at routers R0,0 , R0,1 , R0,2 , R0,3 and R0,4 following Prio=Local. At R0,0 , this ﬂit wins as it is the local ﬂit. At R0,1 , R0,2 , and R0,3 , the bypass mux is set. If there was a local contending ﬂit at R0,1 , R0,2 or R0,3 , the bypass mux would be disabled due to Prio=Local. 3) At the rising edge of the next link cycle (FWE ), the ﬂit is sent out and it performs a 4-hop traversal, bypassing all the intermediate muxes and crossbars. The ﬂit is latched at R0,4 at FWE and goes through the bi-synchronous FIFO. 4) The ﬂit performs local arbitration (SA-L) at R0,4 at FR . The router frequencies at R0,4 need not be same as that at R0,0 for the design to work. 5) At the rising edge of the next link cycle (FSN ), the ﬂit sends a SSR north. This SSR enables the bypass mux at R1,4 . 6) The ﬂit performs a 2-hop traversal till R2,4 at the rising edge of FSN and gets latched at the next rising edge. V. IM P L EM EN TAT ION A. Circuit Implementation To reduce the transmission energy on the link, we leverage a low-voltage single-ended signaling on the links between the routers [16]. The circuits at the end points of our links are shown in Fig. 4. The Tx operates at the link voltage VL and uses a voltage-locked repeater circuit [16]. The Rx converts the low-swing signal back to VL . In case of a bypass, this signal is directly forwarded to the output port (Fig. 4), else it goes through a level-shifter to transfer it to the router voltage VR and go to the bi-synchronous input FIFO. B. Clock Distribution and Frequency Generation We assume a global clock is distributed throughout the entire chip and is used as the router clock. To generalize the 747 proposed microarchitecture, we have used a bi-synchronous FIFO for each of the incoming and outgoing port. However as multiple works have reported, frequency scaling with scaling factor of power of 2 signiﬁcantly simpliﬁes the design and veriﬁcation of the asynchronous FIFOs [10]. Therefore, the link frequencies are derived from the router frequency using power of 2 (FR , FR /2, FR /4). As the link frequencies are locally generated, following design simpliﬁcations are achieved. • Timing margin is usually quite tight with bi-synchronous FIFOs, if the clock domains are asynchronous. However in this case as the link clocks are synchronously derived FIFO design is simpliﬁed. Similarly timing closure through synthesis and place-and-route becomes simpler. • For clock distribution, we use a two-bit frequency id (FID ) per direction per row/column, which is sent to every router. For example, F1WE determines the link frequency of the west to east links in row 1 (Fig. 3) and is distributed across all the routers in row 1, which locally generates the corresponding clock for launching the data across the link (FWE ). C. Frequency Controller Router vs. Link Frequency: Our architecture requires the same link frequency across the entire direction in each row and column. Each row and column can independently set their own frequencies. This can be done statically or dynamically. Each router can operate independently at its own frequency FR and the design will be functionally correct without any synchronization issues. However, if FR is lower than the frequency of any of its outgoing links, the effective link frequency will become limited by FR . This is because local arbitration (SA-L) occurs at FR . Thus we recommend setting FR≥ max(FWE , FEW , FNS , FSN ). Per-Direction Link Frequency: We provide a unique control knob to the NoC, not available in traditional designs, where we can change the frequency of individual rows/columns and get lower energy points for the same performance. In prior works, the policy of assigning voltagefrequency (VF ) states typically uses accessible network metrics as discussed in Section II-B. In a SMART NoC, the network congestion can also be estimated by observing the total number of SSRs sent by the routers. We propose to use the structure shown in Fig. 3 for estimating the trafﬁc in each direction in each row/column. The valid bit of all SSRs spanning a direction enter the Link Frequency Controller (LFC). For every SSR that is initiated, an accumulator in its corresponding LFC is incremented by one. Over a conﬁgurable time-epoch, the LFC uses the accumulator count to determine if the link frequency in that direction needs to change. A unique designpoint in SMART DVFS is whether higher SSR activity should lower or raise the frequency, since that trades off HPCMAX versus link throughput. We experiment with both design points in our evaluations. V I . EVALUAT ION We use the gem5 + Garnet [24] infrastructure for all our evaluations, which provides a cycle-accurate NoC timing model. Network energy is calculated using DSENT [25] where we model components corresponding to SMART and our additions. The energy of the low-swing transmitter-linkreceiver is estimated from chip measurements [16]. Target System: For synthetic trafﬁc, we model a 256core system. Full-system runs use a 64-core system. We model a 32nm technology node, and choose a clock frequency of F=2GHz. We observe a baseline HPCMAX of 4 at this conﬁguration [17] which we validate via DSENT. We use the following (V,F) conﬁgs: (1V, F), (0.9V, F/2), (0.75V, F/4). System Conﬁguration: We use the following naming scheme: MESH-FX is a regular mesh with X as a factor by which Router frequency (FR ) is scaled down; SMART-RXLY is a SMART topology with FR scaled down by X and all the link frequencies (for every direction) are scaled down by Y; SMART-R1Dyn is a SMART with routers operating at the highest frequency and per-row-column per-direction frequencies set by our LFC (Section V-C). A. Synthetic Trafﬁc Performance: The proposed network is ﬁrst evaluated against synthetic trafﬁc patterns. The results for bitcomplement trafﬁc are shown in Fig. 6. First the MESHFX systems are compared with SMART-RXLX systems, i.e. SMART systems with routers and links assigned to the same frequency. The baseline SMART system (SMART-R1L1) achieves lower low-load-latency than MESH-F1, as already demonstrated before [17]. However uniformly reducing frequencies both in SMART and MESH behaves differently. While in MESH-F2, the low-load latency is doubled and the network throughput is almost halved, SMART-F2 resulted in an improved throughput than MESH-F2 with a low-load latency of 17.68, which is still lower than the low-load-latency of 22 cycles for MESH-F1. This clearly demonstrates the potential of adjusting router and link frequency uniformly while maintaining an acceptable network throughput. At ultralow injection rate, a SMART-R4L4 will have similar latency with MESH-R1L1 with a signiﬁcant amount of energy beneﬁt. We note that uniformly scaling router and link frequency works seamlessly with the baseline SMART design [17]. Next, taking advantage of our proposed router microarchitecture, we evaluate SMART-R1L2 and SMART-R1L4. SMART-R1L2 achieves a lower load-load latency and SMART-R1L4 achieves a similar latency compared to SMART-R1L1 which is attributed due to higher hops per cycles, and reduced time spent at the intermediate routers compared to SMART-R2L2 and SMART-R4L4. The saturation throughput of SMART-R1L2 and SMART-R2L2 are similar. This is attributed to the fact that the router can only send packets every two cycles for both these networks, therefore at sufﬁciently high injection rate, backpressure builds up at NIC-router buffer and limits the throughput. Uniform vs. Per Row/Column Frequency Allocation: From the previous observation, one can see that reduced link frequency helps in lowering low-load latency, however network throughput remains unaffected. The most congestion in a Mesh happens typically at the middle of the network 748 Fig. 6. Performance of proposed network with bit-complement synthetic trafﬁc for different ﬂit-injection rate (System: 16x16 Mesh with XY routing). Fig. 7. Performance with uniform random trafﬁc in a 16x16 mesh Fig. 8. Impact of HPCMAX on network delay (at low injection rate, bitcomplement synthetic trafﬁc, 16x16 mesh) for most synthetic trafﬁc patterns [18]. To improve the network saturation rate, our link frequency controller assigns the highest link frequency to the links crossing the center of the network whereas the links near the periphery of the network operate at lower frequency. The average latency plot shows that the low-load-latency of SMART-R1LDYN is similar to SMART-R1L1 and SMART-R1L2. The worst case latency across a network for bit-complement trafﬁc is along the periphery of the network which remains unaffected. However, we observe an improvement in the latency near the saturation rate, due to higher link frequencies at the center. The ﬁnal saturation rate still remains the same. Fig. 7 shows the network performance for a uniform random trafﬁc. The injection rate of network saturation increases uniformly for each conﬁguration, however the trend between the conﬁgurations remains same. Fig. 8 shows the improvement in average network latency for the different conﬁgurations as HPCMAX is increased from 4 to 5 and 6. SMART-R1L1 and SMART-R1L-DYN has Fig. 9. Total Network Dynamic Energy (at low injection rate, bit-complement synthetic trafﬁc, 16x16 mesh) the maximum improvement, as links operate at the highest frequency with the least HPC. The improvement reduces for SMART-R1L2 and SMART-R2L2. All SMART conﬁgurations with link frequency FR /4 do not show any improvement as these conﬁguration has a HPCMAX=16 due to 4X lower frequency and increasing HPC does not improve throughput for a 16x16 Mesh as only one dimensional bypass is enabled. Energy: Fig. 9 shows the normalized (with respect to SMART-R1L1) energy breakdown of the system. A baseline MESH (MESH-F1) design has higher energy consumption, than SMART-R1L1. Link energy remains same for all conﬁgurations as under all bypass schemes, the ﬂits passes through the same number of links for a given routing scheme. For SMARTR2L2 and SMART-R4L4, the router energy reduces both due to voltage scaling as well as reduced router activity for higher HPCMAX . Router energy also reduces for SMART-R1L2 and SMART-R1L4 (no voltage scaling applied) as buffer energy, which is the most signiﬁcant fraction of the router energy reduces due to more number of ﬂits being able to bypass the intermediate routers due to a higher HPCMAX . SMARTR1LDyn shows higher energy as the frequency selection algorithm assigns link frequencies from either FR or FR /2, however due to low injection rate, the dynamic frequency selection does not help network congestion. Fig. 10 shows the normalized (with respect to SMART-R1L1) delay-vs-energy plot for different conﬁgurations. Clear trends can be seen here. Traditional DVFS (MESH-F2) lowers energy at the cost of delay. Uniform frequency scaling associated with router voltage scaling (SMART-R2L2 and SMART-R4L4) improves energy, however increases delay. For our proposed router and link frequency decoupled schemes (SMART-R1L2 and SMARTR1L4), a lower network latency with lower energy is achieved demonstrating the beneﬁt of our proposed methodology. 749 SMART DVFS schemes it remains fairly constant all schemes, enabling lower-energy designs at the same performance. V I I . CONC LU S ION In this work we make a case for running single-cycle multihop NoCs at lower link frequencies than the rest of the subsystem to enable ﬂits to traverse chip dimensions within one clock cycle. We demonstrate an architecture that provides energy-efﬁciency with same (or better) overall performance, unlike traditional DVFS schemes that need to trade-off latency against energy. This work opens up a novel design-space of tuning traversal distance with clock frequency and can pave the way for research in energy-efﬁcient high-performance NoCs and DVFS policies for the dark silicon era. "
2017,A load balancing inspired optimization framework for exascale multicore systems - A complex networks approach.,"Many-core multi-threaded performance is plagued by on-chip communication nonidealities, limited memory bandwidth, and critical sections. Inspired by complex network theory of social communities, we propose a novel methodology to model the dynamic execution of an application and partition the application into an optimal number of clusters for parallel execution. We first adopt an LLVM IR compiler analysis of a specific application and construct a dynamic application dependency graph encoding its computational and memory operations. Next, based on this graph, we propose an optimization model to find the optimal clusters such that (1) the intra-cluster edges are maximized, (2) the execution times of the clusters are nearly equalized, for load balancing, and (3) the cluster size does not exceed the core count. Our novel approach confines data movement to be mainly inside a cluster for power reduction and congestion prevention. Finally, we propose an algorithm to sort the graph of connected clusters topologically and map the clusters onto NoC. Experimental results on a 32-core NoC demonstrate a maximum speedup of 131.82% when compared to thread-based execution. Furthermore, the scalability of our framework makes it a promising software design automation platform.","A Load Balancing Inspired Optimization Framework for Exascale Multicore Systems: A Complex Networks Approach Yao Xiao, Yuankun Xue, Shahin Nazarian, Paul Bogdan Department of Electrical Engineering University of Southern California, Los Angeles, CA, USA {xiaoyao, yuankunx, shahin.nazarian, pbogdan}@usc.edu Abstract—Many-core multi-threaded performance is plagued by onchip communication nonidealities, limited memory bandwidth, and critical sections. Inspired by complex network theory of social communities, we propose a novel methodology to model the dynamic execution of an application and partition the application into an optimal number of clusters for parallel execution. We ﬁrst adopt an LLVM IR compiler analysis of a speciﬁc application and construct a dynamic application dependency graph encoding its computational and memory operations. Next, based on this graph, we propose an optimization model to ﬁnd the optimal clusters such that (1) the intra-cluster edges are maximized, (2) the execution times of the clusters are nearly equalized, for load balancing, and (3) the cluster size does not exceed the core count. Our novel approach conﬁnes data movement to be mainly inside a cluster for power reduction and congestion prevention. Finally, we propose an algorithm to sort the graph of connected clusters topologically and map the clusters onto NoC. Experimental results on a 32-core NoC demonstrate a maximum speedup of 131.82% when compared to threadbased execution. Furthermore, the scalability of our framework makes it a promising software design automation platform. I . IN TRODUC T ION The tight power and thermal constraints call for ﬁne-grained exploration of chip multiprocessors (CMPs) and data-center-on-achip [2] to provide performance improvement in exascale computing. To make use of CMPs, software paradigms have been shifted from sequential programming to multi-threading. However, three fundamental inefﬁciency issues can appear if threads are spawned without careful consideration of the underlying hardware. (1) Non-negligible on-chip communication overhead. With applications being randomly partitioned, plenty of inter-core communications are generated, leading to many ﬂits injected into the network. Those ﬂits are unwanted as none of them would exist with running the application in only one core. Therefore, intelligent application partitioning is required to minimize inter-core communication overhead. (2) Limited off-chip memory bandwidth. Due to limited offchip memory bandwidth, the performance of data-intensive multithreaded programs is negatively affected due to frequent updates in the main memory. A critical thread may be delayed due to race conditions to access the main memory simultaneously. Increasing the number of threads to the point of off-chip bandwidth saturation degrades the power consumption with no performance increase. (3) Increased critical sections. Locks are used to prevent multiple threads from writing to shared variables simultaneously to guarantee the correctness of a multi-threaded program. In other words, due to synchronization, the serial portions of the program increase. According to Amdahl’s Law, speedup is limited by the sequential parts. Therefore, as more threads are spawned, thread-based execution could potentially become slower compared to sequential execution. In this paper, the goal is to design a novel methodology to 978-1-5386-3093-8/17/$31.00 ©2017 IEEE automatically parallelize complex programs without increasing the programmer’s efforts. Considering the three pitfalls mentioned previously, we propose a complex network based parallelization framework to partition applications into highly interdependent clusters of tasks representing communities1 in a graph rather than threads such that the amount of data transferred among communities is minimized. As shown in Figure 1, we ﬁrst construct the weighted dynamic application dependency graph where the nodes denote individual low level virtual machine (LLVM) intermediate representation (IR) [13] instructions generated by Clang compiler, and edges represent data dependencies between different instructions on the same virtual registers. Edge weights represent latency (L1 hits, L1 misses, or L2 misses assuming there is a shared L2 cache among cores) and data sizes (1, 2, 4, 8 bytes, cache line, or memory page). Second, based on the constructed graph of IR instructions we present the mathematical optimization model to detect community structures ensuring that (1) the number of inter-cluster communication ﬂits is minimal; (2) communities reach approximately equalized execution times; (3) the number of communities is smaller than or equal to the number of cores. Third, having calculated the optimal communities and their dependencies, we construct a cluster graph where nodes indicate communities. We then use topological sort to map the clusters onto the NoC, while ensuring that the clusters at the same depth are executed in parallel. In case the number of clusters is smaller than the core count, the rest of the cores are shut off using power gating. There are three primary issues that cause performance degradation in parallel computing: (1) load imbalance, (2) resource sharing, (3) synchronization. Our framework mitigates these three bottlenecks by a robust real-time aware optimization approach that (1) prevents the difference of execution times between two consecutive clusters from being too large considering cache miss cycles and data sizes for memory instructions, (2) conﬁnies most of data movement within each cluster as the framework tries to partition the dependency graph into clusters with maximized intra-cluster communications, making better use of caches. Moreover, mesh-based NoC is used to route ﬂits efﬁciently for cases where a core requires variables stored in another core’s caches, and (3) applies pipeline parallelism to parallelize sequential applications rather than multi-threading to reduce synchronization overhead caused by threads with locks and barriers. Towards this end, our main contributions are as follows. • We present an architecture-independent application proﬁling approach that identiﬁes the IR-level data dependency of one application and represents it as a dynamic application dependency 1Of note, throughout the manuscript, we use the terms ""community"", ""cluster"", and ""subcomponent"" as synonyms. 978-1-5386-3093-8/17/$31.00 ©2017 IEEE 217 Figure 1: Overview of the framework. A: Input C/C++ applications. B: A compiler based parser obtains the dynamic LLVM IR instructions from C/C++ applications. C: Construct a DADG by analyzing the dependencies between LLVM IR instructions. The DADG nodes represent IR instructions; edges represent dependencies between instructions; weights are collected by instrumenting a lightweight function rdtsc() and some inlined code to ﬁnd the latency and data size for memory operations. Weights for the rest of instructions are set to 1. D: We develop a mathematical optimization model to partition the DADG into several clusters considering maximum intra-cluster edge weights, load balancing, and availability of hardware resources. E: We map clusters onto NoC based on Topological Sort for parallel execution. graph (DADG). graph based on inter-linear programming (ILP). On a different • We propose a complex-network inspired framework to automatidirection, ﬁne-grained parallelism is also exploited by synthesis or cally parallelize the execution of the application with minimized reconﬁguration of the communication and computation architectures inter-core trafﬁc overhead by intelligently partitioning DADGs best-ﬁt to the learned application structures. Xue et al. [24] unify the into networked (distributed) processing communities. learning of application task structures with optimized reconﬁguration • We develop a power-aware scheduling and mapping algorithm of NoC-based multi-core system in a general mathematical model that parallelizes the execution of the clusters on an NoCthat provides guaranteed optimality. Despite signiﬁcant research debased multi-core platform with optimized power consumption velopments that take advantage of applications parallelism at different via power-gating. levels or on different platforms, we propose a radical approach that The rest of the paper provides the related work, preliminaries, explores the IR instruction-level ﬁne-grained parallelism in order to complex network based parallelization framework, simulation results, guide the design and optimization of multi-core platforms. and conclusions in successive sections. I I I . PR E L IM INAR I E S I I . R E LAT ED WORK In recent years, there has been a surge of efforts in exploiting ﬁne-grained parallelism and minimizing the execution overhead (e.g., energy, runtime, thermal and communication cost) of applications on multi-core systems by optimizing the task-to-core mapping and scheduling based on the application task structures. To take advantage of the graphical models of parallel applications, prior efforts focus on both runtime and static extraction of execution dependency structures at task [18][21][23] or dataﬂow [14] level for both conventional and NoC-based multi-core systems. Based on the knowledge of the inter-dependencies among different tasks or threads, the optimal modeling, parallelization, scheduling, mapping and data routing of an application on a given architecture is further investigated from a wide spectrum of perspectives. For high-level modeling and control of multi-core systems, the authors in [3] propose a complex dynamics approach to characterize the workloads for dynamic optimization of performance, power and thermal overhead. Leveraging the learned dependency structures, ﬁne-tuned scheduling and mapping strategies are also well studied for task and thread execution [7][9][22], memory access [26], energy efﬁciency [4] on both homogeneous and heterogeneous multi-core systems at both design and execution time [19]. For automatic parallelization at the task level on general purpose platforms, Fonseca et al. [10] propose a framework to automatically perform parallelization of sequential Java programs by identifying data access patterns and control ﬂow information. Similar idea is proposed in Li et al. [15] by discovering code sections which can run in parallel, and ranking those parallel targets to provide feedback to users. Cordes et al. [5] extend the automatic parallelization to embedded systems by leveraging a hierarchical task dependency In this paper, we describe a complex network based framework to parallelize sequential programs by constructing the corresponding dynamic application dependency graph (DADG), identifying edge weights between dependent instructions, and guiding the clusterto-core scheduling and mapping while balancing the workload and minimizing the data movement. Therefore, in this section we provide preliminaries on pipeline parallelism to speed up applications and mathematical models to detect communities. A. Pipeline Parallelism Pipeline parallelism [20] is a technique where instructions inside the outer loop are split into stages preserving serial semantics, which are assigned to different cores in order to be executed in time-sliced fashion like hardware pipelining. In Figure 2, a sequential program is partitioned into three stages with distinct features. For example, to compress ﬁles, ﬁrst stage is to open one ﬁle; second stage is to compress all words in the ﬁle; and the third segment is to write compressed words into another ﬁle. Without parallelism, we can only compress one ﬁle in three time units assuming all three stages have the same execution times. However, with the help of the compilers and programmers, pipeline parallelism can be achieved by inserting software buffers between two stages to store the intermediate results. For each iteration, stage 1 enqueues data necessary for stage 2 in the current buffer (pipe). The data, when required, is dequeued into the stage 2 for processing but at the same time stage 1 operates on the next iteration. This way, the overall speedup is nearly the number of stages in each program. One caveat is that producing too many stages increases communication overhead including enqueue and dequeue operations. 218 order to achieve better performance, one cannot assume to use all of available cores. This paper proposes a new parallelization framework based on concepts in complex network to obtain the optimal number of clusters with minimal inter-cluster edge weights based on the datadependent structures of each application. IV. COM P L EX N E TWORK BA S ED PARA L L E L I ZAT ION FRAM EWORK The proposed parallelization framework consists of three stages. In the ﬁrst stage, an application is ﬁrst analyzed by the LLVM compiler to construct a DADG by collecting the dynamic LLVM IR traces and identifying the interdependencies between computation and memory operations. In the second stage, the constructed DADG is partitioned into clusters based on the identiﬁed network communities with the balanced workloads. Finally, the partitioned application is scheduled and mapped to different cores in an NoC-based multi-core system for parallel execution. A. Spatio-Temporal Interdependency Description of Computations and Communications To describe the spatio-temporal interdependencies between the computations and memory operations, we adopt an architecture independent LLVM IR [13][18]. The rationale for adopting this compiler framework is that it is a language-independent type-system that exposes the primitives used to implement high-level language (HLL) features. It includes an instruction for typed address arithmetic, and a mechanism for implementing the exception handling HLL features. Furthermore, IR is crucial in LLVM. It is an abstract machine language which mimics the basic computations, memory operations, and branch instructions with unlimited virtual registers to prevent register spilling. Therefore, backends can easily produce from IR, machine code suited for any target platform regardless of ARM in portable mobiles or x86 in laptops and high-end servers. As shown in Figure 1, there are several features for our approach: IR instructions are collected dynamically. Static compilation has several drawbacks. (1) Memory operations are difﬁcult to detect dependencies, which could potentially increase communication overhead if we map dependent memory operations onto different cores. (2) The number of iterations in one loop sometimes cannot be statically determined. Depending on how many iterations one loop has, load imbalance appears between different clusters. Therefore, rather than static compilation, dynamic execution traces are collected to reﬂect true dependencies and break one loop into several iterations executing sequentially, increasing the chances of grouping different iterations into clusters. Memory operations are instrumented to get correct values for latency and data sizes. The store and load instructions have different execution times and data sizes if data required to fetch reside in L1, L2, L3, or main memory. Taking into account those values could potentially group computations and memory operations with the same registers into one cluster, leading to more efﬁcient use of caches and less communication overhead. In this way, load balancing is achieved by explicitly formulating weight constraints in an optimization model. The parser collects C/C++ essential instructions within an outer loop and constructs a DADG from dynamic traces generated by the compiler. In the parser, we maintain three hash tables called source table, destination table, and dependency table respectively. The source/destination tables are used to keep track of source/de-stination registers with keys being source or destination Figure 2: From sequential execution to pipeline parallelism Figure 3: Community detection. Three communities are detected based on the maximum number of intra-community edges. B. Community Detection Community structures [16] refer to the grouping of nodes with high density of edges inside each community, shown in Figure 3. It is of great signiﬁcance to detect those structures for which scientists can ﬁnd self-similarity [25] of groups of nodes, for example, in social networks. To detect common structures, hierarchical clustering [11] is applied based on similarity of nodes. This technique is categorized into two classes: agglomerative and divisive [17]. In an agglomerative method, initially each node belongs to one cluster. Later more and more nodes are merged together depending on the high connectivity between nodes. In a divisive approach, starting from the original network, only edges between nodes with low similarity are removed to form clusters. However, modularity [11] has been proposed and proven to be more efﬁcient compared to the above-mentioned methods. Modularity-based community detection is basically an optimization problem where given a complex graph, we want to maximize the following quality function Q to get the best ﬁtting clusters [17]: n(cid:2) Q = (eii − ai 2 ) (1) i=1 (cid:3) where n denotes the number of communities in a network; eij denotes the number of edges cluster i connects with cluster j ; and ai denotes the number of all edges cluster i connects with all clusters including itself, which can be expressed as ai = j eij . Therefore, modularity is based on a quality function to calculate the number of edges which falls within clusters minus the expected number of edges in a random graph with the same expected degree for each node [11]. Despite its beneﬁts, community detection strategies have not been exploited in parallel computing to discover the communities of intensive processing and inter-dependencies among instructions. Nevertheless, we think that due to synchronization overhead, limited off-chip bandwidth, and complex on-chip communication trafﬁc, in 219 Figure 4: The ﬂow chart of constructing a DADG registers and values being the corresponding line number. The dependency table is to store dependencies between nodes with keys being the line number for current instruction, and values being clock cycles, data sizes and line numbers of previous instructions dependent on the same virtual register. The parser instruments the lightweight rdtsc function and some inlined code to collect the attributes of memory operations, i.e., data sizes and clock cycles as edge weights. Example: In Figure 5, twelve IR instructions are generated by the compiler Clang. As soon as the parser reads the ﬁrst instruction in Figure 5, it checks source registers as indicated in Figure 4. Since this instruction does not have the source register, then only the destination register is hashed into the destination table with keys being %1 and values being 1. Instructions 2 and 3 follow the same procedure as the ﬁrst instruction. When the parser reads the fourth instruction2 , it checks whether the source registers in the instruction match with any destination registers in previous instructions. In this case, the source register %1 matches with the same destination register in node 1. Thus, this is hashed into the dependency table with keys being 4 (the line number of the current instruction), values being 1 (the line number of the previous instruction which depends on the source register %1), and weights being 1 (non-memory operations). The dependency table can be regarded as a DADG in which keys represent nodes and key-value pairs indicate directed edges. B. Mathematical Optimization Model In order to propose a rigorous mathematical strategy for parallelizing applications, we build on our architecture independent spatiotemporal DADG representation of an application and formulate a novel community detection problem that seeks to: (1) Determine a strongly connected subcomponent of the DADG that encapsulates strong causal dependencies between computations and memory operations dependent on registers in computations yet is complex enough to require localized specialized processing elements (functional units in cores or accelerators) and corresponding memory systems; (2) Perform load balancing by distributing computations and related memory operations among the identiﬁed computational communities to improve system performance under uncertain inputs on average; (3) Minimize the deviations between the number of strongly connected 2Registers %SIZE and %1 are hashed into the source table to prevent from violating true memory dependencies. Register %1 is hashed into the destination table. Figure 5: Comparison among different partitions communities (subgraphs of the DADG) and the hardware resources (cores or accelerators). To make the discussion more concrete, we introduce a series of deﬁnitions that help us construct the community detection problem as follows. Deﬁnition 1: A dynamic application dependency graph (DADG) is a weighted directed graph G = G(ni , eij , wij |i, j ∈ |N |) where each node ni represents one LLVM IR instruction, and each edge eij , associated with different weights wij , characterizes dependency from the current node ni to the previous node nj or control ﬂow such as jump and branch to guarantee the strict program order. Deﬁnition 2: A weight wij between node i and j is deﬁned as latency function T (eij ) times data size D(ni ). Latency function T (eij ) calculates the latency from node i to node j based on the Likewise, data size D(ni ) calculates the number of bytes node i timing information for memory operations provided by the compiler. requires to transfer from one location to another location (possible locations are disk, main memory, caches, processor registers). Deﬁnition 3: A quality function Q for DADGs is an indicator of how good a grouping of clusters for parallel execution is based on load balancing, available hardware resources, and data movement. Using these deﬁnitions, the mathematical optimization model in terms of intelligently partitioning DADGs can be formulated as follows: Given a DADG G , ﬁnd non-overlapping clusters nc which maximize a quality function Q 3 : Q = nc(cid:2) c=1 (c) [ W W (c) − ( S 2W )2 ] − R1 − R2 R1 = λ1 W 2 nc(cid:2) c=1 [Wc − Wneighbor(c) ]2 R2 = λ2 n2 c (nc − N )2 H (nc − N ) (2) (3) (4) W where nc denotes the cluster size; N denotes the core count; (c) denotes the sum of weights all connected within cluster c (W j∈c wij ); W is the sum of weights of all edges (c) = i∈c (cid:3) (cid:3) 3Note that the formula is used for undirected networks. We think this is a simple way to model directed networks. 220 Figure 6: Mapping clusters onto NoC for parallel execution. First, we convert the representation of the cluter graph into the ordering graph by Topological Sort. Topological Sort, essentially, reorders a directed acyclic graph (DAG) based on the rule that for every direct edge eij between nodes i and j , i comes before j in the ordering graph. Then, we map nodes with no incoming edges in the ordering graph onto NoC, making sure nodes and their neighbors should be adjacent to each other to reduce the transmission distance. (cid:3) (cid:3) i c (cid:4) (W = W 2 , 1 n2 j wij ); S (c) is the sum of weights of all the edges adjacent to cluster c; λ1 and λ2 are regularization parameters; neighbor(c) denotes clusters connected to the cluster c; H (x) is the Heaviside step function (H (x) = x−∞ δ(s)ds); δ(x) is the Dirac delta function. Intuitively, the ﬁrst term in equation (2) aims to maximize the intra-cluster weights and reduce the communication requirements among different clusters. The second and third terms aim to balance the computational (processing) requirements for each core and account for the limited number of hardware resources imposed by pipeline parallelism. Similar to prevention of over-ﬁtting in machine learning, R1 and R2 are regularization terms and 1 are used to make sure those terms have the same unit: (1) The ﬁrst term in equation (2) limits data movement almost within each cluster. It measures the difference between the sum of edge weights in a cluster and the sum of edge weights adjacent to the cluster. Through maximization of this term, we try to ﬁnd partitions where data movement is constrained. (2) R1 is used for load balancing. By measuring the sum of the deviation squared between the total weights in a cluster c and its neighbors, R1 is magniﬁed and the value of Q is reduced if clusters have unbalanced weights. Therefore, by maximizing Q, R1 is meant to be minimized by equalizing works in clusters c and its neighbor. Therefore, we try to balance the weights/work between different clusters, making stages in pipeline parallelism have roughly equalized execution times. (3) R2 is used to ensure the number of clusters doesn’t exceed the core count. (nc − N )2 means if the number of clusters nc is different from the number of available cores N in a system, Q is further reduced. However, H (nc − N ) takes a value of 0 until nc equals N , and then has a value of 1 if nc is greater than N . Hence, R2 is large only when nc exceeds the number of cores in the system. If nc is less than N , H (nc−N ) = 0 and the rest of idle cores are turned off to save energy while providing the best performance. Therefore, in order to maximize Q, R2 should be minimized by making sure that nc (the number of communities) is slightly less than N (core count). (4) For regularization parameters λ1 and λ2 , both can be adjusted during run-time. If λ1 = λ2 = 0, the quality function Q is reduced to a standard model without considering balanced works and available resources. If λ1 , λ2 are very large numbers, the ﬁrst term in equation (2) can be ignored, and the model tries to detect communities such that balanced works and nc less than N are achieved without evaluating the maximum communication messages restricted within one community. Therefore, values of λ1 and λ2 should be somewhere in-between. In section 5.2.2, we will show some results regarding the effects of different values of parameters on the number of clusters and execution times. The advantages of applying the mathematical optimization model to partition sequential programs are: (1) Minimal programmer’s efforts to write parallel programs to exploit the speedup provided by multi-core chips. (2) Easy to detect independencies at the granularity of IR instructions and balanced load among clusters. (3) Limited communication overhead in NoC leading to small chances of congestion. As shown in Figure 5, mapping the entire application into one core would mean no communication overhead among cores, but this approach cannot improve performance as the other core is being idle all the time. The second method is just to partition the graph randomly. However, this random partitioning can cause signiﬁcant communication overhead among cores, making cache utilization and performance poor. The last one can group many instructions into clusters such that the number of inter-cluster ﬂits is minimized. Data movement is restricted by keeping data locally as much as possible to save energy and improve performance. C. Mapping Determining the optimal number of clusters raises the question on how to map them onto the NoC such that (1) hop count of communicated ﬂits among clusters is minimized and (2) independent clusters can be executed in parallel. A cluster graph (CG) is constructed where nodes represent clusters and edges indicate data dependencies. There are two properties associated with CG. (1) CG is directed: As there should be an order in which tasks are executed due to program sequential semantics, one task waits data provided by the other tasks until it is executed, leading to a directed graph. (2) CG is acyclic: One cluster depends on data which are generated from its previous clusters. Based on the directed and acyclic graph, we sort CG topologically to ensure that for any directed edge (v , w) in E ∈ CG, v precedes w in the ordering, which can be expressed as an Ordering Graph (OG). Based on OG, clusters are mapped into NoC for pipeline parallelism. In conclusion, we propose the following algorithm which is a combination of Topological Sort and mapping. Algorithm 1 exploits parallelism and pipelining. We deﬁne depth of cluster v in OG as the number of edges from v to its root, and level of cluster v as the number of clusters at the same depth as v . Therefore, (1) Depth of i represents a stage i + 1 in pipelining. In Figure 6, clusters 2 and 3 in OG at the depth of 1 represent 2nd 221 stage while cluster 4 at the depth of 2 represents 3rd stage. Moreover, cluster 4 cannot be executed before clusters 2 and 3 as it waits data generated by 2nd stage. (2) Different levels at the same depth of i represent the number of clusters which can be executed in parallel. In Figure 6, clusters 2 and 3 at the stage 2 can be executed in parallel as they both only depend on availability of data produced by cluster 1. After mapping, if there are still idle cores, to save power consumption, those cores are turned off using power gating. Algorithm 1 Mapping Algorithm Input: Clusters and their dependencies in CG = (V , E ) from Section 4.2 Output: Mapping of clusters in CG into NoC 1: C ounter = 0 2: while CG is not empty do Vpartial = No_Incoming_Edges (CG) if C ounter == 0 then Map Vpartial to (0, 0) Map Vpartial to their nearest parent clusters based on 8: Greedy Heuristic Running_In_Parallel (Vpartial ) Delete Vpartial from CG C ounter++ 13: end while 14: if There still exist idle cores C in NoC then Power_Gating (C ) 15: 16: end if 3: 4: 5: 6: 7: 9: 10: 11: 12: else end if Table I: Conﬁguration parameters CPU Network cores OOO, 2-wide issue, 16 MSHRs L1 private caches 64KB, 4-way associative, 32-byte blocks L2 shared caches 256KB, distributed across nodes Topology Mesh Routing Algorithm XY routing Flow Control Virtual channel ﬂit-based Table II: Benchmarks and descriptions Benchmark Mandelbrot MM.1 Stencil MD FFT Dijkstra Blackscholes FFT6 MM.2 qSort Source OmpSCR[8] Description Calculate Mandelbrot Set Simple matrix multiplication 2D nine point stencil operation SHOC[6] Simulate molecular dynamics OmpSCR[8] Compute Fast Fourier Transform OmpSCR[8] Find the shortest path MiBench[12] Calculate European options PARSEC[1] Compute 1D FFT OmpSCR[8] Strassen’s matrix multiplication Quicksort algorithm OmpSCR[8] is very high due to array operations. One cluster should be centered on at least one of those nodes. As we can see in Figure 7, we can infer that we have at least three distributed arrays and operations on one array barely depend on those on another arrays. However, low discernible DADGs are difﬁcult to be seen as interconnected clusters clearly to humans. Those applications are hard to be parallelized by programmers. One of examples is blackscholes. Therefore, we apply the parallelization framework to those applications to reduce programmer’s efforts, making it practical to be executed in parallel. In Table 3, average degree measures the sum of the number of edges incident on each node divided by the total number of edges. The reason why average degree is around 2 is that the number of edges in DADGs depend on the number of source registers. Almost all IR instructions except call functions have only one or two source registers, making DADGs sparse. 2) Effects of λ1 and λ2 on Load Balancing and Cluster Count: To illustrate the effects of different values of λ1 and λ2 on load shown in Figure 10. |R1 | is the second term used in equation 2, balancing and cluster count, results regarding 10 applications are meaning sum of the difference of loads between two consecutive clusters. The higher |R1 |, the worse load balancing. In Figure 8, from ﬁgures in the ﬁrst column, |R1 | has its peak when λ1 = 0. However λ1 can be adjusted to ﬁne-tune the load difference among clusters, making tasks more balanced. After λ1 approaches some threshold, |R1 | plummets to 0 as R1 is becoming the dominant term in equation (2) compared to the ﬁrst term. It is Table III: The main properties of DADGs Benchmark Mandelbrot MM.1 Stencil MD FFT Dijkstra Blackscholes FFT6 MM.2 qSort Nodes 1,045,696 1,489,656 2,107,098 1,498,210 610,011 398,674 1,236,128 338,920 1,514,622 1,118,977 Edges 1,315,168 1,957,420 2,847,856 2,070,557 799,933 550,462 1,516,241 458,273 2,063,665 1,442,563 Avg degree Avg path length 2.549 7.718 2.701 14.517 2.549 13.703 2.571 19.307 2.486 13.425 2.433 11.179 2.35 23.296 2.513 21.753 2.422 16.33 2.353 29.312 V. EVALUAT ION In this section, we provide simulation conﬁgurations and experimental results to demonstrate the validity of our framework. A. Simulation Conﬁgurations We simulate a symmetric CMP with all out-of-order cores in NoC with the parameters shown in Table 1. Three different types of execution are considered and compared: sequential execution where all instructions are executed in one core, thread-based execution where the number of threads spawned is equal to core count, and optimization-based execution discussed in this paper. Thread-based and optimization-based executions are evaluated on a 32-core NoC as all of our workloads can be conﬁgured to 32 communities if proper λ2 is applied. Table 2 shows the simulated workloads. B. Experimental Results 1) Complex Network and Basic Properties: Figure 7 shows the DADG connectivity structure for several applications (e.g., MM.1, Dijkstra, and Blackscholes). Table 3 summarizes their main attributes. In Figure 7, DADGs can be classiﬁed into 3 categories: high/medium/low discernibility. High discernible DADGs are clearly seen as some interconnected clusters. One of examples is MM.1. Medium discernible DADGs may be seen as some regular patterns by humans. One of examples is Dijkstra. Those applications mentioned above can be parallelized by programmers without many efforts. The similarity in high and medium discernible DADGs is that there are some visible patterns to humans. The reason is that array declaration in C/C++ programs corresponds to one IR instruction called ""getelementptr"". Therefore, all array-related operations depend on this instruction. This node is becoming central and betweenness 222 Figure 7: The three DADGs representing MM.1, Dijkstra, and Blackscholes respectively Figure 8: Load balancing and cluster count. Lower is better. natural that to balance load among clusters to its best, one node is assigned to one cluster and |R1 | = 0. Therefore there is no point in increasing the value of λ1 to the threshold. In the rest of ﬁgures, Since in this case N is set to be 0, we want to make sure that all clusters generated by the framework can be fully mapped into NoC by increasing λ2 . All applications, although some have large cluster counts at the beginning, can be conﬁned within core count if proper λ2 is applied. 3) Comparisons With Sequential Execution and Thread-based Execution: We simulated all 10 applications on the 32-core NoC4 . In Figure 9, for embarrassingly parallel programs such as Man4 In optimization-based execution, we set both λ1 and λ2 to be 0.5. Figure 9: Speedup on the 32-core NoC delbrot, speedup given by thread-based execution is 10% higher than optimization-based execution as threads are independent from each other whereas communities still have load imbalance and intercommunity communications. In such a case, each thread can be mapped to different cores to execute faster due to no communication overhead. Nevertheless, for most non-embarrassingly parallel programs, in general, optimization-based execution achieves better performance. Locks and barriers are applied to ensure correctness of multi-threaded programs, giving rise to more synchronization overhead. Besides, on-chip inter-thread or intra-thread communication appears to cause congestion, slowing down the entire program. The optimization-based execution speedup varies from 10.2% to 131.82% when compared to thread-based execution. The degree of data movement inﬂuences signiﬁcantly the overall speedup. 4) Scalability: We evaluate the cluster count and cycle counters for the slowest and fastest stages for two applications FFT and qSort based on different input sizes. In Figure 10, input size is linearly proportional to the cycle counter in the slowest stage and inversely proportional to the counter in the fastest stage. But when adjusting λ1 to be 0.5, the cycle counter in the slowest stage is reduced by nearly 10% as increasing λ1 reorganizes the graph by distributing some nodes in a dense cluster into a sparse cluster, taking into consideration the difference between loads in clusters. In terms of cluster size, although input size varies, cluster size only changes slightly, making it easy for λ2 to reduce the size within core count. V I . CONC LU S ION S The main goal of this paper is to try to run a sequential program in NoC such that we can gain the maximum speedup in multicore systems. Considering the deﬁciencies of multi-threading, we propose a complex network inspired parallelization framework to efﬁciently partition sequential programs. We ﬁrst construct the DADG of an application where nodes indicate LLVM IR instructions and edges represent dependencies on virtual registers. Next, we formulate the optimization model by considering not only the inter-cluster edges, but also load balancing and cluster size. We can adjust the load among different clusters and cluster size by ﬁne-tuning the regularization parameters λ1 and λ2 used in equation (2). In order to save energy and prevent NoC congestion, data communications are mainly constrained in each cluster. Finally, we construct a CG where nodes denote clusters and edges indicate data dependencies. Having constructed the CG, we propose an algorithm based on topological sort, to identify clusters for parallel execution and map them onto the NoC. Our evaluation with 10 workloads performed on a 32-core 223 [5] D. Cordes et al. “Automatic parallelization of embedded software using hierarchical task graphs and integer linear programming”. In: CODES+ISSS. 2010. [6] A. Danalis et al. “The scalable heterogeneous computing (SHOC) benchmark suite”. In: GPGPU-3. 2010. [7] G. F. Diamos et al. “Harmony: an execution model and runtime for heterogeneous many core systems”. In: HPDC. 2008. [8] A. J. Dorta et al. “The OpenMP source code repository”. In: PDP. 2005. [9] M. Fattah et al. “Adjustable contiguity of run-time task allocation in networked many-core systems”. In: ASP-DAC. 2014. [10] A. Fonseca et al. “Automatic parallelization: Executing sequential programs on a task-based parallel runtime”. In: IJPP. 2016. [11] S. Fortunato. “Community detection in graphs”. In: Physics reports. 2010. [12] M. R. Guthaus et al. “MiBench: A free, commercially representative embedded benchmark suite”. In: Workload Characterization, 2001. [13] C. Lattner et al. “LLVM: A compilation framework for lifelong program analysis & transformation”. In: CGO. 2004. [14] F. Li et al. “Automatic extraction of coarse-grained data-ﬂow threads from imperative programs”. In: IEEE Micro. 2012. [15] Z. Li et al. “Unveiling parallelization opportunities in sequential programs”. In: Journal of Systems and Software. 2016. [16] M. E. J. Newman. “The structure and function of complex networks”. In: SIAM review. 2003. [17] M. E. J. Newman and M. Girvan. “Finding and evaluating community structure in networks”. In: Physical review E. 2004. [18] B. P. Railing et al. “Contech: Efﬁciently generating dynamic task graphs for arbitrary parallel programs”. In: TACO. 2015. [19] A. K. Singh et al. “Mapping on multi/many-core systems: survey of current and emerging trends”. In: DAC. 2013. [20] M. A. Suleman et al. “Feedback-directed pipeline parallelism”. In: PACT. 2010. [21] K. S. Vallerio and N. Jha. “Task graph extraction for embedded system synthesis”. In: VLSI Design. 2003. J. A. Winter et al. “Scalable thread scheduling and global power management for heterogeneous many-core architectures”. In: PACT. 2010. [23] Y. Xue et al. “Scalable and realistic benchmark synthesis for efﬁcient NoC performance evaluation: A complex network analysis approach”. In: CODES+ISSS. 2016. [24] Y. Xue and P. Bogdan. “Improving NoC performance under spatio-temporal variability by runtime reconﬁguration: a general mathematical framework”. In: NOCS. 2016. [25] Y. Xue and P. Bogdan. “Reliable Multi-fractal Characterization of Weighted Complex Networks: Algorithms and Implications”. In: Scientiﬁc Reports. Vol. 7. 7487. 2017. [26] G. L. Yuan et al. “Complexity effective memory access scheduling for many-core accelerator architectures”. In: MICRO. 2009. [22] Figure 10: Scalability. FFT : left column; qSort: right column NoC shows that load balancing and core count can be alleviated by the framework under various input sizes. Overall speedup of most applications is 10.2% to 131.82% higher compared to the threadbased execution. V I I . ACKNOW L EDG EM EN T The authors are thankful to the reviewers for their valuable feedback. The authors gratefully acknowledge the support by the National Science Foundation under CAREER Award CPS-1453860, the U.S. Army Defense Advanced Research Projects Agency (DARPA) under grant no. W911NF-17-1-0076, DARPA Young Faculty Award under grant no. N66001-17-1-4044, the Okawa Foundation Award and the University of Southern California support. "
2017,Thermal-sensitive design and power optimization for a 3D torus-based optical NoC.,"In order to overcome limitations of traditional electronic interconnects in terms of power efficiency and bandwidth density, optical networks-on-chip (NoCs) based on 3D integrated silicon photonics have been proposed as an emerging on-chip communication architecture for multiprocessor systems-on-chip (MPSoCs) with large core counts. However, due to thermo-optic effects, wavelength-selective silicon photonic devices such as microresonators, which are widely used in optical NoCs, suffer from temperature-dependent wavelength shifts. As a result, on-chip temperature variations cause significant thermal-induced optical power loss which may counteract the power advantages of optical NoCs. To tackle this problem, in this work, we present a thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture. Based on an optical thermal modeling platform which models the thermal effect in optical NoCs from a system-level perspective, a thermal-sensitive routing algorithm is proposed for the 3D torus-based optical NoC to optimize its power consumption in the presence of on-chip temperature variations. Simulation results show that in an 8×8×2 3D torus-based optical NoC under a set of real applications, as compared with a matched 3D mesh-based optical NoC with traditional dimension order routing, the power consumption is reduced by 25% if thermal tuning for microresonators is not utilized, by 19% if thermal tuning is utilized for microresonators, and by 17% if athermal microresonators are used.","Thermal-Sensitive Design and Power Optimization for a 3D Torus-Based Optical NoC Kang Yao ∗ , Yaoyao Ye ∗ , Sudeep Pasricha † , Jiang Xu ‡ ∗ † Dept. of Micro/Nano Electronics, Shanghai Jiao Tong University, Shanghai, China Dept. of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO, USA Dept. of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China ‡ Abstract—In order to overcome limitations of traditional electronic interconnects in terms of power efﬁciency and bandwidth density, optical networks-on-chip (NoCs) based on 3D integrated silicon photonics have been proposed as an emerging on-chip communication architecture for multiprocessor systems-on-chip (MPSoCs) with large core counts. However, due to thermooptic effects, wavelength-selective silicon photonic devices such as microresonators, which are widely used in optical NoCs, suffer from temperature-dependent wavelength shifts. As a result, onchip temperature variations cause signiﬁcant thermal-induced optical power loss which may counteract the power advantages of optical NoCs. To tackle this problem, in this work, we present a thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture. Based on an optical thermal modeling platform which models the thermal effect in optical NoCs from a system-level perspective, a thermal-sensitive routing algorithm is proposed for the 3D torus-based optical NoC to optimize its power consumption in the presence of onchip temperature variations. Simulation results show that in an 8x8x2 3D torus-based optical NoC under a set of real applications, as compared with a matched 3D mesh-based optical NoC with traditional dimension order routing, the power consumption is reduced by 25% if thermal tuning for microresonators is not utilized, by 19% if thermal tuning is utilized for microresonators, and by 17% if athermal microresonators are used. Index Terms—Optical network-on-chip, chip multiprocessor, thermo-optic effect, temperature sensitivity. I . IN TRODUC T ION As the scale of transistors enters the deep nanometer region, the number of transistors available on a single chip has increased to several billions. By enabling energy-efﬁcient parallel processing at lower clock frequencies, multiprocessor systems-on-chip (MPSoCs) are a natural platform for embedded systems as well as high-performance computing. Networkon-chip (NoC) architectures have been widely proposed as a new generation of on-chip communication architectures, which could scale better than on-chip shared buses and ad-hoc networks as the number of cores increases [1], [2]. However, due to the limitations of traditional electronic interconnects in power efﬁciency and bandwidth density, as well as issues of high-frequency crosstalk noise and parasitic capacitance in deep-submicron integrated circuit design, there are still bandwidth, power efﬁciency and reliability bottlenecks in traditional NoCs based on electronic interconnects. This work is sponsored by Shanghai Sailing Program, and NSFC (Project 61602298). Corresponding author: Yaoyao Ye. Email: yeyaoyao@sjtu.edu.cn With the booming developments in nanoscale silicon photonic technologies for short-haul communications, silicon photonics based optical interconnects are emerging as a promising new approach to moving on-chip data at high speeds and low power. Compared to traditional electronic interconnects, optical interconnects can enable signiﬁcantly increased bandwidth density, low power consumption, and low latency. By integrating optical interconnects in NoC architectures, optical NoCs can overcome many of the most serious on-chip communication issues [3]–[7]. Most of the prior works on optical NoCs are based on silicon photonic devices including optical waveguides and silicon microresonators (MRs). Considering the high efﬁciency of electronic interconnects in on-chip local communication as well as for control, optical NoCs are often controlled and conﬁgured in the electronic domain. Threedimensional (3D) integration technologies provide the support for realizing mixed-technology electronic-controlled optical NoCs [8]. However, one of the major challenges in optical NoC designs is thermal sensitivity, which is an intrinsic characteristic of photonic devices. Due to the fact that the power density on chip is uneven and the thermal conductivity of packaging materials is limited, chip temperature ﬂuctuates temporally as well as spatially. The temperature can rise quickly from room temperature after a cold start, and vary by more than 30𝑜𝐶 across a steady-state chip under typical operating conditions [9]. As a result of thermo-optic effects, wavelength-selective silicon photonic devices such as microresonators, which are widely used in optical NoCs, suffer from temperature-dependent wavelength shifts [10]. The emission wavelength of on-chip lasers, such as VCSELs (vertical cavity surface-emitting lasers), also shifts with ambient temperatures [11], while the power efﬁciency degrades at high temperatures [12]. The thermal related wavelength mismatch between the laser located in the source node and the microresonators in intermediate nodes along a photonic path can cause signiﬁcant additional optical power loss. An investigation of related thermal issues shows that if we take the thermal regulation power into account, optical interconnects may not have advantages in power efﬁciency as compared with their electrical counterparts [13]. In order to mitigate thermal effects in optical NoCs, run-time thermal management techniques such as OS-based workload migration and DVFS (dynamic voltage and frequency scaling) have been proposed 978-1-5386-3093-8/17/$31.00 ©2017 IEEE 827 to reduce the on-chip temperature gradients [14]–[16]. Due to the limitations of these thermal management techniques, device-level thermal compensation techniques are still in need. Thermal tuning by local microheaters is one such device-level solution, however, it is relatively slow and power inefﬁcient [17], [18]. Additionally, microresonators with low temperature dependence as well as athermal microresonators have been demonstrated by applying proper polymer materials [19], [20]. However, there are still compatibility issues when implementing athermal microresonators with CMOS technology. Furthermore, some efforts have been made to overcome the thermal challenges in optical NoCs from system-level perspectives [16], [21]–[26]. In [23], the authors proposed a thermalaware methodology to design optical NoCs with distributed CMOS-compatible VCSELs, based on steady-state thermal simulations and SNR (signal-to-noise ratio) analysis. In [21], [22], the authors systematically modeled thermal effects in optical NoCs and proposed several low-temperature-sensitivity techniques. In [24], a system-level proactive thread migration technique and a device-level thermal island framework were proposed to alleviate the thermal issues in optical NoCs. To further tackle the thermal issue in optical NoC designs, in this work, we present a novel thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture in the presence of on-chip temperature variations. The rest of the paper is organized as follows. In Section II, we present the proposed thermal-sensitive design and power optimization methodology. Section III presents simulation results and comparisons in terms of thermal-induced energy efﬁciency and network performance. Last, Section IV concludes. I I . TH ERMA L -S EN S I T IV E D E S IGN AND POW ER O P T IM I ZAT ION In this section, we propose a thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture (Figure 1). Based on optical thermal models that characterize thermal effects in optical NoCs from a systemlevel perspective, a thermal-sensitive routing mechanism is proposed for the 3D torus-based optical NoC to optimize its power consumption in the presence of on-chip temperature variations. A. 3D Torus-based optical NoC architecture Regular network topologies, such as mesh and torus, are preferred in NoC designs because of their predictable scalability in terms of performance and power consumption. In order to improve the NoCs performance with shorter interconnection lengths, NoC architectures based on 3D network topologies have been proposed [27]–[29]. It has been demonstrated that as compared to its 2D implementation, the 3D mesh-based NoC can improve performance signiﬁcantly with higher integration densities and smaller footprints. As compared to 3D mesh topology, the 3D torus topology takes advantage of the wraparound links among edge nodes to offer better path diversity and better load balance. Fig. 1. The proposed thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture Figure 2 shows the topology of a 3D torus-based optical NoC architecture, where each router is connected to a local processor core. Each processor is assigned a unique ID of (𝑥𝑖 , 𝑦𝑖 , 𝑧𝑖 ) for addressing, and the local router has the same address. The proposed 3D torus-based optical NoC uses circuit switching, in which an optical path is reserved before payload transmission. An overlapped electronic control network is used for optical path conﬁguration and maintenance. Before a packet transmission, a single-ﬂit path-setup packet would be routed in the electronic control network for path reservation. The payload data is transmitted along the reserved optical path after the path setup. High-speed optical transmission is achieved in this architecture without buffering in intermediate routers. Fig. 2. A 3D torus-based optical NoC architecture B. Hybrid optical-electronic router architecture In the 3D torus-based optical NoC, hybrid optical-electronic routers are used to interconnect processor cores. The hybrid optical-electronic router architecture (Figure 3) is composed of a 7×7 fully-connected optical switch, an electronic control unit, and an electronic/optical (E/O) interface. The electronic control unit an adaptive power control unit. The 7×7 fully-connected includes a thermal-sensitive routing unit and 828 optical switch is responsible for directing optical signals in the network, while the electronic control unit implements the routing algorithm and power control. In addition, the electronic control units in the network are interconnected into an electronic control network with metallic interconnects for control purposes, which includes selecting optical path conﬁgurations and delivering temperature information. The E/O interface, which is in charge of serialization, deserialization, and E/O conversions, is used to facilitate communications between the electronic and optical domain. Fig. 3. A hybrid optical-electronic router architecture In [29], a reduced 7×7 optical switch was proposed speNoC. In this paper, we extend it to a 7×7 fully-connected cially for dimension-order routing in a 3D mesh-based optical optical switch (Figure 4), which can support any routing algorithms including the newly proposed thermal sensitive routing scheme. The 7×7 fully-connected optical switch is built from basic optical switching elements (BOSEs) which are based on wavelength-selective microresonators, optical waveguides, and optical terminators [29]. By powering on/off plements 1x2 optical switching functions. The 7×7 fullythe microresonator, the basic optical switching element imconnected optical switch has seven bidirectional ports, including injection/ejection, up, down, east, west, south, and north ports. The local processor core is connected by the injection/ejection ports through an O/E interface while other ports are connected to neighboring optical switches. The proposed 7×7 fully-connected optical switch inherits the lowloss feature from the reduced 7×7 optical switch [29]. The ports are aligned to their intended directions. Compared to the reduced 7×7 optical switch for dimension-order routing only proposed in [29], our new port-to-port switching functions in the proposed 7×7 fully-connected optical switching fabric include switchings from south to east/west, from north to east/west, from up to east/west/south/north, from down to east/west/south/north. C. Thermal-sensitive Routing for Power Consumption Reduction The traditional dimension-order routing (e.g. XYZ routing) is a low-complexity deterministic algorithm, which is particularly suitable for mesh or torus-based networks. Its simplicity and efﬁciency is due to the fact that it is a deterministic routing Fig. 4. A 7x7 fully-connected optical switching fabric approach which determines a path with minimum information (the source address and the destination address). However according to our previous studies, the worst-case thermalinduced power consumption of deterministic dimension order routing is signiﬁcant in the presence of on-chip temperature variations. In this section, we propose a thermal-sensitive routing mechanism which selects a path according to runtime on-chip temperature conditions. By avoiding paths with severe thermal-induced optical power loss, the power consumption for a packet transmission can be signiﬁcantly reduced. 1) Optical thermal model: As a result of the thermo-optic effect, material refractive index is temperature dependent and follows Equation (1), where 𝑛0 is the refractive index at room temperature, 𝑑𝑛/𝑑𝑇 is the thermo-optic coefﬁcient of the material, and Δ𝑇 is the temperature variation. Physical measurements show that the thermo-optic coefﬁcient of silicon is on the order of 10−4 /𝐾 and is nonlinear over a large temperature range at 1550nm wavelength [30]. 𝑛 = 𝑛0 + 𝑑𝑛 𝑑𝑇 Δ𝑇 (1) The thermo-optic effect will cause changes in the device characteristics. As shown in Equation (2), the resonant wavelength of a single-microresonator basic optical switching element 𝜆𝐵𝑂𝑆𝐸 shifts approximately linearly with temperature 𝑇𝐵𝑂𝑆𝐸 , where 𝜆𝐵𝑂𝑆𝐸 0 is the resonant wavelength at room temperature 𝑇0 , and 𝜌𝐵𝑂𝑆𝐸 is deﬁned as the temperaturedependent wavelength shift of the basic optical switching element. 𝜆𝐵𝑂𝑆𝐸 = 𝜆𝐵𝑂𝑆𝐸 0 + 𝜌𝐵𝑂𝑆𝐸 (𝑇𝐵𝑂𝑆𝐸 − 𝑇0 ) (2) As shown in Equation (3), the lasing wavelength of VCSELs 𝜆𝑉 𝐶 𝑆𝐸𝐿 also red-shifts approximately linearly with temperature 𝑇𝑉 𝐶 𝑆𝐸𝐿 , where 𝜆𝑉 𝐶 𝑆𝐸𝐿 0 is the lasing wavelength 829 at room temperature 𝑇0 , and 𝜌𝑉 𝐶 𝑆𝐸𝐿 is deﬁned as the temperature dependent wavelength shift of VCSEL. 𝜆𝑉 𝐶 𝑆𝐸𝐿 = 𝜆𝑉 𝐶 𝑆𝐸𝐿 0 + 𝜌𝑉 𝐶 𝑆𝐸𝐿 (𝑇𝑉 𝐶 𝑆𝐸𝐿 − 𝑇0 ) (3) Besides, the output power of a VCSEL degrades at higher operating temperatures. Assuming that the VCSEL is driven by current 𝐼 which is above the threshold but before the point where the output power starts to decrease with the current, we can express the output optical power 𝑃𝑜𝑢𝑡 by Equation (4), where 𝐼 is the driving current, 𝛼 is the minimum threshold current, 𝑇𝑡ℎ is the temperature at which the threshold current is the minimum, 𝛽 is a coefﬁcient related to the temperature dependance of the threshold current, 𝜀 is the slope efﬁciency at 0𝑜𝐶 , and 𝛾 is a positive coefﬁcient. 𝑃𝑜𝑢𝑡 = (𝐼 − 𝛼 − 𝛽 (𝑇𝑉 𝐶𝑆𝐸𝐿 − 𝑇𝑡ℎ )2 )(𝜀 − 𝛾 ⋅ 𝑇𝑉 𝐶 𝑆𝐸𝐿 ) (4) If using an off-chip VCSEL as the laser source, the lasing wavelength can be ﬁxed by equipping with a temperature control unit. If using an on-chip VCSEL as the laser source, the temperature-dependent wavelength shift and power efﬁciency degradation should be taken into account in the thermal model. Temperature variations across the chip will result in wavelength mismatches between the laser wavelength and the resonant wavelengths of intermediate switching elements in the path. As shown in Equation (5), the wavelength mismatch results in additional optical power loss (in dB) in switching. 2𝛿 is the 3-dB bandwidth of the basic optical switching element, 𝜅2 is the fraction of power coupling between the waveguide and the ring, and 𝜅2 ring [31]. When 2𝜅2 ≫ 𝜅2 𝑝 is the power loss per round-trip of the 𝑝 , nearly full power transfer can be achieved at the peak resonance, exhibiting a low insertion loss. A deviation from the peak resonant wavelength would result in more power loss in an active switching especially if with a narrow 3-dB bandwidth. For a basic optical switching element working at the 1550nm wavelength range, if the quality factor is on the order of 5000, a 10𝑜𝐶 temperature change would make the power spectrum shift about 0.5nm and result in a power loss variation of about 10dB. 𝐿 = 10𝑙𝑜𝑔(( 2𝜅2 + 𝜅2 2𝜅2 𝑝 )2 ⋅ (1 + (𝜆𝑉 𝐶 𝑆𝐸𝐿 − 𝜆𝐵𝑂𝑆𝐸 )2 𝛿2 ) (5) 2) Thermal-sensitive routing: Based on the optical thermal models presented above, we propose a thermal-sensitive routing mechanism to reduce thermal-induced power consumption in the presence of on-chip temperature variations. The routing algorithm determines a path to transmit a packet from the source to the destination. In traditional deterministic routing such as dimension-order routing, a deterministic path is decided based only on the source address and the destination address. However, in the presence of on-chip temperature variations, some paths which are under high temperature variations suffer from severe optical power loss. In order to avoid such paths, we propose to introduce adaptiveness in routing by considering on-chip temperature conditions when making routing decisions. Figure 5 shows the proposed thermal-sensitive routing unit. It is composed of a shortest path routing unit, a temperature table, and an optical thermal-effect modeling unit. The proposed thermal-sensitive routing works as a source routing mechanism. It needs global temperature information to make routing decisions, so the overhead of this routing algorithm includes the on-chip temperature sensing and the broadcasting of global temperature information. For each packet to be transmitted, the shortest path routing unit reads the header ﬂit of the packet to get the source id and destination id, and then it ﬁnds out the shortest paths between the source and destination. The found shortest paths are considered as candidate paths, and they will be compared for thermal-induced optical power loss by the optical thermal-effect modeling unit. The temperature table keeps the global temperature information at the granularity of each processor core. Considering that the on-chip temperature could ﬂuctuate temporally, the temperature table will receive updates from other nodes. The optical thermal-effect modeling unit gets all the candidate paths information from the shortest path routing unit, and reads the temperature table for global temperature information. It then calculates the thermal-induced optical power loss for each candidate path, according to the optical thermal models presented in the previous section. The path with the minimum thermal-induced optical power loss will be selected out of all the candidate paths. Fig. 5. The proposed thermal-sensitive routing unit 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fpppp H264dh H264dl Robot Sample Satell Sparse Average y c n e c i i f f e y g r e n e d e z i l a m r o N 1.2 1 0.8 0.6 0.4 0.2 0 Fig. 6. Normalized energy efﬁciency for real applications, without thermal tuning, 0.62𝑛𝑚 3-dB bandwidth I I I . S IMU LAT ION R E SU LT S AND COM PAR I SON S We evaluated the energy efﬁciency and performance of a 3D 8x8x2 torus-based optical NoC. We assumed 40Gbps data-link bandwidth. In order to show the advantages of the proposed 3D torus-based optical NoC with thermal-sensitive routing, we 830     0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e n e r y g e i f f y c n e c i 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 7. Normalized energy efﬁciency for real applications, with thermal tuning, 0.62𝑛𝑚 3-dB bandwidth 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e n e r y g e i f f y c n e c i 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 8. Normalized energy efﬁciency for real applications, with athermal MRs, 0.62𝑛𝑚 3-dB bandwidth use a matched 3D 8x8x2 mesh-based optical NoC with the traditional XYZ routing as a baseline for comparison. SystemCbased cycle-accurate simulators are developed for network simulations of the proposed 3D torus-based optical NoC and the baseline 3D mesh-based optical NoC. Network simulations are conducted under several real applications including FPPPP, H263E, H264DH, H26DL, ROBOT, SAMPLE, and SPARSE. For each application, trafﬁc information is used to simulate the on-chip temperature distributions by McPAT [32] and 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l e n e d e z r y g e i f f y c n e c i 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 9. Normalized energy efﬁciency for real applications, without thermal tuning, 0.775𝑛𝑚 3-dB bandwidth 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e n e r y g e i f f y c n e c i 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 10. Normalized energy efﬁciency for real applications, with thermal tuning, 0.775𝑛𝑚 3-dB bandwidth 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e n e r y g e i f f y c n e c i 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 11. Normalized energy efﬁciency for real applications, with athermal MRs, 0.775𝑛𝑚 3-dB bandwidth HotSpot [33]. Two traditional techniques have been proposed to compensate for the temperature-dependent wavelength shift in microresonators, including the active thermal tuning with local microheaters and the passively temperature-compensated athermal microresonators [17] [20]. The athermal microresonators usually have a limited range of working temperatures, beyond which the microresonators would be thermal sensitive. In our case study, we assume that the athermal microresonators are working within their required temperature range. 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l e p d e z f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 12. Normalized performance for real applications, without tuning, 0.62𝑛𝑚 3-dB bandwidth thermal 831                       0 0.3 0.6 0.9 1.2 1.5 1.8 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e p f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 13. Normalized performance for real applications, with thermal tuning, 0.62𝑛𝑚 3-dB bandwidth 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e p f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 14. Normalized performance for real applications, with athermal MRs, 0.62𝑛𝑚 3-dB bandwidth We assume the laser wavelength and resonant wavelength of microresonators are 1550nm at room temperature. A. Thermal-induced energy efﬁciency The energy consumption for a packet transmission in the proposed 3D torus-based optical NoC involves the energy consumed for payload transmission in the optical domain and the energy consumed in the electronic domain for control purposes. Since the size of the control packets is small, the energy consumed in the electronic domain only takes 0 0.2 0.4 0.6 0.8 1 1.2 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l e p d e z f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 15. Normalized performance for real applications, without tuning, 0.775𝑛𝑚 3-dB bandwidth thermal 0 0.3 0.6 0.9 1.2 1.5 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e p f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 16. Normalized performance for real applications, with thermal tuning, 0.775𝑛𝑚 3-dB bandwidth 0 0.3 0.6 0.9 1.2 1.5 Fpppp H264dh H264dl Robot Sample Satell Sparse Average N o r m a i l d e z e p f r o r m e c n a 3D OTorus w/ the proposed routing 3D OMesh w/ XYZ routing Fig. 17. Normalized performance for real applications, with athermal MRs, 0.775𝑛𝑚 3-dB bandwidth a small proportion of overall communication energy, with the energy consumption in O/E interfaces accounting for the major proportion of the total energy consumption. The energy consumed by a payload transmission includes the energy consumed by the O/E interfaces, and the energy consumed by thermal tuning for microresonators [17]. For the evaluation of O/E conversions power consumption, we use the VCSEL model in [12], the serializer and deserializer designs in [34], and the VCSEL driver and TIA-LA circuit designs in [35]. The photodetector model is based on a Ge waveguide photodetector monolithically integrated in 130nm CMOS process with a sensitivity of −14.2𝑑𝐵𝑚 for 10−12 of bit error rate (BER) [36]. Figures 6-8 show the normalized energy efﬁciency of the proposed 3D 8x8x2 torus-based optical NoC under different real application workloads, when the 3-dB bandwidth of BOSEs is 0.62nm. If thermal tuning is not utilized for microresonators (Figure 6), the proposed thermal-sensitive routing would reduce the average energy efﬁciency by 25%. If thermal tuning is utilized for microresonators (Figure 7), the proposed thermal-sensitive routing would reduce the average energy efﬁciency by 19%. If athermal microresonators are used (Figure 8), the proposed thermal-sensitive routing would reduce the average energy efﬁciency by 17%. The thermalrelated energy efﬁciency is sensitive to the 3dB bandwidth 832           of BOSEs. As shown in Figure 9 to Figure 11, when the 3dB bandwidth of BOSEs is 0.775nm, the proposed thermalsensitive routing would reduce the average energy efﬁciency by 24% if thermal tuning for microresonators is not utilized; by 20% if thermal tuning is utilized; by 10% if athermal microresonators are used. B. Network performance Figures 12-14 show the normalized performance of the proposed 3D 8x8x2 torus-based optical NoC under different real application workloads, when the 3-dB bandwidth of BOSEs is 0.62nm. We can observe that the average network performance is almost the same with the traditional XYZ routing, without sacriﬁcing performance. This is due to the fact that the proposed thermal-sensitive routing always chooses a path from shortest paths. As shown in Figures 15-17, when the 3-dB bandwidth of BOSEs is 0.775nm, we can get the same conclusions. IV. CONC LU S ION S In this work, we propose a thermal-sensitive design and power optimization approach for a 3D torus-based optical NoC architecture. Based on an optical thermal modeling platform which models the thermal effects in optical NoCs from a system-level perspective, a thermal-sensitive routing algorithm is proposed for the 3D torus-based optical NoC architecture to optimize its power consumption in the presence of on-chip temperature variations. Simulation results show that in an 8x8x2 3D torus-based optical NoC under a set of real application workloads, as compared with a matched 3D mesh-based optical NoC with the traditional dimension order routing, the power consumption is reduced by 25% if thermal tuning for microresonators is not utilized, by 19% if thermal tuning is utilized for microresonators, and by 17% if athermal microresonators are used. "
2018,Wavefront-MCTS - multi-objective design space exploration of NoC architectures based on Monte Carlo tree search.,"Application-specific MPSoCs profit immensely from a custom-fit Network-on-Chip (NoC) architecture in terms of network performance and power consumption. In this paper we suggest a new approach to explore application-specific NoC architectures. In contrast to other heuristics, our approach uses a set of network modifications defined with graph rewriting rules to model the design space exploration as a Markov Decision Process (MDP). The MDP can be efficiently explored using the Monte Carlo Tree Search (MCTS) heuristics. We formulate a weighted sum reward function to compute a single solution with a good trade-off between power and latency or a set of max reward functions to compute the complete Pareto front between the two objectives. The Wavefront feature adds additional efficiency when computing the Pareto front by exchanging solutions between parallel MCTS optimization processes. Comparison with other popular search heuristics demonstrates a higher efficiency of MCTS-based heuristics for several test cases. Additionally, the Wavefront-MCTS heuristics allows complete tracability and control by the designer to enable an interactive design space exploration process.","Wavefront-MCTS: Multi-objective Design Space Exploration of NoC Architectures based on Monte Carlo Tree Search Yong Hu yong.hu@tum.de Chair of Electronic Design Automation, Technical University of Munich, Germany Daniel Mueller-Gritschneder daniel.mueller@tum.de Chair of Electronic Design Automation, Technical University of Munich, Germany Ulf Schlichtmann ulf.schlichtmann@tum.de Chair of Electronic Design Automation, Technical University of Munich, Germany ABSTRACT Application-speciic MPSoCs proit immensely from a custom-it Network-on-Chip (NoC) architecture in terms of network performance and power consumption. In this paper we suggest a new approach to explore application-speciic NoC architectures. In contrast to other heuristics, our approach uses a set of network modiications deined with graph rewriting rules to model the design space exploration as a Markov Decision Process (MDP). The MDP can be eiciently explored using the Monte Carlo Tree Search (MCTS) heuristics. We formulate a weighted sum reward function to compute a single solution with a good trade-of between power and latency or a set of max reward functions to compute the complete Pareto front between the two objectives. The Wavefront feature adds additional eiciency when computing the Pareto front by exchanging solutions between parallel MCTS optimization processes. Comparison with other popular search heuristics demonstrates a higher eiciency of MCTS-based heuristics for several test cases. Additionally, the Wavefront-MCTS heuristics allows complete tracability and control by the designer to enable an interactive design space exploration process. KEYWORDS NoC, MCTS, multi-objective design space exploration ACM Format: Yong Hu, Daniel Mueller-Gritschneder, and Ulf Schlichtmann. 2018. WavefrontMCTS: Multi-objective Design Space Exploration of NoC Architectures based on Monte Carlo Tree Search. In IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD ’18), November 5–8, 2018, San Diego, CA, USA. ACM, New York, NY, USA, 8 pages. https://doi.org/10. 1145/3240765.3240863 1 INTRODUCTION In modern chips, more and more processing elements (PEs) are integrated into a single Multi-Processor System-on-Chip (MPSoC). This challenges the interconnect design, which must provide a good trade-of between communication latency with power and area overheads. Here, Network-on-Chip (NoC) interconnects have Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proit or commercial advantage and that copies bear this notice and the full citation on the irst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciic permission and /or a fee. Request permissions from permissions@acm.org. ICCAD ’18, November 5–8, 2018, San Diego, CA, USA © 2018 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery. ACM ISBN 978-1-4503-5950-4/18/11. . . $15.00 https://doi.org/10.1145/3240765.3240863 established themselves as a popular solution due to their good scalability for a high number of PEs. However, application-speciic MPSoCs, e.g. smartphone chips, make use of a high number of ixed-function PEs such as Video decoders or DMAs. For such systems, the network traic is highly unbalanced. This motivates designers to develop application-speciic NoC architectures, which are custom-it for their MPSoCs. Generally, there exist two types of NoC synthesis approaches: top-down approaches and iterative approaches. The top-down approaches start from the system speciication and make decisions step by step based on heuristics. E.g if two PEs communicate with each other very heavily, they will be connected to the same router. However, top-down approaches have a common drawback. The top-level decisions are made before obtaining the complete NoC architecture, so performances and costs can only be estimated with high-level models, for which the accuracy of estimation cannot be guaranteed. Iterative design space exploration (DSE) approaches start from a given single or population of NoC architectures. They iteratively explore new NoC architectures in the design space and search for the one that has the optimal performance at an acceptable cost. The huge size of the NoC design space challenges these approaches, hence, calling for eicient exploration heuristics. Besides, designers often want to be able to trace and control the changes made during the DSE process. But existing heuristics such as Genetic Algorithms (GAs) make it hard for the designer to track the decisions applied. This paper proposes a new iterative NoC DSE approach that supports an interactive low while also obtaining high eiciency comparable and often better than existing heuristics. At the core of the approach, the Monte Carlo Tree Search (MCTS) heuristic is applied. For this, the DSE is modelled as a Markov Decision Process (MDP) using graph rewriting. The algorithm can search for a single optimized design by weighting the multiple objectives such as power and average latency in a single reward function. Alternatively, we also propose the Wavefront-MCTS heuristic that eiciently computes the complete Pareto front for multiple objectives. The contributions of this paper are the following: • The formulation of the NoC DSE as Markov Decision Process (MDP) with graph rewriting. The MDP model enables a traceable and interactive low that ofers designers insight and control of the DSE process. • The application of the Monte Carlo Tree Search (MCTS) algorithm for NoC DSE. Compared with a simulated annealing (SA) algorithm and a genetic algorithm (GA), the MCTS algorithm shows obvious improvements in exploration eiciency. • The Wavefront-MCTS algorithm for obtaining the complete Pareto front. The algorithm uses a set of Max reward functions to guide parallel MCTS-based explorations towards non-dominated NoC architectures. The Wavefront modiication of MCTS enables an exchange between these parallel explorations to increase eiciency. Compared with the existing popular algorithm NSGA-II, the Wavefront-MCTS heuristic covers larger parts of the Pareto front due to the systematic exploration enforced by the Max reward function. The remainder of this paper is organized as follows. Sec. 2 discusses related work and the MCTS heuristic. Sec. 3 explains the MCTS-based DSE for NoCs in detail. Sec.4 introduces the WavefrontMCTS. Sec. 5 shows experimental results that demonstrate the eiciency and tracability of the DSE. Sec. 6 concludes the paper. 2 RELATED WORK 2.1 State of the Art in NoC DSE There has been extensive work on eicient design space exploration heuristics for application-speciic NoC architectures. As was already pointed out, they can be categorized into iterative and top-down approaches. In terms of iterative approaches, the method in [12] uses Tabu search in the NoC synthesis for application-speciic MPSoCs. It starts from an initial solution and iteratively explores neighborhoods. Explored designs are marked Tabu to avoid cycles in the search. The approach in [10] proposes a multi-commodity low (MCF)-based scheme to ind the optimal NoC topology that minimizes power consumption under communication latency constraints. It also provides an approximation algorithm, which they report is much faster than the commercial LP solver CPLEX. The approach in [4] applies a GA to explore the NoC design space. It models the connections in the topology as endpoint pairs and endpoints are regarded as genes. The connections are modiied randomly, when the gene is mutated generating new designs. The work in [15] uses a SA algorithm to explore the NoC space. The approach ilters out designs with large delay to support hard timing constraints in QoS systems. The work in [14] also applies SA in the design space exploration and it further models the memory system including caches. The work in [6] uses the STAGE machine learning algorithm to optimize the placement of planar and vertical communication links in 3D-NoCs for energy eiciency. It iteratively applies a base search and a meta search. The base search runs in a greedy way to ind local optima and generate new training data. The meta-search learns from features of the training data and tries to explore a good start state for the base search. And the features consist of average hop count, products of communication hops and bandwidth and clustering coeicient. In a top-down fashion, the approach in [16] uses spectral clustering to assign PEs to routers. In a subsequent step, the routing between PEs is determined by the A* algorithm. A similar approach with diferent clustering algorithm was presented in [17]. As was already pointed out, the assignment of PEs to routers is a key decision for application-speciic NoCs. In these approaches, this decision is done based on a cost function that combines latency, bandwidths and loorplan information to ind the best cluster of PEs. Yet, no simulation can be used at this level of abstraction to test the decision. Especially for top-down approaches or the cross-over steps of GAs, it is very hard for the designer to trace and understand the decisions applied by the heuristics to the NoC. Here, SA has the advantage that a sequence of changes to the NoC can be back-traced. In our experience, this is a great advantage for designers to get more insight and control into the design space exploration, in order to enhance the trust in the exploration results. The MCTS-based heuristic in this paper also allows such insights, yet, has higher eiciency than SA. 2.2 Background on MDP and MCTS As the name implies, MDPs model decision processes. They are described as sequences of states and actions as following: (1) State s : The decision space is represented with a inite number of states (2) Reward function Q (s ): The quality of a state s (3) Action a : An action can be applied on state s to generate an output state s ′ . For each state s , its available actions are represented as the set A(s ) (4) The transition function f (s , a ): Whenever the action a is applied on the state s , it gives the output state s ′ = f (s , a ) The exploration of an MDP is in principle the search for the sequence of actions that can yield the highest reward from given a speciic initial state s0 . MCTS is used as an efective method to explore MDPs [3], including in the famous AlphaGo. It structures the exploration of the MDP as a tree T . Each node v in the tree T stores one state s (v ). MCTS stores the initial state s0 in the root node of the tree vr oo t with s (vr oo t ) = s0 . When an action a ∈ A(s ) is applied on s (v ), a new node v ′ is created with a new state s (v ′) = f (s , a ) and it is added as child of node v to the MCTS tree. Besides the state, a node v also stores the reward function Q (s (v )) and the visiting times N (v ). For game engines Q (s (v )) is often the winning rate. For NoCs it could be a cost function combining area, power and latency. The visiting times of a node v is always initialized as one when a node v is created, that is N (v ) = 1. Each time when a new child is added to successors of the node v , N (v ) will be increased by one. As shown in Fig. 1, the MCTS solves the MDP problem iteratively by exploring successor nodes of the root following the tree policy and default policy. The tree policy includes the selection and the expansion: (1) In the selection step, the most urgent node vu is selected for expansion. There exist diferent formulations for urgentness. The most popular one is the Upper Conidence Bound for Trees (UCT) [13]. It calculates the urgentness as: U CT (v ) = Q (s (v )) + 2Cp s 2 ln(N (vr oo t )) N (v ) (1) Here Cp is a constant weight factor depending on the range of Q (v ). The U CT (v ) function may have both positive and negative values. Larger values indicate higher urgentness such that the most urgent node is selected by: maxv ∈Tr U CT (v ) → vu (2) The sub-tree Tr only includes successor nodes of the current root node vr oo t . Selection  Expansion Simulation Back propagation Figure 1: Monte Carlo Tree Search (2) In the expansion step, an action a ∈ A(s (vu )) is applied on the state of the most urgent node to create a new child node v ′ with s (v ′) = f (s (vu ), a ). The default policy includes the simulation and the backpropagation: (1) In the simulation step, the newly generated child node is evaluated by computing Q (s (v ′)). (2) In the backpropagation step, the evaluation results Q (s (v ′)) are sent through the parent node to all predecessor nodes until the current root node vr oo t . This also triggers the predecessors to update their visiting times N (v ). MCTS keeps adding and exploring new successor nodes to the current root node vr oo t based on the tree policy and default policy until a pre-deined computation budget runs out. Then MCTS selects the best direct child node of the current root node as new root node. This is equal to selecting the action a that leads from the previous root node to the new root node. The best direct child node is either selected as the one that leads to the successor node of the root node with highest Q -value or the direct child node with the highest visited times. This is a major advantage of MCTS over other heuristics such as SA. MCTS discovers late reward gains, which are not obtained in direct children of the root node but in grandchildren and even their successors. Additionally, the UCT formulation balances exploration versus exploitation very well. 3 MCTS-BASED DSE FOR NOCS 3.1 MDP Model using Graph Rewriting The NoC architecture can be well described with a graph: PEs and routers are represented by nodes and physical links are represented by directed edges between nodes as shown in Fig. 2(b). A modiication of the NoC architecture can be formulated using the theory of graph rewriting [8]. Graph rewriting is based on rules, which consist of a left-hand-side (LHS) graph and a right-hand-side (RHS) graph. The LHS graph describes a region of interest (ROI), where to modify the graph. The LHS can be deined not only based on the graph structure, but also with some property constraints such as node degree, the distance between two nodes or the name or property of a node. The RHS describes how to modiiy the ROI. The modiications can also be made on both the graph structure and its properties. A rule execution on a so-called design graph is a three step process: (1) In the match step, we search for the LHS in the design graph. All matches between LHS and design graph are stored. For a single rule there can be several matches. (2) In the selection step, one match is chosen. (3) In the apply step, the matching sub-graph in the design graph is replaced by the RHS graph of the rule. Simply stated, we replace a sub-graph of the design graph by a new sub-graph. An example of a the graph rewriting rule for a NoC modiication is illustrated in Fig. 2. The LHS includes two PEs a and LHS Graph a e1 b e2 e3 d c Constraints: Node a and d are PEs.  Node b and c are routers The port number of router b and router c  are both below 7 The communication bandwidth from PE a  to PE d is above 50Mbits/s RHS Graph Modifications: a d e1 e2 f Node a and d are not changed A new router f is added. Connections of  router b and c are shifted to router f,  including e1, e2 and all connections that  are not shown in LHS Router b and c are removed (a) Graph Rewriting Rule Input State Output State PE1 PE2 PE3 PE1 PE2 R R R R R R Action R R R PE4 PE5 PE6 PE4 PE5 PE3 R R PE6 (b) Execution of the Rule Figure 2: Illustration of Graph Rewriting for NoCs d and two routers b and c . There needs to exist a connection from a to b , b to c and c to d for the LHS to match. Besides, router b and c are constrained to have less than 7 ports and the communication from a to d should be above 50Mbi t s /s . Since two PEs communicate heavily and the connected routers are still relatively small, we can merge two routers into one, in order to reduce communication latency. This modiication is described in the RHS of the rule in Fig. 2(a). The rule is applied on a design graph in Fig. 2(b). During the match step, we look for the LHS in the design graph using graph isomorphism. In this example, a single match for the LHS is marked in the host graph, which consists of the PE1, PE2 and their connected routers. In the apply step, the design graph is modiied according to the RHS to generate a new design graph representing a new NoC architecture. Deining a set of graph rewriting rules allows us to model the NoC exploration as MDP. Each NoC architecture represents a state s described by a graph. Each graph rewriting rule is an action. If there exist a match between the LHS of the rule and the NoC architecture, this rule can be applied. Then the action a is deined to be available for the state s , that is a ∈ A(s ). The transfer function with s ′ = f (s , a ) is implemented by executing rule a on the initial NoC graph s to obtain a new NoC Graph representing the new state s ′ . We encode basic NoC modiications as rules, including adding/removing a router, adding/removing a directed link between a pair of routers and shifting a PE to a a diferent router. Any other kind of modiication can always be achieved with a combination of these basic rules. 3.2 Weighted-Sum Reward Function The only missing component of our MDP is the reward function Q (s ), which represents the quality of the state s . The reward function depends on the target of the DSE. When we are looking for a Initialize tree root  Select node with UCT Expand with graph rewriting Simulate and backprogagate no Current root stop yes Select child as new root no Exploration stop yes output Figure 3: worklow single good trade-of between latency and power, we can weight for example two objectives power д1 (s ) and average latency д2 (s ) to obtain a single scalar reward function Qw s (s ): Qw s (s ) = −1 · (w 1 · д1 (s ) + w 2 · д2 (s )), (3) where w 1 and w 2 are weight factors. the multiplication by -1 is necessary as the reward function must be maximized while latency and power should be minimized. After modelling the DSE as an MDP problem, we are able to apply the MCTS algorithm. The worklow is shown in Fig. 3. It starts from an arbitrary NoC architecture and uses it as the root. The selection, expansion, simulation and backpropagation are executed iteratively to search for the best action to optimize the root. When the budget runs out, the root is replaced by the child node that is generated from the best action. With the new root, the MCTS is re-started. When the complete exploration budget runs out, the algorithm outputs the best one among the explored nodes as well as the sequence of actions that lead to this design. This allows to backtrace all modiications done by the MCTS heuristic. 4 WAVEFRONT-MCTS It is hard to choose the weight factors that can end up with the desired trade-of between average latency and power. In order to obtain better insight into the trade-of, we can compute the complete Pareto front. The Pareto front is made up of the non-dominated points, which are deined for two competing objectives д1 and д2 as: • Dominance: The objective vector ga = [д1 (sa ), д2 (sa )] is dominated by gb , if is gb is better in one of the objectives and not worse in the other. • Non-dominated point: The state sa with objective vector ga = g(sa ) is non-dominated, if there exists no other state sb with gb = g(sb ) that dominates ga . The objective vectors of all non-dominated states form the so-called Pareto front. One can get diferent points of the Pareto front by modifying the weight vectors. Yet there exist better methods to explore the Pareto front in a more systematic way as introduced in the following. 4.1 Max Reward Function We use Max terms to search for non-dominated states, also referred in optimization theory as MinMax optimization. The reward (cid:2870) (cid:2777) Pareto front boundary line : g(cid:3117)−b(cid:3117)n(cid:3117) = g(cid:3118)−b(cid:3118)n(cid:3118) contour line : architectures with  equal costs cost()= cost(cid:4666)g(cid:2869) , g (cid:2870)(cid:4667) = max(cid:4666)g(cid:3117)−b(cid:3117)n(cid:3117) , g(cid:3118)−b(cid:3118)n(cid:3118) )  Figure 4: Reward function Qma x for two-dimension objectives (cid:2869) (cid:2870) (cid:2869)∗ (cid:2869) (cid:2870) (cid:2871) (cid:2869) (cid:2870) (cid:2871) Bias point: (cid:2869) = 0.75 × (cid:2869)∗ + 0.25 × (cid:2870)∗ (cid:2870) = 0.5 × (cid:2869)∗ + 0.5 × (cid:2870)∗ (cid:2871) = 0.25 × (cid:2869)∗ + 0.75 × (cid:2870)∗ (cid:2869) = (cid:2870) = (cid:2871) = (cid:2869)∗ + (cid:2870)∗ Normalization vector: (cid:2870)∗ (cid:2869) Figure 5: Bias point placement for two objectives function is given as: Qma x (s , b, n) = −1 · max( д1 (s ) − b1 n1 , д2 (s ) − b2 n2 ) (4) ≥ n1 д2 −b2 n2 Here, b = [b1 , b2 ]T is the bias vector and n = [n1 , n2 ]T is the normalization vector. Setting the normalization vector and bias vector, the Qma x (s , b, n) searches for non-dominated states with diferent trade-ofs between the objectives. This is illustrated in Fig. 4. A boundary line separates the objective space into two parts. Below and on the boundary line, д1 and д2 satisfy that д1 −b1 , the reward function depends on д1 only. So for architectures below the boundary line, if they have the same д1 , then they have same reward. This creates a set of vertical contour lines as shown in Fig. 4 where we have to lower д1 to gain reward. Similarly, above the boundary line, there exists a set of horizontal contour lines, where we have to lower д2 to gain reward. The highest reward is gained for the crossing between the Pareto front and the boundary line. The boundary line always includes the bias point b and its slope is determined with the normalization vector n. In order to obtain a good spread of points on the Pareto front, the bias vectors and normalization vectors are selected according to the so-called Individual Minima IM. For each objective дm , we set: Q im (s , m) = −1 · дm (s ) (5) Running MCTS for the single objective дm , we can obtain the state s ∗m and the IM g∗m = g(s ∗m ). If the bias vector b is placed near the g∗m , it is more probable to obtain Pareto point that is close to g∗m . One can use the IM to select the bias vectors and normalization vector as follows [5]: n = g∗1 + g∗2 , (6) bn = b(wn ) = G∗ · wx where G∗ = [g∗1 , g∗2 ] and the sum of the elements of the weight vector wn is always 1. One example is shown in Fig. 5. It uses three bias vectors, which are placed equal-distantly between the two IM by choosing the weight vectors accordingly. This leads to a systematic exploration of diferent parts of the Pareto front. This method can be extended to support arbitrary number of objectives, e.g, if we want to see the trade-of between average latency of diferent use case scenarios or also want to consider area.  4.2 Wavefront Feature For each objective дm we run one MCTS exploration with reward function Q im (s , m) and for a pre-chosen set of bias points bn , we run an MCTS exploration using the reward function Qma x (s , bn , n). To increase the eiciency of this exploration, we propose the WavefrontMCTS algorithm. Instead of running independent MCTS explorations, Wavefront-MCTS stores all explored states in one joint MCTS tree. Explorations are parallelized at root level, which means that each exploration can select one node from the tree as its own root and grow according to its own reward function. Meanwhile, diferent explorations can also exchange root nodes with each other. This brings the following beneits: • The eiciency is further improved because there can exist overlaps among the searching spaces of explorations. Once a space is explored, the information can spread to others. • It allows to escape from local optima. When an exploration gets stuck in a local minimum, other exploration may ind better states in other regions of the search tree and share the information. • The bias point depends on the global optimum g∗m for each single objective. It is possible that the exploration for the individual minimum with Q im (s , m) gets stuck in a local optima. Another exploration may then ind a better g∗m than the current known best for a certain objective. In this case, our algorithm can exchange the information and all explorations re-calibrate to the new g∗m . , g∗2 ]. In order to exchange root nodes between explorations, the MCTS algorithm needs to be adapted. The pseudo-code of the WavefrontMCTS is given in Algorithm 2. The inputs consist of an initial state s0 , a set of weight vectors wn and the individual minima [g∗1 The algorithm starts with the initial state as root nodes for all explorations and builds up the MCTS tree. The weight vectors determine N diferent search directions. The MCTS tree grows towards those N directions. For each exploration, it still follows the basic worklow in Fig. 3. It irst tries to search the best action for the current root vr oo t , n by iteratively running the following steps: • SELECT(vr oo t , n , wn , G∗ ) : This function selects and returns the most urgent node vu in the sub-tree with given root vr oo t , n . For each rule, if its LHS can be found in the state s (vu ), it is one of the available actions. If the root has an available action that is never applied, then the root and this rule will be selected. Otherwise, the algorithm searches among all child nodes that have at least one available action and select the one with highest value in the UCT(v , w, G∗ ) function as shown in Alg. 1. • EXPAND(vu ) : This function expands the node vu using graph rewriting. If node vu has non-applied available actions, one of them will be randomly selected and applied on vu . Otherwise, the action will be selected among all available actions. The process of applying a rule is shown in Sec. 3.1. If there exist multiple matches of the LHS, a random match will be selected and get rewritten. The newly generated state creates a new node v ′ . It is added as a child of node vu and its visited time is initialized as N (v ′) = 1. The edge between the new child and vu stores the rule and the selected match to get a complete trace of optimization process. • SIMULATE(V ′ ) : Unlike normal MCTS, the newly generated node is not simulated immediately in Wavefront-MCTS. Instead, newly generated nodes are stored in the set V ′ . After expansions of all N search directions are inished, the set of newly generated nodes V ′ are simulated together to obtain their performances and costs including area, power and average latency. The advantage of this low is that simulations can be parallelized and distributed to multiple threads and even multiple machines. This can signiicantly increase the speed of exploration. • BACKPROPAGATE(V ′ ) : After simulation, the set of newly generated nodes, V ′ , is then backpropagated. For each node v ∈ V ′ , we trace all of its predecessor nodes, including parent, grandparent until the tree root. The visited times of those predecessor nodes are increased by one. • UPDATEMINIMA(G∗ ,V ′ ) : each newly generated node v ′ ∈ V ′ will be compared with current individual minima G∗ = 2 ]. If a node is found better than g∗ 2 , the individual minima will be replaced with the new one. 1 or g∗ 1 , g∗ [g∗ Algorithm 1 UCT Function based on Biased Max Reward Function Input: Node v Weight vector wn Individual Minima G∗ = [g∗ Output: UCT value of node v for weight vector wn 1 , g∗ 2 ] bn ← G∗ · wn n ← g∗1 + g∗2 U CT ← Qma x (s (v ), bn , n) + Cp q 2l n N (vr o o t ) N (v ) return U CT As shown in the worklow in Fig. 3, after a certain number of iterations, the MCTS chooses the most promising action to update its root. For Wavefront-MCTS, the most promising action is the one that created the direct child node of any root node, which leads to the node with highest Qma x value. This is described in Line 22 to 34 of Alg. 2. The current root nodes of diferent search directions are stored in the set Vr oo t and their successor nodes are stored in the set Vs . The roots of various search directions are updated one by one. Each direction n searches for its best node by comparing the quality of nodes using its Qma x reward function together with its weight vector wn . One important feature is that the root update searches among the direct child nodes of all root nodes vr oo t , n . In this way, all search directions can share information between each other. And the best node for direction n may exist not in the sub-tree of its own root vr oo t , n but in the sub-tree of another search direction, e.g., due to local minima or when one exploration discovers a very competitive state. In this case, the exploration can move to the root of another search direction. 5 EXPERIMENTAL RESULTS Our experiments are performed with several benchmark applications. They consist of the multimedia application obtained from [9], the SoC benchmark used in the European project NaNoC [1], the industrial mobile phone application [2] and a synthetic MPSoC application with uniform distributed communication load. The multimedia application and MPSoC application each consist of 16 PEs, Algorithm 2 Wavefront-MCTS Algorithm 1: Input: Initial state s0 Weight vectors W = [w1 , . . ., wN ] Individual Minima G∗ = [g∗ 4: Output: Non-dominated states S ∗ , MCTS Tree T 1 , g∗ 2: 3: 2 ] 5: T ← ADDNODE(∅, v0 ) with s (v0 ) = s0 6: for n = 1 to N do vr oo t , n ← v0 , with s (v0 ) = s0 8: end for 9: for l = 1 to L do 7: 10: while within computation budget do V ′ ← ∅ for n = 1 to N do vu ← SELECT(vr oo t , n , wn ,G∗ ) v ′ ← EXPAND(vu ) V ′ ← V ′ ∪ {v ′ } T ←ADDNODE(T , v ′ ) end for SIMULATE(V ′ ) BACKPROPAGATE(V ′ ) UPDATEMINIMA(G∗ ,V ′ ) end while Vs ← ∅ , Vr oo t ← ∅ for n = 1 to N do Vr oo t ← Vr oo t ∪ {vr oo t , n } Vs ← Vs ∪ {vu | vu is on subtree with root vr oo t , n } end for for n = 1 to N do bn ← G∗ · wn vb e s t ← arg maxv ∈Vs Qma x (s (v ), bn , n) while the parent of vb e s t < Vr oo t do n ← g∗1 + g∗2 vb e s t ← the parent of vb e s t end while vr oo t , n ← vb e s t 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: 30: 31: 32: 33: 34: end for 35: end for 36: S ∗ ← FINDNONDOMINATEDSTATES(T ) 37: return S ∗ , T the mobile application consists of 22 PEs and the NaNoC application consists of 25 PEs. The initial NoC designs are created based on the classical mesh architecture. We use ORION 3.0 [11] to provide a good estimation on the NoC power and area. Cycle-accurate SystemC simulations are applied to obtain the communication latency. They are executed in parallel to obtain a fast DSE. The LISNoC [18] is used as baseline to generated VHDL codes at RTL level to calibrate the ORION and the SystemC models. In order to obtain a working NoC, a routing must be set as well. Here we use a custom deterministic routing generator. The routing paths for each low are found by solving an Integer Linear Program (ILP) that minimizes the routing path length and conlicts at the router output ports. Table 1: Comparison between Optimization Heuristics Testbench Method Multimedia Mobile NaNoC MPSoC Initial SA GA MCTS Initial SA GA MCTS Initial SA GA MCTS Initial SA GA MCTS Area (um2 ) 324207 62349 225782 39183 563529 303679 302679 114253 571403 278813 305318 96456 324207 188438 204266 138016 Power (mW ) 66.7 13.01 47.2 8.12 115.28 62.15 62.16 23.52 116.97 57.01 63.21 19.87 66.31 38.75 41.53 28.86 Latency (Cycles) 43.28 15.13 28.98 13.89 16.2 12.72 14.79 13.56 15.2 12.42 14.14 13.3 20.47 15.57 18.33 16.19 Qw s (s ) -183.3 -46.9 -126.97 -36.68 -306.1 -204.89 -225.6 -165 -249.47 -165.88 -194.08 -149.56 -287.59 -204.14 -235.21 -197.97 5.1 Comparison of MCTS with SA and GA Our experiments compare the MCTS optimization heuristic with other popular methods: Simulated Annealing (SA) and a Genetic Algorithm (GA). All three methods start from the same initial designs and are allocated the same computation budget. They also share the same overall weighted sum reward function Qw s (s ) for fair comparison. The area is not used in the reward function because it is correlated to the power as can be seen from the experimental results in Table 1. In application-speciic NoC synthesis, other parameters and goals may be of importance: Some lows may be more latency-sensitive than others, several use cases may exist and must be eiciently executed on the same platform and so on. This can all be included in the weighted reward function as long as weights are supplied to set the preference of each goal. Compared with initial designs, all three methods obtain significant improvements. Clearly, all benchmark systems do beneit from a custom-it NoC architecture. For the multimedia application, the SA improves the reward function by 74.21%, GA by 30.73% and MCTS by 79.99%. Also in all other benchmark systems, MCTS achieves the highest reward gain. So, as can be seen, MCTS is a very competitive heuristic. Of course, each heuristic can be further optimized to perform better on the NoC DSE problem. We believe the comparison is fair, as a rather standard implementation of each heuristic is used. MCTS performs very well and better than the other heuristics because it is designed to balance exploration vs. exploitation very well. 5.2 Wavefront Feature The Wavefront feature was introduced to improve the eiciency of standard MCTS when we want to compute the complete Pareto Front. To show its eiciency, we compute the Pareto front between power and average latency for the MPSoC benchmark. Both use 9 search directions with the same set of weight vectors using the Qma x reward function. Their exploration budgets are both set to 15 20 25 Average Latency [cycles] 140 120 100 80 60 40 20 P o w e r [ m W ] Wavefront MCTS MCTS (a) At 2k explored architectures 15 20 25 30 Average Latency [cycles] 0 100 200 P o w e r [ m W ] Wavefront MCTS MCTS (b) At 5k explored architectures 0 10 20 30 40 Average Latency [cycles] 100 200 300 400 P o w e r [ m W ] Wavefront MCTS MCTS (c) At 10k explored architectures 0 10 20 30 40 Average Latency [cycles] 100 200 300 400 P o w e r [ m W ] Wavefront MCTS MCTS (d) At 20k explored architectures Figure 6: Comparison of Wavefront-MCTS vs. MCTS without Wavefront Feature 20k NoC simulations. Fig. 6 shows diferent stages of the exploration. At an early stage, when Wavefront-MCTS and MCTS explored 2k archtiectures each, the Wavefront-MCTS is already signiicantly ahead of MCTS. Similar behavior can be observed in Fig. 6(b) when each of them explored 5k architectures. In Fig. 6(c), the non-dominated states of MCTS are also not anymore dominated by Wavefront-MCTS, but the Wavefront-MCTS covers a much larger range of the Pareto front. Wavefront-MCTS already inds a stable front after exploring 10k architectures, while this is observed for standard MCTS for 20k architectures. Hence, the Wavefront feature improves eiciency signiicantly without adding any signiicant computational overhead. 5.3 Comparison: Wavefront-MCTS vs. NSGA-II Our experiments also compare the Wavefront-MCTS algorithm with one of the most popular multi-objective optimization heuristics, the NSGA-II algorithm [7]. The results are shown in Fig. 7. For the MPSoC benchmark in Fig. 7(a), the non-dominated architectures of Wavefront-MCTS range from (11.04 , 340) to (36.23 , 7.195). In comparison, the ones of NSGAII range from (12.45 , 162) to (31.03 , 15.22). The minimum power found by Wavefront-MCTS is 52.73% lesser than the minimum power found by NSGA-II and the minimum latency is 11.33% lesser. For the mobile benchmark in Fig. 7(b), the Wavefront-MCTS also covers a wider range of the Pareto front. The discovered non-dominated architectures of both methods do not dominate one or the other. For the NaNoC benchmark in Fig. 7(c), the Wavefront-MCTS covers a much wider range of the Pareto front. Yet, the solution discovered by NSGA-II dominate the ones from MCTS in some parts of the front. Here Wavefront-MCTS did not yet stabilize and discover the complete front. For the multimedia benchmark in Fig. 7(d), all explored architectures are shown. As becomes obvious, there exist architectures that can both optimize power and latency very well for the system. These were discovered by the Wavefront-MCTS algorithm, while they were not found by NSGA-II. So overall ,we can conclude, that Wavefront-MCTS is very competitive when we target to explore the complete Pareto 0 10 20 30 40 Average Latency [cycles] 200 400 P o w e r [ m W ] Wavefront MCTS NSGAII (a) MPSoC 0 10 20 30 Average Latency [cycles] 50 100 P o w e r [ m W ] Wavefront MCTS NSGAII (b) Mobile 0 10 15 20 Average Latency [cycles] 50 100 150 P o w e r [ m W ] Wavefront MCTS NSGAII (c) NaNoC 10 20 30 40 Average Latency [cycles] 20 40 60 80 P o w e r [ m W ] Wavefront MCTS NSGAII (d) Multimedia Figure 7: Wavefront-MCTS vs.NSGA-II Comparison front. Especially the systematic search with the Qma x reward function allows to discover the complete range of the Pareto front very eiciently. 5.4 Interactive DSE One important feature of the MCTS-based approach is that it can be traced very well and allows for an interactive DSE. This is demonstrated with the mobile benchmark. The initial architecture is a 5x5 mesh as shown in Fig. 9(a). The trace of an exploration path is shown in Fig. 8. This is the path taken by the actions to move from root node to next root node. It shows the performance and power gain for each action on the optimization path together with each action which are shown in the lower part of the Figure. Architectures can also be traced along the optimization path. The intermediate architecture after applying 30 actions is shown in Fig. 9(b). Compared with the initial architecture, many links were removed as well as some redundant routers. As a result, the power and area are reduced, but meanwhile due to less routing resources, some lows have to choose longer and more crowded paths. This is conirmed in Fig. 8 that architecture with index 30 has a low power but high latency. The inal architecture is shown in Fig. 9(c). Compared with the intermediate architecture in Fig. 9(b), PEs were re-grouped. They are those that communicate with a high bandwidth between each other. This is beneicial to reduce latency. But for power, the inluence is not straightforward. On one hand, actions removed more redundant links and routers reducing power. On the other hand, actions created some high-radix routers increasing power. It is diicult to predict which efect is stronger. But this is shown in the performance trace in Fig. 8. Compared with the intermediate architecture of index 30, the last output architecture has a much lower latency and a slightly higher power. In general, designers can also control the exploration interactively. One may only run MCTS for a limited number of actions, then apply actions manually, or re-start the exploration from a given design, possibly, modifying the preferences for the goals. The trace also shows how MCTS balances exploration vs. exploitation. From short term view, the irst two actions seem to be a                 Mobile -> 1 : Remove Link R1 to R6   1 -> 2 : Remove Link R16 to R21  2 -> 3 : Remove Link R12 to R13  3 -> 4 : Remove Link R10 to R11  4 -> 5 : Remove Link R14 to R13  5 -> 6 : Remove Link R22 to R17  6 -> 7 : Remove Link R19 to R14  7 -> 8 : Shift  DMA from R2 to R18  … …  30 -> 31 : Shift SRAM1 from R18 to R16   31 -> 32 : Shift  CPU from R8 to R2  32 -> 33 : Add Link R24 to R4   … …  5  10  15  20  25  30  35  40  50  45  55  60  63  Figure 8: Exploration Trace for Mobile Benchmark bad decision, because they obtain only a slight power reduction but sacriice a lot of latency. However, from long term view, they are beneicial because, in the following actions, the power is reduced while latency remains almost constant. To select the best action for the current node, MCTS not only explores the direct children, but also explores successor nodes that are generated after multiple actions based on the UCT function. 6 CONCLUSION This paper formulates the NoC DSE as MDP and uses graph rewriting to deine MDP actions and the transition function. This approach supports an interactive design and traceability by the designers. The MCTS heuristic is applied and shows high eiciency compared to the classical GA and SA algorithm. Further, WavefrontMCTS is proposed. Compared with the popular NSGA-II algorithm, it can cover a larger range of the Pareto front while not sacriicing quality of non-dominated architectures. "
2018,Hybrid on-chip communication architectures for heterogeneous manycore systems.,"The widespread adoption of big data has led to the search for highperformance and low-power computational platforms. Emerging heterogeneous manycore processing platforms consisting of CPU and GPU cores along with various types of accelerators offer power and area-efficient trade-offs for running these applications. However, heterogeneous manycore architectures need to satisfy the communication and memory requirements of the diverse computing elements that conventional Network-on-Chip (NoC) architectures are unable to handle effectively. Further, with increasing system sizes and level of heterogeneity, it becomes difficult to quickly explore the large design space and establish the appropriate design trade-offs. To address these challenges, machine learning-inspired heterogeneous manycore system design is a promising research direction to pursue. In this paper, we highlight various salient features of heterogeneous manycore architectures enabled by emerging interconnect technologies and machine learning techniques.","Hybrid On-Chip Communication Architectures for  Heterogeneous Manycore Systems  (Invited Paper)  Biresh Kumar Joardar*, Janardhan Rao Doppa*, Partha Pratim Pande*, Diana Marculescu†, Radu Marculescu†  *School of EECS, Washington State University   †ECE Department, Carnegie Mellon University   Pullman, WA 99164, U.S.A.   Pittsburgh, PA 15213, U.S.A.  {biresh.joardar, jana.doppa, pande}@wsu.edu  {dianam, radum}@cmu.edu  ABSTRACT  The widespread adoption of big data has led to the search for highperformance and low-power computational platforms. Emerging  heterogeneous manycore processing platforms consisting of CPU  and GPU cores along with various types of accelerators offer  power and area-efficient trade-offs for running these applications.  However, heterogeneous manycore architectures need to satisfy  the communication and memory requirements of the diverse  computing elements that conventional Network-on-Chip (NoC)  architectures are unable to handle effectively. Further, with  increasing system sizes and level of heterogeneity , it becomes  difficult to quickly explore the large design space and establish the  appropriate design trade-offs. To address these challenges,  machine  learning-inspired heterogeneous manycore system  design is a promising research direction to pursue. In this paper ,  we highlight various salient features of heterogeneous manycore  architectures enabled by emerging interconnect technologies and  machine learning techniques.   CCS CONCEPTS  • Hardware → 3D integrated circuits; Network on Chip;  Thermal optimization; • Computer systems organization →  Neural networks; • Theory of computation → Optimization  with randomized search heuristics  KEYWORDS  Manycore, Heterogeneous Network-on-Chip, Machine Learning  ACM format:  B. K. Joardar, J. R. Doppa, P. P. Pande, D. Marculescu, and R. Marculescu.  2018. Hybrid On-Chip Communication Architectures for Heterogeneous  Manycore Systems. In ICCAD, November 2018, San Diego, CA, USA  https://doi.org/10.1145/3240765.3243480  1 INTRODUCTION  Machine learning, graph analytics, and other big-data applications  have become crucial for many domains. This has led to a search  for appropriate computing systems that can efficiently handle the  tremendous amount of data and computation that is associated  Permission to make digital or hard copies of all or part of this work for personal or  classroom use is granted without fee provided that copies are not made or distributed  for profit or commercial advantage and that copies bear this notice and the full  citation on the first page. Copyrights for components of this work owned by others  than ACM must be honored. Abstracting with credit is permitted. To copy otherwise,  or republish, to post on servers or to redistribute to lists, requires prior specific  permission and/or a fee. Request permissions from Permissions@acm.org.  ICCAD '18, November 5–8, 2018, San Diego, CA, USA  © 2018 Association for Computing Machinery.  ACM ISBN 978-1-4503-5950-4/18/11…$15.00  https://doi.org/10.1145/3240765.3243480  © 2017 Association for Computing Machinery.  ACM ISBN 978-1-4503-4984-0/17/10…$15.00  with these applications. Large-scale data centers and highperformance computing clusters (HPCs) are employed to solve  these compute- and data-intensive applications. However, the  design of data centers and HPC clusters is dominated by power ,  area and thermal constraints. On the contrary, emerging  manycore processing platforms that consist of CPU and GPU  cores along with memory controllers (MCs) and accelerators have  small footprints and offer a power and area-efficient proposition  for running various big data applications. In these heterogeneous  manycore systems, diverse computational units have varied and  often conflicting Quality-of-Service (QoS) requirements [1, 2].  Therefore, an efficient heterogeneous architecture needs to satisfy  these communication requirements simultaneously within a  limited power budget.   To integrate these large numbers of embedded cores in a single  die, Network-on-Chip (NoC) has emerged as an enabling solution  to facilitate more efficient communication. However, typical NoC  infrastructures employed in conventional manycore platforms are  sub-optimal to handle specific needs of individual cores. As an  example, most of the NoCs targeting discrete GPU systems are  based on conventional wired NoC architectures [3]. For a  heterogeneous architecture designed with conventional NoCs, e.g.  Mesh, there exist a few links that are heavily utilized when  compared to the rest of the links in the NoC [1]. During high  traffic, such links become bandwidth bottlenecks, thereby  negatively affecting the overall system performance.    To address these challenges, we need to explore design  methodologies for an optimal NoC as the interconnection  backbone for heterogeneous manycore chips that can efficiently  handle the communication requirements of CPUs, GPUs, and  application-specific accelerators. Therefore, heterogeneous  manycore system design can be formulated as a multi-objective  optimization (MOO) problem. Furthermore, as system size and  level of heterogeneity increases, conventional MOO algorithms  take significant amount of time to find near-optimal solutions due  to their relatively unguided nature of design space exploration.   To reduce the design time for finding near-optimal solutions,  more efficient and scalable optimization techniques are required.  Machine learning (ML) inspired techniques present a promising  direction to explore in this regard. Moreover, novel design  optimization methodologies need to be complemented with  innovations in the overall interconnection architecture . Hence,  we should exploit the benefits offered by the emerging NoC  architectures like wireless NoC (WiNoC), 3D NoC, etc. to design  energy–efficient and low-latency communication infrastructures  for massive manycore chips targeting big data applications.     In this paper, we present a detailed study of the communication  requirements of heterogeneous architectures consisting of CPUs,  GPUs and MCs. Subsequently, we highlight the potential of MLbased design optimization methodology for heterogeneous  manycore platforms. Next, we describe the role of emerging  interconnects in designing high-performance and energy-efficient  heterogeneous manycore systems. Specifically, we discuss the  design of (a) hybrid wired/wireless NoC, and (b) 3D NoC  architecture to highlight the role of emerging interconnects in the  design of heterogeneous manycore chips. This paper is a part of  the ICCAD 2018 Special Session on ""Managing Heterogeneous  Many-cores for High-Performance and Energy-Efficiency"". The  other two papers of this Special sessions are : “Dynamic Resource  Management for Heterogeneous Many-Cores” [6] and “Online  Learning for Adaptive Optimization of Heterogeneous SoCs” [7].  2 Heterogeneous Manycore Architectures   In this section, we describe the challenges associated with  designing an efficient CPU-GPU based manycore architecture.  More specifically, we  first analyze  the communication  requirements of various types of cores. Next, we study the  limitations of existing NoC architectures for heterogeneous  systems to motivate the need for a better on-chip communication  infrastructure.  2.1 Many-to-few communication patterns  A CPU-GPU based heterogeneous manycore architecture  typically consists of a few CPUs, MCs, and a large number of  GPUs. The MCs are shared among CPU and GPU cores, and  provide a unified virtual memory space for the processors. Each  MC incorporates a Last Level Cache (LLC) and a mechanism to  access the main memory. Each processing core in the system  maintains its own L1 cache and mainly communicates with the  few MCs. Fig. 1 shows an example heterogeneous system with  multiple CPU, GPU and MCs.   Due to heterogeneity among the constituent cores, CPU-GPU  based systems exhibit several interesting traffic characteristics.  GPUs exhibit high data parallelism with fast context-switching  capabilities. Owing to its distinct architecture, GPUs achieve high  throughput while hiding much of the memory access latency.  However, this requires large volumes of data to be communicated,  which necessitates the design of a high bandwidth network. In  other words, GPUs are throughput-sensitive [4, 5]. Also, processes  executed in each GPU core are usually independent of processes  in other GPUs, resulting in low inter-GPU communication [8]. On  the other hand, GPUs communicate heavily with the few shared  MCs. As a result, the communication resembles a many-to-few  pattern, where many GPUs communicate with few MCs [8, 9].  Contrary to GPUs, CPU cores use instruction-level parallelism to  achieve high performance on a limited number of threads. If any  of these threads stall, CPUs incur a large penalty. Therefore, CPUs  are more sensitive to the memory access times and hence,  communications  involving CPUs require  low-latency data  Fig. 1: Overview of the considered heterogeneous architecture.  The system is divided into CPU, GPU, and MC tiles. Tiles are  interconnected via an NoC. This figure is for illustration purposes  only; it is not optimized for any specific design metric.  In a heterogeneous manycore architecture,  the  traffic  requirements vary depending on the type of nodes involved in  data exchanges. The CPU-MC communications are primarily  latency-sensitive, while the GPU-MC communications are more  throughput-sensitive [4, 5]. Hence, an NoC designed for  heterogeneous CPU-GPU systems must be optimized to ensure  that the CPU-MC communication latency is minimized, while the  overall NoC throughput is maximized. Finally, application specific accelerators come with widely varying memory access  patterns and QoS requirements in terms of latency and  throughput. All these features need to be considered while  designing the overall NoC architecture .  Fig. 2. Traffic pattern heat map for Backpropagation and BreadthFirst Search running on a 64-tile heterogeneous manycore system.  2                                                  e g a t n e c r e P c i f f a r t f o 100% 75% 50% 25% 0% CORE-MC CORE-CORE BP BFS CDN GAU HS LEN LUD NW KNN PF Fig. 3. Traffic breakdown showing the percentage of traffic  between (in either direction) MC and either CPU or GPU (COREMC) and between CPUs-CPUS, GPUs-GPUs and CPUs-GPUs  (CORE-CORE, either direction) for a 64-tile manycore system.   exchanges with the MCs. Existing NoC designs targeting discrete  GPU systems typically attempt to improve the overall bandwidth  [8, 9]. Consequently, these NoC designs are not suitable for  heterogeneous manycore architectures incorporating multiple  CPUs and GPUs on the same die. As an example, we show the  communication pattern observed  in a CPU-GPU based  heterogeneous system for the Backpropagation (BP) and BreadthFirst Search (BFS) benchmarks from the Rodinia suite [10]  running on a generic 64-tile system (8 CPUs, 16 MCs, and 40  GPUs) in Fig. 2. Other relevant big data benchmarks (considered  in Fig. 3) exhibit similar communication patterns when run on the  heterogeneous system.   Some of the  interesting  features we observe  from the  communication patterns shown in Fig. 2 are listed below:  • GPU-MC pairs exhibit heavy but nearly uniform traffic  due to well distributed and parallelized GPU workloads.  Communication between the other pairs of cores, e.g.,  GPU-GPU is insignificant.   Similar to GPUs, the CPUs mostly communicate with the  MCs. Interestingly, the CPU-GPU communication is  almost non-existent.  • Majority of the traffic (more than 80% on average) is  associated with the MCs.  From the above observations, we notice that both CPU and GPU  cores communicate with the MCs. As the number of GPUs are  usually much higher, GPU traffic often monopolizes the network  and causes congestion [11]. As a result, CPU traffic is stalled  leading to more idle cycles in CPUs. Additionally, since  heterogeneous systems typically have a small number of MCs, this  creates many-to-few communication pattern, especially between  the GPUs and the MCs [8].  Fig. 3 shows the percentage of total  traffic going to/from the MCs for 8 different Rodinia benchmarks  (BP: Backpropagation, BFS: Breadth first search, GAU: Gaussian,  •  f o e g a t n e c r e P s k n i L 25% 20% 15% 10% 5% 0% Opt Mesh σopt μmesh = 1.4μopt σmesh = 1.8σopt μopt μmesh Number of flits Fig. 4. Distribution of load (traffic) among links in Mesh NoC as  opposed to an NoC optimized for many-to-few traffic (Opt).   HS: Hotspot, LUD: LU decomposition, NW: Needleman -Wunsch,  KNN: K-Nearest Neighbor, and PF: Pathfinder) and 2 CNNs (CDN:  CNN for Cifar-10 [12] and LEN: CNN for digit recognition [13]).  We observe from Fig. 3 that on an average 80% of the total traffic  is associated with the few MCs leading to many-to-few (many  cores communicating with few MCs) communication irrespective  of the benchmark. As a result, without proper architectural  support, MCs (and links associated with them) can become traffic  hotspots, thereby negatively impacting the overall performance.   2.2 Disadvantages of conventional NoCs  Conventional NoCs like mesh and ring are not suitable for  handling many-to-few communication patterns observed in  heterogeneous manycore systems. As the number of cores on a  single chip increases, the hop count of these NoCs increase too.  Increased hop count leads to higher network latency and energy  consumption, while lowering the system throughput [14].   As an example, in this section, we analyze the performance of a  mesh NoC under many-to-few communication. Mesh NoC is the  preferred design for on-chip communication due to its simplicity.  Intel’s Xeon Phi and Tilera’s TILE are examples of commercially  available architectures using Mesh NoC. Fig. 4 shows the  distribution of traffic among links in a 64-core CPU-GPU based  heterogeneous system. For comparison, we consider two flavors  of NoCs: a) regular mesh, and b) many-to-few traffic optimized  architecture (Opt) while executing the LeNet [13] benchmark.  LeNet is a 7-layer Convolutional Neural Network (CNN) used for  digit classification. It consists of alternate convolution and pooling  layers followed by a pair of fully-connected layers. It is clear from  Fig. 4 that even in an optimized mesh, there is a wide imbalance  in the amount of load carried by each link. This is because, mesh  NoC lacks path diversity and hence some of the links (near the  MCs) are over-utilized as many cores attempt to repeatedly access  the few MCs via limited number of links. As can be observed, some  of these links carry more than three times the average number of  flits whereas links far from MCs are often under-utilized. As a  result,  these over-utilized  links become  the sources of  performance bottleneck under heavy many-to-few traffic leading  to higher latency and reduced throughput [1]. Therefore,  conventional NoC architectures like mesh are not suitable for  heterogeneous systems.   To overcome these challenges, it is of paramount importance to  explore design of application-specific NoCs  that  can  simultaneously meet the various QoS requirements. Additionally,  we need to exploit the advantages provided by emerging NoC  architectures, e.g., wireless and 3D interconnects, to achieve  energy-efficiency and high-performance.   3 Heterogeneous NoC with Emerging  Interconnects  In this section, we first discuss the need for efficient design space  exploration algorithms, and then explore ML-based techniques for  efficient NoC design. Next, we present salient features of two  emerging NoCs with (a) Hybrid wireline/wireless links, and (b)                      P D E d e z i l a m r o N AMOSA TSTAGE = 9 hrs MOO-STAGE TAMOSA = 85 hrs 80 1.5 1.4 1.3 1.2 1.1 1 0.9 0 4 8 12 Time (hrs) 16 20 24 Fig. 5. Normalized quality of NoC solutions (EDP) obtained  using AMOSA and MOO-STAGE for multiple objectives  (Latency, Throughput, Energy) for the BFS benchmark.  3D-TSV/planar  links  that  can  handle many-to-few  communication and satisfy all the QoS objectives simultaneously.    3.1 ML-enabled NoC design optimization   In this section, we discuss a ML-based methodology for  optimizing the heterogeneous NoC design that reduces the design  time significantly without sacrificing the solution quality. For a  CPU-GPU based heterogeneous architecture (shown in Fig. 1), it  is important that we optimize for (a) CPU-MC latency, and (b)  GPU-MC throughput. Apart from these design metrics, there are  additional objectives including energy, temperature, etc. The NoC  for heterogeneous systems should satisfy all these design  requirements and efficiently handle the many-to-few traffic.  Hence, designing the NoC targeting heterogeneous manycore  systems can be formulated as a multi-objective optimization  (MOO) problem. Genetic algorithms (e.g., NSGA-II [15]) and  simulated annealing based AMOSA [16] are some of the most  widely-used MOO techniques. However, with growing design  space and number of objectives, these algorithms suffer scalability  challenges to find near-optimal designs as they do not  learn/leverage the knowledge from the designs explored in the  past. These algorithms determine whether to visit neighboring  solutions based on the current solution set. This require s  significant time since the algorithm may need to traverse many  neighborhoods before reaching a good solution or require many  restarts with different initial solutions to find better local optima .  Therefore, more efficient, accurate, and scalable design  optimization techniques are required.   To this end, ML frameworks can be instantiated to improve the  scalability of existing algorithms to find near-optimal designs  [17]. The key idea in ML-based frameworks is to learn appropriate  form of search control knowledge based on the designs explored  in the past to intelligently explore the design space ; this can  provide significant improvements in the optimization time  without sacrificing solution quality. For homogeneous NoC  design, ML-based  techniques have shown great promise  outperforming conventional optimization algorithms  [17].  Inspired by this success, we show the performance of MOOSTAGE, a generalization of the STAGE algorithm to solve MOO  problems [17,18], for the purpose of heterogeneous NoC design .  STAGE [18] is an online learning algorithm originally developed  4  to improve the performance of local search algorithms (e.g., hill  climbing) for single objective optimization problems.   For standard local search procedures, e.g. hill-climbing, simulated  annealing, etc., one of the key limitations is that the quality of the  local search critically depends on the starting point of the search  process. To mitigate this, MOO-STAGE learns an evaluation  function from previous search trajectories and predicts the  promise of a design as a starting solution for local search. This  allows MOO-STAGE to prune away bad starting states and  reduces the number of searches needed to find (near-) optimal  designs in a given design space. Conventional MOO algorithms  based on random restarts do not leverage any such knowledge and  spend significant time searching from states that would otherwise  be rejected by MOO-STAGE.   Fig. 5 shows the Energy-Delay Product (EDP) comparison  between ML-based MOO-STAGE, and a widely used conventional  MOO algorithm AMOSA. Here, both algorithms are applied to the  problem of designing a 3D heterogeneous NoC while considering  multiple objectives (latency, throughput, and energy) with the  BFS benchmark from the Rodinia suite [10] as an example. From  Fig. 5, it is clear that MOO-STAGE finds better NoC design  solutions much faster than AMOSA, which spends 9X more time  before reaching within 3% of the solution quality of MOO-STAGE.  Of note, AMOSA never finds a better solution even after running  for a significantly longer period of time. Similar observations are  made for other benchmarks (considered in Fig. 3) as well. Hence,  we can conclude that MOO-STAGE is suitable for efficient  exploration of the heterogeneous manycore systems design space.  Next, we look into the role of emerging NoC architectures for  energy-efficient and high-performance manycore system design.  As case studies, we discuss the use of wireless and 3D  interconnects for heterogeneous manycore systems.  3.2 Wireless NoC  Wireless NoC (WiNoC) is capable of achieving energy–efficient  and low-latency communication infrastructures for massive  manycore chips [19]. The wireless links provide long range  shortcuts for greatly reducing the communication latency  between physically distant cores.   As a case study, we design a hybrid NoC architecture comprising  of both wireline and wireless links customized for the CPU-GPU  heterogeneous computing platform for training two popular  CNNs, namely LeNet [13] and CDBNet [12] (using MNIST and  CIFAR-10 datasets respectively). We call this proposed NoC a  Wireless-enabled Heterogeneous NoC (WiHetNoC). Similar to  LeNet (described in Sec 2.2), Convolutional Deep Belief Neural  Network (CDBNet) consists of three convolution layers followed  by pooling layers, and one fully connected layer (total: 7-layers).  CDBNet is used to perform image recognition involving colored  images from ten different object classes (CIFAR-10 dataset).   It has been already demonstrated that for multi-hop on-chip  communication, mm-wave wireless links can achieve a lower EDP  when compared to wireline links [20, 21]. The use of single-hop                                                                                        wireless links between CPUs and MCs not only enables low  latency single-hop CPU-MC data exchanges, but also makes the  NoC design agnostic of the CPU and MC placements and instantly  fulfills the CPU QoS requirements. Hence, it is advisable to use  dedicated single-hop wireless links for CPU-MC communication.  The GPU-MC communication is handled through a combination  of wireline and wireless links that are tailored to the many-to-few  traffic pattern. To fulfill the GPU QoS requirements, the network  throughput of the WiHetNoC should be maximized.    Figs. 6 and 7 show the latency and EDP of the WiHetNoC with  respect to an optimized wireline-only counterpart (HetNoC) and a  generic mesh respectively (all values normalized with respect to  mesh). The HetNoC has the same architecture as the WiHetNoC  with long-range wireline links in place of the wireless links.  It is  clear from these figures that WiHetNoC enables 24% more latency  and 29% more EDP improvement on an average for both LeNet  and CDBNet, when compared to the HetNoC. Additionally, when  compared to the mesh NoC, WiHetNoC achieves 42% lower  network latency and 59% better EDP on an average. These results  demonstrate that WiHetNoC can provide more performance  benefits compared to its wireline counterparts for heterogeneous  manycore systems.   3.3 Three-Dimensional (3D) NoC   Similar to WiNoC, 3D NoC is another emerging interconnect  paradigm that can be utilized as the communication backbone for  heterogeneous manycore systems. In 3D NoCs, planar dies are  stacked on top of each other and connected via vertical links.  These vertical links connect the tiles in adjacent layers analogous  to the long-range shortcuts in WiHetNoC enabling low latency  communication in manycore systems.  However, 3D NoCs for heterogeneous systems pose several  design challenges. Like the WiHetNoC, the 3D NoC also must  handle the traffic requirements of both CPU and GPU  communications. Moreover, 3D NoC must address the thermal  issues inherent in 3D ICs [2]. The communication requirements  of CPUs and GPUs can be optimized similar to the WiHetNoC.  However, 3D NoCs impose an additional temperature constraint.  Hence, the optimization procedure for 3D heterogeneous NoC  design must consider the joint effects of both temperature and  performance.  By addressing the above-mentioned challenges, we can design a  3D NoC architecture customized for the CPU-GPU heterogeneous  manycore platforms [2]. Next, to demonstrate the benefit of  jointly optimizing both performance and temperature, we choose  two flavors of heterogeneous 3D NoC architectures, (a) Only  optimized for performance similar to WiHetNoC (3DHetperf) and  its mesh equivalent (3DMeshperf), (b) Jointly-optimized for  temperature and performance  (3DHettherm) and  its mesh  equivalent (3DMeshtherm). Fig. 8 compares the network EDP and  temperature of 3DHettherm with respect to the similarly optimized  3DMeshtherm and the performance-only optimized NoCs 3DHetperf  and 3DMeshperf for LeNet and CDBNet. It is clear from Fig. 8 that  by jointly optimizing both performance and thermal, 3DHettherm  (a) (b) Fig. 6. Normalized network latency with respect to mesh for training (a) LeNet (b) CDBNet. (C: Convolution, P: Pooling, F: Full Connect)[1]  1 0.8 0.6 0.4 0.2 0 C1 P1 C2 P2 C3 F1 F2 C1 P1 C2 P2 C3 F1 F2 FORWARD BACKWARD N o r m a i l z d e L a t n e y c WiHetNoC HetNoC 1 0.8 0.6 0.4 0.2 0 C1 P1 C2 P2 C3 P3 F1 C1 P1 C2 P2 C3 P3 F1 FORWARD BACKWARD N o r a i l z d e L a t n e y c WiHetNoC HetNoC CIFAR (a) LeNet CIFAR (b) LeNet Fig 8: Temperature profile and EDP for different NoCs: (a) Maximum system temperature and (b) network EDP. [2]  40 55 70 3DMeshperf 85 T e m p e r a t u r e ᵒ ( C ) 3DHetperf 3DMeshtherm 3DHettherm CDBNet 3DMeshperf 1 0.75 0.5 0.25 0 N o r m a i l e z E d D P 3DMeshtherm 3DHetperf 3DHettherm CDBNet FORWARD (a) BACKWARD (b) Fig. 7. Normalized network EDP with respect to mesh for training (a) LeNet (b) CDBNet. (C: Convolution, P: Pooling, F: Full Connect) [1]  1 0.8 0.6 0.4 0.2 0 C1 P1 C2 P2 C3 F1 F2 C1 P1 C2 P2 C3 F1 F2 N o r m a i l z E d e D P WiHetNoC HetNoC 1 0.8 0.6 0.4 0.2 0 C1 P1 C2 P2 C3 P3 F1 C1 P1 C2 P2 C3 P3 F1 FORWARD BACKWARD N o r m a i l z E d e D P WiHetNoC HetNoC                                                 machine learning aided techniques for more efficient design space  exploration to reduce the design time. We have also highlighted  the benefits of using emerging interconnect technologies (e.g.  wireless and 3D integration) for heterogeneous manycore system  design. Compared  to  their  conventional wireline-only  counterparts, emerging Network-on-Chip architectures provide  higher performance and  lower energy consumption  for  heterogeneous manycore systems.    ACKNOWLEDGMENTS  2.  [5]  [6]  "
2018,CustomTopo - a topology generation method for application-specific wavelength-routed optical NoCs.,"Optical network-on-chip (NoC) is a promising platform beyond electronic NoCs. In particular, wavelength-routed optical network-on-chip (WRONoC) is renowned for its high bandwidth and ultra-low signal delay. Current WRONoC topology generation approaches focus on full-connectivity, i.e. all masters are connected to all slaves. This assumption leads to wasted resources for application-specific designs. In this work, we propose CustomTopo: a general solution to the topology generation problem on WRONoCs that supports customized connectivity. CustomTopo models the topology structure and its communication behavior as an integer-linear-programming (ILP) problem, with an adjustable optimization target considering the number of add-drop filters (ADFs), the number of wavelengths, and insertion loss. The time for solving the ILP problem in general positively correlates with the network communication densities. Experimental results show that CustomTopo is applicable for various communication requirements, and the resulting customized topology enables a remarkable reduction in both resource usage and insertion loss.","CustomTopo: A Topology Generation Method for Application-Speciﬁc Wavelength-Routed Optical NoCs Mengchu Li† ▽ , Tsun-Ming Tseng† , Davide Ber tozzi⋆ , Mahdi Tala⋆ , and Ulf Schlichtmann† mengchu.li@campus.lmu.de, {tsun-ming.tseng, ulf.schlichtmann}@tum.de, {davide.bertozzi, mahdi.tala}@unife.it †Chair of Electronic Design Automation, Technical University of Munich, Arcisstraße 21, 80333 M¨unchen, Germany ▽ Ludwig-Maximilians-Universit¨at M¨unchen, Geschwister-Scholl-Platz 1, 80539 M¨unchen, Germany ⋆Dipartimento di Ingegneria, University of Ferrara, Via Saragat, 1, 44122 Ferrara, Italy ABSTRACT Optical network-on-chip (NoC) is a promising platform beyond electronic NoCs. In particular, wavelength-routed optical network-on-chip (WRONoC) is renowned for its high bandwidth and ultra-low signal delay. Current WRONoC topology generation approaches focus on full-connectivity, i.e. all masters are connected to all slaves. This assumption leads to wasted resources for application-speciﬁc designs. In this work, we propose CustomTopo: a general solution to the topology generation problem on WRONoCs that supports customized connectivity. CustomTopo models the topology structure and its communication behavior as an integer-linear-programming (ILP) problem, with an adjustable optimization target considering the number of add-drop ﬁlters (ADFs), the number of wavelengths, and insertion loss. The time for solving the ILP problem in general positively correlates with the network communication densities. Experimental results show that CustomTopo is applicable for various communication requirements, and the resulting customized topology enables a remarkable reduction in both resource usage and insertion loss. 1 Introduction With the rapid growth of on-chip communication in multiprocessor systems-on-chips (MPSoCs), optical networks-onchips (ONoCs) have emerged as an appealing next-generation platform, thanks to their advantages in high bandwidth and ultra-low signal delay. The key components of ONoCs include silicon waveguides for signal transmission and optical switching blocks for signal routing. Based on the routing mechanisms, ONoCs can be classiﬁed into two categories: 1) active networks that apply a real-time switching mechanism to operate the routing process, and 2) passive networks that apply add-drop ﬁlters (ADFs) [1] tuned to ﬁxed wavelengths. The latter are also known as wavelength-routed optical networks-on-chips (WRONoCs). WRONoCs are renowned for supporting congestion- and reconﬁguration-free communication [2] [3]. In contrast to active networks where path setup/reservation for each signal is performed during the communication process [4–6], WRONoCs statically reserve signal paths in the design phase, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and /or a fee. Request permissions from permissions@acm.org. ICCAD ’18, November 5–8, 2018, San Diego, CA, USA © 2018 ACM. ISBN 978-1-4503-5950-4/18/11. . . $15.00 DOI: https://doi.org/10.1145/3240765.3240789 i2 Λi i1 o1 i2 Λi i1 λj o1 i2 Λi i1 λi o1 o2 (a) Master1 ADF1 Λ1 o2 λj (b) ADF2 Λ2 o2 λi (c) ADF3 Λ3 λ4 Slave4 λ1 λ2 λ3 Slave1 Slave2 Slave3 (d) Figure 1: (a) A 2×2 ADF structure. (b) Non-resonant signals pass through. (c) On-resonant signals change their direction. (d) A simple WRONoC topology. and thus do not suﬀer from signal delay caused by path setup and conﬂicts resolution. Signals modulated to different wavelengths can travel along the same waveguides (which is known as wavelength-division multiplexing (WDM)), until they are demultiplexed at diﬀerent ADFs. Figure 1(a) illustrates a 2-input×2-output ADF structure, which includes a pair of crossing waveguides and two microring resonators (MRRs) conﬁgured to be on-resonant with a speciﬁc wavelength denoted as Λi . When signals of wavelength λj other than Λi enter the ADF, they will pass through the ADF keeping their original direction as shown in Figure 1(b); but when signals of wavelength λi equal to Λi enter the ADF, they will resonate with the MMRs and thus change their directions as shown in Figure 1(c). Figure 1(d) illustrates a simple WRONoC topology, where master and slaves can be regarded as the output and the input ports of communication nodes, respectively. With three ADFs conﬁgured to Λ1 , Λ2 , and Λ3 , the master communicates with its four slaves with signals modulated on four diﬀerent wavelengths: signals modulated to λ1 , λ2 , and λ3 get demultiplexed at ADF1 , ADF2 , and ADF3 to the ﬁrst three slaves; since the signal modulated to λ4 does not resonate with any ADF, it travels straight through all ADFs and arrives at Slave4 . Considering that WRONoCs support ful l bandwidth, i.e., all signals can travel along all waveguides simultaneously, most related work makes the natural assumption that a WRONoC topology should provide ful l connectivity (or the communication graph should be complete ), i.e all masters require connection to all slaves [2, 3, 7, 8]. However, this assumption is often over-conservative. Representative examples are processor-memory networks. Though a processor may communicate with all other processors and memories, a memory typically never communicates with another memory [9, 10]. Besides, for a 3D setting where an optical NoC is Hub2 Hub1 Mem1 Mem2 ADF1 Λ1 ADF5 Λ1 ADF2 Λ3 ADF6 Λ3 Hub2 Hub1 Mem1 Mem2 Figure 2: Logic topology for a 2-hub×2-memory design without redundancy (signals from diﬀerent masters diﬀer in form, and signals of diﬀerent wavelengths diﬀer in color). vertically stacked on top of an electronic NoC. If the latencyand/or bandwidth-critical communication ﬂows are known in advance, the ONoC can be used to ”accelerate” the critical ﬂows, while the ENoC delivers baseline global connectivity [11, 12]. For applications that do not require complete communication, providing full connectivity may lead to signiﬁcant waste of resources. Two important metrics [8] for resource usage in a WRONoC topology are the number of wavelengths and the number of ADFs, which are limited by both manufacturing technologies and performance factors: constrained by available WDM bandwidth, many works point out that the maximal number of wavelengths cannot surpass 64 [13–15], and some others indicate that only 16 distinguishable and stable wavelengths can be achieved [11]. Moreover, wavelength usage correlates with ADF usage. As each ADF introduces two MRRs and a pair of (crossed) waveguides, more ADFs result in a higher power loss and crosstalk noise power, and thus also a lower signal-to-noise ratio (SNR) [16]. However, under the full-connectivity context, the required number of wavelengths is linearly proportional to the number of communication nodes, and the required number of ADFs increases even quadratically [17], which raises severe scalability concerns. Take a 2-hub×2-memory design1 proposed in [18] as an example: if we implement the design under the complete communication assumption, a reasonable choice is to apply the widely-acknowledged 4 × 4 λ-router [2], which consists of 6 ADFs conﬁgured to 4 diﬀerent wavelengths. But if we target the actual network function: 1) there is no communication between the two memories, and 2) neither hub nor memory transmits a signal to itself. Therefore, the wavelengths and the ADFs reserved for memory-to-memory communication and for self-communication are indeed redundant. Figure 2 illustrates an exemplary topology that removes the redundancy, where colored dashed lines represent the routing paths of signals. As we can see, 4 ADFs conﬁgured to 2 diﬀerent wavelengths are already enough for all necessary communications, i.e. a resource reduction of −33% ADFs and −50% wavelengths is achieved, which gives an indication of the potential beneﬁts that we can expect from a customized topology ﬁtting to the required connectivity. Unlike full-connectivity designs, for which there are generally applicable routers such as λ-router and GWOR [3], customized designs require individual treatment based on a well-formulated topology generation model. Previous work has studied the WRONoC topology from some speciﬁc aspects. [19] lays the groundwork for a topology synthesis discipline, but it is restricted to symmetric n×n topologies. [11] proposes a reduction method on λ-router for applicationspeciﬁc designs. But since λ-router is not intended for incom1 Hubs indicate optical interfaces connected to processor clusters and memories indicate memory controllers. plete communication, its performance is limited and heavily depends on the symmetry of the communication graph. As the scope of WRONoC applications continuously extends, the symmetric subclass becomes insuﬃcient [12]. Thus, there is a pressing need for a general WRONoC topology generation method that is not limited to any initial topology, communication graph, or router-structure. In this paper, we propose CustomTopo : a general solution to the topology generation problem on WRONoCs, without the assumption that the network communication must be complete or symmetric. Based on a communication matrix derived from an input communication graph, we model the topology generation problem as an integer linear programming problem, the optimization ob jective of which focuses on reducing the ADF and the wavelength usage, while keeping the insertion loss smal l. 2 General Model for WRONoCs The general model for WRONoCs is formulated as follows: Input: a communication graph specifying all master-slave pairs that require communication. Output: a full-bandwidth topology specifying the logic connection between network components, the wavelength usage, and the signal path between each master-slave pair. Minimization Ob jective [8, 19]: 1) the number of ADFs, 2) the number of wavelengths assigned to ADFs. 3) the worst-case insertion loss of all signal paths2 . 2.1 From Communication Graph to Communication Matrix For a given communication graph, we build a set M for masters and a set S for slaves. In case the communication graph is not complete, we introduce a function ϕ :M× S → {1, 0} to represent whether a master m ∈ M communicates with a slave s ∈ S : ϕ(m, s) = (cid:26) 1 if m communicates with s, 0 otherwise. If we denote the number of masters as nm := |M| and the number of slaves as ns := |S |, the entire communication behavior can be modeled as an ns ×nm communication matrix, in which each entry represents a wavelength: m1 λm1 ,s1 λm1 ,s2 ... m2 λm2 ,s1 λm2 ,s2 ... ··· · · · · · · . . . mnm λmnm ,s1 λmnm ,s2 ... λm1 ,sns λm2 ,sns · · · λmnm ,sns .   s1 s2 ... sns   For all 1 ≤ i ≤ nm and 1 ≤ j ≤ ns , if ϕ(mi , sj ) = 0, i.e. there is no communication between mi and sj , the corresponding entry λmi ,sj will be set as NA; otherwise if ϕ(mi , sj ) = 1, the entry λmi ,sj will be set as the wavelength that mi uses for communication with sj . On WRONoCs, a wavelength can be shared among diﬀerent master-slave pairs, but the corresponding signal paths must not overlap [19]. This puts two constraints on wavelength usage at end nodes: 1) wavelengths for communication between the same master and diﬀerent slaves must be diﬀerent ; and 2) wavelengths for communication between different masters and the same slave must be diﬀerent. With 2 We assume that optical power is provided by an array of continuous-wave offchip laser sources, which are multiplexed onto a single input power waveguide. On the chip, the optical power is then distributed to the transmitters for modulation through a power distribution network. In this context, controlling the worst-case insertion loss turns out to be a simple yet effective way to limit the output power requirements for the laser sources [10, 20, 21]. m1 m2 mnm ADFm1 ,sns Λm1 ,sns ADFm2 ,sns Λm2 ,sns s1 s2 sns ADFm1 ,s1 Λm1 ,s1 ADFm1 ,s2 Λm1 ,s2 ADFm2 ,s1 Λm2 ,s1 ADFm2 ,s2 Λm2 ,s2 ADFmnm ,sns Λmnm ,sns ADFmnm ,s2 Λmnm ,s2 ADFmnm ,s1 Λmnm ,s1 Figure 3: An initial topology with nm masters and ns slaves. our communication matrix, these constraints can be formulated as follows: ∀1 ≤ i ≤ nm ∀1 ≤ j ≤ ns ∀1 ≤ k1 ,k2 ≤ ns ∀1 ≤ k ′ 1 , k ′ 2 ≤ nm : , (ϕ(mi , sk1 ) = ϕ(mi , sk2 ) = 1) ⇒ λmi ,sk1 (ϕ(mk′ , sj ) = ϕ(mk′ , sj ) = 1) ⇒ λmk′ 6= λmi ,sk2 ,sj 6= λmk′ ,sj , 2 (1) 1 2 1 (2) which means that except for the entries set as NA, all entries in the same column and in the same row of the matrix must be pairwise distinct. We call the communication matrices that satisfy these constraints valid communication matrices. 2.2 From Communication Matrix to Topology 2.2.1 Initial Topology A valid communication matrix can be transformed into a full-bandwidth topology straightforwardly by implementing an ADF for each non-NA entry, as shown in Figure 3. An ADF at the i-th column and the j -th row of the topology is indexed as ADFmi ,sj with a label Λmi ,sj , indicating that it only resonates with wavelength λmi ,sj . By sequentially connecting the ADFs in the same columns and in the same rows, signals can be delivered to their destinations simultaneously without conﬂict. We refer to this topology as initial topology in the rest of this section. 2.2.2 Topology Optimization: Three Targets As proposed in [8], a WRONoC topology is speciﬁed by two design parameters: the number of ADFs and the number of diﬀerent wavelengths assigned to the ADFs. However, when considering the physical layout, insertion loss becomes another key metric. Though the explicit insertion loss is dependent on the physical features and thus cannot be derived from a logic topology [20], we still try to approximate the insertion loss for comprehensive optimization. In general, we optimize the initial topology based on three criteria : wavelength usage, ADF usage, and insertion loss3 . 2.2.3 Expectation: Wavelength Usage The wavelength usage for full-bandwidth communication can be read from the communication matrix, where the number of wavelengths equals the number of the distinct entries. For a complete communication graph, the theoretical minimum wavelength usage can be derived by transforming the matrix into a colored bipartite graph : M and S can be regarded as two sets of vertices, and an entry λmi ,sj 6= NA can be regarded as the color denotation of an edge from mi to sj . Thus, the entries in the same column/row of the communication matrix can be regarded as the colors of adjacent edges sharing the same master/slave vertex. In this manner, the design constraints (1)(2) can be transformed into an edge coloring problem, and the minimum number of distinct entries is thus equal to ω := max{nm ,ns }, according to 3 Another layout-dependent performance factor of ONoCs is signal-to-noise ratio (SNR). As proposed in [16], SNR usually negatively correlates with the number of ADFs and wavelengths. In this work, we approximate the maximization of SNR by existing optimization targets. ADFm,sn Λm,sn s1 sj sn m ADFm,s1 Λm,s1 ADFm,sj Λm,sj ADFm,sn Λm,sn s1 sj sn m ADFm,s1 Λm,s1 λm,s1 λm,sj λm,sn λm,s1 0 λm,sn Figure 4: ADF reduction for a one-column matrix. Vizing’s theorem [22]. Since complete communication is not a necessity in our topology generation model, we can expect the minimum wavelength usage in a customized topology to be smaller than or equal to ω . 2.2.4 Minimization: ADF Usage The ADF usage in an initial topology can be directly read from the communication matrix, where the number of ADFs is equal to the number of the non-NA entries. However, considering a 2×2 ADF structure as shown in Figure 1, some of the ADFs can be removed by utilizing wavelengths shared among diﬀerent master-slave pairs. We ﬁrst consider a simple one-column communication matrix for one master and its n slaves. The initial topology derived from this matrix consists of n ADFs. However, n−1 ADFs are already suﬃcient to carry out the communication, as shown in Figure 4: if we arbitrarily choose an ADFm,sj to be replaced by a normal waveguide, and connect sj to the vacant output port of the bottom ADF, signals modulated to λm,sj will travel across all the sequentially connected ADFs and ﬁnally arrive at sj without being aﬀected, since λm,sj 6= Λm,si for all 1 ≤ i ≤ n, i 6= j . In this case, we deﬁne sj as the default slave of m and we deﬁne the signal path from m to sj as the default path of m. Besides, we denote λm,sj as 0, indicating that the communication between m and sj does not rely on any ADF for demultiplexing. We now consider an ns × nm communication matrix with a 0 in each column. An example is shown in Figure 5(a), where each master has its own default slave. Speciﬁcally, the default slave of m1 is s1 , and the default slave of m2 is s2 . In this case, if both (m1 , s2 ) and (m2 , s1 ) apply λk for communication, the resulting topology shown in Figure 5(b) can be safely reduced by one ADF, either as shown in Figure 5(c) or as shown in Figure 5(d), with corresponding changes to the signal communication paths. In particular, the removal of ADFm2 ,s1 results in a detour of the signal path from m2 to s1 through the default path of m2 , to share the same ADF with m1 for demultiplexing. In general, suppose that mi1 , mi2 , sj1 , and sj2 are masters and slaves that fulﬁll the following constraint: λmi1 ,sj2 = λmi2 ,sj1 = 0 ∧ λmi1 ,sj1 = λmi2 ,sj2 := λk . (3) Then mi1 and mi2 can share the same ADF, and the corresponding communication matrix will be in the form:   · · · mi1 · · · mi2 · · · . . . . . . . .. . .. . . . . . . . . . . . . . .. . .. . . . . . . . . . . . . . .. . .. . . . . . . sj1 λk 0 . .. . .. . .. sj2 0 . . . λk . . . . . .   or   · · · mi1 · · · mi2 · · · . . . . . . . .. . .. . . . . . . . . . . . . . .. . .. . . . . . . . . . . . . . .. . .. . . . . . . sj2 0 . .. λk . .. . .. sj1 λk 0 . . . . . . . . .   . (b) s1 s2 sns m1 Λk m2 Λk mnm ⋆ ⋆ ⋆ ⋆ λk 0 0 λk 0 (a) (c) s1 s2 sns m1 Λk m2 mnm (d) s1 s2 sns m1 m2 Λk mnm Figure 5: ADF reduction with ADF-sharing structure. (a) A communication matrix containing an ADF-sharing structure. (b) Reduced topology with a default path for each master. (c)(d) Further ADF reduction options. The resulting changed signal paths are indicated by green dash lines. We refer to this situation as {λmi1 ,sj1 ,λmi1 ,sj2 ,λmi2 ,sj1 , } form an ADF-sharing structure. To minimize the λmi2 ,sj2 ADF usage, we aim to maximize the number of ADF-sharing structures in the communication matrix. 2.2.5 Minimization: Insertion Loss in Signal Paths On WRONoCs, insertion loss results from waveguide length (propagation loss), waveguide bending (bending loss), waveguide crossings (crossing loss), and ADFs (through loss and drop loss) [23]. Among them, propagation loss, bending loss, and crossing loss are dependent on the physical layout of the chip. In this work, we do not want to make restrictive assumptions on the physical location of the masters and the slaves, which will be determined by placement and routing tools at a later design stage. Therefore, we do not directly target the optimization of the layout-aware insertion loss, but rather a more abstract yet indirect metric with tight correlation with the ﬁnal insertion loss ﬁgures. We identify this metric with the insertion loss contributions from ADFs in the logic topology, namely the through loss and the drop loss of the constituting MRRs, and the internal crossing loss in the ADF. For all master-slave pairs that communicate, we derive their corresponding signal paths, and minimize the worst-case insertion loss. In order to reduce the accuracy gap in insertion loss analysis between logic topology and physical one, we try to reduce inevitable waveguide crossings implied by the logic topology. By taking advantage of the reduction approach introduced in Section 2.2.4, some ADFs can be removed from the initial topology, but the waveguide crossings contained in these ADFs will be kept by default to retain the signal paths. Among these crossings, some are removable by rearranging the location of network components, but some are inevitable for the given logic connection, as shown in Figure 6(a). However, by optimizing the communication matrix, we can reduce the formation of inevitable crossings. For example, Figure 6(b) shows a communication matrix and its resulting topology that supports the same connectivity as Figure 6(a). m2 s3 m3 s4 ⋆ 0 ⋆ ⋆ ⋆ ⋆ ⋆ ⋆ 0 0 NA NA s2 m1 s1 m2 s3 m3 s4 ⋆ 0 ⋆ ⋆ 0 ⋆ ⋆ ⋆ ⋆ 0 NA NA s2 s1 m1 (a) (b) Figure 6: Two topologies supporting the same connectivity with diﬀerent default paths (blue line). (a) contains a removable crossing (green circle), and two inevitable crossings (red circles); (b) removes the removable crossing and transforms the inevitable crossings into a removable waveguide loop (green dash line). The only diﬀerence is that the default slave of m2 is changed from s2 to s3 , which results in a new default path containing a removable waveguide loop without ADF, and thus all waveguide crossings in this loop become removable as well. To reduce external crossings in the ﬁnal layout, we maximize the number of removable crossings implied by the topology. 3 Mathematical Model of CustomTopo We implement the topology optimization approach introduced in Section 2 as an integer-linear-programming model. 3.1 Matrix Initialization The wavelength assignment in a topology is speciﬁed by entries in the communication matrix. For an ns ×nm communication matrix, we denote the maximum number of the nonNA entries in each column and in each row as n′ s and n′ m , respectively. As introduced in Section 2.2.3, we can expect the upper bound of wavelength usage to be ω := max{n′ m }. Thus, the range of the entries in the communication matrix can be denoted as a set of integers: {0, 1, · · · ,ω}. In particular, we add 0 to this set to indicate the default slaves, as introduced in Section 2.2.4. For each individual entry λmi ,sj , we introduce a sequence of binary variables (b )0≤k≤ω , where b k = 1 implies that λmi ,sj is assigned with value k , i.e. (mi , sj ) uses wavelength k for communication. We introduce the following constraint to ensure that each entry is assigned exactly once: s ,n′ λi,j k λi,j X0≤k≤ω b λi,j k = 1. (4) 3.2 Conﬂict Resolution To avoid signal conﬂicts, all entries in the same column and in the same row of the communication matrix must be pairwise distinct, as described in constraints (1)(2) in Section 2.1. We linearize these constraints as follows: ∀1 ≤ i ≤ nm ∀0 ≤ k ≤ ω : X0≤j≤ns ∀1 ≤ j ≤ ns ∀0 ≤ k ≤ ω : X0≤i≤nm b λi,j k ≤ 1, (5) b λi,j k ≤ 1, (6) which ensure that a value appears at most once in each column and in each row of the matrix. 3.3 ADF-Sharing Structure To optimize the ADF usage, for every two masters mi1 , mi2 and every two slaves sj1 , sj2 , we introduce a binary variable bshare i1 ,j1 ,i2 ,j2 to indicate whether they form an ADF-sharing structure, as introduced in Section 2.2.4. We then introduce the following constraints: λi1 ,j2 0 λi2 ,j1 0 b b ≥ bshare i1 ,j1 ,i2 ,j2 , ≥ bshare i1 ,j1 ,i2 ,j2 , λi2 ,j2 k b · k ≤ M · (1− bshare i1 ,j1 ,i2 ,j2 ), (7) (8) (9) λi1 ,j1 k b · k ≤ M · (1− bshare i1 ,j1 ,i2 ,j2 ), (10) λi1 ,j1 k b λi2 ,j2 k b X1≤k≤ω X1≤k≤ω · k − X1≤k≤ω · k − X1≤k≤ω where M is an extremely large auxiliary constant. If bshare = 1, the above constraints can be considered as the linear form of constraint (3) in Section 2.2.4. Speciﬁcally, constraints (7)(8) imply that λmi1 will be assigned with 0, and constraints (9)(10) imply that λmi1 will be assigned with the same positive value k . Otherwise if bshare i1 ,j1 ,i2 ,j2 = 0, the above constraints trivially hold and thus do not inﬂuence the wavelength assignment. and λmi2 and λmi2 ,sj1 ,sj2 ,sj2 ,sj1 i1 ,j1 ,i2 ,j2 3.4 Topology Construction We initialize the topology by introducing a binary variable bΛi,j for each entry in the communication matrix. bΛi,j = 1 indicates that there is an ADF at the i-th column and the j -th row of the topology, as introduced in Section 2.2.1. By default, there is an ADF for each positive entry, except for the entries that form an ADF-sharing structure, where the two positive entries can share one single ADF. This can be formulated as the following constraint: bΛi,j ≥ X1≤k≤ω b λi,j k − Xma ∈M,sb ∈S bshare i,j,a,b , (11) which means that for a positive entry λmi ,sj , if it is not part of an ADF-sharing structure, bΛi,j will be set to 1; otherwise bΛi,j can be either 1 or 0. We then introduce the following constraints to model the ADF usage for every two masters mi1 , mi2 , and every two slaves sj1 , sj2 : bΛi1 ,j1 + bΛi2 ,j2 ≤ 2− bshare i1 ,j1 ,i2 ,j2 , bΛi1 ,j1 + bΛi2 ,j2 ≥ bshare i1 ,j1 ,i2 ,j2 . (12) (13) i1 ,j1 ,i2 ,j2 = 1, either bΛi1 ,j1 or bΛi2 ,j2 will be set to Thus, if bshare 1 while the other will be set to 0. Otherwise if bshare the above constraints become trivial and thus do not inﬂuence the ADF usage. i1 ,j1 ,i2 ,j2 = 0, 3.5 Signal Paths and Insertion Loss For each master-slave pair (mi , sj ), we approximate the insertion loss in its signal path as the summation of through loss, drop loss, and crossing loss caused by ADFs, as introduced in Section 2.2.5. Speciﬁcally, if a signal passes through an ADF without direction change, we denote the insertion loss at the ADF as IADF , and calculate it as: IADF = 2 · Ithrough + Icross , where Ithrough indicates the insertion loss resulting from a non-resonant MRR, and Icross indicates the insertion loss resulted from a waveguide crossing. Ithrough is multiplied with 2 since an ADF consists of two MRRs. On the other hand, if a signal is dropped by an ADF, i.e. the signal resonates with the ADF, we denote the drop loss at the ADF as Idrop . Thus, the insertion loss of a signal path can be calculated by the number of non-resonant and on-resonant ADFs in the path. For each master-slave pair (mi , sj ), we introduce an integer variable vI i,j to indicate the insertion loss in its signal path, and we introduce an integer variable vΛi,j to indicate the number of ADFs in the path. The calculation is formulated as follows: vI i,j =vΛi,j · IADF + (1− b λi,j 0 ) · (Idrop − IADF ). (14) λi,j If b 0 = 1, i.e. (mi , sj ) does not rely on any ADF for demultiplexing, the insertion loss is calculated as the product of vΛi,j and IADF . Otherwise if b 0 = 0, i.e. the signal resonates with an ADF in its path, one IADF will be replaced by Idrop in the calculation. To model the number of ADFs in each signal path, we distinguish three cases for the signal paths: λi,j 3.5.1 Case 1: Default Path A master communicates with its default slave through its default path, where the signal does not resonate with any ADF, as introduced in Section 2.2.4. In this case, the entry λmi ,sj in the communication matrix will be set to zero, and the signal path consists of all ADFs in the i-th column and in the j -th row of the topology. This can be formulated as the following constraint: vΛi,j ≥ X1≤k≤ns bΛi,k + X1≤k≤nm bΛk,j −M · (1− b λi,j 0 ), (15) where M is an extremely large auxiliary constant. If b 0 = 1, i.e. sj is the default slave of mi , the above constraint counts all ADFs in the default path and assigns the value to vΛi,j 4 . Otherwise if b 0 = 0, the above constraint trivially holds, which means that this path model will not be applied to (mi , sj ). λi,j λi,j 3.5.2 Case 2: Direct Demultiplexing A master mi communicates with its slave sj via direct demultiplexing, if there is an ADF at the i-th column and the j -th row of the topology, as shown in Figure 5(b). In this case, the signal path consists of ADFmi ,sj and all ADFs that are above it (in the i-th column) or left to it (in the j -th row). This can be formulated as the following constraint: vΛi,j ≥ X1≤k≤j bΛi,k + X1≤k<i bΛk,j −M · (1− bΛi,j ), (16) where M is an extremely large auxiliary constant. If bΛi,j = 1, i.e. there is an ADF for λmi ,sj , the above constraint counts all ADFs in the signal path and assigns the value to vΛi,j . Otherwise if bΛi,j = 0, the above constraint trivially holds, which means that this path model will not be applied to (mi , sj ). 3.5.3 Case 3: Demultiplexing with Detour A master mi communicates with its slave sj via demultiplexing with a detour, if the ADF for λmi ,sj is removed by an ADF-sharing structure, as shown in Figure 5(c)(d). In this case, by denoting the shared ADF as ADFm′ , the signal path can be considered as two parts: 1) from mi to ADFm′ , along the default path of mi ; and 2) from ADFm′ to sj , along the default path of m′ i . This can be i ,s′ i ,s′ j j i ,s′ j 4 Λi,j will be assigned to its The ’≥’ in this constraint implies ’=’, because v minimum allowable value by the minimization target. formulated as the following constraint: vΛi,j ≥ X1≤k≤ns bΛi,k + Xi′≤k≤nm bΛk,j ′ + Xj ′<k≤ns + X1≤k≤nm Λk,sj −M · bΛi,j −M · (1− bshare i,j,i′ ,j ′ ), bΛj ′ ,i′ b Besides, we introduce another integer variable v remove to represent the number of removable waveguide crossings, which is modelled as follows: (17) v remove = X1≤i≤nm ,1≤j≤ns bremove i,j . (24) j i ,s′ where M is an extremely large auxiliary constant. This constraint is applied to all λm′ that can potentially form an ADF-sharing structure with λmi ,sj . If bΛi,j = 0 and bshare 1, i.e. the ADF for λmi ,sj does not exist and (mi , sj ) shares an ADF with (m′ j ), the above constraint counts all ADFs in the signal path and assigns the value to vΛi,j . Otherwise if either bΛi,j = 1 or bshare i,j,i′ ,j ′ = 0, the above constraint trivially holds, which means that this path model will not be applied to (mi , sj ) and ADFm′ . i,j,i′ ,j ′ = i , s′ i ,s′ j 3.6 Removable Waveguide Loop To reduce inevitable waveguide crossings outside ADFs, we tend to form removable waveguide loops in the topology, as introduced in Section 2.2.5. Suppose sj is the default slave of mi , a removable waveguide loop is formed when there is no ADF beneath the j -th row in the i-th column and there is no ADF right to the i-th column in the j -th row, as shown in Figure 6. For each master-slave pair (mi , sj ), we introduce a binary variable bloop to indicate whether its signal path contains a removable waveguide loop. The corresponding constraints are formulated as follows: i,j M · (1− bloop , λi,j bloop i,j ≤ b 0 i,j ) ≥ Xj+1≤k≤ns bΛi,k + Xi+1≤k≤nm bΛk,j , (18) (19) where M is an extremely large auxiliary constant. Constraint (18) ensures that a removable waveguide loop can only be formed if sj is the default slave of mi , and constraint (19) ensures that a removable waveguide loop will not be formed if there is any ADF in the loop. We then introduce a binary variable bremove to indicate whether the waveguide crossing in the i-th column and in the j -th row of the topology is removable. A waveguide crossing is removable, when it is in a removable waveguide loop. This can be formulated by the following constraint: i,j bremove i,j ≤ X1≤k≤j−1 bloop i,k + X1≤k≤i−1 bloop k,j . (20) 3.7 Optimization Target The optimization target of the model is described at the beginning of Section 2. Speciﬁcally, we introduce three more integer variables that should be minimized: vΛtotal represents the number of ADFs in the topology, which is modelled as follows: vΛtotal = X1≤i≤nm ,1≤j≤ns bΛi,j . (21) vλtotal represents the number of wavelengths assigned to the ADFs, which is modelled as follows: ∀1 ≤ i ≤ nm∀1 ≤ j ≤ ns : vλtotal ≥ X1≤k≤ω b λi,j k · k . (22) And vIworst represents the worst-case insertion loss among all signal paths, which is modelled as follows: ∀1 ≤ i ≤ nm∀1 ≤ j ≤ ns : vIworst ≥ vI i,j . (23) To reduce inevitable waveguide crossings in the ﬁnal layout, we add maximizing v remove to the optimization target. Thus, the complete optimization ob jective can be formulated as follows: Minimize: α · vΛtotal +β · vλtotal + γ · vIworst − δ · v remove , where α, β , γ , and δ are constant weight coeﬃcients that can be adjusted by the user to control optimization preference. v remove is multiplied with −1 for maximization. 4 Experimental Results We implement CustomTopo in C++, and solve the optimization model using Gurobi [24], a mixed integer linear programming (MILP) solver. The program is run on a computer with 2 Xeon processors under 2.67 GHz base frequency. The weight coeﬃcients α, β , γ , and δ are assigned with 10, 10, 100, and 1, respectively5 . The insertion loss parameters are from [16] and shown as follows: Propagation loss Crossing loss (Icross ) Through loss per MRR (Ithrough ) Drop loss (Idrop ) 0.274dB/cm 0.04dB 0.005dB 0.5dB 4.1 General Comparison We tested CustomTopo on 7 test cases including: one small case (case 1) with high communication density; two mediumsized cases (case 2, 3) with medium communication density; one large case (case 4) with low communication density; and 3 cases with (semi-)symmetric communication graphs (case 5, 6, 7). We compare against a state-of-the-art reduction method for topology customization, namely the λ-router reduction method proposed in [11]. We compare the topologies generated by CustomTopo with λ-router topologies before and after the reduction to demonstrate the beneﬁts that we can expect from our customized topologies. Detailed test case information and comparison results are shown in Table 16 . In general, CustomTopo reduces the resource usage signiﬁcantly, which also contributes to a remarkable reduction of the worst-case insertion loss: • Compared with original λ-router topologies, for test cases that have high communication density (case 1 and case 5), the average ADF and wavelength usage are reduced by about 20% and 30%, respectively. The reduction becomes more signiﬁcant as the communication density decreases: e.g. for the largest test case (case 4) that has sparse network communication (22 communicating master-slave pairs), the ADF usage is reduced from 120 to 10 and the wavelength usage is reduced from 16 to 6. • The λ-router reduction approach [11] depends on the symmetry of the test cases. Case 5 and case 6 are semi-symmetric, and our customized topologies enable 5 This assignment balances the optimization preferences among vΛtotal , v λtotal , Iworst differs from the others by one magnitude. vremove and v Iworst , since v is assigned with a smaller value since it is not the ma jor optimization target. 6 The reduction approach proposed in [11] focused on ADF and wavelength usIworst cannot easily be derived from our age. The worst-case insertion loss v implementation of this method. Thus, v Iworst is only calculated for the last three test cases, which were proposed in the paper with explicit signal paths. Table 1: Comparison among topology generation approaches Index Ref. #N #p Method λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo λ-router λ-reduction CustomTopo vΛtotal vλtotal vIworst Time 1 [20] 8 44 28 24 24 66 24 13 66 15 9 120 20 10 28 20 20 28 18 12 28 12 12 8 8 6 12 10 7 12 9 4 16 14 6 8 7 5 8 7 6 8 6 6 0.85 − − 0.85 1.05 53s 2 [25] 12 26 − − 0.8 1.05 184s 3 [26] 12 20 − − 0.6 1.25 14s 4 [27] 16 22 − − 0.7 0.85 0.75 0.9 0.85 0.75 0.8 0.85 0.75 0.8 13s 5 [11] 8 48 − (sym.) 138s 6 8 24 − (sym.) 3s 7 (full sym.) 8 24 − 63s Ref.: reference of the test cases. #N: the number of nodes. #p: the number of communicating master-slave pairs. vΛtotal : the number of ADFs. vλtotal : the number of diﬀerent wavelengths assigned to ADFs. vIworst : the worst-case insertion loss resulted from ADFs. Time: the program runtime denoted in seconds. more wavelength reduction for both cases, and more ADF reduction for case 6. Case 7 is fully symmetric, and our customized topology shows the same reduction results as [11]. For other test cases (case 1-4), both the ADF usage and the wavelength usage is further reduced by about 40%. • For small test cases (case 1, 5, 6, 7), the worst-case insertion loss in our customized topologies is similar or slightly higher than λ-router topologies. But for larger test cases, as the ADF usage is signiﬁcantly reduced, we achieve a remarkable reduction in the worst-case insertion loss. A more detailed analysis of layout-aware insertion loss follows in Section 4.3, proving that the customized logic topology lends itself to better physical implementation as well. • The program runtime varies among individual cases. But in general it shows a trend of positive correlation with the communication density. For most cases, the optimization terminates within 3 minutes. 4.2 Results Illustration We illustrate the experimental results of test case 17 in Figure 7 to give an overview of the whole working process of CustomTopo. Figure 7(a) shows the communication graph of case 1, which is given as the input to CustomTopo. Based on this input, CustomTopo constructs an optimized communication matrix where each entry indicates a wavelength, as shown in Figure 7(b). For each ADF-sharing structure in the communication matrix, CustomTopo removes one ADF from the initial topology and outputs an optimized logic topology, as shown in Figure 7(c). The logic topology can then be used for physical design with a state-of-the-art placement and 7 This test case consists of 4 hubs and 4 memory controllers with their location explicitly specified. H1 H2 H3 H4 M1 M2 M3 M4 H1 H2 H3 M1 M2 M3 M4 H4 Λ2 Λ6 Λ1 Λ4 Λ3 Λ5 Λ5 Λ2 Λ4 Λ1 Λ6 Λ3 H1 H2 H3 H4 M1 M2 M3 M4 H1 H2 H3 H4 M1 M2 M3 M4 2 6 1 4 3 5 0 5 2 2 6 4 1 6 3 0 2 4 H1 M1 H2 H3 H4 M4 M2 M3 5 3 6 0 1 1 2 4 0 3 5 1 0 4 3 2 3 6 0 0 6 3 0 4 3 1 Λ1 Λ1 Λ5 Λ5 Λ3 Λ3 Λ2 Λ2 Λ4 Λ4 Λ6 Λ6 (a) (b) (c) (d) Figure 7: Illustration of test case 1. (a) Input communication graph. (b) Optimized communication matrix. (c) Optimized logic topology. (d) Final physical layout. routing tool, in this case we use PROTON+ [20], to determine the ﬁnal layout of the ONoC, as shown in Figure 7(d). 4.3 Discussion: Physical Layout CustomTopo minimizes the worst-case insertion loss based on the logic topology. Since we do not make an assumption on the location of masters and slaves, the propagation loss and the crossing loss outside ADFs are not included in the optimization model. To investigate the insertion loss in the ﬁnal layout, we feed CustomTopo topology for test case 1 to PROTON+ [20], a state-of-the-art physical design tool for WRONoCs, to compare it with the λ-router topology shown in Figure 8. Comparing Figure 7(d) with Figure 8, we can see that ADFs in the λ-router layout are centralized in the middle, and ADFs in the CustomTopo layout are distributed in a larger area. A possible reason is that the signal paths in λ-router topology have similar lengths, and the signal paths in our customized topology have much diﬀerent lengths. To minimize the worst-case insertion loss, PROTON+ optimizes the longest signal path as the ﬁrst priority, which changes the centralized layout. As shown in Table 2, CustomTopo layout saves 8 waveguides compared with λ-router layout, contributed by the ADF reduction. The waveguide reduction and the distributed layout feature then contribute to the remarkable 40+% reG. Bois, and P. Paulin, “Optical ring network-on-chip (ornoc): Architecture and design methodology,” in Proc. Design, Automation, and Test Europe Conf., 2011, pp. 788–793. [8] A. Peano, L. Ramini, M. Gavanelli, M. Nonato, and D. Bertozzi, “Design technology for fault-free and maximally-parallel wavelength-routed optical networks-on-chip,” in Proc. Int. Conf. Comput.-Aided Des., 2016, pp. 3:1–3:8. [9] Z. Wang, Z. Pang, P. Yang, J. Xu, X. Chen, R. K. V. Maeda, Z. Wang, L. H. Duong, H. Li, and Z. Wang, “Moca: an inter/intra-chip optical network for memory,” in Proc. Design Autom. Conf., 2017, pp. 1–6. [10] L. Ramini, P. Grani, S. Bartolini, and D. Bertozzi, “Contrasting wavelength-routed optical noc topologies for power-eﬃcient 3d-stacked multicore processors using physical-layer analysis,” in Proc. Design, Automation, and Test Europe Conf., 2013, pp. 1589–1594. [11] S. L. Beux, I. O’Connor, G. Nicolescu, G. Bois, and P. G. Paulin, “Reduction methods for adapting optical network on chip topologies to 3d architectures,” Microprocessors and Microsystems: Embedded Hardware Design, vol. 37, no. 1, pp. 87–98, 2013. [12] H. Omar and K. Hamwi, “Mhynesys ii: Multi-stage hybrid network on chip synthesis for next generation 3d ic manycore,” in IEEE International Symposium on Circuits and Systems, 2013, pp. 325–328. [13] K. Preston, N. Scherwood-Droz, J. S. Levy, and M. Lipson, “Performance guidelines for wdm interconnects based on silicon microring resonators,” CLEO: Science and Innovations, 2011. [14] P. Grani, R. Proietti, V. Akella, and S. J. B. Yoo, “Design and evaluation of awgr-based photonic noc architectures for 2.5d integrated high performance computing systems,” in High Performance Computer Architecture (HPCA), 2017, pp. 289–300. [15] D. Vantrease, R. Schreiber, M. Monchiero, M. McLaren, N. P. Jouppi, M. Fiorentino, A. Davis, N. Binkert, R. G. Beausoleil, and J. H. Ahn, “Corona: System implications of emerging nanophotonic technology,” ACM SIGARCH Computer Architecture News, vol. 36, no. 3, pp. 153–164, 2008. [16] M. Nikdast, J. Xu, L. H. K. Duong, X. Wu, X. Wang, Z. Wang, Z. Wang, P. Yang, Y. Ye, and Q. Hao, “Crosstalk noise in wdm-based optical networks-on-chips: A formal study and comparison,” IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 23, no. 11, pp. 2552–2565, 2015. [17] F. Liu, H. Zhang, Y. Chen, Z. Huang, and H. Gu, “Wavelength-reused hierarchical optical network on chip architecture for manycore processors,” IEEE Transactions on Sustainable Computing, 2017. [18] L. Ramini, D. Bertozzi, and L. P. Carloni, “Engineering a bandwidth-scalable optical layer for a 3d multi-core processor with awareness of layout constraints,” in IEEE/ACM International Symposium on Networks-on-Chip (NoCS), 2012, pp. 185–192. [19] M. Tala, M. Castellari, M. Balboni, and D. Bertozzi, “Populating and exploring the design space of wavelength-routed optical network-on-chip topologies by leveraging the add-drop ﬁltering primitive,” in IEEE/ACM International Symposium on Networks-on-Chip (NoCS), 2016, pp. 1–8. [20] A. V. Beuningen, L. Ramini, D. Bertozzi, and U. Schlichtmann, “PROTON+: A placement and routing tool for 3d optical networks-on-chip with a single optical layer,” J. Emerg. Technol. Comput. Syst., vol. 12, no. 4, pp. 44:1–44:28, 2016. [21] A. V. Beuningen and U. Schlichtmann, “PLATON: A force-directed placement algorithm for 3d optical networks-on-chip,” in Proc. Int. Symp. Phy. Des., 2016, pp. 27–34. [22] D. K¨ Figure 8: Physical layout generated from 8 × 8 λ-router topology by PROTON+. Table 2: Physical features of ﬁnal layouts Physical feature # waveguides (total) # crossings (total) # crossings (Pworst ) Length of waveguides (total) Length of waveguides (Pworst ) Insertion loss (total) Insertion loss (Pworst ) Pworst : the signal path with the maximum insertion loss. CustomTopo 56 51 23 10.7073cm 1.5732cm 5.98dB 2.08dB λ-router 64 90 40 9.7344cm 1.0521cm 7.67dB 2.79dB duction of total waveguide crossings and the maximum singlepath waveguide crossings. A trade-oﬀ is that the waveguide length is larger in CustomTopo layout than in λ-router layout. But thanks to fewer waveguide crossings, both the total insertion and the maximum single-path insertion loss are reduced by more than 20%. 5 Conclusion In this work, we propose CustomTopo, a general approach for WRONoC topology generation that optimizes the resource usage for application-speciﬁc designs. We analyze the topology generation problem from three aspects: wavelength usage, ADF usage, and insertion loss, and we propose reduction methods regarding each aspect. We implement our methods as an integer-linear-programming model, the program runtime for solving which positively correlates with the network communication density. CustomTopo is applicable to both symmetric and asymmetric networks. Speciﬁcally, for asymmetric networks, CustomTopo signiﬁcantly outperforms the state-of-the-art method by 40% further reduction in wavelength and ADF usage. 6 "
2018,A ferroelectric FET based power-efficient architecture for data-intensive computing.,"In this paper, we present a ferroelectric FET (FeFET) based power-efficient architecture to accelerate data-intensive applications such as deep neural networks (DNNs). We propose a cross-cutting solution combining emerging device technologies, circuit optimizations, and micro-architecture innovations. At device level, FeFET crossbar is utilized to perform vector-matrix multiplication (VMM). As a field effect device, FeFET significantly reduces the read/write energy compared with the resistive random-access memory (ReRAM). At circuit level, we propose an all-digital peripheral design, reducing the large overhead introduced by ADC and DAC in prior works. In terms of micro-architecture innovation, a dedicated hierarchical network-on-chip (H-NoC) is developed for input broadcasting and on-the-fly partial results processing, reducing the data transmission volume and latency. Speed, power, area and computing accuracy are evaluated based on detailed device characterization and system modeling. For DNN computing, our design achieves 254× and 9.7× gain in power efficiency (GOPS/W) compared to GPU and ReRAM based designs, respectively.","A Ferroelectric FET based Power-efficient Architecture  for Data-intensive Computing  Yun Long, Taesik Na, Prakshi Rastogi, Karthik Rao, Asif Islam Khan, Sudhakar Yalamanchili and Saibal Mukhopadhyay  Georgia Institute of Technology, School of Electrical and Computer Engineering  Atlanta, GA, 30318, USA  ABSTRACT  In this paper, we present a ferroelectric FET (FeFET) based powerefficient architecture to accelerate data-intensive applications such  as deep neural networks (DNNs). We propose a cross-cutting  solution combining emerging device  technologies, circuit  optimizations, and micro-architecture innovations. At device level,  FeFET crossbar is utilized to perform vector-matrix multiplication  (VMM). As a field effect device, FeFET significantly reduces the  read/write energy compared with the resistive random-access  memory (ReRAM). At circuit level, we propose an all-digital  peripheral design, reducing the large overhead introduced by ADC  and DAC in prior works. In terms of micro-architecture innovation,  a dedicated hierarchical network-on-chip (H-NoC) is developed for  input broadcasting and on-the-fly partial results processing,  reducing the data transmission volume and latency. Speed, power,  area and computing accuracy are evaluated based on detailed  device characterization and system modeling. For DNN computing,  our design achieves 254x and 9.7x gain in power efficiency  (GOPS/W) compared to GPU and ReRAM based designs,  respectively.  1  INTRODUCTION  Due to the emergence of deep neural network (DNN),  acceleration of data-intensive vector-matrix and matrix-matrix  operations have received significant attention in recent past. Direct  integration of computation and storage within a memory device can  fundamentally eliminate the separation between compute and data,  thereby enabling orders of magnitude higher energy-efficiency in  data-intensive applications. There have been significant efforts in  exploiting emerging non-volatile memory (NVM), in particular,  resistive random-access memory (ReRAM), to perform in-memory  computation [1-4]. The key idea behind the ReRAM based  accelerator is utilizing crossbar array to perform vector-matrix  multiplication (VMM), which is the major type of computation for  DNN. The pioneering works, PRIME [1] and ISAAC [2],  demonstrated that ReRAM based DNN accelerators promise much  higher computing efficiency than the CPUs/GPUs.  However, when examined closely from a circuit rather than  microarchitecture perspective, we note that designing a scalable  architecture with ReRAM based in-memory computation remains  challenging. First, a crossbar with many parallel ReRAM devices  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. ICCAD '18, November 5–8, 2018, San Diego, CA, USA © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5950-4/18/11…$15.00 https://doi.org/10.1145/3240765.3240770 presents a low-impedance resistive load. This is fundamentally at  odds with CMOS gates which are designed to drive highimpedance loads (i.e. the gate of MOSFET). Although many prior  ReRAM has relatively low on-state resistance (1KΩ to 100KΩ for  works neglected  this challenge, we show  through circuit  (cid:1844)(cid:3042)(cid:3041) ) [5-7], the energy dissipation during VMM operation can be  simulations that power-hungry analog drivers are necessary to  ensure accurate computation in ReRAM crossbar. Second, as  detrimental as all ReRAM devices in the crossbar simultaneously  consume read current. Third, constrained by the crossbar size as  well as the system capacity, device re-programming are required to  solve large problems. The high programming energy (>1 pJ/cell)  [5, 8] in ReRAM as well as the in-efficient data movement can  degrade the computing efficiency. Further, the ADC and DAC in  prior works introduces large overhead for both power and chip area.  We argue that transforming the promise of in-memory  computation to a fully-fledged DNN accelerator requires a crosscutting solutions connecting emerging device technologies, circuit  techniques, and micro-architectural supports. Towards this end, we  propose a ferroelectric FET (FeFET) based high efficient  architecture for DNN acceleration. Our design is built on three core  concepts, namely, (i) leverage unique properties of FeFET for ultralow read/write energy; (ii) exploit the advantages of FeFET to  design an all-digital crossbar peripheral, eliminating  the  ADC/DAC in prior works; and (iii) enable efficient microarchitecture by connecting multiple VMM engines (crossbar and its  peripherals) using a hierarchical network-on-chip (H-NoC) with inrouter processing, reducing the data transmission volume and  latency.  FeFET as the basic computing cell: FeFET has similar  structure with a normal MOSFET, except it has a ferroelectric layer  inside the gate. The polarization of the ferroelectric layer can be  switched and retained, thereby, the transistor threshold voltage can  be tuned in a non-volatile fashion. The development of FeFET has  made tremendous progress in recent years with demonstrations  from commercial foundries [9-11]. As a three-terminal transistor  device, FeFET provides a high-impedance gate terminal and very  high on/off ratio, thanks to its steep switching slope [11]. The high  on/off ratio of FeFET ensures high computing accuracy, while low  read current (~ 1 nA/cell) and programming energy (~ 1 fJ/cell)  reduces crossbar energy [9].  FeFET based VMM engine:  We leverage the unique  characteristics of FeFET to replace the power/are hungry analog  peripherals with lightweight all-digital peripheral design. To be  more specific: first, rather than the voltage buffer which are  required to drive ReRAM, we observe that low-power digital  drivers are sufficient to drive the high-impedance gate of FeFET.  Second, we replace the power-hungry ADC with the precharge/discharge circuit and sense amplifier (SA) to realize the  function of time-to-digital conversion (TDC).  Micro-architecture for efficient data communication: We  develop a communication fabric connecting the VMM engines  using a hierarchical router network. We propose routers with  embedded logic to process the partial results within the NoC. The  proposed H-NoC is coupled with optimized partitioning of matrices  and data flow to enables efficient and scalable architecture using  many VMM engines.  The chip power, area, and computing speed analyses are driven  by experimentally calibrated FeFET models, coupled with detail  semi-custom design in 28nm CMOS including full-custom  (schematic/layout) design of VMM engines and synthesized  designs for digital components such as activation & pooling unit,  H-NoC with in-router processing, data flow controller, etc. The  architectural performance is evaluated using a cycle-level simulator  for benchmark convolutional neural networks (CNNs). We also  analyze the impact of device variations (modeled with stochastic  Gaussian noise) to the computing accuracy.   Even though FeFET based crossbar achieves more than 100x  lower energy dissipation than ReRAM crossbar, detailed circuit  simulations show that simply replacing ReRAM crossbar with  FeFET crossbar without optimization for circuit and architecture  will lead to only 1.2x reduction in power. This is because the power  is dominated by  the peripheral circuits  rather  than  the  device/crossbar itself. For our VMM engine design, benefiting  from the optimized all-digital peripherals, we observe 6.3x power  reduction than a conventional ReRAM design. Further, an  efficiency optimization is presented that couples the design of  VMM engines with the H-NoC to optimize the data flow, reduce  data access  latency and maximize computing efficiency  (GOPS/W). Overall, for the acceleration of DNN inference, our  design demonstrates 254x and 9.7x gain in computing efficiency  compared with GPU and ReRAM based design, respectively.  2 BACKGROUND  2.1 ReRAM based VMM Processing Engines  Figure 1: (a) ReRAM based VMM engine. (b) Current summed at bitline based on Kirchhoff’s law. (c) 16-bit multiplication. (d) PIM architecture. (cid:1848)(cid:3031)(cid:3031) (cid:1848)(cid:3046)(cid:3046) (cid:3398)(cid:3397)Op-amp Buffer t u p n i l a t i g i D DAC .  (cid:1844)(cid:2869) (cid:1844)(cid:2870) WL (cid:1844)(cid:3041) BL BL BL Figure 2: WL buffer is required for ReRAM crossbar.  2.2 Challenges of ReRAM VMM engine  Figure 1(a) illustrates an ReRAM based VMM engine with the  crossbar and peripherals. The DNN's parameters are first  programmed into the devices conductance, input vectors are fed as  word line (WL) voltage, and the current summed at each bitline  (BL) results the multiplication-accumulation (MAC) operation, as  shown in Figure 1(b). The digital-to-analog (DAC) and analog-todigital (ADC) conversions are required in and out of the array.  Note that one-resistor-one-transistor (1T1R) cell is commonly  used to increase the selectivity and reduce the leakage current [6].  In practice, rather than storing a whole parameter in a single device,  multiple devices connecting to the same WL are used to represent  one parameter value [1, 2]. As shown in Figure 1(c), to perform a  16-bit multiplication, 8 devices connecting to the same wordline  (WL) are utilized to represent one 16-bit number with each cell  stores 2 bits. Similarly, to reduce the overhead of DAC, the input  number is divided into several segments and sequentially fed into  the crossbar. The final result is summed together with a shift & add  unit. There are a few recent works explore the ReRAM based  processing-in-memory (PIM) architecture where ReRAM array  serves for both computation and memory [1, 3], shown in Figure  The first key challenge is the low on-state resistance ((cid:2174)(cid:2197)(cid:2196) ) in  1(d).  ReRAM. As illustrated in Figure 2, the WL load of ReRAM  crossbar consists of many parallel connected resistors, therefore, a  voltage buffer (typically designed with operational amplifier (Opamp)) with low output-impedance is required to provide large  enough current to drive the WL and provide stable WL voltage for  inference. This results in increased power dissipation (and chip area  overhead) especially for large crossbar arrays. Our SPICE  simulation indicates that to ensure a stable WL voltage (i.e. voltage  across the ReRAM device), the WL buffer consumes ~10x power  over the crossbar itself.  The second key challenge is the high programming energy.  As DNN becomes more complex and deeper, it is impractical to  assume that all DNN parameters can be mapped on chip at once.  Therefore, re-programming of crossbars is necessary. As ReRAM  programming energy is still very high (~ 1 pJ/cell) [5], the energyefficiency of ReRAM VMM engine degrades significantly with  increasing problem (DNN weights) size.  The third design challenge of ReRAM based VMM engine is  the power and area overheads of DAC/ADC. For instance, in [2],  the ADC occupies almost half of the system power and 45% of chip  area.    3 FERROELECTRIC FET  Ferroelectric FET is a transistor in which the ferroelectric oxide  layer is included in the gate dielectric stack, as shown in Figure  3(a). A ferroelectric oxide is an insulator which exhibits a            M i A w R D i p h c f f o h d t d n a b h g i H Controller eDRAM buffer Buffer 0 PE 0 Buffer 1 PE 1 e c a f r e t n i M A R D 512-bit bandwidth Buffer 2 Buffer 3 PE 2 PE 3 l s a r Chip interconnections VMM engines Router e h p i r e P L W g n i l o o P / n o i t a v i t c A 128 x 128 FeFET Crossbar Figure 3: (a) FeFET structure. (b) FeFET hysteresis loop with binary state encoded. (c) Gradual switching of the ferroelectric layer and corresponding  I-V characterization [12].  Table I. Comparison between FeFET and ReRAM.  Device characterization FeFET [9] ReRAM [6] Write endurance 105 (109)* 106 (1010)* Date retention > 10 years < 10 years  Write speed 500 ns (10 ns)* 50 ns (10 ns)* Write energy ~ 1 fJ ~ 5 pJ (1 pJ)* On/off ratio > 103 < 10 (103)* Area 4 F2 4 F2 * Date in parentheses are the best reported results from literatures. spontaneous electric polarization in the absence of electric field.  The direction of the polarization can be switched by applying a  into the 'ON' state (i.e. low (cid:1848)(cid:3047)(cid:3035) state). Similarly, if the polarization  voltage larger than the coercive voltage on the gate terminal of  FeFET [10]. As shown in Figure 3(a), when the polarization is  transistor 'OFF' state (i.e. high (cid:1848)(cid:3047)(cid:3035) state). Figure 3(b) shows the  pointing downwards, channel is in inversion, bringing the transistor  is pointing upwards, channel is in accumulation which gives the  FeFET hysteresis loop with binary state encoded. Moreover,  gradual switching of the ferroelectric layer (i.e. multi-level of  threshold voltages and channel conductance) has been  demonstrated. Figure 3(c) presents the experimental data showing  4 different levels of transistor threshold voltages [12].  Thanks to the recent discovery of ferroelectricity from silicon  doped hafnium oxide (Si:HfO2) [10], the HfO2 thin file based  FeFET is transferred to the mainstream CMOS platform with  demonstrations from major commercial foundries [9, 12]. It has  already been demonstrated that Hafnium oxide FeFET has good  temperature stability, writing endurance, data retention and  switching speed/energy which make FeFET now comparable or  even better than other non-volatile memory candidates such as  ReRAM (the comparison is shown in Table 1). The ultra-low  writing energy due to the unique electrical field effect switching  Local buffer BL Peripherals Figure 4: System architecture.  mechanism is the most prominent feature which distinguish FeFET  from other emerging technologies.   Besides utilizing FeFET as non-volatile memory [9, 10, 12],  there have been a few recent works exploring FeFET based logic  (AND, OR, etc.) design [13] and binary neural network  acceleration (using 4 FeFET cells for XNOR logic) [14]. However,  prior works focus on device/crossbar modeling and lack of  system/architecture level design. In this work, we propose a fullyfledged system  level design combining emerging device  technologies, circuit optimization, and architecture innovations.   4 SYSTEM DESIGN  Figure 4 shows the overview of the system architecture  consisting of 4 parallel processing engines (PE) connected to an  off-chip memory. Inside each PE, there are a set of interconnected  VMM engines. Our current design assumes there are 256 VMM  engines in each PE. A PE also contains one global buffer to store  the temporary input/output data, and an activation & pooling unit  with 128 × 128 devices, WL/BL peripherals, and a small local  to handle the activation function and pooling operations. H-NoC is  utilized to shuttle data between the buffer and VMM engines. At  the bottom level, each VMM engine consists of a FeFET crossbar  buffer.   4.1  FeFET based VMM engine  corresponding layout view of a 128 × 128 crossbar under 28nm  4.1.1 FeFET for 1-bit multiplication  Figure 5(a) shows the configuration of the FeFET crossbar,  where gate, drain, source of the transistor are connected to WL, BL  and source line (SL), respectively. Figure 5(b) shows the  technology. Weights are stored as transistor channel conductance  conductance (DNN's weight) ((cid:1835) = (cid:1848) × (cid:1833) ), FeFET is a field effect  (i.e. threshold voltage) and input vectors are used to drive WLs (i.e.  transistor gate).   device where drain current ((cid:1835)(cid:3031)(cid:3046) ) depends on the difference between  the gate voltage ((cid:1848)(cid:3034)(cid:3046) , represents input) and the threshold voltage  Unlike the case of ReRAM where the read current is the direct  multiplication of applied voltage (DNN's input) and device  ( (cid:1848)(cid:3047)(cid:3035) , represents weight). Hence, directly performing  the  multiplication of input and weight is not possible in FeFET.  To  address this, we employ the FeFET based AND logic [13] to  perform the 1-bit multiplication, as shown in Figure 5(c). One-bit                  .  Digital output Counter (cid:1848)(cid:3003)(cid:3013) (cid:1848)(cid:3019)(cid:3006)(cid:3007) (cid:1874)(cid:3042)(cid:3048)(cid:3047)(cid:1874)(cid:3045)(cid:3032)(cid:3033) SA Sense amplifier clk ⋯ C (cid:1848)(cid:3003)(cid:3013) WL WL (cid:1848)(cid:3031)(cid:3031) Pre-charge Discharge BL SL GND Ctrl (cid:1874)(cid:2869) (cid:1874)(cid:2870) Delay time When (cid:1855)(cid:1864)(cid:1863) = 0, (cid:1841)(cid:1873)(cid:1872)(cid:3020)(cid:3002) = 0 (reset) N pluses When (cid:1855)(cid:1864)(cid:1863) = 1, (cid:1841)(cid:1873)(cid:1872)(cid:3020)(cid:3002) = (cid:1848)(cid:3003)(cid:3013) (cid:3408) (cid:1848)(cid:3019)(cid:3006)(cid:3007) ? 1: 0 Figure 6: Pre-charge/discharge reading scheme and the SA+counter based  TDC design.  Our SPICE simulation indicates that, for a 128 × 128 FeFET  crossbar, our design consumes 2.7x less power than the ADC based  approach in ISAAC [2], while achieving the same speed.   4.1.3 On-chip memory   We employ a mix of SRAM and eDRAM as the on-chip  memory [2, 15]. The small (128 Byte) local buffer in each VMM  engine to store temporary input/output data is implemented using  SRAM.  Each PE also contains a global buffer implemented using  eDRAM. The global buffer receives input data from off-chip  DRAM and collect computing results from FeFET arrays. The size  of global buffer is 16 KB. In total, there are 192 KB on-chip  256 VMM engines (one 128 × 128 FeFET crossbar inside). In  memory (local buffer + global buffer) in our system.   On the other side, our system contains 4 PEs with each PE has  total, the maximum size of DNN parameter can be mapped on our  system is 2 MB. Compared with recent ReRAM based work such  as ISAAC (30 MB storage capacity consuming 66 W power), our  design is very compact in terms of chip area and power, enabling  the integration on the mobile and edge devices. With limited  storage capacity, we emphasize the necessity of considering device  re-programming during computing.  4.2 Micro-architecture support  In this subsection we discuss the micro-architectural support  including data partitioning and mapping, the communication  architecture, and how they are integrated to design a scalable  system.  4.2.1 Data partitioning and mapping  parameters of size s × s, the weight matrix is then partitioned into  several small segments with the granularity of s × s. Each partition  Figure 7 illustrates a common approach to partition a large  matrix-matrix multiplication operation across multiple VMM  is assigned (programmed) to a VMM engine, in total, n × m VMM  engines. Assuming the crossbar inside the VMM engine can hold  engine will be used (the definition for n and m are shown in Figure  7). Similarly, the input matrix is first transposed, partitioned and  sequentially fed into the corresponding VMM engines. Note that in  Figure 7, different color and shade are used to help tracking the  input and weight mapping.  Figure 5: (a) Configuration of FeFET crossbar. (b) Layout view of a 128 × 128 crossbar under 28nm technology. (c) FeFET based 1-bit multiplication (i.e. AND logic).  of weight is encoded as high (cid:1848)(cid:3047)(cid:3035) or low (cid:1848)(cid:3047)(cid:3035) , representing either 0  high or low WL voltage ((cid:1848)(cid:3034)(cid:3046) ).  When the input bit is 0 (i.e. low (cid:1848)(cid:3034)(cid:3046) ),  the current is always 0 with either high (cid:1848)(cid:3047)(cid:3035) or low (cid:1848)(cid:3047)(cid:3035) since the  or 1, respectively; similarly, 1 bit of input vector can be encoded as  if the input bit is 1 (i.e. high (cid:1848)(cid:3034)(cid:3046) ), the transistor is still off when (cid:1848)(cid:3047)(cid:3035)  is high (green dot in Figure 5(c)), but turns on when (cid:1848)(cid:3047)(cid:3035) is low (blue  transistor is turned off (red dot in Figure 5(c)). On the other hand,  dot in Figure 5(c)). The large on/off ratio of FeFET, thanks to its  steep subthreshold slope (<60 mV/Dec) [11], creates large  difference between the output '1' current and output '0' current.   Another advantage of  the proposed FeFET crossbar  configuration is that it has a similar architecture with the FeFET  memory array [9]. Therefore, the well-developed and chip verified  programming scheme can be seamlessly employed in our design.  4.1.2 VMM engine peripherals  One advantage of our design is that now the WL connects to  transistor's gate, which is a capacitive load. Therefore, there is no  word line voltage drop issue as in the ReRAM scenario. Moreover,  since we are performing 1-bit multiplication, there is no need for  DAC. This allows us to use digital CMOS for WL peripherals,  significantly reducing power dissipation without sacrificing  accuracy.   First, the BL is pre-charged to the supply voltage (cid:1848)(cid:3031)(cid:3031) . Then, during  To eliminate the large overhead of ADC, distinguished from  prior works and inspired by the reading scheme of the SRAM, we  same column are turned on, the BL voltage ( (cid:1848)(cid:3003)(cid:3013) ) drops with  propose a pre-charge/discharge approach as shown in Figure 6.  computing, depending on how many transistors (FeFETs) in the  voltage ((cid:1848)(cid:3019)(cid:3006)(cid:3007) ) and (cid:1848)(cid:3003)(cid:3013) periodically by a clock signal clk. When clk  1 if (cid:1848)(cid:3003)(cid:3013) (cid:3408) (cid:1848)(cid:3019)(cid:3006)(cid:3007) , or 0 if (cid:1848)(cid:3003)(cid:3013) < (cid:1848)(cid:3019)(cid:3006)(cid:3007) . Therefore, within 1 clock  different speed. We utilize a sense-amplifier (SA, similar with the  cycle, if (cid:1848)(cid:3003)(cid:3013) is larger than the reference voltage, the SA generates  one in SRAM) to sample the difference between the reference  is low, the output is 0 (reset). When clk is high, the output of SA is  a pulse; if not, the output of SA remains 0. We then utilize a counter  to count the number of pulses from SA. Basically, with a simple  SA and counter, we realize the time to digital converting (TDC).        (cid:1871)× (cid:1871) (cid:1871)(cid:1866) ⋯⋯ ⋯⋯ × (cid:1865) × (cid:1871) (cid:1871) ⋯⋯ ⋯⋯ (cid:1871) ⋯⋯ ⋯⋯ ⋯⋯⋯⋯⋯⋯ ⋯⋯⋯⋯⋯⋯ ⋯⋯⋯⋯⋯⋯ ⋯⋯⋯⋯⋯⋯ ⋯⋯⋯⋯⋯⋯⋯⋯ ⋯⋯ ⋯⋯ ⋯⋯ ⋯⋯ (cid:1866) × (cid:1871) (cid:1871) ⋯⋯ ⋯⋯ (cid:1871) ⋯⋯ ⋯⋯ (cid:1864) Input (transpose) ⋯⋯ ⋯⋯ ⋯⋯ ⋯⋯ ⋯⋯⋯⋯ ⋯⋯⋯⋯ ⋯ VMM12 Weight VMM1m ⋯⋯⋯⋯ VMM11 VMM21 VMM22 VMM2m ⋯⋯⋯⋯ ⋯⋯ ⋯⋯ ⋯⋯ VMMnm VMMn2 VMMn1 Send sequentially (cid:2869) (cid:2870) (cid:3046) m m m u u u s s s (cid:3046)⋯ m (cid:3041) u s Figure 7: Matrix partition and mapping to multiple VMM engines. Different color and shade are used to help tracking the input and weight mapping.  From Figure 7, we observe that each input segment is shared  across multiple VMM engines horizontally (e.g. VMM11, VMM12,  till VMM1m). We call it as row-wise input sharing. On the other  side, partial results generated from the same column of multiple  VMM engines should be summed together vertically (e.g. VMM11,  VMM21, till VMMn1 in Figure 7) since they belong to the same  column in the original weight matrix. We call it as column-wise  output summation.   4.2.2 VMM organization and H-NOC design  As shown in Figure 8(a), VMM engines are organized in a  hierarchy fashion with H-NoC for the interconnection. Even though  the hierarchical NoC topology is not a new concept [4], we show  that our H-NoC is specifically designed to address the discrepancy  between row-wise  input sharing and column-wise output  summation, reduce data transmission volume and latency.  At the bottom level, 4 VMM engines share a router. Then, 4  such routers are connected to a router in the higher level.  ports and corresponding I/O buffers. A 5 × 5 switching matrix is  Considering 256 VMM engines in a PE, there are 64, 16, 4, and 1  routers exist in different levels (Figure 8(a) only shows 3 levels).  Figure 8(b) shows the router design, containing five input/output  equipped to route input/output ports and the routing is based on  store-and-forward  (SAF)  approach. Distinguished  from  conventional router designs, we insert a computing block (i.e.  accumulator) inside the router to enable on-the-fly partial results  summation. The benefits of the proposed H-NoC design are in twofold:  First, H-NoC is dedicated to realizing efficient row-wise  input sharing. Figure 8(c)  illustrates  three different data  forwarding patterns. The first example shows the one-to-one  forwarding. The top-level router decodes the first 4-bit address  in out Top-left Switching matrix in out Top-right Bottom-left in out Accumulator in out Bottom-right in out Router with accumulator inside (b) Hierarchical NOC VMM engine Router (a) ‘1000 1000 1000’ Routers ‘1100 1000 0010’ VMM engines (c) ‘1111 1111 1000’ Destination VMM engines Figure 8: (a) Hierarchical network-on-chip. (b) Router design with  accumulator integrated. (c) Three different data forwarding patterns and  corresponding  addresses,  including one-to-one  forwarding  and  broadcasting.  (each bit represents the on/off of top-left, top-right, bottom-right,  bottom-left output ports, e.g. '1000' means the packet goes to its topleft branch) and sent the packet to its sub-level router. Then the sublevel router decodes the next 4-bits and repeats until the packet  arrives the designated VMM engine at the top-left corner. Besides  one-to-one forwarding, the packet can be broadcast. As shown in  the last example of Figure 8(c), since the first 4-bit address is '1111',  the top-level router broadcasts the packet to its sub-level routers in  four directions. This process repeats and finally a single packet is  assigned to 16 distributed VMM engines simultaneously.   show 2 × 8 = 16 segments). Based on our analyses, in Figure 9(a),  A case study is used to illustrate how the row-wise input sharing  benefits from the input broadcasting. As shown in Figure 9(a), a  large weight matrix is first partitioned into several segments (we  sharing the same router node ❹ (Again, we use different color and  the inputs are shared horizontally and the outputs are summed  vertically. Then, we map W11, W21, W31, W41 to 4 VMM engines  shade to help tracking the input and weight mapping). Then, input  Input vector Weight matrix (cid:1835)(cid:2869)(cid:1835)(cid:2870)(cid:1835)(cid:2871)(cid:1835)(cid:2872) (cid:1835)(cid:2873)(cid:1835)(cid:2874)(cid:1835)(cid:2875)(cid:1835)(cid:2876) (cid:1849)(cid:2869)(cid:2870)(cid:1849)(cid:2870)(cid:2870) (cid:1849)(cid:2871)(cid:2870)(cid:1849)(cid:2872)(cid:2870) (cid:1849)(cid:2873)(cid:2870)(cid:1849)(cid:2874)(cid:2870)(cid:1849)(cid:2875)(cid:2870)(cid:1849)(cid:2876)(cid:2870) (cid:1849)(cid:2869)(cid:2869)(cid:1849)(cid:2870)(cid:2869) (cid:1849)(cid:2871)(cid:2869)(cid:1849)(cid:2872)(cid:2869) (cid:1849)(cid:2873)(cid:2869)(cid:1849)(cid:2874)(cid:2869)(cid:1849)(cid:2875)(cid:2869)(cid:1849)(cid:2876)(cid:2869) (a) (cid:1845)(cid:2926)(cid:2911)(cid:2928)(cid:2930)(cid:2919)(cid:2911)(cid:2922) = (cid:3533) (cid:1835)(cid:3036) · (cid:1849)(cid:3036)(cid:2869) (cid:2872) (cid:3036)(cid:2880)(cid:2869) (cid:1835)(cid:2869) (cid:1835)(cid:2871) (cid:1849)(cid:2869)(cid:2869) (cid:1849)(cid:2871)(cid:2869) (cid:1835)(cid:2870) (cid:1835)(cid:2872) (cid:1849)(cid:2870)(cid:2869) (cid:1849)(cid:2872)(cid:2869) ❹ (cid:1845)(cid:3047)(cid:3042)(cid:3047)(cid:3028)(cid:3039) = (cid:3533) (cid:1835)(cid:3036) · (cid:1849)(cid:3036)(cid:2869) (cid:2876) (cid:3036)(cid:2880)(cid:2869) (cid:1835)(cid:2873) (cid:1835)(cid:2875) (cid:1849)(cid:2873)(cid:2869) (cid:1849)(cid:2875)(cid:2869) (cid:1835)(cid:2874) (cid:1835)(cid:2876) (cid:1849)(cid:2874)(cid:2869) (cid:1849)(cid:2876)(cid:2869) ❺ (cid:1835)(cid:2869) (cid:1835)(cid:2871) (cid:1849)(cid:2869)(cid:2870) (cid:1849)(cid:2871)(cid:2870) (cid:1835)(cid:2870) (cid:1835)(cid:2872) (cid:1849)(cid:2870)(cid:2871) (cid:1849)(cid:2872)(cid:2870) ❻ (cid:1835)(cid:2874) (cid:1835)(cid:2876) (cid:1849)(cid:2874)(cid:2870) (cid:1849)(cid:2876)(cid:2870) (cid:1835)(cid:2873) (cid:1835)(cid:2875) (cid:1849)(cid:2873)(cid:2870) (cid:1849)(cid:2875)(cid:2870) ❸ ❷ (cid:1835)(cid:2872) ❶ Address: 1100 1000 0010 Input partition is broadcast to  multiple VMM engines (b) Figure 9: A case study to illustrate how data are mapped via H-NoC.          summation ((cid:1845)(cid:3047)(cid:3042)(cid:3047)(cid:3028)(cid:3039) = ∑ (cid:1835)(cid:3036) ∙ (cid:1849)(cid:3036)(cid:2869) (cid:2876)(cid:3036)(cid:2880)(cid:2869) (cid:1845)(cid:3043)(cid:3028)(cid:3045)(cid:3047)(cid:3036)(cid:3028)(cid:3039) = ∑ (cid:1835)(cid:3036) ∙ (cid:1849)(cid:3036)(cid:2869) (cid:2876)(cid:3036)(cid:2880)(cid:2873) vectors are sent to corresponding VMM engines (horizontally  sharing). For example:  I4 (in blue) should go to two VMM engines  which store W41 and W42. Conventionally, this requires two packets  shown in Figure 9(b), router ❶ decode the first 4-bit address  and two cycles since there are two destination VMM engines. With  top-right directions (i.e. sends packet to routers ❷ and ❸). These  H-NoC, this can be done with a single packet and one cycle. As  to their top-left router ❹ and ❻. Finally, the packet goes to the  bottom-right leaf VMM engines of router ❹ and ❻.  (1100) and then broadcasts I4 to its sub-level router at top-left and  two routers then decode the next 4-bits (1000) and sent the packet   Note that, the broadcasting has a uniform spatial pattern (as in  Figure 9(b), I4 is broadcast to bottom-right VMM engines of  different regions) which is, coincidentally, in accordance with the  regulated weight matrix mapping.   Second, H-NoC is dedicated for efficient column-wise  partial results summation. Enabled by the in-router accumulator,  ). First, router ❹ and ❺ works  the results summation is performed on-the-fly, i.e. output  summation happens during data transmitting. Again, we use the  case in Figure 9 as an example. It takes two steps to get the  utilizing the built-in accumulator (i.e. (cid:1845)(cid:3043)(cid:3028)(cid:3045)(cid:3047)(cid:3036)(cid:3028)(cid:3039) = ∑ (cid:1835)(cid:3036) ∙ (cid:1849)(cid:3036)(cid:2869) ). Router ❷ then accumulates the partial  independently and parallelly, each receiving four partial results  results from ❹ and ❺ and sends the final summation to global  from the connected VMM engines and summing the partial data   and  buffer. Therefore, rather than sending each partial result to the  global buffer as separate packets, only 1 packet is sent to the global  buffer leveraging the on-the-fly/parallel processing enabled by HNOC.  working in parallel, the worst-case latency is limited to 4 × number	of	router	levels, since it takes 4 clock cycles for a router  In a general case, depending on how many VMM engines are  involved for one matrix computing, this process repeats until all the  partial results are summed together. As routers in the same level are  to accumulate partial results from its 4 branches.  Note that the VMM operation and input transfer are in pipeline,  ensuring high transmission rate and clock frequency. Also, the  proposed H-NoC is naturally deadlock free since the routing only  happens in the up-down directions.   As a conclusion, we argue that the proposed H-NoC design best  exploits  the  large weight-matrix partitioning,  input vector  broadcasting/share, and output summation. These benefits combine  to provide a harmonic, fully-fledged micro-architecture design.  Moreover, it can also be employed in other non-volatile memory  (such as ReRAM) based DNN accelerator architecture.  (cid:2872)(cid:3036)(cid:2880)(cid:2869) 4.3 Execution model  Figure 10 illustrates the chip-level execution model which  contains 6 steps. (1): The controller inside PE asks the memory  interface to load data from off-chip memory and stores in the global  buffer. (2): The data are then dispatched to VMM engines via HNoC for computation. (3): After the computing is done, partial  results are first summed on-the-fly and then collected back to the  global buffer. (4) and (5): The output from VMM engine arrays is  fed into the activation & pooling unit. The activation & pooling  unit supports the computation of rectified linear unit (ReLU) and  max pooling. (6): The result is sent back to off-chip memory.  .  ⋯ Off-chip DRAM ① ⑥ Memory interface Controller Global buffer Controller Global buffer ② ③ ④ ⑤ Array of VMM engines Connected with H-NOC Activation Pooling Array of VMM engines Connected with H-NOC Activation Pooling PE0 PE1 Figure 10. Chip-level execution model.  Table II: Power and area of our system.  Number Component Power (mW) Area (um2) WL peripherals 0.0001 0.38 BL peripherals 0.011 14.8 Local buffer (128 Bytes) 0.04 972.6 FeFET crossbar 0.00098* 2873.5 Array total 1.46 5789.1 Activation/pooling 19.2 165376 H-NOC 170.0 1616700 Global buffer (16 KB) 5.2 21000 controller 0.48 940.3 PE total 0.568 W 3.29 mm2 Chip total 2.274 W 13.14 mm2 * The power number for FeFET crossbar is for reading/inference. 128 1 256 1 4 1 Currently, our system only supports the inference stage of CNN  computing. Including training capability is our future work.  5 RESULTS  5.1 System power and area  We performed SPICE simulation with 28nm CMOS technology  using extracted netlist of the crossbar together with the proposed  WL/BL peripherals to estimate power and latency of the VMM  engine. The SPICE simulation of the VMM engine is then coupled  with synthesized digital blocks (such as shift & add unit, activation  & pooling unit, H-NoC, and controller) to form a completed chiplevel modeling. Synopsys Design Compiler and PrimeTime are  used to model the power and area of the synthesized components.  The on-chip memory is modeled with CACTI [16]. To best reduce  the off-chip data  transmission  latency, DRAM with high  bandwidth, such as High Bandwidth Memory (HBM) and Hybrid  Memory Cube (HMC) is desired. We model the off-chip data  access latency with the specification of HMC [17]. Table II  summarizes the power and area of each block of our system. The  total chip power is 2.27 W, and the chip area is 13.14 mm2.  The benchmark comprises 4 different well-known CNNs,  namely, AlexNet, GoogleNet, VGG-16, and VGG-19. We evaluate  the benchmarks performance with a large and sophisticated dataset,  ImageNet. We evaluate our benchmarks with Caffe deep learning  framework running on a state-of-the-art NVIDIA GTX 1080Ti  GPU.  5.2  Performance analyses      We first evaluate the performance of our system from two  independent aspects: H-NoC for data transmission and VMM  engine for computation.  First, for data transmission efficiency, we compare our H-NoC  design with the naive approach (no input broadcasting/reuse or  output on-the-fly processing) and ISAAC-like design (using two  stage hierarchical buffer for output accumulation) [2]. Figure 11(a)  shows the data (input, weights, and internal temporary data)  transmission latency for processing one image using 4 different  benchmark CNNs. On average, our design reduces the latency by  14.5x and 6.7x over the naive approach and ISAAC-like design  across the benchmark CNNs, respectively.   Second, we analyze the power efficiency of FeFET VMM  engines and compare with ReRAM based design, as illustrated in  Figure 11(b). For the baseline ReRAM design, we consider using  ADC in the BL peripherals and insert buffer to drive the WL. With  a simple technology replacement from ReRAM to FeFET (still  using the same peripherals), we observe that the baseline FeFET  based design achieves only 1.2x power reduction because the  power consumption on the peripherals (WL buffer and ADC at BL)  dominated. Therefore, we argue that only technology replacement  (ReRAM->FeFET) does not provide significant advantage at chip  and system level. On the other hand, with the optimized digital-like  peripherals (i.e. replace the power-hungry ADC with SA based  TDC design and also eliminate the WL buffer), significant power  efficiency improvement is observed (another 5.7x). In total, with  the  cross-cutting  solutions  combining  emerging device  technologies and circuit innovations, FeFET based VMM engine  demonstrates 6.3x power efficiency over the baseline ReRAM  design.   We then evaluate the overall efficiency (GOPS/W) on the  system level which combine both data transmission as well as  computation (including device re-programming). Figure 12(a)  shows the layer-by-layer efficiency of AlexNet. We observe that  FC layers shows lower efficiency mostly due to large weight matrix  requires more crossbar re-programming.  We also compare with  GPU and ReRAM based design across the benchmark, shown in  Figure 12(b). Thanks to high efficient H-NoC and low power  FeFET VMM engine, the average computing efficiency of our  design across the benchmarks are 254x and 9.7x higher over GPU  and ReRAM designs, respectively.   We argue that the device technologies, circuit optimization,  together with the micro-architecture innovation, make our work a  very computing efficient solution for DNN accelerator when  compared with recent NVM based designs.  5.3 Computing accuracy  The device variation of FeFET can potentially impact the  computing accuracy. Similar with prior ReRAM based design, we  deviation: σ) varies from 1% to 20%.  use Gaussian noise to represent the stochastic device variation [18].  We calibrate our device variation model with experimental data in  recent published works [9, 12]. The typical variation (the standard  device variation is low (σ < 3%). However, the accuracy quickly  Figure 13 shows the classification accuracy deterioration under  device variation. The computation shows good robustness when the  drops to zero when the variation is high, indicating that device with  high uniformity is high desired. Should aware that the observation  for FeFET here can be seamlessly applied to ReRAM which has  similar range of device variation [18].  6 COMPARISONS WITH PRIOR WORKS  Figure 11: System performance improvements for (a) H-NoC for data  transmission and (b) VMM engine for computation.  0 2 4 6 5.7x 8 10 12 14 16 Our design Baseline FeFET Baseline ReRAM WL BL Crossbar NOC Ohters 30 25 20 15 10 5 0 AlexNet GoogleNet Naïve ISAAC-like (a) VGG-16 H-NoC VGG-19 Power distribution (mW) (b) 6.3x 1.2x D a a t r t a s n a s m m i n o s s e i ( m r f / ) Figure 12: (a) Computing efficiency (GOPS/W) for the layer-by-layer  analysis of AlexNet. (b) Computing efficiency of benchmark DNNs and  comparison with GPU/baseline ReRAM.  0.1 1 10 100 1000 AlexNet GoogleNet VGG-19 GPU Baseline ReRAM Our design (b) ResNet 0 50 100 150 200 250 1 2 3 4 5 Layer number (a) 6 7 8 E i f f y c n e c i ( O G S P / W ) Conv layer FC layer E i f f y c n e c i ( O G S P / W ) Figure 13: The top-5 ImageNet classification accuracy considering device  variation.  0 0.2 0.4 0.6 0.8 1 AlexNet 0 0.0003 GoogleNet 0.001 VGG-16 0.01 VGG-19 0.1 0.03 0.03 p o T 5 u c c a r y c a                     .  [1]  [2]  [3]  [4]  [5]  P. Chi et al., ""PRIME: a novel processing-in-memory architecture for neural  network computation in ReRAM-based main memory,"" in ACM SIGARCH  Computer Architecture News, 2016, vol. 44, no. 3, pp. 27-39: IEEE Press.  A. Shafiee et al., ""ISAAC: A convolutional neural network accelerator with insitu analog arithmetic in crossbars,"" ACM SIGARCH Computer Architecture  News, vol. 44, no. 3, pp. 14-26, 2016.  L. Song, X. Qian, H. Li, and Y. Chen, ""PipeLayer: A pipelined ReRAM-based  accelerator for deep learning,"" in High Performance Computer Architecture  (HPCA), 2017 IEEE International Symposium on, 2017, pp. 541-552: IEEE.  D. Fujiki, S. Mahlke, and R. Das, ""In-Memory Data Parallel Processor,"" in  Proceedings of the Twenty-Third International Conference on Architectural  Support for Programming Languages and Operating Systems, 2018, pp. 1-14:  ACM.  S. Yu, B. Gao, Z. Fang, H. Yu, J. Kang, and H.-S. P. Wong, ""A neuromorphic  visual system using RRAM synaptic devices with sub-pJ energy and tolerance  to variability: Experimental characterization and large-scale modeling,"" in  Electron Devices Meeting (IEDM), 2012 IEEE International, 2012, pp. 10.4.  1-10.4. 4: IEEE.  S. Yu et al., ""Binary neural network with 16 Mb RRAM macro chip for  classification and online training,"" in Electron Devices Meeting (IEDM), 2016  IEEE International, 2016, pp. 16.2. 1-16.2. 4: IEEE.  C. Nail et al., ""Understanding RRAM endurance, retention and window margin  trade-off using experimental results and simulations,"" in Electron Devices  Meeting (IEDM), 2016 IEEE International, 2016, pp. 4.5. 1-4.5. 4: IEEE.  S. Park et al., ""Neuromorphic speech systems using advanced ReRAM-based  synapse,"" in Electron Devices Meeting (IEDM), 2013 IEEE International,  2013, pp. 25.6. 1-25.6. 4: IEEE.  [9] M. Trentzsch et al., ""A 28nm HKMG super low power embedded NVM  technology based on ferroelectric FETs,"" in Electron Devices Meeting (IEDM),  2016 IEEE International, 2016, pp. 11.5. 1-11.5. 4: IEEE.  J. Muller, T. S. Boscke, U. Schroder, R. Hoffmann, T. Mikolajick, and L. Frey,  ""Nanosecond Polarization Switching and Long Retention in a Novel MFIS[10]  [7]  [6]  [8]  The high demand for energy efficient execution of deep neural  networks have motivated the fast development of DNN accelerators  across various platforms including GPU, ASIC [15], FPGA [19],  and NVM [1-4]. Among these solutions, NVM based architecture  best exploits the in-memory computing and data-level parallelism,  largely eliminating the memory wall bottleneck in von-Neumann  architecture and providing the unprecedented performance over the  conventional approaches.   Beyond the use of a new technology, our design fundamentally  differs from prior ReRAM based NVM solution. First, we  demonstrate that orders of magnitude increase in the efficiency of  FeFET VMM crossbar may not lead to similar performance  enhancement at the system level as peripherals dominate system  power. Therefore, we present lightweight digital peripherals to  increase chip's efficiency. Second, we present a communication  fabric, realizing input vector sharing and partial results on-the-fly  processing. Third, we propose a compact system design with the  emphasis of device re-programming, making the system suitable  for power-constrained platforms.  We perform a detailed comparison between our design and  accelerators implemented with ASIC, FPGA and ReRAM. The key  design features are summarized in Table 3. Should note that the  ReRAM efficiency reported in Table 3 is higher than the number in  our simulation (Figure 12). This is because prior works did not  consider overheads of WL drivers. Also, to have an apple-to-apple  comparison, 443.5 GOPS/W for our system  is  the peak  performance without considering the device re-programming.  I. CONCLUSIONS  We present a FeFET based accelerator design for data-intensive  applications. With a cross-cutting solution combining emerging  device technologies, circuit optimization, and micro-architectural  innovations, state-of-the-art performance  is achieved. Our  simulation indicates the proposed design improves the computing  efficiency by 254x and 9.7x over GPU and ReRAM designs,  respectively. As FeFET continues to mature towards a commercial  technology, we show the pathway to a high-efficient architecture  that successfully leverages unique properties of this technology to  accelerate challenging data-intensive computing applications.  ACKNOWLEDGMENT  This material is supported by the National Science Foundation.  "
2018,Security aspects of neuromorphic MPSoCs.,"Neural networks and deep learning are promising techniques for bringing brain inspired computing into embedded platforms. They pave the way to new kinds of associative memories, classifiers, data-mining, machine learning or search engines, which can be the basis of critical and sensitive applications such as autonomous driving. Emerging non-volatile memory technologies integrated in the so called Multi-Processor System-on-Chip (MPSoC) architectures enable the realization of such computational paradigms. These architectures take advantage of the Network-on-Chip concept to efficiently carry out communications with dedicated distributed memories and processing elements. However, current MPSoC-based neuromorphic architectures are deployed without taking security into account. The growing complexity and the hyper-sharing of hardware resources of MPSoCs may become a threat, thus increasing the risk of malware infections and Trojans introduced at design time. Specially, MPSoC microarchitectural side-channels and fault injection attacks can be exploited to leak sensitive information and to cause malfunctions. In this work we present three contributions to that issue: i) first analysis of security issues in MPSoC-based neuromorphic architectures; ii) discussion of the threat model of the neuromorphic architectures; ii) demonstration of the correlation between SNN input and the neural computation.","Security Aspects of Neuromorphic MPSoCs Invited Paper Johanna Sepulveda Technical University of Munich Munich, Germany johanna.sepulveda@tum.de Cezar Reinbrecht Delft University of Technology Delft, Netherlands C.R.WedigReinbrecht@tudelft.nl Jean-Philippe Diguet CNRS, Lab-STICC Lorient, France jean-philippe.diguet@univ-ubs.fr ABSTRACT Neural networks and deep learning are promising techniques for bringing brain inspired computing into embedded platforms. They pave the way to new kinds of associative memories, classifiers, data-mining, machine learning or search engines, which can be the basis of critical and sensitive applications such as autonomous driving. Emerging non-volatile memory technologies integrated in the so called Multi-Processor System-on-Chip (MPSoC) architectures enable the realization of such computational paradigms. These architectures take advantage of the Network-on-Chip concept to efficiently carry out communications with dedicated distributed memories and processing elements. However, current MPSoC-based neuromorphic architectures are deployed without taking security into account. The growing complexity and the hyper-sharing of hardware resources of MPSoCs may become a threat, thus increasing the risk of malware infections and Trojans introduced at design time. Specially, MPSoC microarchitectural side-channels and fault injection attacks can be exploited to leak sensitive information and to cause malfunctions. In this work we present three contributions to that issue: i) first analysis of security issues in MPSoC-based neuromorphic architectures; ii) discussion of the threat model of the neuromorphic architectures; ii) demonstration of the correlation between SNN input and the neural computation. 1 INTRODUCTION The end of Moore’s law is pushing the renewed interest on entirely new computing approaches. Nature, as a source of highly optimized and efficient systems and strategies which have resulted from the evolutionary pressure of billions of years, has been used as a source of inspiration. This approach has marked the route to innovation in many areas. Neuromorphic computing is an example of this quest. It refers to unconventional architectures, devices and models inspired in the morphology and functionality of the human brain. The brain is composed of neurons, an electrically excitable cell that receives, processes and transmits information through signals called spikes. It integrates information of other neurons and exhibits complex internal dynamics. Neurons present excitatory or inhibitory behavior which is triggered according to the satisfaction of the activation/deactivation rules (neuronal firing behavior). The brain can be divided into regions, which are responsible for different functions. The biological brain contains about 100 billion neurons, more than 100,000 km of interconnections, and has an estimated Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and /or a fee. Request permissions from permissions@acm.org. ICCAD ’18, November 5–8, 2018, San Diego, CA, USA © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5950-4/18/11. . . $15.00 https://doi.org/10.1145/3240765.3274038 storage capacity of 1.25 × 1012 bytes [13]. The brain is the most complex organ in the human body. It is responsible for every thought, action, memory, perception and experience of the world. It is extremely effective and robust to execute energy-efficient operations in highly noisy environments. It is self-adaptive and self-optimizing, able to react autonomously to changes in the environment and the internal system state. All those characteristics are attractive for many application areas that require high performance, adaptability, and autonomous systems. Neuromorphic computing is a promising solution that paves the way to new computational paradigms, such as machine learning, and to efficient devices, such as associative memories, classifiers, data-mining or search engines. The term neuromorphic computing was first proposed in 1990 in [24]. It referred to an analog device able to emulate the primitive operations of the neurological systems. Currently, neuromorphic computers refer to any circuit (analog or digital) that emulates biological brain behavior to process data. They are composed by four elements: i) neurons, to process data; ii) synapses, which enable the learning and storage process; iii) axons, which allow the communication among neurons; and iv) a control system, to manage the learning process. A common trend in the semiconductor industry is to develop neuromorphic chipsets designed to better tackle machine-learning tasks by including neural processing units (NPUs) into their systems-on-Chip (SoCs). These hardware accelerators aim to support general-purpose approximation and machine learning programs. Some examples are the Kirin 970 from Huawei [15], A11 Bionic from Apple (included into the iPhone 8, 8 Plus and X) [1], Snapdragon 845 from Qualcomm [28], Loihi from Intel [6] and TrueNorth from IBM [16]. Neuromorphic SoCs are massive circuits. Similar to the brain, they rely on clustered circuits that perform highly specialized functionalities. Different functionalities are executed concurrently. The high parallelism of the Multi-Processors Systems-on-Chip (MPSoC) is becoming the key enabler platform to support neuromorphic computation. Several neuromorphic MPSoCs include digital or analog models of the neuron. However, a common approach in both scenarios is the use of memories to realize the synapses and a hierarchical communication structure (bus or Network-on-Chip) to emulate the axons. Neuromorphic SoCs, as the preferred platform for supporting machine learning algorithms, are attractive to attackers. The development of a machine-learning product is costly. It includes the access to well-structured and representative data sets to capture the relationships among features, the time spent on the training, evaluation and optimization processes. As a result, the topology and activation/deactivation rules (synaptic weights) of a set of neurons are generated. An attacker may exploit the hardware vulnerabilities of the neuromorphic MPSoCs to retrieve information of the design or algorithm supported by the system. In this paper, we present the following contributions: • First analysis of security issues in MPSoC-based neuromorphic architectures; • Description of five threat models to extract sensitive information about the design or configuration of spiking neural networks (SNNs) in MPSoCs; • First demonstration of the correlation between the SNN input and the neural computation (defined in this work as brain activity). 2 RELATED WORK Just recently, with the evolution of multi-processors and heterogeneous SoC architectures, the neuromorphic potential can finally be exploited. Several neuromorphic architectures have been proposed in the last years [1, 15, 16, 28]. In order to further improve the performance of the neuromorphic architectures, new technologies, such as memristors and in-memory computing, have been studied [17, 18, 22]. In this work, we discuss neuromorphic architectures implemented as MPSoCs and based on classical CMOS technology. Current NPU proposals differ in the neuron model, synapse approach and the communication strategy. According to the neuron model, neuromorphic MPSoCs can be classified into three categories: i) software-based; ii) digital-hardware-based, and iii) mixed-signal-hardware-based. Regarding the synapse, the works differ by the type and amount of memory employed to store data (SRAM, SDRAM, CAM). A bigger memory allows the representation of complex systems, which are able to support a higher number of synapses per neuron. According to the communication structure, neuromorphic architectures can use buses, Networks-on-Chip (NoC) or hybrid architectures. Table 1 summarizes the architectural characteristics of different neuromorphic MPSoCs. Previous works have shown the great impact of the microarchitecture on the neuromorphic MPSoC flexibility, performance and cost. While analog neural models can faithfully represent the spiking behavior, thus providing greater flexibility, the mixed-signal models present higher controllability. On the other hand, the digital neurons are easier to predict and understand. Digital neurons are used in SpiNNaker[9], DHyANA[14], TrueNorth[16], and Loihi[6] architectures. Communication structure has been identified as the bottleneck to meet the system requirements of the neuromorphic MPSoCs [8]. The authors of [27] use point-to-point connections. However, the complexity of the routing during physical design may limit the overall performance. In order to handle the communication complexity hierarchical buses [33] or NoCs [4, 6, 9, 11, 14, 16] are employed. The runtime reconfiguration capabilities of some of the neuromorphic architectures offer a high flexibility, being able to continue learning during the operation, at the cost of performance degradation and high area and power consumption. SpinNNaker and DHyana achieve high performance through a customized NoC topology (2D triangular toroidal and hierarchical NoC, respectively). Hierarchical NoCs are especially interesting because they favor the neural clusterization and region-based computation, such as in the biological brain. Hierarchical NoCs employ a mesh-based NoC in the global communication and a bus for local communication. Thus, by combining the fast broadcast capability of buses and the flexible global spike communication through the NoC, higher throughput can be achieved. 3 NEUROMORPHIC ARCHITECTURE High VLSI integration levels and demanding requirements of the neuromorphic architectures promote the adoption of MPSoCs as the preferred platform. These devices are organized in a tile-based architecture interconnected through a NoC using routers and links to exchange data. Each tile is composed of a single IP hardware core (e.g. single processor or memory) or of a cluster of IP hardware cores (several processors and shared memories), which communicate through a bus. In order to increase the efficiency and flexibility of those systems, memory hierarchies are integrated as well. Communication among tiles is performed through the NoC. In order to support the neuromorphic applications, neuromorphic hardware accelerators, also known as NPUs, are integrated into the MPSoCs. Three main components define the neuromorphic accelerators configuration: Neuron model, synapse and interconnection. Neuron model. The main processing unit. It is responsible to capture the stimulus from each synapse, process the information and to decide if a new stimulus (spike) will be propagated or not according to the neural firing behavior. These spikes (inputs and outputs) use a continuous range of values, where digital implementations are limited by the sampling rate and data representation. Synapse. Receives outer neurons spikes and stores them for the later process of the neuron. Generally, each source of spike represents a different synapse and a configurable weight. Since synapses are implemented through memories (SRAM, SDRAM, CAM), there is a trade-off between the number of synapses per neuron and hardware costs, such as area and power. Self-learning architectures are able to reconfigure the weight values of the synapse at run-time. Interconnection. The neuron-synapses relation of the system is defined through the interconnection structure. The communication topology defines the way the elements are connected. General architectures use general-purpose topologies, such as mesh, torus or ring NoCs. In SNNs, the most challenging communication feature is the control flow of the messages. Fully synchronous approaches are not common, because this kind of chip has timing constraints which are difficult to meet. Most proposals use the GALS (globally asynchronous locally synchronous) strategy. The same clock source is used inside each group of neurons, while between the groups an event-based asynchronous protocol takes place. 4 THREAT MODEL Cloud computing, neuromorphic systems, and approximate computing are few examples of the computational paradigms which are pushing the rise of new MPSoCs. Such paradigms promote a shift from a local computation to the ubiquitous and hyper-connected world, where resource sharing on-chip and extra-chip is possible. Many applications can be executed simultaneously in an MPSoC and many of them execute tasks that require the integration of the MPSoC into the cloud. While sharing MPSoC computational and communication resources promises to bring new benefits and opportunities, it also represents a risk. Security plays a key role in this scenario, where secure isolation, attack resilience and secrecy are required. Software approaches based on modern Operating Systems (OS) use advanced sandboxing techniques that isolate tasks by running them into virtual machines. The OS isolation provides domain-based separation between the tasks running on the same node and also prevent other outside tasks from inadvertently accessing tasks in its domain. However, this approach doesn’t cover all possible attacks. The activity of the victim’s task may be leaked through the so-called side-channel attacks. Shared resources and microarchitectural organization of the MPSoC may be used to recover the secret information of the victim or to gain control over the system resources. Researchers have shown the effectiveness of the microarchitectural attacks even under restrictive softwarecontrolled isolation scenarios [19, 23]. Thus, in order to guarantee the security of a system, hardware security must be also considered. Proposed Architecture ROLLS [27] BrainScaleS [33] EMBRACE [11] Neurogrid [4] SpiNNaker [9] DHyANA [14] TrueNorth [16] Loihi [6] Kirin [15] Bionic [1] Snapdragon NPUs [28] Learning Mechanism yes Interconnection Mechanism Point-to-Point (AER) Hierarchical Buses STAR NoC MESH NoC STAR NoC 2D Triangular Toroidal NoC BUS MESH NoC MESH NoC Synapse per Neuron 1-bit bistable (256) SRAM (256) (400) RAM (6x 109 ) TSM, SDRAM (103 ) SRAM, CAM (256) SRAM (256) SRAM (2048) (Not Disclosed) Neuron Number of Model Cores Exp. IF 256 (Analog) (1 neuron/core) Exp. IF 512 (Analog) (1 neuron/core) IF 400 (Analog) (1 neuron/core) Quad. IF 16 (Analog) (256x256 neurons/core) IF or IZHI 18 (Software) (1000 neurons/core) IZHI 16 (Digital) (16 neurons/core) Augmented IF 4096 (Digital) (256 neurons/core) CUBA Leaky IF 128 (Digital) (1024 neurons/core) (Not Disclosed) 8+12 (Software) (8xCPU + 12xGPU) (Not Disclosed) 6 (Software) ( 2xMonsoon + 4xMistral) (Not Disclosed) 8+1+1 (Software) (8xCPU + GPU + DSP) Table 1: Comparative table between state-of-the-art multi-core neuromorphic architectures. (Not Disclosed) (Not Disclosed) (Not Disclosed) (Not Disclosed) yes yes yes yes (Not Disclosed) MESH NoC no no yes yes no no Technology Node 180 nm 180 nm 65 nm 180 nm 130 nm 65 nm 28 nm 14 nm 10nm 10nm 20nm Hardware attacks can have three possible goals: i) IC counterfeit, which aims to clone or use ICs or intellectual property (IP) modules without allowance. An IC conterfeit technique is the microprobing, which by attaching microscopic needles onto the internal wiring of a chip, enables an external agent to copy the layout of a specific function; ii) retrieve data, which during the normal system operation sensitive information may be revealed through the physical features of the systems, such as technology features (e.g., power, electromagnetic emission, heat), design methodology (e.g., scan-chains, jtag), or the architecture (e.g., computational timing, memory accesses); or iii) modify the system functionality, thus allowing an attacker to assume control of the system. Fault attacks can be used to cause bit flips or glitches and therefore forcing some execution condition or bypassing some security check. Generally, the goal of the attacks to neuromorphic architectures will be to clone the SNN algorithm. Therefore, extracting the topology and synapses weights. SNN configuration is valuable. In order to design a SNN huge and specialized human and computational resources are employed. The cloning of SNNs allows an attacker to obtain monetary or market benefits. Considering all these attacks goals, the following subsections present threat models for neuromorphic architecture scenario, considering: i) IC attacks; ii) side channel attacks, and iii) fault attacks. 4.1 IC Attacks Integrated Circuit attacks aim to probe or change the device with the objective to reverse engineer the system. Consequently, the attacker will be able to clone a function or the entire chip. Although neuromorphic chips are extremely dense in terms of transistors, they are built in a modular manner - in replicated blocks. Therefore, if an attacker understands all the secrets of one module (number of neurons, synapses and computation strategy, interconnection among neurons), this information can be used to reverse engineer the complete system. One technique for an IC attack is based on a Focused Ion Beam. Focused-Ion Beam Attack: Focused Ion Beam (FIB) attacks are permanent modifications in the IC layout. A FIB can create shortcircuits, open wires, or even remove the transistor completely. As consequence, an attacker can force values or probe directly to the layout. This technique can be used to recover information from memories in integrated circuits. The work in [12] uses FIB to trim transistors of a SRAM, thus modifying their dynamic performance and leakage characteristics. As the symmetry of a 6T SRAM cell is corrupted, the startup behavior of the cell is biased. However, SRAM cells remains fully-functional. Hence, SNNs chips can be manipulated in the same way, and the weight stored in the system can be retrieved. The steps of such attacks are the following: • Attacker must decapsulate the target integrated circuit; • Attacker must find the area of interest in the layout; • Attacker must be able to access the layout through a FIB (no physical countermeasures in the front side or back side of the chip). 4.2 Side Channel Attacks Side channel analysis is a technique where the behavior of the hardware execution leaks indirect information. Usually, the attacker analyzes the leakage with statistical techniques to retrieve sensitive data, such as secret keys, embedded software, or interface information of the system. The nature of the leakage can be physical, caused by the technology characteristics, or logical, due the microarchitecture of the system. In this subsection, three side-channel attacks are discussed. Power/EM Analysis: During execution, the switching activity can reveal the patterns of the computation. This activity can be evaluated through the so called power attack[20], or even by the electromagnetic emissions, known as EM attack[10]. The typical approach to relate the switching activity with the logical information (zeros and ones), as presented in typical power and EM attacks, does not work for neuromorphic architectures. The reason is that spike neural networks perform complex multiplications and sums according to the weight of the synapses, and since there are a huge amount of operations in a not known relation neuron-synapses, it seems extremely difficult to directly correlate the binary transitions with the computation. However, the leakage in this scenario should be interpreted differently, not as switching activity, but brain activity. This brain activity is a metric that relates the process to the number of neurons activated during some time. According to the input value, different duration and intensity of the neural network spikes are produced. This fact creates a signature (template) that depends on the input and structure of the system. This approach requires a calibration step, which extracts the signatures for each possible input of the system before the real attack can be executed. Each SNN receives spikes as inputs, which are prior encoded through an algorithm. Therefore, to calibrate, the attacker must know this algorithm as well. The threat model for power or EM attacks in SNNs is listed below: • Attacker must access voltage supply or EM traces during execution; • Attacker must know the spiking encoding algorithm used for the input (for calibration); • Attacker must be able to manipulate inputs to the victim system (for calibration). Active Photon Probing: Semi-invasive laser imaging attacks use laser emissions to literally see the hardware activity [32]. With this technique, it is possible to see activated areas of the chip, where memories are the common victim. The regular structure of memories makes it easier to identify the accesses. However, this technique is invasive or semi-invasive, which means it must remove the package or parts of it. This proposed threat model aims to reveal SNN configuration, which means, to extract the relation of all neuronsynapse configured in the system. This relation refers to the neural network topology, and such information can be used to clone the SNN. To perform an attack, the SNN must be stressed with a high intensity of spikes in its inputs. As much as an SNN is stressed, it will activate all possible synapses. This corresponds to the accesses in the memory, where the positions refer to each neuron ID. Then, during this process, the optical analysis sets which positions were accessed, defining the weight zero for the ones never activated (no synapse-neuron connection). Current neuromorphic architectures use clustered solutions, where the memories with the synapseneuron relation can be well identified. Further optical analysis can be performed to understand the internal cluster behavior, for example, when a memory is shared between a group of neurons, the optical analysis should check which neuron has presented internal activity as well. Therefore, the laser imaging attack treat model is defined as: • Attacker must have physical access to the device; • Attacker must be able to identify memories location; • Attacker must be able to generate inputs to the system (stress process). Configuration/Test Interface ( JTAG):. A dangerous backdoor in many designs are specific interfaces, like the infrastructure for the design-for-testability (DFT), or the system configuration of FPGAs. Typically, both strategies use common industry protocols, such as JTAG. Neuromorphic architectures still do not have a standard test configuration, but as they become more popular, a standardization is expected. Since the SNN configuration is performed by filling the memories with specific content, in the same manner as it occurred for FPGAs, it is expected that JTAG-like protocols will emerge as the standard protocol. JTAG has already been a source of attacks [31], where the attacker can easily access information stored in the target device. Moreover, complex test structures, for example, scan chains, are expected to be used in neuromorphic architectures. Scan chains were already used for attackers [5]. Therefore, the threat model regarding this design-related attack is: • Attacker must access the target device; • Attacker must know the interface protocol, that enable attacker observability of the design (this includes test or runtime configuration interfaces); 4.3 Fault Attacks Fault attacks are another type of threat targetting system functionality. The attacker intentional causes errors in a system to provoke a specific effect to gain some privileged access [3]. There are temporary faults, known as transient effects (glitches), and permanent faults. Laser attacks are one of the most used techniques for performing fault attacks. Laser Attack: In neuromorphic architectures, one possible target of fault attacks is the learning mechanism. When present in the design, the self-learning mechanism triggers the update of the weight of each synapse. Their enable inputs are typically simply implemented through a few bits control signal. Therefore, an attacker can manipulate this vector through a laser source to update intentionally the weights and see the system behavior. In this case, the objective of the attack is to recover the self-learning strategy, understanding the steps configured in the mechanism. Note that a probe mechanism is also required for this attack. The threat model is: • Attacker must decapsulate target integrated circuit; • Attacker must find the area of interest in the layout; • Attacker must be able to input data in the SNN. • Attacker must be able to read the output of SNN. Note that variations of fault attacks can be used to trigger specific functions of the integrated circuits that provides deep information about the system. One classical example is the manipulation of the test structure. 5 VULNERABILITIES EVALUATION The experiments performed in this Section aims to demonstrate the leakage sources present in the MPSoC-based neuromorphic solutions. The first set of evaluations use a popular application of SNNs to observe the brain activity. The second sub-section provides an analysis of industrial layout ICs to put in evidence the implementation vulnerabilities of such designs. All experiments used an RTL neuromorphic MPSoC model. 5.1 Brain Activity Leakage DHyANA [14] is the MPSoC-based neuromorphic architecture used as the reference to evaluate the brain activity leakage. DHyANA uses the neuron model proposed by Izhikevich [2], which presents a higher expressiveness when compared with other popular neuron models, such as the Integrate-and-Fire mechanism [25]. This neuron model was implemented as a digital dedicated hardware with SRAM memories as the synapses, with 256 positions. The interconnection is performed through a hierarchical NoC, with a global mesh-based NoC and a local bus. Each spike in the system is represented as a packet with a neuron identification. The application mapped to DHyANA was the classification of the MNIST database (a dataset of handwritten images) [21]. The input used the Poisson Encoding of MNIST, which is the most popular method of converting static images into spike-trains [7, 26]. Each pixel of the image creates a spike-train related to its intensity. Higher intensities generate spikes at higher rates. Each pixel uses a window of 250 microseconds, with a maximum of 1000 spikes per window. According to the threat model presented of power/EM attacks, a calibration step is required before the attack is performed. Therefore, the first simulations used as input all possible intensities of a pixel. Simulation monitors stored the spiking activity in each cycle during the 250 microseconds of each pixel. As a result, signatures were produced, revealing the relationship between the computation of the neural network and each possible input (pixel intensity). Fig. 1 shows the signature of four different intensities. Note that in spite of this experiment using simulation probes, in a field experiment, the attacker could use power or electromagnetic traces instead, since the hardware activity is directly related to these physical features. After calibration, the attacker has a dictionary, where the effect on the system caused by each input is known. For instance, an attack could monitor the activity through hardware monitors (e.g., temperature, power and timing) and based on the trace extracted, correlate with each possible input. For example, the navigability of self-driven cars will be based on images, which are captured by cameras and sensors around the vehicle. Such images will be processed by SNNs-based image classifiers in order to identify traffic signs and events and then take driving decisions. By using the hardware monitors the attacker may retrieve the captured image, thus spying the cars’ camera. 5.2 Layout vulnerabilities Most physical attacks, that need access to the target device, aim to exploit layout information. The regular structure of memories simplifies the strategy of an attack and the localization of the attack spot in the silicon surface. Besides, the design of memories is much more sensible than logic gates, since they use few transistors to be area and power optimized. Our analysis consider as an example the IBM Truenorth design. The layout of this IC was disclosed in [16] with rich details. As shown in Fig. 2 from this paper, the position of the clusters and the position of each element inside it, are well identified. An attacker with such information can plan different targets of attacks. This includes the memory hierarchy [34], NoC routers as shown in [29, 30], neuron scheduler and the neuron itself. 6 COUNTERMEASURES ANALYSIS Based on the threat models presented in Section 4, corroborated by the analysis of Section 5, we can propose a set of countermeasures strategies to be implemented in MPSoC-based neuromorphic architectures. The main concern of the authors regards the intellectual property of the neural network algorithm, which is the topology (the way the neurons are logically connected), the synapse weights, Figure 1: Spikes Activity over different inputs. Input are pixels encoded according to NMIST. and the learning mechanism configuration. Table 2 present the techniques suggested for each threat model. 7 CONCLUSION This paper is the first to present an analysis of the security issues in MPSoC-based neuromorphic architectures. The spiking neural network configuration, given by the topology, synapses weight and learning mechanism were identified as the most sensitive and valuable information to extract in such platforms. Under the scope of hardware attacks, several threat models were presented, elucidating what each possible attack could target, and how it could be performed. Today, IC attacks, Side Channel Analysis Coding for New Efficient Associative Memories. In Proceedings of the Ninth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS ’13). Article 19, 9 pages. [9] S. B. Furber, D. R. Lester, L. A. Plana, J. D. Garside, E. Painkras, S. Temple, and A. D. Brown. 2013. Overview of the SpiNNaker System Architecture. IEEE Trans. Comput. 62, 12 (2013), 2454–2467. [10] Karine Gandolfi, Christophe Mourtel, and Francis Olivier. 2001. Electromagnetic Analysis: Concrete Results. Springer Berlin Heidelberg, Berlin, Heidelberg, 251– 261. [11] Jim Harkin, Fearghal Morgan, Liam McDaid, Steve Hall, Brian McGinley, and Seamus Cawley. 2009. A Reconfigurable and Biologically Inspired Paradigm for Computation Using Network-on-chip and Spiking Neural Networks. Int. J. Reconfig. Comput. 2009, Article 2 (Jan. 2009), 13 pages. http://dx.doi.org/10.1155/ 2009/908740 [12] C. Helfmeier, C. Boit, D. Nedospasov, and J. Seifert. 2013. Cloning Physically Unclonable Functions. In 2013 IEEE International Symposium on Hardware-Oriented Security and Trust (HOST). 1–6. [13] Michel A Hofman and Dean Falk. 2012. Evolution of the primate brain: from neuron to behavior. Vol. 195. Elsevier. [14] P. C. Holanda, C. R. W. Reinbrecht, G. Bontorin, V. V. Bandeira, and R. A. L. Reis. 2016. DHyANA: A NoC-based neural network hardware architecture. In 2016 IEEE International Conference on Electronics, Circuits and Systems. 177–180. [15] Huawei. 2017. HUAWEI Reveals the Future of Mobile AI at IFA 2017. (2017). https://consumer.huawei.com/en/press/news/2017/ifa2017-kirin970/. [16] IBM. 2017. IBM demos event-based gesture recognition using a brain-inspired chip at CVPR 2017. (2017). https://www.ibm.com/blogs/research/2017/07/braininspired-cvpr-2017. [17] Sung Hyun Jo, Ting Chang, Idongesit Ebong, Bhavitavya B. Bhadviya, Pinaki Mazumder, and Wei Lu. 2010. Nanoscale Memristor Device as Synapse in Neuromorphic Systems. Nano Letters 10, 4 (2010), 1297–1301. [18] S. Kim, M. Ishii, S. Lewis, T. Perri, M. BrightSky, W. Kim, R. Jordan, G. W. Burr, N. Sosa, A. Ray, J. . Han, C. Miller, K. Hosokawa, and C. Lam. 2015. NVM neuromorphic core with 64k-cell (256-by-256) phase change memory synaptic array with on-chip neuron circuits for continuous in-situ learning. In 2015 IEEE International Electron Devices Meeting (IEDM). 17.1.1–17.1.4. [19] Paul Kocher, Jann Horn, Anders Fogh, , Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz, and Yuval Yarom. 2019. Spectre Attacks: Exploiting Speculative Execution. In 40th IEEE Symposium on Security and Privacy (S&P’19). [20] P. C. Kocher, J. Jaffe, and B. Jun. 1999. Differential Power Analysis. In Proceedings of the 19th Annual International Cryptology Conference on Advances in Cryptology (CRYPTO 99). 388–397. [21] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278–2324. [22] Konstantin Likharev, Andreas Mayr, Ibrahim Muckra, and OzgÃČÂĳr TÃČÂĳrel. 2004. CrossNets: High-Performance Neuromorphic Architectures for CMOL Circuits. 1006 (01 2004), 146–63. [23] Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Anders Fogh, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, and Mike Hamburg. 2018. Meltdown: Reading Kernel Memory from User Space. In 27th USENIX Security Symposium (USENIX Security 18). [24] C. Mead. 1990. Neuromorphic electronic systems. Proc. IEEE 78, 10 (1990), 1629–1636. [25] Jeff Moehlis. 2008. SIAM Rev. 50, 2 (2008), 397–401. http://www.jstor.org/stable/ 20454122 [26] Peter O’Connor, Dan Neil, Shih-Chii Liu, Tobi Delbruck, and Michael Pfeiffer. 2013. Real-Time Classification and Sensor Fusion with a Spiking Deep Belief Network. 7 (10 2013), 178. [27] Ning Qiao, Hesham Mostafa, Federico Corradi, Marc Osswald, Fabio Stefanini, Dora Sumislawska, and Giacomo Indiveri. 2015. A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128K synapses. Frontiers in Neuroscience 9 (2015), 141. https://doi.org/10.3389/fnins.2015.00141 [28] Qualcomm. 2017. Meet the high-performance engine that makes AI even smarter. (2017). https://www.qualcomm.com/snapdragon/artificial-intelligence. [29] C. Reinbrecht, B. Forlin, A. Zankl, and J. SepÃžlveda. 2018. Earthquake x2014; A NoC-based optimized differential cache-collision attack for MPSoCs. In 2018 Design, Automation Test in Europe Conference Exhibition (DATE). 648–653. https: //doi.org/10.23919/DATE.2018.8342090 [30] C. Reinbrecht, A. Susin, L. Bossuet, and J. Sepulveda. 2016. Gossip NoC – Avoiding Timing Side-Channel Attacks through Traffic Management. In 2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). 601–606. [31] K. Rosenfeld and R. Karri. 2010. Attacks and Defenses for JTAG. IEEE Design Test of Computers 27, 1 (2010), 36–47. [32] D. Samyde, S. Skorobogatov, R. Anderson, and J. . Quisquater. 2002. On a new way to read data from memory. In First International IEEE Security in Storage Workshop, 2002. Proceedings. 65–69. [33] Dominik Schmidt. 2014. Automated Characterization of a Wafer-Scale Neuromorphic Hardware System. Masterarbeit. Universität Heidelberg. [34] J. Sepulveda, C. Reinbrecht, S. Payandeh, B. Niazmand, and G. Jervan. 2018. Understanding MPSoCs: Exploiting Memory Microarchitectural Vulnerabilities of High Performance NoC-Based MPSoCs. In SAMOS XVIII International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation. 1–6. Figure 2: Layout from the Truenorth IC from [16]. Fault Injection Type of Attack SCA Attack DPA/DEMA Active Photon Probing JTAG Attack Countermeasure Masked Logic Sensor Mesh JTAG Encryption Fault Monitor at Memories or EDC IC Camouflage Shield Test Known-Answer Test Table 2: Countermeasures strategies for each attack identified as a threat for neuromorphic architectures. Microprobing IC Modification (FIB) SFA/DFA (laser) IC Attack and Fault Attacks are the practical threats for neuromorphic systems, as shown in our vulnerability evaluation section. But despite the five threat models presented in this work, SNNs still have much more uncovered details that motivate research on the security field. ACKNOWLEDGMENTS This work was partially funded by the Fraunhofer High Performance Center for Secure Connected Systems of Munich and by the German Federal Ministry of Education and Research (BMBF), grant number 01IS160253 (ARAMiS II). "
2019,Centrifuge - Evaluating full-system HLS-generated heterogenous-accelerator SoCs using FPGA-Acceleration.,"To overcome the end of traditional scaling, modern SoC systems consist of general-purpose compute augmented with large numbers of specialized accelerators. However, building and evaluating these systems is extremely expensive and time-consuming, even in early stages of development. While high-level modeling and back-of-the-envelope calculations can provide early insights into a new system, there are key effects that only manifest at the full-system level. However, full-system design has traditionally required writing RTL or developing complex software models for the entire design. In this paper, we describe a methodology and implement an open-source flow (“Centrifuge”) that can rapidly generate and evaluate heterogeneous SoCs by combining an HLS toolchain with the open-source FireSim FPGA-accelerated simulation platform. Our system can quickly produce complete SoC systems with many integrated HLS-generated accelerators as specified by the user, simulate them quickly and cycle-accurately on FPGAs, and run complete software stacks on top, including booting Linux and running full application frameworks. Our system allows users to easily explore a variety of accelerator integration techniques, by automatically integrating accelerators in several ways-as tightly coupled RoCC accelerators, as accelerators that communicate over the standard on-chip network, and lastly as “disaggregated” accelerators that are directly attached to an Ethernet network between SoCs. By integrating these tools, our methodology allows users to rapidly generate an entire hardware/software stack for a customized SoC that can be fabricated as an ASIC and evaluate its end-to-end performance using cycle-exact FPGA simulation, allowing for agile design-space exploration of novel accelerator-based systems.",
2019,Wavelength-Routed Optical NoCs - Design and EDA - State of the Art and Future Directions - Invited Paper.,"Wavelength-routed optical network-on-chip (WRONoC) design consists of topological and physical synthesis. It covers many interacting design aspects such as wavelength assignment, message routing, network construction, component placement, and waveguide routing. Due to the high complexity of the design problem, current manual design usually trades optimality for scalability and feasibility, which results in performance degradation and waste of resources. In this paper, we will present an overview of the existing design automation approaches that have demonstrated their effectiveness in customizing and optimizing application-specific WRONoC designs, and of the potential design automation directions to address a wider range of design challenges. We will also discuss the advantages of comprehensive optimization considering multiple design aspects simultaneously, and the possible barriers that need to be removed to achieve this goal.",
2019,Task Mapping-Assisted Laser Power Scaling for Optical Network-on-Chips.,"Energy efficiency of an optical network-on-chip (ONoC) largely relies on an effective laser power management strategy. Addressing the limitations of existing techniques, we propose a Task Mapping-Assisted Laser Power Scaling (TMALPS) framework to optimize the energy consumption and the application execution time of an ONoC. Through the combination of task mapping exploration and runtime laser power reconfiguration applied to a wide range of application benchmarks, our TMALPS framework achieves an average of 66% saving of the energy-delay product, compared to a baseline scenario where the optimization techniques are not applied. Significant improvement over existing techniques was also observed. The hardware overhead required to support our TMALPS framework is minimal with intelligent reuse of existing on-chip hardware resource.",
